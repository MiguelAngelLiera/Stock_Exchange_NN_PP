{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import reader1 as rd\n",
    "import utilerias as utls\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import PIL.Image\n",
    "# Llamamos a la función antes de ejecutar el script\n",
    "utls.eliminar_archivos_registro(\"logs/lstm\")\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs/lstm')\n",
    "DATOS = 'Datos históricos COMI 3ene16-31dic2020 semanal.csv'\n",
    "cierre = rd.leer_archivo(DATOS).astype(float)\n",
    "c_entrenamiento = np.array(cierre[:int(len(cierre) * 0.7)])\n",
    "\n",
    "#Se convierte en un arreglo bidimensional\n",
    "c_entrenamiento = np.reshape(c_entrenamiento, (c_entrenamiento.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "m_m_s = MinMaxScaler(feature_range=(0,1))\n",
    "c_entrenamiento_n = m_m_s.fit_transform(c_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 8\n",
    "N = len(c_entrenamiento_n) #182\n",
    "X_entrenamiento = []\n",
    "y_entrenamiento = []\n",
    "for i in range(time_steps, N):\n",
    "    X_entrenamiento.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "    y_entrenamiento.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "X_entrenamiento, y_entrenamiento = np.array(X_entrenamiento), np.array(y_entrenamiento)\n",
    "#Se le da una tercera dimension al conjunto de entradas de entrenamiento\n",
    "X_entrenamiento = np.reshape(X_entrenamiento, (X_entrenamiento.shape[0], X_entrenamiento.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "red = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n"
     ]
    }
   ],
   "source": [
    "print(y_entrenamiento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Se entrena con un aprendizaje por reforzamiento del profesor\\nred = Sequential()\\nred.add(LSTM(units=50,return_sequences=True,input_shape=(X_entrenamiento.shape[1], 1)))#tiene un tamaño de entrada de 8 y de salida 1, input_shape = (8, 1)\\nred.add(Dropout(0.2))#Se apagan aleatoriamente el 20% de las neuronas de la capa anterior\\nred.add(LSTM(units=50,return_sequences=True))\\nred.add(Dropout(0.2))\\nred.add(LSTM(units=50,return_sequences=True))\\nred.add(Dropout(0.2))\\nred.add(LSTM(units=50))\\nred.add(Dropout(0.2))\\nred.add(Dense(units=1))\\nred.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\\nhistory = red.fit(X_entrenamiento,y_entrenamiento,epochs=60,batch_size=32)#batch_size=32\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Se entrena con un aprendizaje por reforzamiento del profesor\n",
    "red = Sequential()\n",
    "red.add(LSTM(units=50,return_sequences=True,input_shape=(X_entrenamiento.shape[1], 1)))#tiene un tamaño de entrada de 8 y de salida 1, input_shape = (8, 1)\n",
    "red.add(Dropout(0.2))#Se apagan aleatoriamente el 20% de las neuronas de la capa anterior\n",
    "red.add(LSTM(units=50,return_sequences=True))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(LSTM(units=50,return_sequences=True))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(LSTM(units=50))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(Dense(units=1))\n",
    "red.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\n",
    "history = red.fit(X_entrenamiento,y_entrenamiento,epochs=60,batch_size=32)#batch_size=32\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"losses = history.history['loss']\\nprint(losses)\\nplt.plot(range(len(losses)),losses)\\nplt.show()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener la pérdida durante el entrenamiento\n",
    "\"\"\"losses = history.history['loss']\n",
    "print(losses)\n",
    "plt.plot(range(len(losses)),losses)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_reales = cierre[int(len(cierre) * 0.7):] #verdaderos valores del conjunto de prueba\n",
    "precios_reales = np.reshape(precios_reales, (precios_reales.shape[0], 1)) #se le da una dimension mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# inputs = dataset_total[len(dataset_total) - len(dataset_test) - time_steps:].values\n",
    "\n",
    "inputs_cierre = cierre[len(cierre) - len(precios_reales) - time_steps:]#toma los ultimos 86 elementos, los ultimos 8 de entrenamiento y todos los de prueba  \n",
    "#print(len(cierre) - len(precios_reales) - time_steps)\n",
    "inputs_cierre = np.array(inputs_cierre).reshape(-1,1)\n",
    "#print(len(inputs_cierre))\n",
    "#print(inputs_cierre.shape)\n",
    "m_m_s_entrenamiento = MinMaxScaler(feature_range=(0,1))\n",
    "inputs_cierre = m_m_s_entrenamiento.fit_transform(inputs_cierre)# se normalizan los datos usandlo los parametros que se le dieron a m_m_s\n",
    "#inputs_cierre = m_m_s.transform(inputs_cierre) \n",
    "X_entrenamiento = []\n",
    "for i in range(time_steps, len(inputs_cierre)):\n",
    "    X_entrenamiento.append(inputs_cierre[i-time_steps:i, 0]) # setoman en paquetes de 8 \n",
    "X_entrenamiento = np.array(X_entrenamiento)\n",
    "X_entrenamiento = np.reshape(X_entrenamiento, (X_entrenamiento.shape[0], X_entrenamiento.shape[1], 1))#(78, 8, 1)\n",
    "\n",
    "precios_predichos = red.predict(X_entrenamiento)\n",
    "s_normalizar = precios_predichos\n",
    "precios_predichos = m_m_s_entrenamiento.inverse_transform(precios_predichos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La normalización funciona correctamente\n",
    "plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "# red.save('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_entrenamiento.size)\n",
    "# plt.plot(y_entrenamiento)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cierre_s_pred = c_entrenamiento_n\n",
    "\n",
    "# loss_m = []\n",
    "# for epoch in range(100):  # Número de épocas\n",
    "#     ts_cierre_s_pred = c_entrenamiento_n[:time_steps]#se obtienen los primeros time_steps(8) elementos del trainig set\n",
    "#     loss = []\n",
    "#     X_train_c_pred = []\n",
    "#     # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "#     for i in range(time_steps, N):\n",
    "#         # Obtener las características y la etiqueta actual\n",
    "#         x_actual = ts_cierre_s_pred[i-time_steps:i,0]\n",
    "#         X_train_c_pred.append(x_actual)\n",
    "#         x_actual = x_actual.reshape(1,time_steps,1)\n",
    "\n",
    "#         y_actual = np.array([y_entrenamiento[i-time_steps]])\n",
    "\n",
    "#         print(f\"x_actual: {x_actual}\")\n",
    "#         print(f\"y_actual: {y_actual}\")\n",
    "        \n",
    "#         # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "#         #loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "\n",
    "#         # Predicción del modelo\n",
    "#         #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "#         prediccion = red(x_actual)\n",
    "        \n",
    "#         # Agregar la predicción a las características para el siguiente paso\n",
    "#         # print(ts_cierre_s_pred)\n",
    "#         print(f\"prediccion: {prediccion}\")\n",
    "#         ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "\n",
    "\n",
    "\n",
    "#     # print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "#     # loss_m.append(np.mean(np.array(loss)))\n",
    "#     X_train_c_pred = np.array(X_train_c_pred)\n",
    "#     X_train_c_pred = np.reshape(X_train_c_pred, (X_train_c_pred.shape[0], X_train_c_pred.shape[1], 1))\n",
    "#     history = red.fit(X_train_c_pred, y_entrenamiento, epochs=1, batch_size=32)\n",
    "#     loss = history.history['loss']\n",
    "#     loss_m.append(loss)\n",
    "#     loss_m.append(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "class CustomLearningRateScheduler(Callback):\n",
    "    def __init__(self, initial_lr, decay_factor):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_factor = decay_factor\n",
    "        self.iteration = 0  # Contador de iteraciones\n",
    "        self.lote_designado = 1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        print(f\"loss en el callback: {logs['loss']}, batch {batch}, lote_designado {self.lote_designado}\")\n",
    "        if (logs['loss'] <= 0.01 and batch == self.lote_designado):\n",
    "            self.lote_designado = self.lote_designado + 1\n",
    "            self.decay_factor = self.decay_factor  * 0.8\n",
    "            print(f\">>nuevo factor: {self.decay_factor*0.8}\")\n",
    "        #lr = self.initial_lr * (self.decay_factor ** self.iteration)\n",
    "        lr = self.initial_lr / (1 + self.decay_factor * self.iteration)\n",
    "        print(f\"lr: {lr}, batch: {batch}\")\n",
    "        if (logs['epoca'] == 1):\n",
    "            writer.add_scalar(\"Learning Rate en cada batch: \",lr,batch)\n",
    "        #print(red.summary())\n",
    "        K.set_value(red.optimizer.lr, lr)\n",
    "        self.iteration += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        K.set_value(red.optimizer.lr, self.initial_lr)\n",
    "        self.iteration = 0\n",
    "        print(\"Se resetea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se resetea\n",
      "y_entrenamiento: [0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24278472]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03868245705962181\n",
      "Predicción post entrenamiento : [[0.19537914]]\n",
      "PERDIDAAAA despues: 0.022282421588897705\n",
      "loss en el callback: 0.040994416922330856, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.24278472]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.18011832]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.24278472]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0057600741274654865\n",
      "Predicción post entrenamiento : [[0.1708916]]\n",
      "PERDIDAAAA despues: 0.004444679245352745\n",
      "loss en el callback: 0.0023720236495137215, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.18011832]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.24278472 0.18011832]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17471977]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.24278472 0.18011832]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00042090474744327366\n",
      "Predicción post entrenamiento : [[0.1720672]]\n",
      "PERDIDAAAA despues: 0.0003191007999703288\n",
      "loss en el callback: 0.0003323341952636838, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.18011832]\n",
      "  [0.17471977]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24278472\n",
      " 0.18011832 0.17471977]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.183022]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24278472\n",
      "  0.18011832 0.17471977]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007435669540427625\n",
      "Predicción post entrenamiento : [[0.17821206]]\n",
      "PERDIDAAAA despues: 0.0005043832934461534\n",
      "loss en el callback: 0.0016135749174281955, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.18011832]\n",
      "  [0.17471977]\n",
      "  [0.18302201]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.24278472 0.18011832\n",
      " 0.17471977 0.18302201]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19015017]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.24278472 0.18011832\n",
      "  0.17471977 0.18302201]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0041754115372896194\n",
      "Predicción post entrenamiento : [[0.18258536]]\n",
      "PERDIDAAAA despues: 0.0032550005707889795\n",
      "loss en el callback: 0.006239014677703381, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.18011832]\n",
      "  [0.17471977]\n",
      "  [0.18302201]\n",
      "  [0.19015017]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.24278472 0.18011832 0.17471977\n",
      " 0.18302201 0.19015017]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19163355]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.24278472 0.18011832 0.17471977\n",
      "  0.18302201 0.19015017]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00211173202842474\n",
      "Predicción post entrenamiento : [[0.18729074]]\n",
      "PERDIDAAAA despues: 0.001731456839479506\n",
      "loss en el callback: 0.003056044690310955, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.18011832]\n",
      "  [0.17471977]\n",
      "  [0.18302201]\n",
      "  [0.19015017]\n",
      "  [0.19163355]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.24278472 0.18011832 0.17471977 0.18302201\n",
      " 0.19015017 0.19163355]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.2067931]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.24278472 0.18011832 0.17471977 0.18302201\n",
      "  0.19015017 0.19163355]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003640703624114394\n",
      "Predicción post entrenamiento : [[0.2052335]]\n",
      "PERDIDAAAA despues: 0.0034549289848655462\n",
      "loss en el callback: 0.0007618779200129211, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.18011832]\n",
      "  [0.17471977]\n",
      "  [0.18302201]\n",
      "  [0.19015017]\n",
      "  [0.19163355]\n",
      "  [0.2067931 ]]]\n",
      "ejemplar: [0.04223169 0.24278472 0.18011832 0.17471977 0.18302201 0.19015017\n",
      " 0.19163355 0.2067931 ]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22877839]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.24278472 0.18011832 0.17471977 0.18302201 0.19015017\n",
      "  0.19163355 0.2067931 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001071276143193245\n",
      "Predicción post entrenamiento : [[0.22833095]]\n",
      "PERDIDAAAA despues: 0.0010421868646517396\n",
      "loss en el callback: 7.186967559391633e-05, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.24278472]\n",
      "  [0.18011832]\n",
      "  [0.17471977]\n",
      "  [0.18302201]\n",
      "  [0.19015017]\n",
      "  [0.19163355]\n",
      "  [0.2067931 ]\n",
      "  [0.22877839]]]\n",
      "ejemplar: [0.24278472 0.18011832 0.17471977 0.18302201 0.19015017 0.19163355\n",
      " 0.2067931  0.22877839]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.25621253]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.24278472 0.18011832 0.17471977 0.18302201 0.19015017 0.19163355\n",
      "  0.2067931  0.22877839]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006595514714717865\n",
      "Predicción post entrenamiento : [[0.25465345]]\n",
      "PERDIDAAAA despues: 0.0005819025100208819\n",
      "loss en el callback: 0.0008858848595991731, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.18011832]\n",
      "  [0.17471977]\n",
      "  [0.18302201]\n",
      "  [0.19015017]\n",
      "  [0.19163355]\n",
      "  [0.2067931 ]\n",
      "  [0.22877839]\n",
      "  [0.25621253]]]\n",
      "ejemplar: [0.18011832 0.17471977 0.18302201 0.19015017 0.19163355 0.2067931\n",
      " 0.22877839 0.25621253]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2449586]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.18011832 0.17471977 0.18302201 0.19015017 0.19163355 0.2067931\n",
      "  0.22877839 0.25621253]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001333144842647016\n",
      "Predicción post entrenamiento : [[0.24258398]]\n",
      "PERDIDAAAA despues: 0.001165378256700933\n",
      "loss en el callback: 0.0022902069613337517, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.17471977]\n",
      "  [0.18302201]\n",
      "  [0.19015017]\n",
      "  [0.19163355]\n",
      "  [0.2067931 ]\n",
      "  [0.22877839]\n",
      "  [0.25621253]\n",
      "  [0.24495859]]]\n",
      "ejemplar: [0.17471977 0.18302201 0.19015017 0.19163355 0.2067931  0.22877839\n",
      " 0.25621253 0.24495859]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.2456327]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.17471977 0.18302201 0.19015017 0.19163355 0.2067931  0.22877839\n",
      "  0.25621253 0.24495859]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011356450850144029\n",
      "Predicción post entrenamiento : [[0.2456483]]\n",
      "PERDIDAAAA despues: 0.0011366968974471092\n",
      "loss en el callback: 1.7897880866257765e-07, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.18302201]\n",
      "  [0.19015017]\n",
      "  [0.19163355]\n",
      "  [0.2067931 ]\n",
      "  [0.22877839]\n",
      "  [0.25621253]\n",
      "  [0.24495859]\n",
      "  [0.24563269]]]\n",
      "ejemplar: [0.18302201 0.19015017 0.19163355 0.2067931  0.22877839 0.25621253\n",
      " 0.24495859 0.24563269]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25156128]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.18302201 0.19015017 0.19163355 0.2067931  0.22877839 0.25621253\n",
      "  0.24495859 0.24563269]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019604775588959455\n",
      "Predicción post entrenamiento : [[0.2512058]]\n",
      "PERDIDAAAA despues: 0.0019291243515908718\n",
      "loss en el callback: 0.00010460086923558265, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.19015017]\n",
      "  [0.19163355]\n",
      "  [0.2067931 ]\n",
      "  [0.22877839]\n",
      "  [0.25621253]\n",
      "  [0.24495859]\n",
      "  [0.24563269]\n",
      "  [0.25156128]]]\n",
      "ejemplar: [0.19015017 0.19163355 0.2067931  0.22877839 0.25621253 0.24495859\n",
      " 0.24563269 0.25156128]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2575194]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.19015017 0.19163355 0.2067931  0.22877839 0.25621253 0.24495859\n",
      "  0.24563269 0.25156128]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004169403575360775\n",
      "Predicción post entrenamiento : [[0.2554587]]\n",
      "PERDIDAAAA despues: 0.003907529637217522\n",
      "loss en el callback: 0.0033568665385246277, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19163355]\n",
      "  [0.2067931 ]\n",
      "  [0.22877839]\n",
      "  [0.25621253]\n",
      "  [0.24495859]\n",
      "  [0.24563269]\n",
      "  [0.25156128]\n",
      "  [0.25751939]]]\n",
      "ejemplar: [0.19163355 0.2067931  0.22877839 0.25621253 0.24495859 0.24563269\n",
      " 0.25156128 0.25751939]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26238757]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19163355 0.2067931  0.22877839 0.25621253 0.24495859 0.24563269\n",
      "  0.25156128 0.25751939]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004298720974475145\n",
      "Predicción post entrenamiento : [[0.2604165]]\n",
      "PERDIDAAAA despues: 0.004044141620397568\n",
      "loss en el callback: 0.003378895577043295, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.2067931 ]\n",
      "  [0.22877839]\n",
      "  [0.25621253]\n",
      "  [0.24495859]\n",
      "  [0.24563269]\n",
      "  [0.25156128]\n",
      "  [0.25751939]\n",
      "  [0.26238757]]]\n",
      "ejemplar: [0.2067931  0.22877839 0.25621253 0.24495859 0.24563269 0.25156128\n",
      " 0.25751939 0.26238757]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.26914802]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.2067931  0.22877839 0.25621253 0.24495859 0.24563269 0.25156128\n",
      "  0.25751939 0.26238757]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030129095539450645\n",
      "Predicción post entrenamiento : [[0.2681509]]\n",
      "PERDIDAAAA despues: 0.0029044393450021744\n",
      "loss en el callback: 0.001079779351130128, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22877839]\n",
      "  [0.25621253]\n",
      "  [0.24495859]\n",
      "  [0.24563269]\n",
      "  [0.25156128]\n",
      "  [0.25751939]\n",
      "  [0.26238757]\n",
      "  [0.26914802]]]\n",
      "ejemplar: [0.22877839 0.25621253 0.24495859 0.24563269 0.25156128 0.25751939\n",
      " 0.26238757 0.26914802]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27578858]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22877839 0.25621253 0.24495859 0.24563269 0.25156128 0.25751939\n",
      "  0.26238757 0.26914802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008923355489969254\n",
      "Predicción post entrenamiento : [[0.27331364]]\n",
      "PERDIDAAAA despues: 0.008461898192763329\n",
      "loss en el callback: 0.006713603623211384, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.25621253]\n",
      "  [0.24495859]\n",
      "  [0.24563269]\n",
      "  [0.25156128]\n",
      "  [0.25751939]\n",
      "  [0.26238757]\n",
      "  [0.26914802]\n",
      "  [0.27578858]]]\n",
      "ejemplar: [0.25621253 0.24495859 0.24563269 0.25156128 0.25751939 0.26238757\n",
      " 0.26914802 0.27578858]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.27794477]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.25621253 0.24495859 0.24563269 0.25156128 0.25751939 0.26238757\n",
      "  0.26914802 0.27578858]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010571715421974659\n",
      "Predicción post entrenamiento : [[0.27427828]]\n",
      "PERDIDAAAA despues: 0.00983119010925293\n",
      "loss en el callback: 0.015504548326134682, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.24495859]\n",
      "  [0.24563269]\n",
      "  [0.25156128]\n",
      "  [0.25751939]\n",
      "  [0.26238757]\n",
      "  [0.26914802]\n",
      "  [0.27578858]\n",
      "  [0.27794477]]]\n",
      "ejemplar: [0.24495859 0.24563269 0.25156128 0.25751939 0.26238757 0.26914802\n",
      " 0.27578858 0.27794477]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.27409306]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.24495859 0.24563269 0.25156128 0.25751939 0.26238757 0.26914802\n",
      "  0.27578858 0.27794477]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015898287296295166\n",
      "Predicción post entrenamiento : [[0.27040207]]\n",
      "PERDIDAAAA despues: 0.014981129206717014\n",
      "loss en el callback: 0.01755976304411888, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.24563269]\n",
      "  [0.25156128]\n",
      "  [0.25751939]\n",
      "  [0.26238757]\n",
      "  [0.26914802]\n",
      "  [0.27578858]\n",
      "  [0.27794477]\n",
      "  [0.27409306]]]\n",
      "ejemplar: [0.24563269 0.25156128 0.25751939 0.26238757 0.26914802 0.27578858\n",
      " 0.27794477 0.27409306]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.27317297]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.24563269 0.25156128 0.25751939 0.26238757 0.26914802 0.27578858\n",
      "  0.27794477 0.27409306]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013069020584225655\n",
      "Predicción post entrenamiento : [[0.27013114]]\n",
      "PERDIDAAAA despues: 0.012382789514958858\n",
      "loss en el callback: 0.014537754468619823, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.25156128]\n",
      "  [0.25751939]\n",
      "  [0.26238757]\n",
      "  [0.26914802]\n",
      "  [0.27578858]\n",
      "  [0.27794477]\n",
      "  [0.27409306]\n",
      "  [0.27317297]]]\n",
      "ejemplar: [0.25156128 0.25751939 0.26238757 0.26914802 0.27578858 0.27794477\n",
      " 0.27409306 0.27317297]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.27369753]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.25156128 0.25751939 0.26238757 0.26914802 0.27578858 0.27794477\n",
      "  0.27409306 0.27317297]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006646155379712582\n",
      "Predicción post entrenamiento : [[0.2715432]]\n",
      "PERDIDAAAA despues: 0.006299539003521204\n",
      "loss en el callback: 0.007479861378669739, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25751939]\n",
      "  [0.26238757]\n",
      "  [0.26914802]\n",
      "  [0.27578858]\n",
      "  [0.27794477]\n",
      "  [0.27409306]\n",
      "  [0.27317297]\n",
      "  [0.27369753]]]\n",
      "ejemplar: [0.25751939 0.26238757 0.26914802 0.27578858 0.27794477 0.27409306\n",
      " 0.27317297 0.27369753]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.27476877]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25751939 0.26238757 0.26914802 0.27578858 0.27794477 0.27409306\n",
      "  0.27317297 0.27369753]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007884434424340725\n",
      "Predicción post entrenamiento : [[0.2732482]]\n",
      "PERDIDAAAA despues: 0.00761670945212245\n",
      "loss en el callback: 0.005216431804001331, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.26238757]\n",
      "  [0.26914802]\n",
      "  [0.27578858]\n",
      "  [0.27794477]\n",
      "  [0.27409306]\n",
      "  [0.27317297]\n",
      "  [0.27369753]\n",
      "  [0.27476877]]]\n",
      "ejemplar: [0.26238757 0.26914802 0.27578858 0.27794477 0.27409306 0.27317297\n",
      " 0.27369753 0.27476877]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2759426]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.26238757 0.26914802 0.27578858 0.27794477 0.27409306 0.27317297\n",
      "  0.27369753 0.27476877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.085260924417526e-05\n",
      "Predicción post entrenamiento : [[0.27608594]]\n",
      "PERDIDAAAA despues: 8.345109381480142e-05\n",
      "loss en el callback: 4.8034311475930735e-05, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26914802]\n",
      "  [0.27578858]\n",
      "  [0.27794477]\n",
      "  [0.27409306]\n",
      "  [0.27317297]\n",
      "  [0.27369753]\n",
      "  [0.27476877]\n",
      "  [0.27594259]]]\n",
      "ejemplar: [0.26914802 0.27578858 0.27794477 0.27409306 0.27317297 0.27369753\n",
      " 0.27476877 0.27594259]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2782928]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26914802 0.27578858 0.27794477 0.27409306 0.27317297 0.27369753\n",
      "  0.27476877 0.27594259]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020247799693606794\n",
      "Predicción post entrenamiento : [[0.27874368]]\n",
      "PERDIDAAAA despues: 0.00018984974303748459\n",
      "loss en el callback: 0.0004851959820371121, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.27578858]\n",
      "  [0.27794477]\n",
      "  [0.27409306]\n",
      "  [0.27317297]\n",
      "  [0.27369753]\n",
      "  [0.27476877]\n",
      "  [0.27594259]\n",
      "  [0.2782928 ]]]\n",
      "ejemplar: [0.27578858 0.27794477 0.27409306 0.27317297 0.27369753 0.27476877\n",
      " 0.27594259 0.2782928 ]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27988246]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.27578858 0.27794477 0.27409306 0.27317297 0.27369753 0.27476877\n",
      "  0.27594259 0.2782928 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014306440716609359\n",
      "Predicción post entrenamiento : [[0.28081247]]\n",
      "PERDIDAAAA despues: 0.0013611557660624385\n",
      "loss en el callback: 0.002233365550637245, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.27794477]\n",
      "  [0.27409306]\n",
      "  [0.27317297]\n",
      "  [0.27369753]\n",
      "  [0.27476877]\n",
      "  [0.27594259]\n",
      "  [0.2782928 ]\n",
      "  [0.27988246]]]\n",
      "ejemplar: [0.27794477 0.27409306 0.27317297 0.27369753 0.27476877 0.27594259\n",
      " 0.2782928  0.27988246]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.280703]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.27794477 0.27409306 0.27317297 0.27369753 0.27476877 0.27594259\n",
      "  0.2782928  0.27988246]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010218576062470675\n",
      "Predicción post entrenamiento : [[0.28147238]]\n",
      "PERDIDAAAA despues: 0.0009732609614729881\n",
      "loss en el callback: 0.0015562876360490918, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.27409306]\n",
      "  [0.27317297]\n",
      "  [0.27369753]\n",
      "  [0.27476877]\n",
      "  [0.27594259]\n",
      "  [0.2782928 ]\n",
      "  [0.27988246]\n",
      "  [0.28070301]]]\n",
      "ejemplar: [0.27409306 0.27317297 0.27369753 0.27476877 0.27594259 0.2782928\n",
      " 0.27988246 0.28070301]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.2809308]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.27409306 0.27317297 0.27369753 0.27476877 0.27594259 0.2782928\n",
      "  0.27988246 0.28070301]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.56824850011617e-05\n",
      "Predicción post entrenamiento : [[0.28127345]]\n",
      "PERDIDAAAA despues: 6.024563481332734e-05\n",
      "loss en el callback: 0.00033049227204173803, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.27317297]\n",
      "  [0.27369753]\n",
      "  [0.27476877]\n",
      "  [0.27594259]\n",
      "  [0.2782928 ]\n",
      "  [0.27988246]\n",
      "  [0.28070301]\n",
      "  [0.28093079]]]\n",
      "ejemplar: [0.27317297 0.27369753 0.27476877 0.27594259 0.2782928  0.27988246\n",
      " 0.28070301 0.28093079]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.28161114]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.27317297 0.27369753 0.27476877 0.27594259 0.2782928  0.27988246\n",
      "  0.28070301 0.28093079]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.5005389286670834e-06\n",
      "Predicción post entrenamiento : [[0.281784]]\n",
      "PERDIDAAAA despues: 1.1069383845097036e-06\n",
      "loss en el callback: 9.025390318129212e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.27369753]\n",
      "  [0.27476877]\n",
      "  [0.27594259]\n",
      "  [0.2782928 ]\n",
      "  [0.27988246]\n",
      "  [0.28070301]\n",
      "  [0.28093079]\n",
      "  [0.28161114]]]\n",
      "ejemplar: [0.27369753 0.27476877 0.27594259 0.2782928  0.27988246 0.28070301\n",
      " 0.28093079 0.28161114]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.28251797]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.27369753 0.27476877 0.27594259 0.2782928  0.27988246 0.28070301\n",
      "  0.28093079 0.28161114]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028826447669416666\n",
      "Predicción post entrenamiento : [[0.28262192]]\n",
      "PERDIDAAAA despues: 0.0002847454743459821\n",
      "loss en el callback: 3.1661522370995954e-05, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.27476877]\n",
      "  [0.27594259]\n",
      "  [0.2782928 ]\n",
      "  [0.27988246]\n",
      "  [0.28070301]\n",
      "  [0.28093079]\n",
      "  [0.28161114]\n",
      "  [0.28251797]]]\n",
      "ejemplar: [0.27476877 0.27594259 0.2782928  0.27988246 0.28070301 0.28093079\n",
      " 0.28161114 0.28251797]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2834949]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.27476877 0.27594259 0.2782928  0.27988246 0.28070301 0.28093079\n",
      "  0.28161114 0.28251797]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.825996777275577e-05\n",
      "Predicción post entrenamiento : [[0.2834243]]\n",
      "PERDIDAAAA despues: 5.718717147829011e-05\n",
      "loss en el callback: 1.807077569537796e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.27594259]\n",
      "  [0.2782928 ]\n",
      "  [0.27988246]\n",
      "  [0.28070301]\n",
      "  [0.28093079]\n",
      "  [0.28161114]\n",
      "  [0.28251797]\n",
      "  [0.28349489]]]\n",
      "ejemplar: [0.27594259 0.2782928  0.27988246 0.28070301 0.28093079 0.28161114\n",
      " 0.28251797 0.28349489]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.28432596]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.27594259 0.2782928  0.27988246 0.28070301 0.28093079 0.28161114\n",
      "  0.28251797 0.28349489]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.2664486146532e-05\n",
      "Predicción post entrenamiento : [[0.28321686]]\n",
      "PERDIDAAAA despues: 7.254177762661129e-05\n",
      "loss en el callback: 0.003496171673759818, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.2782928 ]\n",
      "  [0.27988246]\n",
      "  [0.28070301]\n",
      "  [0.28093079]\n",
      "  [0.28161114]\n",
      "  [0.28251797]\n",
      "  [0.28349489]\n",
      "  [0.28432596]]]\n",
      "ejemplar: [0.2782928  0.27988246 0.28070301 0.28093079 0.28161114 0.28251797\n",
      " 0.28349489 0.28432596]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.28411376]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.2782928  0.27988246 0.28070301 0.28093079 0.28161114 0.28251797\n",
      "  0.28349489 0.28432596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.463502697646618e-05\n",
      "Predicción post entrenamiento : [[0.28409818]]\n",
      "PERDIDAAAA despues: 7.436596206389368e-05\n",
      "loss en el callback: 9.878519904304994e-07, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27988246]\n",
      "  [0.28070301]\n",
      "  [0.28093079]\n",
      "  [0.28161114]\n",
      "  [0.28251797]\n",
      "  [0.28349489]\n",
      "  [0.28432596]\n",
      "  [0.28411376]]]\n",
      "ejemplar: [0.27988246 0.28070301 0.28093079 0.28161114 0.28251797 0.28349489\n",
      " 0.28432596 0.28411376]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2847092]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27988246 0.28070301 0.28093079 0.28161114 0.28251797 0.28349489\n",
      "  0.28432596 0.28411376]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002504479605704546\n",
      "Predicción post entrenamiento : [[0.2853012]]\n",
      "PERDIDAAAA despues: 0.0024455746170133352\n",
      "loss en el callback: 0.0013664232101291418, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.28070301]\n",
      "  [0.28093079]\n",
      "  [0.28161114]\n",
      "  [0.28251797]\n",
      "  [0.28349489]\n",
      "  [0.28432596]\n",
      "  [0.28411376]\n",
      "  [0.28470919]]]\n",
      "ejemplar: [0.28070301 0.28093079 0.28161114 0.28251797 0.28349489 0.28432596\n",
      " 0.28411376 0.28470919]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.28573585]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.28070301 0.28093079 0.28161114 0.28251797 0.28349489 0.28432596\n",
      "  0.28411376 0.28470919]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004891637247055769\n",
      "Predicción post entrenamiento : [[0.28679174]]\n",
      "PERDIDAAAA despues: 0.00474505266174674\n",
      "loss en el callback: 0.00471872603520751, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.28093079]\n",
      "  [0.28161114]\n",
      "  [0.28251797]\n",
      "  [0.28349489]\n",
      "  [0.28432596]\n",
      "  [0.28411376]\n",
      "  [0.28470919]\n",
      "  [0.28573585]]]\n",
      "ejemplar: [0.28093079 0.28161114 0.28251797 0.28349489 0.28432596 0.28411376\n",
      " 0.28470919 0.28573585]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2871892]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.28093079 0.28161114 0.28251797 0.28349489 0.28432596 0.28411376\n",
      "  0.28470919 0.28573585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024504493921995163\n",
      "Predicción post entrenamiento : [[0.28750673]]\n",
      "PERDIDAAAA despues: 0.0024191122502088547\n",
      "loss en el callback: 0.0004479502094909549, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.28161114]\n",
      "  [0.28251797]\n",
      "  [0.28349489]\n",
      "  [0.28432596]\n",
      "  [0.28411376]\n",
      "  [0.28470919]\n",
      "  [0.28573585]\n",
      "  [0.28718919]]]\n",
      "ejemplar: [0.28161114 0.28251797 0.28349489 0.28432596 0.28411376 0.28470919\n",
      " 0.28573585 0.28718919]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28799644]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.28161114 0.28251797 0.28349489 0.28432596 0.28411376 0.28470919\n",
      "  0.28573585 0.28718919]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020789222326129675\n",
      "Predicción post entrenamiento : [[0.28763604]]\n",
      "PERDIDAAAA despues: 0.0021119171287864447\n",
      "loss en el callback: 0.0004484436067286879, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.28251797]\n",
      "  [0.28349489]\n",
      "  [0.28432596]\n",
      "  [0.28411376]\n",
      "  [0.28470919]\n",
      "  [0.28573585]\n",
      "  [0.28718919]\n",
      "  [0.28799644]]]\n",
      "ejemplar: [0.28251797 0.28349489 0.28432596 0.28411376 0.28470919 0.28573585\n",
      " 0.28718919 0.28799644]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28813565]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.28251797 0.28349489 0.28432596 0.28411376 0.28470919 0.28573585\n",
      "  0.28718919 0.28799644]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009331357665359974\n",
      "Predicción post entrenamiento : [[0.288735]]\n",
      "PERDIDAAAA despues: 0.00921592302620411\n",
      "loss en el callback: 0.0014218157157301903, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.28349489]\n",
      "  [0.28432596]\n",
      "  [0.28411376]\n",
      "  [0.28470919]\n",
      "  [0.28573585]\n",
      "  [0.28718919]\n",
      "  [0.28799644]\n",
      "  [0.28813565]]]\n",
      "ejemplar: [0.28349489 0.28432596 0.28411376 0.28470919 0.28573585 0.28718919\n",
      " 0.28799644 0.28813565]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2891966]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.28349489 0.28432596 0.28411376 0.28470919 0.28573585 0.28718919\n",
      "  0.28799644 0.28813565]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0794675350189209\n",
      "Predicción post entrenamiento : [[0.29308105]]\n",
      "PERDIDAAAA despues: 0.07729258388280869\n",
      "loss en el callback: 0.10789977759122849, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.28432596]\n",
      "  [0.28411376]\n",
      "  [0.28470919]\n",
      "  [0.28573585]\n",
      "  [0.28718919]\n",
      "  [0.28799644]\n",
      "  [0.28813565]\n",
      "  [0.28919661]]]\n",
      "ejemplar: [0.28432596 0.28411376 0.28470919 0.28573585 0.28718919 0.28799644\n",
      " 0.28813565 0.28919661]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.29348573]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.28432596 0.28411376 0.28470919 0.28573585 0.28718919 0.28799644\n",
      "  0.28813565 0.28919661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09168468415737152\n",
      "Predicción post entrenamiento : [[0.2975693]]\n",
      "PERDIDAAAA despues: 0.08922838419675827\n",
      "loss en el callback: 0.09163516759872437, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.28411376]\n",
      "  [0.28470919]\n",
      "  [0.28573585]\n",
      "  [0.28718919]\n",
      "  [0.28799644]\n",
      "  [0.28813565]\n",
      "  [0.28919661]\n",
      "  [0.29348573]]]\n",
      "ejemplar: [0.28411376 0.28470919 0.28573585 0.28718919 0.28799644 0.28813565\n",
      " 0.28919661 0.29348573]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.29796043]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.28411376 0.28470919 0.28573585 0.28718919 0.28799644 0.28813565\n",
      "  0.28919661 0.29348573]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07652030885219574\n",
      "Predicción post entrenamiento : [[0.30150822]]\n",
      "PERDIDAAAA despues: 0.07457009702920914\n",
      "loss en el callback: 0.08659248799085617, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.28470919]\n",
      "  [0.28573585]\n",
      "  [0.28718919]\n",
      "  [0.28799644]\n",
      "  [0.28813565]\n",
      "  [0.28919661]\n",
      "  [0.29348573]\n",
      "  [0.29796043]]]\n",
      "ejemplar: [0.28470919 0.28573585 0.28718919 0.28799644 0.28813565 0.28919661\n",
      " 0.29348573 0.29796043]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.30215982]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.28470919 0.28573585 0.28718919 0.28799644 0.28813565 0.28919661\n",
      "  0.29348573 0.29796043]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09253416955471039\n",
      "Predicción post entrenamiento : [[0.3061378]]\n",
      "PERDIDAAAA despues: 0.09012983739376068\n",
      "loss en el callback: 0.1149095743894577, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.28573585]\n",
      "  [0.28718919]\n",
      "  [0.28799644]\n",
      "  [0.28813565]\n",
      "  [0.28919661]\n",
      "  [0.29348573]\n",
      "  [0.29796043]\n",
      "  [0.30215982]]]\n",
      "ejemplar: [0.28573585 0.28718919 0.28799644 0.28813565 0.28919661 0.29348573\n",
      " 0.29796043 0.30215982]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3069669]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.28573585 0.28718919 0.28799644 0.28813565 0.28919661 0.29348573\n",
      "  0.29796043 0.30215982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0771118625998497\n",
      "Predicción post entrenamiento : [[0.31044906]]\n",
      "PERDIDAAAA despues: 0.07519006729125977\n",
      "loss en el callback: 0.09193237870931625, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.28718919]\n",
      "  [0.28799644]\n",
      "  [0.28813565]\n",
      "  [0.28919661]\n",
      "  [0.29348573]\n",
      "  [0.29796043]\n",
      "  [0.30215982]\n",
      "  [0.3069669 ]]]\n",
      "ejemplar: [0.28718919 0.28799644 0.28813565 0.28919661 0.29348573 0.29796043\n",
      " 0.30215982 0.3069669 ]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.311454]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.28718919 0.28799644 0.28813565 0.28919661 0.29348573 0.29796043\n",
      "  0.30215982 0.3069669 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06621243804693222\n",
      "Predicción post entrenamiento : [[0.3141714]]\n",
      "PERDIDAAAA despues: 0.06482135504484177\n",
      "loss en el callback: 0.042020201683044434, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28799644]\n",
      "  [0.28813565]\n",
      "  [0.28919661]\n",
      "  [0.29348573]\n",
      "  [0.29796043]\n",
      "  [0.30215982]\n",
      "  [0.3069669 ]\n",
      "  [0.311454  ]]]\n",
      "ejemplar: [0.28799644 0.28813565 0.28919661 0.29348573 0.29796043 0.30215982\n",
      " 0.3069669  0.311454  ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31535766]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28799644 0.28813565 0.28919661 0.29348573 0.29796043 0.30215982\n",
      "  0.3069669  0.311454  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10720153152942657\n",
      "Predicción post entrenamiento : [[0.31891605]]\n",
      "PERDIDAAAA despues: 0.10488403588533401\n",
      "loss en el callback: 0.06993787735700607, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28813565]\n",
      "  [0.28919661]\n",
      "  [0.29348573]\n",
      "  [0.29796043]\n",
      "  [0.30215982]\n",
      "  [0.3069669 ]\n",
      "  [0.311454  ]\n",
      "  [0.31535766]]]\n",
      "ejemplar: [0.28813565 0.28919661 0.29348573 0.29796043 0.30215982 0.3069669\n",
      " 0.311454   0.31535766]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3205326]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28813565 0.28919661 0.29348573 0.29796043 0.30215982 0.3069669\n",
      "  0.311454   0.31535766]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1164354756474495\n",
      "Predicción post entrenamiento : [[0.32436818]]\n",
      "PERDIDAAAA despues: 0.11383257806301117\n",
      "loss en el callback: 0.10226591676473618, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28919661]\n",
      "  [0.29348573]\n",
      "  [0.29796043]\n",
      "  [0.30215982]\n",
      "  [0.3069669 ]\n",
      "  [0.311454  ]\n",
      "  [0.31535766]\n",
      "  [0.32053259]]]\n",
      "ejemplar: [0.28919661 0.29348573 0.29796043 0.30215982 0.3069669  0.311454\n",
      " 0.31535766 0.32053259]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32670206]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28919661 0.29348573 0.29796043 0.30215982 0.3069669  0.311454\n",
      "  0.31535766 0.32053259]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11991877853870392\n",
      "Predicción post entrenamiento : [[0.33058855]]\n",
      "PERDIDAAAA despues: 0.11724215745925903\n",
      "loss en el callback: 0.12269870191812515, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.29348573]\n",
      "  [0.29796043]\n",
      "  [0.30215982]\n",
      "  [0.3069669 ]\n",
      "  [0.311454  ]\n",
      "  [0.31535766]\n",
      "  [0.32053259]\n",
      "  [0.32670206]]]\n",
      "ejemplar: [0.29348573 0.29796043 0.30215982 0.3069669  0.311454   0.31535766\n",
      " 0.32053259 0.32670206]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.33359703]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.29348573 0.29796043 0.30215982 0.3069669  0.311454   0.31535766\n",
      "  0.32053259 0.32670206]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14211413264274597\n",
      "Predicción post entrenamiento : [[0.33782646]]\n",
      "PERDIDAAAA despues: 0.13894319534301758\n",
      "loss en el callback: 0.1489230841398239, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29796043]\n",
      "  [0.30215982]\n",
      "  [0.3069669 ]\n",
      "  [0.311454  ]\n",
      "  [0.31535766]\n",
      "  [0.32053259]\n",
      "  [0.32670206]\n",
      "  [0.33359703]]]\n",
      "ejemplar: [0.29796043 0.30215982 0.3069669  0.311454   0.31535766 0.32053259\n",
      " 0.32670206 0.33359703]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34091613]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29796043 0.30215982 0.3069669  0.311454   0.31535766 0.32053259\n",
      "  0.32670206 0.33359703]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13182313740253448\n",
      "Predicción post entrenamiento : [[0.34478548]]\n",
      "PERDIDAAAA despues: 0.12902837991714478\n",
      "loss en el callback: 0.11195169389247894, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.30215982]\n",
      "  [0.3069669 ]\n",
      "  [0.311454  ]\n",
      "  [0.31535766]\n",
      "  [0.32053259]\n",
      "  [0.32670206]\n",
      "  [0.33359703]\n",
      "  [0.34091613]]]\n",
      "ejemplar: [0.30215982 0.3069669  0.311454   0.31535766 0.32053259 0.32670206\n",
      " 0.33359703 0.34091613]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34796444]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.30215982 0.3069669  0.311454   0.31535766 0.32053259 0.32670206\n",
      "  0.33359703 0.34091613]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14384807646274567\n",
      "Predicción post entrenamiento : [[0.3519915]]\n",
      "PERDIDAAAA despues: 0.1408095806837082\n",
      "loss en el callback: 0.13776585459709167, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.3069669 ]\n",
      "  [0.311454  ]\n",
      "  [0.31535766]\n",
      "  [0.32053259]\n",
      "  [0.32670206]\n",
      "  [0.33359703]\n",
      "  [0.34091613]\n",
      "  [0.34796444]]]\n",
      "ejemplar: [0.3069669  0.311454   0.31535766 0.32053259 0.32670206 0.33359703\n",
      " 0.34091613 0.34796444]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35538724]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.3069669  0.311454   0.31535766 0.32053259 0.32670206 0.33359703\n",
      "  0.34091613 0.34796444]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13483648002147675\n",
      "Predicción post entrenamiento : [[0.35930786]]\n",
      "PERDIDAAAA despues: 0.1319725513458252\n",
      "loss en el callback: 0.1494148224592209, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.311454  ]\n",
      "  [0.31535766]\n",
      "  [0.32053259]\n",
      "  [0.32670206]\n",
      "  [0.33359703]\n",
      "  [0.34091613]\n",
      "  [0.34796444]\n",
      "  [0.35538724]]]\n",
      "ejemplar: [0.311454   0.31535766 0.32053259 0.32670206 0.33359703 0.34091613\n",
      " 0.34796444 0.35538724]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36286938]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.311454   0.31535766 0.32053259 0.32670206 0.33359703 0.34091613\n",
      "  0.34796444 0.35538724]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16721926629543304\n",
      "Predicción post entrenamiento : [[0.36724293]]\n",
      "PERDIDAAAA despues: 0.16366147994995117\n",
      "loss en el callback: 0.1570432335138321, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31535766]\n",
      "  [0.32053259]\n",
      "  [0.32670206]\n",
      "  [0.33359703]\n",
      "  [0.34091613]\n",
      "  [0.34796444]\n",
      "  [0.35538724]\n",
      "  [0.36286938]]]\n",
      "ejemplar: [0.31535766 0.32053259 0.32670206 0.33359703 0.34091613 0.34796444\n",
      " 0.35538724 0.36286938]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37113035]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31535766 0.32053259 0.32670206 0.33359703 0.34091613 0.34796444\n",
      "  0.35538724 0.36286938]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12488805502653122\n",
      "Predicción post entrenamiento : [[0.37479764]]\n",
      "PERDIDAAAA despues: 0.12230949848890305\n",
      "loss en el callback: 0.1557772308588028, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32053259]\n",
      "  [0.32670206]\n",
      "  [0.33359703]\n",
      "  [0.34091613]\n",
      "  [0.34796444]\n",
      "  [0.35538724]\n",
      "  [0.36286938]\n",
      "  [0.37113035]]]\n",
      "ejemplar: [0.32053259 0.32670206 0.33359703 0.34091613 0.34796444 0.35538724\n",
      " 0.36286938 0.37113035]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37925616]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32053259 0.32670206 0.33359703 0.34091613 0.34796444 0.35538724\n",
      "  0.36286938 0.37113035]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08514814078807831\n",
      "Predicción post entrenamiento : [[0.3824062]]\n",
      "PERDIDAAAA despues: 0.08331968635320663\n",
      "loss en el callback: 0.11447612196207047, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32670206]\n",
      "  [0.33359703]\n",
      "  [0.34091613]\n",
      "  [0.34796444]\n",
      "  [0.35538724]\n",
      "  [0.36286938]\n",
      "  [0.37113035]\n",
      "  [0.37925616]]]\n",
      "ejemplar: [0.32670206 0.33359703 0.34091613 0.34796444 0.35538724 0.36286938\n",
      " 0.37113035 0.37925616]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38727456]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32670206 0.33359703 0.34091613 0.34796444 0.35538724 0.36286938\n",
      "  0.37113035 0.37925616]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08207953721284866\n",
      "Predicción post entrenamiento : [[0.39016798]]\n",
      "PERDIDAAAA despues: 0.08043000847101212\n",
      "loss en el callback: 0.07503043860197067, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33359703]\n",
      "  [0.34091613]\n",
      "  [0.34796444]\n",
      "  [0.35538724]\n",
      "  [0.36286938]\n",
      "  [0.37113035]\n",
      "  [0.37925616]\n",
      "  [0.38727456]]]\n",
      "ejemplar: [0.33359703 0.34091613 0.34796444 0.35538724 0.36286938 0.37113035\n",
      " 0.37925616 0.38727456]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3953086]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33359703 0.34091613 0.34796444 0.35538724 0.36286938 0.37113035\n",
      "  0.37925616 0.38727456]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10185236483812332\n",
      "Predicción post entrenamiento : [[0.3984382]]\n",
      "PERDIDAAAA despues: 0.09986459463834763\n",
      "loss en el callback: 0.1124260276556015, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34091613]\n",
      "  [0.34796444]\n",
      "  [0.35538724]\n",
      "  [0.36286938]\n",
      "  [0.37113035]\n",
      "  [0.37925616]\n",
      "  [0.38727456]\n",
      "  [0.39530861]]]\n",
      "ejemplar: [0.34091613 0.34796444 0.35538724 0.36286938 0.37113035 0.37925616\n",
      " 0.38727456 0.39530861]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.403745]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34091613 0.34796444 0.35538724 0.36286938 0.37113035 0.37925616\n",
      "  0.38727456 0.39530861]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11570388823747635\n",
      "Predicción post entrenamiento : [[0.4070765]]\n",
      "PERDIDAAAA despues: 0.11344853788614273\n",
      "loss en el callback: 0.14638309180736542, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34796444]\n",
      "  [0.35538724]\n",
      "  [0.36286938]\n",
      "  [0.37113035]\n",
      "  [0.37925616]\n",
      "  [0.38727456]\n",
      "  [0.39530861]\n",
      "  [0.403745  ]]]\n",
      "ejemplar: [0.34796444 0.35538724 0.36286938 0.37113035 0.37925616 0.38727456\n",
      " 0.39530861 0.403745  ]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41249302]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34796444 0.35538724 0.36286938 0.37113035 0.37925616 0.38727456\n",
      "  0.39530861 0.403745  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09615897387266159\n",
      "Predicción post entrenamiento : [[0.4155897]]\n",
      "PERDIDAAAA despues: 0.09424803406000137\n",
      "loss en el callback: 0.11449852585792542, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35538724]\n",
      "  [0.36286938]\n",
      "  [0.37113035]\n",
      "  [0.37925616]\n",
      "  [0.38727456]\n",
      "  [0.39530861]\n",
      "  [0.403745  ]\n",
      "  [0.41249302]]]\n",
      "ejemplar: [0.35538724 0.36286938 0.37113035 0.37925616 0.38727456 0.39530861\n",
      " 0.403745   0.41249302]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42121536]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35538724 0.36286938 0.37113035 0.37925616 0.38727456 0.39530861\n",
      "  0.403745   0.41249302]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0773540735244751\n",
      "Predicción post entrenamiento : [[0.4240283]]\n",
      "PERDIDAAAA despues: 0.07579727470874786\n",
      "loss en el callback: 0.0859643965959549, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36286938]\n",
      "  [0.37113035]\n",
      "  [0.37925616]\n",
      "  [0.38727456]\n",
      "  [0.39530861]\n",
      "  [0.403745  ]\n",
      "  [0.41249302]\n",
      "  [0.42121536]]]\n",
      "ejemplar: [0.36286938 0.37113035 0.37925616 0.38727456 0.39530861 0.403745\n",
      " 0.41249302 0.42121536]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42982262]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36286938 0.37113035 0.37925616 0.38727456 0.39530861 0.403745\n",
      "  0.41249302 0.42121536]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09454917907714844\n",
      "Predicción post entrenamiento : [[0.4325403]]\n",
      "PERDIDAAAA despues: 0.09288525581359863\n",
      "loss en el callback: 0.07037003338336945, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.37113035]\n",
      "  [0.37925616]\n",
      "  [0.38727456]\n",
      "  [0.39530861]\n",
      "  [0.403745  ]\n",
      "  [0.41249302]\n",
      "  [0.42121536]\n",
      "  [0.42982262]]]\n",
      "ejemplar: [0.37113035 0.37925616 0.38727456 0.39530861 0.403745   0.41249302\n",
      " 0.42121536 0.42982262]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.43852967]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.37113035 0.37925616 0.38727456 0.39530861 0.403745   0.41249302\n",
      "  0.42121536 0.42982262]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08003024011850357\n",
      "Predicción post entrenamiento : [[0.44104028]]\n",
      "PERDIDAAAA despues: 0.07861606031656265\n",
      "loss en el callback: 0.07123515009880066, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37925616]\n",
      "  [0.38727456]\n",
      "  [0.39530861]\n",
      "  [0.403745  ]\n",
      "  [0.41249302]\n",
      "  [0.42121536]\n",
      "  [0.42982262]\n",
      "  [0.43852967]]]\n",
      "ejemplar: [0.37925616 0.38727456 0.39530861 0.403745   0.41249302 0.42121536\n",
      " 0.42982262 0.43852967]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4470753]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37925616 0.38727456 0.39530861 0.403745   0.41249302 0.42121536\n",
      "  0.42982262 0.43852967]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07378741353750229\n",
      "Predicción post entrenamiento : [[0.4496985]]\n",
      "PERDIDAAAA despues: 0.07236917316913605\n",
      "loss en el callback: 0.09365374594926834, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38727456]\n",
      "  [0.39530861]\n",
      "  [0.403745  ]\n",
      "  [0.41249302]\n",
      "  [0.42121536]\n",
      "  [0.42982262]\n",
      "  [0.43852967]\n",
      "  [0.44707531]]]\n",
      "ejemplar: [0.38727456 0.39530861 0.403745   0.41249302 0.42121536 0.42982262\n",
      " 0.43852967 0.44707531]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.45582688]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38727456 0.39530861 0.403745   0.41249302 0.42121536 0.42982262\n",
      "  0.43852967 0.44707531]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047668181359767914\n",
      "Predicción post entrenamiento : [[0.45811912]]\n",
      "PERDIDAAAA despues: 0.046672504395246506\n",
      "loss en el callback: 0.07487167418003082, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39530861]\n",
      "  [0.403745  ]\n",
      "  [0.41249302]\n",
      "  [0.42121536]\n",
      "  [0.42982262]\n",
      "  [0.43852967]\n",
      "  [0.44707531]\n",
      "  [0.45582688]]]\n",
      "ejemplar: [0.39530861 0.403745   0.41249302 0.42121536 0.42982262 0.43852967\n",
      " 0.44707531 0.45582688]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4643878]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39530861 0.403745   0.41249302 0.42121536 0.42982262 0.43852967\n",
      "  0.44707531 0.45582688]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05483963340520859\n",
      "Predicción post entrenamiento : [[0.46691713]]\n",
      "PERDIDAAAA despues: 0.05366140231490135\n",
      "loss en el callback: 0.10661538690328598, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.403745  ]\n",
      "  [0.41249302]\n",
      "  [0.42121536]\n",
      "  [0.42982262]\n",
      "  [0.43852967]\n",
      "  [0.44707531]\n",
      "  [0.45582688]\n",
      "  [0.4643878 ]]]\n",
      "ejemplar: [0.403745   0.41249302 0.42121536 0.42982262 0.43852967 0.44707531\n",
      " 0.45582688 0.4643878 ]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47334817]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.403745   0.41249302 0.42121536 0.42982262 0.43852967 0.44707531\n",
      "  0.45582688 0.4643878 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061350420117378235\n",
      "Predicción post entrenamiento : [[0.4754704]]\n",
      "PERDIDAAAA despues: 0.060303617268800735\n",
      "loss en el callback: 0.04899324104189873, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41249302]\n",
      "  [0.42121536]\n",
      "  [0.42982262]\n",
      "  [0.43852967]\n",
      "  [0.44707531]\n",
      "  [0.45582688]\n",
      "  [0.4643878 ]\n",
      "  [0.47334817]]]\n",
      "ejemplar: [0.41249302 0.42121536 0.42982262 0.43852967 0.44707531 0.45582688\n",
      " 0.4643878  0.47334817]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.48198816]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41249302 0.42121536 0.42982262 0.43852967 0.44707531 0.45582688\n",
      "  0.4643878  0.47334817]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05788834020495415\n",
      "Predicción post entrenamiento : [[0.48435706]]\n",
      "PERDIDAAAA despues: 0.056754037737846375\n",
      "loss en el callback: 0.07565578818321228, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42121536]\n",
      "  [0.42982262]\n",
      "  [0.43852967]\n",
      "  [0.44707531]\n",
      "  [0.45582688]\n",
      "  [0.4643878 ]\n",
      "  [0.47334817]\n",
      "  [0.48198816]]]\n",
      "ejemplar: [0.42121536 0.42982262 0.43852967 0.44707531 0.45582688 0.4643878\n",
      " 0.47334817 0.48198816]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.49089375]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42121536 0.42982262 0.43852967 0.44707531 0.45582688 0.4643878\n",
      "  0.47334817 0.48198816]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07043837755918503\n",
      "Predicción post entrenamiento : [[0.49290997]]\n",
      "PERDIDAAAA despues: 0.06937222182750702\n",
      "loss en el callback: 0.044071655720472336, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.42982262]\n",
      "  [0.43852967]\n",
      "  [0.44707531]\n",
      "  [0.45582688]\n",
      "  [0.4643878 ]\n",
      "  [0.47334817]\n",
      "  [0.48198816]\n",
      "  [0.49089375]]]\n",
      "ejemplar: [0.42982262 0.43852967 0.44707531 0.45582688 0.4643878  0.47334817\n",
      " 0.48198816 0.49089375]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49947065]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.42982262 0.43852967 0.44707531 0.45582688 0.4643878  0.47334817\n",
      "  0.48198816 0.49089375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10765983909368515\n",
      "Predicción post entrenamiento : [[0.5024619]]\n",
      "PERDIDAAAA despues: 0.10570582747459412\n",
      "loss en el callback: 0.11822887510061264, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.43852967]\n",
      "  [0.44707531]\n",
      "  [0.45582688]\n",
      "  [0.4643878 ]\n",
      "  [0.47334817]\n",
      "  [0.48198816]\n",
      "  [0.49089375]\n",
      "  [0.49947065]]]\n",
      "ejemplar: [0.43852967 0.44707531 0.45582688 0.4643878  0.47334817 0.48198816\n",
      " 0.49089375 0.49947065]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.50907916]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.43852967 0.44707531 0.45582688 0.4643878  0.47334817 0.48198816\n",
      "  0.49089375 0.49947065]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10873046517372131\n",
      "Predicción post entrenamiento : [[0.5122031]]\n",
      "PERDIDAAAA despues: 0.10668002814054489\n",
      "loss en el callback: 0.15366840362548828, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.44707531]\n",
      "  [0.45582688]\n",
      "  [0.4643878 ]\n",
      "  [0.47334817]\n",
      "  [0.48198816]\n",
      "  [0.49089375]\n",
      "  [0.49947065]\n",
      "  [0.50907916]]]\n",
      "ejemplar: [0.44707531 0.45582688 0.4643878  0.47334817 0.48198816 0.49089375\n",
      " 0.49947065 0.50907916]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.51886165]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.44707531 0.45582688 0.4643878  0.47334817 0.48198816 0.49089375\n",
      "  0.49947065 0.50907916]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07584744691848755\n",
      "Predicción post entrenamiento : [[0.5214916]]\n",
      "PERDIDAAAA despues: 0.07440577447414398\n",
      "loss en el callback: 0.09643160551786423, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.45582688]\n",
      "  [0.4643878 ]\n",
      "  [0.47334817]\n",
      "  [0.48198816]\n",
      "  [0.49089375]\n",
      "  [0.49947065]\n",
      "  [0.50907916]\n",
      "  [0.51886165]]]\n",
      "ejemplar: [0.45582688 0.4643878  0.47334817 0.48198816 0.49089375 0.49947065\n",
      " 0.50907916 0.51886165]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5282446]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.45582688 0.4643878  0.47334817 0.48198816 0.49089375 0.49947065\n",
      "  0.50907916 0.51886165]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06531096249818802\n",
      "Predicción post entrenamiento : [[0.5308342]]\n",
      "PERDIDAAAA despues: 0.06399407982826233\n",
      "loss en el callback: 0.12313065677881241, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.4643878 ]\n",
      "  [0.47334817]\n",
      "  [0.48198816]\n",
      "  [0.49089375]\n",
      "  [0.49947065]\n",
      "  [0.50907916]\n",
      "  [0.51886165]\n",
      "  [0.52824461]]]\n",
      "ejemplar: [0.4643878  0.47334817 0.48198816 0.49089375 0.49947065 0.50907916\n",
      " 0.51886165 0.52824461]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5376545]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.4643878  0.47334817 0.48198816 0.49089375 0.49947065 0.50907916\n",
      "  0.51886165 0.52824461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05302192643284798\n",
      "Predicción post entrenamiento : [[0.5392334]]\n",
      "PERDIDAAAA despues: 0.05229730159044266\n",
      "loss en el callback: 0.027778837829828262, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.47334817]\n",
      "  [0.48198816]\n",
      "  [0.49089375]\n",
      "  [0.49947065]\n",
      "  [0.50907916]\n",
      "  [0.51886165]\n",
      "  [0.52824461]\n",
      "  [0.53765452]]]\n",
      "ejemplar: [0.47334817 0.48198816 0.49089375 0.49947065 0.50907916 0.51886165\n",
      " 0.52824461 0.53765452]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5461906]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.47334817 0.48198816 0.49089375 0.49947065 0.50907916 0.51886165\n",
      "  0.52824461 0.53765452]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05682932212948799\n",
      "Predicción post entrenamiento : [[0.54807454]]\n",
      "PERDIDAAAA despues: 0.05593465641140938\n",
      "loss en el callback: 0.04421958327293396, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.48198816]\n",
      "  [0.49089375]\n",
      "  [0.49947065]\n",
      "  [0.50907916]\n",
      "  [0.51886165]\n",
      "  [0.52824461]\n",
      "  [0.53765452]\n",
      "  [0.54619062]]]\n",
      "ejemplar: [0.48198816 0.49089375 0.49947065 0.50907916 0.51886165 0.52824461\n",
      " 0.53765452 0.54619062]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5550958]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.48198816 0.49089375 0.49947065 0.50907916 0.51886165 0.52824461\n",
      "  0.53765452 0.54619062]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10473856329917908\n",
      "Predicción post entrenamiento : [[0.5580053]]\n",
      "PERDIDAAAA despues: 0.10286381095647812\n",
      "loss en el callback: 0.13280627131462097, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.49089375]\n",
      "  [0.49947065]\n",
      "  [0.50907916]\n",
      "  [0.51886165]\n",
      "  [0.52824461]\n",
      "  [0.53765452]\n",
      "  [0.54619062]\n",
      "  [0.55509579]]]\n",
      "ejemplar: [0.49089375 0.49947065 0.50907916 0.51886165 0.52824461 0.53765452\n",
      " 0.54619062 0.55509579]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.56518877]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.49089375 0.49947065 0.50907916 0.51886165 0.52824461 0.53765452\n",
      "  0.54619062 0.55509579]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09637351334095001\n",
      "Predicción post entrenamiento : [[0.5679657]]\n",
      "PERDIDAAAA despues: 0.09465708583593369\n",
      "loss en el callback: 0.12092720717191696, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.49947065]\n",
      "  [0.50907916]\n",
      "  [0.51886165]\n",
      "  [0.52824461]\n",
      "  [0.53765452]\n",
      "  [0.54619062]\n",
      "  [0.55509579]\n",
      "  [0.56518877]]]\n",
      "ejemplar: [0.49947065 0.50907916 0.51886165 0.52824461 0.53765452 0.54619062\n",
      " 0.55509579 0.56518877]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.57526755]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.49947065 0.50907916 0.51886165 0.52824461 0.53765452 0.54619062\n",
      "  0.55509579 0.56518877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07487241178750992\n",
      "Predicción post entrenamiento : [[0.5777226]]\n",
      "PERDIDAAAA despues: 0.07353489100933075\n",
      "loss en el callback: 0.09260742366313934, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.50907916]\n",
      "  [0.51886165]\n",
      "  [0.52824461]\n",
      "  [0.53765452]\n",
      "  [0.54619062]\n",
      "  [0.55509579]\n",
      "  [0.56518877]\n",
      "  [0.57526755]]]\n",
      "ejemplar: [0.50907916 0.51886165 0.52824461 0.53765452 0.54619062 0.55509579\n",
      " 0.56518877 0.57526755]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5852481]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.50907916 0.51886165 0.52824461 0.53765452 0.54619062 0.55509579\n",
      "  0.56518877 0.57526755]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054307352751493454\n",
      "Predicción post entrenamiento : [[0.58693254]]\n",
      "PERDIDAAAA despues: 0.05352511256933212\n",
      "loss en el callback: 0.03771599382162094, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.51886165]\n",
      "  [0.52824461]\n",
      "  [0.53765452]\n",
      "  [0.54619062]\n",
      "  [0.55509579]\n",
      "  [0.56518877]\n",
      "  [0.57526755]\n",
      "  [0.58524811]]]\n",
      "ejemplar: [0.51886165 0.52824461 0.53765452 0.54619062 0.55509579 0.56518877\n",
      " 0.57526755 0.58524811]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.59444344]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.51886165 0.52824461 0.53765452 0.54619062 0.55509579 0.56518877\n",
      "  0.57526755 0.58524811]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05399482697248459\n",
      "Predicción post entrenamiento : [[0.59688824]]\n",
      "PERDIDAAAA despues: 0.052864618599414825\n",
      "loss en el callback: 0.13834498822689056, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.52824461]\n",
      "  [0.53765452]\n",
      "  [0.54619062]\n",
      "  [0.55509579]\n",
      "  [0.56518877]\n",
      "  [0.57526755]\n",
      "  [0.58524811]\n",
      "  [0.59444344]]]\n",
      "ejemplar: [0.52824461 0.53765452 0.54619062 0.55509579 0.56518877 0.57526755\n",
      " 0.58524811 0.59444344]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6043394]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.52824461 0.53765452 0.54619062 0.55509579 0.56518877 0.57526755\n",
      "  0.58524811 0.59444344]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03276645764708519\n",
      "Predicción post entrenamiento : [[0.6060988]]\n",
      "PERDIDAAAA despues: 0.03213261440396309\n",
      "loss en el callback: 0.05073146894574165, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.53765452]\n",
      "  [0.54619062]\n",
      "  [0.55509579]\n",
      "  [0.56518877]\n",
      "  [0.57526755]\n",
      "  [0.58524811]\n",
      "  [0.59444344]\n",
      "  [0.60433942]]]\n",
      "ejemplar: [0.53765452 0.54619062 0.55509579 0.56518877 0.57526755 0.58524811\n",
      " 0.59444344 0.60433942]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.61359125]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.53765452 0.54619062 0.55509579 0.56518877 0.57526755 0.58524811\n",
      "  0.59444344 0.60433942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030848609283566475\n",
      "Predicción post entrenamiento : [[0.6155341]]\n",
      "PERDIDAAAA despues: 0.030169900506734848\n",
      "loss en el callback: 0.06532449275255203, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.54619062]\n",
      "  [0.55509579]\n",
      "  [0.56518877]\n",
      "  [0.57526755]\n",
      "  [0.58524811]\n",
      "  [0.59444344]\n",
      "  [0.60433942]\n",
      "  [0.61359125]]]\n",
      "ejemplar: [0.54619062 0.55509579 0.56518877 0.57526755 0.58524811 0.59444344\n",
      " 0.60433942 0.61359125]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6230742]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.54619062 0.55509579 0.56518877 0.57526755 0.58524811 0.59444344\n",
      "  0.60433942 0.61359125]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04456262290477753\n",
      "Predicción post entrenamiento : [[0.6252113]]\n",
      "PERDIDAAAA despues: 0.043664902448654175\n",
      "loss en el callback: 0.08124635368585587, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.55509579]\n",
      "  [0.56518877]\n",
      "  [0.57526755]\n",
      "  [0.58524811]\n",
      "  [0.59444344]\n",
      "  [0.60433942]\n",
      "  [0.61359125]\n",
      "  [0.62307417]]]\n",
      "ejemplar: [0.55509579 0.56518877 0.57526755 0.58524811 0.59444344 0.60433942\n",
      " 0.61359125 0.62307417]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.63304704]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.55509579 0.56518877 0.57526755 0.58524811 0.59444344 0.60433942\n",
      "  0.61359125 0.62307417]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032194677740335464\n",
      "Predicción post entrenamiento : [[0.6346523]]\n",
      "PERDIDAAAA despues: 0.031621191650629044\n",
      "loss en el callback: 0.039370372891426086, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.56518877]\n",
      "  [0.57526755]\n",
      "  [0.58524811]\n",
      "  [0.59444344]\n",
      "  [0.60433942]\n",
      "  [0.61359125]\n",
      "  [0.62307417]\n",
      "  [0.63304704]]]\n",
      "ejemplar: [0.56518877 0.57526755 0.58524811 0.59444344 0.60433942 0.61359125\n",
      " 0.62307417 0.63304704]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.64272636]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.56518877 0.57526755 0.58524811 0.59444344 0.60433942 0.61359125\n",
      "  0.62307417 0.63304704]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02512652613222599\n",
      "Predicción post entrenamiento : [[0.6438199]]\n",
      "PERDIDAAAA despues: 0.024781031534075737\n",
      "loss en el callback: 0.015823153778910637, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.57526755]\n",
      "  [0.58524811]\n",
      "  [0.59444344]\n",
      "  [0.60433942]\n",
      "  [0.61359125]\n",
      "  [0.62307417]\n",
      "  [0.63304704]\n",
      "  [0.64272636]]]\n",
      "ejemplar: [0.57526755 0.58524811 0.59444344 0.60433942 0.61359125 0.62307417\n",
      " 0.63304704 0.64272636]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.65183574]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.57526755 0.58524811 0.59444344 0.60433942 0.61359125 0.62307417\n",
      "  0.63304704 0.64272636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02290419489145279\n",
      "Predicción post entrenamiento : [[0.6537562]]\n",
      "PERDIDAAAA despues: 0.022326592355966568\n",
      "loss en el callback: 0.08104602992534637, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.58524811]\n",
      "  [0.59444344]\n",
      "  [0.60433942]\n",
      "  [0.61359125]\n",
      "  [0.62307417]\n",
      "  [0.63304704]\n",
      "  [0.64272636]\n",
      "  [0.65183574]]]\n",
      "ejemplar: [0.58524811 0.59444344 0.60433942 0.61359125 0.62307417 0.63304704\n",
      " 0.64272636 0.65183574]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6616967]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.58524811 0.59444344 0.60433942 0.61359125 0.62307417 0.63304704\n",
      "  0.64272636 0.65183574]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017369715496897697\n",
      "Predicción post entrenamiento : [[0.66282314]]\n",
      "PERDIDAAAA despues: 0.017074059695005417\n",
      "loss en el callback: 0.01846526749432087, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.59444344]\n",
      "  [0.60433942]\n",
      "  [0.61359125]\n",
      "  [0.62307417]\n",
      "  [0.63304704]\n",
      "  [0.64272636]\n",
      "  [0.65183574]\n",
      "  [0.66169667]]]\n",
      "ejemplar: [0.59444344 0.60433942 0.61359125 0.62307417 0.63304704 0.64272636\n",
      " 0.65183574 0.66169667]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6706913]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.59444344 0.60433942 0.61359125 0.62307417 0.63304704 0.64272636\n",
      "  0.65183574 0.66169667]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00800651777535677\n",
      "Predicción post entrenamiento : [[0.67186904]]\n",
      "PERDIDAAAA despues: 0.0077971406280994415\n",
      "loss en el callback: 0.027519742026925087, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.60433942]\n",
      "  [0.61359125]\n",
      "  [0.62307417]\n",
      "  [0.63304704]\n",
      "  [0.64272636]\n",
      "  [0.65183574]\n",
      "  [0.66169667]\n",
      "  [0.67069131]]]\n",
      "ejemplar: [0.60433942 0.61359125 0.62307417 0.63304704 0.64272636 0.65183574\n",
      " 0.66169667 0.67069131]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.67986166]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.60433942 0.61359125 0.62307417 0.63304704 0.64272636 0.65183574\n",
      "  0.66169667 0.67069131]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030816097278147936\n",
      "Predicción post entrenamiento : [[0.6813421]]\n",
      "PERDIDAAAA despues: 0.0029194343369454145\n",
      "loss en el callback: 0.05709896236658096, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.61359125]\n",
      "  [0.62307417]\n",
      "  [0.63304704]\n",
      "  [0.64272636]\n",
      "  [0.65183574]\n",
      "  [0.66169667]\n",
      "  [0.67069131]\n",
      "  [0.67986166]]]\n",
      "ejemplar: [0.61359125 0.62307417 0.63304704 0.64272636 0.65183574 0.66169667\n",
      " 0.67069131 0.67986166]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6892754]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.61359125 0.62307417 0.63304704 0.64272636 0.65183574 0.66169667\n",
      "  0.67069131 0.67986166]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004374136042315513\n",
      "Predicción post entrenamiento : [[0.68996644]]\n",
      "PERDIDAAAA despues: 0.0004089850699529052\n",
      "loss en el callback: 0.00896443985402584, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.62307417]\n",
      "  [0.63304704]\n",
      "  [0.64272636]\n",
      "  [0.65183574]\n",
      "  [0.66169667]\n",
      "  [0.67069131]\n",
      "  [0.67986166]\n",
      "  [0.68927538]]]\n",
      "ejemplar: [0.62307417 0.63304704 0.64272636 0.65183574 0.66169667 0.67069131\n",
      " 0.67986166 0.68927538]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6979938]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.62307417 0.63304704 0.64272636 0.65183574 0.66169667 0.67069131\n",
      "  0.67986166 0.68927538]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019974945462308824\n",
      "Predicción post entrenamiento : [[0.69884086]]\n",
      "PERDIDAAAA despues: 0.00017652398673817515\n",
      "loss en el callback: 0.01837778463959694, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.63304704]\n",
      "  [0.64272636]\n",
      "  [0.65183574]\n",
      "  [0.66169667]\n",
      "  [0.67069131]\n",
      "  [0.67986166]\n",
      "  [0.68927538]\n",
      "  [0.69799381]]]\n",
      "ejemplar: [0.63304704 0.64272636 0.65183574 0.66169667 0.67069131 0.67986166\n",
      " 0.68927538 0.69799381]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.70689684]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.63304704 0.64272636 0.65183574 0.66169667 0.67069131 0.67986166\n",
      "  0.68927538 0.69799381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001071841106750071\n",
      "Predicción post entrenamiento : [[0.70628095]]\n",
      "PERDIDAAAA despues: 0.0011125479359179735\n",
      "loss en el callback: 0.004662156105041504, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.64272636]\n",
      "  [0.65183574]\n",
      "  [0.66169667]\n",
      "  [0.67069131]\n",
      "  [0.67986166]\n",
      "  [0.68927538]\n",
      "  [0.69799381]\n",
      "  [0.70689684]]]\n",
      "ejemplar: [0.64272636 0.65183574 0.66169667 0.67069131 0.67986166 0.68927538\n",
      " 0.69799381 0.70689684]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.71420693]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.64272636 0.65183574 0.66169667 0.67069131 0.67986166 0.68927538\n",
      "  0.69799381 0.70689684]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004814443818759173\n",
      "Predicción post entrenamiento : [[0.71359426]]\n",
      "PERDIDAAAA despues: 0.0005087062017992139\n",
      "loss en el callback: 0.004821815062314272, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.65183574]\n",
      "  [0.66169667]\n",
      "  [0.67069131]\n",
      "  [0.67986166]\n",
      "  [0.68927538]\n",
      "  [0.69799381]\n",
      "  [0.70689684]\n",
      "  [0.71420693]]]\n",
      "ejemplar: [0.65183574 0.66169667 0.67069131 0.67986166 0.68927538 0.69799381\n",
      " 0.70689684 0.71420693]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7214225]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.65183574 0.66169667 0.67069131 0.67986166 0.68927538 0.69799381\n",
      "  0.70689684 0.71420693]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029000146314501762\n",
      "Predicción post entrenamiento : [[0.7214126]]\n",
      "PERDIDAAAA despues: 0.0028989489655941725\n",
      "loss en el callback: 1.7480812175563187e-06, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.66169667]\n",
      "  [0.67069131]\n",
      "  [0.67986166]\n",
      "  [0.68927538]\n",
      "  [0.69799381]\n",
      "  [0.70689684]\n",
      "  [0.71420693]\n",
      "  [0.72142249]]]\n",
      "ejemplar: [0.66169667 0.67069131 0.67986166 0.68927538 0.69799381 0.70689684\n",
      " 0.71420693 0.72142249]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7292509]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.66169667 0.67069131 0.67986166 0.68927538 0.69799381 0.70689684\n",
      "  0.71420693 0.72142249]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003523075021803379\n",
      "Predicción post entrenamiento : [[0.7285274]]\n",
      "PERDIDAAAA despues: 0.0034377132542431355\n",
      "loss en el callback: 0.008278009481728077, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.67069131]\n",
      "  [0.67986166]\n",
      "  [0.68927538]\n",
      "  [0.69799381]\n",
      "  [0.70689684]\n",
      "  [0.71420693]\n",
      "  [0.72142249]\n",
      "  [0.72925091]]]\n",
      "ejemplar: [0.67069131 0.67986166 0.68927538 0.69799381 0.70689684 0.71420693\n",
      " 0.72142249 0.72925091]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7361183]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.67069131 0.67986166 0.68927538 0.69799381 0.70689684 0.71420693\n",
      "  0.72142249 0.72925091]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015593882417306304\n",
      "Predicción post entrenamiento : [[0.7353256]]\n",
      "PERDIDAAAA despues: 0.0014974074438214302\n",
      "loss en el callback: 0.008786514401435852, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.67986166]\n",
      "  [0.68927538]\n",
      "  [0.69799381]\n",
      "  [0.70689684]\n",
      "  [0.71420693]\n",
      "  [0.72142249]\n",
      "  [0.72925091]\n",
      "  [0.73611832]]]\n",
      "ejemplar: [0.67986166 0.68927538 0.69799381 0.70689684 0.71420693 0.72142249\n",
      " 0.72925091 0.73611832]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.74282134]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.67986166 0.68927538 0.69799381 0.70689684 0.71420693 0.72142249\n",
      "  0.72925091 0.73611832]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007547093089669943\n",
      "Predicción post entrenamiento : [[0.7423246]]\n",
      "PERDIDAAAA despues: 0.007461031433194876\n",
      "loss en el callback: 0.0037757880054414272, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.68927538]\n",
      "  [0.69799381]\n",
      "  [0.70689684]\n",
      "  [0.71420693]\n",
      "  [0.72142249]\n",
      "  [0.72925091]\n",
      "  [0.73611832]\n",
      "  [0.74282134]]]\n",
      "ejemplar: [0.68927538 0.69799381 0.70689684 0.71420693 0.72142249 0.72925091\n",
      " 0.73611832 0.74282134]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7496061]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.68927538 0.69799381 0.70689684 0.71420693 0.72142249 0.72925091\n",
      "  0.73611832 0.74282134]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005012556444853544\n",
      "Predicción post entrenamiento : [[0.7493077]]\n",
      "PERDIDAAAA despues: 0.004970395006239414\n",
      "loss en el callback: 0.001542908838018775, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.69799381]\n",
      "  [0.70689684]\n",
      "  [0.71420693]\n",
      "  [0.72142249]\n",
      "  [0.72925091]\n",
      "  [0.73611832]\n",
      "  [0.74282134]\n",
      "  [0.74960607]]]\n",
      "ejemplar: [0.69799381 0.70689684 0.71420693 0.72142249 0.72925091 0.73611832\n",
      " 0.74282134 0.74960607]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7562165]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.69799381 0.70689684 0.71420693 0.72142249 0.72925091 0.73611832\n",
      "  0.74282134 0.74960607]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006419533863663673\n",
      "Predicción post entrenamiento : [[0.75612634]]\n",
      "PERDIDAAAA despues: 0.0064050909131765366\n",
      "loss en el callback: 0.0001511027367087081, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.70689684]\n",
      "  [0.71420693]\n",
      "  [0.72142249]\n",
      "  [0.72925091]\n",
      "  [0.73611832]\n",
      "  [0.74282134]\n",
      "  [0.74960607]\n",
      "  [0.75621653]]]\n",
      "ejemplar: [0.70689684 0.71420693 0.72142249 0.72925091 0.73611832 0.74282134\n",
      " 0.74960607 0.75621653]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7627521]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.70689684 0.71420693 0.72142249 0.72925091 0.73611832 0.74282134\n",
      "  0.74960607 0.75621653]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011015728814527392\n",
      "Predicción post entrenamiento : [[0.7625307]]\n",
      "PERDIDAAAA despues: 0.0010869234101846814\n",
      "loss en el callback: 0.0008908378658816218, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.71420693]\n",
      "  [0.72142249]\n",
      "  [0.72925091]\n",
      "  [0.73611832]\n",
      "  [0.74282134]\n",
      "  [0.74960607]\n",
      "  [0.75621653]\n",
      "  [0.76275212]]]\n",
      "ejemplar: [0.71420693 0.72142249 0.72925091 0.73611832 0.74282134 0.74960607\n",
      " 0.75621653 0.76275212]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.76873654]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.71420693 0.72142249 0.72925091 0.73611832 0.74282134 0.74960607\n",
      "  0.75621653 0.76275212]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004550578072667122\n",
      "Predicción post entrenamiento : [[0.7677817]]\n",
      "PERDIDAAAA despues: 0.0044226632453501225\n",
      "loss en el callback: 0.013973284512758255, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.72142249]\n",
      "  [0.72925091]\n",
      "  [0.73611832]\n",
      "  [0.74282134]\n",
      "  [0.74960607]\n",
      "  [0.75621653]\n",
      "  [0.76275212]\n",
      "  [0.76873654]]]\n",
      "ejemplar: [0.72142249 0.72925091 0.73611832 0.74282134 0.74960607 0.75621653\n",
      " 0.76275212 0.76873654]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7739218]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.72142249 0.72925091 0.73611832 0.74282134 0.74960607 0.75621653\n",
      "  0.76275212 0.76873654]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.08295018132776e-05\n",
      "Predicción post entrenamiento : [[0.77388287]]\n",
      "PERDIDAAAA despues: 4.033361256006174e-05\n",
      "loss en el callback: 2.4504141038050875e-05, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.72925091]\n",
      "  [0.73611832]\n",
      "  [0.74282134]\n",
      "  [0.74960607]\n",
      "  [0.75621653]\n",
      "  [0.76275212]\n",
      "  [0.76873654]\n",
      "  [0.77392179]]]\n",
      "ejemplar: [0.72925091 0.73611832 0.74282134 0.74960607 0.75621653 0.76275212\n",
      " 0.76873654 0.77392179]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7799419]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.72925091 0.73611832 0.74282134 0.74960607 0.75621653 0.76275212\n",
      "  0.76873654 0.77392179]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006154481670819223\n",
      "Predicción post entrenamiento : [[0.77959156]]\n",
      "PERDIDAAAA despues: 0.0005981875001452863\n",
      "loss en el callback: 0.0019411778775975108, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.73611832]\n",
      "  [0.74282134]\n",
      "  [0.74960607]\n",
      "  [0.75621653]\n",
      "  [0.76275212]\n",
      "  [0.76873654]\n",
      "  [0.77392179]\n",
      "  [0.77994192]]]\n",
      "ejemplar: [0.73611832 0.74282134 0.74960607 0.75621653 0.76275212 0.76873654\n",
      " 0.77392179 0.77994192]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.78534466]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.73611832 0.74282134 0.74960607 0.75621653 0.76275212 0.76873654\n",
      "  0.77392179 0.77994192]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016228517051786184\n",
      "Predicción post entrenamiento : [[0.78558254]]\n",
      "PERDIDAAAA despues: 0.0016420743195340037\n",
      "loss en el callback: 0.0011746813543140888, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.74282134]\n",
      "  [0.74960607]\n",
      "  [0.75621653]\n",
      "  [0.76275212]\n",
      "  [0.76873654]\n",
      "  [0.77392179]\n",
      "  [0.77994192]\n",
      "  [0.78534466]]]\n",
      "ejemplar: [0.74282134 0.74960607 0.75621653 0.76275212 0.76873654 0.77392179\n",
      " 0.77994192 0.78534466]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.79122263]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.74282134 0.74960607 0.75621653 0.76275212 0.76873654 0.77392179\n",
      "  0.77994192 0.78534466]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001535743591375649\n",
      "Predicción post entrenamiento : [[0.79061735]]\n",
      "PERDIDAAAA despues: 0.0014886694261804223\n",
      "loss en el callback: 0.005809493828564882, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.74960607]\n",
      "  [0.75621653]\n",
      "  [0.76275212]\n",
      "  [0.76873654]\n",
      "  [0.77392179]\n",
      "  [0.77994192]\n",
      "  [0.78534466]\n",
      "  [0.79122263]]]\n",
      "ejemplar: [0.74960607 0.75621653 0.76275212 0.76873654 0.77392179 0.77994192\n",
      " 0.78534466 0.79122263]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.79614127]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.74960607 0.75621653 0.76275212 0.76873654 0.77392179 0.77994192\n",
      "  0.78534466 0.79122263]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007454401813447475\n",
      "Predicción post entrenamiento : [[0.7958065]]\n",
      "PERDIDAAAA despues: 0.007396711967885494\n",
      "loss en el callback: 0.0022263682913035154, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.75621653]\n",
      "  [0.76275212]\n",
      "  [0.76873654]\n",
      "  [0.77392179]\n",
      "  [0.77994192]\n",
      "  [0.78534466]\n",
      "  [0.79122263]\n",
      "  [0.79614127]]]\n",
      "ejemplar: [0.75621653 0.76275212 0.76873654 0.77392179 0.77994192 0.78534466\n",
      " 0.79122263 0.79614127]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.8011413]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.75621653 0.76275212 0.76873654 0.77392179 0.77994192 0.78534466\n",
      "  0.79122263 0.79614127]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0122569864615798\n",
      "Predicción post entrenamiento : [[0.80133826]]\n",
      "PERDIDAAAA despues: 0.012300631031394005\n",
      "loss en el callback: 0.0008844909607432783, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.76275212]\n",
      "  [0.76873654]\n",
      "  [0.77392179]\n",
      "  [0.77994192]\n",
      "  [0.78534466]\n",
      "  [0.79122263]\n",
      "  [0.79614127]\n",
      "  [0.80114132]]]\n",
      "ejemplar: [0.76275212 0.76873654 0.77392179 0.77994192 0.78534466 0.79122263\n",
      " 0.79614127 0.80114132]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8064753]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.76275212 0.76873654 0.77392179 0.77994192 0.78534466 0.79122263\n",
      "  0.79614127 0.80114132]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002716131042689085\n",
      "Predicción post entrenamiento : [[0.80653507]]\n",
      "PERDIDAAAA despues: 0.002722366014495492\n",
      "loss en el callback: 7.310841465368867e-05, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.76873654]\n",
      "  [0.77392179]\n",
      "  [0.77994192]\n",
      "  [0.78534466]\n",
      "  [0.79122263]\n",
      "  [0.79614127]\n",
      "  [0.80114132]\n",
      "  [0.80647528]]]\n",
      "ejemplar: [0.76873654 0.77392179 0.77994192 0.78534466 0.79122263 0.79614127\n",
      " 0.80114132 0.80647528]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.81144]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.76873654 0.77392179 0.77994192 0.78534466 0.79122263 0.79614127\n",
      "  0.80114132 0.80647528]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007963652722537518\n",
      "Predicción post entrenamiento : [[0.8110419]]\n",
      "PERDIDAAAA despues: 0.007892758585512638\n",
      "loss en el callback: 0.0033767581917345524, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.77392179]\n",
      "  [0.77994192]\n",
      "  [0.78534466]\n",
      "  [0.79122263]\n",
      "  [0.79614127]\n",
      "  [0.80114132]\n",
      "  [0.80647528]\n",
      "  [0.81143999]]]\n",
      "ejemplar: [0.77392179 0.77994192 0.78534466 0.79122263 0.79614127 0.80114132\n",
      " 0.80647528 0.81143999]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8158169]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.77392179 0.77994192 0.78534466 0.79122263 0.79614127 0.80114132\n",
      "  0.80647528 0.81143999]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010687328176572919\n",
      "Predicción post entrenamiento : [[0.8171407]]\n",
      "PERDIDAAAA despues: 0.0009839300764724612\n",
      "loss en el callback: 0.051055748015642166, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.77994192]\n",
      "  [0.78534466]\n",
      "  [0.79122263]\n",
      "  [0.79614127]\n",
      "  [0.80114132]\n",
      "  [0.80647528]\n",
      "  [0.81143999]\n",
      "  [0.81581688]]]\n",
      "ejemplar: [0.77994192 0.78534466 0.79122263 0.79614127 0.80114132 0.80647528\n",
      " 0.81143999 0.81581688]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8219796]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.77994192 0.78534466 0.79122263 0.79614127 0.80114132 0.80647528\n",
      "  0.81143999 0.81581688]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006969477515667677\n",
      "Predicción post entrenamiento : [[0.82207215]]\n",
      "PERDIDAAAA despues: 0.006954031065106392\n",
      "loss en el callback: 0.00014660866872873157, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.78534466]\n",
      "  [0.79122263]\n",
      "  [0.79614127]\n",
      "  [0.80114132]\n",
      "  [0.80647528]\n",
      "  [0.81143999]\n",
      "  [0.81581688]\n",
      "  [0.82197958]]]\n",
      "ejemplar: [0.78534466 0.79122263 0.79614127 0.80114132 0.80647528 0.81143999\n",
      " 0.81581688 0.82197958]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.826726]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.78534466 0.79122263 0.79614127 0.80114132 0.80647528 0.81143999\n",
      "  0.81581688 0.82197958]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003079161746427417\n",
      "Predicción post entrenamiento : [[0.8271416]]\n",
      "PERDIDAAAA despues: 0.003033215180039406\n",
      "loss en el callback: 0.0033446578308939934, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.79122263]\n",
      "  [0.79614127]\n",
      "  [0.80114132]\n",
      "  [0.80647528]\n",
      "  [0.81143999]\n",
      "  [0.81581688]\n",
      "  [0.82197958]\n",
      "  [0.82672602]]]\n",
      "ejemplar: [0.79122263 0.79614127 0.80114132 0.80647528 0.81143999 0.81581688\n",
      " 0.82197958 0.82672602]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8317484]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.79122263 0.79614127 0.80114132 0.80647528 0.81143999 0.81581688\n",
      "  0.82197958 0.82672602]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0057819681242108345\n",
      "Predicción post entrenamiento : [[0.83122116]]\n",
      "PERDIDAAAA despues: 0.005862431600689888\n",
      "loss en el callback: 0.004072536714375019, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.79614127]\n",
      "  [0.80114132]\n",
      "  [0.80647528]\n",
      "  [0.81143999]\n",
      "  [0.81581688]\n",
      "  [0.82197958]\n",
      "  [0.82672602]\n",
      "  [0.83174843]]]\n",
      "ejemplar: [0.79614127 0.80114132 0.80647528 0.81143999 0.81581688 0.82197958\n",
      " 0.82672602 0.83174843]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8356278]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.79614127 0.80114132 0.80647528 0.81143999 0.81581688 0.82197958\n",
      "  0.82672602 0.83174843]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029105909634381533\n",
      "Predicción post entrenamiento : [[0.83596236]]\n",
      "PERDIDAAAA despues: 0.0028746037278324366\n",
      "loss en el callback: 0.00209963065572083, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.80114132]\n",
      "  [0.80647528]\n",
      "  [0.81143999]\n",
      "  [0.81581688]\n",
      "  [0.82197958]\n",
      "  [0.82672602]\n",
      "  [0.83174843]\n",
      "  [0.83562779]]]\n",
      "ejemplar: [0.80114132 0.80647528 0.81143999 0.81581688 0.82197958 0.82672602\n",
      " 0.83174843 0.83562779]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.84040886]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.80114132 0.80647528 0.81143999 0.81581688 0.82197958 0.82672602\n",
      "  0.83174843 0.83562779]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011865146225318313\n",
      "Predicción post entrenamiento : [[0.8405758]]\n",
      "PERDIDAAAA despues: 0.0011750408448278904\n",
      "loss en el callback: 0.000545041577424854, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.80647528]\n",
      "  [0.81143999]\n",
      "  [0.81581688]\n",
      "  [0.82197958]\n",
      "  [0.82672602]\n",
      "  [0.83174843]\n",
      "  [0.83562779]\n",
      "  [0.84040886]]]\n",
      "ejemplar: [0.80647528 0.81143999 0.81581688 0.82197958 0.82672602 0.83174843\n",
      " 0.83562779 0.84040886]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8450336]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.80647528 0.81143999 0.81581688 0.82197958 0.82672602 0.83174843\n",
      "  0.83562779 0.84040886]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004648288246244192\n",
      "Predicción post entrenamiento : [[0.845072]]\n",
      "PERDIDAAAA despues: 0.004643055610358715\n",
      "loss en el callback: 2.5844410629360937e-05, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.81143999]\n",
      "  [0.81581688]\n",
      "  [0.82197958]\n",
      "  [0.82672602]\n",
      "  [0.83174843]\n",
      "  [0.83562779]\n",
      "  [0.84040886]\n",
      "  [0.84503359]]]\n",
      "ejemplar: [0.81143999 0.81581688 0.82197958 0.82672602 0.83174843 0.83562779\n",
      " 0.84040886 0.84503359]\n",
      "y: 1.0\n",
      "Predicción : [[0.84943163]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.81143999 0.81581688 0.82197958 0.82672602 0.83174843 0.83562779\n",
      "  0.84040886 0.84503359]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02267083339393139\n",
      "Predicción post entrenamiento : [[0.85059416]]\n",
      "PERDIDAAAA despues: 0.02232210338115692\n",
      "loss en el callback: 0.028915004804730415, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.81581688]\n",
      "  [0.82197958]\n",
      "  [0.82672602]\n",
      "  [0.83174843]\n",
      "  [0.83562779]\n",
      "  [0.84040886]\n",
      "  [0.84503359]\n",
      "  [0.84943163]]]\n",
      "ejemplar: [0.81581688 0.82197958 0.82672602 0.83174843 0.83562779 0.84040886\n",
      " 0.84503359 0.84943163]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.85493386]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.81581688 0.82197958 0.82672602 0.83174843 0.83562779 0.84040886\n",
      "  0.84503359 0.84943163]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013368030078709126\n",
      "Predicción post entrenamiento : [[0.8565022]]\n",
      "PERDIDAAAA despues: 0.013007830828428268\n",
      "loss en el callback: 0.06086603179574013, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.82197958]\n",
      "  [0.82672602]\n",
      "  [0.83174843]\n",
      "  [0.83562779]\n",
      "  [0.84040886]\n",
      "  [0.84503359]\n",
      "  [0.84943163]\n",
      "  [0.85493386]]]\n",
      "ejemplar: [0.82197958 0.82672602 0.83174843 0.83562779 0.84040886 0.84503359\n",
      " 0.84943163 0.85493386]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.860979]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.82197958 0.82672602 0.83174843 0.83562779 0.84040886 0.84503359\n",
      "  0.84943163 0.85493386]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007741608424112201\n",
      "Predicción post entrenamiento : [[0.86105704]]\n",
      "PERDIDAAAA despues: 0.0007698251865804195\n",
      "loss en el callback: 0.00012172442802693695, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.82672602]\n",
      "  [0.83174843]\n",
      "  [0.83562779]\n",
      "  [0.84040886]\n",
      "  [0.84503359]\n",
      "  [0.84943163]\n",
      "  [0.85493386]\n",
      "  [0.86097902]]]\n",
      "ejemplar: [0.82672602 0.83174843 0.83562779 0.84040886 0.84503359 0.84943163\n",
      " 0.85493386 0.86097902]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8651654]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.82672602 0.83174843 0.83562779 0.84040886 0.84503359 0.84943163\n",
      "  0.85493386 0.86097902]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016355575644411147\n",
      "Predicción post entrenamiento : [[0.8643524]]\n",
      "PERDIDAAAA despues: 0.00018501165322959423\n",
      "loss en el callback: 0.011114807799458504, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.83174843]\n",
      "  [0.83562779]\n",
      "  [0.84040886]\n",
      "  [0.84503359]\n",
      "  [0.84943163]\n",
      "  [0.85493386]\n",
      "  [0.86097902]\n",
      "  [0.86516541]]]\n",
      "ejemplar: [0.83174843 0.83562779 0.84040886 0.84503359 0.84943163 0.85493386\n",
      " 0.86097902 0.86516541]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.868454]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.83174843 0.83562779 0.84040886 0.84503359 0.84943163 0.85493386\n",
      "  0.86097902 0.86516541]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003825228486675769\n",
      "Predicción post entrenamiento : [[0.86861664]]\n",
      "PERDIDAAAA despues: 0.00038891201256774366\n",
      "loss en el callback: 0.0006183824152685702, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.83562779]\n",
      "  [0.84040886]\n",
      "  [0.84503359]\n",
      "  [0.84943163]\n",
      "  [0.85493386]\n",
      "  [0.86097902]\n",
      "  [0.86516541]\n",
      "  [0.86845398]]]\n",
      "ejemplar: [0.83562779 0.84040886 0.84503359 0.84943163 0.85493386 0.86097902\n",
      " 0.86516541 0.86845398]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8726356]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.83562779 0.84040886 0.84503359 0.84943163 0.85493386 0.86097902\n",
      "  0.86516541 0.86845398]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014793883310630918\n",
      "Predicción post entrenamiento : [[0.8716917]]\n",
      "PERDIDAAAA despues: 0.0014076692750677466\n",
      "loss en el callback: 0.016408687457442284, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.84040886]\n",
      "  [0.84503359]\n",
      "  [0.84943163]\n",
      "  [0.85493386]\n",
      "  [0.86097902]\n",
      "  [0.86516541]\n",
      "  [0.86845398]\n",
      "  [0.8726356 ]]]\n",
      "ejemplar: [0.84040886 0.84503359 0.84943163 0.85493386 0.86097902 0.86516541\n",
      " 0.86845398 0.8726356 ]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.87594575]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.84040886 0.84503359 0.84943163 0.85493386 0.86097902 0.86516541\n",
      "  0.86845398 0.8726356 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043475741404108703\n",
      "Predicción post entrenamiento : [[0.8764495]]\n",
      "PERDIDAAAA despues: 0.00045601962483488023\n",
      "loss en el callback: 0.0065200598910450935, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.84503359]\n",
      "  [0.84943163]\n",
      "  [0.85493386]\n",
      "  [0.86097902]\n",
      "  [0.86516541]\n",
      "  [0.86845398]\n",
      "  [0.8726356 ]\n",
      "  [0.87594575]]]\n",
      "ejemplar: [0.84503359 0.84943163 0.85493386 0.86097902 0.86516541 0.86845398\n",
      " 0.8726356  0.87594575]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.88069385]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.84503359 0.84943163 0.85493386 0.86097902 0.86516541 0.86845398\n",
      "  0.8726356  0.87594575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.972080619656481e-05\n",
      "Predicción post entrenamiento : [[0.879514]]\n",
      "PERDIDAAAA despues: 1.8248319975100458e-05\n",
      "loss en el callback: 0.02537437155842781, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.84943163]\n",
      "  [0.85493386]\n",
      "  [0.86097902]\n",
      "  [0.86516541]\n",
      "  [0.86845398]\n",
      "  [0.8726356 ]\n",
      "  [0.87594575]\n",
      "  [0.88069385]]]\n",
      "ejemplar: [0.84943163 0.85493386 0.86097902 0.86516541 0.86845398 0.8726356\n",
      " 0.87594575 0.88069385]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8837633]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.84943163 0.85493386 0.86097902 0.86516541 0.86845398 0.8726356\n",
      "  0.87594575 0.88069385]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007145535200834274\n",
      "Predicción post entrenamiento : [[0.8830084]]\n",
      "PERDIDAAAA despues: 0.0006747650913894176\n",
      "loss en el callback: 0.010575883090496063, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.85493386]\n",
      "  [0.86097902]\n",
      "  [0.86516541]\n",
      "  [0.86845398]\n",
      "  [0.8726356 ]\n",
      "  [0.87594575]\n",
      "  [0.88069385]\n",
      "  [0.88376331]]]\n",
      "ejemplar: [0.85493386 0.86097902 0.86516541 0.86845398 0.8726356  0.87594575\n",
      " 0.88069385 0.88376331]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.88729537]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.85493386 0.86097902 0.86516541 0.86845398 0.8726356  0.87594575\n",
      "  0.88069385 0.88376331]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013866110239177942\n",
      "Predicción post entrenamiento : [[0.88711923]]\n",
      "PERDIDAAAA despues: 0.0013735247775912285\n",
      "loss en el callback: 0.0006408364861272275, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.86097902]\n",
      "  [0.86516541]\n",
      "  [0.86845398]\n",
      "  [0.8726356 ]\n",
      "  [0.87594575]\n",
      "  [0.88069385]\n",
      "  [0.88376331]\n",
      "  [0.88729537]]]\n",
      "ejemplar: [0.86097902 0.86516541 0.86845398 0.8726356  0.87594575 0.88069385\n",
      " 0.88376331 0.88729537]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8910841]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.86097902 0.86516541 0.86845398 0.8726356  0.87594575 0.88069385\n",
      "  0.88376331 0.88729537]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002341347048059106\n",
      "Predicción post entrenamiento : [[0.88996893]]\n",
      "PERDIDAAAA despues: 0.002234672661870718\n",
      "loss en el callback: 0.022783854976296425, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.86516541]\n",
      "  [0.86845398]\n",
      "  [0.8726356 ]\n",
      "  [0.87594575]\n",
      "  [0.88069385]\n",
      "  [0.88376331]\n",
      "  [0.88729537]\n",
      "  [0.89108407]]]\n",
      "ejemplar: [0.86516541 0.86845398 0.8726356  0.87594575 0.88069385 0.88376331\n",
      " 0.88729537 0.89108407]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8933692]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.86516541 0.86845398 0.8726356  0.87594575 0.88069385 0.88376331\n",
      "  0.88729537 0.89108407]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004960718099027872\n",
      "Predicción post entrenamiento : [[0.89329416]]\n",
      "PERDIDAAAA despues: 0.004950152710080147\n",
      "loss en el callback: 0.00014990498311817646, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.86845398]\n",
      "  [0.8726356 ]\n",
      "  [0.87594575]\n",
      "  [0.88069385]\n",
      "  [0.88376331]\n",
      "  [0.88729537]\n",
      "  [0.89108407]\n",
      "  [0.8933692 ]]]\n",
      "ejemplar: [0.86845398 0.8726356  0.87594575 0.88069385 0.88376331 0.88729537\n",
      " 0.89108407 0.8933692 ]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8965706]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.86845398 0.8726356  0.87594575 0.88069385 0.88376331 0.88729537\n",
      "  0.89108407 0.8933692 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014899764209985733\n",
      "Predicción post entrenamiento : [[0.89560467]]\n",
      "PERDIDAAAA despues: 0.014664880000054836\n",
      "loss en el callback: 0.02037937380373478, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.8726356 ]\n",
      "  [0.87594575]\n",
      "  [0.88069385]\n",
      "  [0.88376331]\n",
      "  [0.88729537]\n",
      "  [0.89108407]\n",
      "  [0.8933692 ]\n",
      "  [0.89657062]]]\n",
      "ejemplar: [0.8726356  0.87594575 0.88069385 0.88376331 0.88729537 0.89108407\n",
      " 0.8933692  0.89657062]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8989838]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.8726356  0.87594575 0.88069385 0.88376331 0.88729537 0.89108407\n",
      "  0.8933692  0.89657062]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013177118264138699\n",
      "Predicción post entrenamiento : [[0.898204]]\n",
      "PERDIDAAAA despues: 0.012998709455132484\n",
      "loss en el callback: 0.014561038464307785, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.87594575]\n",
      "  [0.88069385]\n",
      "  [0.88376331]\n",
      "  [0.88729537]\n",
      "  [0.89108407]\n",
      "  [0.8933692 ]\n",
      "  [0.89657062]\n",
      "  [0.89898378]]]\n",
      "ejemplar: [0.87594575 0.88069385 0.88376331 0.88729537 0.89108407 0.8933692\n",
      " 0.89657062 0.89898378]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.90141314]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.87594575 0.88069385 0.88376331 0.88729537 0.89108407 0.8933692\n",
      "  0.89657062 0.89898378]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017362915677949786\n",
      "Predicción post entrenamiento : [[0.90164846]]\n",
      "PERDIDAAAA despues: 0.0017559579573571682\n",
      "loss en el callback: 0.001472257892601192, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.88069385]\n",
      "  [0.88376331]\n",
      "  [0.88729537]\n",
      "  [0.89108407]\n",
      "  [0.8933692 ]\n",
      "  [0.89657062]\n",
      "  [0.89898378]\n",
      "  [0.90141314]]]\n",
      "ejemplar: [0.88069385 0.88376331 0.88729537 0.89108407 0.8933692  0.89657062\n",
      " 0.89898378 0.90141314]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9048869]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.88069385 0.88376331 0.88729537 0.89108407 0.8933692  0.89657062\n",
      "  0.89898378 0.90141314]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025570064317435026\n",
      "Predicción post entrenamiento : [[0.9041794]]\n",
      "PERDIDAAAA despues: 0.002485954202711582\n",
      "loss en el callback: 0.010777706280350685, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.88376331]\n",
      "  [0.88729537]\n",
      "  [0.89108407]\n",
      "  [0.8933692 ]\n",
      "  [0.89657062]\n",
      "  [0.89898378]\n",
      "  [0.90141314]\n",
      "  [0.9048869 ]]]\n",
      "ejemplar: [0.88376331 0.88729537 0.89108407 0.8933692  0.89657062 0.89898378\n",
      " 0.90141314 0.9048869 ]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9069986]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.88376331 0.88729537 0.89108407 0.8933692  0.89657062 0.89898378\n",
      "  0.90141314 0.9048869 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004915925208479166\n",
      "Predicción post entrenamiento : [[0.90703094]]\n",
      "PERDIDAAAA despues: 0.004920464940369129\n",
      "loss en el callback: 2.5996747353929095e-05, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.88729537]\n",
      "  [0.89108407]\n",
      "  [0.8933692 ]\n",
      "  [0.89657062]\n",
      "  [0.89898378]\n",
      "  [0.90141314]\n",
      "  [0.9048869 ]\n",
      "  [0.90699857]]]\n",
      "ejemplar: [0.88729537 0.89108407 0.8933692  0.89657062 0.89898378 0.90141314\n",
      " 0.9048869  0.90699857]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9098385]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.88729537 0.89108407 0.8933692  0.89657062 0.89898378 0.90141314\n",
      "  0.9048869  0.90699857]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006388424895703793\n",
      "Predicción post entrenamiento : [[0.9087782]]\n",
      "PERDIDAAAA despues: 0.006220053415745497\n",
      "loss en el callback: 0.022944806143641472, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.89108407]\n",
      "  [0.8933692 ]\n",
      "  [0.89657062]\n",
      "  [0.89898378]\n",
      "  [0.90141314]\n",
      "  [0.9048869 ]\n",
      "  [0.90699857]\n",
      "  [0.9098385 ]]]\n",
      "ejemplar: [0.89108407 0.8933692  0.89657062 0.89898378 0.90141314 0.9048869\n",
      " 0.90699857 0.9098385 ]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9114173]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.89108407 0.8933692  0.89657062 0.89898378 0.90141314 0.9048869\n",
      "  0.90699857 0.9098385 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005839143414050341\n",
      "Predicción post entrenamiento : [[0.91054153]]\n",
      "PERDIDAAAA despues: 0.0005423564580269158\n",
      "loss en el callback: 0.015123185701668262, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.8933692 ]\n",
      "  [0.89657062]\n",
      "  [0.89898378]\n",
      "  [0.90141314]\n",
      "  [0.9048869 ]\n",
      "  [0.90699857]\n",
      "  [0.9098385 ]\n",
      "  [0.91141731]]]\n",
      "ejemplar: [0.8933692  0.89657062 0.89898378 0.90141314 0.9048869  0.90699857\n",
      " 0.9098385  0.91141731]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9128933]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.8933692  0.89657062 0.89898378 0.90141314 0.9048869  0.90699857\n",
      "  0.9098385  0.91141731]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002824814524501562\n",
      "Predicción post entrenamiento : [[0.9119447]]\n",
      "PERDIDAAAA despues: 0.0027248794212937355\n",
      "loss en el callback: 0.018313826993107796, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.89657062]\n",
      "  [0.89898378]\n",
      "  [0.90141314]\n",
      "  [0.9048869 ]\n",
      "  [0.90699857]\n",
      "  [0.9098385 ]\n",
      "  [0.91141731]\n",
      "  [0.9128933 ]]]\n",
      "ejemplar: [0.89657062 0.89898378 0.90141314 0.9048869  0.90699857 0.9098385\n",
      " 0.91141731 0.9128933 ]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9143902]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.89657062 0.89898378 0.90141314 0.9048869  0.90699857 0.9098385\n",
      "  0.91141731 0.9128933 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00559401698410511\n",
      "Predicción post entrenamiento : [[0.9136513]]\n",
      "PERDIDAAAA despues: 0.005484030582010746\n",
      "loss en el callback: 0.013449016958475113, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.89898378]\n",
      "  [0.90141314]\n",
      "  [0.9048869 ]\n",
      "  [0.90699857]\n",
      "  [0.9098385 ]\n",
      "  [0.91141731]\n",
      "  [0.9128933 ]\n",
      "  [0.91439021]]]\n",
      "ejemplar: [0.89898378 0.90141314 0.9048869  0.90699857 0.9098385  0.91141731\n",
      " 0.9128933  0.91439021]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9159087]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.89898378 0.90141314 0.9048869  0.90699857 0.9098385  0.91141731\n",
      "  0.9128933  0.91439021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017451461404561996\n",
      "Predicción post entrenamiento : [[0.9158806]]\n",
      "PERDIDAAAA despues: 0.01744404435157776\n",
      "loss en el callback: 2.7027279429603368e-05, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.90141314]\n",
      "  [0.9048869 ]\n",
      "  [0.90699857]\n",
      "  [0.9098385 ]\n",
      "  [0.91141731]\n",
      "  [0.9128933 ]\n",
      "  [0.91439021]\n",
      "  [0.91590869]]]\n",
      "ejemplar: [0.90141314 0.9048869  0.90699857 0.9098385  0.91141731 0.9128933\n",
      " 0.91439021 0.91590869]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9181242]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.90141314 0.9048869  0.90699857 0.9098385  0.91141731 0.9128933\n",
      "  0.91439021 0.91590869]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009967368096113205\n",
      "Predicción post entrenamiento : [[0.91782933]]\n",
      "PERDIDAAAA despues: 0.009908578358590603\n",
      "loss en el callback: 0.0024247881956398487, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.9048869 ]\n",
      "  [0.90699857]\n",
      "  [0.9098385 ]\n",
      "  [0.91141731]\n",
      "  [0.9128933 ]\n",
      "  [0.91439021]\n",
      "  [0.91590869]\n",
      "  [0.9181242 ]]]\n",
      "ejemplar: [0.9048869  0.90699857 0.9098385  0.91141731 0.9128933  0.91439021\n",
      " 0.91590869 0.9181242 ]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9200213]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.9048869  0.90699857 0.9098385  0.91141731 0.9128933  0.91439021\n",
      "  0.91590869 0.9181242 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016603639349341393\n",
      "Predicción post entrenamiento : [[0.9191434]]\n",
      "PERDIDAAAA despues: 0.016378162428736687\n",
      "loss en el callback: 0.01881541684269905, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.90699857]\n",
      "  [0.9098385 ]\n",
      "  [0.91141731]\n",
      "  [0.9128933 ]\n",
      "  [0.91439021]\n",
      "  [0.91590869]\n",
      "  [0.9181242 ]\n",
      "  [0.9200213 ]]]\n",
      "ejemplar: [0.90699857 0.9098385  0.91141731 0.9128933  0.91439021 0.91590869\n",
      " 0.9181242  0.9200213 ]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9209406]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.90699857 0.9098385  0.91141731 0.9128933  0.91439021 0.91590869\n",
      "  0.9181242  0.9200213 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02572258748114109\n",
      "Predicción post entrenamiento : [[0.91888386]]\n",
      "PERDIDAAAA despues: 0.025067094713449478\n",
      "loss en el callback: 0.08737082779407501, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.9098385 ]\n",
      "  [0.91141731]\n",
      "  [0.9128933 ]\n",
      "  [0.91439021]\n",
      "  [0.91590869]\n",
      "  [0.9181242 ]\n",
      "  [0.9200213 ]\n",
      "  [0.92094058]]]\n",
      "ejemplar: [0.9098385  0.91141731 0.9128933  0.91439021 0.91590869 0.9181242\n",
      " 0.9200213  0.92094058]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.92060685]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.9098385  0.91141731 0.9128933  0.91439021 0.91590869 0.9181242\n",
      "  0.9200213  0.92094058]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01665472239255905\n",
      "Predicción post entrenamiento : [[0.9207055]]\n",
      "PERDIDAAAA despues: 0.016680192202329636\n",
      "loss en el callback: 0.00034660284291021526, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.91141731]\n",
      "  [0.9128933 ]\n",
      "  [0.91439021]\n",
      "  [0.91590869]\n",
      "  [0.9181242 ]\n",
      "  [0.9200213 ]\n",
      "  [0.92094058]\n",
      "  [0.92060685]]]\n",
      "ejemplar: [0.91141731 0.9128933  0.91439021 0.91590869 0.9181242  0.9200213\n",
      " 0.92094058 0.92060685]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9221061]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.91141731 0.9128933  0.91439021 0.91590869 0.9181242  0.9200213\n",
      "  0.92094058 0.92060685]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02353518269956112\n",
      "Predicción post entrenamiento : [[0.92045856]]\n",
      "PERDIDAAAA despues: 0.02303239516913891\n",
      "loss en el callback: 0.06488918513059616, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.9128933 ]\n",
      "  [0.91439021]\n",
      "  [0.91590869]\n",
      "  [0.9181242 ]\n",
      "  [0.9200213 ]\n",
      "  [0.92094058]\n",
      "  [0.92060685]\n",
      "  [0.92210609]]]\n",
      "ejemplar: [0.9128933  0.91439021 0.91590869 0.9181242  0.9200213  0.92094058\n",
      " 0.92060685 0.92210609]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9218401]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.9128933  0.91439021 0.91590869 0.9181242  0.9200213  0.92094058\n",
      "  0.92060685 0.92210609]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02345363236963749\n",
      "Predicción post entrenamiento : [[0.92143196]]\n",
      "PERDIDAAAA despues: 0.02332879789173603\n",
      "loss en el callback: 0.005038085859268904, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.91439021]\n",
      "  [0.91590869]\n",
      "  [0.9181242 ]\n",
      "  [0.9200213 ]\n",
      "  [0.92094058]\n",
      "  [0.92060685]\n",
      "  [0.92210609]\n",
      "  [0.92184007]]]\n",
      "ejemplar: [0.91439021 0.91590869 0.9181242  0.9200213  0.92094058 0.92060685\n",
      " 0.92210609 0.92184007]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9227954]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.91439021 0.91590869 0.9181242  0.9200213  0.92094058 0.92060685\n",
      "  0.92210609 0.92184007]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01534632034599781\n",
      "Predicción post entrenamiento : [[0.92160785]]\n",
      "PERDIDAAAA despues: 0.01505349949002266\n",
      "loss en el callback: 0.03486403077840805, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.91590869]\n",
      "  [0.9181242 ]\n",
      "  [0.9200213 ]\n",
      "  [0.92094058]\n",
      "  [0.92060685]\n",
      "  [0.92210609]\n",
      "  [0.92184007]\n",
      "  [0.92279541]]]\n",
      "ejemplar: [0.91590869 0.9181242  0.9200213  0.92094058 0.92060685 0.92210609\n",
      " 0.92184007 0.92279541]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9229112]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.91590869 0.9181242  0.9200213  0.92094058 0.92060685 0.92210609\n",
      "  0.92184007 0.92279541]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017664358019828796\n",
      "Predicción post entrenamiento : [[0.9228077]]\n",
      "PERDIDAAAA despues: 0.017636848613619804\n",
      "loss en el callback: 0.0003801065613515675, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.9181242 ]\n",
      "  [0.9200213 ]\n",
      "  [0.92094058]\n",
      "  [0.92060685]\n",
      "  [0.92210609]\n",
      "  [0.92184007]\n",
      "  [0.92279541]\n",
      "  [0.92291123]]]\n",
      "ejemplar: [0.9181242  0.9200213  0.92094058 0.92060685 0.92210609 0.92184007\n",
      " 0.92279541 0.92291123]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9239988]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.9181242  0.9200213  0.92094058 0.92060685 0.92210609 0.92184007\n",
      "  0.92279541 0.92291123]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026839716359972954\n",
      "Predicción post entrenamiento : [[0.92347586]]\n",
      "PERDIDAAAA despues: 0.02666865475475788\n",
      "loss en el callback: 0.00913317408412695, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.9200213 ]\n",
      "  [0.92094058]\n",
      "  [0.92060685]\n",
      "  [0.92210609]\n",
      "  [0.92184007]\n",
      "  [0.92279541]\n",
      "  [0.92291123]\n",
      "  [0.92399877]]]\n",
      "ejemplar: [0.9200213  0.92094058 0.92060685 0.92210609 0.92184007 0.92279541\n",
      " 0.92291123 0.92399877]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9243006]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.9200213  0.92094058 0.92060685 0.92210609 0.92184007 0.92279541\n",
      "  0.92291123 0.92399877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05707671493291855\n",
      "Predicción post entrenamiento : [[0.921638]]\n",
      "PERDIDAAAA despues: 0.055811576545238495\n",
      "loss en el callback: 0.15911899507045746, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.92094058]\n",
      "  [0.92060685]\n",
      "  [0.92210609]\n",
      "  [0.92184007]\n",
      "  [0.92279541]\n",
      "  [0.92291123]\n",
      "  [0.92399877]\n",
      "  [0.92430061]]]\n",
      "ejemplar: [0.92094058 0.92060685 0.92210609 0.92184007 0.92279541 0.92291123\n",
      " 0.92399877 0.92430061]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9221155]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.92094058 0.92060685 0.92210609 0.92184007 0.92279541 0.92291123\n",
      "  0.92399877 0.92430061]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10044065862894058\n",
      "Predicción post entrenamiento : [[0.9210583]]\n",
      "PERDIDAAAA despues: 0.0997716635465622\n",
      "loss en el callback: 0.04348178207874298, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.92060685]\n",
      "  [0.92210609]\n",
      "  [0.92184007]\n",
      "  [0.92279541]\n",
      "  [0.92291123]\n",
      "  [0.92399877]\n",
      "  [0.92430061]\n",
      "  [0.9221155 ]]]\n",
      "ejemplar: [0.92060685 0.92210609 0.92184007 0.92279541 0.92291123 0.92399877\n",
      " 0.92430061 0.9221155 ]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9214052]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.92060685 0.92210609 0.92184007 0.92279541 0.92291123 0.92399877\n",
      "  0.92430061 0.9221155 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06581616401672363\n",
      "Predicción post entrenamiento : [[0.9193966]]\n",
      "PERDIDAAAA despues: 0.06478959321975708\n",
      "loss en el callback: 0.10800020396709442, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.92210609]\n",
      "  [0.92184007]\n",
      "  [0.92279541]\n",
      "  [0.92291123]\n",
      "  [0.92399877]\n",
      "  [0.92430061]\n",
      "  [0.9221155 ]\n",
      "  [0.9214052 ]]]\n",
      "ejemplar: [0.92210609 0.92184007 0.92279541 0.92291123 0.92399877 0.92430061\n",
      " 0.9221155  0.9214052 ]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9199364]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.92210609 0.92184007 0.92279541 0.92291123 0.92399877 0.92430061\n",
      "  0.9221155  0.9214052 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04497421160340309\n",
      "Predicción post entrenamiento : [[0.91740817]]\n",
      "PERDIDAAAA despues: 0.043908264487981796\n",
      "loss en el callback: 0.1519170105457306, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.92184007]\n",
      "  [0.92279541]\n",
      "  [0.92291123]\n",
      "  [0.92399877]\n",
      "  [0.92430061]\n",
      "  [0.9221155 ]\n",
      "  [0.9214052 ]\n",
      "  [0.91993642]]]\n",
      "ejemplar: [0.92184007 0.92279541 0.92291123 0.92399877 0.92430061 0.9221155\n",
      " 0.9214052  0.91993642]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9175896]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.92184007 0.92279541 0.92291123 0.92399877 0.92430061 0.9221155\n",
      "  0.9214052  0.91993642]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06387297064065933\n",
      "Predicción post entrenamiento : [[0.916587]]\n",
      "PERDIDAAAA despues: 0.06336719542741776\n",
      "loss en el callback: 0.033994223922491074, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.92279541]\n",
      "  [0.92291123]\n",
      "  [0.92399877]\n",
      "  [0.92430061]\n",
      "  [0.9221155 ]\n",
      "  [0.9214052 ]\n",
      "  [0.91993642]\n",
      "  [0.9175896 ]]]\n",
      "ejemplar: [0.92279541 0.92291123 0.92399877 0.92430061 0.9221155  0.9214052\n",
      " 0.91993642 0.9175896 ]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9168205]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.92279541 0.92291123 0.92399877 0.92430061 0.9221155  0.9214052\n",
      "  0.91993642 0.9175896 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04221724718809128\n",
      "Predicción post entrenamiento : [[0.9154835]]\n",
      "PERDIDAAAA despues: 0.041669588536024094\n",
      "loss en el callback: 0.05231453478336334, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.92291123]\n",
      "  [0.92399877]\n",
      "  [0.92430061]\n",
      "  [0.9221155 ]\n",
      "  [0.9214052 ]\n",
      "  [0.91993642]\n",
      "  [0.9175896 ]\n",
      "  [0.91682053]]]\n",
      "ejemplar: [0.92291123 0.92399877 0.92430061 0.9221155  0.9214052  0.91993642\n",
      " 0.9175896  0.91682053]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.91536105]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.92291123 0.92399877 0.92430061 0.9221155  0.9214052  0.91993642\n",
      "  0.9175896  0.91682053]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05669359490275383\n",
      "Predicción post entrenamiento : [[0.91445494]]\n",
      "PERDIDAAAA despues: 0.05626291781663895\n",
      "loss en el callback: 0.02889828383922577, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.92399877]\n",
      "  [0.92430061]\n",
      "  [0.9221155 ]\n",
      "  [0.9214052 ]\n",
      "  [0.91993642]\n",
      "  [0.9175896 ]\n",
      "  [0.91682053]\n",
      "  [0.91536105]]]\n",
      "ejemplar: [0.92399877 0.92430061 0.9221155  0.9214052  0.91993642 0.9175896\n",
      " 0.91682053 0.91536105]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.91411585]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.92399877 0.92430061 0.9221155  0.9214052  0.91993642 0.9175896\n",
      "  0.91682053 0.91536105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023106466978788376\n",
      "Predicción post entrenamiento : [[0.9133163]]\n",
      "PERDIDAAAA despues: 0.02286403439939022\n",
      "loss en el callback: 0.021586580201983452, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.92430061]\n",
      "  [0.9221155 ]\n",
      "  [0.9214052 ]\n",
      "  [0.91993642]\n",
      "  [0.9175896 ]\n",
      "  [0.91682053]\n",
      "  [0.91536105]\n",
      "  [0.91411585]]]\n",
      "ejemplar: [0.92430061 0.9221155  0.9214052  0.91993642 0.9175896  0.91682053\n",
      " 0.91536105 0.91411585]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9124015]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.92430061 0.9221155  0.9214052  0.91993642 0.9175896  0.91682053\n",
      "  0.91536105 0.91411585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01109861396253109\n",
      "Predicción post entrenamiento : [[0.91116685]]\n",
      "PERDIDAAAA despues: 0.010839996859431267\n",
      "loss en el callback: 0.03982873260974884, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.9221155 ]\n",
      "  [0.9214052 ]\n",
      "  [0.91993642]\n",
      "  [0.9175896 ]\n",
      "  [0.91682053]\n",
      "  [0.91536105]\n",
      "  [0.91411585]\n",
      "  [0.9124015 ]]]\n",
      "ejemplar: [0.9221155  0.9214052  0.91993642 0.9175896  0.91682053 0.91536105\n",
      " 0.91411585 0.9124015 ]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9098001]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.9221155  0.9214052  0.91993642 0.9175896  0.91682053 0.91536105\n",
      "  0.91411585 0.9124015 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008951464667916298\n",
      "Predicción post entrenamiento : [[0.9084506]]\n",
      "PERDIDAAAA despues: 0.008697926066815853\n",
      "loss en el callback: 0.046289779245853424, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.9214052 ]\n",
      "  [0.91993642]\n",
      "  [0.9175896 ]\n",
      "  [0.91682053]\n",
      "  [0.91536105]\n",
      "  [0.91411585]\n",
      "  [0.9124015 ]\n",
      "  [0.90980011]]]\n",
      "ejemplar: [0.9214052  0.91993642 0.9175896  0.91682053 0.91536105 0.91411585\n",
      " 0.9124015  0.90980011]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9072826]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.9214052  0.91993642 0.9175896  0.91682053 0.91536105 0.91411585\n",
      "  0.9124015  0.90980011]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.091378521778097e-06\n",
      "Predicción post entrenamiento : [[0.9075003]]\n",
      "PERDIDAAAA despues: 1.593720298842527e-06\n",
      "loss en el callback: 0.001810849760659039, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.91993642]\n",
      "  [0.9175896 ]\n",
      "  [0.91682053]\n",
      "  [0.91536105]\n",
      "  [0.91411585]\n",
      "  [0.9124015 ]\n",
      "  [0.90980011]\n",
      "  [0.90728259]]]\n",
      "ejemplar: [0.91993642 0.9175896  0.91682053 0.91536105 0.91411585 0.9124015\n",
      " 0.90980011 0.90728259]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.90611196]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.91993642 0.9175896  0.91682053 0.91536105 0.91411585 0.9124015\n",
      "  0.90980011 0.90728259]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028722714632749557\n",
      "Predicción post entrenamiento : [[0.90663064]]\n",
      "PERDIDAAAA despues: 0.0028169446159154177\n",
      "loss en el callback: 0.010062675923109055, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.9175896 ]\n",
      "  [0.91682053]\n",
      "  [0.91536105]\n",
      "  [0.91411585]\n",
      "  [0.9124015 ]\n",
      "  [0.90980011]\n",
      "  [0.90728259]\n",
      "  [0.90611196]]]\n",
      "ejemplar: [0.9175896  0.91682053 0.91536105 0.91411585 0.9124015  0.90980011\n",
      " 0.90728259 0.90611196]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9051971]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.9175896  0.91682053 0.91536105 0.91411585 0.9124015  0.90980011\n",
      "  0.90728259 0.90611196]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034996438771486282\n",
      "Predicción post entrenamiento : [[0.90621364]]\n",
      "PERDIDAAAA despues: 0.0033804026897996664\n",
      "loss en el callback: 0.04655247554183006, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.91682053]\n",
      "  [0.91536105]\n",
      "  [0.91411585]\n",
      "  [0.9124015 ]\n",
      "  [0.90980011]\n",
      "  [0.90728259]\n",
      "  [0.90611196]\n",
      "  [0.90519708]]]\n",
      "ejemplar: [0.91682053 0.91536105 0.91411585 0.9124015  0.90980011 0.90728259\n",
      " 0.90611196 0.90519708]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9049776]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.91682053 0.91536105 0.91411585 0.9124015  0.90980011 0.90728259\n",
      "  0.90611196 0.90519708]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002872927871067077\n",
      "Predicción post entrenamiento : [[0.9051977]]\n",
      "PERDIDAAAA despues: 0.00029480113880708814\n",
      "loss en el callback: 0.0018879593117162585, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.91536105]\n",
      "  [0.91411585]\n",
      "  [0.9124015 ]\n",
      "  [0.90980011]\n",
      "  [0.90728259]\n",
      "  [0.90611196]\n",
      "  [0.90519708]\n",
      "  [0.90497762]]]\n",
      "ejemplar: [0.91536105 0.91411585 0.9124015  0.90980011 0.90728259 0.90611196\n",
      " 0.90519708 0.90497762]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.90372854]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.91536105 0.91411585 0.9124015  0.90980011 0.90728259 0.90611196\n",
      "  0.90519708 0.90497762]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012213116860948503\n",
      "Predicción post entrenamiento : [[0.90282613]]\n",
      "PERDIDAAAA despues: 0.00010299982386641204\n",
      "loss en el callback: 0.022221000865101814, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.91411585]\n",
      "  [0.9124015 ]\n",
      "  [0.90980011]\n",
      "  [0.90728259]\n",
      "  [0.90611196]\n",
      "  [0.90519708]\n",
      "  [0.90497762]\n",
      "  [0.90372854]]]\n",
      "ejemplar: [0.91411585 0.9124015  0.90980011 0.90728259 0.90611196 0.90519708\n",
      " 0.90497762 0.90372854]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9013037]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.91411585 0.9124015  0.90980011 0.90728259 0.90611196 0.90519708\n",
      "  0.90497762 0.90372854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006792036001570523\n",
      "Predicción post entrenamiento : [[0.90050435]]\n",
      "PERDIDAAAA despues: 0.0006381775601767004\n",
      "loss en el callback: 0.018187984824180603, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.9124015 ]\n",
      "  [0.90980011]\n",
      "  [0.90728259]\n",
      "  [0.90611196]\n",
      "  [0.90519708]\n",
      "  [0.90497762]\n",
      "  [0.90372854]\n",
      "  [0.90130371]]]\n",
      "ejemplar: [0.9124015  0.90980011 0.90728259 0.90611196 0.90519708 0.90497762\n",
      " 0.90372854 0.90130371]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.8988739]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.9124015  0.90980011 0.90728259 0.90611196 0.90519708 0.90497762\n",
      "  0.90372854 0.90130371]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002307930728420615\n",
      "Predicción post entrenamiento : [[0.898882]]\n",
      "PERDIDAAAA despues: 0.002308703726157546\n",
      "loss en el callback: 2.503562200217857e-06, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.90980011]\n",
      "  [0.90728259]\n",
      "  [0.90611196]\n",
      "  [0.90519708]\n",
      "  [0.90497762]\n",
      "  [0.90372854]\n",
      "  [0.90130371]\n",
      "  [0.89887393]]]\n",
      "ejemplar: [0.90980011 0.90728259 0.90611196 0.90519708 0.90497762 0.90372854\n",
      " 0.90130371 0.89887393]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.89727765]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.90980011 0.90728259 0.90611196 0.90519708 0.90497762 0.90372854\n",
      "  0.90130371 0.89887393]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002340804785490036\n",
      "Predicción post entrenamiento : [[0.89680004]]\n",
      "PERDIDAAAA despues: 0.0022948174737393856\n",
      "loss en el callback: 0.007991761900484562, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.90728259]\n",
      "  [0.90611196]\n",
      "  [0.90519708]\n",
      "  [0.90497762]\n",
      "  [0.90372854]\n",
      "  [0.90130371]\n",
      "  [0.89887393]\n",
      "  [0.89727765]]]\n",
      "ejemplar: [0.90728259 0.90611196 0.90519708 0.90497762 0.90372854 0.90130371\n",
      " 0.89887393 0.89727765]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.89549285]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.90728259 0.90611196 0.90519708 0.90497762 0.90372854 0.90130371\n",
      "  0.89887393 0.89727765]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004478930030018091\n",
      "Predicción post entrenamiento : [[0.89508635]]\n",
      "PERDIDAAAA despues: 0.0045335059985518456\n",
      "loss en el callback: 0.00489124096930027, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.90611196]\n",
      "  [0.90519708]\n",
      "  [0.90497762]\n",
      "  [0.90372854]\n",
      "  [0.90130371]\n",
      "  [0.89887393]\n",
      "  [0.89727765]\n",
      "  [0.89549285]]]\n",
      "ejemplar: [0.90611196 0.90519708 0.90497762 0.90372854 0.90130371 0.89887393\n",
      " 0.89727765 0.89549285]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.8940881]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.90611196 0.90519708 0.90497762 0.90372854 0.90130371 0.89887393\n",
      "  0.89727765 0.89549285]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005439627915620804\n",
      "Predicción post entrenamiento : [[0.8948498]]\n",
      "PERDIDAAAA despues: 0.005327853374183178\n",
      "loss en el callback: 0.026618042960762978, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.90519708]\n",
      "  [0.90497762]\n",
      "  [0.90372854]\n",
      "  [0.90130371]\n",
      "  [0.89887393]\n",
      "  [0.89727765]\n",
      "  [0.89549285]\n",
      "  [0.89408809]]]\n",
      "ejemplar: [0.90519708 0.90497762 0.90372854 0.90130371 0.89887393 0.89727765\n",
      " 0.89549285 0.89408809]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.89379156]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.90519708 0.90497762 0.90372854 0.90130371 0.89887393 0.89727765\n",
      "  0.89549285 0.89408809]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022023424971848726\n",
      "Predicción post entrenamiento : [[0.8942457]]\n",
      "PERDIDAAAA despues: 0.0021599249448627234\n",
      "loss en el callback: 0.008642558939754963, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.90497762]\n",
      "  [0.90372854]\n",
      "  [0.90130371]\n",
      "  [0.89887393]\n",
      "  [0.89727765]\n",
      "  [0.89549285]\n",
      "  [0.89408809]\n",
      "  [0.89379156]]]\n",
      "ejemplar: [0.90497762 0.90372854 0.90130371 0.89887393 0.89727765 0.89549285\n",
      " 0.89408809 0.89379156]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.8930287]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.90497762 0.90372854 0.90130371 0.89887393 0.89727765 0.89549285\n",
      "  0.89408809 0.89379156]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006314302794635296\n",
      "Predicción post entrenamiento : [[0.892885]]\n",
      "PERDIDAAAA despues: 0.006337152794003487\n",
      "loss en el callback: 0.0006766243022866547, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.90372854]\n",
      "  [0.90130371]\n",
      "  [0.89887393]\n",
      "  [0.89727765]\n",
      "  [0.89549285]\n",
      "  [0.89408809]\n",
      "  [0.89379156]\n",
      "  [0.89302868]]]\n",
      "ejemplar: [0.90372854 0.90130371 0.89887393 0.89727765 0.89549285 0.89408809\n",
      " 0.89379156 0.89302868]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.89128524]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.90372854 0.90130371 0.89887393 0.89727765 0.89549285 0.89408809\n",
      "  0.89379156 0.89302868]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011154570616781712\n",
      "Predicción post entrenamiento : [[0.89209706]]\n",
      "PERDIDAAAA despues: 0.01098374929279089\n",
      "loss en el callback: 0.03275484964251518, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.90130371]\n",
      "  [0.89887393]\n",
      "  [0.89727765]\n",
      "  [0.89549285]\n",
      "  [0.89408809]\n",
      "  [0.89379156]\n",
      "  [0.89302868]\n",
      "  [0.89128524]]]\n",
      "ejemplar: [0.90130371 0.89887393 0.89727765 0.89549285 0.89408809 0.89379156\n",
      " 0.89302868 0.89128524]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.8903762]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.90130371 0.89887393 0.89727765 0.89549285 0.89408809 0.89379156\n",
      "  0.89302868 0.89128524]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003697308711707592\n",
      "Predicción post entrenamiento : [[0.8906304]]\n",
      "PERDIDAAAA despues: 0.003666458185762167\n",
      "loss en el callback: 0.0022146953269839287, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.89887393]\n",
      "  [0.89727765]\n",
      "  [0.89549285]\n",
      "  [0.89408809]\n",
      "  [0.89379156]\n",
      "  [0.89302868]\n",
      "  [0.89128524]\n",
      "  [0.89037621]]]\n",
      "ejemplar: [0.89887393 0.89727765 0.89549285 0.89408809 0.89379156 0.89302868\n",
      " 0.89128524 0.89037621]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.889144]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.89887393 0.89727765 0.89549285 0.89408809 0.89379156 0.89302868\n",
      "  0.89128524 0.89037621]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.399409954203293e-05\n",
      "Predicción post entrenamiento : [[0.88868034]]\n",
      "PERDIDAAAA despues: 5.035987851442769e-05\n",
      "loss en el callback: 0.007854202762246132, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.89727765]\n",
      "  [0.89549285]\n",
      "  [0.89408809]\n",
      "  [0.89379156]\n",
      "  [0.89302868]\n",
      "  [0.89128524]\n",
      "  [0.89037621]\n",
      "  [0.889144  ]]]\n",
      "ejemplar: [0.89727765 0.89549285 0.89408809 0.89379156 0.89302868 0.89128524\n",
      " 0.89037621 0.889144  ]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.8874911]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.89727765 0.89549285 0.89408809 0.89379156 0.89302868 0.89128524\n",
      "  0.89037621 0.889144  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.660022412077524e-05\n",
      "Predicción post entrenamiento : [[0.88679266]]\n",
      "PERDIDAAAA despues: 2.8637103241635486e-05\n",
      "loss en el callback: 0.015428050421178341, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.89549285]\n",
      "  [0.89408809]\n",
      "  [0.89379156]\n",
      "  [0.89302868]\n",
      "  [0.89128524]\n",
      "  [0.89037621]\n",
      "  [0.889144  ]\n",
      "  [0.88749111]]]\n",
      "ejemplar: [0.89549285 0.89408809 0.89379156 0.89302868 0.89128524 0.89037621\n",
      " 0.889144   0.88749111]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8857115]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.89549285 0.89408809 0.89379156 0.89302868 0.89128524 0.89037621\n",
      "  0.889144   0.88749111]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000984386308118701\n",
      "Predicción post entrenamiento : [[0.8858667]]\n",
      "PERDIDAAAA despues: 0.000974670983850956\n",
      "loss en el callback: 0.000949450652115047, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.89408809]\n",
      "  [0.89379156]\n",
      "  [0.89302868]\n",
      "  [0.89128524]\n",
      "  [0.89037621]\n",
      "  [0.889144  ]\n",
      "  [0.88749111]\n",
      "  [0.88571149]]]\n",
      "ejemplar: [0.89408809 0.89379156 0.89302868 0.89128524 0.89037621 0.889144\n",
      " 0.88749111 0.88571149]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8849612]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.89408809 0.89379156 0.89302868 0.89128524 0.89037621 0.889144\n",
      "  0.88749111 0.88571149]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012136419536545873\n",
      "Predicción post entrenamiento : [[0.88580346]]\n",
      "PERDIDAAAA despues: 0.001155666308477521\n",
      "loss en el callback: 0.04282154515385628, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.89379156]\n",
      "  [0.89302868]\n",
      "  [0.89128524]\n",
      "  [0.89037621]\n",
      "  [0.889144  ]\n",
      "  [0.88749111]\n",
      "  [0.88571149]\n",
      "  [0.88496119]]]\n",
      "ejemplar: [0.89379156 0.89302868 0.89128524 0.89037621 0.889144   0.88749111\n",
      " 0.88571149 0.88496119]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8849787]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.89379156 0.89302868 0.89128524 0.89037621 0.889144   0.88749111\n",
      "  0.88571149 0.88496119]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005877382587641478\n",
      "Predicción post entrenamiento : [[0.8851039]]\n",
      "PERDIDAAAA despues: 0.005858206190168858\n",
      "loss en el callback: 0.0006416183314286172, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.89302868]\n",
      "  [0.89128524]\n",
      "  [0.89037621]\n",
      "  [0.889144  ]\n",
      "  [0.88749111]\n",
      "  [0.88571149]\n",
      "  [0.88496119]\n",
      "  [0.88497871]]]\n",
      "ejemplar: [0.89302868 0.89128524 0.89037621 0.889144   0.88749111 0.88571149\n",
      " 0.88496119 0.88497871]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8840443]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.89302868 0.89128524 0.89037621 0.889144   0.88749111 0.88571149\n",
      "  0.88496119 0.88497871]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007087124977260828\n",
      "Predicción post entrenamiento : [[0.88442683]]\n",
      "PERDIDAAAA despues: 0.007022862788289785\n",
      "loss en el callback: 0.006499332841485739, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.89128524]\n",
      "  [0.89037621]\n",
      "  [0.889144  ]\n",
      "  [0.88749111]\n",
      "  [0.88571149]\n",
      "  [0.88496119]\n",
      "  [0.88497871]\n",
      "  [0.88404429]]]\n",
      "ejemplar: [0.89128524 0.89037621 0.889144   0.88749111 0.88571149 0.88496119\n",
      " 0.88497871 0.88404429]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8832388]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.89128524 0.89037621 0.889144   0.88749111 0.88571149 0.88496119\n",
      "  0.88497871 0.88404429]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005554650444537401\n",
      "Predicción post entrenamiento : [[0.8837195]]\n",
      "PERDIDAAAA despues: 0.00548322731629014\n",
      "loss en el callback: 0.010832427069544792, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24437955]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03931233659386635\n",
      "Predicción post entrenamiento : [[0.21792589]]\n",
      "PERDIDAAAA despues: 0.029522020369768143\n",
      "loss en el callback: 0.02149546891450882, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24437955]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.24437955]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.20237312]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.24437955]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009633412584662437\n",
      "Predicción post entrenamiento : [[0.17942959]]\n",
      "PERDIDAAAA despues: 0.005656005814671516\n",
      "loss en el callback: 0.010107114911079407, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24437955]\n",
      "  [0.20237312]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.24437955 0.20237312]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1834122]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.24437955 0.20237312]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008531301864422858\n",
      "Predicción post entrenamiento : [[0.17906544]]\n",
      "PERDIDAAAA despues: 0.0006181008066050708\n",
      "loss en el callback: 0.0008825819822959602, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24437955]\n",
      "  [0.20237312]\n",
      "  [0.18341219]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24437955\n",
      " 0.20237312 0.18341219]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1904372]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24437955\n",
      "  0.20237312 0.18341219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012029531644657254\n",
      "Predicción post entrenamiento : [[0.18757181]]\n",
      "PERDIDAAAA despues: 0.00101239955984056\n",
      "loss en el callback: 0.0007422096678055823, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24437955]\n",
      "  [0.20237312]\n",
      "  [0.18341219]\n",
      "  [0.1904372 ]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.24437955 0.20237312\n",
      " 0.18341219 0.1904372 ]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.20019113]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.24437955 0.20237312\n",
      "  0.18341219 0.1904372 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005573873408138752\n",
      "Predicción post entrenamiento : [[0.19294482]]\n",
      "PERDIDAAAA despues: 0.004544388502836227\n",
      "loss en el callback: 0.006570869591087103, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24437955]\n",
      "  [0.20237312]\n",
      "  [0.18341219]\n",
      "  [0.1904372 ]\n",
      "  [0.20019113]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.24437955 0.20237312 0.18341219\n",
      " 0.1904372  0.20019113]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.20292863]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.24437955 0.20237312 0.18341219\n",
      "  0.1904372  0.20019113]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032774098217487335\n",
      "Predicción post entrenamiento : [[0.19887294]]\n",
      "PERDIDAAAA despues: 0.002829492324963212\n",
      "loss en el callback: 0.0028678695671260357, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24437955]\n",
      "  [0.20237312]\n",
      "  [0.18341219]\n",
      "  [0.1904372 ]\n",
      "  [0.20019113]\n",
      "  [0.20292863]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.24437955 0.20237312 0.18341219 0.1904372\n",
      " 0.20019113 0.20292863]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.21982634]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.24437955 0.20237312 0.18341219 0.1904372\n",
      "  0.20019113 0.20292863]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005383374635130167\n",
      "Predicción post entrenamiento : [[0.21489544]]\n",
      "PERDIDAAAA despues: 0.004684113897383213\n",
      "loss en el callback: 0.005438054446130991, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.24437955]\n",
      "  [0.20237312]\n",
      "  [0.18341219]\n",
      "  [0.1904372 ]\n",
      "  [0.20019113]\n",
      "  [0.20292863]\n",
      "  [0.21982634]]]\n",
      "ejemplar: [0.04223169 0.24437955 0.20237312 0.18341219 0.1904372  0.20019113\n",
      " 0.20292863 0.21982634]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.24032816]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.24437955 0.20237312 0.18341219 0.1904372  0.20019113\n",
      "  0.20292863 0.21982634]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019607297144830227\n",
      "Predicción post entrenamiento : [[0.23852503]]\n",
      "PERDIDAAAA despues: 0.0018042952287942171\n",
      "loss en el callback: 0.0010488368570804596, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.24437955]\n",
      "  [0.20237312]\n",
      "  [0.18341219]\n",
      "  [0.1904372 ]\n",
      "  [0.20019113]\n",
      "  [0.20292863]\n",
      "  [0.21982634]\n",
      "  [0.24032816]]]\n",
      "ejemplar: [0.24437955 0.20237312 0.18341219 0.1904372  0.20019113 0.20292863\n",
      " 0.21982634 0.24032816]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.26879632]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.24437955 0.20237312 0.18341219 0.1904372  0.20019113 0.20292863\n",
      "  0.21982634 0.24032816]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00146425049751997\n",
      "Predicción post entrenamiento : [[0.26516998]]\n",
      "PERDIDAAAA despues: 0.0011998728150501847\n",
      "loss en el callback: 0.003952343948185444, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.20237312]\n",
      "  [0.18341219]\n",
      "  [0.1904372 ]\n",
      "  [0.20019113]\n",
      "  [0.20292863]\n",
      "  [0.21982634]\n",
      "  [0.24032816]\n",
      "  [0.26879632]]]\n",
      "ejemplar: [0.20237312 0.18341219 0.1904372  0.20019113 0.20292863 0.21982634\n",
      " 0.24032816 0.26879632]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.25726983]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.20237312 0.18341219 0.1904372  0.20019113 0.20292863 0.21982634\n",
      "  0.24032816 0.26879632]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002383733168244362\n",
      "Predicción post entrenamiento : [[0.25587738]]\n",
      "PERDIDAAAA despues: 0.002249703276902437\n",
      "loss en el callback: 0.0009954075794667006, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.18341219]\n",
      "  [0.1904372 ]\n",
      "  [0.20019113]\n",
      "  [0.20292863]\n",
      "  [0.21982634]\n",
      "  [0.24032816]\n",
      "  [0.26879632]\n",
      "  [0.25726983]]]\n",
      "ejemplar: [0.18341219 0.1904372  0.20019113 0.20292863 0.21982634 0.24032816\n",
      " 0.26879632 0.25726983]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25676283]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.18341219 0.1904372  0.20019113 0.20292863 0.21982634 0.24032816\n",
      "  0.26879632 0.25726983]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002009681658819318\n",
      "Predicción post entrenamiento : [[0.25479764]]\n",
      "PERDIDAAAA despues: 0.0018373463535681367\n",
      "loss en el callback: 0.0021896767430007458, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.1904372 ]\n",
      "  [0.20019113]\n",
      "  [0.20292863]\n",
      "  [0.21982634]\n",
      "  [0.24032816]\n",
      "  [0.26879632]\n",
      "  [0.25726983]\n",
      "  [0.25676283]]]\n",
      "ejemplar: [0.1904372  0.20019113 0.20292863 0.21982634 0.24032816 0.26879632\n",
      " 0.25726983 0.25676283]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.26120874]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.1904372  0.20019113 0.20292863 0.21982634 0.24032816 0.26879632\n",
      "  0.25726983 0.25676283]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002907877555117011\n",
      "Predicción post entrenamiento : [[0.25915658]]\n",
      "PERDIDAAAA despues: 0.0026907646097242832\n",
      "loss en el callback: 0.002849521115422249, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.20019113]\n",
      "  [0.20292863]\n",
      "  [0.21982634]\n",
      "  [0.24032816]\n",
      "  [0.26879632]\n",
      "  [0.25726983]\n",
      "  [0.25676283]\n",
      "  [0.26120874]]]\n",
      "ejemplar: [0.20019113 0.20292863 0.21982634 0.24032816 0.26879632 0.25726983\n",
      " 0.25676283 0.26120874]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2663606]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.20019113 0.20292863 0.21982634 0.24032816 0.26879632 0.25726983\n",
      "  0.25676283 0.26120874]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005389341618865728\n",
      "Predicción post entrenamiento : [[0.26262996]]\n",
      "PERDIDAAAA despues: 0.004855508916079998\n",
      "loss en el callback: 0.008509584702551365, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.20292863]\n",
      "  [0.21982634]\n",
      "  [0.24032816]\n",
      "  [0.26879632]\n",
      "  [0.25726983]\n",
      "  [0.25676283]\n",
      "  [0.26120874]\n",
      "  [0.26636061]]]\n",
      "ejemplar: [0.20292863 0.21982634 0.24032816 0.26879632 0.25726983 0.25676283\n",
      " 0.26120874 0.26636061]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.27000707]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.20292863 0.21982634 0.24032816 0.26879632 0.25726983 0.25676283\n",
      "  0.26120874 0.26636061]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0053559173829853535\n",
      "Predicción post entrenamiento : [[0.26492822]]\n",
      "PERDIDAAAA despues: 0.0046383291482925415\n",
      "loss en el callback: 0.016566064208745956, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.21982634]\n",
      "  [0.24032816]\n",
      "  [0.26879632]\n",
      "  [0.25726983]\n",
      "  [0.25676283]\n",
      "  [0.26120874]\n",
      "  [0.26636061]\n",
      "  [0.27000707]]]\n",
      "ejemplar: [0.21982634 0.24032816 0.26879632 0.25726983 0.25676283 0.26120874\n",
      " 0.26636061 0.27000707]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27385175]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.21982634 0.24032816 0.26879632 0.25726983 0.25676283 0.26120874\n",
      "  0.26636061 0.27000707]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035514100454747677\n",
      "Predicción post entrenamiento : [[0.27190813]]\n",
      "PERDIDAAAA despues: 0.003323532873764634\n",
      "loss en el callback: 0.003754750359803438, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.24032816]\n",
      "  [0.26879632]\n",
      "  [0.25726983]\n",
      "  [0.25676283]\n",
      "  [0.26120874]\n",
      "  [0.26636061]\n",
      "  [0.27000707]\n",
      "  [0.27385175]]]\n",
      "ejemplar: [0.24032816 0.26879632 0.25726983 0.25676283 0.26120874 0.26636061\n",
      " 0.27000707 0.27385175]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27925164]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.24032816 0.26879632 0.25726983 0.25676283 0.26120874 0.26636061\n",
      "  0.27000707 0.27385175]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009589613415300846\n",
      "Predicción post entrenamiento : [[0.27637807]]\n",
      "PERDIDAAAA despues: 0.009035073220729828\n",
      "loss en el callback: 0.009025274775922298, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.26879632]\n",
      "  [0.25726983]\n",
      "  [0.25676283]\n",
      "  [0.26120874]\n",
      "  [0.26636061]\n",
      "  [0.27000707]\n",
      "  [0.27385175]\n",
      "  [0.27925164]]]\n",
      "ejemplar: [0.26879632 0.25726983 0.25676283 0.26120874 0.26636061 0.27000707\n",
      " 0.27385175 0.27925164]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28081608]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.26879632 0.25726983 0.25676283 0.26120874 0.26636061 0.27000707\n",
      "  0.27385175 0.27925164]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011170407757163048\n",
      "Predicción post entrenamiento : [[0.2765319]]\n",
      "PERDIDAAAA despues: 0.010283172130584717\n",
      "loss en el callback: 0.018509719520807266, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.25726983]\n",
      "  [0.25676283]\n",
      "  [0.26120874]\n",
      "  [0.26636061]\n",
      "  [0.27000707]\n",
      "  [0.27385175]\n",
      "  [0.27925164]\n",
      "  [0.28081608]]]\n",
      "ejemplar: [0.25726983 0.25676283 0.26120874 0.26636061 0.27000707 0.27385175\n",
      " 0.27925164 0.28081608]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2756756]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.25726983 0.25676283 0.26120874 0.26636061 0.27000707 0.27385175\n",
      "  0.27925164 0.28081608]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016299869865179062\n",
      "Predicción post entrenamiento : [[0.27207735]]\n",
      "PERDIDAAAA despues: 0.015394034795463085\n",
      "loss en el callback: 0.018476277589797974, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.25676283]\n",
      "  [0.26120874]\n",
      "  [0.26636061]\n",
      "  [0.27000707]\n",
      "  [0.27385175]\n",
      "  [0.27925164]\n",
      "  [0.28081608]\n",
      "  [0.27567559]]]\n",
      "ejemplar: [0.25676283 0.26120874 0.26636061 0.27000707 0.27385175 0.27925164\n",
      " 0.28081608 0.27567559]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.27400327]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.25676283 0.26120874 0.26636061 0.27000707 0.27385175 0.27925164\n",
      "  0.28081608 0.27567559]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013259547762572765\n",
      "Predicción post entrenamiento : [[0.27187806]]\n",
      "PERDIDAAAA despues: 0.012774629518389702\n",
      "loss en el callback: 0.007959411479532719, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.26120874]\n",
      "  [0.26636061]\n",
      "  [0.27000707]\n",
      "  [0.27385175]\n",
      "  [0.27925164]\n",
      "  [0.28081608]\n",
      "  [0.27567559]\n",
      "  [0.27400327]]]\n",
      "ejemplar: [0.26120874 0.26636061 0.27000707 0.27385175 0.27925164 0.28081608\n",
      " 0.27567559 0.27400327]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2745659]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.26120874 0.26636061 0.27000707 0.27385175 0.27925164 0.28081608\n",
      "  0.27567559 0.27400327]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006788496859371662\n",
      "Predicción post entrenamiento : [[0.27358964]]\n",
      "PERDIDAAAA despues: 0.0066285766661167145\n",
      "loss en el callback: 0.001974340295419097, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.26636061]\n",
      "  [0.27000707]\n",
      "  [0.27385175]\n",
      "  [0.27925164]\n",
      "  [0.28081608]\n",
      "  [0.27567559]\n",
      "  [0.27400327]\n",
      "  [0.27456591]]]\n",
      "ejemplar: [0.26636061 0.27000707 0.27385175 0.27925164 0.28081608 0.27567559\n",
      " 0.27400327 0.27456591]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.27596226]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.26636061 0.27000707 0.27385175 0.27925164 0.28081608 0.27567559\n",
      "  0.27400327 0.27456591]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008097809739410877\n",
      "Predicción post entrenamiento : [[0.27411553]]\n",
      "PERDIDAAAA despues: 0.007768853101879358\n",
      "loss en el callback: 0.00631106598302722, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.27000707]\n",
      "  [0.27385175]\n",
      "  [0.27925164]\n",
      "  [0.28081608]\n",
      "  [0.27567559]\n",
      "  [0.27400327]\n",
      "  [0.27456591]\n",
      "  [0.27596226]]]\n",
      "ejemplar: [0.27000707 0.27385175 0.27925164 0.28081608 0.27567559 0.27400327\n",
      " 0.27456591 0.27596226]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.27585497]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.27000707 0.27385175 0.27925164 0.28081608 0.27567559 0.27400327\n",
      "  0.27456591 0.27596226]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.928458217065781e-05\n",
      "Predicción post entrenamiento : [[0.27382946]]\n",
      "PERDIDAAAA despues: 4.7316156269516796e-05\n",
      "loss en el callback: 0.005954981315881014, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.27385175]\n",
      "  [0.27925164]\n",
      "  [0.28081608]\n",
      "  [0.27567559]\n",
      "  [0.27400327]\n",
      "  [0.27456591]\n",
      "  [0.27596226]\n",
      "  [0.27585497]]]\n",
      "ejemplar: [0.27385175 0.27925164 0.28081608 0.27567559 0.27400327 0.27456591\n",
      " 0.27596226 0.27585497]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.27508163]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.27385175 0.27925164 0.28081608 0.27567559 0.27400327 0.27456591\n",
      "  0.27596226 0.27585497]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030417615198530257\n",
      "Predicción post entrenamiento : [[0.27602366]]\n",
      "PERDIDAAAA despues: 0.0002722046338021755\n",
      "loss en el callback: 0.002715925918892026, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.27925164]\n",
      "  [0.28081608]\n",
      "  [0.27567559]\n",
      "  [0.27400327]\n",
      "  [0.27456591]\n",
      "  [0.27596226]\n",
      "  [0.27585497]\n",
      "  [0.27508163]]]\n",
      "ejemplar: [0.27925164 0.28081608 0.27567559 0.27400327 0.27456591 0.27596226\n",
      " 0.27585497 0.27508163]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27660182]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.27925164 0.28081608 0.27567559 0.27400327 0.27456591 0.27596226\n",
      "  0.27585497 0.27508163]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016895795706659555\n",
      "Predicción post entrenamiento : [[0.2772389]]\n",
      "PERDIDAAAA despues: 0.0016376114217564464\n",
      "loss en el callback: 0.0008726698579266667, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.28081608]\n",
      "  [0.27567559]\n",
      "  [0.27400327]\n",
      "  [0.27456591]\n",
      "  [0.27596226]\n",
      "  [0.27585497]\n",
      "  [0.27508163]\n",
      "  [0.27660182]]]\n",
      "ejemplar: [0.28081608 0.27567559 0.27400327 0.27456591 0.27596226 0.27585497\n",
      " 0.27508163 0.27660182]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27665648]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.28081608 0.27567559 0.27400327 0.27456591 0.27596226 0.27585497\n",
      "  0.27508163 0.27660182]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012969388626515865\n",
      "Predicción post entrenamiento : [[0.2765653]]\n",
      "PERDIDAAAA despues: 0.0013035134179517627\n",
      "loss en el callback: 1.7264355847146362e-05, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.27567559]\n",
      "  [0.27400327]\n",
      "  [0.27456591]\n",
      "  [0.27596226]\n",
      "  [0.27585497]\n",
      "  [0.27508163]\n",
      "  [0.27660182]\n",
      "  [0.27665648]]]\n",
      "ejemplar: [0.27567559 0.27400327 0.27456591 0.27596226 0.27585497 0.27508163\n",
      " 0.27660182 0.27665648]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27550942]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.27567559 0.27400327 0.27456591 0.27596226 0.27585497 0.27508163\n",
      "  0.27660182 0.27665648]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001829484390327707\n",
      "Predicción post entrenamiento : [[0.27624115]]\n",
      "PERDIDAAAA despues: 0.00016368918295484036\n",
      "loss en el callback: 0.0016113430028781295, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.27400327]\n",
      "  [0.27456591]\n",
      "  [0.27596226]\n",
      "  [0.27585497]\n",
      "  [0.27508163]\n",
      "  [0.27660182]\n",
      "  [0.27665648]\n",
      "  [0.27550942]]]\n",
      "ejemplar: [0.27400327 0.27456591 0.27596226 0.27585497 0.27508163 0.27660182\n",
      " 0.27665648 0.27550942]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.2761713]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.27400327 0.27456591 0.27596226 0.27585497 0.27508163 0.27660182\n",
      "  0.27665648 0.27550942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.441972487256862e-05\n",
      "Predicción post entrenamiento : [[0.27587518]]\n",
      "PERDIDAAAA despues: 4.845452349400148e-05\n",
      "loss en el callback: 0.00021721021039411426, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.27456591]\n",
      "  [0.27596226]\n",
      "  [0.27585497]\n",
      "  [0.27508163]\n",
      "  [0.27660182]\n",
      "  [0.27665648]\n",
      "  [0.27550942]\n",
      "  [0.2761713 ]]]\n",
      "ejemplar: [0.27456591 0.27596226 0.27585497 0.27508163 0.27660182 0.27665648\n",
      " 0.27550942 0.2761713 ]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27619356]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.27456591 0.27596226 0.27585497 0.27508163 0.27660182 0.27665648\n",
      "  0.27550942 0.2761713 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005430188030004501\n",
      "Predicción post entrenamiento : [[0.27689627]]\n",
      "PERDIDAAAA despues: 0.000510762445628643\n",
      "loss en el callback: 0.0019483511568978429, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.27596226]\n",
      "  [0.27585497]\n",
      "  [0.27508163]\n",
      "  [0.27660182]\n",
      "  [0.27665648]\n",
      "  [0.27550942]\n",
      "  [0.2761713 ]\n",
      "  [0.27619356]]]\n",
      "ejemplar: [0.27596226 0.27585497 0.27508163 0.27660182 0.27665648 0.27550942\n",
      " 0.2761713  0.27619356]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2771599]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.27596226 0.27585497 0.27508163 0.27660182 0.27665648 0.27550942\n",
      "  0.2761713  0.27619356]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.684366679910454e-06\n",
      "Predicción post entrenamiento : [[0.2753541]]\n",
      "PERDIDAAAA despues: 2.580442810540262e-07\n",
      "loss en el callback: 0.007452832069247961, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.27585497]\n",
      "  [0.27508163]\n",
      "  [0.27660182]\n",
      "  [0.27665648]\n",
      "  [0.27550942]\n",
      "  [0.2761713 ]\n",
      "  [0.27619356]\n",
      "  [0.2771599 ]]]\n",
      "ejemplar: [0.27585497 0.27508163 0.27660182 0.27665648 0.27550942 0.2761713\n",
      " 0.27619356 0.2771599 ]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27536204]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.27585497 0.27508163 0.27660182 0.27665648 0.27550942 0.2761713\n",
      "  0.27619356 0.2771599 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.386768068798119e-07\n",
      "Predicción post entrenamiento : [[0.2751711]]\n",
      "PERDIDAAAA despues: 2.2220224593638704e-07\n",
      "loss en el callback: 0.00013183838746044785, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.27508163]\n",
      "  [0.27660182]\n",
      "  [0.27665648]\n",
      "  [0.27550942]\n",
      "  [0.2761713 ]\n",
      "  [0.27619356]\n",
      "  [0.2771599 ]\n",
      "  [0.27536204]]]\n",
      "ejemplar: [0.27508163 0.27660182 0.27665648 0.27550942 0.2761713  0.27619356\n",
      " 0.2771599  0.27536204]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27521247]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.27508163 0.27660182 0.27665648 0.27550942 0.2761713  0.27619356\n",
      "  0.2771599  0.27536204]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.871802327168552e-08\n",
      "Predicción post entrenamiento : [[0.27549636]]\n",
      "PERDIDAAAA despues: 4.733102798581967e-10\n",
      "loss en el callback: 0.0003208130656275898, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27660182]\n",
      "  [0.27665648]\n",
      "  [0.27550942]\n",
      "  [0.2761713 ]\n",
      "  [0.27619356]\n",
      "  [0.2771599 ]\n",
      "  [0.27536204]\n",
      "  [0.27521247]]]\n",
      "ejemplar: [0.27660182 0.27665648 0.27550942 0.2761713  0.27619356 0.2771599\n",
      " 0.27536204 0.27521247]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27571848]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27660182 0.27665648 0.27550942 0.2761713  0.27619356 0.2771599\n",
      "  0.27536204 0.27521247]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034851878881454468\n",
      "Predicción post entrenamiento : [[0.27663046]]\n",
      "PERDIDAAAA despues: 0.003378341207280755\n",
      "loss en el callback: 0.0038276435807347298, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27665648]\n",
      "  [0.27550942]\n",
      "  [0.2761713 ]\n",
      "  [0.27619356]\n",
      "  [0.2771599 ]\n",
      "  [0.27536204]\n",
      "  [0.27521247]\n",
      "  [0.27571848]]]\n",
      "ejemplar: [0.27665648 0.27550942 0.2761713  0.27619356 0.2771599  0.27536204\n",
      " 0.27521247 0.27571848]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27654028]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27665648 0.27550942 0.2761713  0.27619356 0.2771599  0.27536204\n",
      "  0.27521247 0.27571848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006262475624680519\n",
      "Predicción post entrenamiento : [[0.27811176]]\n",
      "PERDIDAAAA despues: 0.006016225088387728\n",
      "loss en el callback: 0.014599884860217571, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27550942]\n",
      "  [0.2761713 ]\n",
      "  [0.27619356]\n",
      "  [0.2771599 ]\n",
      "  [0.27536204]\n",
      "  [0.27521247]\n",
      "  [0.27571848]\n",
      "  [0.27654028]]]\n",
      "ejemplar: [0.27550942 0.2761713  0.27619356 0.2771599  0.27536204 0.27521247\n",
      " 0.27571848 0.27654028]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2779863]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27550942 0.2761713  0.27619356 0.2771599  0.27536204 0.27521247\n",
      "  0.27571848 0.27654028]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034462667535990477\n",
      "Predicción post entrenamiento : [[0.27849042]]\n",
      "PERDIDAAAA despues: 0.0033873303327709436\n",
      "loss en el callback: 0.0010819868184626102, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.2761713 ]\n",
      "  [0.27619356]\n",
      "  [0.2771599 ]\n",
      "  [0.27536204]\n",
      "  [0.27521247]\n",
      "  [0.27571848]\n",
      "  [0.27654028]\n",
      "  [0.27798629]]]\n",
      "ejemplar: [0.2761713  0.27619356 0.2771599  0.27536204 0.27521247 0.27571848\n",
      " 0.27654028 0.27798629]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.27860656]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.2761713  0.27619356 0.2771599  0.27536204 0.27521247 0.27571848\n",
      "  0.27654028 0.27798629]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003023358527570963\n",
      "Predicción post entrenamiento : [[0.27933162]]\n",
      "PERDIDAAAA despues: 0.002944149309769273\n",
      "loss en el callback: 0.0026930870953947306, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27619356]\n",
      "  [0.2771599 ]\n",
      "  [0.27536204]\n",
      "  [0.27521247]\n",
      "  [0.27571848]\n",
      "  [0.27654028]\n",
      "  [0.27798629]\n",
      "  [0.27860656]]]\n",
      "ejemplar: [0.27619356 0.2771599  0.27536204 0.27521247 0.27571848 0.27654028\n",
      " 0.27798629 0.27860656]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.27933758]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27619356 0.2771599  0.27536204 0.27521247 0.27571848 0.27654028\n",
      "  0.27798629 0.27860656]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011108530685305595\n",
      "Predicción post entrenamiento : [[0.28076828]]\n",
      "PERDIDAAAA despues: 0.010808996856212616\n",
      "loss en el callback: 0.01009221002459526, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.2771599 ]\n",
      "  [0.27536204]\n",
      "  [0.27521247]\n",
      "  [0.27571848]\n",
      "  [0.27654028]\n",
      "  [0.27798629]\n",
      "  [0.27860656]\n",
      "  [0.27933758]]]\n",
      "ejemplar: [0.2771599  0.27536204 0.27521247 0.27571848 0.27654028 0.27798629\n",
      " 0.27860656 0.27933758]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.28080684]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.2771599  0.27536204 0.27521247 0.27571848 0.27654028 0.27798629\n",
      "  0.27860656 0.27933758]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08426807820796967\n",
      "Predicción post entrenamiento : [[0.28461587]]\n",
      "PERDIDAAAA despues: 0.08207114040851593\n",
      "loss en el callback: 0.06225394085049629, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27536204]\n",
      "  [0.27521247]\n",
      "  [0.27571848]\n",
      "  [0.27654028]\n",
      "  [0.27798629]\n",
      "  [0.27860656]\n",
      "  [0.27933758]\n",
      "  [0.28080684]]]\n",
      "ejemplar: [0.27536204 0.27521247 0.27571848 0.27654028 0.27798629 0.27860656\n",
      " 0.27933758 0.28080684]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28450468]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27536204 0.27521247 0.27571848 0.27654028 0.27798629 0.27860656\n",
      "  0.27933758 0.28080684]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09720417112112045\n",
      "Predicción post entrenamiento : [[0.28864473]]\n",
      "PERDIDAAAA despues: 0.09463977813720703\n",
      "loss en el callback: 0.10114432871341705, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27521247]\n",
      "  [0.27571848]\n",
      "  [0.27654028]\n",
      "  [0.27798629]\n",
      "  [0.27860656]\n",
      "  [0.27933758]\n",
      "  [0.28080684]\n",
      "  [0.28450468]]]\n",
      "ejemplar: [0.27521247 0.27571848 0.27654028 0.27798629 0.27860656 0.27933758\n",
      " 0.28080684 0.28450468]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28902146]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27521247 0.27571848 0.27654028 0.27798629 0.27860656 0.27933758\n",
      "  0.28080684 0.28450468]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08154565840959549\n",
      "Predicción post entrenamiento : [[0.29247552]]\n",
      "PERDIDAAAA despues: 0.07958489656448364\n",
      "loss en el callback: 0.06340759247541428, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27571848]\n",
      "  [0.27654028]\n",
      "  [0.27798629]\n",
      "  [0.27860656]\n",
      "  [0.27933758]\n",
      "  [0.28080684]\n",
      "  [0.28450468]\n",
      "  [0.28902146]]]\n",
      "ejemplar: [0.27571848 0.27654028 0.27798629 0.27860656 0.27933758 0.28080684\n",
      " 0.28450468 0.28902146]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29310074]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27571848 0.27654028 0.27798629 0.27860656 0.27933758 0.28080684\n",
      "  0.28450468 0.28902146]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09812767803668976\n",
      "Predicción post entrenamiento : [[0.2970631]]\n",
      "PERDIDAAAA despues: 0.09566092491149902\n",
      "loss en el callback: 0.07932810485363007, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27654028]\n",
      "  [0.27798629]\n",
      "  [0.27860656]\n",
      "  [0.27933758]\n",
      "  [0.28080684]\n",
      "  [0.28450468]\n",
      "  [0.28902146]\n",
      "  [0.29310074]]]\n",
      "ejemplar: [0.27654028 0.27798629 0.27860656 0.27933758 0.28080684 0.28450468\n",
      " 0.28902146 0.29310074]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29788664]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27654028 0.27798629 0.27860656 0.27933758 0.28080684 0.28450468\n",
      "  0.28902146 0.29310074]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08223731815814972\n",
      "Predicción post entrenamiento : [[0.3012409]]\n",
      "PERDIDAAAA despues: 0.08032476902008057\n",
      "loss en el callback: 0.06644875556230545, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27798629]\n",
      "  [0.27860656]\n",
      "  [0.27933758]\n",
      "  [0.28080684]\n",
      "  [0.28450468]\n",
      "  [0.28902146]\n",
      "  [0.29310074]\n",
      "  [0.29788664]]]\n",
      "ejemplar: [0.27798629 0.27860656 0.27933758 0.28080684 0.28450468 0.28902146\n",
      " 0.29310074 0.29788664]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.30228993]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27798629 0.27860656 0.27933758 0.28080684 0.28450468 0.28902146\n",
      "  0.29310074 0.29788664]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07101257145404816\n",
      "Predicción post entrenamiento : [[0.30520517]]\n",
      "PERDIDAAAA despues: 0.06946735829114914\n",
      "loss en el callback: 0.04788026586174965, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27860656]\n",
      "  [0.27933758]\n",
      "  [0.28080684]\n",
      "  [0.28450468]\n",
      "  [0.28902146]\n",
      "  [0.29310074]\n",
      "  [0.29788664]\n",
      "  [0.30228993]]]\n",
      "ejemplar: [0.27860656 0.27933758 0.28080684 0.28450468 0.28902146 0.29310074\n",
      " 0.29788664 0.30228993]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30644596]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27860656 0.27933758 0.28080684 0.28450468 0.28902146 0.29310074\n",
      "  0.29788664 0.30228993]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11311662197113037\n",
      "Predicción post entrenamiento : [[0.31038406]]\n",
      "PERDIDAAAA despues: 0.11048313975334167\n",
      "loss en el callback: 0.13451409339904785, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27933758]\n",
      "  [0.28080684]\n",
      "  [0.28450468]\n",
      "  [0.28902146]\n",
      "  [0.29310074]\n",
      "  [0.29788664]\n",
      "  [0.30228993]\n",
      "  [0.30644596]]]\n",
      "ejemplar: [0.27933758 0.28080684 0.28450468 0.28902146 0.29310074 0.29788664\n",
      " 0.30228993 0.30644596]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31210592]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27933758 0.28080684 0.28450468 0.28902146 0.29310074 0.29788664\n",
      "  0.30228993 0.30644596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1222572848200798\n",
      "Predicción post entrenamiento : [[0.3162213]]\n",
      "PERDIDAAAA despues: 0.11939631402492523\n",
      "loss en el callback: 0.12805840373039246, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28080684]\n",
      "  [0.28450468]\n",
      "  [0.28902146]\n",
      "  [0.29310074]\n",
      "  [0.29788664]\n",
      "  [0.30228993]\n",
      "  [0.30644596]\n",
      "  [0.31210592]]]\n",
      "ejemplar: [0.28080684 0.28450468 0.28902146 0.29310074 0.29788664 0.30228993\n",
      " 0.30644596 0.31210592]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3185418]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28080684 0.28450468 0.28902146 0.29310074 0.29788664 0.30228993\n",
      "  0.30644596 0.31210592]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12563705444335938\n",
      "Predicción post entrenamiento : [[0.32245934]]\n",
      "PERDIDAAAA despues: 0.12287522852420807\n",
      "loss en el callback: 0.1055842787027359, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28450468]\n",
      "  [0.28902146]\n",
      "  [0.29310074]\n",
      "  [0.29788664]\n",
      "  [0.30228993]\n",
      "  [0.30644596]\n",
      "  [0.31210592]\n",
      "  [0.3185418 ]]]\n",
      "ejemplar: [0.28450468 0.28902146 0.29310074 0.29788664 0.30228993 0.30644596\n",
      " 0.31210592 0.3185418 ]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3253614]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28450468 0.28902146 0.29310074 0.29788664 0.30228993 0.30644596\n",
      "  0.31210592 0.3185418 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14839129149913788\n",
      "Predicción post entrenamiento : [[0.32959694]]\n",
      "PERDIDAAAA despues: 0.14514604210853577\n",
      "loss en el callback: 0.13666966557502747, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28902146]\n",
      "  [0.29310074]\n",
      "  [0.29788664]\n",
      "  [0.30228993]\n",
      "  [0.30644596]\n",
      "  [0.31210592]\n",
      "  [0.3185418 ]\n",
      "  [0.3253614 ]]]\n",
      "ejemplar: [0.28902146 0.29310074 0.29788664 0.30228993 0.30644596 0.31210592\n",
      " 0.3185418  0.3253614 ]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33270773]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28902146 0.29310074 0.29788664 0.30228993 0.30644596 0.31210592\n",
      "  0.3185418  0.3253614 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1378510445356369\n",
      "Predicción post entrenamiento : [[0.3367592]]\n",
      "PERDIDAAAA despues: 0.13485896587371826\n",
      "loss en el callback: 0.12543076276779175, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29310074]\n",
      "  [0.29788664]\n",
      "  [0.30228993]\n",
      "  [0.30644596]\n",
      "  [0.31210592]\n",
      "  [0.3185418 ]\n",
      "  [0.3253614 ]\n",
      "  [0.33270773]]]\n",
      "ejemplar: [0.29310074 0.29788664 0.30228993 0.30644596 0.31210592 0.3185418\n",
      " 0.3253614  0.33270773]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.33996814]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29310074 0.29788664 0.30228993 0.30644596 0.31210592 0.3185418\n",
      "  0.3253614  0.33270773]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14997756481170654\n",
      "Predicción post entrenamiento : [[0.34424302]]\n",
      "PERDIDAAAA despues: 0.14668479561805725\n",
      "loss en el callback: 0.14006832242012024, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29788664]\n",
      "  [0.30228993]\n",
      "  [0.30644596]\n",
      "  [0.31210592]\n",
      "  [0.3185418 ]\n",
      "  [0.3253614 ]\n",
      "  [0.33270773]\n",
      "  [0.33996814]]]\n",
      "ejemplar: [0.29788664 0.30228993 0.30644596 0.31210592 0.3185418  0.3253614\n",
      " 0.33270773 0.33996814]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.34772024]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29788664 0.30228993 0.30644596 0.31210592 0.3185418  0.3253614\n",
      "  0.33270773 0.33996814]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1405259370803833\n",
      "Predicción post entrenamiento : [[0.35175952]]\n",
      "PERDIDAAAA despues: 0.13751384615898132\n",
      "loss en el callback: 0.16987478733062744, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30228993]\n",
      "  [0.30644596]\n",
      "  [0.31210592]\n",
      "  [0.3185418 ]\n",
      "  [0.3253614 ]\n",
      "  [0.33270773]\n",
      "  [0.33996814]\n",
      "  [0.34772024]]]\n",
      "ejemplar: [0.30228993 0.30644596 0.31210592 0.3185418  0.3253614  0.33270773\n",
      " 0.33996814 0.34772024]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.35544184]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30228993 0.30644596 0.31210592 0.3185418  0.3253614  0.33270773\n",
      "  0.33996814 0.34772024]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1733490377664566\n",
      "Predicción post entrenamiento : [[0.35958734]]\n",
      "PERDIDAAAA despues: 0.16991424560546875\n",
      "loss en el callback: 0.15646466612815857, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30644596]\n",
      "  [0.31210592]\n",
      "  [0.3185418 ]\n",
      "  [0.3253614 ]\n",
      "  [0.33270773]\n",
      "  [0.33996814]\n",
      "  [0.34772024]\n",
      "  [0.35544184]]]\n",
      "ejemplar: [0.30644596 0.31210592 0.3185418  0.3253614  0.33270773 0.33996814\n",
      " 0.34772024 0.35544184]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36365756]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30644596 0.31210592 0.3185418  0.3253614  0.33270773 0.33996814\n",
      "  0.34772024 0.35544184]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13022558391094208\n",
      "Predicción post entrenamiento : [[0.367471]]\n",
      "PERDIDAAAA despues: 0.12748783826828003\n",
      "loss en el callback: 0.14564025402069092, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31210592]\n",
      "  [0.3185418 ]\n",
      "  [0.3253614 ]\n",
      "  [0.33270773]\n",
      "  [0.33996814]\n",
      "  [0.34772024]\n",
      "  [0.35544184]\n",
      "  [0.36365756]]]\n",
      "ejemplar: [0.31210592 0.3185418  0.3253614  0.33270773 0.33996814 0.34772024\n",
      " 0.35544184 0.36365756]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37210554]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31210592 0.3185418  0.3253614  0.33270773 0.33996814 0.34772024\n",
      "  0.35544184 0.36365756]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08937239646911621\n",
      "Predicción post entrenamiento : [[0.3750024]]\n",
      "PERDIDAAAA despues: 0.08764873445034027\n",
      "loss en el callback: 0.07399562001228333, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.3185418 ]\n",
      "  [0.3253614 ]\n",
      "  [0.33270773]\n",
      "  [0.33996814]\n",
      "  [0.34772024]\n",
      "  [0.35544184]\n",
      "  [0.36365756]\n",
      "  [0.37210554]]]\n",
      "ejemplar: [0.3185418  0.3253614  0.33270773 0.33996814 0.34772024 0.35544184\n",
      " 0.36365756 0.37210554]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3799803]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.3185418  0.3253614  0.33270773 0.33996814 0.34772024 0.35544184\n",
      "  0.36365756 0.37210554]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08631229400634766\n",
      "Predicción post entrenamiento : [[0.3829572]]\n",
      "PERDIDAAAA despues: 0.08457199484109879\n",
      "loss en el callback: 0.08751389384269714, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.3253614 ]\n",
      "  [0.33270773]\n",
      "  [0.33996814]\n",
      "  [0.34772024]\n",
      "  [0.35544184]\n",
      "  [0.36365756]\n",
      "  [0.37210554]\n",
      "  [0.3799803 ]]]\n",
      "ejemplar: [0.3253614  0.33270773 0.33996814 0.34772024 0.35544184 0.36365756\n",
      " 0.37210554 0.3799803 ]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3881801]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.3253614  0.33270773 0.33996814 0.34772024 0.35544184 0.36365756\n",
      "  0.37210554 0.3799803 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10645321011543274\n",
      "Predicción post entrenamiento : [[0.3915043]]\n",
      "PERDIDAAAA despues: 0.10429508984088898\n",
      "loss en el callback: 0.12179992347955704, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33270773]\n",
      "  [0.33996814]\n",
      "  [0.34772024]\n",
      "  [0.35544184]\n",
      "  [0.36365756]\n",
      "  [0.37210554]\n",
      "  [0.3799803 ]\n",
      "  [0.38818011]]]\n",
      "ejemplar: [0.33270773 0.33996814 0.34772024 0.35544184 0.36365756 0.37210554\n",
      " 0.3799803  0.38818011]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39694324]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33270773 0.33996814 0.34772024 0.35544184 0.36365756 0.37210554\n",
      "  0.3799803  0.38818011]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12037742137908936\n",
      "Predicción post entrenamiento : [[0.40020767]]\n",
      "PERDIDAAAA despues: 0.11812286078929901\n",
      "loss en el callback: 0.12231581658124924, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.33996814]\n",
      "  [0.34772024]\n",
      "  [0.35544184]\n",
      "  [0.36365756]\n",
      "  [0.37210554]\n",
      "  [0.3799803 ]\n",
      "  [0.38818011]\n",
      "  [0.39694324]]]\n",
      "ejemplar: [0.33996814 0.34772024 0.35544184 0.36365756 0.37210554 0.3799803\n",
      " 0.38818011 0.39694324]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4057891]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.33996814 0.34772024 0.35544184 0.36365756 0.37210554 0.3799803\n",
      "  0.38818011 0.39694324]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10036161541938782\n",
      "Predicción post entrenamiento : [[0.4086246]]\n",
      "PERDIDAAAA despues: 0.09857309609651566\n",
      "loss en el callback: 0.07273466140031815, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.34772024]\n",
      "  [0.35544184]\n",
      "  [0.36365756]\n",
      "  [0.37210554]\n",
      "  [0.3799803 ]\n",
      "  [0.38818011]\n",
      "  [0.39694324]\n",
      "  [0.40578911]]]\n",
      "ejemplar: [0.34772024 0.35544184 0.36365756 0.37210554 0.3799803  0.38818011\n",
      " 0.39694324 0.40578911]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41440716]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.34772024 0.35544184 0.36365756 0.37210554 0.3799803  0.38818011\n",
      "  0.39694324 0.40578911]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08118749409914017\n",
      "Predicción post entrenamiento : [[0.41704446]]\n",
      "PERDIDAAAA despues: 0.07969153672456741\n",
      "loss en el callback: 0.0811423733830452, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.35544184]\n",
      "  [0.36365756]\n",
      "  [0.37210554]\n",
      "  [0.3799803 ]\n",
      "  [0.38818011]\n",
      "  [0.39694324]\n",
      "  [0.40578911]\n",
      "  [0.41440716]]]\n",
      "ejemplar: [0.35544184 0.36365756 0.37210554 0.3799803  0.38818011 0.39694324\n",
      " 0.40578911 0.41440716]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42295533]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.35544184 0.36365756 0.37210554 0.3799803  0.38818011 0.39694324\n",
      "  0.40578911 0.41440716]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0988195613026619\n",
      "Predicción post entrenamiento : [[0.426045]]\n",
      "PERDIDAAAA despues: 0.09688659757375717\n",
      "loss en el callback: 0.1293799877166748, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36365756]\n",
      "  [0.37210554]\n",
      "  [0.3799803 ]\n",
      "  [0.38818011]\n",
      "  [0.39694324]\n",
      "  [0.40578911]\n",
      "  [0.41440716]\n",
      "  [0.42295533]]]\n",
      "ejemplar: [0.36365756 0.37210554 0.3799803  0.38818011 0.39694324 0.40578911\n",
      " 0.41440716 0.42295533]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4321239]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36365756 0.37210554 0.3799803  0.38818011 0.39694324 0.40578911\n",
      "  0.41440716 0.42295533]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08369560539722443\n",
      "Predicción post entrenamiento : [[0.4349373]]\n",
      "PERDIDAAAA despues: 0.08207567781209946\n",
      "loss en el callback: 0.09286107867956161, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37210554]\n",
      "  [0.3799803 ]\n",
      "  [0.38818011]\n",
      "  [0.39694324]\n",
      "  [0.40578911]\n",
      "  [0.41440716]\n",
      "  [0.42295533]\n",
      "  [0.4321239 ]]]\n",
      "ejemplar: [0.37210554 0.3799803  0.38818011 0.39694324 0.40578911 0.41440716\n",
      " 0.42295533 0.4321239 ]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.44109854]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37210554 0.3799803  0.38818011 0.39694324 0.40578911 0.41440716\n",
      "  0.42295533 0.4321239 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07707017660140991\n",
      "Predicción post entrenamiento : [[0.44369397]]\n",
      "PERDIDAAAA despues: 0.07563585788011551\n",
      "loss en el callback: 0.063434898853302, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.3799803 ]\n",
      "  [0.38818011]\n",
      "  [0.39694324]\n",
      "  [0.40578911]\n",
      "  [0.41440716]\n",
      "  [0.42295533]\n",
      "  [0.4321239 ]\n",
      "  [0.44109854]]]\n",
      "ejemplar: [0.3799803  0.38818011 0.39694324 0.40578911 0.41440716 0.42295533\n",
      " 0.4321239  0.44109854]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.44990173]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.3799803  0.38818011 0.39694324 0.40578911 0.41440716 0.42295533\n",
      "  0.4321239  0.44109854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05029056966304779\n",
      "Predicción post entrenamiento : [[0.45205492]]\n",
      "PERDIDAAAA despues: 0.0493294782936573\n",
      "loss en el callback: 0.053396642208099365, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.38818011]\n",
      "  [0.39694324]\n",
      "  [0.40578911]\n",
      "  [0.41440716]\n",
      "  [0.42295533]\n",
      "  [0.4321239 ]\n",
      "  [0.44109854]\n",
      "  [0.44990173]]]\n",
      "ejemplar: [0.38818011 0.39694324 0.40578911 0.41440716 0.42295533 0.4321239\n",
      " 0.44109854 0.44990173]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.45846674]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.38818011 0.39694324 0.40578911 0.41440716 0.42295533 0.4321239\n",
      "  0.44109854 0.44990173]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057647865265607834\n",
      "Predicción post entrenamiento : [[0.46053657]]\n",
      "PERDIDAAAA despues: 0.056658219546079636\n",
      "loss en el callback: 0.045982323586940765, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.39694324]\n",
      "  [0.40578911]\n",
      "  [0.41440716]\n",
      "  [0.42295533]\n",
      "  [0.4321239 ]\n",
      "  [0.44109854]\n",
      "  [0.44990173]\n",
      "  [0.45846674]]]\n",
      "ejemplar: [0.39694324 0.40578911 0.41440716 0.42295533 0.4321239  0.44109854\n",
      " 0.44990173 0.45846674]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.46710938]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.39694324 0.40578911 0.41440716 0.42295533 0.4321239  0.44109854\n",
      "  0.44990173 0.45846674]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06447991728782654\n",
      "Predicción post entrenamiento : [[0.46951094]]\n",
      "PERDIDAAAA despues: 0.06326603144407272\n",
      "loss en el callback: 0.07216905802488327, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.40578911]\n",
      "  [0.41440716]\n",
      "  [0.42295533]\n",
      "  [0.4321239 ]\n",
      "  [0.44109854]\n",
      "  [0.44990173]\n",
      "  [0.45846674]\n",
      "  [0.46710938]]]\n",
      "ejemplar: [0.40578911 0.41440716 0.42295533 0.4321239  0.44109854 0.44990173\n",
      " 0.45846674 0.46710938]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.47612718]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.40578911 0.41440716 0.42295533 0.4321239  0.44109854 0.44990173\n",
      "  0.45846674 0.46710938]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.060742996633052826\n",
      "Predicción post entrenamiento : [[0.47836316]]\n",
      "PERDIDAAAA despues: 0.05964583531022072\n",
      "loss en el callback: 0.06913630664348602, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.41440716]\n",
      "  [0.42295533]\n",
      "  [0.4321239 ]\n",
      "  [0.44109854]\n",
      "  [0.44990173]\n",
      "  [0.45846674]\n",
      "  [0.46710938]\n",
      "  [0.47612718]]]\n",
      "ejemplar: [0.41440716 0.42295533 0.4321239  0.44109854 0.44990173 0.45846674\n",
      " 0.46710938 0.47612718]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.48500347]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.41440716 0.42295533 0.4321239  0.44109854 0.44990173 0.45846674\n",
      "  0.46710938 0.47612718]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07359965890645981\n",
      "Predicción post entrenamiento : [[0.487599]]\n",
      "PERDIDAAAA despues: 0.07219810783863068\n",
      "loss en el callback: 0.13538114726543427, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.42295533]\n",
      "  [0.4321239 ]\n",
      "  [0.44109854]\n",
      "  [0.44990173]\n",
      "  [0.45846674]\n",
      "  [0.46710938]\n",
      "  [0.47612718]\n",
      "  [0.48500347]]]\n",
      "ejemplar: [0.42295533 0.4321239  0.44109854 0.44990173 0.45846674 0.46710938\n",
      " 0.47612718 0.48500347]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49432087]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.42295533 0.4321239  0.44109854 0.44990173 0.45846674 0.46710938\n",
      "  0.47612718 0.48500347]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1110658049583435\n",
      "Predicción post entrenamiento : [[0.49732292]]\n",
      "PERDIDAAAA despues: 0.10907385498285294\n",
      "loss en el callback: 0.11431016772985458, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.4321239 ]\n",
      "  [0.44109854]\n",
      "  [0.44990173]\n",
      "  [0.45846674]\n",
      "  [0.46710938]\n",
      "  [0.47612718]\n",
      "  [0.48500347]\n",
      "  [0.49432087]]]\n",
      "ejemplar: [0.4321239  0.44109854 0.44990173 0.45846674 0.46710938 0.47612718\n",
      " 0.48500347 0.49432087]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.50415546]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.4321239  0.44109854 0.44990173 0.45846674 0.46710938 0.47612718\n",
      "  0.48500347 0.49432087]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11200182139873505\n",
      "Predicción post entrenamiento : [[0.5072376]]\n",
      "PERDIDAAAA despues: 0.10994832962751389\n",
      "loss en el callback: 0.11484275013208389, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.44109854]\n",
      "  [0.44990173]\n",
      "  [0.45846674]\n",
      "  [0.46710938]\n",
      "  [0.47612718]\n",
      "  [0.48500347]\n",
      "  [0.49432087]\n",
      "  [0.50415546]]]\n",
      "ejemplar: [0.44109854 0.44990173 0.45846674 0.46710938 0.47612718 0.48500347\n",
      " 0.49432087 0.50415546]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.51404095]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.44109854 0.44990173 0.45846674 0.46710938 0.47612718 0.48500347\n",
      "  0.49432087 0.50415546]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07852597534656525\n",
      "Predicción post entrenamiento : [[0.51599437]]\n",
      "PERDIDAAAA despues: 0.07743499428033829\n",
      "loss en el callback: 0.03926778584718704, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.44990173]\n",
      "  [0.45846674]\n",
      "  [0.46710938]\n",
      "  [0.47612718]\n",
      "  [0.48500347]\n",
      "  [0.49432087]\n",
      "  [0.50415546]\n",
      "  [0.51404095]]]\n",
      "ejemplar: [0.44990173 0.45846674 0.46710938 0.47612718 0.48500347 0.49432087\n",
      " 0.50415546 0.51404095]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5228189]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.44990173 0.45846674 0.46710938 0.47612718 0.48500347 0.49432087\n",
      "  0.50415546 0.51404095]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06811358034610748\n",
      "Predicción post entrenamiento : [[0.52499366]]\n",
      "PERDIDAAAA despues: 0.066983163356781\n",
      "loss en el callback: 0.05783862993121147, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.45846674]\n",
      "  [0.46710938]\n",
      "  [0.47612718]\n",
      "  [0.48500347]\n",
      "  [0.49432087]\n",
      "  [0.50415546]\n",
      "  [0.51404095]\n",
      "  [0.52281892]]]\n",
      "ejemplar: [0.45846674 0.46710938 0.47612718 0.48500347 0.49432087 0.50415546\n",
      " 0.51404095 0.52281892]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.53189945]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.45846674 0.46710938 0.47612718 0.48500347 0.49432087 0.50415546\n",
      "  0.51404095 0.52281892]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05570542439818382\n",
      "Predicción post entrenamiento : [[0.5342359]]\n",
      "PERDIDAAAA despues: 0.05460799112915993\n",
      "loss en el callback: 0.09966200590133667, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.46710938]\n",
      "  [0.47612718]\n",
      "  [0.48500347]\n",
      "  [0.49432087]\n",
      "  [0.50415546]\n",
      "  [0.51404095]\n",
      "  [0.52281892]\n",
      "  [0.53189945]]]\n",
      "ejemplar: [0.46710938 0.47612718 0.48500347 0.49432087 0.50415546 0.51404095\n",
      " 0.52281892 0.53189945]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.54130816]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.46710938 0.47612718 0.48500347 0.49432087 0.50415546 0.51404095\n",
      "  0.52281892 0.53189945]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059181008487939835\n",
      "Predicción post entrenamiento : [[0.543106]]\n",
      "PERDIDAAAA despues: 0.05830950662493706\n",
      "loss en el callback: 0.0383073054254055, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.47612718]\n",
      "  [0.48500347]\n",
      "  [0.49432087]\n",
      "  [0.50415546]\n",
      "  [0.51404095]\n",
      "  [0.52281892]\n",
      "  [0.53189945]\n",
      "  [0.54130816]]]\n",
      "ejemplar: [0.47612718 0.48500347 0.49432087 0.50415546 0.51404095 0.52281892\n",
      " 0.53189945 0.54130816]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.55035526]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.47612718 0.48500347 0.49432087 0.50415546 0.51404095 0.52281892\n",
      "  0.53189945 0.54130816]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10782942175865173\n",
      "Predicción post entrenamiento : [[0.55325556]]\n",
      "PERDIDAAAA despues: 0.10593307018280029\n",
      "loss en el callback: 0.11071790009737015, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.48500347]\n",
      "  [0.49432087]\n",
      "  [0.50415546]\n",
      "  [0.51404095]\n",
      "  [0.52281892]\n",
      "  [0.53189945]\n",
      "  [0.54130816]\n",
      "  [0.55035526]]]\n",
      "ejemplar: [0.48500347 0.49432087 0.50415546 0.51404095 0.52281892 0.53189945\n",
      " 0.54130816 0.55035526]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.56061345]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.48500347 0.49432087 0.50415546 0.51404095 0.52281892 0.53189945\n",
      "  0.54130816 0.55035526]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0992351770401001\n",
      "Predicción post entrenamiento : [[0.56308204]]\n",
      "PERDIDAAAA despues: 0.09768597781658173\n",
      "loss en el callback: 0.07832993566989899, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.49432087]\n",
      "  [0.50415546]\n",
      "  [0.51404095]\n",
      "  [0.52281892]\n",
      "  [0.53189945]\n",
      "  [0.54130816]\n",
      "  [0.55035526]\n",
      "  [0.56061345]]]\n",
      "ejemplar: [0.49432087 0.50415546 0.51404095 0.52281892 0.53189945 0.54130816\n",
      " 0.55035526 0.56061345]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.57059973]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.49432087 0.50415546 0.51404095 0.52281892 0.53189945 0.54130816\n",
      "  0.55035526 0.56061345]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07744869589805603\n",
      "Predicción post entrenamiento : [[0.57195216]]\n",
      "PERDIDAAAA despues: 0.07669777423143387\n",
      "loss en el callback: 0.01850731112062931, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.50415546]\n",
      "  [0.51404095]\n",
      "  [0.52281892]\n",
      "  [0.53189945]\n",
      "  [0.54130816]\n",
      "  [0.55035526]\n",
      "  [0.56061345]\n",
      "  [0.57059973]]]\n",
      "ejemplar: [0.50415546 0.51404095 0.52281892 0.53189945 0.54130816 0.55035526\n",
      " 0.56061345 0.57059973]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5795329]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.50415546 0.51404095 0.52281892 0.53189945 0.54130816 0.55035526\n",
      "  0.56061345 0.57059973]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05700374394655228\n",
      "Predicción post entrenamiento : [[0.581945]]\n",
      "PERDIDAAAA despues: 0.05585777387022972\n",
      "loss en el callback: 0.10360689461231232, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.51404095]\n",
      "  [0.52281892]\n",
      "  [0.53189945]\n",
      "  [0.54130816]\n",
      "  [0.55035526]\n",
      "  [0.56061345]\n",
      "  [0.57059973]\n",
      "  [0.57953292]]]\n",
      "ejemplar: [0.51404095 0.52281892 0.53189945 0.54130816 0.55035526 0.56061345\n",
      " 0.57059973 0.57953292]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5894606]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.51404095 0.52281892 0.53189945 0.54130816 0.55035526 0.56061345\n",
      "  0.57059973 0.57953292]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05633535608649254\n",
      "Predicción post entrenamiento : [[0.5914511]]\n",
      "PERDIDAAAA despues: 0.05539442598819733\n",
      "loss en el callback: 0.05971147492527962, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.52281892]\n",
      "  [0.53189945]\n",
      "  [0.54130816]\n",
      "  [0.55035526]\n",
      "  [0.56061345]\n",
      "  [0.57059973]\n",
      "  [0.57953292]\n",
      "  [0.58946061]]]\n",
      "ejemplar: [0.52281892 0.53189945 0.54130816 0.55035526 0.56061345 0.57059973\n",
      " 0.57953292 0.58946061]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5988767]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.52281892 0.53189945 0.54130816 0.55035526 0.56061345 0.57059973\n",
      "  0.57953292 0.58946061]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03477396070957184\n",
      "Predicción post entrenamiento : [[0.6010114]]\n",
      "PERDIDAAAA despues: 0.033982377499341965\n",
      "loss en el callback: 0.10350234061479568, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.53189945]\n",
      "  [0.54130816]\n",
      "  [0.55035526]\n",
      "  [0.56061345]\n",
      "  [0.57059973]\n",
      "  [0.57953292]\n",
      "  [0.58946061]\n",
      "  [0.59887671]]]\n",
      "ejemplar: [0.53189945 0.54130816 0.55035526 0.56061345 0.57059973 0.57953292\n",
      " 0.58946061 0.59887671]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.60863435]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.53189945 0.54130816 0.55035526 0.56061345 0.57059973 0.57953292\n",
      "  0.58946061 0.59887671]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032614417374134064\n",
      "Predicción post entrenamiento : [[0.6102937]]\n",
      "PERDIDAAAA despues: 0.03201783820986748\n",
      "loss en el callback: 0.03638804331421852, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.54130816]\n",
      "  [0.55035526]\n",
      "  [0.56061345]\n",
      "  [0.57059973]\n",
      "  [0.57953292]\n",
      "  [0.58946061]\n",
      "  [0.59887671]\n",
      "  [0.60863435]]]\n",
      "ejemplar: [0.54130816 0.55035526 0.56061345 0.57059973 0.57953292 0.58946061\n",
      " 0.59887671 0.60863435]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6180665]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.54130816 0.55035526 0.56061345 0.57059973 0.57953292 0.58946061\n",
      "  0.59887671 0.60863435]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046701930463314056\n",
      "Predicción post entrenamiento : [[0.6198518]]\n",
      "PERDIDAAAA despues: 0.045933473855257034\n",
      "loss en el callback: 0.04620315507054329, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.55035526]\n",
      "  [0.56061345]\n",
      "  [0.57059973]\n",
      "  [0.57953292]\n",
      "  [0.58946061]\n",
      "  [0.59887671]\n",
      "  [0.60863435]\n",
      "  [0.61806649]]]\n",
      "ejemplar: [0.55035526 0.56061345 0.57059973 0.57953292 0.58946061 0.59887671\n",
      " 0.60863435 0.61806649]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.62770855]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.55035526 0.56061345 0.57059973 0.57953292 0.58946061 0.59887671\n",
      "  0.60863435 0.61806649]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034138936549425125\n",
      "Predicción post entrenamiento : [[0.6288302]]\n",
      "PERDIDAAAA despues: 0.03372570872306824\n",
      "loss en el callback: 0.016655921936035156, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.56061345]\n",
      "  [0.57059973]\n",
      "  [0.57953292]\n",
      "  [0.58946061]\n",
      "  [0.59887671]\n",
      "  [0.60863435]\n",
      "  [0.61806649]\n",
      "  [0.62770855]]]\n",
      "ejemplar: [0.56061345 0.57059973 0.57953292 0.58946061 0.59887671 0.60863435\n",
      " 0.61806649 0.62770855]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6368736]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.56061345 0.57059973 0.57953292 0.58946061 0.59887671 0.60863435\n",
      "  0.61806649 0.62770855]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02701626345515251\n",
      "Predicción post entrenamiento : [[0.6377203]]\n",
      "PERDIDAAAA despues: 0.026738647371530533\n",
      "loss en el callback: 0.008608083240687847, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.57059973]\n",
      "  [0.57953292]\n",
      "  [0.58946061]\n",
      "  [0.59887671]\n",
      "  [0.60863435]\n",
      "  [0.61806649]\n",
      "  [0.62770855]\n",
      "  [0.6368736 ]]]\n",
      "ejemplar: [0.57059973 0.57953292 0.58946061 0.59887671 0.60863435 0.61806649\n",
      " 0.62770855 0.6368736 ]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6456361]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.57059973 0.57953292 0.58946061 0.59887671 0.60863435 0.61806649\n",
      "  0.62770855 0.6368736 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024819159880280495\n",
      "Predicción post entrenamiento : [[0.64710575]]\n",
      "PERDIDAAAA despues: 0.024358252063393593\n",
      "loss en el callback: 0.03465038537979126, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.57953292]\n",
      "  [0.58946061]\n",
      "  [0.59887671]\n",
      "  [0.60863435]\n",
      "  [0.61806649]\n",
      "  [0.62770855]\n",
      "  [0.6368736 ]\n",
      "  [0.64563608]]]\n",
      "ejemplar: [0.57953292 0.58946061 0.59887671 0.60863435 0.61806649 0.62770855\n",
      " 0.6368736  0.64563608]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6549346]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.57953292 0.58946061 0.59887671 0.60863435 0.61806649 0.62770855\n",
      "  0.6368736  0.64563608]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019197849556803703\n",
      "Predicción post entrenamiento : [[0.6567824]]\n",
      "PERDIDAAAA despues: 0.018689213320612907\n",
      "loss en el callback: 0.06945312768220901, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.58946061]\n",
      "  [0.59887671]\n",
      "  [0.60863435]\n",
      "  [0.61806649]\n",
      "  [0.62770855]\n",
      "  [0.6368736 ]\n",
      "  [0.64563608]\n",
      "  [0.65493459]]]\n",
      "ejemplar: [0.58946061 0.59887671 0.60863435 0.61806649 0.62770855 0.6368736\n",
      " 0.64563608 0.65493459]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.66478574]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.58946061 0.59887671 0.60863435 0.61806649 0.62770855 0.6368736\n",
      "  0.64563608 0.65493459]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009098243899643421\n",
      "Predicción post entrenamiento : [[0.6659333]]\n",
      "PERDIDAAAA despues: 0.008880640380084515\n",
      "loss en el callback: 0.02430403046309948, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.59887671]\n",
      "  [0.60863435]\n",
      "  [0.61806649]\n",
      "  [0.62770855]\n",
      "  [0.6368736 ]\n",
      "  [0.64563608]\n",
      "  [0.65493459]\n",
      "  [0.66478574]]]\n",
      "ejemplar: [0.59887671 0.60863435 0.61806649 0.62770855 0.6368736  0.64563608\n",
      " 0.65493459 0.66478574]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6738497]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.59887671 0.60863435 0.61806649 0.62770855 0.6368736  0.64563608\n",
      "  0.65493459 0.66478574]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037852288223803043\n",
      "Predicción post entrenamiento : [[0.6743786]]\n",
      "PERDIDAAAA despues: 0.003720431588590145\n",
      "loss en el callback: 0.004497538320720196, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.60863435]\n",
      "  [0.61806649]\n",
      "  [0.62770855]\n",
      "  [0.6368736 ]\n",
      "  [0.64563608]\n",
      "  [0.65493459]\n",
      "  [0.66478574]\n",
      "  [0.6738497 ]]]\n",
      "ejemplar: [0.60863435 0.61806649 0.62770855 0.6368736  0.64563608 0.65493459\n",
      " 0.66478574 0.6738497 ]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6823189]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.60863435 0.61806649 0.62770855 0.6368736  0.64563608 0.65493459\n",
      "  0.66478574 0.6738497 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007767867064103484\n",
      "Predicción post entrenamiento : [[0.682536]]\n",
      "PERDIDAAAA despues: 0.0007647334132343531\n",
      "loss en el callback: 0.0007248768815770745, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.61806649]\n",
      "  [0.62770855]\n",
      "  [0.6368736 ]\n",
      "  [0.64563608]\n",
      "  [0.65493459]\n",
      "  [0.66478574]\n",
      "  [0.6738497 ]\n",
      "  [0.68231893]]]\n",
      "ejemplar: [0.61806649 0.62770855 0.6368736  0.64563608 0.65493459 0.66478574\n",
      " 0.6738497  0.68231893]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6903928]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.61806649 0.62770855 0.6368736  0.64563608 0.65493459 0.66478574\n",
      "  0.6738497  0.68231893]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004723796737380326\n",
      "Predicción post entrenamiento : [[0.6903768]]\n",
      "PERDIDAAAA despues: 0.00047307429485954344\n",
      "loss en el callback: 3.4112949833797757e-06, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.62770855]\n",
      "  [0.6368736 ]\n",
      "  [0.64563608]\n",
      "  [0.65493459]\n",
      "  [0.66478574]\n",
      "  [0.6738497 ]\n",
      "  [0.68231893]\n",
      "  [0.69039279]]]\n",
      "ejemplar: [0.62770855 0.6368736  0.64563608 0.65493459 0.66478574 0.6738497\n",
      " 0.68231893 0.69039279]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.69820577]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.62770855 0.6368736  0.64563608 0.65493459 0.66478574 0.6738497\n",
      "  0.68231893 0.69039279]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017164495075121522\n",
      "Predicción post entrenamiento : [[0.69806284]]\n",
      "PERDIDAAAA despues: 0.0017283132765442133\n",
      "loss en el callback: 0.0002665833744686097, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.6368736 ]\n",
      "  [0.64563608]\n",
      "  [0.65493459]\n",
      "  [0.66478574]\n",
      "  [0.6738497 ]\n",
      "  [0.68231893]\n",
      "  [0.69039279]\n",
      "  [0.69820577]]]\n",
      "ejemplar: [0.6368736  0.64563608 0.65493459 0.66478574 0.6738497  0.68231893\n",
      " 0.69039279 0.69820577]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7057725]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.6368736  0.64563608 0.65493459 0.66478574 0.6738497  0.68231893\n",
      "  0.69039279 0.69820577]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009227169211953878\n",
      "Predicción post entrenamiento : [[0.7060311]]\n",
      "PERDIDAAAA despues: 0.00090707530034706\n",
      "loss en el callback: 0.001028881291858852, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.64563608]\n",
      "  [0.65493459]\n",
      "  [0.66478574]\n",
      "  [0.6738497 ]\n",
      "  [0.68231893]\n",
      "  [0.69039279]\n",
      "  [0.69820577]\n",
      "  [0.70577252]]]\n",
      "ejemplar: [0.64563608 0.65493459 0.66478574 0.6738497  0.68231893 0.69039279\n",
      " 0.69820577 0.70577252]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.71370316]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.64563608 0.65493459 0.66478574 0.6738497  0.68231893 0.69039279\n",
      "  0.69820577 0.70577252]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021282024681568146\n",
      "Predicción post entrenamiento : [[0.71390337]]\n",
      "PERDIDAAAA despues: 0.0021467150654643774\n",
      "loss en el callback: 0.0007893964066170156, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.65493459]\n",
      "  [0.66478574]\n",
      "  [0.6738497 ]\n",
      "  [0.68231893]\n",
      "  [0.69039279]\n",
      "  [0.69820577]\n",
      "  [0.70577252]\n",
      "  [0.71370316]]]\n",
      "ejemplar: [0.65493459 0.66478574 0.6738497  0.68231893 0.69039279 0.69820577\n",
      " 0.70577252 0.71370316]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.721605]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.65493459 0.66478574 0.6738497  0.68231893 0.69039279 0.69820577\n",
      "  0.70577252 0.71370316]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026738818269222975\n",
      "Predicción post entrenamiento : [[0.72036123]]\n",
      "PERDIDAAAA despues: 0.002546799136325717\n",
      "loss en el callback: 0.02105778083205223, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.66478574]\n",
      "  [0.6738497 ]\n",
      "  [0.68231893]\n",
      "  [0.69039279]\n",
      "  [0.69820577]\n",
      "  [0.70577252]\n",
      "  [0.71370316]\n",
      "  [0.721605  ]]]\n",
      "ejemplar: [0.66478574 0.6738497  0.68231893 0.69039279 0.69820577 0.70577252\n",
      " 0.71370316 0.721605  ]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.727896]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.66478574 0.6738497  0.68231893 0.69039279 0.69820577 0.70577252\n",
      "  0.71370316 0.721605  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009776095394045115\n",
      "Predicción post entrenamiento : [[0.72822493]]\n",
      "PERDIDAAAA despues: 0.0009982887422665954\n",
      "loss en el callback: 0.0023033227771520615, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.6738497 ]\n",
      "  [0.68231893]\n",
      "  [0.69039279]\n",
      "  [0.69820577]\n",
      "  [0.70577252]\n",
      "  [0.71370316]\n",
      "  [0.721605  ]\n",
      "  [0.72789598]]]\n",
      "ejemplar: [0.6738497  0.68231893 0.69039279 0.69820577 0.70577252 0.71370316\n",
      " 0.721605   0.72789598]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.73536706]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.6738497  0.68231893 0.69039279 0.69820577 0.70577252 0.71370316\n",
      "  0.721605   0.72789598]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006307493895292282\n",
      "Predicción post entrenamiento : [[0.7341706]]\n",
      "PERDIDAAAA despues: 0.006118882913142443\n",
      "loss en el callback: 0.020584596320986748, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.68231893]\n",
      "  [0.69039279]\n",
      "  [0.69820577]\n",
      "  [0.70577252]\n",
      "  [0.71370316]\n",
      "  [0.721605  ]\n",
      "  [0.72789598]\n",
      "  [0.73536706]]]\n",
      "ejemplar: [0.68231893 0.69039279 0.69820577 0.70577252 0.71370316 0.721605\n",
      " 0.72789598 0.73536706]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7410346]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.68231893 0.69039279 0.69820577 0.70577252 0.71370316 0.721605\n",
      "  0.72789598 0.73536706]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038723195903003216\n",
      "Predicción post entrenamiento : [[0.7404943]]\n",
      "PERDIDAAAA despues: 0.00380536587908864\n",
      "loss en el callback: 0.004782848060131073, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.69039279]\n",
      "  [0.69820577]\n",
      "  [0.70577252]\n",
      "  [0.71370316]\n",
      "  [0.721605  ]\n",
      "  [0.72789598]\n",
      "  [0.73536706]\n",
      "  [0.74103463]]]\n",
      "ejemplar: [0.69039279 0.69820577 0.70577252 0.71370316 0.721605   0.72789598\n",
      " 0.73536706 0.74103463]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7471678]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.69039279 0.69820577 0.70577252 0.71370316 0.721605   0.72789598\n",
      "  0.73536706 0.74103463]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005051413085311651\n",
      "Predicción post entrenamiento : [[0.74709255]]\n",
      "PERDIDAAAA despues: 0.005040717776864767\n",
      "loss en el callback: 0.00010807689250214025, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.69820577]\n",
      "  [0.70577252]\n",
      "  [0.71370316]\n",
      "  [0.721605  ]\n",
      "  [0.72789598]\n",
      "  [0.73536706]\n",
      "  [0.74103463]\n",
      "  [0.74716783]]]\n",
      "ejemplar: [0.69820577 0.70577252 0.71370316 0.721605   0.72789598 0.73536706\n",
      " 0.74103463 0.74716783]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7536175]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.69820577 0.70577252 0.71370316 0.721605   0.72789598 0.73536706\n",
      "  0.74103463 0.74716783]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005786604015156627\n",
      "Predicción post entrenamiento : [[0.75381154]]\n",
      "PERDIDAAAA despues: 0.0005880321841686964\n",
      "loss en el callback: 0.0007432703860104084, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.70577252]\n",
      "  [0.71370316]\n",
      "  [0.721605  ]\n",
      "  [0.72789598]\n",
      "  [0.73536706]\n",
      "  [0.74103463]\n",
      "  [0.74716783]\n",
      "  [0.75361753]]]\n",
      "ejemplar: [0.70577252 0.71370316 0.721605   0.72789598 0.73536706 0.74103463\n",
      " 0.74716783 0.75361753]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.76019734]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.70577252 0.71370316 0.721605   0.72789598 0.73536706 0.74103463\n",
      "  0.74716783 0.75361753]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034714220091700554\n",
      "Predicción post entrenamiento : [[0.7590881]]\n",
      "PERDIDAAAA despues: 0.003341941861435771\n",
      "loss en el callback: 0.017979362979531288, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.71370316]\n",
      "  [0.721605  ]\n",
      "  [0.72789598]\n",
      "  [0.73536706]\n",
      "  [0.74103463]\n",
      "  [0.74716783]\n",
      "  [0.75361753]\n",
      "  [0.76019734]]]\n",
      "ejemplar: [0.71370316 0.721605   0.72789598 0.73536706 0.74103463 0.74716783\n",
      " 0.75361753 0.76019734]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.76533955]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.71370316 0.721605   0.72789598 0.73536706 0.74103463 0.74716783\n",
      "  0.75361753 0.76019734]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.806782726518577e-06\n",
      "Predicción post entrenamiento : [[0.7643367]]\n",
      "PERDIDAAAA despues: 1.0209851097897626e-05\n",
      "loss en el callback: 0.013838150538504124, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.721605  ]\n",
      "  [0.72789598]\n",
      "  [0.73536706]\n",
      "  [0.74103463]\n",
      "  [0.74716783]\n",
      "  [0.75361753]\n",
      "  [0.76019734]\n",
      "  [0.76533955]]]\n",
      "ejemplar: [0.721605   0.72789598 0.73536706 0.74103463 0.74716783 0.75361753\n",
      " 0.76019734 0.76533955]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.77028704]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.721605   0.72789598 0.73536706 0.74103463 0.74716783 0.75361753\n",
      "  0.76019734 0.76533955]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022962396906223148\n",
      "Predicción post entrenamiento : [[0.7695172]]\n",
      "PERDIDAAAA despues: 0.000206884928047657\n",
      "loss en el callback: 0.008855617605149746, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.72789598]\n",
      "  [0.73536706]\n",
      "  [0.74103463]\n",
      "  [0.74716783]\n",
      "  [0.75361753]\n",
      "  [0.76019734]\n",
      "  [0.76533955]\n",
      "  [0.77028704]]]\n",
      "ejemplar: [0.72789598 0.73536706 0.74103463 0.74716783 0.75361753 0.76019734\n",
      " 0.76533955 0.77028704]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7750874]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.72789598 0.73536706 0.74103463 0.74716783 0.75361753 0.76019734\n",
      "  0.76533955 0.77028704]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009016441181302071\n",
      "Predicción post entrenamiento : [[0.77450556]]\n",
      "PERDIDAAAA despues: 0.0008670391980558634\n",
      "loss en el callback: 0.005487111862748861, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.73536706]\n",
      "  [0.74103463]\n",
      "  [0.74716783]\n",
      "  [0.75361753]\n",
      "  [0.76019734]\n",
      "  [0.76533955]\n",
      "  [0.77028704]\n",
      "  [0.77508742]]]\n",
      "ejemplar: [0.73536706 0.74103463 0.74716783 0.75361753 0.76019734 0.76533955\n",
      " 0.77028704 0.77508742]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.78006023]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.73536706 0.74103463 0.74716783 0.75361753 0.76019734 0.76533955\n",
      "  0.77028704 0.77508742]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007854658178985119\n",
      "Predicción post entrenamiento : [[0.78049546]]\n",
      "PERDIDAAAA despues: 0.0008100511040538549\n",
      "loss en el callback: 0.004165292251855135, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.74103463]\n",
      "  [0.74716783]\n",
      "  [0.75361753]\n",
      "  [0.76019734]\n",
      "  [0.76533955]\n",
      "  [0.77028704]\n",
      "  [0.77508742]\n",
      "  [0.78006023]]]\n",
      "ejemplar: [0.74103463 0.74716783 0.75361753 0.76019734 0.76533955 0.77028704\n",
      " 0.77508742 0.78006023]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7856559]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.74103463 0.74716783 0.75361753 0.76019734 0.76533955 0.77028704\n",
      "  0.77508742 0.78006023]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005753757432103157\n",
      "Predicción post entrenamiento : [[0.784482]]\n",
      "PERDIDAAAA despues: 0.005577044561505318\n",
      "loss en el callback: 0.020963555201888084, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.74716783]\n",
      "  [0.75361753]\n",
      "  [0.76019734]\n",
      "  [0.76533955]\n",
      "  [0.77028704]\n",
      "  [0.77508742]\n",
      "  [0.78006023]\n",
      "  [0.78565592]]]\n",
      "ejemplar: [0.74716783 0.75361753 0.76019734 0.76533955 0.77028704 0.77508742\n",
      " 0.78006023 0.78565592]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7896677]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.74716783 0.75361753 0.76019734 0.76533955 0.77028704 0.77508742\n",
      "  0.78006023 0.78565592]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009848116897046566\n",
      "Predicción post entrenamiento : [[0.78752905]]\n",
      "PERDIDAAAA despues: 0.009428217075765133\n",
      "loss en el callback: 0.06095985695719719, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.75361753]\n",
      "  [0.76019734]\n",
      "  [0.76533955]\n",
      "  [0.77028704]\n",
      "  [0.77508742]\n",
      "  [0.78006023]\n",
      "  [0.78565592]\n",
      "  [0.78966773]]]\n",
      "ejemplar: [0.75361753 0.76019734 0.76533955 0.77028704 0.77508742 0.78006023\n",
      " 0.78565592 0.78966773]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.79257107]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.75361753 0.76019734 0.76533955 0.77028704 0.77508742 0.78006023\n",
      "  0.78565592 0.78966773]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014601798029616475\n",
      "Predicción post entrenamiento : [[0.79232305]]\n",
      "PERDIDAAAA despues: 0.001441286876797676\n",
      "loss en el callback: 0.001187685295008123, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.76019734]\n",
      "  [0.76533955]\n",
      "  [0.77028704]\n",
      "  [0.77508742]\n",
      "  [0.78006023]\n",
      "  [0.78565592]\n",
      "  [0.78966773]\n",
      "  [0.79257107]]]\n",
      "ejemplar: [0.76019734 0.76533955 0.77028704 0.77508742 0.78006023 0.78565592\n",
      " 0.78966773 0.79257107]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.79706407]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.76019734 0.76533955 0.77028704 0.77508742 0.78006023 0.78565592\n",
      "  0.78966773 0.79257107]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005604524631053209\n",
      "Predicción post entrenamiento : [[0.7975004]]\n",
      "PERDIDAAAA despues: 0.005670041777193546\n",
      "loss en el callback: 0.005486282054334879, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.76533955]\n",
      "  [0.77028704]\n",
      "  [0.77508742]\n",
      "  [0.78006023]\n",
      "  [0.78565592]\n",
      "  [0.78966773]\n",
      "  [0.79257107]\n",
      "  [0.79706407]]]\n",
      "ejemplar: [0.76533955 0.77028704 0.77508742 0.78006023 0.78565592 0.78966773\n",
      " 0.79257107 0.79706407]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8018137]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.76533955 0.77028704 0.77508742 0.78006023 0.78565592 0.78966773\n",
      "  0.79257107 0.79706407]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002180389128625393\n",
      "Predicción post entrenamiento : [[0.8021646]]\n",
      "PERDIDAAAA despues: 0.002147742547094822\n",
      "loss en el callback: 0.0022571233566850424, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.77028704]\n",
      "  [0.77508742]\n",
      "  [0.78006023]\n",
      "  [0.78565592]\n",
      "  [0.78966773]\n",
      "  [0.79257107]\n",
      "  [0.79706407]\n",
      "  [0.80181372]]]\n",
      "ejemplar: [0.77028704 0.77508742 0.78006023 0.78565592 0.78966773 0.79257107\n",
      " 0.79706407 0.80181372]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8063692]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.77028704 0.77508742 0.78006023 0.78565592 0.78966773 0.79257107\n",
      "  0.79706407 0.80181372]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009819580242037773\n",
      "Predicción post entrenamiento : [[0.80639696]]\n",
      "PERDIDAAAA despues: 0.009814076125621796\n",
      "loss en el callback: 1.1771095159929246e-05, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.77508742]\n",
      "  [0.78006023]\n",
      "  [0.78565592]\n",
      "  [0.78966773]\n",
      "  [0.79257107]\n",
      "  [0.79706407]\n",
      "  [0.80181372]\n",
      "  [0.80636919]]]\n",
      "ejemplar: [0.77508742 0.78006023 0.78565592 0.78966773 0.79257107 0.79706407\n",
      " 0.80181372 0.80636919]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.81051064]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.77508742 0.78006023 0.78565592 0.78966773 0.79257107 0.79706407\n",
      "  0.80181372 0.80636919]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005141690373420715\n",
      "Predicción post entrenamiento : [[0.8107435]]\n",
      "PERDIDAAAA despues: 0.005108347628265619\n",
      "loss en el callback: 0.0009228726266883314, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.78006023]\n",
      "  [0.78565592]\n",
      "  [0.78966773]\n",
      "  [0.79257107]\n",
      "  [0.79706407]\n",
      "  [0.80181372]\n",
      "  [0.80636919]\n",
      "  [0.81051064]]]\n",
      "ejemplar: [0.78006023 0.78565592 0.78966773 0.79257107 0.79706407 0.80181372\n",
      " 0.80636919 0.81051064]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8147777]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.78006023 0.78565592 0.78966773 0.79257107 0.79706407 0.80181372\n",
      "  0.80636919 0.81051064]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00865086168050766\n",
      "Predicción post entrenamiento : [[0.8160094]]\n",
      "PERDIDAAAA despues: 0.008423252031207085\n",
      "loss en el callback: 0.040005430579185486, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.78565592]\n",
      "  [0.78966773]\n",
      "  [0.79257107]\n",
      "  [0.79706407]\n",
      "  [0.80181372]\n",
      "  [0.80636919]\n",
      "  [0.81051064]\n",
      "  [0.81477767]]]\n",
      "ejemplar: [0.78565592 0.78966773 0.79257107 0.79706407 0.80181372 0.80636919\n",
      " 0.81051064 0.81477767]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.81988937]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.78565592 0.78966773 0.79257107 0.79706407 0.80181372 0.80636919\n",
      "  0.81051064 0.81477767]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004856462124735117\n",
      "Predicción post entrenamiento : [[0.8198988]]\n",
      "PERDIDAAAA despues: 0.0048551494255661964\n",
      "loss en el callback: 1.5009039771030075e-06, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.78966773]\n",
      "  [0.79257107]\n",
      "  [0.79706407]\n",
      "  [0.80181372]\n",
      "  [0.80636919]\n",
      "  [0.81051064]\n",
      "  [0.81477767]\n",
      "  [0.81988937]]]\n",
      "ejemplar: [0.78966773 0.79257107 0.79706407 0.80181372 0.80636919 0.81051064\n",
      " 0.81477767 0.81988937]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.82341856]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.78966773 0.79257107 0.79706407 0.80181372 0.80636919 0.81051064\n",
      "  0.81477767 0.81988937]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002645675092935562\n",
      "Predicción post entrenamiento : [[0.8247019]]\n",
      "PERDIDAAAA despues: 0.0025153011083602905\n",
      "loss en el callback: 0.04700152948498726, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.79257107]\n",
      "  [0.79706407]\n",
      "  [0.80181372]\n",
      "  [0.80636919]\n",
      "  [0.81051064]\n",
      "  [0.81477767]\n",
      "  [0.81988937]\n",
      "  [0.82341856]]]\n",
      "ejemplar: [0.79257107 0.79706407 0.80181372 0.80636919 0.81051064 0.81477767\n",
      " 0.81988937 0.82341856]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.82827777]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.79257107 0.79706407 0.80181372 0.80636919 0.81051064 0.81477767\n",
      "  0.81988937 0.82341856]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0072138141840696335\n",
      "Predicción post entrenamiento : [[0.8291534]]\n",
      "PERDIDAAAA despues: 0.0070658354088664055\n",
      "loss en el callback: 0.016176188364624977, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.79706407]\n",
      "  [0.80181372]\n",
      "  [0.80636919]\n",
      "  [0.81051064]\n",
      "  [0.81477767]\n",
      "  [0.81988937]\n",
      "  [0.82341856]\n",
      "  [0.82827777]]]\n",
      "ejemplar: [0.79706407 0.80181372 0.80636919 0.81051064 0.81477767 0.81988937\n",
      " 0.82341856 0.82827777]\n",
      "y: 1.0\n",
      "Predicción : [[0.8331275]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.79706407 0.80181372 0.80636919 0.81051064 0.81477767 0.81988937\n",
      "  0.82341856 0.82827777]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027846431359648705\n",
      "Predicción post entrenamiento : [[0.834427]]\n",
      "PERDIDAAAA despues: 0.027414418756961823\n",
      "loss en el callback: 0.03466234728693962, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.80181372]\n",
      "  [0.80636919]\n",
      "  [0.81051064]\n",
      "  [0.81477767]\n",
      "  [0.81988937]\n",
      "  [0.82341856]\n",
      "  [0.82827777]\n",
      "  [0.8331275 ]]]\n",
      "ejemplar: [0.80181372 0.80636919 0.81051064 0.81477767 0.81988937 0.82341856\n",
      " 0.82827777 0.8331275 ]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.83840144]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.80181372 0.80636919 0.81051064 0.81477767 0.81988937 0.82341856\n",
      "  0.82827777 0.8331275 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01746431365609169\n",
      "Predicción post entrenamiento : [[0.840118]]\n",
      "PERDIDAAAA despues: 0.017013566568493843\n",
      "loss en el callback: 0.0896705761551857, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.80636919]\n",
      "  [0.81051064]\n",
      "  [0.81477767]\n",
      "  [0.81988937]\n",
      "  [0.82341856]\n",
      "  [0.82827777]\n",
      "  [0.8331275 ]\n",
      "  [0.83840144]]]\n",
      "ejemplar: [0.80636919 0.81051064 0.81477767 0.81988937 0.82341856 0.82827777\n",
      " 0.8331275  0.83840144]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.84402275]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.80636919 0.81051064 0.81477767 0.81988937 0.82341856 0.82827777\n",
      "  0.8331275  0.83840144]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020052497275173664\n",
      "Predicción post entrenamiento : [[0.84379756]]\n",
      "PERDIDAAAA despues: 0.002025468274950981\n",
      "loss en el callback: 0.0009019018616527319, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.81051064]\n",
      "  [0.81477767]\n",
      "  [0.81988937]\n",
      "  [0.82341856]\n",
      "  [0.82827777]\n",
      "  [0.8331275 ]\n",
      "  [0.83840144]\n",
      "  [0.84402275]]]\n",
      "ejemplar: [0.81051064 0.81477767 0.81988937 0.82341856 0.82827777 0.8331275\n",
      " 0.83840144 0.84402275]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8476916]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.81051064 0.81477767 0.81988937 0.82341856 0.82827777 0.8331275\n",
      "  0.83840144 0.84402275]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009158315369859338\n",
      "Predicción post entrenamiento : [[0.8477796]]\n",
      "PERDIDAAAA despues: 0.0009105144417844713\n",
      "loss en el callback: 0.00015702701057307422, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.81477767]\n",
      "  [0.81988937]\n",
      "  [0.82341856]\n",
      "  [0.82827777]\n",
      "  [0.8331275 ]\n",
      "  [0.83840144]\n",
      "  [0.84402275]\n",
      "  [0.8476916 ]]]\n",
      "ejemplar: [0.81477767 0.81988937 0.82341856 0.82827777 0.8331275  0.83840144\n",
      " 0.84402275 0.8476916 ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8517974]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.81477767 0.81988937 0.82341856 0.82827777 0.8331275  0.83840144\n",
      "  0.84402275 0.8476916 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.419362529821228e-06\n",
      "Predicción post entrenamiento : [[0.8515999]]\n",
      "PERDIDAAAA despues: 7.312070010812022e-06\n",
      "loss en el callback: 0.0008130633505061269, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.81988937]\n",
      "  [0.82341856]\n",
      "  [0.82827777]\n",
      "  [0.8331275 ]\n",
      "  [0.83840144]\n",
      "  [0.84402275]\n",
      "  [0.8476916 ]\n",
      "  [0.8517974 ]]]\n",
      "ejemplar: [0.81988937 0.82341856 0.82827777 0.8331275  0.83840144 0.84402275\n",
      " 0.8476916  0.8517974 ]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.85572964]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.81988937 0.82341856 0.82827777 0.8331275  0.83840144 0.84402275\n",
      "  0.8476916  0.8517974 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00046469795051962137\n",
      "Predicción post entrenamiento : [[0.855361]]\n",
      "PERDIDAAAA despues: 0.00044893979793414474\n",
      "loss en el callback: 0.0028588450513780117, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.82341856]\n",
      "  [0.82827777]\n",
      "  [0.8331275 ]\n",
      "  [0.83840144]\n",
      "  [0.84402275]\n",
      "  [0.8476916 ]\n",
      "  [0.8517974 ]\n",
      "  [0.85572964]]]\n",
      "ejemplar: [0.82341856 0.82827777 0.8331275  0.83840144 0.84402275 0.8476916\n",
      " 0.8517974  0.85572964]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.85936797]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.82341856 0.82827777 0.8331275  0.83840144 0.84402275 0.8476916\n",
      "  0.8517974  0.85572964]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8259015632793307e-05\n",
      "Predicción post entrenamiento : [[0.8590354]]\n",
      "PERDIDAAAA despues: 1.5527250070590526e-05\n",
      "loss en el callback: 0.002160988748073578, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.82827777]\n",
      "  [0.8331275 ]\n",
      "  [0.83840144]\n",
      "  [0.84402275]\n",
      "  [0.8476916 ]\n",
      "  [0.8517974 ]\n",
      "  [0.85572964]\n",
      "  [0.85936797]]]\n",
      "ejemplar: [0.82827777 0.8331275  0.83840144 0.84402275 0.8476916  0.8517974\n",
      " 0.85572964 0.85936797]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8633517]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.82827777 0.8331275  0.83840144 0.84402275 0.8476916  0.8517974\n",
      "  0.85572964 0.85936797]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014138329424895346\n",
      "Predicción post entrenamiento : [[0.86333174]]\n",
      "PERDIDAAAA despues: 0.0001418585452483967\n",
      "loss en el callback: 9.03269938135054e-06, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.8331275 ]\n",
      "  [0.83840144]\n",
      "  [0.84402275]\n",
      "  [0.8476916 ]\n",
      "  [0.8517974 ]\n",
      "  [0.85572964]\n",
      "  [0.85936797]\n",
      "  [0.8633517 ]]]\n",
      "ejemplar: [0.8331275  0.83840144 0.84402275 0.8476916  0.8517974  0.85572964\n",
      " 0.85936797 0.8633517 ]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8675873]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.8331275  0.83840144 0.84402275 0.8476916  0.8517974  0.85572964\n",
      "  0.85936797 0.8633517 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011141115101054311\n",
      "Predicción post entrenamiento : [[0.8685937]]\n",
      "PERDIDAAAA despues: 0.00013366858183871955\n",
      "loss en el callback: 0.03515562415122986, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.83840144]\n",
      "  [0.84402275]\n",
      "  [0.8476916 ]\n",
      "  [0.8517974 ]\n",
      "  [0.85572964]\n",
      "  [0.85936797]\n",
      "  [0.8633517 ]\n",
      "  [0.86758733]]]\n",
      "ejemplar: [0.83840144 0.84402275 0.8476916  0.8517974  0.85572964 0.85936797\n",
      " 0.8633517  0.86758733]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.872751]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.83840144 0.84402275 0.8476916  0.8517974  0.85572964 0.85936797\n",
      "  0.8633517  0.86758733]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005149658536538482\n",
      "Predicción post entrenamiento : [[0.8726815]]\n",
      "PERDIDAAAA despues: 0.0005118164117448032\n",
      "loss en el callback: 0.00010812398977577686, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.84402275]\n",
      "  [0.8476916 ]\n",
      "  [0.8517974 ]\n",
      "  [0.85572964]\n",
      "  [0.85936797]\n",
      "  [0.8633517 ]\n",
      "  [0.86758733]\n",
      "  [0.872751  ]]]\n",
      "ejemplar: [0.84402275 0.8476916  0.8517974  0.85572964 0.85936797 0.8633517\n",
      " 0.86758733 0.872751  ]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8765765]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.84402275 0.8476916  0.8517974  0.85572964 0.85936797 0.8633517\n",
      "  0.86758733 0.872751  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011478459928184748\n",
      "Predicción post entrenamiento : [[0.8764338]]\n",
      "PERDIDAAAA despues: 0.0011381974909454584\n",
      "loss en el callback: 0.00048522092401981354, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.8476916 ]\n",
      "  [0.8517974 ]\n",
      "  [0.85572964]\n",
      "  [0.85936797]\n",
      "  [0.8633517 ]\n",
      "  [0.86758733]\n",
      "  [0.872751  ]\n",
      "  [0.87657648]]]\n",
      "ejemplar: [0.8476916  0.8517974  0.85572964 0.85936797 0.8633517  0.86758733\n",
      " 0.872751   0.87657648]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8799144]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.8476916  0.8517974  0.85572964 0.85936797 0.8633517  0.86758733\n",
      "  0.872751   0.87657648]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032464435789734125\n",
      "Predicción post entrenamiento : [[0.87782276]]\n",
      "PERDIDAAAA despues: 0.003012464614585042\n",
      "loss en el callback: 0.0709950253367424, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.8517974 ]\n",
      "  [0.85572964]\n",
      "  [0.85936797]\n",
      "  [0.8633517 ]\n",
      "  [0.86758733]\n",
      "  [0.872751  ]\n",
      "  [0.87657648]\n",
      "  [0.8799144 ]]]\n",
      "ejemplar: [0.8517974  0.85572964 0.85936797 0.8633517  0.86758733 0.872751\n",
      " 0.87657648 0.8799144 ]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.88140017]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.8517974  0.85572964 0.85936797 0.8633517  0.86758733 0.872751\n",
      "  0.87657648 0.8799144 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011426356621086597\n",
      "Predicción post entrenamiento : [[0.88080174]]\n",
      "PERDIDAAAA despues: 0.011298776604235172\n",
      "loss en el callback: 0.009085376746952534, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.85572964]\n",
      "  [0.85936797]\n",
      "  [0.8633517 ]\n",
      "  [0.86758733]\n",
      "  [0.872751  ]\n",
      "  [0.87657648]\n",
      "  [0.8799144 ]\n",
      "  [0.88140017]]]\n",
      "ejemplar: [0.85572964 0.85936797 0.8633517  0.86758733 0.872751   0.87657648\n",
      " 0.8799144  0.88140017]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8843524]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.85572964 0.85936797 0.8633517  0.86758733 0.872751   0.87657648\n",
      "  0.8799144  0.88140017]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010032073594629765\n",
      "Predicción post entrenamiento : [[0.8846607]]\n",
      "PERDIDAAAA despues: 0.010093934834003448\n",
      "loss en el callback: 0.0030970813240855932, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.85936797]\n",
      "  [0.8633517 ]\n",
      "  [0.86758733]\n",
      "  [0.872751  ]\n",
      "  [0.87657648]\n",
      "  [0.8799144 ]\n",
      "  [0.88140017]\n",
      "  [0.88435239]]]\n",
      "ejemplar: [0.85936797 0.8633517  0.86758733 0.872751   0.87657648 0.8799144\n",
      " 0.88140017 0.88435239]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8882079]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.85936797 0.8633517  0.86758733 0.872751   0.87657648 0.8799144\n",
      "  0.88140017 0.88435239]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008101766579784453\n",
      "Predicción post entrenamiento : [[0.8881585]]\n",
      "PERDIDAAAA despues: 0.0008073661592788994\n",
      "loss en el callback: 5.830137524753809e-05, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.8633517 ]\n",
      "  [0.86758733]\n",
      "  [0.872751  ]\n",
      "  [0.87657648]\n",
      "  [0.8799144 ]\n",
      "  [0.88140017]\n",
      "  [0.88435239]\n",
      "  [0.88820791]]]\n",
      "ejemplar: [0.8633517  0.86758733 0.872751   0.87657648 0.8799144  0.88140017\n",
      " 0.88435239 0.88820791]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.89175725]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.8633517  0.86758733 0.872751   0.87657648 0.8799144  0.88140017\n",
      "  0.88435239 0.88820791]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014015439664945006\n",
      "Predicción post entrenamiento : [[0.8917843]]\n",
      "PERDIDAAAA despues: 0.0014035708736628294\n",
      "loss en el callback: 1.8055829059449024e-05, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.86758733]\n",
      "  [0.872751  ]\n",
      "  [0.87657648]\n",
      "  [0.8799144 ]\n",
      "  [0.88140017]\n",
      "  [0.88435239]\n",
      "  [0.88820791]\n",
      "  [0.89175725]]]\n",
      "ejemplar: [0.86758733 0.872751   0.87657648 0.8799144  0.88140017 0.88435239\n",
      " 0.88820791 0.89175725]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8953069]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.86758733 0.872751   0.87657648 0.8799144  0.88140017 0.88435239\n",
      "  0.88820791 0.89175725]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034131265711039305\n",
      "Predicción post entrenamiento : [[0.8944822]]\n",
      "PERDIDAAAA despues: 0.003317446680739522\n",
      "loss en el callback: 0.014017143286764622, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.872751  ]\n",
      "  [0.87657648]\n",
      "  [0.8799144 ]\n",
      "  [0.88140017]\n",
      "  [0.88435239]\n",
      "  [0.88820791]\n",
      "  [0.89175725]\n",
      "  [0.89530689]]]\n",
      "ejemplar: [0.872751   0.87657648 0.8799144  0.88140017 0.88435239 0.88820791\n",
      " 0.89175725 0.89530689]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8978107]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.872751   0.87657648 0.8799144  0.88140017 0.88435239 0.88820791\n",
      "  0.89175725 0.89530689]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004610386211425066\n",
      "Predicción post entrenamiento : [[0.8983084]]\n",
      "PERDIDAAAA despues: 0.004678220953792334\n",
      "loss en el callback: 0.009256421588361263, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.87657648]\n",
      "  [0.8799144 ]\n",
      "  [0.88140017]\n",
      "  [0.88435239]\n",
      "  [0.88820791]\n",
      "  [0.89175725]\n",
      "  [0.89530689]\n",
      "  [0.8978107 ]]]\n",
      "ejemplar: [0.87657648 0.8799144  0.88140017 0.88435239 0.88820791 0.89175725\n",
      " 0.89530689 0.8978107 ]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9011179]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.87657648 0.8799144  0.88140017 0.88435239 0.88820791 0.89175725\n",
      "  0.89530689 0.8978107 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019223640265408903\n",
      "Predicción post entrenamiento : [[0.9001874]]\n",
      "PERDIDAAAA despues: 0.00016729836352169514\n",
      "loss en el callback: 0.016847673803567886, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.8799144 ]\n",
      "  [0.88140017]\n",
      "  [0.88435239]\n",
      "  [0.88820791]\n",
      "  [0.89175725]\n",
      "  [0.89530689]\n",
      "  [0.8978107 ]\n",
      "  [0.90111792]]]\n",
      "ejemplar: [0.8799144  0.88140017 0.88435239 0.88820791 0.89175725 0.89530689\n",
      " 0.8978107  0.90111792]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.90279007]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.8799144  0.88140017 0.88435239 0.88820791 0.89175725 0.89530689\n",
      "  0.8978107  0.90111792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018529373919591308\n",
      "Predicción post entrenamiento : [[0.9031781]]\n",
      "PERDIDAAAA despues: 0.0018864937592297792\n",
      "loss en el callback: 0.004722231067717075, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.88140017]\n",
      "  [0.88435239]\n",
      "  [0.88820791]\n",
      "  [0.89175725]\n",
      "  [0.89530689]\n",
      "  [0.8978107 ]\n",
      "  [0.90111792]\n",
      "  [0.90279007]]]\n",
      "ejemplar: [0.88140017 0.88435239 0.88820791 0.89175725 0.89530689 0.8978107\n",
      " 0.90111792 0.90279007]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9056897]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.88140017 0.88435239 0.88820791 0.89175725 0.89530689 0.8978107\n",
      "  0.90111792 0.90279007]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00436824094504118\n",
      "Predicción post entrenamiento : [[0.90611786]]\n",
      "PERDIDAAAA despues: 0.004425018094480038\n",
      "loss en el callback: 0.0058045340701937675, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.88435239]\n",
      "  [0.88820791]\n",
      "  [0.89175725]\n",
      "  [0.89530689]\n",
      "  [0.8978107 ]\n",
      "  [0.90111792]\n",
      "  [0.90279007]\n",
      "  [0.90568972]]]\n",
      "ejemplar: [0.88435239 0.88820791 0.89175725 0.89530689 0.8978107  0.90111792\n",
      " 0.90279007 0.90568972]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.90907335]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.88435239 0.88820791 0.89175725 0.89530689 0.8978107  0.90111792\n",
      "  0.90279007 0.90568972]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01569223217666149\n",
      "Predicción post entrenamiento : [[0.9092344]]\n",
      "PERDIDAAAA despues: 0.01573260687291622\n",
      "loss en el callback: 0.000861435488332063, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.88820791]\n",
      "  [0.89175725]\n",
      "  [0.89530689]\n",
      "  [0.8978107 ]\n",
      "  [0.90111792]\n",
      "  [0.90279007]\n",
      "  [0.90568972]\n",
      "  [0.90907335]]]\n",
      "ejemplar: [0.88820791 0.89175725 0.89530689 0.8978107  0.90111792 0.90279007\n",
      " 0.90568972 0.90907335]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9122516]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.88820791 0.89175725 0.89530689 0.8978107  0.90111792 0.90279007\n",
      "  0.90568972 0.90907335]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008829251863062382\n",
      "Predicción post entrenamiento : [[0.91129595]]\n",
      "PERDIDAAAA despues: 0.008650572970509529\n",
      "loss en el callback: 0.021027691662311554, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.89175725]\n",
      "  [0.89530689]\n",
      "  [0.8978107 ]\n",
      "  [0.90111792]\n",
      "  [0.90279007]\n",
      "  [0.90568972]\n",
      "  [0.90907335]\n",
      "  [0.91225159]]]\n",
      "ejemplar: [0.89175725 0.89530689 0.8978107  0.90111792 0.90279007 0.90568972\n",
      " 0.90907335 0.91225159]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9140957]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.89175725 0.89530689 0.8978107  0.90111792 0.90279007 0.90568972\n",
      "  0.90907335 0.91225159]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015111665241420269\n",
      "Predicción post entrenamiento : [[0.91083854]]\n",
      "PERDIDAAAA despues: 0.014321473427116871\n",
      "loss en el callback: 0.17263750731945038, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.89530689]\n",
      "  [0.8978107 ]\n",
      "  [0.90111792]\n",
      "  [0.90279007]\n",
      "  [0.90568972]\n",
      "  [0.90907335]\n",
      "  [0.91225159]\n",
      "  [0.9140957 ]]]\n",
      "ejemplar: [0.89530689 0.8978107  0.90111792 0.90279007 0.90568972 0.90907335\n",
      " 0.91225159 0.9140957 ]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9134587]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.89530689 0.8978107  0.90111792 0.90279007 0.90568972 0.90907335\n",
      "  0.91225159 0.9140957 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023378640413284302\n",
      "Predicción post entrenamiento : [[0.9124388]]\n",
      "PERDIDAAAA despues: 0.023067796602845192\n",
      "loss en el callback: 0.02573283575475216, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.8978107 ]\n",
      "  [0.90111792]\n",
      "  [0.90279007]\n",
      "  [0.90568972]\n",
      "  [0.90907335]\n",
      "  [0.91225159]\n",
      "  [0.9140957 ]\n",
      "  [0.9134587 ]]]\n",
      "ejemplar: [0.8978107  0.90111792 0.90279007 0.90568972 0.90907335 0.91225159\n",
      " 0.9140957  0.9134587 ]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9148253]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.8978107  0.90111792 0.90279007 0.90568972 0.90907335 0.91225159\n",
      "  0.9140957  0.9134587 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015195897780358791\n",
      "Predicción post entrenamiento : [[0.9130541]]\n",
      "PERDIDAAAA despues: 0.014762355014681816\n",
      "loss en el callback: 0.06530889123678207, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.90111792]\n",
      "  [0.90279007]\n",
      "  [0.90568972]\n",
      "  [0.90907335]\n",
      "  [0.91225159]\n",
      "  [0.9140957 ]\n",
      "  [0.9134587 ]\n",
      "  [0.91482532]]]\n",
      "ejemplar: [0.90111792 0.90279007 0.90568972 0.90907335 0.91225159 0.9140957\n",
      " 0.9134587  0.91482532]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9154445]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.90111792 0.90279007 0.90568972 0.90907335 0.91225159 0.9140957\n",
      "  0.9134587  0.91482532]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02153562381863594\n",
      "Predicción post entrenamiento : [[0.9146227]]\n",
      "PERDIDAAAA despues: 0.021295109763741493\n",
      "loss en el callback: 0.017568476498126984, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.90279007]\n",
      "  [0.90568972]\n",
      "  [0.90907335]\n",
      "  [0.91225159]\n",
      "  [0.9140957 ]\n",
      "  [0.9134587 ]\n",
      "  [0.91482532]\n",
      "  [0.91544449]]]\n",
      "ejemplar: [0.90279007 0.90568972 0.90907335 0.91225159 0.9140957  0.9134587\n",
      " 0.91482532 0.91544449]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9167321]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.90279007 0.90568972 0.90907335 0.91225159 0.9140957  0.9134587\n",
      "  0.91482532 0.91544449]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021915188059210777\n",
      "Predicción post entrenamiento : [[0.9163361]]\n",
      "PERDIDAAAA despues: 0.021798111498355865\n",
      "loss en el callback: 0.004948718938976526, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.90568972]\n",
      "  [0.90907335]\n",
      "  [0.91225159]\n",
      "  [0.9140957 ]\n",
      "  [0.9134587 ]\n",
      "  [0.91482532]\n",
      "  [0.91544449]\n",
      "  [0.91673207]]]\n",
      "ejemplar: [0.90568972 0.90907335 0.91225159 0.9140957  0.9134587  0.91482532\n",
      " 0.91544449 0.91673207]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.91855526]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.90568972 0.90907335 0.91225159 0.9140957  0.9134587  0.91482532\n",
      "  0.91544449 0.91673207]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014313756488263607\n",
      "Predicción post entrenamiento : [[0.9183426]]\n",
      "PERDIDAAAA despues: 0.014262913726270199\n",
      "loss en el callback: 0.0014673449331894517, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.90907335]\n",
      "  [0.91225159]\n",
      "  [0.9140957 ]\n",
      "  [0.9134587 ]\n",
      "  [0.91482532]\n",
      "  [0.91544449]\n",
      "  [0.91673207]\n",
      "  [0.91855526]]]\n",
      "ejemplar: [0.90907335 0.91225159 0.9140957  0.9134587  0.91482532 0.91544449\n",
      " 0.91673207 0.91855526]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9202706]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.90907335 0.91225159 0.9140957  0.9134587  0.91482532 0.91544449\n",
      "  0.91673207 0.91855526]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01696942001581192\n",
      "Predicción post entrenamiento : [[0.92013144]]\n",
      "PERDIDAAAA despues: 0.016933178529143333\n",
      "loss en el callback: 0.0006246144184842706, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.91225159]\n",
      "  [0.9140957 ]\n",
      "  [0.9134587 ]\n",
      "  [0.91482532]\n",
      "  [0.91544449]\n",
      "  [0.91673207]\n",
      "  [0.91855526]\n",
      "  [0.92027062]]]\n",
      "ejemplar: [0.91225159 0.9140957  0.9134587  0.91482532 0.91544449 0.91673207\n",
      " 0.91855526 0.92027062]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.92154]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.91225159 0.9140957  0.9134587  0.91482532 0.91544449 0.91673207\n",
      "  0.91855526 0.92027062]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026040134951472282\n",
      "Predicción post entrenamiento : [[0.92167425]]\n",
      "PERDIDAAAA despues: 0.02608347497880459\n",
      "loss en el callback: 0.0007408640813082457, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.9140957 ]\n",
      "  [0.9134587 ]\n",
      "  [0.91482532]\n",
      "  [0.91544449]\n",
      "  [0.91673207]\n",
      "  [0.91855526]\n",
      "  [0.92027062]\n",
      "  [0.92154002]]]\n",
      "ejemplar: [0.9140957  0.9134587  0.91482532 0.91544449 0.91673207 0.91855526\n",
      " 0.92027062 0.92154002]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.922531]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.9140957  0.9134587  0.91482532 0.91544449 0.91673207 0.91855526\n",
      "  0.92027062 0.92154002]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05623430386185646\n",
      "Predicción post entrenamiento : [[0.9211782]]\n",
      "PERDIDAAAA despues: 0.055594541132450104\n",
      "loss en el callback: 0.05420788750052452, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.9134587 ]\n",
      "  [0.91482532]\n",
      "  [0.91544449]\n",
      "  [0.91673207]\n",
      "  [0.91855526]\n",
      "  [0.92027062]\n",
      "  [0.92154002]\n",
      "  [0.92253101]]]\n",
      "ejemplar: [0.9134587  0.91482532 0.91544449 0.91673207 0.91855526 0.92027062\n",
      " 0.92154002 0.92253101]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9218057]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.9134587  0.91482532 0.91544449 0.91673207 0.91855526 0.92027062\n",
      "  0.92154002 0.92253101]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10024437308311462\n",
      "Predicción post entrenamiento : [[0.9203999]]\n",
      "PERDIDAAAA despues: 0.09935616701841354\n",
      "loss en el callback: 0.06520462036132812, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.91482532]\n",
      "  [0.91544449]\n",
      "  [0.91673207]\n",
      "  [0.91855526]\n",
      "  [0.92027062]\n",
      "  [0.92154002]\n",
      "  [0.92253101]\n",
      "  [0.92180568]]]\n",
      "ejemplar: [0.91482532 0.91544449 0.91673207 0.91855526 0.92027062 0.92154002\n",
      " 0.92253101 0.92180568]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9215093]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.91482532 0.91544449 0.91673207 0.91855526 0.92027062 0.92154002\n",
      "  0.92253101 0.92180568]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06586960703134537\n",
      "Predicción post entrenamiento : [[0.9190505]]\n",
      "PERDIDAAAA despues: 0.06461354345083237\n",
      "loss en el callback: 0.13780489563941956, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.91544449]\n",
      "  [0.91673207]\n",
      "  [0.91855526]\n",
      "  [0.92027062]\n",
      "  [0.92154002]\n",
      "  [0.92253101]\n",
      "  [0.92180568]\n",
      "  [0.92150933]]]\n",
      "ejemplar: [0.91544449 0.91673207 0.91855526 0.92027062 0.92154002 0.92253101\n",
      " 0.92180568 0.92150933]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.92010415]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.91544449 0.91673207 0.91855526 0.92027062 0.92154002 0.92253101\n",
      "  0.92180568 0.92150933]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04504537954926491\n",
      "Predicción post entrenamiento : [[0.91797036]]\n",
      "PERDIDAAAA despues: 0.04414418712258339\n",
      "loss en el callback: 0.11149026453495026, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.91673207]\n",
      "  [0.91855526]\n",
      "  [0.92027062]\n",
      "  [0.92154002]\n",
      "  [0.92253101]\n",
      "  [0.92180568]\n",
      "  [0.92150933]\n",
      "  [0.92010415]]]\n",
      "ejemplar: [0.91673207 0.91855526 0.92027062 0.92154002 0.92253101 0.92180568\n",
      " 0.92150933 0.92010415]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.91914]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.91673207 0.91855526 0.92027062 0.92154002 0.92253101 0.92180568\n",
      "  0.92150933 0.92010415]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06465902924537659\n",
      "Predicción post entrenamiento : [[0.91820586]]\n",
      "PERDIDAAAA despues: 0.06418484449386597\n",
      "loss en el callback: 0.02986791729927063, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.91855526]\n",
      "  [0.92027062]\n",
      "  [0.92154002]\n",
      "  [0.92253101]\n",
      "  [0.92180568]\n",
      "  [0.92150933]\n",
      "  [0.92010415]\n",
      "  [0.91913998]]]\n",
      "ejemplar: [0.91855526 0.92027062 0.92154002 0.92253101 0.92180568 0.92150933\n",
      " 0.92010415 0.91913998]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.91924983]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.91855526 0.92027062 0.92154002 0.92253101 0.92180568 0.92150933\n",
      "  0.92010415 0.91913998]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04322144016623497\n",
      "Predicción post entrenamiento : [[0.91804993]]\n",
      "PERDIDAAAA despues: 0.042723964899778366\n",
      "loss en el callback: 0.0426047146320343, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.92027062]\n",
      "  [0.92154002]\n",
      "  [0.92253101]\n",
      "  [0.92180568]\n",
      "  [0.92150933]\n",
      "  [0.92010415]\n",
      "  [0.91913998]\n",
      "  [0.91924983]]]\n",
      "ejemplar: [0.92027062 0.92154002 0.92253101 0.92180568 0.92150933 0.92010415\n",
      " 0.91913998 0.91924983]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.91872466]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.92027062 0.92154002 0.92253101 0.92180568 0.92150933 0.92010415\n",
      "  0.91913998 0.91924983]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05830668658018112\n",
      "Predicción post entrenamiento : [[0.9176419]]\n",
      "PERDIDAAAA despues: 0.05778494477272034\n",
      "loss en el callback: 0.038895294070243835, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.92154002]\n",
      "  [0.92253101]\n",
      "  [0.92180568]\n",
      "  [0.92150933]\n",
      "  [0.92010415]\n",
      "  [0.91913998]\n",
      "  [0.91924983]\n",
      "  [0.91872466]]]\n",
      "ejemplar: [0.92154002 0.92253101 0.92180568 0.92150933 0.92010415 0.91913998\n",
      " 0.91924983 0.91872466]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9178673]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.92154002 0.92253101 0.92180568 0.92150933 0.92010415 0.91913998\n",
      "  0.91924983 0.91872466]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024261044338345528\n",
      "Predicción post entrenamiento : [[0.91702557]]\n",
      "PERDIDAAAA despues: 0.023999536409974098\n",
      "loss en el callback: 0.022483544424176216, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.92253101]\n",
      "  [0.92180568]\n",
      "  [0.92150933]\n",
      "  [0.92010415]\n",
      "  [0.91913998]\n",
      "  [0.91924983]\n",
      "  [0.91872466]\n",
      "  [0.9178673 ]]]\n",
      "ejemplar: [0.92253101 0.92180568 0.92150933 0.92010415 0.91913998 0.91924983\n",
      " 0.91872466 0.9178673 ]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.91682655]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.92253101 0.92180568 0.92150933 0.92010415 0.91913998 0.91924983\n",
      "  0.91872466 0.9178673 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012050552293658257\n",
      "Predicción post entrenamiento : [[0.9154923]]\n",
      "PERDIDAAAA despues: 0.011759397573769093\n",
      "loss en el callback: 0.044854786247015, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.92180568]\n",
      "  [0.92150933]\n",
      "  [0.92010415]\n",
      "  [0.91913998]\n",
      "  [0.91924983]\n",
      "  [0.91872466]\n",
      "  [0.9178673 ]\n",
      "  [0.91682655]]]\n",
      "ejemplar: [0.92180568 0.92150933 0.92010415 0.91913998 0.91924983 0.91872466\n",
      " 0.9178673  0.91682655]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.91486514]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.92180568 0.92150933 0.92010415 0.91913998 0.91924983 0.91872466\n",
      "  0.9178673  0.91682655]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009935544803738594\n",
      "Predicción post entrenamiento : [[0.9139679]]\n",
      "PERDIDAAAA despues: 0.009757483378052711\n",
      "loss en el callback: 0.022737419232726097, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.92150933]\n",
      "  [0.92010415]\n",
      "  [0.91913998]\n",
      "  [0.91924983]\n",
      "  [0.91872466]\n",
      "  [0.9178673 ]\n",
      "  [0.91682655]\n",
      "  [0.91486514]]]\n",
      "ejemplar: [0.92150933 0.92010415 0.91913998 0.91924983 0.91872466 0.9178673\n",
      " 0.91682655 0.91486514]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.91334325]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.92150933 0.92010415 0.91913998 0.91924983 0.91872466 0.9178673\n",
      "  0.91682655 0.91486514]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.048600723966956e-05\n",
      "Predicción post entrenamiento : [[0.91326827]]\n",
      "PERDIDAAAA despues: 4.942607120028697e-05\n",
      "loss en el callback: 0.0001803937047952786, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.92010415]\n",
      "  [0.91913998]\n",
      "  [0.91924983]\n",
      "  [0.91872466]\n",
      "  [0.9178673 ]\n",
      "  [0.91682655]\n",
      "  [0.91486514]\n",
      "  [0.91334325]]]\n",
      "ejemplar: [0.92010415 0.91913998 0.91924983 0.91872466 0.9178673  0.91682655\n",
      " 0.91486514 0.91334325]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.91250443]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.92010415 0.91913998 0.91924983 0.91872466 0.9178673  0.91682655\n",
      "  0.91486514 0.91334325]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022279436234384775\n",
      "Predicción post entrenamiento : [[0.9129158]]\n",
      "PERDIDAAAA despues: 0.0021892765071243048\n",
      "loss en el callback: 0.006437971722334623, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.91913998]\n",
      "  [0.91924983]\n",
      "  [0.91872466]\n",
      "  [0.9178673 ]\n",
      "  [0.91682655]\n",
      "  [0.91486514]\n",
      "  [0.91334325]\n",
      "  [0.91250443]]]\n",
      "ejemplar: [0.91913998 0.91924983 0.91872466 0.9178673  0.91682655 0.91486514\n",
      " 0.91334325 0.91250443]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9123048]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.91913998 0.91924983 0.91872466 0.9178673  0.91682655 0.91486514\n",
      "  0.91334325 0.91250443]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002709208056330681\n",
      "Predicción post entrenamiento : [[0.91204596]]\n",
      "PERDIDAAAA despues: 0.0027362226974219084\n",
      "loss en el callback: 0.0018435997189953923, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.91924983]\n",
      "  [0.91872466]\n",
      "  [0.9178673 ]\n",
      "  [0.91682655]\n",
      "  [0.91486514]\n",
      "  [0.91334325]\n",
      "  [0.91250443]\n",
      "  [0.91230482]]]\n",
      "ejemplar: [0.91924983 0.91872466 0.9178673  0.91682655 0.91486514 0.91334325\n",
      " 0.91250443 0.91230482]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9114648]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.91924983 0.91872466 0.9178673  0.91682655 0.91486514 0.91334325\n",
      "  0.91250443 0.91230482]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005492884665727615\n",
      "Predicción post entrenamiento : [[0.91160905]]\n",
      "PERDIDAAAA despues: 0.0005560704739764333\n",
      "loss en el callback: 0.0007912664441391826, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.91872466]\n",
      "  [0.9178673 ]\n",
      "  [0.91682655]\n",
      "  [0.91486514]\n",
      "  [0.91334325]\n",
      "  [0.91250443]\n",
      "  [0.91230482]\n",
      "  [0.91146481]]]\n",
      "ejemplar: [0.91872466 0.9178673  0.91682655 0.91486514 0.91334325 0.91250443\n",
      " 0.91230482 0.91146481]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.91073275]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.91872466 0.9178673  0.91682655 0.91486514 0.91334325 0.91250443\n",
      "  0.91230482 0.91146481]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003260010271333158\n",
      "Predicción post entrenamiento : [[0.9105234]]\n",
      "PERDIDAAAA despues: 0.00031848569051362574\n",
      "loss en el callback: 0.0014706116635352373, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.9178673 ]\n",
      "  [0.91682655]\n",
      "  [0.91486514]\n",
      "  [0.91334325]\n",
      "  [0.91250443]\n",
      "  [0.91230482]\n",
      "  [0.91146481]\n",
      "  [0.91073275]]]\n",
      "ejemplar: [0.9178673  0.91682655 0.91486514 0.91334325 0.91250443 0.91230482\n",
      " 0.91146481 0.91073275]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.909495]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.9178673  0.91682655 0.91486514 0.91334325 0.91250443 0.91230482\n",
      "  0.91146481 0.91073275]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001173255848698318\n",
      "Predicción post entrenamiento : [[0.9094518]]\n",
      "PERDIDAAAA despues: 0.0011702973861247301\n",
      "loss en el callback: 7.067959813866764e-05, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.91682655]\n",
      "  [0.91486514]\n",
      "  [0.91334325]\n",
      "  [0.91250443]\n",
      "  [0.91230482]\n",
      "  [0.91146481]\n",
      "  [0.91073275]\n",
      "  [0.909495  ]]]\n",
      "ejemplar: [0.91682655 0.91486514 0.91334325 0.91250443 0.91230482 0.91146481\n",
      " 0.91073275 0.909495  ]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9083564]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.91682655 0.91486514 0.91334325 0.91250443 0.91230482 0.91146481\n",
      "  0.91073275 0.909495  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003308944869786501\n",
      "Predicción post entrenamiento : [[0.9079824]]\n",
      "PERDIDAAAA despues: 0.0032660551369190216\n",
      "loss en el callback: 0.0048555233515799046, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.91486514]\n",
      "  [0.91334325]\n",
      "  [0.91250443]\n",
      "  [0.91230482]\n",
      "  [0.91146481]\n",
      "  [0.91073275]\n",
      "  [0.909495  ]\n",
      "  [0.90835643]]]\n",
      "ejemplar: [0.91486514 0.91334325 0.91250443 0.91230482 0.91146481 0.91073275\n",
      " 0.909495   0.90835643]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9068778]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.91486514 0.91334325 0.91250443 0.91230482 0.91146481 0.91073275\n",
      "  0.909495   0.90835643]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003361915471032262\n",
      "Predicción post entrenamiento : [[0.9067887]]\n",
      "PERDIDAAAA despues: 0.0033515901304781437\n",
      "loss en el callback: 0.0003059803566429764, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.91334325]\n",
      "  [0.91250443]\n",
      "  [0.91230482]\n",
      "  [0.91146481]\n",
      "  [0.91073275]\n",
      "  [0.909495  ]\n",
      "  [0.90835643]\n",
      "  [0.90687782]]]\n",
      "ejemplar: [0.91334325 0.91250443 0.91230482 0.91146481 0.91073275 0.909495\n",
      " 0.90835643 0.90687782]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.90595305]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.91334325 0.91250443 0.91230482 0.91146481 0.91073275 0.909495\n",
      "  0.90835643 0.90687782]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031882524490356445\n",
      "Predicción post entrenamiento : [[0.9053593]]\n",
      "PERDIDAAAA despues: 0.003255653427913785\n",
      "loss en el callback: 0.010270664468407631, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.91250443]\n",
      "  [0.91230482]\n",
      "  [0.91146481]\n",
      "  [0.91073275]\n",
      "  [0.909495  ]\n",
      "  [0.90835643]\n",
      "  [0.90687782]\n",
      "  [0.90595305]]]\n",
      "ejemplar: [0.91250443 0.91230482 0.91146481 0.91073275 0.909495   0.90835643\n",
      " 0.90687782 0.90595305]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9047012]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.91250443 0.91230482 0.91146481 0.91073275 0.909495   0.90835643\n",
      "  0.90687782 0.90595305]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003986754454672337\n",
      "Predicción post entrenamiento : [[0.9052859]]\n",
      "PERDIDAAAA despues: 0.0039132568053901196\n",
      "loss en el callback: 0.013292756862938404, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.91230482]\n",
      "  [0.91146481]\n",
      "  [0.91073275]\n",
      "  [0.909495  ]\n",
      "  [0.90835643]\n",
      "  [0.90687782]\n",
      "  [0.90595305]\n",
      "  [0.90470117]]]\n",
      "ejemplar: [0.91230482 0.91146481 0.91073275 0.909495   0.90835643 0.90687782\n",
      " 0.90595305 0.90470117]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9046158]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.91230482 0.91146481 0.91073275 0.909495   0.90835643 0.90687782\n",
      "  0.90595305 0.90470117]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013035607989877462\n",
      "Predicción post entrenamiento : [[0.904245]]\n",
      "PERDIDAAAA despues: 0.001330473693087697\n",
      "loss en el callback: 0.004438731819391251, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.91146481]\n",
      "  [0.91073275]\n",
      "  [0.909495  ]\n",
      "  [0.90835643]\n",
      "  [0.90687782]\n",
      "  [0.90595305]\n",
      "  [0.90470117]\n",
      "  [0.90461582]]]\n",
      "ejemplar: [0.91146481 0.91073275 0.909495   0.90835643 0.90687782 0.90595305\n",
      " 0.90470117 0.90461582]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.90336365]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.91146481 0.91073275 0.909495   0.90835643 0.90687782 0.90595305\n",
      "  0.90470117 0.90461582]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004778627771884203\n",
      "Predicción post entrenamiento : [[0.9038508]]\n",
      "PERDIDAAAA despues: 0.004711514338850975\n",
      "loss en el callback: 0.010402346029877663, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.91073275]\n",
      "  [0.909495  ]\n",
      "  [0.90835643]\n",
      "  [0.90687782]\n",
      "  [0.90595305]\n",
      "  [0.90470117]\n",
      "  [0.90461582]\n",
      "  [0.90336365]]]\n",
      "ejemplar: [0.91073275 0.909495   0.90835643 0.90687782 0.90595305 0.90470117\n",
      " 0.90461582 0.90336365]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.90291226]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.91073275 0.909495   0.90835643 0.90687782 0.90595305 0.90470117\n",
      "  0.90461582 0.90336365]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008833778090775013\n",
      "Predicción post entrenamiento : [[0.9038517]]\n",
      "PERDIDAAAA despues: 0.008658070117235184\n",
      "loss en el callback: 0.04005182161927223, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.909495  ]\n",
      "  [0.90835643]\n",
      "  [0.90687782]\n",
      "  [0.90595305]\n",
      "  [0.90470117]\n",
      "  [0.90461582]\n",
      "  [0.90336365]\n",
      "  [0.90291226]]]\n",
      "ejemplar: [0.909495   0.90835643 0.90687782 0.90595305 0.90470117 0.90461582\n",
      " 0.90336365 0.90291226]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.90282255]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.909495   0.90835643 0.90687782 0.90595305 0.90470117 0.90461582\n",
      "  0.90336365 0.90291226]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023386080283671618\n",
      "Predicción post entrenamiento : [[0.903597]]\n",
      "PERDIDAAAA despues: 0.0022643047850579023\n",
      "loss en el callback: 0.027977658435702324, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.90835643]\n",
      "  [0.90687782]\n",
      "  [0.90595305]\n",
      "  [0.90470117]\n",
      "  [0.90461582]\n",
      "  [0.90336365]\n",
      "  [0.90291226]\n",
      "  [0.90282255]]]\n",
      "ejemplar: [0.90835643 0.90687782 0.90595305 0.90470117 0.90461582 0.90336365\n",
      " 0.90291226 0.90282255]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9026304]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.90835643 0.90687782 0.90595305 0.90470117 0.90461582 0.90336365\n",
      "  0.90291226 0.90282255]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.697156691690907e-05\n",
      "Predicción post entrenamiento : [[0.9022839]]\n",
      "PERDIDAAAA despues: 4.234233347233385e-05\n",
      "loss en el callback: 0.004261971451342106, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.90687782]\n",
      "  [0.90595305]\n",
      "  [0.90470117]\n",
      "  [0.90461582]\n",
      "  [0.90336365]\n",
      "  [0.90291226]\n",
      "  [0.90282255]\n",
      "  [0.90263039]]]\n",
      "ejemplar: [0.90687782 0.90595305 0.90470117 0.90461582 0.90336365 0.90291226\n",
      " 0.90282255 0.90263039]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9013831]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.90687782 0.90595305 0.90470117 0.90461582 0.90336365 0.90291226\n",
      "  0.90282255 0.90263039]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039767567068338394\n",
      "Predicción post entrenamiento : [[0.9015962]]\n",
      "PERDIDAAAA despues: 0.00040621974039822817\n",
      "loss en el callback: 0.002016529208049178, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.90595305]\n",
      "  [0.90470117]\n",
      "  [0.90461582]\n",
      "  [0.90336365]\n",
      "  [0.90291226]\n",
      "  [0.90282255]\n",
      "  [0.90263039]\n",
      "  [0.9013831 ]]]\n",
      "ejemplar: [0.90595305 0.90470117 0.90461582 0.90336365 0.90291226 0.90282255\n",
      " 0.90263039 0.9013831 ]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.90088934]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.90595305 0.90470117 0.90461582 0.90336365 0.90291226 0.90282255\n",
      "  0.90263039 0.9013831 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002623455657158047\n",
      "Predicción post entrenamiento : [[0.9016584]]\n",
      "PERDIDAAAA despues: 0.00023802339273970574\n",
      "loss en el callback: 0.03399437665939331, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.90470117]\n",
      "  [0.90461582]\n",
      "  [0.90336365]\n",
      "  [0.90291226]\n",
      "  [0.90282255]\n",
      "  [0.90263039]\n",
      "  [0.9013831 ]\n",
      "  [0.90088934]]]\n",
      "ejemplar: [0.90470117 0.90461582 0.90336365 0.90291226 0.90282255 0.90263039\n",
      " 0.9013831  0.90088934]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.90102303]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.90470117 0.90461582 0.90336365 0.90291226 0.90282255 0.90263039\n",
      "  0.9013831  0.90088934]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003525202628225088\n",
      "Predicción post entrenamiento : [[0.90056866]]\n",
      "PERDIDAAAA despues: 0.00036978861317038536\n",
      "loss en el callback: 0.007028378080576658, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.90461582]\n",
      "  [0.90336365]\n",
      "  [0.90291226]\n",
      "  [0.90282255]\n",
      "  [0.90263039]\n",
      "  [0.9013831 ]\n",
      "  [0.90088934]\n",
      "  [0.90102303]]]\n",
      "ejemplar: [0.90461582 0.90336365 0.90291226 0.90282255 0.90263039 0.9013831\n",
      " 0.90088934 0.90102303]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.90012234]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.90461582 0.90336365 0.90291226 0.90282255 0.90263039 0.9013831\n",
      "  0.90088934 0.90102303]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037847666535526514\n",
      "Predicción post entrenamiento : [[0.90097636]]\n",
      "PERDIDAAAA despues: 0.0036804170813411474\n",
      "loss en el callback: 0.047511082142591476, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.90336365]\n",
      "  [0.90291226]\n",
      "  [0.90282255]\n",
      "  [0.90263039]\n",
      "  [0.9013831 ]\n",
      "  [0.90088934]\n",
      "  [0.90102303]\n",
      "  [0.90012234]]]\n",
      "ejemplar: [0.90336365 0.90291226 0.90282255 0.90263039 0.9013831  0.90088934\n",
      " 0.90102303 0.90012234]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9004068]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.90336365 0.90291226 0.90282255 0.90263039 0.9013831  0.90088934\n",
      "  0.90102303 0.90012234]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004599901847541332\n",
      "Predicción post entrenamiento : [[0.9009053]]\n",
      "PERDIDAAAA despues: 0.004532526712864637\n",
      "loss en el callback: 0.012032316997647285, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.90291226]\n",
      "  [0.90282255]\n",
      "  [0.90263039]\n",
      "  [0.9013831 ]\n",
      "  [0.90088934]\n",
      "  [0.90102303]\n",
      "  [0.90012234]\n",
      "  [0.90040678]]]\n",
      "ejemplar: [0.90291226 0.90282255 0.90263039 0.9013831  0.90088934 0.90102303\n",
      " 0.90012234 0.90040678]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9005454]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.90291226 0.90282255 0.90263039 0.9013831  0.90088934 0.90102303\n",
      "  0.90012234 0.90040678]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00327446055598557\n",
      "Predicción post entrenamiento : [[0.90077853]]\n",
      "PERDIDAAAA despues: 0.0032478361390531063\n",
      "loss en el callback: 0.002237299457192421, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.2433653]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03891117125749588\n",
      "Predicción post entrenamiento : [[0.20052344]]\n",
      "PERDIDAAAA despues: 0.02384469471871853\n",
      "loss en el callback: 0.03696141019463539, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2433653 ]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.2433653 ]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.18492626]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.2433653 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006512988358736038\n",
      "Predicción post entrenamiento : [[0.17061326]]\n",
      "PERDIDAAAA despues: 0.004407643806189299\n",
      "loss en el callback: 0.00473854411393404, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2433653 ]\n",
      "  [0.18492626]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.2433653  0.18492626]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17454474]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.2433653  0.18492626]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041375361615791917\n",
      "Predicción post entrenamiento : [[0.17283155]]\n",
      "PERDIDAAAA despues: 0.0003469929797574878\n",
      "loss en el callback: 0.00014782871585339308, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2433653 ]\n",
      "  [0.18492626]\n",
      "  [0.17454474]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.2433653\n",
      " 0.18492626 0.17454474]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.18406989]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.2433653\n",
      "  0.18492626 0.17454474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008018130902200937\n",
      "Predicción post entrenamiento : [[0.17985368]]\n",
      "PERDIDAAAA despues: 0.0005808146088384092\n",
      "loss en el callback: 0.0012946698116138577, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2433653 ]\n",
      "  [0.18492626]\n",
      "  [0.17454474]\n",
      "  [0.18406989]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.2433653  0.18492626\n",
      " 0.17454474 0.18406989]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19213952]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.2433653  0.18492626\n",
      "  0.17454474 0.18406989]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0044364626519382\n",
      "Predicción post entrenamiento : [[0.18583648]]\n",
      "PERDIDAAAA despues: 0.0036365401465445757\n",
      "loss en el callback: 0.0049054683186113834, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2433653 ]\n",
      "  [0.18492626]\n",
      "  [0.17454474]\n",
      "  [0.18406989]\n",
      "  [0.19213952]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.2433653  0.18492626 0.17454474\n",
      " 0.18406989 0.19213952]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19522731]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.2433653  0.18492626 0.17454474\n",
      "  0.18406989 0.19213952]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024549392983317375\n",
      "Predicción post entrenamiento : [[0.19144037]]\n",
      "PERDIDAAAA despues: 0.0020940150134265423\n",
      "loss en el callback: 0.002525108400732279, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2433653 ]\n",
      "  [0.18492626]\n",
      "  [0.17454474]\n",
      "  [0.18406989]\n",
      "  [0.19213952]\n",
      "  [0.19522731]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.2433653  0.18492626 0.17454474 0.18406989\n",
      " 0.19213952 0.19522731]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.21158312]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.2433653  0.18492626 0.17454474 0.18406989\n",
      "  0.19213952 0.19522731]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004241690970957279\n",
      "Predicción post entrenamiento : [[0.20966968]]\n",
      "PERDIDAAAA despues: 0.003996113780885935\n",
      "loss en el callback: 0.0011142732109874487, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.2433653 ]\n",
      "  [0.18492626]\n",
      "  [0.17454474]\n",
      "  [0.18406989]\n",
      "  [0.19213952]\n",
      "  [0.19522731]\n",
      "  [0.21158312]]]\n",
      "ejemplar: [0.04223169 0.2433653  0.18492626 0.17454474 0.18406989 0.19213952\n",
      " 0.19522731 0.21158312]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.23402971]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.2433653  0.18492626 0.17454474 0.18406989 0.19213952\n",
      "  0.19522731 0.21158312]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014426076086238027\n",
      "Predicción post entrenamiento : [[0.23191676]]\n",
      "PERDIDAAAA despues: 0.0012865649769082665\n",
      "loss en el callback: 0.0013158248038962483, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.2433653 ]\n",
      "  [0.18492626]\n",
      "  [0.17454474]\n",
      "  [0.18406989]\n",
      "  [0.19213952]\n",
      "  [0.19522731]\n",
      "  [0.21158312]\n",
      "  [0.23402971]]]\n",
      "ejemplar: [0.2433653  0.18492626 0.17454474 0.18406989 0.19213952 0.19522731\n",
      " 0.21158312 0.23402971]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.26080436]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.2433653  0.18492626 0.17454474 0.18406989 0.19213952 0.19522731\n",
      "  0.21158312 0.23402971]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009164882358163595\n",
      "Predicción post entrenamiento : [[0.2570389]]\n",
      "PERDIDAAAA despues: 0.0007026789826340973\n",
      "loss en el callback: 0.003982258029282093, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.18492626]\n",
      "  [0.17454474]\n",
      "  [0.18406989]\n",
      "  [0.19213952]\n",
      "  [0.19522731]\n",
      "  [0.21158312]\n",
      "  [0.23402971]\n",
      "  [0.26080436]]]\n",
      "ejemplar: [0.18492626 0.17454474 0.18406989 0.19213952 0.19522731 0.21158312\n",
      " 0.23402971 0.26080436]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24752517]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.18492626 0.17454474 0.18406989 0.19213952 0.19522731 0.21158312\n",
      "  0.23402971 0.26080436]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015271550510078669\n",
      "Predicción post entrenamiento : [[0.24367714]]\n",
      "PERDIDAAAA despues: 0.001241209334693849\n",
      "loss en el callback: 0.005282890982925892, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.17454474]\n",
      "  [0.18406989]\n",
      "  [0.19213952]\n",
      "  [0.19522731]\n",
      "  [0.21158312]\n",
      "  [0.23402971]\n",
      "  [0.26080436]\n",
      "  [0.24752517]]]\n",
      "ejemplar: [0.17454474 0.18406989 0.19213952 0.19522731 0.21158312 0.23402971\n",
      " 0.26080436 0.24752517]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24636112]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.17454474 0.18406989 0.19213952 0.19522731 0.21158312 0.23402971\n",
      "  0.26080436 0.24752517]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011852708412334323\n",
      "Predicción post entrenamiento : [[0.2458211]]\n",
      "PERDIDAAAA despues: 0.0011483791749924421\n",
      "loss en el callback: 0.00018542415637057275, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.18406989]\n",
      "  [0.19213952]\n",
      "  [0.19522731]\n",
      "  [0.21158312]\n",
      "  [0.23402971]\n",
      "  [0.26080436]\n",
      "  [0.24752517]\n",
      "  [0.24636112]]]\n",
      "ejemplar: [0.18406989 0.19213952 0.19522731 0.21158312 0.23402971 0.26080436\n",
      " 0.24752517 0.24636112]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25248474]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.18406989 0.19213952 0.19522731 0.21158312 0.23402971 0.26080436\n",
      "  0.24752517 0.24636112]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00204310636036098\n",
      "Predicción post entrenamiento : [[0.2496796]]\n",
      "PERDIDAAAA despues: 0.0017973862122744322\n",
      "loss en el callback: 0.004418815020471811, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.19213952]\n",
      "  [0.19522731]\n",
      "  [0.21158312]\n",
      "  [0.23402971]\n",
      "  [0.26080436]\n",
      "  [0.24752517]\n",
      "  [0.24636112]\n",
      "  [0.25248474]]]\n",
      "ejemplar: [0.19213952 0.19522731 0.21158312 0.23402971 0.26080436 0.24752517\n",
      " 0.24636112 0.25248474]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25659224]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.19213952 0.19522731 0.21158312 0.23402971 0.26080436 0.24752517\n",
      "  0.24636112 0.25248474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004050529096275568\n",
      "Predicción post entrenamiento : [[0.2504855]]\n",
      "PERDIDAAAA despues: 0.003310510190203786\n",
      "loss en el callback: 0.017973676323890686, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19522731]\n",
      "  [0.21158312]\n",
      "  [0.23402971]\n",
      "  [0.26080436]\n",
      "  [0.24752517]\n",
      "  [0.24636112]\n",
      "  [0.25248474]\n",
      "  [0.25659224]]]\n",
      "ejemplar: [0.19522731 0.21158312 0.23402971 0.26080436 0.24752517 0.24636112\n",
      " 0.25248474 0.25659224]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2578437]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19522731 0.21158312 0.23402971 0.26080436 0.24752517 0.24636112\n",
      "  0.25248474 0.25659224]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003723533358424902\n",
      "Predicción post entrenamiento : [[0.2567258]]\n",
      "PERDIDAAAA despues: 0.0035883509553968906\n",
      "loss en el callback: 0.0012467729393392801, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.21158312]\n",
      "  [0.23402971]\n",
      "  [0.26080436]\n",
      "  [0.24752517]\n",
      "  [0.24636112]\n",
      "  [0.25248474]\n",
      "  [0.25659224]\n",
      "  [0.2578437 ]]]\n",
      "ejemplar: [0.21158312 0.23402971 0.26080436 0.24752517 0.24636112 0.25248474\n",
      " 0.25659224 0.2578437 ]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.26552168]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.21158312 0.23402971 0.26080436 0.24752517 0.24636112 0.25248474\n",
      "  0.25659224 0.2578437 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00262795970775187\n",
      "Predicción post entrenamiento : [[0.2614962]]\n",
      "PERDIDAAAA despues: 0.002231441903859377\n",
      "loss en el callback: 0.011658132076263428, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.23402971]\n",
      "  [0.26080436]\n",
      "  [0.24752517]\n",
      "  [0.24636112]\n",
      "  [0.25248474]\n",
      "  [0.25659224]\n",
      "  [0.2578437 ]\n",
      "  [0.26552168]]]\n",
      "ejemplar: [0.23402971 0.26080436 0.24752517 0.24636112 0.25248474 0.25659224\n",
      " 0.2578437  0.26552168]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26874384]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.23402971 0.26080436 0.24752517 0.24636112 0.25248474 0.25659224\n",
      "  0.2578437  0.26552168]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007642042823135853\n",
      "Predicción post entrenamiento : [[0.26463583]]\n",
      "PERDIDAAAA despues: 0.0069406842812895775\n",
      "loss en el callback: 0.013735121116042137, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.26080436]\n",
      "  [0.24752517]\n",
      "  [0.24636112]\n",
      "  [0.25248474]\n",
      "  [0.25659224]\n",
      "  [0.2578437 ]\n",
      "  [0.26552168]\n",
      "  [0.26874384]]]\n",
      "ejemplar: [0.26080436 0.24752517 0.24636112 0.25248474 0.25659224 0.2578437\n",
      " 0.26552168 0.26874384]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26846665]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.26080436 0.24752517 0.24636112 0.25248474 0.25659224 0.2578437\n",
      "  0.26552168 0.26874384]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008712491020560265\n",
      "Predicción post entrenamiento : [[0.26687202]]\n",
      "PERDIDAAAA despues: 0.008417345583438873\n",
      "loss en el callback: 0.0035602510906755924, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.24752517]\n",
      "  [0.24636112]\n",
      "  [0.25248474]\n",
      "  [0.25659224]\n",
      "  [0.2578437 ]\n",
      "  [0.26552168]\n",
      "  [0.26874384]\n",
      "  [0.26846665]]]\n",
      "ejemplar: [0.24752517 0.24636112 0.25248474 0.25659224 0.2578437  0.26552168\n",
      " 0.26874384 0.26846665]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.26563483]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.24752517 0.24636112 0.25248474 0.25659224 0.2578437  0.26552168\n",
      "  0.26874384 0.26846665]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013836859725415707\n",
      "Predicción post entrenamiento : [[0.2615249]]\n",
      "PERDIDAAAA despues: 0.012886843644082546\n",
      "loss en el callback: 0.020325861871242523, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.24636112]\n",
      "  [0.25248474]\n",
      "  [0.25659224]\n",
      "  [0.2578437 ]\n",
      "  [0.26552168]\n",
      "  [0.26874384]\n",
      "  [0.26846665]\n",
      "  [0.26563483]]]\n",
      "ejemplar: [0.24636112 0.25248474 0.25659224 0.2578437  0.26552168 0.26874384\n",
      " 0.26846665 0.26563483]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26338688]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.24636112 0.25248474 0.25659224 0.2578437  0.26552168 0.26874384\n",
      "  0.26846665 0.26563483]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010927298106253147\n",
      "Predicción post entrenamiento : [[0.2608803]]\n",
      "PERDIDAAAA despues: 0.010409535840153694\n",
      "loss en el callback: 0.009269538335502148, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.25248474]\n",
      "  [0.25659224]\n",
      "  [0.2578437 ]\n",
      "  [0.26552168]\n",
      "  [0.26874384]\n",
      "  [0.26846665]\n",
      "  [0.26563483]\n",
      "  [0.26338688]]]\n",
      "ejemplar: [0.25248474 0.25659224 0.2578437  0.26552168 0.26874384 0.26846665\n",
      " 0.26563483 0.26338688]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.26362374]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.25248474 0.25659224 0.2578437  0.26552168 0.26874384 0.26846665\n",
      "  0.26563483 0.26338688]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005105127114802599\n",
      "Predicción post entrenamiento : [[0.26154065]]\n",
      "PERDIDAAAA despues: 0.004811791703104973\n",
      "loss en el callback: 0.006465941201895475, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25659224]\n",
      "  [0.2578437 ]\n",
      "  [0.26552168]\n",
      "  [0.26874384]\n",
      "  [0.26846665]\n",
      "  [0.26563483]\n",
      "  [0.26338688]\n",
      "  [0.26362374]]]\n",
      "ejemplar: [0.25659224 0.2578437  0.26552168 0.26874384 0.26846665 0.26563483\n",
      " 0.26338688 0.26362374]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2635792]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25659224 0.2578437  0.26552168 0.26874384 0.26846665 0.26563483\n",
      "  0.26338688 0.26362374]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00602249801158905\n",
      "Predicción post entrenamiento : [[0.26179808]]\n",
      "PERDIDAAAA despues: 0.005749226082116365\n",
      "loss en el callback: 0.005715645849704742, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.2578437 ]\n",
      "  [0.26552168]\n",
      "  [0.26874384]\n",
      "  [0.26846665]\n",
      "  [0.26563483]\n",
      "  [0.26338688]\n",
      "  [0.26362374]\n",
      "  [0.26357919]]]\n",
      "ejemplar: [0.2578437  0.26552168 0.26874384 0.26846665 0.26563483 0.26338688\n",
      " 0.26362374 0.26357919]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26336014]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.2578437  0.26552168 0.26874384 0.26846665 0.26563483 0.26338688\n",
      "  0.26362374 0.26357919]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2892720405943692e-05\n",
      "Predicción post entrenamiento : [[0.26304075]]\n",
      "PERDIDAAAA despues: 1.528837310615927e-05\n",
      "loss en el callback: 0.00018760940292850137, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26552168]\n",
      "  [0.26874384]\n",
      "  [0.26846665]\n",
      "  [0.26563483]\n",
      "  [0.26338688]\n",
      "  [0.26362374]\n",
      "  [0.26357919]\n",
      "  [0.26336014]]]\n",
      "ejemplar: [0.26552168 0.26874384 0.26846665 0.26563483 0.26338688 0.26362374\n",
      " 0.26357919 0.26336014]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2646011]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26552168 0.26874384 0.26846665 0.26563483 0.26338688 0.26362374\n",
      "  0.26357919 0.26336014]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007795917335897684\n",
      "Predicción post entrenamiento : [[0.26520243]]\n",
      "PERDIDAAAA despues: 0.0007463741349056363\n",
      "loss en el callback: 0.000822477275505662, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26874384]\n",
      "  [0.26846665]\n",
      "  [0.26563483]\n",
      "  [0.26338688]\n",
      "  [0.26362374]\n",
      "  [0.26357919]\n",
      "  [0.26336014]\n",
      "  [0.26460111]]]\n",
      "ejemplar: [0.26874384 0.26846665 0.26563483 0.26338688 0.26362374 0.26357919\n",
      " 0.26336014 0.26460111]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26524943]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26874384 0.26846665 0.26563483 0.26338688 0.26362374 0.26357919\n",
      "  0.26336014 0.26460111]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027517247945070267\n",
      "Predicción post entrenamiento : [[0.26639408]]\n",
      "PERDIDAAAA despues: 0.0026329457759857178\n",
      "loss en el callback: 0.002936224453151226, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26846665]\n",
      "  [0.26563483]\n",
      "  [0.26338688]\n",
      "  [0.26362374]\n",
      "  [0.26357919]\n",
      "  [0.26336014]\n",
      "  [0.26460111]\n",
      "  [0.26524943]]]\n",
      "ejemplar: [0.26846665 0.26563483 0.26338688 0.26362374 0.26357919 0.26336014\n",
      " 0.26460111 0.26524943]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26566088]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26846665 0.26563483 0.26338688 0.26362374 0.26357919 0.26336014\n",
      "  0.26460111 0.26524943]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022098117042332888\n",
      "Predicción post entrenamiento : [[0.26596713]]\n",
      "PERDIDAAAA despues: 0.002181112766265869\n",
      "loss en el callback: 0.00018891711079049855, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26563483]\n",
      "  [0.26338688]\n",
      "  [0.26362374]\n",
      "  [0.26357919]\n",
      "  [0.26336014]\n",
      "  [0.26460111]\n",
      "  [0.26524943]\n",
      "  [0.26566088]]]\n",
      "ejemplar: [0.26563483 0.26338688 0.26362374 0.26357919 0.26336014 0.26460111\n",
      " 0.26524943 0.26566088]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.26514196]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26563483 0.26338688 0.26362374 0.26357919 0.26336014 0.26460111\n",
      "  0.26524943 0.26566088]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005708896205760539\n",
      "Predicción post entrenamiento : [[0.2658482]]\n",
      "PERDIDAAAA despues: 0.000537640240509063\n",
      "loss en el callback: 0.0016632764600217342, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26338688]\n",
      "  [0.26362374]\n",
      "  [0.26357919]\n",
      "  [0.26336014]\n",
      "  [0.26460111]\n",
      "  [0.26524943]\n",
      "  [0.26566088]\n",
      "  [0.26514196]]]\n",
      "ejemplar: [0.26338688 0.26362374 0.26357919 0.26336014 0.26460111 0.26524943\n",
      " 0.26566088 0.26514196]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.26552913]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26338688 0.26362374 0.26357919 0.26336014 0.26460111 0.26524943\n",
      "  0.26566088 0.26514196]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00029953167540952563\n",
      "Predicción post entrenamiento : [[0.2653643]]\n",
      "PERDIDAAAA despues: 0.0003052644897252321\n",
      "loss en el callback: 7.222382555482909e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26362374]\n",
      "  [0.26357919]\n",
      "  [0.26336014]\n",
      "  [0.26460111]\n",
      "  [0.26524943]\n",
      "  [0.26566088]\n",
      "  [0.26514196]\n",
      "  [0.26552913]]]\n",
      "ejemplar: [0.26362374 0.26357919 0.26336014 0.26460111 0.26524943 0.26566088\n",
      " 0.26514196 0.26552913]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2655293]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26362374 0.26357919 0.26336014 0.26460111 0.26524943 0.26566088\n",
      "  0.26514196 0.26552913]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011537583777680993\n",
      "Predicción post entrenamiento : [[0.26598063]]\n",
      "PERDIDAAAA despues: 0.001123301568441093\n",
      "loss en el callback: 0.0006335588404908776, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26357919]\n",
      "  [0.26336014]\n",
      "  [0.26460111]\n",
      "  [0.26524943]\n",
      "  [0.26566088]\n",
      "  [0.26514196]\n",
      "  [0.26552913]\n",
      "  [0.2655293 ]]]\n",
      "ejemplar: [0.26357919 0.26336014 0.26460111 0.26524943 0.26566088 0.26514196\n",
      " 0.26552913 0.2655293 ]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.266157]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26357919 0.26336014 0.26460111 0.26524943 0.26566088 0.26514196\n",
      "  0.26552913 0.2655293 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.418831905350089e-05\n",
      "Predicción post entrenamiento : [[0.26599294]]\n",
      "PERDIDAAAA despues: 9.73996939137578e-05\n",
      "loss en el callback: 8.159929711837322e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26336014]\n",
      "  [0.26460111]\n",
      "  [0.26524943]\n",
      "  [0.26566088]\n",
      "  [0.26514196]\n",
      "  [0.26552913]\n",
      "  [0.2655293 ]\n",
      "  [0.266157  ]]]\n",
      "ejemplar: [0.26336014 0.26460111 0.26524943 0.26566088 0.26514196 0.26552913\n",
      " 0.2655293  0.266157  ]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.26624453]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26336014 0.26460111 0.26524943 0.26566088 0.26514196 0.26552913\n",
      "  0.2655293  0.266157  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.149019074859098e-05\n",
      "Predicción post entrenamiento : [[0.26597896]]\n",
      "PERDIDAAAA despues: 7.605157588841394e-05\n",
      "loss en el callback: 0.00023452994355466217, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26460111]\n",
      "  [0.26524943]\n",
      "  [0.26566088]\n",
      "  [0.26514196]\n",
      "  [0.26552913]\n",
      "  [0.2655293 ]\n",
      "  [0.266157  ]\n",
      "  [0.26624453]]]\n",
      "ejemplar: [0.26460111 0.26524943 0.26566088 0.26514196 0.26552913 0.2655293\n",
      " 0.266157   0.26624453]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.2663534]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26460111 0.26524943 0.26566088 0.26514196 0.26552913 0.2655293\n",
      "  0.266157   0.26624453]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.319645712617785e-05\n",
      "Predicción post entrenamiento : [[0.266029]]\n",
      "PERDIDAAAA despues: 8.92195021151565e-05\n",
      "loss en el callback: 0.000356309610651806, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26524943]\n",
      "  [0.26566088]\n",
      "  [0.26514196]\n",
      "  [0.26552913]\n",
      "  [0.2655293 ]\n",
      "  [0.266157  ]\n",
      "  [0.26624453]\n",
      "  [0.2663534 ]]]\n",
      "ejemplar: [0.26524943 0.26566088 0.26514196 0.26552913 0.2655293  0.266157\n",
      " 0.26624453 0.2663534 ]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2662107]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26524943 0.26566088 0.26514196 0.26552913 0.2655293  0.266157\n",
      "  0.26624453 0.2663534 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004698177799582481\n",
      "Predicción post entrenamiento : [[0.26759523]]\n",
      "PERDIDAAAA despues: 0.004510294646024704\n",
      "loss en el callback: 0.009303749538958073, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26566088]\n",
      "  [0.26514196]\n",
      "  [0.26552913]\n",
      "  [0.2655293 ]\n",
      "  [0.266157  ]\n",
      "  [0.26624453]\n",
      "  [0.2663534 ]\n",
      "  [0.26621071]]]\n",
      "ejemplar: [0.26566088 0.26514196 0.26552913 0.2655293  0.266157   0.26624453\n",
      " 0.2663534  0.26621071]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.26767984]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26566088 0.26514196 0.26552913 0.2655293  0.266157   0.26624453\n",
      "  0.2663534  0.26621071]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00774333905428648\n",
      "Predicción post entrenamiento : [[0.2689507]]\n",
      "PERDIDAAAA despues: 0.007521292194724083\n",
      "loss en el callback: 0.007633065339177847, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26514196]\n",
      "  [0.26552913]\n",
      "  [0.2655293 ]\n",
      "  [0.266157  ]\n",
      "  [0.26624453]\n",
      "  [0.2663534 ]\n",
      "  [0.26621071]\n",
      "  [0.26767984]]]\n",
      "ejemplar: [0.26514196 0.26552913 0.2655293  0.266157   0.26624453 0.2663534\n",
      " 0.26621071 0.26767984]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.26898006]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26514196 0.26552913 0.2655293  0.266157   0.26624453 0.2663534\n",
      "  0.26621071 0.26767984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00458479905501008\n",
      "Predicción post entrenamiento : [[0.26953766]]\n",
      "PERDIDAAAA despues: 0.004509598482400179\n",
      "loss en el callback: 0.0011894154595211148, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.26552913]\n",
      "  [0.2655293 ]\n",
      "  [0.266157  ]\n",
      "  [0.26624453]\n",
      "  [0.2663534 ]\n",
      "  [0.26621071]\n",
      "  [0.26767984]\n",
      "  [0.26898006]]]\n",
      "ejemplar: [0.26552913 0.2655293  0.266157   0.26624453 0.2663534  0.26621071\n",
      " 0.26767984 0.26898006]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2697252]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.26552913 0.2655293  0.266157   0.26624453 0.2663534  0.26621071\n",
      "  0.26767984 0.26898006]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004078921861946583\n",
      "Predicción post entrenamiento : [[0.27054682]]\n",
      "PERDIDAAAA despues: 0.003974648658186197\n",
      "loss en el callback: 0.003439163789153099, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.2655293 ]\n",
      "  [0.266157  ]\n",
      "  [0.26624453]\n",
      "  [0.2663534 ]\n",
      "  [0.26621071]\n",
      "  [0.26767984]\n",
      "  [0.26898006]\n",
      "  [0.2697252 ]]]\n",
      "ejemplar: [0.2655293  0.266157   0.26624453 0.2663534  0.26621071 0.26767984\n",
      " 0.26898006 0.2697252 ]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.2707291]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.2655293  0.266157   0.26624453 0.2663534  0.26621071 0.26767984\n",
      "  0.26898006 0.2697252 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01299725566059351\n",
      "Predicción post entrenamiento : [[0.2724105]]\n",
      "PERDIDAAAA despues: 0.012616700492799282\n",
      "loss en el callback: 0.014971530064940453, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.266157  ]\n",
      "  [0.26624453]\n",
      "  [0.2663534 ]\n",
      "  [0.26621071]\n",
      "  [0.26767984]\n",
      "  [0.26898006]\n",
      "  [0.2697252 ]\n",
      "  [0.27072909]]]\n",
      "ejemplar: [0.266157   0.26624453 0.2663534  0.26621071 0.26767984 0.26898006\n",
      " 0.2697252  0.27072909]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27268946]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.266157   0.26624453 0.2663534  0.26621071 0.26767984 0.26898006\n",
      "  0.2697252  0.27072909]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08904674649238586\n",
      "Predicción post entrenamiento : [[0.276756]]\n",
      "PERDIDAAAA despues: 0.08663632720708847\n",
      "loss en el callback: 0.08630477637052536, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.26624453]\n",
      "  [0.2663534 ]\n",
      "  [0.26621071]\n",
      "  [0.26767984]\n",
      "  [0.26898006]\n",
      "  [0.2697252 ]\n",
      "  [0.27072909]\n",
      "  [0.27268946]]]\n",
      "ejemplar: [0.26624453 0.2663534  0.26621071 0.26767984 0.26898006 0.2697252\n",
      " 0.27072909 0.27268946]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.27702644]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.26624453 0.2663534  0.26621071 0.26767984 0.26898006 0.2697252\n",
      "  0.27072909 0.27268946]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10192316025495529\n",
      "Predicción post entrenamiento : [[0.28125206]]\n",
      "PERDIDAAAA despues: 0.0992429330945015\n",
      "loss en el callback: 0.09640873223543167, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.2663534 ]\n",
      "  [0.26621071]\n",
      "  [0.26767984]\n",
      "  [0.26898006]\n",
      "  [0.2697252 ]\n",
      "  [0.27072909]\n",
      "  [0.27268946]\n",
      "  [0.27702644]]]\n",
      "ejemplar: [0.2663534  0.26621071 0.26767984 0.26898006 0.2697252  0.27072909\n",
      " 0.27268946 0.27702644]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28167105]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.2663534  0.26621071 0.26767984 0.26898006 0.2697252  0.27072909\n",
      "  0.27268946 0.27702644]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08579768985509872\n",
      "Predicción post entrenamiento : [[0.28547552]]\n",
      "PERDIDAAAA despues: 0.08358340710401535\n",
      "loss en el callback: 0.09165298938751221, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.26621071]\n",
      "  [0.26767984]\n",
      "  [0.26898006]\n",
      "  [0.2697252 ]\n",
      "  [0.27072909]\n",
      "  [0.27268946]\n",
      "  [0.27702644]\n",
      "  [0.28167105]]]\n",
      "ejemplar: [0.26621071 0.26767984 0.26898006 0.2697252  0.27072909 0.27268946\n",
      " 0.27702644 0.28167105]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.28611678]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.26621071 0.26767984 0.26898006 0.2697252  0.27072909 0.27268946\n",
      "  0.27702644 0.28167105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10255195200443268\n",
      "Predicción post entrenamiento : [[0.29011324]]\n",
      "PERDIDAAAA despues: 0.1000082939863205\n",
      "loss en el callback: 0.08700425922870636, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.26767984]\n",
      "  [0.26898006]\n",
      "  [0.2697252 ]\n",
      "  [0.27072909]\n",
      "  [0.27268946]\n",
      "  [0.27702644]\n",
      "  [0.28167105]\n",
      "  [0.28611678]]]\n",
      "ejemplar: [0.26767984 0.26898006 0.2697252  0.27072909 0.27268946 0.27702644\n",
      " 0.28167105 0.28611678]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29113626]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.26767984 0.26898006 0.2697252  0.27072909 0.27268946 0.27702644\n",
      "  0.28167105 0.28611678]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0861544981598854\n",
      "Predicción post entrenamiento : [[0.2949027]]\n",
      "PERDIDAAAA despues: 0.08395762741565704\n",
      "loss en el callback: 0.09043130278587341, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.26898006]\n",
      "  [0.2697252 ]\n",
      "  [0.27072909]\n",
      "  [0.27268946]\n",
      "  [0.27702644]\n",
      "  [0.28167105]\n",
      "  [0.28611678]\n",
      "  [0.29113626]]]\n",
      "ejemplar: [0.26898006 0.2697252  0.27072909 0.27268946 0.27702644 0.28167105\n",
      " 0.28611678 0.29113626]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.29607445]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.26898006 0.2697252  0.27072909 0.27268946 0.27702644 0.28167105\n",
      "  0.28611678 0.29113626]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0743638351559639\n",
      "Predicción post entrenamiento : [[0.29946238]]\n",
      "PERDIDAAAA despues: 0.07252755016088486\n",
      "loss en el callback: 0.07862120866775513, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.2697252 ]\n",
      "  [0.27072909]\n",
      "  [0.27268946]\n",
      "  [0.27702644]\n",
      "  [0.28167105]\n",
      "  [0.28611678]\n",
      "  [0.29113626]\n",
      "  [0.29607445]]]\n",
      "ejemplar: [0.2697252  0.27072909 0.27268946 0.27702644 0.28167105 0.28611678\n",
      " 0.29113626 0.29607445]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30092105]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.2697252  0.27072909 0.27268946 0.27702644 0.28167105 0.28611678\n",
      "  0.29113626 0.29607445]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11686351150274277\n",
      "Predicción post entrenamiento : [[0.30497587]]\n",
      "PERDIDAAAA despues: 0.114107646048069\n",
      "loss en el callback: 0.1311945915222168, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27072909]\n",
      "  [0.27268946]\n",
      "  [0.27702644]\n",
      "  [0.28167105]\n",
      "  [0.28611678]\n",
      "  [0.29113626]\n",
      "  [0.29607445]\n",
      "  [0.30092105]]]\n",
      "ejemplar: [0.27072909 0.27268946 0.27702644 0.28167105 0.28611678 0.29113626\n",
      " 0.29607445 0.30092105]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3069706]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27072909 0.27268946 0.27702644 0.28167105 0.28611678 0.29113626\n",
      "  0.29607445 0.30092105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1258748173713684\n",
      "Predicción post entrenamiento : [[0.31112757]]\n",
      "PERDIDAAAA despues: 0.12294241040945053\n",
      "loss en el callback: 0.11565817147493362, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27268946]\n",
      "  [0.27702644]\n",
      "  [0.28167105]\n",
      "  [0.28611678]\n",
      "  [0.29113626]\n",
      "  [0.29607445]\n",
      "  [0.30092105]\n",
      "  [0.3069706 ]]]\n",
      "ejemplar: [0.27268946 0.27702644 0.28167105 0.28611678 0.29113626 0.29607445\n",
      " 0.30092105 0.3069706 ]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3137541]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27268946 0.27702644 0.28167105 0.28611678 0.29113626 0.29607445\n",
      "  0.30092105 0.3069706 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.129053995013237\n",
      "Predicción post entrenamiento : [[0.31784192]]\n",
      "PERDIDAAAA despues: 0.12613369524478912\n",
      "loss en el callback: 0.1198364794254303, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.27702644]\n",
      "  [0.28167105]\n",
      "  [0.28611678]\n",
      "  [0.29113626]\n",
      "  [0.29607445]\n",
      "  [0.30092105]\n",
      "  [0.3069706 ]\n",
      "  [0.31375411]]]\n",
      "ejemplar: [0.27702644 0.28167105 0.28611678 0.29113626 0.29607445 0.30092105\n",
      " 0.3069706  0.31375411]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.32103908]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.27702644 0.28167105 0.28611678 0.29113626 0.29607445 0.30092105\n",
      "  0.3069706  0.31375411]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15174002945423126\n",
      "Predicción post entrenamiento : [[0.32529703]]\n",
      "PERDIDAAAA despues: 0.1484408974647522\n",
      "loss en el callback: 0.14849571883678436, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28167105]\n",
      "  [0.28611678]\n",
      "  [0.29113626]\n",
      "  [0.29607445]\n",
      "  [0.30092105]\n",
      "  [0.3069706 ]\n",
      "  [0.31375411]\n",
      "  [0.32103908]]]\n",
      "ejemplar: [0.28167105 0.28611678 0.29113626 0.29607445 0.30092105 0.3069706\n",
      " 0.31375411 0.32103908]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.32865372]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28167105 0.28611678 0.29113626 0.29607445 0.30092105 0.3069706\n",
      "  0.31375411 0.32103908]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1408778429031372\n",
      "Predicción post entrenamiento : [[0.33252445]]\n",
      "PERDIDAAAA despues: 0.1379871815443039\n",
      "loss en el callback: 0.19784970581531525, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.28611678]\n",
      "  [0.29113626]\n",
      "  [0.29607445]\n",
      "  [0.30092105]\n",
      "  [0.3069706 ]\n",
      "  [0.31375411]\n",
      "  [0.32103908]\n",
      "  [0.32865372]]]\n",
      "ejemplar: [0.28611678 0.29113626 0.29607445 0.30092105 0.3069706  0.31375411\n",
      " 0.32103908 0.32865372]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.33604077]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.28611678 0.29113626 0.29607445 0.30092105 0.3069706  0.31375411\n",
      "  0.32103908 0.32865372]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15303491055965424\n",
      "Predicción post entrenamiento : [[0.34027725]]\n",
      "PERDIDAAAA despues: 0.14973825216293335\n",
      "loss en el callback: 0.1267598420381546, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29113626]\n",
      "  [0.29607445]\n",
      "  [0.30092105]\n",
      "  [0.3069706 ]\n",
      "  [0.31375411]\n",
      "  [0.32103908]\n",
      "  [0.32865372]\n",
      "  [0.33604077]]]\n",
      "ejemplar: [0.29113626 0.29607445 0.30092105 0.3069706  0.31375411 0.32103908\n",
      " 0.32865372 0.33604077]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3440785]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29113626 0.29607445 0.30092105 0.3069706  0.31375411 0.32103908\n",
      "  0.32865372 0.33604077]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14326952397823334\n",
      "Predicción post entrenamiento : [[0.34809807]]\n",
      "PERDIDAAAA despues: 0.140242800116539\n",
      "loss en el callback: 0.10747244209051132, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.29607445]\n",
      "  [0.30092105]\n",
      "  [0.3069706 ]\n",
      "  [0.31375411]\n",
      "  [0.32103908]\n",
      "  [0.32865372]\n",
      "  [0.33604077]\n",
      "  [0.34407851]]]\n",
      "ejemplar: [0.29607445 0.30092105 0.3069706  0.31375411 0.32103908 0.32865372\n",
      " 0.33604077 0.34407851]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3521513]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.29607445 0.30092105 0.3069706  0.31375411 0.32103908 0.32865372\n",
      "  0.33604077 0.34407851]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.17609991133213043\n",
      "Predicción post entrenamiento : [[0.35646656]]\n",
      "PERDIDAAAA despues: 0.17249679565429688\n",
      "loss en el callback: 0.15372535586357117, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30092105]\n",
      "  [0.3069706 ]\n",
      "  [0.31375411]\n",
      "  [0.32103908]\n",
      "  [0.32865372]\n",
      "  [0.33604077]\n",
      "  [0.34407851]\n",
      "  [0.3521513 ]]]\n",
      "ejemplar: [0.30092105 0.3069706  0.31375411 0.32103908 0.32865372 0.33604077\n",
      " 0.34407851 0.3521513 ]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36088702]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30092105 0.3069706  0.31375411 0.32103908 0.32865372 0.33604077\n",
      "  0.34407851 0.3521513 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13223285973072052\n",
      "Predicción post entrenamiento : [[0.3646123]]\n",
      "PERDIDAAAA despues: 0.1295374184846878\n",
      "loss en el callback: 0.17313675582408905, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.3069706 ]\n",
      "  [0.31375411]\n",
      "  [0.32103908]\n",
      "  [0.32865372]\n",
      "  [0.33604077]\n",
      "  [0.34407851]\n",
      "  [0.3521513 ]\n",
      "  [0.36088702]]]\n",
      "ejemplar: [0.3069706  0.31375411 0.32103908 0.32865372 0.33604077 0.34407851\n",
      " 0.3521513  0.36088702]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.36953184]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.3069706  0.31375411 0.32103908 0.32865372 0.33604077 0.34407851\n",
      "  0.3521513  0.36088702]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09091784805059433\n",
      "Predicción post entrenamiento : [[0.3724707]]\n",
      "PERDIDAAAA despues: 0.0891541913151741\n",
      "loss en el callback: 0.07497813552618027, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.31375411]\n",
      "  [0.32103908]\n",
      "  [0.32865372]\n",
      "  [0.33604077]\n",
      "  [0.34407851]\n",
      "  [0.3521513 ]\n",
      "  [0.36088702]\n",
      "  [0.36953184]]]\n",
      "ejemplar: [0.31375411 0.32103908 0.32865372 0.33604077 0.34407851 0.3521513\n",
      " 0.36088702 0.36953184]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.37772435]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.31375411 0.32103908 0.32865372 0.33604077 0.34407851 0.3521513\n",
      "  0.36088702 0.36953184]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08764293044805527\n",
      "Predicción post entrenamiento : [[0.3807558]]\n",
      "PERDIDAAAA despues: 0.08585721254348755\n",
      "loss en el callback: 0.100664421916008, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32103908]\n",
      "  [0.32865372]\n",
      "  [0.33604077]\n",
      "  [0.34407851]\n",
      "  [0.3521513 ]\n",
      "  [0.36088702]\n",
      "  [0.36953184]\n",
      "  [0.37772435]]]\n",
      "ejemplar: [0.32103908 0.32865372 0.33604077 0.34407851 0.3521513  0.36088702\n",
      " 0.36953184 0.37772435]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.38625225]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32103908 0.32865372 0.33604077 0.34407851 0.3521513  0.36088702\n",
      "  0.36953184 0.37772435]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1077149361371994\n",
      "Predicción post entrenamiento : [[0.3894159]]\n",
      "PERDIDAAAA despues: 0.10564833879470825\n",
      "loss en el callback: 0.1007189080119133, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.32865372]\n",
      "  [0.33604077]\n",
      "  [0.34407851]\n",
      "  [0.3521513 ]\n",
      "  [0.36088702]\n",
      "  [0.36953184]\n",
      "  [0.37772435]\n",
      "  [0.38625225]]]\n",
      "ejemplar: [0.32865372 0.33604077 0.34407851 0.3521513  0.36088702 0.36953184\n",
      " 0.37772435 0.38625225]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39509603]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.32865372 0.33604077 0.34407851 0.3521513  0.36088702 0.36953184\n",
      "  0.37772435 0.38625225]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12166262418031693\n",
      "Predicción post entrenamiento : [[0.39839587]]\n",
      "PERDIDAAAA despues: 0.11937154084444046\n",
      "loss en el callback: 0.0927632600069046, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.33604077]\n",
      "  [0.34407851]\n",
      "  [0.3521513 ]\n",
      "  [0.36088702]\n",
      "  [0.36953184]\n",
      "  [0.37772435]\n",
      "  [0.38625225]\n",
      "  [0.39509603]]]\n",
      "ejemplar: [0.33604077 0.34407851 0.3521513  0.36088702 0.36953184 0.37772435\n",
      " 0.38625225 0.39509603]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40422702]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.33604077 0.34407851 0.3521513  0.36088702 0.36953184 0.37772435\n",
      "  0.38625225 0.39509603]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10135379433631897\n",
      "Predicción post entrenamiento : [[0.40736386]]\n",
      "PERDIDAAAA despues: 0.09936633706092834\n",
      "loss en el callback: 0.09322915971279144, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.34407851]\n",
      "  [0.3521513 ]\n",
      "  [0.36088702]\n",
      "  [0.36953184]\n",
      "  [0.37772435]\n",
      "  [0.38625225]\n",
      "  [0.39509603]\n",
      "  [0.40422702]]]\n",
      "ejemplar: [0.34407851 0.3521513  0.36088702 0.36953184 0.37772435 0.38625225\n",
      " 0.39509603 0.40422702]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41344154]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.34407851 0.3521513  0.36088702 0.36953184 0.37772435 0.38625225\n",
      "  0.39509603 0.40422702]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08173870295286179\n",
      "Predicción post entrenamiento : [[0.41622877]]\n",
      "PERDIDAAAA despues: 0.0801527351140976\n",
      "loss en el callback: 0.08666548877954483, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.3521513 ]\n",
      "  [0.36088702]\n",
      "  [0.36953184]\n",
      "  [0.37772435]\n",
      "  [0.38625225]\n",
      "  [0.39509603]\n",
      "  [0.40422702]\n",
      "  [0.41344154]]]\n",
      "ejemplar: [0.3521513  0.36088702 0.36953184 0.37772435 0.38625225 0.39509603\n",
      " 0.40422702 0.41344154]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4224464]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.3521513  0.36088702 0.36953184 0.37772435 0.38625225 0.39509603\n",
      "  0.40422702 0.41344154]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09913979470729828\n",
      "Predicción post entrenamiento : [[0.42506295]]\n",
      "PERDIDAAAA despues: 0.09749892354011536\n",
      "loss en el callback: 0.055743079632520676, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36088702]\n",
      "  [0.36953184]\n",
      "  [0.37772435]\n",
      "  [0.38625225]\n",
      "  [0.39509603]\n",
      "  [0.40422702]\n",
      "  [0.41344154]\n",
      "  [0.4224464 ]]]\n",
      "ejemplar: [0.36088702 0.36953184 0.37772435 0.38625225 0.39509603 0.40422702\n",
      " 0.41344154 0.4224464 ]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4314449]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36088702 0.36953184 0.37772435 0.38625225 0.39509603 0.40422702\n",
      "  0.41344154 0.4224464 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08408893644809723\n",
      "Predicción post entrenamiento : [[0.43430817]]\n",
      "PERDIDAAAA despues: 0.08243655413389206\n",
      "loss en el callback: 0.11801017820835114, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.36953184]\n",
      "  [0.37772435]\n",
      "  [0.38625225]\n",
      "  [0.39509603]\n",
      "  [0.40422702]\n",
      "  [0.41344154]\n",
      "  [0.4224464 ]\n",
      "  [0.43144491]]]\n",
      "ejemplar: [0.36953184 0.37772435 0.38625225 0.39509603 0.40422702 0.41344154\n",
      " 0.4224464  0.43144491]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4407253]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.36953184 0.37772435 0.38625225 0.39509603 0.40422702 0.41344154\n",
      "  0.4224464  0.43144491]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07727755606174469\n",
      "Predicción post entrenamiento : [[0.4430207]]\n",
      "PERDIDAAAA despues: 0.07600662857294083\n",
      "loss en el callback: 0.04411328583955765, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.37772435]\n",
      "  [0.38625225]\n",
      "  [0.39509603]\n",
      "  [0.40422702]\n",
      "  [0.41344154]\n",
      "  [0.4224464 ]\n",
      "  [0.43144491]\n",
      "  [0.4407253 ]]]\n",
      "ejemplar: [0.37772435 0.38625225 0.39509603 0.40422702 0.41344154 0.4224464\n",
      " 0.43144491 0.4407253 ]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.44950706]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.37772435 0.38625225 0.39509603 0.40422702 0.41344154 0.4224464\n",
      "  0.43144491 0.4407253 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05046774074435234\n",
      "Predicción post entrenamiento : [[0.45111328]]\n",
      "PERDIDAAAA despues: 0.04974864423274994\n",
      "loss en el callback: 0.02515845187008381, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.38625225]\n",
      "  [0.39509603]\n",
      "  [0.40422702]\n",
      "  [0.41344154]\n",
      "  [0.4224464 ]\n",
      "  [0.43144491]\n",
      "  [0.4407253 ]\n",
      "  [0.44950706]]]\n",
      "ejemplar: [0.38625225 0.39509603 0.40422702 0.41344154 0.4224464  0.43144491\n",
      " 0.4407253  0.44950706]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.45779783]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.38625225 0.39509603 0.40422702 0.41344154 0.4224464  0.43144491\n",
      "  0.4407253  0.44950706]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05796952545642853\n",
      "Predicción post entrenamiento : [[0.45980382]]\n",
      "PERDIDAAAA despues: 0.05700758844614029\n",
      "loss en el callback: 0.04766136407852173, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.39509603]\n",
      "  [0.40422702]\n",
      "  [0.41344154]\n",
      "  [0.4224464 ]\n",
      "  [0.43144491]\n",
      "  [0.4407253 ]\n",
      "  [0.44950706]\n",
      "  [0.45779783]]]\n",
      "ejemplar: [0.39509603 0.40422702 0.41344154 0.4224464  0.43144491 0.4407253\n",
      " 0.44950706 0.45779783]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.46663404]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.39509603 0.40422702 0.41344154 0.4224464  0.43144491 0.4407253\n",
      "  0.44950706 0.45779783]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06472155451774597\n",
      "Predicción post entrenamiento : [[0.4688342]]\n",
      "PERDIDAAAA despues: 0.06360693275928497\n",
      "loss en el callback: 0.04709146171808243, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.40422702]\n",
      "  [0.41344154]\n",
      "  [0.4224464 ]\n",
      "  [0.43144491]\n",
      "  [0.4407253 ]\n",
      "  [0.44950706]\n",
      "  [0.45779783]\n",
      "  [0.46663404]]]\n",
      "ejemplar: [0.40422702 0.41344154 0.4224464  0.43144491 0.4407253  0.44950706\n",
      " 0.45779783 0.46663404]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.47574386]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.40422702 0.41344154 0.4224464  0.43144491 0.4407253  0.44950706\n",
      "  0.45779783 0.46663404]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.060932088643312454\n",
      "Predicción post entrenamiento : [[0.4783462]]\n",
      "PERDIDAAAA despues: 0.0596541166305542\n",
      "loss en el callback: 0.11014532297849655, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.41344154]\n",
      "  [0.4224464 ]\n",
      "  [0.43144491]\n",
      "  [0.4407253 ]\n",
      "  [0.44950706]\n",
      "  [0.45779783]\n",
      "  [0.46663404]\n",
      "  [0.47574386]]]\n",
      "ejemplar: [0.41344154 0.4224464  0.43144491 0.4407253  0.44950706 0.45779783\n",
      " 0.46663404 0.47574386]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4852626]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.41344154 0.4224464  0.43144491 0.4407253  0.44950706 0.45779783\n",
      "  0.46663404 0.47574386]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07345912605524063\n",
      "Predicción post entrenamiento : [[0.4878122]]\n",
      "PERDIDAAAA despues: 0.07208357751369476\n",
      "loss en el callback: 0.08448096364736557, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.4224464 ]\n",
      "  [0.43144491]\n",
      "  [0.4407253 ]\n",
      "  [0.44950706]\n",
      "  [0.45779783]\n",
      "  [0.46663404]\n",
      "  [0.47574386]\n",
      "  [0.4852626 ]]]\n",
      "ejemplar: [0.4224464  0.43144491 0.4407253  0.44950706 0.45779783 0.46663404\n",
      " 0.47574386 0.4852626 ]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49470466]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.4224464  0.43144491 0.4407253  0.44950706 0.45779783 0.46663404\n",
      "  0.47574386 0.4852626 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11081013828516006\n",
      "Predicción post entrenamiento : [[0.4974093]]\n",
      "PERDIDAAAA despues: 0.1090167984366417\n",
      "loss en el callback: 0.07350069284439087, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.43144491]\n",
      "  [0.4407253 ]\n",
      "  [0.44950706]\n",
      "  [0.45779783]\n",
      "  [0.46663404]\n",
      "  [0.47574386]\n",
      "  [0.4852626 ]\n",
      "  [0.49470466]]]\n",
      "ejemplar: [0.43144491 0.4407253  0.44950706 0.45779783 0.46663404 0.47574386\n",
      " 0.4852626  0.49470466]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.50432485]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.43144491 0.4407253  0.44950706 0.45779783 0.46663404 0.47574386\n",
      "  0.4852626  0.49470466]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11188846826553345\n",
      "Predicción post entrenamiento : [[0.5072932]]\n",
      "PERDIDAAAA despues: 0.10991144925355911\n",
      "loss en el callback: 0.10927210003137589, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.4407253 ]\n",
      "  [0.44950706]\n",
      "  [0.45779783]\n",
      "  [0.46663404]\n",
      "  [0.47574386]\n",
      "  [0.4852626 ]\n",
      "  [0.49470466]\n",
      "  [0.50432485]]]\n",
      "ejemplar: [0.4407253  0.44950706 0.45779783 0.46663404 0.47574386 0.4852626\n",
      " 0.49470466 0.50432485]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5142409]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.4407253  0.44950706 0.45779783 0.46663404 0.47574386 0.4852626\n",
      "  0.49470466 0.50432485]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0784139335155487\n",
      "Predicción post entrenamiento : [[0.5167763]]\n",
      "PERDIDAAAA despues: 0.07700041681528091\n",
      "loss en el callback: 0.07457460463047028, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.44950706]\n",
      "  [0.45779783]\n",
      "  [0.46663404]\n",
      "  [0.47574386]\n",
      "  [0.4852626 ]\n",
      "  [0.49470466]\n",
      "  [0.50432485]\n",
      "  [0.51424092]]]\n",
      "ejemplar: [0.44950706 0.45779783 0.46663404 0.47574386 0.4852626  0.49470466\n",
      " 0.50432485 0.51424092]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.52369714]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.44950706 0.45779783 0.46663404 0.47574386 0.4852626  0.49470466\n",
      "  0.50432485 0.51424092]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06765595078468323\n",
      "Predicción post entrenamiento : [[0.5261274]]\n",
      "PERDIDAAAA despues: 0.06639759987592697\n",
      "loss en el callback: 0.08608818799257278, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.45779783]\n",
      "  [0.46663404]\n",
      "  [0.47574386]\n",
      "  [0.4852626 ]\n",
      "  [0.49470466]\n",
      "  [0.50432485]\n",
      "  [0.51424092]\n",
      "  [0.52369714]]]\n",
      "ejemplar: [0.45779783 0.46663404 0.47574386 0.4852626  0.49470466 0.50432485\n",
      " 0.51424092 0.52369714]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.53316224]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.45779783 0.46663404 0.47574386 0.4852626  0.49470466 0.50432485\n",
      "  0.51424092 0.52369714]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05511093512177467\n",
      "Predicción post entrenamiento : [[0.5351391]]\n",
      "PERDIDAAAA despues: 0.054186686873435974\n",
      "loss en el callback: 0.047045785933732986, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.46663404]\n",
      "  [0.47574386]\n",
      "  [0.4852626 ]\n",
      "  [0.49470466]\n",
      "  [0.50432485]\n",
      "  [0.51424092]\n",
      "  [0.52369714]\n",
      "  [0.53316224]]]\n",
      "ejemplar: [0.46663404 0.47574386 0.4852626  0.49470466 0.50432485 0.51424092\n",
      " 0.52369714 0.53316224]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.54244953]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.46663404 0.47574386 0.4852626  0.49470466 0.50432485 0.51424092\n",
      "  0.52369714 0.53316224]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05862698704004288\n",
      "Predicción post entrenamiento : [[0.5446612]]\n",
      "PERDIDAAAA despues: 0.057560842484235764\n",
      "loss en el callback: 0.07827652990818024, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.47574386]\n",
      "  [0.4852626 ]\n",
      "  [0.49470466]\n",
      "  [0.50432485]\n",
      "  [0.51424092]\n",
      "  [0.52369714]\n",
      "  [0.53316224]\n",
      "  [0.54244953]]]\n",
      "ejemplar: [0.47574386 0.4852626  0.49470466 0.50432485 0.51424092 0.52369714\n",
      " 0.53316224 0.54244953]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.55215704]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.47574386 0.4852626  0.49470466 0.50432485 0.51424092 0.52369714\n",
      "  0.53316224 0.54244953]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10664934664964676\n",
      "Predicción post entrenamiento : [[0.55487853]]\n",
      "PERDIDAAAA despues: 0.104879230260849\n",
      "loss en el callback: 0.09453195333480835, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.4852626 ]\n",
      "  [0.49470466]\n",
      "  [0.50432485]\n",
      "  [0.51424092]\n",
      "  [0.52369714]\n",
      "  [0.53316224]\n",
      "  [0.54244953]\n",
      "  [0.55215704]]]\n",
      "ejemplar: [0.4852626  0.49470466 0.50432485 0.51424092 0.52369714 0.53316224\n",
      " 0.54244953 0.55215704]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5625185]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.4852626  0.49470466 0.50432485 0.51424092 0.52369714 0.53316224\n",
      "  0.54244953 0.55215704]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09803857654333115\n",
      "Predicción post entrenamiento : [[0.56471163]]\n",
      "PERDIDAAAA despues: 0.0966699868440628\n",
      "loss en el callback: 0.05349668115377426, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.49470466]\n",
      "  [0.50432485]\n",
      "  [0.51424092]\n",
      "  [0.52369714]\n",
      "  [0.53316224]\n",
      "  [0.54244953]\n",
      "  [0.55215704]\n",
      "  [0.56251848]]]\n",
      "ejemplar: [0.49470466 0.50432485 0.51424092 0.52369714 0.53316224 0.54244953\n",
      " 0.55215704 0.56251848]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5724074]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.49470466 0.50432485 0.51424092 0.52369714 0.53316224 0.54244953\n",
      "  0.55215704 0.56251848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0764458179473877\n",
      "Predicción post entrenamiento : [[0.5750467]]\n",
      "PERDIDAAAA despues: 0.0749933123588562\n",
      "loss en el callback: 0.1237148642539978, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.50432485]\n",
      "  [0.51424092]\n",
      "  [0.52369714]\n",
      "  [0.53316224]\n",
      "  [0.54244953]\n",
      "  [0.55215704]\n",
      "  [0.56251848]\n",
      "  [0.57240742]]]\n",
      "ejemplar: [0.50432485 0.51424092 0.52369714 0.53316224 0.54244953 0.55215704\n",
      " 0.56251848 0.57240742]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.58282846]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.50432485 0.51424092 0.52369714 0.53316224 0.54244953 0.55215704\n",
      "  0.56251848 0.57240742]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055440954864025116\n",
      "Predicción post entrenamiento : [[0.5850609]]\n",
      "PERDIDAAAA despues: 0.05439464747905731\n",
      "loss en el callback: 0.08595293015241623, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.51424092]\n",
      "  [0.52369714]\n",
      "  [0.53316224]\n",
      "  [0.54244953]\n",
      "  [0.55215704]\n",
      "  [0.56251848]\n",
      "  [0.57240742]\n",
      "  [0.58282846]]]\n",
      "ejemplar: [0.51424092 0.52369714 0.53316224 0.54244953 0.55215704 0.56251848\n",
      " 0.57240742 0.58282846]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5928963]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.51424092 0.52369714 0.53316224 0.54244953 0.55215704 0.56251848\n",
      "  0.57240742 0.58282846]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054716240614652634\n",
      "Predicción post entrenamiento : [[0.59523386]]\n",
      "PERDIDAAAA despues: 0.053628116846084595\n",
      "loss en el callback: 0.08703151345252991, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.52369714]\n",
      "  [0.53316224]\n",
      "  [0.54244953]\n",
      "  [0.55215704]\n",
      "  [0.56251848]\n",
      "  [0.57240742]\n",
      "  [0.58282846]\n",
      "  [0.59289628]]]\n",
      "ejemplar: [0.52369714 0.53316224 0.54244953 0.55215704 0.56251848 0.57240742\n",
      " 0.58282846 0.59289628]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.60305876]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.52369714 0.53316224 0.54244953 0.55215704 0.56251848 0.57240742\n",
      "  0.58282846 0.59289628]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03323173522949219\n",
      "Predicción post entrenamiento : [[0.6047909]]\n",
      "PERDIDAAAA despues: 0.03260320425033569\n",
      "loss en el callback: 0.04671795666217804, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.53316224]\n",
      "  [0.54244953]\n",
      "  [0.55215704]\n",
      "  [0.56251848]\n",
      "  [0.57240742]\n",
      "  [0.58282846]\n",
      "  [0.59289628]\n",
      "  [0.60305876]]]\n",
      "ejemplar: [0.53316224 0.54244953 0.55215704 0.56251848 0.57240742 0.58282846\n",
      " 0.59289628 0.60305876]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.61273676]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.53316224 0.54244953 0.55215704 0.56251848 0.57240742 0.58282846\n",
      "  0.59289628 0.60305876]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031149500980973244\n",
      "Predicción post entrenamiento : [[0.61443186]]\n",
      "PERDIDAAAA despues: 0.0305540319532156\n",
      "loss en el callback: 0.049665667116642, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.54244953]\n",
      "  [0.55215704]\n",
      "  [0.56251848]\n",
      "  [0.57240742]\n",
      "  [0.58282846]\n",
      "  [0.59289628]\n",
      "  [0.60305876]\n",
      "  [0.61273676]]]\n",
      "ejemplar: [0.54244953 0.55215704 0.56251848 0.57240742 0.58282846 0.59289628\n",
      " 0.60305876 0.61273676]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.62252414]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.54244953 0.55215704 0.56251848 0.57240742 0.58282846 0.59289628\n",
      "  0.60305876 0.61273676]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04479514807462692\n",
      "Predicción post entrenamiento : [[0.62409097]]\n",
      "PERDIDAAAA despues: 0.04413437098264694\n",
      "loss en el callback: 0.0313836894929409, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.55215704]\n",
      "  [0.56251848]\n",
      "  [0.57240742]\n",
      "  [0.58282846]\n",
      "  [0.59289628]\n",
      "  [0.60305876]\n",
      "  [0.61273676]\n",
      "  [0.62252414]]]\n",
      "ejemplar: [0.55215704 0.56251848 0.57240742 0.58282846 0.59289628 0.60305876\n",
      " 0.61273676 0.62252414]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.632402]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.55215704 0.56251848 0.57240742 0.58282846 0.59289628 0.60305876\n",
      "  0.61273676 0.62252414]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03242657333612442\n",
      "Predicción post entrenamiento : [[0.6339422]]\n",
      "PERDIDAAAA despues: 0.03187425062060356\n",
      "loss en el callback: 0.031561821699142456, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.56251848]\n",
      "  [0.57240742]\n",
      "  [0.58282846]\n",
      "  [0.59289628]\n",
      "  [0.60305876]\n",
      "  [0.61273676]\n",
      "  [0.62252414]\n",
      "  [0.632402  ]]]\n",
      "ejemplar: [0.56251848 0.57240742 0.58282846 0.59289628 0.60305876 0.61273676\n",
      " 0.62252414 0.632402  ]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6423844]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.56251848 0.57240742 0.58282846 0.59289628 0.60305876 0.61273676\n",
      "  0.62252414 0.632402  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025235049426555634\n",
      "Predicción post entrenamiento : [[0.64255875]]\n",
      "PERDIDAAAA despues: 0.02517968975007534\n",
      "loss en el callback: 0.0003508302033878863, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.57240742]\n",
      "  [0.58282846]\n",
      "  [0.59289628]\n",
      "  [0.60305876]\n",
      "  [0.61273676]\n",
      "  [0.62252414]\n",
      "  [0.632402  ]\n",
      "  [0.64238441]]]\n",
      "ejemplar: [0.57240742 0.58282846 0.59289628 0.60305876 0.61273676 0.62252414\n",
      " 0.632402   0.64238441]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6509541]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.57240742 0.58282846 0.59289628 0.60305876 0.61273676 0.62252414\n",
      "  0.632402   0.64238441]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023171821609139442\n",
      "Predicción post entrenamiento : [[0.65183926]]\n",
      "PERDIDAAAA despues: 0.02290313132107258\n",
      "loss en el callback: 0.009977915324270725, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.58282846]\n",
      "  [0.59289628]\n",
      "  [0.60305876]\n",
      "  [0.61273676]\n",
      "  [0.62252414]\n",
      "  [0.632402  ]\n",
      "  [0.64238441]\n",
      "  [0.65095413]]]\n",
      "ejemplar: [0.58282846 0.59289628 0.60305876 0.61273676 0.62252414 0.632402\n",
      " 0.64238441 0.65095413]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6602931]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.58282846 0.59289628 0.60305876 0.61273676 0.62252414 0.632402\n",
      "  0.64238441 0.65095413]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017741650342941284\n",
      "Predicción post entrenamiento : [[0.6601454]]\n",
      "PERDIDAAAA despues: 0.01778101921081543\n",
      "loss en el callback: 0.000228602671995759, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.59289628]\n",
      "  [0.60305876]\n",
      "  [0.61273676]\n",
      "  [0.62252414]\n",
      "  [0.632402  ]\n",
      "  [0.64238441]\n",
      "  [0.65095413]\n",
      "  [0.6602931 ]]]\n",
      "ejemplar: [0.59289628 0.60305876 0.61273676 0.62252414 0.632402   0.64238441\n",
      " 0.65095413 0.6602931 ]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6684896]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.59289628 0.60305876 0.61273676 0.62252414 0.632402   0.64238441\n",
      "  0.65095413 0.6602931 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008405384607613087\n",
      "Predicción post entrenamiento : [[0.6694687]]\n",
      "PERDIDAAAA despues: 0.008226809091866016\n",
      "loss en el callback: 0.016546346247196198, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.60305876]\n",
      "  [0.61273676]\n",
      "  [0.62252414]\n",
      "  [0.632402  ]\n",
      "  [0.64238441]\n",
      "  [0.65095413]\n",
      "  [0.6602931 ]\n",
      "  [0.66848958]]]\n",
      "ejemplar: [0.60305876 0.61273676 0.62252414 0.632402   0.64238441 0.65095413\n",
      " 0.6602931  0.66848958]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.67775583]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.60305876 0.61273676 0.62252414 0.632402   0.64238441 0.65095413\n",
      "  0.6602931  0.66848958]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003319843439385295\n",
      "Predicción post entrenamiento : [[0.6767213]]\n",
      "PERDIDAAAA despues: 0.0034401321318000555\n",
      "loss en el callback: 0.010904135182499886, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.61273676]\n",
      "  [0.62252414]\n",
      "  [0.632402  ]\n",
      "  [0.64238441]\n",
      "  [0.65095413]\n",
      "  [0.6602931 ]\n",
      "  [0.66848958]\n",
      "  [0.67775583]]]\n",
      "ejemplar: [0.61273676 0.62252414 0.632402   0.64238441 0.65095413 0.6602931\n",
      " 0.66848958 0.67775583]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.68487567]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.61273676 0.62252414 0.632402   0.64238441 0.65095413 0.6602931\n",
      "  0.66848958 0.67775583]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006408062763512135\n",
      "Predicción post entrenamiento : [[0.6852107]]\n",
      "PERDIDAAAA despues: 0.0006239561480470002\n",
      "loss en el callback: 0.0017591513460502028, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.62252414]\n",
      "  [0.632402  ]\n",
      "  [0.64238441]\n",
      "  [0.65095413]\n",
      "  [0.6602931 ]\n",
      "  [0.66848958]\n",
      "  [0.67775583]\n",
      "  [0.68487567]]]\n",
      "ejemplar: [0.62252414 0.632402   0.64238441 0.65095413 0.6602931  0.66848958\n",
      " 0.67775583 0.68487567]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6933112]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.62252414 0.632402   0.64238441 0.65095413 0.6602931  0.66848958\n",
      "  0.67775583 0.68487567]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035403715446591377\n",
      "Predicción post entrenamiento : [[0.6941292]]\n",
      "PERDIDAAAA despues: 0.00032392298453487456\n",
      "loss en el callback: 0.01333659514784813, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.632402  ]\n",
      "  [0.64238441]\n",
      "  [0.65095413]\n",
      "  [0.6602931 ]\n",
      "  [0.66848958]\n",
      "  [0.67775583]\n",
      "  [0.68487567]\n",
      "  [0.69331121]]]\n",
      "ejemplar: [0.632402   0.64238441 0.65095413 0.6602931  0.66848958 0.67775583\n",
      " 0.68487567 0.69331121]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.70209396]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.632402   0.64238441 0.65095413 0.6602931  0.66848958 0.67775583\n",
      "  0.68487567 0.69331121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001409391756169498\n",
      "Predicción post entrenamiento : [[0.70170456]]\n",
      "PERDIDAAAA despues: 0.0014387808041647077\n",
      "loss en el callback: 0.0019191759638488293, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.64238441]\n",
      "  [0.65095413]\n",
      "  [0.6602931 ]\n",
      "  [0.66848958]\n",
      "  [0.67775583]\n",
      "  [0.68487567]\n",
      "  [0.69331121]\n",
      "  [0.70209396]]]\n",
      "ejemplar: [0.64238441 0.65095413 0.6602931  0.66848958 0.67775583 0.68487567\n",
      " 0.69331121 0.70209396]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.70944124]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.64238441 0.65095413 0.6602931  0.66848958 0.67775583 0.68487567\n",
      "  0.69331121 0.70209396]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007132921600714326\n",
      "Predicción post entrenamiento : [[0.7092925]]\n",
      "PERDIDAAAA despues: 0.0007212610216811299\n",
      "loss en el callback: 0.0002981797733809799, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.65095413]\n",
      "  [0.6602931 ]\n",
      "  [0.66848958]\n",
      "  [0.67775583]\n",
      "  [0.68487567]\n",
      "  [0.69331121]\n",
      "  [0.70209396]\n",
      "  [0.70944124]]]\n",
      "ejemplar: [0.65095413 0.6602931  0.66848958 0.67775583 0.68487567 0.69331121\n",
      " 0.70209396 0.70944124]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7166988]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.65095413 0.6602931  0.66848958 0.67775583 0.68487567 0.69331121\n",
      "  0.70209396 0.70944124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002413571812212467\n",
      "Predicción post entrenamiento : [[0.7161885]]\n",
      "PERDIDAAAA despues: 0.0023636885453015566\n",
      "loss en el callback: 0.003999884705990553, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.6602931 ]\n",
      "  [0.66848958]\n",
      "  [0.67775583]\n",
      "  [0.68487567]\n",
      "  [0.69331121]\n",
      "  [0.70209396]\n",
      "  [0.70944124]\n",
      "  [0.71669883]]]\n",
      "ejemplar: [0.6602931  0.66848958 0.67775583 0.68487567 0.69331121 0.70209396\n",
      " 0.70944124 0.71669883]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7235788]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.6602931  0.66848958 0.67775583 0.68487567 0.69331121 0.70209396\n",
      "  0.70944124 0.71669883]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002881907392293215\n",
      "Predicción post entrenamiento : [[0.7236505]]\n",
      "PERDIDAAAA despues: 0.002889611292630434\n",
      "loss en el callback: 9.147317905444652e-05, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.66848958]\n",
      "  [0.67775583]\n",
      "  [0.68487567]\n",
      "  [0.69331121]\n",
      "  [0.70209396]\n",
      "  [0.70944124]\n",
      "  [0.71669883]\n",
      "  [0.72357881]]]\n",
      "ejemplar: [0.66848958 0.67775583 0.68487567 0.69331121 0.70209396 0.70944124\n",
      " 0.71669883 0.72357881]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7307696]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.66848958 0.67775583 0.68487567 0.69331121 0.70209396 0.70944124\n",
      "  0.71669883 0.72357881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011655633570626378\n",
      "Predicción post entrenamiento : [[0.7302682]]\n",
      "PERDIDAAAA despues: 0.0011315792798995972\n",
      "loss en el callback: 0.0039697312749922276, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.67775583]\n",
      "  [0.68487567]\n",
      "  [0.69331121]\n",
      "  [0.70209396]\n",
      "  [0.70944124]\n",
      "  [0.71669883]\n",
      "  [0.72357881]\n",
      "  [0.73076957]]]\n",
      "ejemplar: [0.67775583 0.68487567 0.69331121 0.70209396 0.70944124 0.71669883\n",
      " 0.72357881 0.73076957]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7373604]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.67775583 0.68487567 0.69331121 0.70209396 0.70944124 0.71669883\n",
      "  0.72357881 0.73076957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00662809144705534\n",
      "Predicción post entrenamiento : [[0.7366794]]\n",
      "PERDIDAAAA despues: 0.006517663598060608\n",
      "loss en el callback: 0.007775912992656231, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.68487567]\n",
      "  [0.69331121]\n",
      "  [0.70209396]\n",
      "  [0.70944124]\n",
      "  [0.71669883]\n",
      "  [0.72357881]\n",
      "  [0.73076957]\n",
      "  [0.73736042]]]\n",
      "ejemplar: [0.68487567 0.69331121 0.70209396 0.70944124 0.71669883 0.72357881\n",
      " 0.73076957 0.73736042]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7433959]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.68487567 0.69331121 0.70209396 0.70944124 0.71669883 0.72357881\n",
      "  0.73076957 0.73736042]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004171772859990597\n",
      "Predicción post entrenamiento : [[0.7424693]]\n",
      "PERDIDAAAA despues: 0.0040529328398406506\n",
      "loss en el callback: 0.012750936672091484, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.69331121]\n",
      "  [0.70209396]\n",
      "  [0.70944124]\n",
      "  [0.71669883]\n",
      "  [0.72357881]\n",
      "  [0.73076957]\n",
      "  [0.73736042]\n",
      "  [0.74339592]]]\n",
      "ejemplar: [0.69331121 0.70209396 0.70944124 0.71669883 0.72357881 0.73076957\n",
      " 0.73736042 0.74339592]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7493242]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.69331121 0.70209396 0.70944124 0.71669883 0.72357881 0.73076957\n",
      "  0.73736042 0.74339592]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005362584721297026\n",
      "Predicción post entrenamiento : [[0.74838525]]\n",
      "PERDIDAAAA despues: 0.005225948058068752\n",
      "loss en el callback: 0.013552194461226463, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.70209396]\n",
      "  [0.70944124]\n",
      "  [0.71669883]\n",
      "  [0.72357881]\n",
      "  [0.73076957]\n",
      "  [0.73736042]\n",
      "  [0.74339592]\n",
      "  [0.7493242 ]]]\n",
      "ejemplar: [0.70209396 0.70944124 0.71669883 0.72357881 0.73076957 0.73736042\n",
      " 0.74339592 0.7493242 ]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7549742]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.70209396 0.70944124 0.71669883 0.72357881 0.73076957 0.73736042\n",
      "  0.74339592 0.7493242 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006457709241658449\n",
      "Predicción post entrenamiento : [[0.7550068]]\n",
      "PERDIDAAAA despues: 0.000647429027594626\n",
      "loss en el callback: 1.7877964637591504e-05, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.70944124]\n",
      "  [0.71669883]\n",
      "  [0.72357881]\n",
      "  [0.73076957]\n",
      "  [0.73736042]\n",
      "  [0.74339592]\n",
      "  [0.7493242 ]\n",
      "  [0.75497419]]]\n",
      "ejemplar: [0.70944124 0.71669883 0.72357881 0.73076957 0.73736042 0.74339592\n",
      " 0.7493242  0.75497419]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7611392]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.70944124 0.71669883 0.72357881 0.73076957 0.73736042 0.74339592\n",
      "  0.7493242  0.75497419]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035832971334457397\n",
      "Predicción post entrenamiento : [[0.75990826]]\n",
      "PERDIDAAAA despues: 0.0034374408423900604\n",
      "loss en el callback: 0.021318914368748665, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.71669883]\n",
      "  [0.72357881]\n",
      "  [0.73076957]\n",
      "  [0.73736042]\n",
      "  [0.74339592]\n",
      "  [0.7493242 ]\n",
      "  [0.75497419]\n",
      "  [0.76113921]]]\n",
      "ejemplar: [0.71669883 0.72357881 0.73076957 0.73736042 0.74339592 0.7493242\n",
      " 0.75497419 0.76113921]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.76588047]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.71669883 0.72357881 0.73076957 0.73736042 0.74339592 0.7493242\n",
      "  0.75497419 0.76113921]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.7275364118395373e-06\n",
      "Predicción post entrenamiento : [[0.76574033]]\n",
      "PERDIDAAAA despues: 3.2100313092087163e-06\n",
      "loss en el callback: 0.00035787635715678334, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.72357881]\n",
      "  [0.73076957]\n",
      "  [0.73736042]\n",
      "  [0.74339592]\n",
      "  [0.7493242 ]\n",
      "  [0.75497419]\n",
      "  [0.76113921]\n",
      "  [0.76588047]]]\n",
      "ejemplar: [0.72357881 0.73076957 0.73736042 0.74339592 0.7493242  0.75497419\n",
      " 0.76113921 0.76588047]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.77151483]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.72357881 0.73076957 0.73736042 0.74339592 0.7493242  0.75497419\n",
      "  0.76113921 0.76588047]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026834188611246645\n",
      "Predicción post entrenamiento : [[0.77227056]]\n",
      "PERDIDAAAA despues: 0.0002936723758466542\n",
      "loss en el callback: 0.012856650166213512, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.73076957]\n",
      "  [0.73736042]\n",
      "  [0.74339592]\n",
      "  [0.7493242 ]\n",
      "  [0.75497419]\n",
      "  [0.76113921]\n",
      "  [0.76588047]\n",
      "  [0.77151483]]]\n",
      "ejemplar: [0.73076957 0.73736042 0.74339592 0.7493242  0.75497419 0.76113921\n",
      " 0.76588047 0.77151483]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7778877]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.73076957 0.73736042 0.74339592 0.7493242  0.75497419 0.76113921\n",
      "  0.76588047 0.77151483]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00107765628490597\n",
      "Predicción post entrenamiento : [[0.7777449]]\n",
      "PERDIDAAAA despues: 0.001068300218321383\n",
      "loss en el callback: 0.0003733019984792918, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.73736042]\n",
      "  [0.74339592]\n",
      "  [0.7493242 ]\n",
      "  [0.75497419]\n",
      "  [0.76113921]\n",
      "  [0.76588047]\n",
      "  [0.77151483]\n",
      "  [0.7778877 ]]]\n",
      "ejemplar: [0.73736042 0.74339592 0.7493242  0.75497419 0.76113921 0.76588047\n",
      " 0.77151483 0.7778877 ]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.78305805]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.73736042 0.74339592 0.7493242  0.75497419 0.76113921 0.76588047\n",
      "  0.77151483 0.7778877 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009624873055145144\n",
      "Predicción post entrenamiento : [[0.7825817]]\n",
      "PERDIDAAAA despues: 0.0009331570472568274\n",
      "loss en el callback: 0.003729271236807108, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.74339592]\n",
      "  [0.7493242 ]\n",
      "  [0.75497419]\n",
      "  [0.76113921]\n",
      "  [0.76588047]\n",
      "  [0.77151483]\n",
      "  [0.7778877 ]\n",
      "  [0.78305805]]]\n",
      "ejemplar: [0.74339592 0.7493242  0.75497419 0.76113921 0.76588047 0.77151483\n",
      " 0.7778877  0.78305805]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.787695]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.74339592 0.7493242  0.75497419 0.76113921 0.76588047 0.77151483\n",
      "  0.7778877  0.78305805]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00606725737452507\n",
      "Predicción post entrenamiento : [[0.78603387]]\n",
      "PERDIDAAAA despues: 0.005811238661408424\n",
      "loss en el callback: 0.0393105074763298, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.7493242 ]\n",
      "  [0.75497419]\n",
      "  [0.76113921]\n",
      "  [0.76588047]\n",
      "  [0.77151483]\n",
      "  [0.7778877 ]\n",
      "  [0.78305805]\n",
      "  [0.78769499]]]\n",
      "ejemplar: [0.7493242  0.75497419 0.76113921 0.76588047 0.77151483 0.7778877\n",
      " 0.78305805 0.78769499]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7910572]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.7493242  0.75497419 0.76113921 0.76588047 0.77151483 0.7778877\n",
      "  0.78305805 0.78769499]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010125829838216305\n",
      "Predicción post entrenamiento : [[0.78977257]]\n",
      "PERDIDAAAA despues: 0.00986893754452467\n",
      "loss en el callback: 0.025938915088772774, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.75497419]\n",
      "  [0.76113921]\n",
      "  [0.76588047]\n",
      "  [0.77151483]\n",
      "  [0.7778877 ]\n",
      "  [0.78305805]\n",
      "  [0.78769499]\n",
      "  [0.79105723]]]\n",
      "ejemplar: [0.75497419 0.76113921 0.76588047 0.77151483 0.7778877  0.78305805\n",
      " 0.78769499 0.79105723]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7946975]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.75497419 0.76113921 0.76588047 0.77151483 0.7778877  0.78305805\n",
      "  0.78769499 0.79105723]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016272151842713356\n",
      "Predicción post entrenamiento : [[0.79445755]]\n",
      "PERDIDAAAA despues: 0.001607912709005177\n",
      "loss en el callback: 0.0010272263316437602, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.76113921]\n",
      "  [0.76588047]\n",
      "  [0.77151483]\n",
      "  [0.7778877 ]\n",
      "  [0.78305805]\n",
      "  [0.78769499]\n",
      "  [0.79105723]\n",
      "  [0.79469752]]]\n",
      "ejemplar: [0.76113921 0.76588047 0.77151483 0.7778877  0.78305805 0.78769499\n",
      " 0.79105723 0.79469752]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7993128]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.76113921 0.76588047 0.77151483 0.7778877  0.78305805 0.78769499\n",
      "  0.79105723 0.79469752]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059462725184857845\n",
      "Predicción post entrenamiento : [[0.7982897]]\n",
      "PERDIDAAAA despues: 0.005789539776742458\n",
      "loss en el callback: 0.01756932958960533, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.76588047]\n",
      "  [0.77151483]\n",
      "  [0.7778877 ]\n",
      "  [0.78305805]\n",
      "  [0.78769499]\n",
      "  [0.79105723]\n",
      "  [0.79469752]\n",
      "  [0.79931277]]]\n",
      "ejemplar: [0.76588047 0.77151483 0.7778877  0.78305805 0.78769499 0.79105723\n",
      " 0.79469752 0.79931277]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.80287004]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.76588047 0.77151483 0.7778877  0.78305805 0.78769499 0.79105723\n",
      "  0.79469752 0.79931277]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020828566048294306\n",
      "Predicción post entrenamiento : [[0.80241024]]\n",
      "PERDIDAAAA despues: 0.002125035971403122\n",
      "loss en el callback: 0.0032964625861495733, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.77151483]\n",
      "  [0.7778877 ]\n",
      "  [0.78305805]\n",
      "  [0.78769499]\n",
      "  [0.79105723]\n",
      "  [0.79469752]\n",
      "  [0.79931277]\n",
      "  [0.80287004]]]\n",
      "ejemplar: [0.77151483 0.7778877  0.78305805 0.78769499 0.79105723 0.79469752\n",
      " 0.79931277 0.80287004]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8070437]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.77151483 0.7778877  0.78305805 0.78769499 0.79105723 0.79469752\n",
      "  0.79931277 0.80287004]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009686360135674477\n",
      "Predicción post entrenamiento : [[0.80769795]]\n",
      "PERDIDAAAA despues: 0.009558000601828098\n",
      "loss en el callback: 0.007876996882259846, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.7778877 ]\n",
      "  [0.78305805]\n",
      "  [0.78769499]\n",
      "  [0.79105723]\n",
      "  [0.79469752]\n",
      "  [0.79931277]\n",
      "  [0.80287004]\n",
      "  [0.80704367]]]\n",
      "ejemplar: [0.7778877  0.78305805 0.78769499 0.79105723 0.79469752 0.79931277\n",
      " 0.80287004 0.80704367]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8120867]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.7778877  0.78305805 0.78769499 0.79105723 0.79469752 0.79931277\n",
      "  0.80287004 0.80704367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0049181487411260605\n",
      "Predicción post entrenamiento : [[0.8132746]]\n",
      "PERDIDAAAA despues: 0.00475294329226017\n",
      "loss en el callback: 0.03168904036283493, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.78305805]\n",
      "  [0.78769499]\n",
      "  [0.79105723]\n",
      "  [0.79469752]\n",
      "  [0.79931277]\n",
      "  [0.80287004]\n",
      "  [0.80704367]\n",
      "  [0.8120867 ]]]\n",
      "ejemplar: [0.78305805 0.78769499 0.79105723 0.79469752 0.79931277 0.80287004\n",
      " 0.80704367 0.8120867 ]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.81713104]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.78305805 0.78769499 0.79105723 0.79469752 0.79931277 0.80287004\n",
      "  0.80704367 0.8120867 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008218626491725445\n",
      "Predicción post entrenamiento : [[0.8170273]]\n",
      "PERDIDAAAA despues: 0.008237452246248722\n",
      "loss en el callback: 0.0001776805002009496, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.78769499]\n",
      "  [0.79105723]\n",
      "  [0.79469752]\n",
      "  [0.79931277]\n",
      "  [0.80287004]\n",
      "  [0.80704367]\n",
      "  [0.8120867 ]\n",
      "  [0.81713104]]]\n",
      "ejemplar: [0.78769499 0.79105723 0.79469752 0.79931277 0.80287004 0.80704367\n",
      " 0.8120867  0.81713104]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.82061136]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.78769499 0.79105723 0.79469752 0.79931277 0.80287004 0.80704367\n",
      "  0.8120867  0.81713104]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047563547268509865\n",
      "Predicción post entrenamiento : [[0.8210085]]\n",
      "PERDIDAAAA despues: 0.004701733123511076\n",
      "loss en el callback: 0.0028230282478034496, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.79105723]\n",
      "  [0.79469752]\n",
      "  [0.79931277]\n",
      "  [0.80287004]\n",
      "  [0.80704367]\n",
      "  [0.8120867 ]\n",
      "  [0.81713104]\n",
      "  [0.82061136]]]\n",
      "ejemplar: [0.79105723 0.79469752 0.79931277 0.80287004 0.80704367 0.8120867\n",
      " 0.81713104 0.82061136]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.82444406]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.79105723 0.79469752 0.79931277 0.80287004 0.80704367 0.8120867\n",
      "  0.81713104 0.82061136]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002541231457144022\n",
      "Predicción post entrenamiento : [[0.82546276]]\n",
      "PERDIDAAAA despues: 0.0024395622313022614\n",
      "loss en el callback: 0.02559014782309532, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.79469752]\n",
      "  [0.79931277]\n",
      "  [0.80287004]\n",
      "  [0.80704367]\n",
      "  [0.8120867 ]\n",
      "  [0.81713104]\n",
      "  [0.82061136]\n",
      "  [0.82444406]]]\n",
      "ejemplar: [0.79469752 0.79931277 0.80287004 0.80704367 0.8120867  0.81713104\n",
      " 0.82061136 0.82444406]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.82911366]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.79469752 0.79931277 0.80287004 0.80704367 0.8120867  0.81713104\n",
      "  0.82061136 0.82444406]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007072520442306995\n",
      "Predicción post entrenamiento : [[0.8298957]]\n",
      "PERDIDAAAA despues: 0.006941600237041712\n",
      "loss en el callback: 0.012656078673899174, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.79931277]\n",
      "  [0.80287004]\n",
      "  [0.80704367]\n",
      "  [0.8120867 ]\n",
      "  [0.81713104]\n",
      "  [0.82061136]\n",
      "  [0.82444406]\n",
      "  [0.82911366]]]\n",
      "ejemplar: [0.79931277 0.80287004 0.80704367 0.8120867  0.81713104 0.82061136\n",
      " 0.82444406 0.82911366]\n",
      "y: 1.0\n",
      "Predicción : [[0.8337212]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.79931277 0.80287004 0.80704367 0.8120867  0.81713104 0.82061136\n",
      "  0.82444406 0.82911366]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02764863334596157\n",
      "Predicción post entrenamiento : [[0.8341674]]\n",
      "PERDIDAAAA despues: 0.027500445023179054\n",
      "loss en el callback: 0.0035119112581014633, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.80287004]\n",
      "  [0.80704367]\n",
      "  [0.8120867 ]\n",
      "  [0.81713104]\n",
      "  [0.82061136]\n",
      "  [0.82444406]\n",
      "  [0.82911366]\n",
      "  [0.83372122]]]\n",
      "ejemplar: [0.80287004 0.80704367 0.8120867  0.81713104 0.82061136 0.82444406\n",
      " 0.82911366 0.83372122]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.83791137]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.80287004 0.80704367 0.8120867  0.81713104 0.82061136 0.82444406\n",
      "  0.82911366 0.83372122]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01759408228099346\n",
      "Predicción post entrenamiento : [[0.8383264]]\n",
      "PERDIDAAAA despues: 0.017484154552221298\n",
      "loss en el callback: 0.003048169892281294, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.80704367]\n",
      "  [0.8120867 ]\n",
      "  [0.81713104]\n",
      "  [0.82061136]\n",
      "  [0.82444406]\n",
      "  [0.82911366]\n",
      "  [0.83372122]\n",
      "  [0.83791137]]]\n",
      "ejemplar: [0.80704367 0.8120867  0.81713104 0.82061136 0.82444406 0.82911366\n",
      " 0.83372122 0.83791137]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8422884]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.80704367 0.8120867  0.81713104 0.82061136 0.82444406 0.82911366\n",
      "  0.83372122 0.83791137]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021635887678712606\n",
      "Predicción post entrenamiento : [[0.8420559]]\n",
      "PERDIDAAAA despues: 0.0021852680947631598\n",
      "loss en el callback: 0.0009264758555218577, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.8120867 ]\n",
      "  [0.81713104]\n",
      "  [0.82061136]\n",
      "  [0.82444406]\n",
      "  [0.82911366]\n",
      "  [0.83372122]\n",
      "  [0.83791137]\n",
      "  [0.84228837]]]\n",
      "ejemplar: [0.8120867  0.81713104 0.82061136 0.82444406 0.82911366 0.83372122\n",
      " 0.83791137 0.84228837]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.84608346]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.8120867  0.81713104 0.82061136 0.82444406 0.82911366 0.83372122\n",
      "  0.83791137 0.84228837]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010157505748793483\n",
      "Predicción post entrenamiento : [[0.84680533]]\n",
      "PERDIDAAAA despues: 0.0009702583192847669\n",
      "loss en el callback: 0.013196666724979877, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.81713104]\n",
      "  [0.82061136]\n",
      "  [0.82444406]\n",
      "  [0.82911366]\n",
      "  [0.83372122]\n",
      "  [0.83791137]\n",
      "  [0.84228837]\n",
      "  [0.84608346]]]\n",
      "ejemplar: [0.81713104 0.82061136 0.82444406 0.82911366 0.83372122 0.83791137\n",
      " 0.84228837 0.84608346]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8506439]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.81713104 0.82061136 0.82444406 0.82911366 0.83372122 0.83791137\n",
      "  0.84228837 0.84608346]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.055801244045142e-06\n",
      "Predicción post entrenamiento : [[0.85010815]]\n",
      "PERDIDAAAA despues: 1.4698130144097377e-06\n",
      "loss en el callback: 0.00486353412270546, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.82061136]\n",
      "  [0.82444406]\n",
      "  [0.82911366]\n",
      "  [0.83372122]\n",
      "  [0.83791137]\n",
      "  [0.84228837]\n",
      "  [0.84608346]\n",
      "  [0.85064387]]]\n",
      "ejemplar: [0.82061136 0.82444406 0.82911366 0.83372122 0.83791137 0.84228837\n",
      " 0.84608346 0.85064387]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8537239]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.82061136 0.82444406 0.82911366 0.83372122 0.83791137 0.84228837\n",
      "  0.84608346 0.85064387]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003822454600594938\n",
      "Predicción post entrenamiento : [[0.8542624]]\n",
      "PERDIDAAAA despues: 0.0004035930905956775\n",
      "loss en el callback: 0.007646516896784306, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.82444406]\n",
      "  [0.82911366]\n",
      "  [0.83372122]\n",
      "  [0.83791137]\n",
      "  [0.84228837]\n",
      "  [0.84608346]\n",
      "  [0.85064387]\n",
      "  [0.85372388]]]\n",
      "ejemplar: [0.82444406 0.82911366 0.83372122 0.83791137 0.84228837 0.84608346\n",
      " 0.85064387 0.85372388]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8580824]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.82444406 0.82911366 0.83372122 0.83791137 0.84228837 0.84608346\n",
      "  0.85064387 0.85372388]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.925179827201646e-06\n",
      "Predicción post entrenamiento : [[0.85619]]\n",
      "PERDIDAAAA despues: 1.199279381580709e-06\n",
      "loss en el callback: 0.05457058548927307, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.82911366]\n",
      "  [0.83372122]\n",
      "  [0.83791137]\n",
      "  [0.84228837]\n",
      "  [0.84608346]\n",
      "  [0.85064387]\n",
      "  [0.85372388]\n",
      "  [0.85808241]]]\n",
      "ejemplar: [0.82911366 0.83372122 0.83791137 0.84228837 0.84608346 0.85064387\n",
      " 0.85372388 0.85808241]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.86012965]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.82911366 0.83372122 0.83791137 0.84228837 0.84608346 0.85064387\n",
      "  0.85372388 0.85808241]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002283882349729538\n",
      "Predicción post entrenamiento : [[0.86087435]]\n",
      "PERDIDAAAA despues: 0.0002064342115772888\n",
      "loss en el callback: 0.01528459507972002, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.83372122]\n",
      "  [0.83791137]\n",
      "  [0.84228837]\n",
      "  [0.84608346]\n",
      "  [0.85064387]\n",
      "  [0.85372388]\n",
      "  [0.85808241]\n",
      "  [0.86012965]]]\n",
      "ejemplar: [0.83372122 0.83791137 0.84228837 0.84608346 0.85064387 0.85372388\n",
      " 0.85808241 0.86012965]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8646828]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.83372122 0.83791137 0.84228837 0.84608346 0.85064387 0.85372388\n",
      "  0.85808241 0.86012965]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.853189213667065e-05\n",
      "Predicción post entrenamiento : [[0.86446834]]\n",
      "PERDIDAAAA despues: 5.529641930479556e-05\n",
      "loss en el callback: 0.000922014529351145, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.83791137]\n",
      "  [0.84228837]\n",
      "  [0.84608346]\n",
      "  [0.85064387]\n",
      "  [0.85372388]\n",
      "  [0.85808241]\n",
      "  [0.86012965]\n",
      "  [0.86468279]]]\n",
      "ejemplar: [0.83791137 0.84228837 0.84608346 0.85064387 0.85372388 0.85808241\n",
      " 0.86012965 0.86468279]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8681172]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.83791137 0.84228837 0.84608346 0.85064387 0.85372388 0.85808241\n",
      "  0.86012965 0.86468279]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003261301899328828\n",
      "Predicción post entrenamiento : [[0.86734897]]\n",
      "PERDIDAAAA despues: 0.00029897282365709543\n",
      "loss en el callback: 0.010636592283844948, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.84228837]\n",
      "  [0.84608346]\n",
      "  [0.85064387]\n",
      "  [0.85372388]\n",
      "  [0.85808241]\n",
      "  [0.86012965]\n",
      "  [0.86468279]\n",
      "  [0.86811721]]]\n",
      "ejemplar: [0.84228837 0.84608346 0.85064387 0.85372388 0.85808241 0.86012965\n",
      " 0.86468279 0.86811721]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.87091565]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.84228837 0.84608346 0.85064387 0.85372388 0.85808241 0.86012965\n",
      "  0.86468279 0.86811721]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007963144453242421\n",
      "Predicción post entrenamiento : [[0.8701477]]\n",
      "PERDIDAAAA despues: 0.0007535627810284495\n",
      "loss en el callback: 0.011349596083164215, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.84608346]\n",
      "  [0.85064387]\n",
      "  [0.85372388]\n",
      "  [0.85808241]\n",
      "  [0.86012965]\n",
      "  [0.86468279]\n",
      "  [0.86811721]\n",
      "  [0.87091565]]]\n",
      "ejemplar: [0.84608346 0.85064387 0.85372388 0.85808241 0.86012965 0.86468279\n",
      " 0.86811721 0.87091565]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.87354296]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.84608346 0.85064387 0.85372388 0.85808241 0.86012965 0.86468279\n",
      "  0.86811721 0.87091565]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025609806180000305\n",
      "Predicción post entrenamiento : [[0.8722379]]\n",
      "PERDIDAAAA despues: 0.0024305973201990128\n",
      "loss en el callback: 0.031166061758995056, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.85064387]\n",
      "  [0.85372388]\n",
      "  [0.85808241]\n",
      "  [0.86012965]\n",
      "  [0.86468279]\n",
      "  [0.86811721]\n",
      "  [0.87091565]\n",
      "  [0.87354296]]]\n",
      "ejemplar: [0.85064387 0.85372388 0.85808241 0.86012965 0.86468279 0.86811721\n",
      " 0.87091565 0.87354296]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8755841]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.85064387 0.85372388 0.85808241 0.86012965 0.86468279 0.86811721\n",
      "  0.87091565 0.87354296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010216780938208103\n",
      "Predicción post entrenamiento : [[0.8744406]]\n",
      "PERDIDAAAA despues: 0.009986920282244682\n",
      "loss en el callback: 0.025638742372393608, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.85372388]\n",
      "  [0.85808241]\n",
      "  [0.86012965]\n",
      "  [0.86468279]\n",
      "  [0.86811721]\n",
      "  [0.87091565]\n",
      "  [0.87354296]\n",
      "  [0.87558413]]]\n",
      "ejemplar: [0.85372388 0.85808241 0.86012965 0.86468279 0.86811721 0.87091565\n",
      " 0.87354296 0.87558413]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8774746]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.85372388 0.85808241 0.86012965 0.86468279 0.86811721 0.87091565\n",
      "  0.87354296 0.87558413]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008701617829501629\n",
      "Predicción post entrenamiento : [[0.8768201]]\n",
      "PERDIDAAAA despues: 0.008579935878515244\n",
      "loss en el callback: 0.009821600280702114, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.85808241]\n",
      "  [0.86012965]\n",
      "  [0.86468279]\n",
      "  [0.86811721]\n",
      "  [0.87091565]\n",
      "  [0.87354296]\n",
      "  [0.87558413]\n",
      "  [0.87747461]]]\n",
      "ejemplar: [0.85808241 0.86012965 0.86468279 0.86811721 0.87091565 0.87354296\n",
      " 0.87558413 0.87747461]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.87990266]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.85808241 0.86012965 0.86468279 0.86811721 0.87091565 0.87354296\n",
      "  0.87558413 0.87747461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000406359089538455\n",
      "Predicción post entrenamiento : [[0.8799012]]\n",
      "PERDIDAAAA despues: 0.0004062990192323923\n",
      "loss en el callback: 6.617943881792598e-08, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.86012965]\n",
      "  [0.86468279]\n",
      "  [0.86811721]\n",
      "  [0.87091565]\n",
      "  [0.87354296]\n",
      "  [0.87558413]\n",
      "  [0.87747461]\n",
      "  [0.87990266]]]\n",
      "ejemplar: [0.86012965 0.86468279 0.86811721 0.87091565 0.87354296 0.87558413\n",
      " 0.87747461 0.87990266]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8826252]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.86012965 0.86468279 0.86811721 0.87091565 0.87354296 0.87558413\n",
      "  0.87747461 0.87990266]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008011828176677227\n",
      "Predicción post entrenamiento : [[0.8820864]]\n",
      "PERDIDAAAA despues: 0.0007709700148552656\n",
      "loss en el callback: 0.00601911498233676, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.86468279]\n",
      "  [0.86811721]\n",
      "  [0.87091565]\n",
      "  [0.87354296]\n",
      "  [0.87558413]\n",
      "  [0.87747461]\n",
      "  [0.87990266]\n",
      "  [0.88262522]]]\n",
      "ejemplar: [0.86468279 0.86811721 0.87091565 0.87354296 0.87558413 0.87747461\n",
      " 0.87990266 0.88262522]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.88505137]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.86468279 0.86811721 0.87091565 0.87354296 0.87558413 0.87747461\n",
      "  0.87990266 0.88262522]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002320007188245654\n",
      "Predicción post entrenamiento : [[0.8859081]]\n",
      "PERDIDAAAA despues: 0.0024032751098275185\n",
      "loss en el callback: 0.028132224455475807, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.86811721]\n",
      "  [0.87091565]\n",
      "  [0.87354296]\n",
      "  [0.87558413]\n",
      "  [0.87747461]\n",
      "  [0.87990266]\n",
      "  [0.88262522]\n",
      "  [0.88505137]]]\n",
      "ejemplar: [0.86811721 0.87091565 0.87354296 0.87558413 0.87747461 0.87990266\n",
      " 0.88262522 0.88505137]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8883748]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.86811721 0.87091565 0.87354296 0.87558413 0.87747461 0.87990266\n",
      "  0.88262522 0.88505137]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034180311486124992\n",
      "Predicción post entrenamiento : [[0.88846844]]\n",
      "PERDIDAAAA despues: 0.003428989090025425\n",
      "loss en el callback: 0.00025076192105188966, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.87091565]\n",
      "  [0.87354296]\n",
      "  [0.87558413]\n",
      "  [0.87747461]\n",
      "  [0.87990266]\n",
      "  [0.88262522]\n",
      "  [0.88505137]\n",
      "  [0.88837481]]]\n",
      "ejemplar: [0.87091565 0.87354296 0.87558413 0.87747461 0.87990266 0.88262522\n",
      " 0.88505137 0.88837481]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.8906781]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.87091565 0.87354296 0.87558413 0.87747461 0.87990266 0.88262522\n",
      "  0.88505137 0.88837481]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1731455742847174e-05\n",
      "Predicción post entrenamiento : [[0.8911648]]\n",
      "PERDIDAAAA despues: 1.530212648503948e-05\n",
      "loss en el callback: 0.006916881538927555, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.87354296]\n",
      "  [0.87558413]\n",
      "  [0.87747461]\n",
      "  [0.87990266]\n",
      "  [0.88262522]\n",
      "  [0.88505137]\n",
      "  [0.88837481]\n",
      "  [0.89067811]]]\n",
      "ejemplar: [0.87354296 0.87558413 0.87747461 0.87990266 0.88262522 0.88505137\n",
      " 0.88837481 0.89067811]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.89326954]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.87354296 0.87558413 0.87747461 0.87990266 0.88262522 0.88505137\n",
      "  0.88837481 0.89067811]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011239409213885665\n",
      "Predicción post entrenamiento : [[0.8918955]]\n",
      "PERDIDAAAA despues: 0.0010336972773075104\n",
      "loss en el callback: 0.03738047182559967, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.87558413]\n",
      "  [0.87747461]\n",
      "  [0.87990266]\n",
      "  [0.88262522]\n",
      "  [0.88505137]\n",
      "  [0.88837481]\n",
      "  [0.89067811]\n",
      "  [0.89326954]]]\n",
      "ejemplar: [0.87558413 0.87747461 0.87990266 0.88262522 0.88505137 0.88837481\n",
      " 0.89067811 0.89326954]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.89393884]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.87558413 0.87747461 0.87990266 0.88262522 0.88505137 0.88837481\n",
      "  0.89067811 0.89326954]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002953030401840806\n",
      "Predicción post entrenamiento : [[0.8921711]]\n",
      "PERDIDAAAA despues: 0.0027640294283628464\n",
      "loss en el callback: 0.05643598735332489, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.87747461]\n",
      "  [0.87990266]\n",
      "  [0.88262522]\n",
      "  [0.88505137]\n",
      "  [0.88837481]\n",
      "  [0.89067811]\n",
      "  [0.89326954]\n",
      "  [0.89393884]]]\n",
      "ejemplar: [0.87747461 0.87990266 0.88262522 0.88505137 0.88837481 0.89067811\n",
      " 0.89326954 0.89393884]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.8943205]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.87747461 0.87990266 0.88262522 0.88505137 0.88837481 0.89067811\n",
      "  0.89326954 0.89393884]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012213735841214657\n",
      "Predicción post entrenamiento : [[0.8943203]]\n",
      "PERDIDAAAA despues: 0.012213696725666523\n",
      "loss en el callback: 1.9877575141435955e-09, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.87990266]\n",
      "  [0.88262522]\n",
      "  [0.88505137]\n",
      "  [0.88837481]\n",
      "  [0.89067811]\n",
      "  [0.89326954]\n",
      "  [0.89393884]\n",
      "  [0.89432049]]]\n",
      "ejemplar: [0.87990266 0.88262522 0.88505137 0.88837481 0.89067811 0.89326954\n",
      " 0.89393884 0.89432049]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8966197]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.87990266 0.88262522 0.88505137 0.88837481 0.89067811 0.89326954\n",
      "  0.89393884 0.89432049]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006135931238532066\n",
      "Predicción post entrenamiento : [[0.8949046]]\n",
      "PERDIDAAAA despues: 0.0058701834641397\n",
      "loss en el callback: 0.05921424552798271, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.88262522]\n",
      "  [0.88505137]\n",
      "  [0.88837481]\n",
      "  [0.89067811]\n",
      "  [0.89326954]\n",
      "  [0.89393884]\n",
      "  [0.89432049]\n",
      "  [0.89661968]]]\n",
      "ejemplar: [0.88262522 0.88505137 0.88837481 0.89067811 0.89326954 0.89393884\n",
      " 0.89432049 0.89661968]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.8971846]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.88262522 0.88505137 0.88837481 0.89067811 0.89326954 0.89393884\n",
      "  0.89432049 0.89661968]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011239905841648579\n",
      "Predicción post entrenamiento : [[0.8968643]]\n",
      "PERDIDAAAA despues: 0.011172089725732803\n",
      "loss en el callback: 0.003288192907348275, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.88505137]\n",
      "  [0.88837481]\n",
      "  [0.89067811]\n",
      "  [0.89326954]\n",
      "  [0.89393884]\n",
      "  [0.89432049]\n",
      "  [0.89661968]\n",
      "  [0.89718461]]]\n",
      "ejemplar: [0.88505137 0.88837481 0.89067811 0.89326954 0.89393884 0.89432049\n",
      " 0.89661968 0.89718461]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8989914]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.88505137 0.88837481 0.89067811 0.89326954 0.89393884 0.89432049\n",
      "  0.89661968 0.89718461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019163822755217552\n",
      "Predicción post entrenamiento : [[0.89864516]]\n",
      "PERDIDAAAA despues: 0.019068079069256783\n",
      "loss en el callback: 0.003593279980123043, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.88837481]\n",
      "  [0.89067811]\n",
      "  [0.89326954]\n",
      "  [0.89393884]\n",
      "  [0.89432049]\n",
      "  [0.89661968]\n",
      "  [0.89718461]\n",
      "  [0.89899141]]]\n",
      "ejemplar: [0.88837481 0.89067811 0.89326954 0.89393884 0.89432049 0.89661968\n",
      " 0.89718461 0.89899141]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9006417]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.88837481 0.89067811 0.89326954 0.89393884 0.89432049 0.89661968\n",
      "  0.89718461 0.89899141]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011900192126631737\n",
      "Predicción post entrenamiento : [[0.8993672]]\n",
      "PERDIDAAAA despues: 0.01162375882267952\n",
      "loss en el callback: 0.037356045097112656, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.89067811]\n",
      "  [0.89326954]\n",
      "  [0.89393884]\n",
      "  [0.89432049]\n",
      "  [0.89661968]\n",
      "  [0.89718461]\n",
      "  [0.89899141]\n",
      "  [0.90064168]]]\n",
      "ejemplar: [0.89067811 0.89326954 0.89393884 0.89432049 0.89661968 0.89718461\n",
      " 0.89899141 0.90064168]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9009104]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.89067811 0.89326954 0.89393884 0.89432049 0.89661968 0.89718461\n",
      "  0.89899141 0.90064168]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01748109608888626\n",
      "Predicción post entrenamiento : [[0.9009323]]\n",
      "PERDIDAAAA despues: 0.017486896365880966\n",
      "loss en el callback: 1.714173413347453e-05, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.89326954]\n",
      "  [0.89393884]\n",
      "  [0.89432049]\n",
      "  [0.89661968]\n",
      "  [0.89718461]\n",
      "  [0.89899141]\n",
      "  [0.90064168]\n",
      "  [0.90091038]]]\n",
      "ejemplar: [0.89326954 0.89393884 0.89432049 0.89661968 0.89718461 0.89899141\n",
      " 0.90064168 0.90091038]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9022327]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.89326954 0.89393884 0.89432049 0.89661968 0.89718461 0.89899141\n",
      "  0.90064168 0.90091038]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01783251017332077\n",
      "Predicción post entrenamiento : [[0.9015523]]\n",
      "PERDIDAAAA despues: 0.017651258036494255\n",
      "loss en el callback: 0.012530449777841568, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.89393884]\n",
      "  [0.89432049]\n",
      "  [0.89661968]\n",
      "  [0.89718461]\n",
      "  [0.89899141]\n",
      "  [0.90064168]\n",
      "  [0.90091038]\n",
      "  [0.90223271]]]\n",
      "ejemplar: [0.89393884 0.89432049 0.89661968 0.89718461 0.89899141 0.90064168\n",
      " 0.90091038 0.90223271]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9024765]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.89393884 0.89432049 0.89661968 0.89718461 0.89899141 0.90064168\n",
      "  0.90091038 0.90223271]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010724951513111591\n",
      "Predicción post entrenamiento : [[0.90211445]]\n",
      "PERDIDAAAA despues: 0.010650096461176872\n",
      "loss en el callback: 0.0038179585244506598, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.89432049]\n",
      "  [0.89661968]\n",
      "  [0.89718461]\n",
      "  [0.89899141]\n",
      "  [0.90064168]\n",
      "  [0.90091038]\n",
      "  [0.90223271]\n",
      "  [0.90247649]]]\n",
      "ejemplar: [0.89432049 0.89661968 0.89718461 0.89899141 0.90064168 0.90091038\n",
      " 0.90223271 0.90247649]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9031738]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.89432049 0.89661968 0.89718461 0.89899141 0.90064168 0.90091038\n",
      "  0.90223271 0.90247649]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012807427905499935\n",
      "Predicción post entrenamiento : [[0.9026089]]\n",
      "PERDIDAAAA despues: 0.012679880484938622\n",
      "loss en el callback: 0.009408722631633282, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.89661968]\n",
      "  [0.89718461]\n",
      "  [0.89899141]\n",
      "  [0.90064168]\n",
      "  [0.90091038]\n",
      "  [0.90223271]\n",
      "  [0.90247649]\n",
      "  [0.9031738 ]]]\n",
      "ejemplar: [0.89661968 0.89718461 0.89899141 0.90064168 0.90091038 0.90223271\n",
      " 0.90247649 0.9031738 ]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.903898]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.89661968 0.89718461 0.89899141 0.90064168 0.90091038 0.90223271\n",
      "  0.90247649 0.9031738 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020657606422901154\n",
      "Predicción post entrenamiento : [[0.9032417]]\n",
      "PERDIDAAAA despues: 0.02046937867999077\n",
      "loss en el callback: 0.01335693709552288, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.89718461]\n",
      "  [0.89899141]\n",
      "  [0.90064168]\n",
      "  [0.90091038]\n",
      "  [0.90223271]\n",
      "  [0.90247649]\n",
      "  [0.9031738 ]\n",
      "  [0.903898  ]]]\n",
      "ejemplar: [0.89718461 0.89899141 0.90064168 0.90091038 0.90223271 0.90247649\n",
      " 0.9031738  0.903898  ]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.90420294]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.89718461 0.89899141 0.90064168 0.90091038 0.90223271 0.90247649\n",
      "  0.9031738  0.903898  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04787766933441162\n",
      "Predicción post entrenamiento : [[0.9030374]]\n",
      "PERDIDAAAA despues: 0.04736897721886635\n",
      "loss en el callback: 0.03916832432150841, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.89899141]\n",
      "  [0.90064168]\n",
      "  [0.90091038]\n",
      "  [0.90223271]\n",
      "  [0.90247649]\n",
      "  [0.9031738 ]\n",
      "  [0.903898  ]\n",
      "  [0.90420294]]]\n",
      "ejemplar: [0.89899141 0.90064168 0.90091038 0.90223271 0.90247649 0.9031738\n",
      " 0.903898   0.90420294]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9041154]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.89899141 0.90064168 0.90091038 0.90223271 0.90247649 0.9031738\n",
      "  0.903898   0.90420294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08935532718896866\n",
      "Predicción post entrenamiento : [[0.900798]]\n",
      "PERDIDAAAA despues: 0.08738306164741516\n",
      "loss en el callback: 0.23310373723506927, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.90064168]\n",
      "  [0.90091038]\n",
      "  [0.90223271]\n",
      "  [0.90247649]\n",
      "  [0.9031738 ]\n",
      "  [0.903898  ]\n",
      "  [0.90420294]\n",
      "  [0.90411538]]]\n",
      "ejemplar: [0.90064168 0.90091038 0.90223271 0.90247649 0.9031738  0.903898\n",
      " 0.90420294 0.90411538]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.901614]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.90064168 0.90091038 0.90223271 0.90247649 0.9031738  0.903898\n",
      "  0.90420294 0.90411538]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05605313554406166\n",
      "Predicción post entrenamiento : [[0.8995141]]\n",
      "PERDIDAAAA despues: 0.05506320297718048\n",
      "loss en el callback: 0.1129993423819542, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.90091038]\n",
      "  [0.90223271]\n",
      "  [0.90247649]\n",
      "  [0.9031738 ]\n",
      "  [0.903898  ]\n",
      "  [0.90420294]\n",
      "  [0.90411538]\n",
      "  [0.90161401]]]\n",
      "ejemplar: [0.90091038 0.90223271 0.90247649 0.9031738  0.903898   0.90420294\n",
      " 0.90411538 0.90161401]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.90003645]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.90091038 0.90223271 0.90247649 0.9031738  0.903898   0.90420294\n",
      "  0.90411538 0.90161401]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03692979738116264\n",
      "Predicción post entrenamiento : [[0.89983064]]\n",
      "PERDIDAAAA despues: 0.036850739270448685\n",
      "loss en el callback: 0.001724390545859933, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.90223271]\n",
      "  [0.90247649]\n",
      "  [0.9031738 ]\n",
      "  [0.903898  ]\n",
      "  [0.90420294]\n",
      "  [0.90411538]\n",
      "  [0.90161401]\n",
      "  [0.90003645]]]\n",
      "ejemplar: [0.90223271 0.90247649 0.9031738  0.903898   0.90420294 0.90411538\n",
      " 0.90161401 0.90003645]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.90037835]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.90223271 0.90247649 0.9031738  0.903898   0.90420294 0.90411538\n",
      "  0.90161401 0.90003645]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055469561368227005\n",
      "Predicción post entrenamiento : [[0.89997077]]\n",
      "PERDIDAAAA despues: 0.0552777424454689\n",
      "loss en el callback: 0.0066139972768723965, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.90247649]\n",
      "  [0.9031738 ]\n",
      "  [0.903898  ]\n",
      "  [0.90420294]\n",
      "  [0.90411538]\n",
      "  [0.90161401]\n",
      "  [0.90003645]\n",
      "  [0.90037835]]]\n",
      "ejemplar: [0.90247649 0.9031738  0.903898   0.90420294 0.90411538 0.90161401\n",
      " 0.90003645 0.90037835]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9001856]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.90247649 0.9031738  0.903898   0.90420294 0.90411538 0.90161401\n",
      "  0.90003645 0.90037835]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035658057779073715\n",
      "Predicción post entrenamiento : [[0.89886224]]\n",
      "PERDIDAAAA despues: 0.03516002744436264\n",
      "loss en el callback: 0.05034970864653587, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.9031738 ]\n",
      "  [0.903898  ]\n",
      "  [0.90420294]\n",
      "  [0.90411538]\n",
      "  [0.90161401]\n",
      "  [0.90003645]\n",
      "  [0.90037835]\n",
      "  [0.90018559]]]\n",
      "ejemplar: [0.9031738  0.903898   0.90420294 0.90411538 0.90161401 0.90003645\n",
      " 0.90037835 0.90018559]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.8989733]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.9031738  0.903898   0.90420294 0.90411538 0.90161401 0.90003645\n",
      "  0.90037835 0.90018559]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049158163368701935\n",
      "Predicción post entrenamiento : [[0.8973095]]\n",
      "PERDIDAAAA despues: 0.04842314496636391\n",
      "loss en el callback: 0.07723485678434372, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.903898  ]\n",
      "  [0.90420294]\n",
      "  [0.90411538]\n",
      "  [0.90161401]\n",
      "  [0.90003645]\n",
      "  [0.90037835]\n",
      "  [0.90018559]\n",
      "  [0.89897329]]]\n",
      "ejemplar: [0.903898   0.90420294 0.90411538 0.90161401 0.90003645 0.90037835\n",
      " 0.90018559 0.89897329]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.8971294]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.903898   0.90420294 0.90411538 0.90161401 0.90003645 0.90037835\n",
      "  0.90018559 0.89897329]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018230855464935303\n",
      "Predicción post entrenamiento : [[0.8951269]]\n",
      "PERDIDAAAA despues: 0.01769409328699112\n",
      "loss en el callback: 0.09056052565574646, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.90420294]\n",
      "  [0.90411538]\n",
      "  [0.90161401]\n",
      "  [0.90003645]\n",
      "  [0.90037835]\n",
      "  [0.90018559]\n",
      "  [0.89897329]\n",
      "  [0.89712942]]]\n",
      "ejemplar: [0.90420294 0.90411538 0.90161401 0.90003645 0.90037835 0.90018559\n",
      " 0.89897329 0.89712942]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.89457315]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.90420294 0.90411538 0.90161401 0.90003645 0.90037835 0.90018559\n",
      "  0.89897329 0.89712942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007660032715648413\n",
      "Predicción post entrenamiento : [[0.8936489]]\n",
      "PERDIDAAAA despues: 0.00749910669401288\n",
      "loss en el callback: 0.024791071191430092, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.90411538]\n",
      "  [0.90161401]\n",
      "  [0.90003645]\n",
      "  [0.90037835]\n",
      "  [0.90018559]\n",
      "  [0.89897329]\n",
      "  [0.89712942]\n",
      "  [0.89457315]]]\n",
      "ejemplar: [0.90411538 0.90161401 0.90003645 0.90037835 0.90018559 0.89897329\n",
      " 0.89712942 0.89457315]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.8927623]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.90411538 0.90161401 0.90003645 0.90037835 0.90018559 0.89897329\n",
      "  0.89712942 0.89457315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006017783191055059\n",
      "Predicción post entrenamiento : [[0.89253896]]\n",
      "PERDIDAAAA despues: 0.005983182229101658\n",
      "loss en el callback: 0.001662620110437274, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.90161401]\n",
      "  [0.90003645]\n",
      "  [0.90037835]\n",
      "  [0.90018559]\n",
      "  [0.89897329]\n",
      "  [0.89712942]\n",
      "  [0.89457315]\n",
      "  [0.8927623 ]]]\n",
      "ejemplar: [0.90161401 0.90003645 0.90037835 0.90018559 0.89897329 0.89712942\n",
      " 0.89457315 0.8927623 ]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.89136475]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.90161401 0.90003645 0.90037835 0.90018559 0.89897329 0.89712942\n",
      "  0.89457315 0.8927623 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022121050278656185\n",
      "Predicción post entrenamiento : [[0.8908388]]\n",
      "PERDIDAAAA despues: 0.00023713223345112056\n",
      "loss en el callback: 0.007466592825949192, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.90003645]\n",
      "  [0.90037835]\n",
      "  [0.90018559]\n",
      "  [0.89897329]\n",
      "  [0.89712942]\n",
      "  [0.89457315]\n",
      "  [0.8927623 ]\n",
      "  [0.89136475]]]\n",
      "ejemplar: [0.90003645 0.90037835 0.90018559 0.89897329 0.89712942 0.89457315\n",
      " 0.8927623  0.89136475]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.8900324]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.90003645 0.90037835 0.90018559 0.89897329 0.89712942 0.89457315\n",
      "  0.8927623  0.89136475]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004854343831539154\n",
      "Predicción post entrenamiento : [[0.8911116]]\n",
      "PERDIDAAAA despues: 0.0047051259316504\n",
      "loss en el callback: 0.06579925864934921, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.90037835]\n",
      "  [0.90018559]\n",
      "  [0.89897329]\n",
      "  [0.89712942]\n",
      "  [0.89457315]\n",
      "  [0.8927623 ]\n",
      "  [0.89136475]\n",
      "  [0.89003241]]]\n",
      "ejemplar: [0.90037835 0.90018559 0.89897329 0.89712942 0.89457315 0.8927623\n",
      " 0.89136475 0.89003241]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.89042705]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.90037835 0.90018559 0.89897329 0.89712942 0.89457315 0.8927623\n",
      "  0.89136475 0.89003241]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005465322639793158\n",
      "Predicción post entrenamiento : [[0.889851]]\n",
      "PERDIDAAAA despues: 0.005550831090658903\n",
      "loss en el callback: 0.009017170406877995, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.90018559]\n",
      "  [0.89897329]\n",
      "  [0.89712942]\n",
      "  [0.89457315]\n",
      "  [0.8927623 ]\n",
      "  [0.89136475]\n",
      "  [0.89003241]\n",
      "  [0.89042705]]]\n",
      "ejemplar: [0.90018559 0.89897329 0.89712942 0.89457315 0.8927623  0.89136475\n",
      " 0.89003241 0.89042705]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.8887176]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.90018559 0.89897329 0.89712942 0.89457315 0.8927623  0.89136475\n",
      "  0.89003241 0.89042705]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.756658711357886e-07\n",
      "Predicción post entrenamiento : [[0.888157]]\n",
      "PERDIDAAAA despues: 1.6667755176058563e-08\n",
      "loss en el callback: 0.009020181372761726, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.89897329]\n",
      "  [0.89712942]\n",
      "  [0.89457315]\n",
      "  [0.8927623 ]\n",
      "  [0.89136475]\n",
      "  [0.89003241]\n",
      "  [0.89042705]\n",
      "  [0.88871759]]]\n",
      "ejemplar: [0.89897329 0.89712942 0.89457315 0.8927623  0.89136475 0.89003241\n",
      " 0.89042705 0.88871759]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.88666177]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.89897329 0.89712942 0.89457315 0.8927623  0.89136475 0.89003241\n",
      "  0.89042705 0.88871759]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.6185992939863354e-05\n",
      "Predicción post entrenamiento : [[0.88686216]]\n",
      "PERDIDAAAA despues: 3.381525675649755e-05\n",
      "loss en el callback: 0.0014273544074967504, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.89712942]\n",
      "  [0.89457315]\n",
      "  [0.8927623 ]\n",
      "  [0.89136475]\n",
      "  [0.89003241]\n",
      "  [0.89042705]\n",
      "  [0.88871759]\n",
      "  [0.88666177]]]\n",
      "ejemplar: [0.89712942 0.89457315 0.8927623  0.89136475 0.89003241 0.89042705\n",
      " 0.88871759 0.88666177]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8852643]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.89712942 0.89457315 0.8927623  0.89136475 0.89003241 0.89042705\n",
      "  0.88871759 0.88666177]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010044256487162784\n",
      "Predicción post entrenamiento : [[0.88477933]]\n",
      "PERDIDAAAA despues: 9.095743007492274e-05\n",
      "loss en el callback: 0.007784135639667511, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.89457315]\n",
      "  [0.8927623 ]\n",
      "  [0.89136475]\n",
      "  [0.89003241]\n",
      "  [0.89042705]\n",
      "  [0.88871759]\n",
      "  [0.88666177]\n",
      "  [0.88526428]]]\n",
      "ejemplar: [0.89457315 0.8927623  0.89136475 0.89003241 0.89042705 0.88871759\n",
      " 0.88666177 0.88526428]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.8832698]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.89457315 0.8927623  0.89136475 0.89003241 0.89042705 0.88871759\n",
      "  0.88666177 0.88526428]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010521452641114593\n",
      "Predicción post entrenamiento : [[0.88247544]]\n",
      "PERDIDAAAA despues: 0.0010012438287958503\n",
      "loss en el callback: 0.0194501131772995, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.8927623 ]\n",
      "  [0.89136475]\n",
      "  [0.89003241]\n",
      "  [0.89042705]\n",
      "  [0.88871759]\n",
      "  [0.88666177]\n",
      "  [0.88526428]\n",
      "  [0.88326979]]]\n",
      "ejemplar: [0.8927623  0.89136475 0.89003241 0.89042705 0.88871759 0.88666177\n",
      " 0.88526428 0.88326979]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.88128805]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.8927623  0.89136475 0.89003241 0.89042705 0.88871759 0.88666177\n",
      "  0.88526428 0.88326979]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010492587462067604\n",
      "Predicción post entrenamiento : [[0.88113314]]\n",
      "PERDIDAAAA despues: 0.0010392467956990004\n",
      "loss en el callback: 0.0008536716923117638, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.89136475]\n",
      "  [0.89003241]\n",
      "  [0.89042705]\n",
      "  [0.88871759]\n",
      "  [0.88666177]\n",
      "  [0.88526428]\n",
      "  [0.88326979]\n",
      "  [0.88128805]]]\n",
      "ejemplar: [0.89136475 0.89003241 0.89042705 0.88871759 0.88666177 0.88526428\n",
      " 0.88326979 0.88128805]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.8800882]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.89136475 0.89003241 0.89042705 0.88871759 0.88666177 0.88526428\n",
      "  0.88326979 0.88128805]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006778138689696789\n",
      "Predicción post entrenamiento : [[0.88027763]]\n",
      "PERDIDAAAA despues: 0.006746984086930752\n",
      "loss en el callback: 0.0011354362359270453, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.89003241]\n",
      "  [0.89042705]\n",
      "  [0.88871759]\n",
      "  [0.88666177]\n",
      "  [0.88526428]\n",
      "  [0.88326979]\n",
      "  [0.88128805]\n",
      "  [0.88008821]]]\n",
      "ejemplar: [0.89003241 0.89042705 0.88871759 0.88666177 0.88526428 0.88326979\n",
      " 0.88128805 0.88008821]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.87925696]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.89003241 0.89042705 0.88871759 0.88666177 0.88526428 0.88326979\n",
      "  0.88128805 0.88008821]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007847295142710209\n",
      "Predicción post entrenamiento : [[0.8788358]]\n",
      "PERDIDAAAA despues: 0.007922090590000153\n",
      "loss en el callback: 0.004757193382829428, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.89042705]\n",
      "  [0.88871759]\n",
      "  [0.88666177]\n",
      "  [0.88526428]\n",
      "  [0.88326979]\n",
      "  [0.88128805]\n",
      "  [0.88008821]\n",
      "  [0.87925696]]]\n",
      "ejemplar: [0.89042705 0.88871759 0.88666177 0.88526428 0.88326979 0.88128805\n",
      " 0.88008821 0.87925696]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.8778071]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.89042705 0.88871759 0.88666177 0.88526428 0.88326979 0.88128805\n",
      "  0.88008821 0.87925696]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003958120476454496\n",
      "Predicción post entrenamiento : [[0.8775095]]\n",
      "PERDIDAAAA despues: 0.003995656035840511\n",
      "loss en el callback: 0.002635084092617035, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.88871759]\n",
      "  [0.88666177]\n",
      "  [0.88526428]\n",
      "  [0.88326979]\n",
      "  [0.88128805]\n",
      "  [0.88008821]\n",
      "  [0.87925696]\n",
      "  [0.87780708]]]\n",
      "ejemplar: [0.88871759 0.88666177 0.88526428 0.88326979 0.88128805 0.88008821\n",
      " 0.87925696 0.87780708]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.8759513]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.88871759 0.88666177 0.88526428 0.88326979 0.88128805 0.88008821\n",
      "  0.87925696 0.87780708]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009319966658949852\n",
      "Predicción post entrenamiento : [[0.87656873]]\n",
      "PERDIDAAAA despues: 0.009201131761074066\n",
      "loss en el callback: 0.016836704686284065, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.88666177]\n",
      "  [0.88526428]\n",
      "  [0.88326979]\n",
      "  [0.88128805]\n",
      "  [0.88008821]\n",
      "  [0.87925696]\n",
      "  [0.87780708]\n",
      "  [0.87595129]]]\n",
      "ejemplar: [0.88666177 0.88526428 0.88326979 0.88128805 0.88008821 0.87925696\n",
      " 0.87780708 0.87595129]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.87502664]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.88666177 0.88526428 0.88326979 0.88128805 0.88008821 0.87925696\n",
      "  0.87780708 0.87595129]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014853222295641899\n",
      "Predicción post entrenamiento : [[0.87584203]]\n",
      "PERDIDAAAA despues: 0.014655137434601784\n",
      "loss en el callback: 0.02935800515115261, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.88526428]\n",
      "  [0.88326979]\n",
      "  [0.88128805]\n",
      "  [0.88008821]\n",
      "  [0.87925696]\n",
      "  [0.87780708]\n",
      "  [0.87595129]\n",
      "  [0.87502664]]]\n",
      "ejemplar: [0.88526428 0.88326979 0.88128805 0.88008821 0.87925696 0.87780708\n",
      " 0.87595129 0.87502664]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.8744345]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.88526428 0.88326979 0.88128805 0.88008821 0.87925696 0.87780708\n",
      "  0.87595129 0.87502664]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0058901384472846985\n",
      "Predicción post entrenamiento : [[0.87496424]]\n",
      "PERDIDAAAA despues: 0.005809103138744831\n",
      "loss en el callback: 0.01318372879177332, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.88326979]\n",
      "  [0.88128805]\n",
      "  [0.88008821]\n",
      "  [0.87925696]\n",
      "  [0.87780708]\n",
      "  [0.87595129]\n",
      "  [0.87502664]\n",
      "  [0.87443447]]]\n",
      "ejemplar: [0.88326979 0.88128805 0.88008821 0.87925696 0.87780708 0.87595129\n",
      " 0.87502664 0.87443447]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.87353384]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.88326979 0.88128805 0.88008821 0.87925696 0.87780708 0.87595129\n",
      "  0.87502664 0.87443447]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004947494016960263\n",
      "Predicción post entrenamiento : [[0.87334514]]\n",
      "PERDIDAAAA despues: 0.0005031799082644284\n",
      "loss en el callback: 0.0013540007639676332, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.88128805]\n",
      "  [0.88008821]\n",
      "  [0.87925696]\n",
      "  [0.87780708]\n",
      "  [0.87595129]\n",
      "  [0.87502664]\n",
      "  [0.87443447]\n",
      "  [0.87353384]]]\n",
      "ejemplar: [0.88128805 0.88008821 0.87925696 0.87780708 0.87595129 0.87502664\n",
      " 0.87443447 0.87353384]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.87208426]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.88128805 0.88008821 0.87925696 0.87780708 0.87595129 0.87502664\n",
      "  0.87443447 0.87353384]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.755410817684606e-05\n",
      "Predicción post entrenamiento : [[0.87099886]]\n",
      "PERDIDAAAA despues: 0.0001090444638975896\n",
      "loss en el callback: 0.035600095987319946, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.88008821]\n",
      "  [0.87925696]\n",
      "  [0.87780708]\n",
      "  [0.87595129]\n",
      "  [0.87502664]\n",
      "  [0.87443447]\n",
      "  [0.87353384]\n",
      "  [0.87208426]]]\n",
      "ejemplar: [0.88008821 0.87925696 0.87780708 0.87595129 0.87502664 0.87443447\n",
      " 0.87353384 0.87208426]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8699425]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.88008821 0.87925696 0.87780708 0.87595129 0.87502664 0.87443447\n",
      "  0.87353384 0.87208426]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022225508000701666\n",
      "Predicción post entrenamiento : [[0.86922854]]\n",
      "PERDIDAAAA despues: 0.0022903766948729753\n",
      "loss en el callback: 0.016017712652683258, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.87925696]\n",
      "  [0.87780708]\n",
      "  [0.87595129]\n",
      "  [0.87502664]\n",
      "  [0.87443447]\n",
      "  [0.87353384]\n",
      "  [0.87208426]\n",
      "  [0.86994249]]]\n",
      "ejemplar: [0.87925696 0.87780708 0.87595129 0.87502664 0.87443447 0.87353384\n",
      " 0.87208426 0.86994249]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8681768]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.87925696 0.87780708 0.87595129 0.87502664 0.87443447 0.87353384\n",
      "  0.87208426 0.86994249]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026648035272955894\n",
      "Predicción post entrenamiento : [[0.8683049]]\n",
      "PERDIDAAAA despues: 0.0026515955105423927\n",
      "loss en el callback: 0.0006595667800866067, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.87780708]\n",
      "  [0.87595129]\n",
      "  [0.87502664]\n",
      "  [0.87443447]\n",
      "  [0.87353384]\n",
      "  [0.87208426]\n",
      "  [0.86994249]\n",
      "  [0.86817682]]]\n",
      "ejemplar: [0.87780708 0.87595129 0.87502664 0.87443447 0.87353384 0.87208426\n",
      " 0.86994249 0.86817682]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.86714256]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.87780708 0.87595129 0.87502664 0.87443447 0.87353384 0.87208426\n",
      "  0.86994249 0.86817682]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008930295705795288\n",
      "Predicción post entrenamiento : [[0.8677985]]\n",
      "PERDIDAAAA despues: 0.008806752040982246\n",
      "loss en el callback: 0.019961586222052574, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.87595129]\n",
      "  [0.87502664]\n",
      "  [0.87443447]\n",
      "  [0.87353384]\n",
      "  [0.87208426]\n",
      "  [0.86994249]\n",
      "  [0.86817682]\n",
      "  [0.86714256]]]\n",
      "ejemplar: [0.87595129 0.87502664 0.87443447 0.87353384 0.87208426 0.86994249\n",
      " 0.86817682 0.86714256]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8666843]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.87595129 0.87502664 0.87443447 0.87353384 0.87208426 0.86994249\n",
      "  0.86817682 0.86714256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01031139399856329\n",
      "Predicción post entrenamiento : [[0.86663747]]\n",
      "PERDIDAAAA despues: 0.010320911183953285\n",
      "loss en el callback: 8.48250201670453e-05, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.87502664]\n",
      "  [0.87443447]\n",
      "  [0.87353384]\n",
      "  [0.87208426]\n",
      "  [0.86994249]\n",
      "  [0.86817682]\n",
      "  [0.86714256]\n",
      "  [0.86668432]]]\n",
      "ejemplar: [0.87502664 0.87443447 0.87353384 0.87208426 0.86994249 0.86817682\n",
      " 0.86714256 0.86668432]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.86569554]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.87502664 0.87443447 0.87353384 0.87208426 0.86994249 0.86817682\n",
      "  0.86714256 0.86668432]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00847739726305008\n",
      "Predicción post entrenamiento : [[0.86669254]]\n",
      "PERDIDAAAA despues: 0.008294797502458096\n",
      "loss en el callback: 0.0593387596309185, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23287494]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03488257899880409\n",
      "Predicción post entrenamiento : [[0.1934735]]\n",
      "PERDIDAAAA despues: 0.02171713300049305\n",
      "loss en el callback: 0.03257312253117561, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23287494]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.23287494]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17778909]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.23287494]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005411944817751646\n",
      "Predicción post entrenamiento : [[0.16635162]]\n",
      "PERDIDAAAA despues: 0.0038599439430981874\n",
      "loss en el callback: 0.0032142375130206347, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23287494]\n",
      "  [0.17778909]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.23287494 0.17778909]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17017367]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.23287494 0.17778909]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000255036837188527\n",
      "Predicción post entrenamiento : [[0.1662897]]\n",
      "PERDIDAAAA despues: 0.0001460689672967419\n",
      "loss en el callback: 0.0006337253726087511, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23287494]\n",
      "  [0.17778909]\n",
      "  [0.17017367]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23287494\n",
      " 0.17778909 0.17017367]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17730951]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23287494\n",
      "  0.17778909 0.17017367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00046465813647955656\n",
      "Predicción post entrenamiento : [[0.17216793]]\n",
      "PERDIDAAAA despues: 0.0002694306895136833\n",
      "loss en el callback: 0.0018180438783019781, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23287494]\n",
      "  [0.17778909]\n",
      "  [0.17017367]\n",
      "  [0.17730951]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.23287494 0.17778909\n",
      " 0.17017367 0.17730951]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18406336]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.23287494 0.17778909\n",
      "  0.17017367 0.17730951]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003425832837820053\n",
      "Predicción post entrenamiento : [[0.17726265]]\n",
      "PERDIDAAAA despues: 0.00267598289065063\n",
      "loss en el callback: 0.0055413562804460526, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23287494]\n",
      "  [0.17778909]\n",
      "  [0.17017367]\n",
      "  [0.17730951]\n",
      "  [0.18406336]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.23287494 0.17778909 0.17017367\n",
      " 0.17730951 0.18406336]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18604718]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.23287494 0.17778909 0.17017367\n",
      "  0.17730951 0.18406336]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016295121749863029\n",
      "Predicción post entrenamiento : [[0.18299814]]\n",
      "PERDIDAAAA despues: 0.0013926457613706589\n",
      "loss en el callback: 0.0016658541280776262, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23287494]\n",
      "  [0.17778909]\n",
      "  [0.17017367]\n",
      "  [0.17730951]\n",
      "  [0.18406336]\n",
      "  [0.18604718]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.23287494 0.17778909 0.17017367 0.17730951\n",
      " 0.18406336 0.18604718]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20230624]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.23287494 0.17778909 0.17017367 0.17730951\n",
      "  0.18406336 0.18604718]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031193771865218878\n",
      "Predicción post entrenamiento : [[0.19824791]]\n",
      "PERDIDAAAA despues: 0.0026825203094631433\n",
      "loss en el callback: 0.003544566687196493, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.23287494]\n",
      "  [0.17778909]\n",
      "  [0.17017367]\n",
      "  [0.17730951]\n",
      "  [0.18406336]\n",
      "  [0.18604718]\n",
      "  [0.20230624]]]\n",
      "ejemplar: [0.04223169 0.23287494 0.17778909 0.17017367 0.17730951 0.18406336\n",
      " 0.18604718 0.20230624]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22146283]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.23287494 0.17778909 0.17017367 0.17730951 0.18406336\n",
      "  0.18604718 0.20230624]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006459117867052555\n",
      "Predicción post entrenamiento : [[0.22102363]]\n",
      "PERDIDAAAA despues: 0.0006237804773263633\n",
      "loss en el callback: 6.185606616782025e-05, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.23287494]\n",
      "  [0.17778909]\n",
      "  [0.17017367]\n",
      "  [0.17730951]\n",
      "  [0.18406336]\n",
      "  [0.18604718]\n",
      "  [0.20230624]\n",
      "  [0.22146283]]]\n",
      "ejemplar: [0.23287494 0.17778909 0.17017367 0.17730951 0.18406336 0.18604718\n",
      " 0.20230624 0.22146283]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24844846]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.23287494 0.17778909 0.17017367 0.17730951 0.18406336 0.18604718\n",
      "  0.20230624 0.22146283]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032104263664223254\n",
      "Predicción post entrenamiento : [[0.24750653]]\n",
      "PERDIDAAAA despues: 0.00028817541897296906\n",
      "loss en el callback: 0.0003180034691467881, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.17778909]\n",
      "  [0.17017367]\n",
      "  [0.17730951]\n",
      "  [0.18406336]\n",
      "  [0.18604718]\n",
      "  [0.20230624]\n",
      "  [0.22146283]\n",
      "  [0.24844846]]]\n",
      "ejemplar: [0.17778909 0.17017367 0.17730951 0.18406336 0.18604718 0.20230624\n",
      " 0.22146283 0.24844846]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23852834]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.17778909 0.17017367 0.17730951 0.18406336 0.18604718 0.20230624\n",
      "  0.22146283 0.24844846]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009049268555827439\n",
      "Predicción post entrenamiento : [[0.238526]]\n",
      "PERDIDAAAA despues: 0.0009047861094586551\n",
      "loss en el callback: 2.90333446173463e-09, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.17017367]\n",
      "  [0.17730951]\n",
      "  [0.18406336]\n",
      "  [0.18604718]\n",
      "  [0.20230624]\n",
      "  [0.22146283]\n",
      "  [0.24844846]\n",
      "  [0.23852834]]]\n",
      "ejemplar: [0.17017367 0.17730951 0.18406336 0.18604718 0.20230624 0.22146283\n",
      " 0.24844846 0.23852834]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24102288]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.17017367 0.17730951 0.18406336 0.18604718 0.20230624 0.22146283\n",
      "  0.24844846 0.23852834]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008462005062028766\n",
      "Predicción post entrenamiento : [[0.23961024]]\n",
      "PERDIDAAAA despues: 0.0007660097326152027\n",
      "loss en el callback: 0.0010123758111149073, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17730951]\n",
      "  [0.18406336]\n",
      "  [0.18604718]\n",
      "  [0.20230624]\n",
      "  [0.22146283]\n",
      "  [0.24844846]\n",
      "  [0.23852834]\n",
      "  [0.24102288]]]\n",
      "ejemplar: [0.17730951 0.18406336 0.18604718 0.20230624 0.22146283 0.24844846\n",
      " 0.23852834 0.24102288]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2453827]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17730951 0.18406336 0.18604718 0.20230624 0.22146283 0.24844846\n",
      "  0.23852834 0.24102288]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014515103539451957\n",
      "Predicción post entrenamiento : [[0.24216561]]\n",
      "PERDIDAAAA despues: 0.0012167264940217137\n",
      "loss en el callback: 0.005214518401771784, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.18406336]\n",
      "  [0.18604718]\n",
      "  [0.20230624]\n",
      "  [0.22146283]\n",
      "  [0.24844846]\n",
      "  [0.23852834]\n",
      "  [0.24102288]\n",
      "  [0.2453827 ]]]\n",
      "ejemplar: [0.18406336 0.18604718 0.20230624 0.22146283 0.24844846 0.23852834\n",
      " 0.24102288 0.2453827 ]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.24853736]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.18406336 0.18604718 0.20230624 0.22146283 0.24844846 0.23852834\n",
      "  0.24102288 0.2453827 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030901243444532156\n",
      "Predicción post entrenamiento : [[0.24662773]]\n",
      "PERDIDAAAA despues: 0.002881462685763836\n",
      "loss en el callback: 0.002760212402790785, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.18604718]\n",
      "  [0.20230624]\n",
      "  [0.22146283]\n",
      "  [0.24844846]\n",
      "  [0.23852834]\n",
      "  [0.24102288]\n",
      "  [0.2453827 ]\n",
      "  [0.24853736]]]\n",
      "ejemplar: [0.18604718 0.20230624 0.22146283 0.24844846 0.23852834 0.24102288\n",
      " 0.2453827  0.24853736]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.25368288]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.18604718 0.20230624 0.22146283 0.24844846 0.23852834 0.24102288\n",
      "  0.2453827  0.24853736]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032330527901649475\n",
      "Predicción post entrenamiento : [[0.2520488]]\n",
      "PERDIDAAAA despues: 0.003049894468858838\n",
      "loss en el callback: 0.0021398330572992563, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20230624]\n",
      "  [0.22146283]\n",
      "  [0.24844846]\n",
      "  [0.23852834]\n",
      "  [0.24102288]\n",
      "  [0.2453827 ]\n",
      "  [0.24853736]\n",
      "  [0.25368288]]]\n",
      "ejemplar: [0.20230624 0.22146283 0.24844846 0.23852834 0.24102288 0.2453827\n",
      " 0.24853736 0.25368288]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2608025]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20230624 0.22146283 0.24844846 0.23852834 0.24102288 0.2453827\n",
      "  0.24853736 0.25368288]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002166386926546693\n",
      "Predicción post entrenamiento : [[0.25817403]]\n",
      "PERDIDAAAA despues: 0.0019286138704046607\n",
      "loss en el callback: 0.005702911410480738, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22146283]\n",
      "  [0.24844846]\n",
      "  [0.23852834]\n",
      "  [0.24102288]\n",
      "  [0.2453827 ]\n",
      "  [0.24853736]\n",
      "  [0.25368288]\n",
      "  [0.26080251]]]\n",
      "ejemplar: [0.22146283 0.24844846 0.23852834 0.24102288 0.2453827  0.24853736\n",
      " 0.25368288 0.26080251]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26549423]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22146283 0.24844846 0.23852834 0.24102288 0.2453827  0.24853736\n",
      "  0.25368288 0.26080251]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007084448356181383\n",
      "Predicción post entrenamiento : [[0.2621872]]\n",
      "PERDIDAAAA despues: 0.006538687273859978\n",
      "loss en el callback: 0.010319539345800877, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24844846]\n",
      "  [0.23852834]\n",
      "  [0.24102288]\n",
      "  [0.2453827 ]\n",
      "  [0.24853736]\n",
      "  [0.25368288]\n",
      "  [0.26080251]\n",
      "  [0.26549423]]]\n",
      "ejemplar: [0.24844846 0.23852834 0.24102288 0.2453827  0.24853736 0.25368288\n",
      " 0.26080251 0.26549423]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26695514]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24844846 0.23852834 0.24102288 0.2453827  0.24853736 0.25368288\n",
      "  0.26080251 0.26549423]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008432603441178799\n",
      "Predicción post entrenamiento : [[0.26395538]]\n",
      "PERDIDAAAA despues: 0.0078906724229455\n",
      "loss en el callback: 0.009833802469074726, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23852834]\n",
      "  [0.24102288]\n",
      "  [0.2453827 ]\n",
      "  [0.24853736]\n",
      "  [0.25368288]\n",
      "  [0.26080251]\n",
      "  [0.26549423]\n",
      "  [0.26695514]]]\n",
      "ejemplar: [0.23852834 0.24102288 0.2453827  0.24853736 0.25368288 0.26080251\n",
      " 0.26549423 0.26695514]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2638642]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23852834 0.24102288 0.2453827  0.24853736 0.25368288 0.26080251\n",
      "  0.26549423 0.26695514]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013423432596027851\n",
      "Predicción post entrenamiento : [[0.26171294]]\n",
      "PERDIDAAAA despues: 0.012929574586451054\n",
      "loss en el callback: 0.007401815615594387, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.24102288]\n",
      "  [0.2453827 ]\n",
      "  [0.24853736]\n",
      "  [0.25368288]\n",
      "  [0.26080251]\n",
      "  [0.26549423]\n",
      "  [0.26695514]\n",
      "  [0.26386419]]]\n",
      "ejemplar: [0.24102288 0.2453827  0.24853736 0.25368288 0.26080251 0.26549423\n",
      " 0.26695514 0.26386419]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26427555]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.24102288 0.2453827  0.24853736 0.25368288 0.26080251 0.26549423\n",
      "  0.26695514 0.26386419]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011113881133496761\n",
      "Predicción post entrenamiento : [[0.26183912]]\n",
      "PERDIDAAAA despues: 0.010606108233332634\n",
      "loss en el callback: 0.009300369769334793, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.2453827 ]\n",
      "  [0.24853736]\n",
      "  [0.25368288]\n",
      "  [0.26080251]\n",
      "  [0.26549423]\n",
      "  [0.26695514]\n",
      "  [0.26386419]\n",
      "  [0.26427555]]]\n",
      "ejemplar: [0.2453827  0.24853736 0.25368288 0.26080251 0.26549423 0.26695514\n",
      " 0.26386419 0.26427555]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2646853]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.2453827  0.24853736 0.25368288 0.26080251 0.26549423 0.26695514\n",
      "  0.26386419 0.26427555]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005257951561361551\n",
      "Predicción post entrenamiento : [[0.26261055]]\n",
      "PERDIDAAAA despues: 0.004961368627846241\n",
      "loss en el callback: 0.0068369414657354355, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.24853736]\n",
      "  [0.25368288]\n",
      "  [0.26080251]\n",
      "  [0.26549423]\n",
      "  [0.26695514]\n",
      "  [0.26386419]\n",
      "  [0.26427555]\n",
      "  [0.2646853 ]]]\n",
      "ejemplar: [0.24853736 0.25368288 0.26080251 0.26549423 0.26695514 0.26386419\n",
      " 0.26427555 0.2646853 ]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26528272]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.24853736 0.25368288 0.26080251 0.26549423 0.26695514 0.26386419\n",
      "  0.26427555 0.2646853 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006289804354310036\n",
      "Predicción post entrenamiento : [[0.2635269]]\n",
      "PERDIDAAAA despues: 0.006014382932335138\n",
      "loss en el callback: 0.005364651791751385, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25368288]\n",
      "  [0.26080251]\n",
      "  [0.26549423]\n",
      "  [0.26695514]\n",
      "  [0.26386419]\n",
      "  [0.26427555]\n",
      "  [0.2646853 ]\n",
      "  [0.26528272]]]\n",
      "ejemplar: [0.25368288 0.26080251 0.26549423 0.26695514 0.26386419 0.26427555\n",
      " 0.2646853  0.26528272]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26616895]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25368288 0.26080251 0.26549423 0.26695514 0.26386419 0.26427555\n",
      "  0.2646853  0.26528272]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.112646246947406e-07\n",
      "Predicción post entrenamiento : [[0.26618364]]\n",
      "PERDIDAAAA despues: 5.885062250854389e-07\n",
      "loss en el callback: 4.4144459820927295e-07, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26080251]\n",
      "  [0.26549423]\n",
      "  [0.26695514]\n",
      "  [0.26386419]\n",
      "  [0.26427555]\n",
      "  [0.2646853 ]\n",
      "  [0.26528272]\n",
      "  [0.26616895]]]\n",
      "ejemplar: [0.26080251 0.26549423 0.26695514 0.26386419 0.26427555 0.2646853\n",
      " 0.26528272 0.26616895]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26824313]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26080251 0.26549423 0.26695514 0.26386419 0.26427555 0.2646853\n",
      "  0.26528272 0.26616895]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005894770147278905\n",
      "Predicción post entrenamiento : [[0.26799467]]\n",
      "PERDIDAAAA despues: 0.0006016035913489759\n",
      "loss en el callback: 0.00011680880561470985, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26549423]\n",
      "  [0.26695514]\n",
      "  [0.26386419]\n",
      "  [0.26427555]\n",
      "  [0.2646853 ]\n",
      "  [0.26528272]\n",
      "  [0.26616895]\n",
      "  [0.26824313]]]\n",
      "ejemplar: [0.26549423 0.26695514 0.26386419 0.26427555 0.2646853  0.26528272\n",
      " 0.26616895 0.26824313]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26885265]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26549423 0.26695514 0.26386419 0.26427555 0.2646853  0.26528272\n",
      "  0.26616895 0.26824313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002386680571362376\n",
      "Predicción post entrenamiento : [[0.27057016]]\n",
      "PERDIDAAAA despues: 0.002221817383542657\n",
      "loss en el callback: 0.009463142603635788, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26695514]\n",
      "  [0.26386419]\n",
      "  [0.26427555]\n",
      "  [0.2646853 ]\n",
      "  [0.26528272]\n",
      "  [0.26616895]\n",
      "  [0.26824313]\n",
      "  [0.26885265]]]\n",
      "ejemplar: [0.26695514 0.26386419 0.26427555 0.2646853  0.26528272 0.26616895\n",
      " 0.26824313 0.26885265]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27055085]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26695514 0.26386419 0.26427555 0.2646853  0.26528272 0.26616895\n",
      "  0.26824313 0.26885265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001773982192389667\n",
      "Predicción post entrenamiento : [[0.27156883]]\n",
      "PERDIDAAAA despues: 0.0016892659477889538\n",
      "loss en el callback: 0.002617513993754983, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26386419]\n",
      "  [0.26427555]\n",
      "  [0.2646853 ]\n",
      "  [0.26528272]\n",
      "  [0.26616895]\n",
      "  [0.26824313]\n",
      "  [0.26885265]\n",
      "  [0.27055085]]]\n",
      "ejemplar: [0.26386419 0.26427555 0.2646853  0.26528272 0.26616895 0.26824313\n",
      " 0.26885265 0.27055085]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27127945]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26386419 0.26427555 0.2646853  0.26528272 0.26616895 0.26824313\n",
      "  0.26885265 0.27055085]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003152686695102602\n",
      "Predicción post entrenamiento : [[0.27177507]]\n",
      "PERDIDAAAA despues: 0.00029791428823955357\n",
      "loss en el callback: 0.0008085453882813454, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26427555]\n",
      "  [0.2646853 ]\n",
      "  [0.26528272]\n",
      "  [0.26616895]\n",
      "  [0.26824313]\n",
      "  [0.26885265]\n",
      "  [0.27055085]\n",
      "  [0.27127945]]]\n",
      "ejemplar: [0.26427555 0.2646853  0.26528272 0.26616895 0.26824313 0.26885265\n",
      " 0.27055085 0.27127945]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27224085]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26427555 0.2646853  0.26528272 0.26616895 0.26824313 0.26885265\n",
      "  0.27055085 0.27127945]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001122595786000602\n",
      "Predicción post entrenamiento : [[0.2726293]]\n",
      "PERDIDAAAA despues: 0.00010417914745630696\n",
      "loss en el callback: 0.0004591357137542218, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.2646853 ]\n",
      "  [0.26528272]\n",
      "  [0.26616895]\n",
      "  [0.26824313]\n",
      "  [0.26885265]\n",
      "  [0.27055085]\n",
      "  [0.27127945]\n",
      "  [0.27224085]]]\n",
      "ejemplar: [0.2646853  0.26528272 0.26616895 0.26824313 0.26885265 0.27055085\n",
      " 0.27127945 0.27224085]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.273202]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.2646853  0.26528272 0.26616895 0.26824313 0.26885265 0.27055085\n",
      "  0.27127945 0.27224085]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006913912948220968\n",
      "Predicción post entrenamiento : [[0.27322647]]\n",
      "PERDIDAAAA despues: 0.0006901051965542138\n",
      "loss en el callback: 1.6237331692536827e-06, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26528272]\n",
      "  [0.26616895]\n",
      "  [0.26824313]\n",
      "  [0.26885265]\n",
      "  [0.27055085]\n",
      "  [0.27127945]\n",
      "  [0.27224085]\n",
      "  [0.273202  ]]]\n",
      "ejemplar: [0.26528272 0.26616895 0.26824313 0.26885265 0.27055085 0.27127945\n",
      " 0.27224085 0.273202  ]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27393147]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26528272 0.26616895 0.26824313 0.26885265 0.27055085 0.27127945\n",
      "  0.27224085 0.273202  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.727195007741102e-06\n",
      "Predicción post entrenamiento : [[0.27445835]]\n",
      "PERDIDAAAA despues: 1.970427547348663e-06\n",
      "loss en el callback: 0.0010687902104109526, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26616895]\n",
      "  [0.26824313]\n",
      "  [0.26885265]\n",
      "  [0.27055085]\n",
      "  [0.27127945]\n",
      "  [0.27224085]\n",
      "  [0.273202  ]\n",
      "  [0.27393147]]]\n",
      "ejemplar: [0.26616895 0.26824313 0.26885265 0.27055085 0.27127945 0.27224085\n",
      " 0.273202   0.27393147]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27527454]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26616895 0.26824313 0.26885265 0.27055085 0.27127945 0.27224085\n",
      "  0.273202   0.27393147]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.30426303207787e-07\n",
      "Predicción post entrenamiento : [[0.27525753]]\n",
      "PERDIDAAAA despues: 3.1115206411413965e-07\n",
      "loss en el callback: 9.967582172976108e-07, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26824313]\n",
      "  [0.26885265]\n",
      "  [0.27055085]\n",
      "  [0.27127945]\n",
      "  [0.27224085]\n",
      "  [0.273202  ]\n",
      "  [0.27393147]\n",
      "  [0.27527454]]]\n",
      "ejemplar: [0.26824313 0.26885265 0.27055085 0.27127945 0.27224085 0.273202\n",
      " 0.27393147 0.27527454]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27613267]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26824313 0.26885265 0.27055085 0.27127945 0.27224085 0.273202\n",
      "  0.27393147 0.27527454]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.330496494731051e-07\n",
      "Predicción post entrenamiento : [[0.2757133]]\n",
      "PERDIDAAAA despues: 5.697138760751841e-08\n",
      "loss en el callback: 0.0006152766873128712, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26885265]\n",
      "  [0.27055085]\n",
      "  [0.27127945]\n",
      "  [0.27224085]\n",
      "  [0.273202  ]\n",
      "  [0.27393147]\n",
      "  [0.27527454]\n",
      "  [0.27613267]]]\n",
      "ejemplar: [0.26885265 0.27055085 0.27127945 0.27224085 0.273202   0.27393147\n",
      " 0.27527454 0.27613267]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27637917]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26885265 0.27055085 0.27127945 0.27224085 0.273202   0.27393147\n",
      "  0.27527454 0.27613267]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003407616401091218\n",
      "Predicción post entrenamiento : [[0.27757767]]\n",
      "PERDIDAAAA despues: 0.003269128268584609\n",
      "loss en el callback: 0.006881146691739559, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27055085]\n",
      "  [0.27127945]\n",
      "  [0.27224085]\n",
      "  [0.273202  ]\n",
      "  [0.27393147]\n",
      "  [0.27527454]\n",
      "  [0.27613267]\n",
      "  [0.27637917]]]\n",
      "ejemplar: [0.27055085 0.27127945 0.27224085 0.273202   0.27393147 0.27527454\n",
      " 0.27613267 0.27637917]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27832696]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27055085 0.27127945 0.27224085 0.273202   0.27393147 0.27527454\n",
      "  0.27613267 0.27637917]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005982887465506792\n",
      "Predicción post entrenamiento : [[0.27882323]]\n",
      "PERDIDAAAA despues: 0.005906361620873213\n",
      "loss en el callback: 0.000899899925570935, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27127945]\n",
      "  [0.27224085]\n",
      "  [0.273202  ]\n",
      "  [0.27393147]\n",
      "  [0.27527454]\n",
      "  [0.27613267]\n",
      "  [0.27637917]\n",
      "  [0.27832696]]]\n",
      "ejemplar: [0.27127945 0.27224085 0.273202   0.27393147 0.27527454 0.27613267\n",
      " 0.27637917 0.27832696]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.27941945]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27127945 0.27224085 0.273202   0.27393147 0.27527454 0.27613267\n",
      "  0.27637917 0.27832696]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003280053148046136\n",
      "Predicción post entrenamiento : [[0.28076524]]\n",
      "PERDIDAAAA despues: 0.0031277136877179146\n",
      "loss en el callback: 0.013849083334207535, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27224085]\n",
      "  [0.273202  ]\n",
      "  [0.27393147]\n",
      "  [0.27527454]\n",
      "  [0.27613267]\n",
      "  [0.27637917]\n",
      "  [0.27832696]\n",
      "  [0.27941945]]]\n",
      "ejemplar: [0.27224085 0.273202   0.27393147 0.27527454 0.27613267 0.27637917\n",
      " 0.27832696 0.27941945]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2814069]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27224085 0.273202   0.27393147 0.27527454 0.27613267 0.27637917\n",
      "  0.27832696 0.27941945]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027232461143285036\n",
      "Predicción post entrenamiento : [[0.2816603]]\n",
      "PERDIDAAAA despues: 0.002696865238249302\n",
      "loss en el callback: 0.0002471955376677215, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.273202  ]\n",
      "  [0.27393147]\n",
      "  [0.27527454]\n",
      "  [0.27613267]\n",
      "  [0.27637917]\n",
      "  [0.27832696]\n",
      "  [0.27941945]\n",
      "  [0.28140691]]]\n",
      "ejemplar: [0.273202   0.27393147 0.27527454 0.27613267 0.27637917 0.27832696\n",
      " 0.27941945 0.28140691]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28231028]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.273202   0.27393147 0.27527454 0.27613267 0.27637917 0.27832696\n",
      "  0.27941945 0.28140691]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01049074251204729\n",
      "Predicción post entrenamiento : [[0.2836003]]\n",
      "PERDIDAAAA despues: 0.01022814679890871\n",
      "loss en el callback: 0.007403505500406027, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27393147]\n",
      "  [0.27527454]\n",
      "  [0.27613267]\n",
      "  [0.27637917]\n",
      "  [0.27832696]\n",
      "  [0.27941945]\n",
      "  [0.28140691]\n",
      "  [0.28231028]]]\n",
      "ejemplar: [0.27393147 0.27527454 0.27613267 0.27637917 0.27832696 0.27941945\n",
      " 0.28140691 0.28231028]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.28426957]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27393147 0.27527454 0.27613267 0.27637917 0.27832696 0.27941945\n",
      "  0.28140691 0.28231028]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08226967602968216\n",
      "Predicción post entrenamiento : [[0.28820682]]\n",
      "PERDIDAAAA despues: 0.08002655953168869\n",
      "loss en el callback: 0.09809987246990204, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27527454]\n",
      "  [0.27613267]\n",
      "  [0.27637917]\n",
      "  [0.27832696]\n",
      "  [0.27941945]\n",
      "  [0.28140691]\n",
      "  [0.28231028]\n",
      "  [0.28426957]]]\n",
      "ejemplar: [0.27527454 0.27613267 0.27637917 0.27832696 0.27941945 0.28140691\n",
      " 0.28231028 0.28426957]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28896442]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27527454 0.27613267 0.27637917 0.27832696 0.27941945 0.28140691\n",
      "  0.28231028 0.28426957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.094443179666996\n",
      "Predicción post entrenamiento : [[0.29305467]]\n",
      "PERDIDAAAA despues: 0.09194591641426086\n",
      "loss en el callback: 0.10584945231676102, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27613267]\n",
      "  [0.27637917]\n",
      "  [0.27832696]\n",
      "  [0.27941945]\n",
      "  [0.28140691]\n",
      "  [0.28231028]\n",
      "  [0.28426957]\n",
      "  [0.28896442]]]\n",
      "ejemplar: [0.27613267 0.27637917 0.27832696 0.27941945 0.28140691 0.28231028\n",
      " 0.28426957 0.28896442]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.29380116]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27613267 0.27637917 0.27832696 0.27941945 0.28140691 0.28231028\n",
      "  0.28426957 0.28896442]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07883870601654053\n",
      "Predicción post entrenamiento : [[0.29727742]]\n",
      "PERDIDAAAA despues: 0.07689864188432693\n",
      "loss en el callback: 0.07610900700092316, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27637917]\n",
      "  [0.27832696]\n",
      "  [0.27941945]\n",
      "  [0.28140691]\n",
      "  [0.28231028]\n",
      "  [0.28426957]\n",
      "  [0.28896442]\n",
      "  [0.29380116]]]\n",
      "ejemplar: [0.27637917 0.27832696 0.27941945 0.28140691 0.28231028 0.28426957\n",
      " 0.28896442 0.29380116]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29816818]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27637917 0.27832696 0.27941945 0.28140691 0.28231028 0.28426957\n",
      "  0.28896442 0.29380116]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09497857093811035\n",
      "Predicción post entrenamiento : [[0.3020955]]\n",
      "PERDIDAAAA despues: 0.09257330745458603\n",
      "loss en el callback: 0.11298733949661255, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27832696]\n",
      "  [0.27941945]\n",
      "  [0.28140691]\n",
      "  [0.28231028]\n",
      "  [0.28426957]\n",
      "  [0.28896442]\n",
      "  [0.29380116]\n",
      "  [0.29816818]]]\n",
      "ejemplar: [0.27832696 0.27941945 0.28140691 0.28231028 0.28426957 0.28896442\n",
      " 0.29380116 0.29816818]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3033559]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27832696 0.27941945 0.28140691 0.28231028 0.28426957 0.28896442\n",
      "  0.29380116 0.29816818]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0791303813457489\n",
      "Predicción post entrenamiento : [[0.3069669]]\n",
      "PERDIDAAAA despues: 0.0771118625998497\n",
      "loss en el callback: 0.08405754715204239, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27941945]\n",
      "  [0.28140691]\n",
      "  [0.28231028]\n",
      "  [0.28426957]\n",
      "  [0.28896442]\n",
      "  [0.29380116]\n",
      "  [0.29816818]\n",
      "  [0.3033559 ]]]\n",
      "ejemplar: [0.27941945 0.28140691 0.28231028 0.28426957 0.28896442 0.29380116\n",
      " 0.29816818 0.3033559 ]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3083316]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27941945 0.28140691 0.28231028 0.28426957 0.28896442 0.29380116\n",
      "  0.29816818 0.3033559 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06782907992601395\n",
      "Predicción post entrenamiento : [[0.31098738]]\n",
      "PERDIDAAAA despues: 0.06645279377698898\n",
      "loss en el callback: 0.03576713800430298, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28140691]\n",
      "  [0.28231028]\n",
      "  [0.28426957]\n",
      "  [0.28896442]\n",
      "  [0.29380116]\n",
      "  [0.29816818]\n",
      "  [0.3033559 ]\n",
      "  [0.30833161]]]\n",
      "ejemplar: [0.28140691 0.28231028 0.28426957 0.28896442 0.29380116 0.29816818\n",
      " 0.3033559  0.30833161]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31274256]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28140691 0.28231028 0.28426957 0.28896442 0.29380116 0.29816818\n",
      "  0.3033559  0.30833161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10892082005739212\n",
      "Predicción post entrenamiento : [[0.3166083]]\n",
      "PERDIDAAAA despues: 0.10638412833213806\n",
      "loss en el callback: 0.10157769918441772, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28231028]\n",
      "  [0.28426957]\n",
      "  [0.28896442]\n",
      "  [0.29380116]\n",
      "  [0.29816818]\n",
      "  [0.3033559 ]\n",
      "  [0.30833161]\n",
      "  [0.31274256]]]\n",
      "ejemplar: [0.28231028 0.28426957 0.28896442 0.29380116 0.29816818 0.3033559\n",
      " 0.30833161 0.31274256]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3186775]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28231028 0.28426957 0.28896442 0.29380116 0.29816818 0.3033559\n",
      "  0.30833161 0.31274256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11770492047071457\n",
      "Predicción post entrenamiento : [[0.32256153]]\n",
      "PERDIDAAAA despues: 0.11505493521690369\n",
      "loss en el callback: 0.16079169511795044, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28426957]\n",
      "  [0.28896442]\n",
      "  [0.29380116]\n",
      "  [0.29816818]\n",
      "  [0.3033559 ]\n",
      "  [0.30833161]\n",
      "  [0.31274256]\n",
      "  [0.31867751]]]\n",
      "ejemplar: [0.28426957 0.28896442 0.29380116 0.29816818 0.3033559  0.30833161\n",
      " 0.31274256 0.31867751]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32530898]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28426957 0.28896442 0.29380116 0.29816818 0.3033559  0.30833161\n",
      "  0.31274256 0.31867751]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12088555097579956\n",
      "Predicción post entrenamiento : [[0.3293753]]\n",
      "PERDIDAAAA despues: 0.11807448416948318\n",
      "loss en el callback: 0.11164561659097672, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28896442]\n",
      "  [0.29380116]\n",
      "  [0.29816818]\n",
      "  [0.3033559 ]\n",
      "  [0.30833161]\n",
      "  [0.31274256]\n",
      "  [0.31867751]\n",
      "  [0.32530898]]]\n",
      "ejemplar: [0.28896442 0.29380116 0.29816818 0.3033559  0.30833161 0.31274256\n",
      " 0.31867751 0.32530898]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3327155]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28896442 0.29380116 0.29816818 0.3033559  0.30833161 0.31274256\n",
      "  0.31867751 0.32530898]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14277954399585724\n",
      "Predicción post entrenamiento : [[0.33703232]]\n",
      "PERDIDAAAA despues: 0.13953585922718048\n",
      "loss en el callback: 0.14951017498970032, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29380116]\n",
      "  [0.29816818]\n",
      "  [0.3033559 ]\n",
      "  [0.30833161]\n",
      "  [0.31274256]\n",
      "  [0.31867751]\n",
      "  [0.32530898]\n",
      "  [0.33271551]]]\n",
      "ejemplar: [0.29380116 0.29816818 0.3033559  0.30833161 0.31274256 0.31867751\n",
      " 0.32530898 0.33271551]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34045988]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29380116 0.29816818 0.3033559  0.30833161 0.31274256 0.31867751\n",
      "  0.32530898 0.33271551]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1321546584367752\n",
      "Predicción post entrenamiento : [[0.344279]]\n",
      "PERDIDAAAA despues: 0.12939250469207764\n",
      "loss en el callback: 0.1430584341287613, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29816818]\n",
      "  [0.3033559 ]\n",
      "  [0.30833161]\n",
      "  [0.31274256]\n",
      "  [0.31867751]\n",
      "  [0.32530898]\n",
      "  [0.33271551]\n",
      "  [0.34045988]]]\n",
      "ejemplar: [0.29816818 0.3033559  0.30833161 0.31274256 0.31867751 0.32530898\n",
      " 0.33271551 0.34045988]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3478172]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29816818 0.3033559  0.30833161 0.31274256 0.31867751 0.32530898\n",
      "  0.33271551 0.34045988]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14395977556705475\n",
      "Predicción post entrenamiento : [[0.3517741]]\n",
      "PERDIDAAAA despues: 0.1409727782011032\n",
      "loss en el callback: 0.10880457609891891, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.3033559 ]\n",
      "  [0.30833161]\n",
      "  [0.31274256]\n",
      "  [0.31867751]\n",
      "  [0.32530898]\n",
      "  [0.33271551]\n",
      "  [0.34045988]\n",
      "  [0.34781721]]]\n",
      "ejemplar: [0.3033559  0.30833161 0.31274256 0.31867751 0.32530898 0.33271551\n",
      " 0.34045988 0.34781721]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35560542]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.3033559  0.30833161 0.31274256 0.31867751 0.32530898 0.33271551\n",
      "  0.34045988 0.34781721]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13467630743980408\n",
      "Predicción post entrenamiento : [[0.35938084]]\n",
      "PERDIDAAAA despues: 0.13191953301429749\n",
      "loss en el callback: 0.20752863585948944, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30833161]\n",
      "  [0.31274256]\n",
      "  [0.31867751]\n",
      "  [0.32530898]\n",
      "  [0.33271551]\n",
      "  [0.34045988]\n",
      "  [0.34781721]\n",
      "  [0.35560542]]]\n",
      "ejemplar: [0.30833161 0.31274256 0.31867751 0.32530898 0.33271551 0.34045988\n",
      " 0.34781721 0.35560542]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36341292]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30833161 0.31274256 0.31867751 0.32530898 0.33271551 0.34045988\n",
      "  0.34781721 0.35560542]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16677503287792206\n",
      "Predicción post entrenamiento : [[0.36762705]]\n",
      "PERDIDAAAA despues: 0.16335083544254303\n",
      "loss en el callback: 0.12786422669887543, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31274256]\n",
      "  [0.31867751]\n",
      "  [0.32530898]\n",
      "  [0.33271551]\n",
      "  [0.34045988]\n",
      "  [0.34781721]\n",
      "  [0.35560542]\n",
      "  [0.36341292]]]\n",
      "ejemplar: [0.31274256 0.31867751 0.32530898 0.33271551 0.34045988 0.34781721\n",
      " 0.35560542 0.36341292]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37199992]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31274256 0.31867751 0.32530898 0.33271551 0.34045988 0.34781721\n",
      "  0.35560542 0.36341292]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12427420914173126\n",
      "Predicción post entrenamiento : [[0.37555757]]\n",
      "PERDIDAAAA despues: 0.12177854031324387\n",
      "loss en el callback: 0.12834393978118896, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31867751]\n",
      "  [0.32530898]\n",
      "  [0.33271551]\n",
      "  [0.34045988]\n",
      "  [0.34781721]\n",
      "  [0.35560542]\n",
      "  [0.36341292]\n",
      "  [0.37199992]]]\n",
      "ejemplar: [0.31867751 0.32530898 0.33271551 0.34045988 0.34781721 0.35560542\n",
      " 0.36341292 0.37199992]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38051412]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31867751 0.32530898 0.33271551 0.34045988 0.34781721 0.35560542\n",
      "  0.36341292 0.37199992]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08441557735204697\n",
      "Predicción post entrenamiento : [[0.38367814]]\n",
      "PERDIDAAAA despues: 0.08258701115846634\n",
      "loss en el callback: 0.09059002250432968, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32530898]\n",
      "  [0.33271551]\n",
      "  [0.34045988]\n",
      "  [0.34781721]\n",
      "  [0.35560542]\n",
      "  [0.36341292]\n",
      "  [0.37199992]\n",
      "  [0.38051412]]]\n",
      "ejemplar: [0.32530898 0.33271551 0.34045988 0.34781721 0.35560542 0.36341292\n",
      " 0.37199992 0.38051412]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38898528]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32530898 0.33271551 0.34045988 0.34781721 0.35560542 0.36341292\n",
      "  0.37199992 0.38051412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08110224455595016\n",
      "Predicción post entrenamiento : [[0.39207625]]\n",
      "PERDIDAAAA despues: 0.0793512687087059\n",
      "loss en el callback: 0.12296546250581741, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33271551]\n",
      "  [0.34045988]\n",
      "  [0.34781721]\n",
      "  [0.35560542]\n",
      "  [0.36341292]\n",
      "  [0.37199992]\n",
      "  [0.38051412]\n",
      "  [0.38898528]]]\n",
      "ejemplar: [0.33271551 0.34045988 0.34781721 0.35560542 0.36341292 0.37199992\n",
      " 0.38051412 0.38898528]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3976507]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33271551 0.34045988 0.34781721 0.35560542 0.36341292 0.37199992\n",
      "  0.38051412 0.38898528]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10036293417215347\n",
      "Predicción post entrenamiento : [[0.40091944]]\n",
      "PERDIDAAAA despues: 0.09830253571271896\n",
      "loss en el callback: 0.13561215996742249, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34045988]\n",
      "  [0.34781721]\n",
      "  [0.35560542]\n",
      "  [0.36341292]\n",
      "  [0.37199992]\n",
      "  [0.38051412]\n",
      "  [0.38898528]\n",
      "  [0.39765069]]]\n",
      "ejemplar: [0.34045988 0.34781721 0.35560542 0.36341292 0.37199992 0.38051412\n",
      " 0.38898528 0.39765069]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40663773]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34045988 0.34781721 0.35560542 0.36341292 0.37199992 0.38051412\n",
      "  0.38898528 0.39765069]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11374431103467941\n",
      "Predicción post entrenamiento : [[0.4101909]]\n",
      "PERDIDAAAA despues: 0.11136024445295334\n",
      "loss en el callback: 0.14805655181407928, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34781721]\n",
      "  [0.35560542]\n",
      "  [0.36341292]\n",
      "  [0.37199992]\n",
      "  [0.38051412]\n",
      "  [0.38898528]\n",
      "  [0.39765069]\n",
      "  [0.40663773]]]\n",
      "ejemplar: [0.34781721 0.35560542 0.36341292 0.37199992 0.38051412 0.38898528\n",
      " 0.39765069 0.40663773]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41601378]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34781721 0.35560542 0.36341292 0.37199992 0.38051412 0.38898528\n",
      "  0.39765069 0.40663773]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0939878299832344\n",
      "Predicción post entrenamiento : [[0.4191385]]\n",
      "PERDIDAAAA despues: 0.09208168089389801\n",
      "loss en el callback: 0.103298619389534, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35560542]\n",
      "  [0.36341292]\n",
      "  [0.37199992]\n",
      "  [0.38051412]\n",
      "  [0.38898528]\n",
      "  [0.39765069]\n",
      "  [0.40663773]\n",
      "  [0.41601378]]]\n",
      "ejemplar: [0.35560542 0.36341292 0.37199992 0.38051412 0.38898528 0.39765069\n",
      " 0.40663773 0.41601378]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42519984]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35560542 0.36341292 0.37199992 0.38051412 0.38898528 0.39765069\n",
      "  0.40663773 0.41601378]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07515357434749603\n",
      "Predicción post entrenamiento : [[0.42765835]]\n",
      "PERDIDAAAA despues: 0.07381165772676468\n",
      "loss en el callback: 0.046945542097091675, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36341292]\n",
      "  [0.37199992]\n",
      "  [0.38051412]\n",
      "  [0.38898528]\n",
      "  [0.39765069]\n",
      "  [0.40663773]\n",
      "  [0.41601378]\n",
      "  [0.42519984]]]\n",
      "ejemplar: [0.36341292 0.37199992 0.38051412 0.38898528 0.39765069 0.40663773\n",
      " 0.41601378 0.42519984]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43391037]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36341292 0.37199992 0.38051412 0.38898528 0.39765069 0.40663773\n",
      "  0.41601378 0.42519984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09205202013254166\n",
      "Predicción post entrenamiento : [[0.43691072]]\n",
      "PERDIDAAAA despues: 0.09024040400981903\n",
      "loss en el callback: 0.0941053256392479, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.37199992]\n",
      "  [0.38051412]\n",
      "  [0.38898528]\n",
      "  [0.39765069]\n",
      "  [0.40663773]\n",
      "  [0.41601378]\n",
      "  [0.42519984]\n",
      "  [0.43391037]]]\n",
      "ejemplar: [0.37199992 0.38051412 0.38898528 0.39765069 0.40663773 0.41601378\n",
      " 0.42519984 0.43391037]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4433972]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.37199992 0.38051412 0.38898528 0.39765069 0.40663773 0.41601378\n",
      "  0.42519984 0.43391037]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07729992270469666\n",
      "Predicción post entrenamiento : [[0.44586322]]\n",
      "PERDIDAAAA despues: 0.0759347528219223\n",
      "loss en el callback: 0.05602683126926422, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38051412]\n",
      "  [0.38898528]\n",
      "  [0.39765069]\n",
      "  [0.40663773]\n",
      "  [0.41601378]\n",
      "  [0.42519984]\n",
      "  [0.43391037]\n",
      "  [0.44339719]]]\n",
      "ejemplar: [0.38051412 0.38898528 0.39765069 0.40663773 0.41601378 0.42519984\n",
      " 0.43391037 0.44339719]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45243683]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38051412 0.38898528 0.39765069 0.40663773 0.41601378 0.42519984\n",
      "  0.43391037 0.44339719]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07090336829423904\n",
      "Predicción post entrenamiento : [[0.4550036]]\n",
      "PERDIDAAAA despues: 0.0695430263876915\n",
      "loss en el callback: 0.07725008577108383, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38898528]\n",
      "  [0.39765069]\n",
      "  [0.40663773]\n",
      "  [0.41601378]\n",
      "  [0.42519984]\n",
      "  [0.43391037]\n",
      "  [0.44339719]\n",
      "  [0.45243683]]]\n",
      "ejemplar: [0.38898528 0.39765069 0.40663773 0.41601378 0.42519984 0.43391037\n",
      " 0.44339719 0.45243683]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.46170476]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38898528 0.39765069 0.40663773 0.41601378 0.42519984 0.43391037\n",
      "  0.44339719 0.45243683]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.045136090368032455\n",
      "Predicción post entrenamiento : [[0.46353742]]\n",
      "PERDIDAAAA despues: 0.04436074197292328\n",
      "loss en el callback: 0.033994510769844055, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39765069]\n",
      "  [0.40663773]\n",
      "  [0.41601378]\n",
      "  [0.42519984]\n",
      "  [0.43391037]\n",
      "  [0.44339719]\n",
      "  [0.45243683]\n",
      "  [0.46170476]]]\n",
      "ejemplar: [0.39765069 0.40663773 0.41601378 0.42519984 0.43391037 0.44339719\n",
      " 0.45243683 0.46170476]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47040078]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39765069 0.40663773 0.41601378 0.42519984 0.43391037 0.44339719\n",
      "  0.45243683 0.46170476]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05205956846475601\n",
      "Predicción post entrenamiento : [[0.4727125]]\n",
      "PERDIDAAAA despues: 0.05101000517606735\n",
      "loss en el callback: 0.06211180239915848, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40663773]\n",
      "  [0.41601378]\n",
      "  [0.42519984]\n",
      "  [0.43391037]\n",
      "  [0.44339719]\n",
      "  [0.45243683]\n",
      "  [0.46170476]\n",
      "  [0.47040078]]]\n",
      "ejemplar: [0.40663773 0.41601378 0.42519984 0.43391037 0.44339719 0.45243683\n",
      " 0.46170476 0.47040078]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47971573]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40663773 0.41601378 0.42519984 0.43391037 0.44339719 0.45243683\n",
      "  0.46170476 0.47040078]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05823659896850586\n",
      "Predicción post entrenamiento : [[0.4820975]]\n",
      "PERDIDAAAA despues: 0.05709272250533104\n",
      "loss en el callback: 0.06317123025655746, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41601378]\n",
      "  [0.42519984]\n",
      "  [0.43391037]\n",
      "  [0.44339719]\n",
      "  [0.45243683]\n",
      "  [0.46170476]\n",
      "  [0.47040078]\n",
      "  [0.47971573]]]\n",
      "ejemplar: [0.41601378 0.42519984 0.43391037 0.44339719 0.45243683 0.46170476\n",
      " 0.47040078 0.47971573]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.48917562]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41601378 0.42519984 0.43391037 0.44339719 0.45243683 0.46170476\n",
      "  0.47040078 0.47971573]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054481398314237595\n",
      "Predicción post entrenamiento : [[0.4911158]]\n",
      "PERDIDAAAA despues: 0.053579431027173996\n",
      "loss en el callback: 0.04330122843384743, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42519984]\n",
      "  [0.43391037]\n",
      "  [0.44339719]\n",
      "  [0.45243683]\n",
      "  [0.46170476]\n",
      "  [0.47040078]\n",
      "  [0.47971573]\n",
      "  [0.48917562]]]\n",
      "ejemplar: [0.42519984 0.43391037 0.44339719 0.45243683 0.46170476 0.47040078\n",
      " 0.47971573 0.48917562]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.49817327]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42519984 0.43391037 0.44339719 0.45243683 0.46170476 0.47040078\n",
      "  0.47971573 0.48917562]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0666273683309555\n",
      "Predicción post entrenamiento : [[0.50043595]]\n",
      "PERDIDAAAA despues: 0.06546438485383987\n",
      "loss en el callback: 0.05953443795442581, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43391037]\n",
      "  [0.44339719]\n",
      "  [0.45243683]\n",
      "  [0.46170476]\n",
      "  [0.47040078]\n",
      "  [0.47971573]\n",
      "  [0.48917562]\n",
      "  [0.49817327]]]\n",
      "ejemplar: [0.43391037 0.44339719 0.45243683 0.46170476 0.47040078 0.47971573\n",
      " 0.48917562 0.49817327]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5075142]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43391037 0.44339719 0.45243683 0.46170476 0.47040078 0.47971573\n",
      "  0.48917562 0.49817327]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10244612395763397\n",
      "Predicción post entrenamiento : [[0.51047105]]\n",
      "PERDIDAAAA despues: 0.10056204348802567\n",
      "loss en el callback: 0.10728689283132553, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44339719]\n",
      "  [0.45243683]\n",
      "  [0.46170476]\n",
      "  [0.47040078]\n",
      "  [0.47971573]\n",
      "  [0.48917562]\n",
      "  [0.49817327]\n",
      "  [0.50751418]]]\n",
      "ejemplar: [0.44339719 0.45243683 0.46170476 0.47040078 0.47971573 0.48917562\n",
      " 0.49817327 0.50751418]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.51769614]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44339719 0.45243683 0.46170476 0.47040078 0.47971573 0.48917562\n",
      "  0.49817327 0.50751418]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10312193632125854\n",
      "Predicción post entrenamiento : [[0.5202444]]\n",
      "PERDIDAAAA despues: 0.10149179399013519\n",
      "loss en el callback: 0.06805084645748138, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45243683]\n",
      "  [0.46170476]\n",
      "  [0.47040078]\n",
      "  [0.47971573]\n",
      "  [0.48917562]\n",
      "  [0.49817327]\n",
      "  [0.50751418]\n",
      "  [0.51769614]]]\n",
      "ejemplar: [0.45243683 0.46170476 0.47040078 0.47971573 0.48917562 0.49817327\n",
      " 0.50751418 0.51769614]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5274368]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45243683 0.46170476 0.47040078 0.47971573 0.48917562 0.49817327\n",
      "  0.50751418 0.51769614]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07119772583246231\n",
      "Predicción post entrenamiento : [[0.52965367]]\n",
      "PERDIDAAAA despues: 0.07001958042383194\n",
      "loss en el callback: 0.055499520152807236, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46170476]\n",
      "  [0.47040078]\n",
      "  [0.47971573]\n",
      "  [0.48917562]\n",
      "  [0.49817327]\n",
      "  [0.50751418]\n",
      "  [0.51769614]\n",
      "  [0.52743679]]]\n",
      "ejemplar: [0.46170476 0.47040078 0.47971573 0.48917562 0.49817327 0.50751418\n",
      " 0.51769614 0.52743679]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.53692925]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46170476 0.47040078 0.47971573 0.48917562 0.49817327 0.50751418\n",
      "  0.51769614 0.52743679]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06094749644398689\n",
      "Predicción post entrenamiento : [[0.53854686]]\n",
      "PERDIDAAAA despues: 0.060151416808366776\n",
      "loss en el callback: 0.02563246339559555, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47040078]\n",
      "  [0.47971573]\n",
      "  [0.48917562]\n",
      "  [0.49817327]\n",
      "  [0.50751418]\n",
      "  [0.51769614]\n",
      "  [0.52743679]\n",
      "  [0.53692925]]]\n",
      "ejemplar: [0.47040078 0.47971573 0.48917562 0.49817327 0.50751418 0.51769614\n",
      " 0.52743679 0.53692925]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5458654]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47040078 0.47971573 0.48917562 0.49817327 0.50751418 0.51769614\n",
      "  0.52743679 0.53692925]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04930797964334488\n",
      "Predicción post entrenamiento : [[0.5473014]]\n",
      "PERDIDAAAA despues: 0.048672307282686234\n",
      "loss en el callback: 0.019798683002591133, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.47971573]\n",
      "  [0.48917562]\n",
      "  [0.49817327]\n",
      "  [0.50751418]\n",
      "  [0.51769614]\n",
      "  [0.52743679]\n",
      "  [0.53692925]\n",
      "  [0.54586542]]]\n",
      "ejemplar: [0.47971573 0.48917562 0.49817327 0.50751418 0.51769614 0.52743679\n",
      " 0.53692925 0.54586542]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.55482554]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.47971573 0.48917562 0.49817327 0.50751418 0.51769614 0.52743679\n",
      "  0.53692925 0.54586542]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052786942571401596\n",
      "Predicción post entrenamiento : [[0.55677456]]\n",
      "PERDIDAAAA despues: 0.051895152777433395\n",
      "loss en el callback: 0.04548567160964012, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.48917562]\n",
      "  [0.49817327]\n",
      "  [0.50751418]\n",
      "  [0.51769614]\n",
      "  [0.52743679]\n",
      "  [0.53692925]\n",
      "  [0.54586542]\n",
      "  [0.55482554]]]\n",
      "ejemplar: [0.48917562 0.49817327 0.50751418 0.51769614 0.52743679 0.53692925\n",
      " 0.54586542 0.55482554]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5643719]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.48917562 0.49817327 0.50751418 0.51769614 0.52743679 0.53692925\n",
      "  0.54586542 0.55482554]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09882050007581711\n",
      "Predicción post entrenamiento : [[0.56760424]]\n",
      "PERDIDAAAA despues: 0.09679871797561646\n",
      "loss en el callback: 0.1595267802476883, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.49817327]\n",
      "  [0.50751418]\n",
      "  [0.51769614]\n",
      "  [0.52743679]\n",
      "  [0.53692925]\n",
      "  [0.54586542]\n",
      "  [0.55482554]\n",
      "  [0.56437188]]]\n",
      "ejemplar: [0.49817327 0.50751418 0.51769614 0.52743679 0.53692925 0.54586542\n",
      " 0.55482554 0.56437188]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.57524246]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.49817327 0.50751418 0.51769614 0.52743679 0.53692925 0.54586542\n",
      "  0.55482554 0.56437188]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09023243933916092\n",
      "Predicción post entrenamiento : [[0.5778368]]\n",
      "PERDIDAAAA despues: 0.08868055045604706\n",
      "loss en el callback: 0.08320460468530655, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.50751418]\n",
      "  [0.51769614]\n",
      "  [0.52743679]\n",
      "  [0.53692925]\n",
      "  [0.54586542]\n",
      "  [0.55482554]\n",
      "  [0.56437188]\n",
      "  [0.57524246]]]\n",
      "ejemplar: [0.50751418 0.51769614 0.52743679 0.53692925 0.54586542 0.55482554\n",
      " 0.56437188 0.57524246]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.58564216]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.50751418 0.51769614 0.52743679 0.53692925 0.54586542 0.55482554\n",
      "  0.56437188 0.57524246]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06930247694253922\n",
      "Predicción post entrenamiento : [[0.58841896]]\n",
      "PERDIDAAAA despues: 0.06784817576408386\n",
      "loss en el callback: 0.12988045811653137, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.51769614]\n",
      "  [0.52743679]\n",
      "  [0.53692925]\n",
      "  [0.54586542]\n",
      "  [0.55482554]\n",
      "  [0.56437188]\n",
      "  [0.57524246]\n",
      "  [0.58564216]]]\n",
      "ejemplar: [0.51769614 0.52743679 0.53692925 0.54586542 0.55482554 0.56437188\n",
      " 0.57524246 0.58564216]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.596328]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.51769614 0.52743679 0.53692925 0.54586542 0.55482554 0.56437188\n",
      "  0.57524246 0.58564216]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04926600679755211\n",
      "Predicción post entrenamiento : [[0.59806335]]\n",
      "PERDIDAAAA despues: 0.048498671501874924\n",
      "loss en el callback: 0.04119407385587692, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.52743679]\n",
      "  [0.53692925]\n",
      "  [0.54586542]\n",
      "  [0.55482554]\n",
      "  [0.56437188]\n",
      "  [0.57524246]\n",
      "  [0.58564216]\n",
      "  [0.59632802]]]\n",
      "ejemplar: [0.52743679 0.53692925 0.54586542 0.55482554 0.56437188 0.57524246\n",
      " 0.58564216 0.59632802]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6058689]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.52743679 0.53692925 0.54586542 0.55482554 0.56437188 0.57524246\n",
      "  0.58564216 0.59632802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04881555959582329\n",
      "Predicción post entrenamiento : [[0.6076251]]\n",
      "PERDIDAAAA despues: 0.04804258421063423\n",
      "loss en el callback: 0.04118594527244568, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.53692925]\n",
      "  [0.54586542]\n",
      "  [0.55482554]\n",
      "  [0.56437188]\n",
      "  [0.57524246]\n",
      "  [0.58564216]\n",
      "  [0.59632802]\n",
      "  [0.60586888]]]\n",
      "ejemplar: [0.53692925 0.54586542 0.55482554 0.56437188 0.57524246 0.58564216\n",
      " 0.59632802 0.60586888]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.615445]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.53692925 0.54586542 0.55482554 0.56437188 0.57524246 0.58564216\n",
      "  0.59632802 0.60586888]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028869230300188065\n",
      "Predicción post entrenamiento : [[0.6174671]]\n",
      "PERDIDAAAA despues: 0.028186175972223282\n",
      "loss en el callback: 0.07125740498304367, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.54586542]\n",
      "  [0.55482554]\n",
      "  [0.56437188]\n",
      "  [0.57524246]\n",
      "  [0.58564216]\n",
      "  [0.59632802]\n",
      "  [0.60586888]\n",
      "  [0.61544502]]]\n",
      "ejemplar: [0.54586542 0.55482554 0.56437188 0.57524246 0.58564216 0.59632802\n",
      " 0.60586888 0.61544502]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.62538767]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.54586542 0.55482554 0.56437188 0.57524246 0.58564216 0.59632802\n",
      "  0.60586888 0.61544502]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026843974366784096\n",
      "Predicción post entrenamiento : [[0.6263182]]\n",
      "PERDIDAAAA despues: 0.026539916172623634\n",
      "loss en el callback: 0.010303611867129803, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.55482554]\n",
      "  [0.56437188]\n",
      "  [0.57524246]\n",
      "  [0.58564216]\n",
      "  [0.59632802]\n",
      "  [0.60586888]\n",
      "  [0.61544502]\n",
      "  [0.62538767]]]\n",
      "ejemplar: [0.55482554 0.56437188 0.57524246 0.58564216 0.59632802 0.60586888\n",
      " 0.61544502 0.62538767]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6345163]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.55482554 0.56437188 0.57524246 0.58564216 0.59632802 0.60586888\n",
      "  0.61544502 0.62538767]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03986271098256111\n",
      "Predicción post entrenamiento : [[0.6363969]]\n",
      "PERDIDAAAA despues: 0.0391153059899807\n",
      "loss en el callback: 0.05359336733818054, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.56437188]\n",
      "  [0.57524246]\n",
      "  [0.58564216]\n",
      "  [0.59632802]\n",
      "  [0.60586888]\n",
      "  [0.61544502]\n",
      "  [0.62538767]\n",
      "  [0.6345163 ]]]\n",
      "ejemplar: [0.56437188 0.57524246 0.58564216 0.59632802 0.60586888 0.61544502\n",
      " 0.62538767 0.6345163 ]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6449115]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.56437188 0.57524246 0.58564216 0.59632802 0.60586888 0.61544502\n",
      "  0.62538767 0.6345163 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028077784925699234\n",
      "Predicción post entrenamiento : [[0.64635336]]\n",
      "PERDIDAAAA despues: 0.027596663683652878\n",
      "loss en el callback: 0.028674283996224403, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.57524246]\n",
      "  [0.58564216]\n",
      "  [0.59632802]\n",
      "  [0.60586888]\n",
      "  [0.61544502]\n",
      "  [0.62538767]\n",
      "  [0.6345163 ]\n",
      "  [0.64491153]]]\n",
      "ejemplar: [0.57524246 0.58564216 0.59632802 0.60586888 0.61544502 0.62538767\n",
      " 0.6345163  0.64491153]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.65505487]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.57524246 0.58564216 0.59632802 0.60586888 0.61544502 0.62538767\n",
      "  0.6345163  0.64491153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021370047703385353\n",
      "Predicción post entrenamiento : [[0.6557518]]\n",
      "PERDIDAAAA despues: 0.021166764199733734\n",
      "loss en el callback: 0.00606556748971343, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.58564216]\n",
      "  [0.59632802]\n",
      "  [0.60586888]\n",
      "  [0.61544502]\n",
      "  [0.62538767]\n",
      "  [0.6345163 ]\n",
      "  [0.64491153]\n",
      "  [0.65505487]]]\n",
      "ejemplar: [0.58564216 0.59632802 0.60586888 0.61544502 0.62538767 0.6345163\n",
      " 0.64491153 0.65505487]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.66427654]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.58564216 0.59632802 0.60586888 0.61544502 0.62538767 0.6345163\n",
      "  0.64491153 0.65505487]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01929335482418537\n",
      "Predicción post entrenamiento : [[0.6657826]]\n",
      "PERDIDAAAA despues: 0.018877245485782623\n",
      "loss en el callback: 0.03904062882065773, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.59632802]\n",
      "  [0.60586888]\n",
      "  [0.61544502]\n",
      "  [0.62538767]\n",
      "  [0.6345163 ]\n",
      "  [0.64491153]\n",
      "  [0.65505487]\n",
      "  [0.66427654]]]\n",
      "ejemplar: [0.59632802 0.60586888 0.61544502 0.62538767 0.6345163  0.64491153\n",
      " 0.65505487 0.66427654]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.67421585]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.59632802 0.60586888 0.61544502 0.62538767 0.6345163  0.64491153\n",
      "  0.65505487 0.66427654]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014226533472537994\n",
      "Predicción post entrenamiento : [[0.6756263]]\n",
      "PERDIDAAAA despues: 0.013892065733671188\n",
      "loss en el callback: 0.033110085874795914, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.60586888]\n",
      "  [0.61544502]\n",
      "  [0.62538767]\n",
      "  [0.6345163 ]\n",
      "  [0.64491153]\n",
      "  [0.65505487]\n",
      "  [0.66427654]\n",
      "  [0.67421585]]]\n",
      "ejemplar: [0.60586888 0.61544502 0.62538767 0.6345163  0.64491153 0.65505487\n",
      " 0.66427654 0.67421585]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.68385935]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.60586888 0.61544502 0.62538767 0.6345163  0.64491153 0.65505487\n",
      "  0.66427654 0.67421585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005823385901749134\n",
      "Predicción post entrenamiento : [[0.6848683]]\n",
      "PERDIDAAAA despues: 0.0056704189628362656\n",
      "loss en el callback: 0.014941016212105751, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.61544502]\n",
      "  [0.62538767]\n",
      "  [0.6345163 ]\n",
      "  [0.64491153]\n",
      "  [0.65505487]\n",
      "  [0.66427654]\n",
      "  [0.67421585]\n",
      "  [0.68385935]]]\n",
      "ejemplar: [0.61544502 0.62538767 0.6345163  0.64491153 0.65505487 0.66427654\n",
      " 0.67421585 0.68385935]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6931848]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.61544502 0.62538767 0.6345163  0.64491153 0.65505487 0.66427654\n",
      "  0.67421585 0.68385935]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001779921934939921\n",
      "Predicción post entrenamiento : [[0.69339097]]\n",
      "PERDIDAAAA despues: 0.0017625680193305016\n",
      "loss en el callback: 0.0005828489665873349, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.62538767]\n",
      "  [0.6345163 ]\n",
      "  [0.64491153]\n",
      "  [0.65505487]\n",
      "  [0.66427654]\n",
      "  [0.67421585]\n",
      "  [0.68385935]\n",
      "  [0.69318479]]]\n",
      "ejemplar: [0.62538767 0.6345163  0.64491153 0.65505487 0.66427654 0.67421585\n",
      " 0.68385935 0.69318479]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.70178497]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.62538767 0.6345163  0.64491153 0.65505487 0.66427654 0.67421585\n",
      "  0.68385935 0.69318479]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.064152305247262e-05\n",
      "Predicción post entrenamiento : [[0.7013097]]\n",
      "PERDIDAAAA despues: 7.885685772635043e-05\n",
      "loss en el callback: 0.00284199183806777, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.6345163 ]\n",
      "  [0.64491153]\n",
      "  [0.65505487]\n",
      "  [0.66427654]\n",
      "  [0.67421585]\n",
      "  [0.68385935]\n",
      "  [0.69318479]\n",
      "  [0.70178497]]]\n",
      "ejemplar: [0.6345163  0.64491153 0.65505487 0.66427654 0.67421585 0.68385935\n",
      " 0.69318479 0.70178497]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.70967126]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.6345163  0.64491153 0.65505487 0.66427654 0.67421585 0.68385935\n",
      "  0.69318479 0.70178497]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.031104021531064e-06\n",
      "Predicción post entrenamiento : [[0.710294]]\n",
      "PERDIDAAAA despues: 3.3601868381083477e-06\n",
      "loss en el callback: 0.007471744436770678, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.64491153]\n",
      "  [0.65505487]\n",
      "  [0.66427654]\n",
      "  [0.67421585]\n",
      "  [0.68385935]\n",
      "  [0.69318479]\n",
      "  [0.70178497]\n",
      "  [0.70967126]]]\n",
      "ejemplar: [0.64491153 0.65505487 0.66427654 0.67421585 0.68385935 0.69318479\n",
      " 0.70178497 0.70967126]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7188249]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.64491153 0.65505487 0.66427654 0.67421585 0.68385935 0.69318479\n",
      "  0.70178497 0.70967126]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043309363536536694\n",
      "Predicción post entrenamiento : [[0.7183173]]\n",
      "PERDIDAAAA despues: 0.0004544807889033109\n",
      "loss en el callback: 0.0031925751827657223, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.65505487]\n",
      "  [0.66427654]\n",
      "  [0.67421585]\n",
      "  [0.68385935]\n",
      "  [0.69318479]\n",
      "  [0.70178497]\n",
      "  [0.70967126]\n",
      "  [0.71882492]]]\n",
      "ejemplar: [0.65505487 0.66427654 0.67421585 0.68385935 0.69318479 0.70178497\n",
      " 0.70967126 0.71882492]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7266412]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.65505487 0.66427654 0.67421585 0.68385935 0.69318479 0.70178497\n",
      "  0.70967126 0.71882492]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.039439464686438e-05\n",
      "Predicción post entrenamiento : [[0.72719604]]\n",
      "PERDIDAAAA despues: 8.015149796847254e-05\n",
      "loss en el callback: 0.005126417614519596, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.66427654]\n",
      "  [0.67421585]\n",
      "  [0.68385935]\n",
      "  [0.69318479]\n",
      "  [0.70178497]\n",
      "  [0.70967126]\n",
      "  [0.71882492]\n",
      "  [0.72664118]]]\n",
      "ejemplar: [0.66427654 0.67421585 0.68385935 0.69318479 0.70178497 0.70967126\n",
      " 0.71882492 0.72664118]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.735313]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.66427654 0.67421585 0.68385935 0.69318479 0.70178497 0.70967126\n",
      "  0.71882492 0.72664118]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004589017480611801\n",
      "Predicción post entrenamiento : [[0.73477435]]\n",
      "PERDIDAAAA despues: 0.004516329150646925\n",
      "loss en el callback: 0.004337591119110584, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.67421585]\n",
      "  [0.68385935]\n",
      "  [0.69318479]\n",
      "  [0.70178497]\n",
      "  [0.70967126]\n",
      "  [0.71882492]\n",
      "  [0.72664118]\n",
      "  [0.735313  ]]]\n",
      "ejemplar: [0.67421585 0.68385935 0.69318479 0.70178497 0.70967126 0.71882492\n",
      " 0.72664118 0.735313  ]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.74287385]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.67421585 0.68385935 0.69318479 0.70178497 0.70967126 0.71882492\n",
      "  0.72664118 0.735313  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005325852427631617\n",
      "Predicción post entrenamiento : [[0.74288106]]\n",
      "PERDIDAAAA despues: 0.005326904822140932\n",
      "loss en el callback: 9.666401865615626e-07, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.68385935]\n",
      "  [0.69318479]\n",
      "  [0.70178497]\n",
      "  [0.70967126]\n",
      "  [0.71882492]\n",
      "  [0.72664118]\n",
      "  [0.735313  ]\n",
      "  [0.74287385]]]\n",
      "ejemplar: [0.68385935 0.69318479 0.70178497 0.70967126 0.71882492 0.72664118\n",
      " 0.735313   0.74287385]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.75071543]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.68385935 0.69318479 0.70178497 0.70967126 0.71882492 0.72664118\n",
      "  0.735313   0.74287385]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002925317967310548\n",
      "Predicción post entrenamiento : [[0.7502241]]\n",
      "PERDIDAAAA despues: 0.002872411860153079\n",
      "loss en el callback: 0.0036083522718399763, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.69318479]\n",
      "  [0.70178497]\n",
      "  [0.70967126]\n",
      "  [0.71882492]\n",
      "  [0.72664118]\n",
      "  [0.735313  ]\n",
      "  [0.74287385]\n",
      "  [0.75071543]]]\n",
      "ejemplar: [0.69318479 0.70178497 0.70967126 0.71882492 0.72664118 0.735313\n",
      " 0.74287385 0.75071543]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7577966]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.69318479 0.70178497 0.70967126 0.71882492 0.72664118 0.735313\n",
      "  0.74287385 0.75071543]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010373271070420742\n",
      "Predicción post entrenamiento : [[0.7570601]]\n",
      "PERDIDAAAA despues: 0.010223794728517532\n",
      "loss en el callback: 0.009127206169068813, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.70178497]\n",
      "  [0.70967126]\n",
      "  [0.71882492]\n",
      "  [0.72664118]\n",
      "  [0.735313  ]\n",
      "  [0.74287385]\n",
      "  [0.75071543]\n",
      "  [0.75779659]]]\n",
      "ejemplar: [0.70178497 0.70967126 0.71882492 0.72664118 0.735313   0.74287385\n",
      " 0.75071543 0.75779659]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7643869]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.70178497 0.70967126 0.71882492 0.72664118 0.735313   0.74287385\n",
      "  0.75071543 0.75779659]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007323975674808025\n",
      "Predicción post entrenamiento : [[0.76264966]]\n",
      "PERDIDAAAA despues: 0.007029647473245859\n",
      "loss en el callback: 0.0384683720767498, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.70967126]\n",
      "  [0.71882492]\n",
      "  [0.72664118]\n",
      "  [0.735313  ]\n",
      "  [0.74287385]\n",
      "  [0.75071543]\n",
      "  [0.75779659]\n",
      "  [0.76438689]]]\n",
      "ejemplar: [0.70967126 0.71882492 0.72664118 0.735313   0.74287385 0.75071543\n",
      " 0.75779659 0.76438689]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7698641]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.70967126 0.71882492 0.72664118 0.735313   0.74287385 0.75071543\n",
      "  0.75779659 0.76438689]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008792728185653687\n",
      "Predicción post entrenamiento : [[0.7676777]]\n",
      "PERDIDAAAA despues: 0.008387480862438679\n",
      "loss en el callback: 0.05400197580456734, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.71882492]\n",
      "  [0.72664118]\n",
      "  [0.735313  ]\n",
      "  [0.74287385]\n",
      "  [0.75071543]\n",
      "  [0.75779659]\n",
      "  [0.76438689]\n",
      "  [0.76986408]]]\n",
      "ejemplar: [0.71882492 0.72664118 0.735313   0.74287385 0.75071543 0.75779659\n",
      " 0.76438689 0.76986408]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.77492136]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.71882492 0.72664118 0.735313   0.74287385 0.75071543 0.75779659\n",
      "  0.76438689 0.76986408]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002057456411421299\n",
      "Predicción post entrenamiento : [[0.775624]]\n",
      "PERDIDAAAA despues: 0.002121690660715103\n",
      "loss en el callback: 0.011273980140686035, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.72664118]\n",
      "  [0.735313  ]\n",
      "  [0.74287385]\n",
      "  [0.75071543]\n",
      "  [0.75779659]\n",
      "  [0.76438689]\n",
      "  [0.76986408]\n",
      "  [0.77492136]]]\n",
      "ejemplar: [0.72664118 0.735313   0.74287385 0.75071543 0.75779659 0.76438689\n",
      " 0.76986408 0.77492136]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7824755]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.72664118 0.735313   0.74287385 0.75071543 0.75779659 0.76438689\n",
      "  0.76986408 0.77492136]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006592937279492617\n",
      "Predicción post entrenamiento : [[0.7814646]]\n",
      "PERDIDAAAA despues: 0.006429796107113361\n",
      "loss en el callback: 0.015790630131959915, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.735313  ]\n",
      "  [0.74287385]\n",
      "  [0.75071543]\n",
      "  [0.75779659]\n",
      "  [0.76438689]\n",
      "  [0.76986408]\n",
      "  [0.77492136]\n",
      "  [0.78247547]]]\n",
      "ejemplar: [0.735313   0.74287385 0.75071543 0.75779659 0.76438689 0.76986408\n",
      " 0.77492136 0.78247547]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7881873]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.735313   0.74287385 0.75071543 0.75779659 0.76438689 0.76986408\n",
      "  0.77492136 0.78247547]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004266428295522928\n",
      "Predicción post entrenamiento : [[0.78779984]]\n",
      "PERDIDAAAA despues: 0.0004107855202164501\n",
      "loss en el callback: 0.0022907417733222246, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.74287385]\n",
      "  [0.75071543]\n",
      "  [0.75779659]\n",
      "  [0.76438689]\n",
      "  [0.76986408]\n",
      "  [0.77492136]\n",
      "  [0.78247547]\n",
      "  [0.78818733]]]\n",
      "ejemplar: [0.74287385 0.75071543 0.75779659 0.76438689 0.76986408 0.77492136\n",
      " 0.78247547 0.78818733]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7940693]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.74287385 0.75071543 0.75779659 0.76438689 0.76986408 0.77492136\n",
      "  0.78247547 0.78818733]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015159810427576303\n",
      "Predicción post entrenamiento : [[0.7929539]]\n",
      "PERDIDAAAA despues: 0.0014303689822554588\n",
      "loss en el callback: 0.017124269157648087, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.75071543]\n",
      "  [0.75779659]\n",
      "  [0.76438689]\n",
      "  [0.76986408]\n",
      "  [0.77492136]\n",
      "  [0.78247547]\n",
      "  [0.78818733]\n",
      "  [0.79406929]]]\n",
      "ejemplar: [0.75071543 0.75779659 0.76438689 0.76986408 0.77492136 0.78247547\n",
      " 0.78818733 0.79406929]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7989763]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.75071543 0.75779659 0.76438689 0.76986408 0.77492136 0.78247547\n",
      "  0.78818733 0.79406929]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002906964858993888\n",
      "Predicción post entrenamiento : [[0.79864156]]\n",
      "PERDIDAAAA despues: 0.0028709808830171824\n",
      "loss en el callback: 0.0018526038620620966, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.75779659]\n",
      "  [0.76438689]\n",
      "  [0.76986408]\n",
      "  [0.77492136]\n",
      "  [0.78247547]\n",
      "  [0.78818733]\n",
      "  [0.79406929]\n",
      "  [0.7989763 ]]]\n",
      "ejemplar: [0.75779659 0.76438689 0.76986408 0.77492136 0.78247547 0.78818733\n",
      " 0.79406929 0.7989763 ]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.80425906]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.75779659 0.76438689 0.76986408 0.77492136 0.78247547 0.78818733\n",
      "  0.79406929 0.7989763 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027274498715996742\n",
      "Predicción post entrenamiento : [[0.8037307]]\n",
      "PERDIDAAAA despues: 0.0026725444477051497\n",
      "loss en el callback: 0.004566957708448172, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.76438689]\n",
      "  [0.76986408]\n",
      "  [0.77492136]\n",
      "  [0.78247547]\n",
      "  [0.78818733]\n",
      "  [0.79406929]\n",
      "  [0.7989763 ]\n",
      "  [0.80425906]]]\n",
      "ejemplar: [0.76438689 0.76986408 0.77492136 0.78247547 0.78818733 0.79406929\n",
      " 0.7989763  0.80425906]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8090726]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.76438689 0.76986408 0.77492136 0.78247547 0.78818733 0.79406929\n",
      "  0.7989763  0.80425906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009854577481746674\n",
      "Predicción post entrenamiento : [[0.8079514]]\n",
      "PERDIDAAAA despues: 0.009633226320147514\n",
      "loss en el callback: 0.019432727247476578, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.76986408]\n",
      "  [0.77492136]\n",
      "  [0.78247547]\n",
      "  [0.78818733]\n",
      "  [0.79406929]\n",
      "  [0.7989763 ]\n",
      "  [0.80425906]\n",
      "  [0.80907261]]]\n",
      "ejemplar: [0.76986408 0.77492136 0.78247547 0.78818733 0.79406929 0.7989763\n",
      " 0.80425906 0.80907261]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.813093]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.76986408 0.77492136 0.78247547 0.78818733 0.79406929 0.7989763\n",
      "  0.80425906 0.80907261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015046202577650547\n",
      "Predicción post entrenamiento : [[0.8117504]]\n",
      "PERDIDAAAA despues: 0.014718631282448769\n",
      "loss en el callback: 0.031070254743099213, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.77492136]\n",
      "  [0.78247547]\n",
      "  [0.78818733]\n",
      "  [0.79406929]\n",
      "  [0.7989763 ]\n",
      "  [0.80425906]\n",
      "  [0.80907261]\n",
      "  [0.81309301]]]\n",
      "ejemplar: [0.77492136 0.78247547 0.78818733 0.79406929 0.7989763  0.80425906\n",
      " 0.80907261 0.81309301]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8169576]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.77492136 0.78247547 0.78818733 0.79406929 0.7989763  0.80425906\n",
      "  0.80907261 0.81309301]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003918612841516733\n",
      "Predicción post entrenamiento : [[0.8173336]]\n",
      "PERDIDAAAA despues: 0.003965826705098152\n",
      "loss en el callback: 0.0029768787790089846, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.78247547]\n",
      "  [0.78818733]\n",
      "  [0.79406929]\n",
      "  [0.7989763 ]\n",
      "  [0.80425906]\n",
      "  [0.80907261]\n",
      "  [0.81309301]\n",
      "  [0.81695759]]]\n",
      "ejemplar: [0.78247547 0.78818733 0.79406929 0.7989763  0.80425906 0.80907261\n",
      " 0.81309301 0.81695759]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8226993]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.78247547 0.78818733 0.79406929 0.7989763  0.80425906 0.80907261\n",
      "  0.81309301 0.81695759]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010099971666932106\n",
      "Predicción post entrenamiento : [[0.8224259]]\n",
      "PERDIDAAAA despues: 0.010045092552900314\n",
      "loss en el callback: 0.0014928808668628335, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.78818733]\n",
      "  [0.79406929]\n",
      "  [0.7989763 ]\n",
      "  [0.80425906]\n",
      "  [0.80907261]\n",
      "  [0.81309301]\n",
      "  [0.81695759]\n",
      "  [0.82269931]]]\n",
      "ejemplar: [0.78818733 0.79406929 0.7989763  0.80425906 0.80907261 0.81309301\n",
      " 0.81695759 0.82269931]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8271891]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.78818733 0.79406929 0.7989763  0.80425906 0.80907261 0.81309301\n",
      "  0.81695759 0.82269931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045451128971762955\n",
      "Predicción post entrenamiento : [[0.82667226]]\n",
      "PERDIDAAAA despues: 0.0004768153594341129\n",
      "loss en el callback: 0.004135808441787958, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.79406929]\n",
      "  [0.7989763 ]\n",
      "  [0.80425906]\n",
      "  [0.80907261]\n",
      "  [0.81309301]\n",
      "  [0.81695759]\n",
      "  [0.82269931]\n",
      "  [0.82718909]]]\n",
      "ejemplar: [0.79406929 0.7989763  0.80425906 0.80907261 0.81309301 0.81695759\n",
      " 0.82269931 0.82718909]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.83124757]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.79406929 0.7989763  0.80425906 0.80907261 0.81309301 0.81695759\n",
      "  0.82269931 0.82718909]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0055079273879528046\n",
      "Predicción post entrenamiento : [[0.832273]]\n",
      "PERDIDAAAA despues: 0.0053567723371088505\n",
      "loss en el callback: 0.021720020100474358, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.7989763 ]\n",
      "  [0.80425906]\n",
      "  [0.80907261]\n",
      "  [0.81309301]\n",
      "  [0.81695759]\n",
      "  [0.82269931]\n",
      "  [0.82718909]\n",
      "  [0.83124757]]]\n",
      "ejemplar: [0.7989763  0.80425906 0.80907261 0.81309301 0.81695759 0.82269931\n",
      " 0.82718909 0.83124757]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.83655965]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.7989763  0.80425906 0.80907261 0.81309301 0.81695759 0.82269931\n",
      "  0.82718909 0.83124757]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020845215767621994\n",
      "Predicción post entrenamiento : [[0.8356178]]\n",
      "PERDIDAAAA despues: 0.002171414205804467\n",
      "loss en el callback: 0.011269005946815014, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.80425906]\n",
      "  [0.80907261]\n",
      "  [0.81309301]\n",
      "  [0.81695759]\n",
      "  [0.82269931]\n",
      "  [0.82718909]\n",
      "  [0.83124757]\n",
      "  [0.83655965]]]\n",
      "ejemplar: [0.80425906 0.80907261 0.81309301 0.81695759 0.82269931 0.82718909\n",
      " 0.83124757 0.83655965]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.839845]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.80425906 0.80907261 0.81309301 0.81695759 0.82269931 0.82718909\n",
      "  0.83124757 0.83655965]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0046162074431777\n",
      "Predicción post entrenamiento : [[0.83992386]]\n",
      "PERDIDAAAA despues: 0.004605498164892197\n",
      "loss en el callback: 0.00010222818673355505, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.80907261]\n",
      "  [0.81309301]\n",
      "  [0.81695759]\n",
      "  [0.82269931]\n",
      "  [0.82718909]\n",
      "  [0.83124757]\n",
      "  [0.83655965]\n",
      "  [0.839845  ]]]\n",
      "ejemplar: [0.80907261 0.81309301 0.81695759 0.82269931 0.82718909 0.83124757\n",
      " 0.83655965 0.839845  ]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.84396315]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.80907261 0.81309301 0.81695759 0.82269931 0.82718909 0.83124757\n",
      "  0.83655965 0.839845  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002080686390399933\n",
      "Predicción post entrenamiento : [[0.84443015]]\n",
      "PERDIDAAAA despues: 0.002038300270214677\n",
      "loss en el callback: 0.0046747480519115925, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.81309301]\n",
      "  [0.81695759]\n",
      "  [0.82269931]\n",
      "  [0.82718909]\n",
      "  [0.83124757]\n",
      "  [0.83655965]\n",
      "  [0.839845  ]\n",
      "  [0.84396315]]]\n",
      "ejemplar: [0.81309301 0.81695759 0.82269931 0.82718909 0.83124757 0.83655965\n",
      " 0.839845   0.84396315]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.84838367]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.81309301 0.81695759 0.82269931 0.82718909 0.83124757 0.83655965\n",
      "  0.839845   0.84396315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007007148233242333\n",
      "Predicción post entrenamiento : [[0.84932685]]\n",
      "PERDIDAAAA despues: 0.0006516703288070858\n",
      "loss en el callback: 0.023230798542499542, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.81695759]\n",
      "  [0.82269931]\n",
      "  [0.82718909]\n",
      "  [0.83124757]\n",
      "  [0.83655965]\n",
      "  [0.839845  ]\n",
      "  [0.84396315]\n",
      "  [0.84838367]]]\n",
      "ejemplar: [0.81695759 0.82269931 0.82718909 0.83124757 0.83655965 0.839845\n",
      " 0.84396315 0.84838367]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.85341036]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.81695759 0.82269931 0.82718909 0.83124757 0.83655965 0.839845\n",
      "  0.84396315 0.84838367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035762288607656956\n",
      "Predicción post entrenamiento : [[0.8539306]]\n",
      "PERDIDAAAA despues: 0.003514278447255492\n",
      "loss en el callback: 0.005169628653675318, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.82269931]\n",
      "  [0.82718909]\n",
      "  [0.83124757]\n",
      "  [0.83655965]\n",
      "  [0.839845  ]\n",
      "  [0.84396315]\n",
      "  [0.84838367]\n",
      "  [0.85341036]]]\n",
      "ejemplar: [0.82269931 0.82718909 0.83124757 0.83655965 0.839845   0.84396315\n",
      " 0.84838367 0.85341036]\n",
      "y: 1.0\n",
      "Predicción : [[0.8582013]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.82269931 0.82718909 0.83124757 0.83655965 0.839845   0.84396315\n",
      "  0.84838367 0.85341036]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020106865093111992\n",
      "Predicción post entrenamiento : [[0.8600049]]\n",
      "PERDIDAAAA despues: 0.01959862746298313\n",
      "loss en el callback: 0.07382097095251083, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.82718909]\n",
      "  [0.83124757]\n",
      "  [0.83655965]\n",
      "  [0.839845  ]\n",
      "  [0.84396315]\n",
      "  [0.84838367]\n",
      "  [0.85341036]\n",
      "  [0.85820132]]]\n",
      "ejemplar: [0.82718909 0.83124757 0.83655965 0.839845   0.84396315 0.84838367\n",
      " 0.85341036 0.85820132]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.863926]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.82718909 0.83124757 0.83655965 0.839845   0.84396315 0.84838367\n",
      "  0.85341036 0.85820132]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01136954315006733\n",
      "Predicción post entrenamiento : [[0.86438894]]\n",
      "PERDIDAAAA despues: 0.011271030642092228\n",
      "loss en el callback: 0.003979215864092112, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.83124757]\n",
      "  [0.83655965]\n",
      "  [0.839845  ]\n",
      "  [0.84396315]\n",
      "  [0.84838367]\n",
      "  [0.85341036]\n",
      "  [0.85820132]\n",
      "  [0.86392599]]]\n",
      "ejemplar: [0.83124757 0.83655965 0.839845   0.84396315 0.84838367 0.85341036\n",
      " 0.85820132 0.86392599]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8682859]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.83124757 0.83655965 0.839845   0.84396315 0.84838367 0.85341036\n",
      "  0.85820132 0.86392599]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004209420585539192\n",
      "Predicción post entrenamiento : [[0.8693015]]\n",
      "PERDIDAAAA despues: 0.0003802994906436652\n",
      "loss en el callback: 0.028419174253940582, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.83655965]\n",
      "  [0.839845  ]\n",
      "  [0.84396315]\n",
      "  [0.84838367]\n",
      "  [0.85341036]\n",
      "  [0.85820132]\n",
      "  [0.86392599]\n",
      "  [0.86828589]]]\n",
      "ejemplar: [0.83655965 0.839845   0.84396315 0.84838367 0.85341036 0.85820132\n",
      " 0.86392599 0.86828589]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.87331736]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.83655965 0.839845   0.84396315 0.84838367 0.85341036 0.85820132\n",
      "  0.86392599 0.86828589]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.1501244191313162e-05\n",
      "Predicción post entrenamiento : [[0.872738]]\n",
      "PERDIDAAAA despues: 2.720979136938695e-05\n",
      "loss en el callback: 0.005640037357807159, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.839845  ]\n",
      "  [0.84396315]\n",
      "  [0.84838367]\n",
      "  [0.85341036]\n",
      "  [0.85820132]\n",
      "  [0.86392599]\n",
      "  [0.86828589]\n",
      "  [0.87331736]]]\n",
      "ejemplar: [0.839845   0.84396315 0.84838367 0.85341036 0.85820132 0.86392599\n",
      " 0.86828589 0.87331736]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8765337]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.839845   0.84396315 0.84838367 0.85341036 0.85820132 0.86392599\n",
      "  0.86828589 0.87331736]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007638534298166633\n",
      "Predicción post entrenamiento : [[0.8760137]]\n",
      "PERDIDAAAA despues: 0.000735380919650197\n",
      "loss en el callback: 0.004844348877668381, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.84396315]\n",
      "  [0.84838367]\n",
      "  [0.85341036]\n",
      "  [0.85820132]\n",
      "  [0.86392599]\n",
      "  [0.86828589]\n",
      "  [0.87331736]\n",
      "  [0.87653369]]]\n",
      "ejemplar: [0.84396315 0.84838367 0.85341036 0.85820132 0.86392599 0.86828589\n",
      " 0.87331736 0.87653369]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8801754]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.84396315 0.84838367 0.85341036 0.85820132 0.86392599 0.86828589\n",
      "  0.87331736 0.87653369]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021162417251616716\n",
      "Predicción post entrenamiento : [[0.88136476]]\n",
      "PERDIDAAAA despues: 0.002227082848548889\n",
      "loss en el callback: 0.05157414451241493, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.84838367]\n",
      "  [0.85341036]\n",
      "  [0.85820132]\n",
      "  [0.86392599]\n",
      "  [0.86828589]\n",
      "  [0.87331736]\n",
      "  [0.87653369]\n",
      "  [0.88017541]]]\n",
      "ejemplar: [0.84838367 0.85341036 0.85820132 0.86392599 0.86828589 0.87331736\n",
      " 0.87653369 0.88017541]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8856986]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.84838367 0.85341036 0.85820132 0.86392599 0.86828589 0.87331736\n",
      "  0.87653369 0.88017541]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009365868754684925\n",
      "Predicción post entrenamiento : [[0.8857549]]\n",
      "PERDIDAAAA despues: 0.000940033991355449\n",
      "loss en el callback: 6.54291216051206e-05, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.85341036]\n",
      "  [0.85820132]\n",
      "  [0.86392599]\n",
      "  [0.86828589]\n",
      "  [0.87331736]\n",
      "  [0.87653369]\n",
      "  [0.88017541]\n",
      "  [0.88569862]]]\n",
      "ejemplar: [0.85341036 0.85820132 0.86392599 0.86828589 0.87331736 0.87653369\n",
      " 0.88017541 0.88569862]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.89018106]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.85341036 0.85820132 0.86392599 0.86828589 0.87331736 0.87653369\n",
      "  0.88017541 0.88569862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002231704565929249\n",
      "Predicción post entrenamiento : [[0.88916034]]\n",
      "PERDIDAAAA despues: 0.00019371521193534136\n",
      "loss en el callback: 0.016757523640990257, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.85820132]\n",
      "  [0.86392599]\n",
      "  [0.86828589]\n",
      "  [0.87331736]\n",
      "  [0.87653369]\n",
      "  [0.88017541]\n",
      "  [0.88569862]\n",
      "  [0.89018106]]]\n",
      "ejemplar: [0.85820132 0.86392599 0.86828589 0.87331736 0.87653369 0.88017541\n",
      " 0.88569862 0.89018106]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.89348984]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.85820132 0.86392599 0.86828589 0.87331736 0.87653369 0.88017541\n",
      "  0.88569862 0.89018106]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013291607610881329\n",
      "Predicción post entrenamiento : [[0.8936619]]\n",
      "PERDIDAAAA despues: 0.001341737573966384\n",
      "loss en el callback: 0.0006360592669807374, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.86392599]\n",
      "  [0.86828589]\n",
      "  [0.87331736]\n",
      "  [0.87653369]\n",
      "  [0.88017541]\n",
      "  [0.88569862]\n",
      "  [0.89018106]\n",
      "  [0.89348984]]]\n",
      "ejemplar: [0.86392599 0.86828589 0.87331736 0.87653369 0.88017541 0.88569862\n",
      " 0.89018106 0.89348984]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.89792925]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.86392599 0.86828589 0.87331736 0.87653369 0.88017541 0.88569862\n",
      "  0.89018106 0.89348984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002291643526405096\n",
      "Predicción post entrenamiento : [[0.8975149]]\n",
      "PERDIDAAAA despues: 0.002252142410725355\n",
      "loss en el callback: 0.0035333139821887016, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.86828589]\n",
      "  [0.87331736]\n",
      "  [0.87653369]\n",
      "  [0.88017541]\n",
      "  [0.88569862]\n",
      "  [0.89018106]\n",
      "  [0.89348984]\n",
      "  [0.89792925]]]\n",
      "ejemplar: [0.86828589 0.87331736 0.87653369 0.88017541 0.88569862 0.89018106\n",
      " 0.89348984 0.89792925]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.90140957]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.86828589 0.87331736 0.87653369 0.88017541 0.88569862 0.89018106\n",
      "  0.89348984 0.89792925]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003447211580350995\n",
      "Predicción post entrenamiento : [[0.90119207]]\n",
      "PERDIDAAAA despues: 0.003421718953177333\n",
      "loss en el callback: 0.0010412768460810184, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.87331736]\n",
      "  [0.87653369]\n",
      "  [0.88017541]\n",
      "  [0.88569862]\n",
      "  [0.89018106]\n",
      "  [0.89348984]\n",
      "  [0.89792925]\n",
      "  [0.90140957]]]\n",
      "ejemplar: [0.87331736 0.87653369 0.88017541 0.88569862 0.89018106 0.89348984\n",
      " 0.89792925 0.90140957]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9050546]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.87331736 0.87653369 0.88017541 0.88569862 0.89018106 0.89348984\n",
      "  0.89792925 0.90140957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0067433323711156845\n",
      "Predicción post entrenamiento : [[0.90543836]]\n",
      "PERDIDAAAA despues: 0.0068065025843679905\n",
      "loss en el callback: 0.004367799963802099, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.87653369]\n",
      "  [0.88017541]\n",
      "  [0.88569862]\n",
      "  [0.89018106]\n",
      "  [0.89348984]\n",
      "  [0.89792925]\n",
      "  [0.90140957]\n",
      "  [0.90505463]]]\n",
      "ejemplar: [0.87653369 0.88017541 0.88569862 0.89018106 0.89348984 0.89792925\n",
      " 0.90140957 0.90505463]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9090522]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.87653369 0.88017541 0.88569862 0.89018106 0.89348984 0.89792925\n",
      "  0.90140957 0.90505463]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018102670088410378\n",
      "Predicción post entrenamiento : [[0.90859276]]\n",
      "PERDIDAAAA despues: 0.017979251220822334\n",
      "loss en el callback: 0.005305965896695852, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.88017541]\n",
      "  [0.88569862]\n",
      "  [0.89018106]\n",
      "  [0.89348984]\n",
      "  [0.89792925]\n",
      "  [0.90140957]\n",
      "  [0.90505463]\n",
      "  [0.90905219]]]\n",
      "ejemplar: [0.88017541 0.88569862 0.89018106 0.89348984 0.89792925 0.90140957\n",
      " 0.90505463 0.90905219]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9124572]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.88017541 0.88569862 0.89018106 0.89348984 0.89792925 0.90140957\n",
      "  0.90505463 0.90905219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01645193062722683\n",
      "Predicción post entrenamiento : [[0.9117451]]\n",
      "PERDIDAAAA despues: 0.016269749030470848\n",
      "loss en el callback: 0.011824537068605423, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.88569862]\n",
      "  [0.89018106]\n",
      "  [0.89348984]\n",
      "  [0.89792925]\n",
      "  [0.90140957]\n",
      "  [0.90505463]\n",
      "  [0.90905219]\n",
      "  [0.91245723]]]\n",
      "ejemplar: [0.88569862 0.89018106 0.89348984 0.89792925 0.90140957 0.90505463\n",
      " 0.90905219 0.91245723]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.91575265]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.88569862 0.89018106 0.89348984 0.89792925 0.90140957 0.90505463\n",
      "  0.90905219 0.91245723]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031369340140372515\n",
      "Predicción post entrenamiento : [[0.9162691]]\n",
      "PERDIDAAAA despues: 0.0031950545962899923\n",
      "loss en el callback: 0.008064682595431805, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.89018106]\n",
      "  [0.89348984]\n",
      "  [0.89792925]\n",
      "  [0.90140957]\n",
      "  [0.90505463]\n",
      "  [0.90905219]\n",
      "  [0.91245723]\n",
      "  [0.91575265]]]\n",
      "ejemplar: [0.89018106 0.89348984 0.89792925 0.90140957 0.90505463 0.90905219\n",
      " 0.91245723 0.91575265]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9198485]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.89018106 0.89348984 0.89792925 0.90140957 0.90505463 0.90905219\n",
      "  0.91245723 0.91575265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004293978214263916\n",
      "Predicción post entrenamiento : [[0.91976863]]\n",
      "PERDIDAAAA despues: 0.004283517133444548\n",
      "loss en el callback: 0.00016040306945797056, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.89348984]\n",
      "  [0.89792925]\n",
      "  [0.90140957]\n",
      "  [0.90505463]\n",
      "  [0.90905219]\n",
      "  [0.91245723]\n",
      "  [0.91575265]\n",
      "  [0.9198485 ]]]\n",
      "ejemplar: [0.89348984 0.89792925 0.90140957 0.90505463 0.90905219 0.91245723\n",
      " 0.91575265 0.9198485 ]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9231512]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.89348984 0.89792925 0.90140957 0.90505463 0.90905219 0.91245723\n",
      "  0.91575265 0.9198485 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007441870868206024\n",
      "Predicción post entrenamiento : [[0.9224736]]\n",
      "PERDIDAAAA despues: 0.00732542434707284\n",
      "loss en el callback: 0.009918857365846634, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.89792925]\n",
      "  [0.90140957]\n",
      "  [0.90505463]\n",
      "  [0.90905219]\n",
      "  [0.91245723]\n",
      "  [0.91575265]\n",
      "  [0.9198485 ]\n",
      "  [0.9231512 ]]]\n",
      "ejemplar: [0.89792925 0.90140957 0.90505463 0.90905219 0.91245723 0.91575265\n",
      " 0.9198485  0.9231512 ]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9259752]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.89792925 0.90140957 0.90505463 0.90905219 0.91245723 0.91575265\n",
      "  0.9198485  0.9231512 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009228355251252651\n",
      "Predicción post entrenamiento : [[0.9244932]]\n",
      "PERDIDAAAA despues: 0.00894581526517868\n",
      "loss en el callback: 0.04022693261504173, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.90140957]\n",
      "  [0.90505463]\n",
      "  [0.90905219]\n",
      "  [0.91245723]\n",
      "  [0.91575265]\n",
      "  [0.9198485 ]\n",
      "  [0.9231512 ]\n",
      "  [0.9259752 ]]]\n",
      "ejemplar: [0.90140957 0.90505463 0.90905219 0.91245723 0.91575265 0.9198485\n",
      " 0.9231512  0.9259752 ]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9277765]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.90140957 0.90505463 0.90905219 0.91245723 0.91575265 0.9198485\n",
      "  0.9231512  0.9259752 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016421563923358917\n",
      "Predicción post entrenamiento : [[0.927878]]\n",
      "PERDIDAAAA despues: 0.0016503934748470783\n",
      "loss en el callback: 0.0002626855275593698, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.90505463]\n",
      "  [0.90905219]\n",
      "  [0.91245723]\n",
      "  [0.91575265]\n",
      "  [0.9198485 ]\n",
      "  [0.9231512 ]\n",
      "  [0.9259752 ]\n",
      "  [0.92777652]]]\n",
      "ejemplar: [0.90505463 0.90905219 0.91245723 0.91575265 0.9198485  0.9231512\n",
      " 0.9259752  0.92777652]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.93118066]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.90505463 0.90905219 0.91245723 0.91575265 0.9198485  0.9231512\n",
      "  0.9259752  0.92777652]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005103151313960552\n",
      "Predicción post entrenamiento : [[0.9304223]]\n",
      "PERDIDAAAA despues: 0.004995379131287336\n",
      "loss en el callback: 0.012887567281723022, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.90905219]\n",
      "  [0.91245723]\n",
      "  [0.91575265]\n",
      "  [0.9198485 ]\n",
      "  [0.9231512 ]\n",
      "  [0.9259752 ]\n",
      "  [0.92777652]\n",
      "  [0.93118066]]]\n",
      "ejemplar: [0.90905219 0.91245723 0.91575265 0.9198485  0.9231512  0.9259752\n",
      " 0.92777652 0.93118066]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9336727]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.90905219 0.91245723 0.91575265 0.9198485  0.9231512  0.9259752\n",
      "  0.92777652 0.93118066]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008850233629345894\n",
      "Predicción post entrenamiento : [[0.93328935]]\n",
      "PERDIDAAAA despues: 0.008778247982263565\n",
      "loss en el callback: 0.0037572490982711315, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.91245723]\n",
      "  [0.91575265]\n",
      "  [0.9198485 ]\n",
      "  [0.9231512 ]\n",
      "  [0.9259752 ]\n",
      "  [0.92777652]\n",
      "  [0.93118066]\n",
      "  [0.93367273]]]\n",
      "ejemplar: [0.91245723 0.91575265 0.9198485  0.9231512  0.9259752  0.92777652\n",
      " 0.93118066 0.93367273]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.93634546]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.91245723 0.91575265 0.9198485  0.9231512  0.9259752  0.92777652\n",
      "  0.93118066 0.93367273]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023268679156899452\n",
      "Predicción post entrenamiento : [[0.93498766]]\n",
      "PERDIDAAAA despues: 0.02285628393292427\n",
      "loss en el callback: 0.0419529564678669, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.91575265]\n",
      "  [0.9198485 ]\n",
      "  [0.9231512 ]\n",
      "  [0.9259752 ]\n",
      "  [0.92777652]\n",
      "  [0.93118066]\n",
      "  [0.93367273]\n",
      "  [0.93634546]]]\n",
      "ejemplar: [0.91575265 0.9198485  0.9231512  0.9259752  0.92777652 0.93118066\n",
      " 0.93367273 0.93634546]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.93797034]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.91575265 0.9198485  0.9231512  0.9259752  0.92777652 0.93118066\n",
      "  0.93367273 0.93634546]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014323984272778034\n",
      "Predicción post entrenamiento : [[0.9365388]]\n",
      "PERDIDAAAA despues: 0.013983375392854214\n",
      "loss en el callback: 0.04273902252316475, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.9198485 ]\n",
      "  [0.9231512 ]\n",
      "  [0.9259752 ]\n",
      "  [0.92777652]\n",
      "  [0.93118066]\n",
      "  [0.93367273]\n",
      "  [0.93634546]\n",
      "  [0.93797034]]]\n",
      "ejemplar: [0.9198485  0.9231512  0.9259752  0.92777652 0.93118066 0.93367273\n",
      " 0.93634546 0.93797034]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.93943954]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.9198485  0.9231512  0.9259752  0.92777652 0.93118066 0.93367273\n",
      "  0.93634546 0.93797034]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02198498509824276\n",
      "Predicción post entrenamiento : [[0.9374308]]\n",
      "PERDIDAAAA despues: 0.021393336355686188\n",
      "loss en el callback: 0.07977636158466339, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.9231512 ]\n",
      "  [0.9259752 ]\n",
      "  [0.92777652]\n",
      "  [0.93118066]\n",
      "  [0.93367273]\n",
      "  [0.93634546]\n",
      "  [0.93797034]\n",
      "  [0.93943954]]]\n",
      "ejemplar: [0.9231512  0.9259752  0.92777652 0.93118066 0.93367273 0.93634546\n",
      " 0.93797034 0.93943954]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.93995833]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.9231512  0.9259752  0.92777652 0.93118066 0.93367273 0.93634546\n",
      "  0.93797034 0.93943954]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03218449652194977\n",
      "Predicción post entrenamiento : [[0.9384866]]\n",
      "PERDIDAAAA despues: 0.0316585972905159\n",
      "loss en el callback: 0.04765725135803223, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.9259752 ]\n",
      "  [0.92777652]\n",
      "  [0.93118066]\n",
      "  [0.93367273]\n",
      "  [0.93634546]\n",
      "  [0.93797034]\n",
      "  [0.93943954]\n",
      "  [0.93995833]]]\n",
      "ejemplar: [0.9259752  0.92777652 0.93118066 0.93367273 0.93634546 0.93797034\n",
      " 0.93943954 0.93995833]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9407853]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.9259752  0.92777652 0.93118066 0.93367273 0.93634546 0.93797034\n",
      "  0.93943954 0.93995833]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022270074114203453\n",
      "Predicción post entrenamiento : [[0.93761694]]\n",
      "PERDIDAAAA despues: 0.02133447863161564\n",
      "loss en el callback: 0.165591761469841, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.92777652]\n",
      "  [0.93118066]\n",
      "  [0.93367273]\n",
      "  [0.93634546]\n",
      "  [0.93797034]\n",
      "  [0.93943954]\n",
      "  [0.93995833]\n",
      "  [0.94078529]]]\n",
      "ejemplar: [0.92777652 0.93118066 0.93367273 0.93634546 0.93797034 0.93943954\n",
      " 0.93995833 0.94078529]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9397541]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.92777652 0.93118066 0.93367273 0.93634546 0.93797034 0.93943954\n",
      "  0.93995833 0.94078529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029261471703648567\n",
      "Predicción post entrenamiento : [[0.9374806]]\n",
      "PERDIDAAAA despues: 0.028488831594586372\n",
      "loss en el callback: 0.1020558550953865, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.93118066]\n",
      "  [0.93367273]\n",
      "  [0.93634546]\n",
      "  [0.93797034]\n",
      "  [0.93943954]\n",
      "  [0.93995833]\n",
      "  [0.94078529]\n",
      "  [0.93975413]]]\n",
      "ejemplar: [0.93118066 0.93367273 0.93634546 0.93797034 0.93943954 0.93995833\n",
      " 0.94078529 0.93975413]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9396817]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.93118066 0.93367273 0.93634546 0.93797034 0.93943954 0.93995833\n",
      "  0.94078529 0.93975413]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029236700385808945\n",
      "Predicción post entrenamiento : [[0.9392768]]\n",
      "PERDIDAAAA despues: 0.029098400846123695\n",
      "loss en el callback: 0.004962153732776642, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.93367273]\n",
      "  [0.93634546]\n",
      "  [0.93797034]\n",
      "  [0.93943954]\n",
      "  [0.93995833]\n",
      "  [0.94078529]\n",
      "  [0.93975413]\n",
      "  [0.93968171]]]\n",
      "ejemplar: [0.93367273 0.93634546 0.93797034 0.93943954 0.93995833 0.94078529\n",
      " 0.93975413 0.93968171]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.94099474]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.93367273 0.93634546 0.93797034 0.93943954 0.93995833 0.94078529\n",
      "  0.93975413 0.93968171]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020186610519886017\n",
      "Predicción post entrenamiento : [[0.93983036]]\n",
      "PERDIDAAAA despues: 0.019857097417116165\n",
      "loss en el callback: 0.031293872743844986, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.93634546]\n",
      "  [0.93797034]\n",
      "  [0.93943954]\n",
      "  [0.93995833]\n",
      "  [0.94078529]\n",
      "  [0.93975413]\n",
      "  [0.93968171]\n",
      "  [0.94099474]]]\n",
      "ejemplar: [0.93634546 0.93797034 0.93943954 0.93995833 0.94078529 0.93975413\n",
      " 0.93968171 0.94099474]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9412003]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.93634546 0.93797034 0.93943954 0.93995833 0.94078529 0.93975413\n",
      "  0.93968171 0.94099474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02286035753786564\n",
      "Predicción post entrenamiento : [[0.9403908]]\n",
      "PERDIDAAAA despues: 0.022616228088736534\n",
      "loss en el callback: 0.017155904322862625, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.93797034]\n",
      "  [0.93943954]\n",
      "  [0.93995833]\n",
      "  [0.94078529]\n",
      "  [0.93975413]\n",
      "  [0.93968171]\n",
      "  [0.94099474]\n",
      "  [0.94120032]]]\n",
      "ejemplar: [0.93797034 0.93943954 0.93995833 0.94078529 0.93975413 0.93968171\n",
      " 0.94099474 0.94120032]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9412547]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.93797034 0.93943954 0.93995833 0.94078529 0.93975413 0.93968171\n",
      "  0.94099474 0.94120032]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032791491597890854\n",
      "Predicción post entrenamiento : [[0.94013655]]\n",
      "PERDIDAAAA despues: 0.03238779306411743\n",
      "loss en el callback: 0.03631601482629776, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.93943954]\n",
      "  [0.93995833]\n",
      "  [0.94078529]\n",
      "  [0.93975413]\n",
      "  [0.93968171]\n",
      "  [0.94099474]\n",
      "  [0.94120032]\n",
      "  [0.94125468]]]\n",
      "ejemplar: [0.93943954 0.93995833 0.94078529 0.93975413 0.93968171 0.94099474\n",
      " 0.94120032 0.94125468]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9406992]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.93943954 0.93995833 0.94078529 0.93975413 0.93968171 0.94099474\n",
      "  0.94120032 0.94125468]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06518112868070602\n",
      "Predicción post entrenamiento : [[0.93993914]]\n",
      "PERDIDAAAA despues: 0.06479360163211823\n",
      "loss en el callback: 0.019616922363638878, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.93995833]\n",
      "  [0.94078529]\n",
      "  [0.93975413]\n",
      "  [0.93968171]\n",
      "  [0.94099474]\n",
      "  [0.94120032]\n",
      "  [0.94125468]\n",
      "  [0.94069922]]]\n",
      "ejemplar: [0.93995833 0.94078529 0.93975413 0.93968171 0.94099474 0.94120032\n",
      " 0.94125468 0.94069922]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9401805]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.93995833 0.94078529 0.93975413 0.93968171 0.94099474 0.94120032\n",
      "  0.94125468 0.94069922]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11221744120121002\n",
      "Predicción post entrenamiento : [[0.93691754]]\n",
      "PERDIDAAAA despues: 0.11004199087619781\n",
      "loss en el callback: 0.2307412326335907, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.94078529]\n",
      "  [0.93975413]\n",
      "  [0.93968171]\n",
      "  [0.94099474]\n",
      "  [0.94120032]\n",
      "  [0.94125468]\n",
      "  [0.94069922]\n",
      "  [0.94018048]]]\n",
      "ejemplar: [0.94078529 0.93975413 0.93968171 0.94099474 0.94120032 0.94125468\n",
      " 0.94069922 0.94018048]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9370607]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.94078529 0.93975413 0.93968171 0.94099474 0.94120032 0.94125468\n",
      "  0.94069922 0.94018048]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0740940049290657\n",
      "Predicción post entrenamiento : [[0.93521893]]\n",
      "PERDIDAAAA despues: 0.07309471815824509\n",
      "loss en el callback: 0.08767885714769363, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.93975413]\n",
      "  [0.93968171]\n",
      "  [0.94099474]\n",
      "  [0.94120032]\n",
      "  [0.94125468]\n",
      "  [0.94069922]\n",
      "  [0.94018048]\n",
      "  [0.93706071]]]\n",
      "ejemplar: [0.93975413 0.93968171 0.94099474 0.94120032 0.94125468 0.94069922\n",
      " 0.94018048 0.93706071]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9351283]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.93975413 0.93968171 0.94099474 0.94120032 0.94125468 0.94069922\n",
      "  0.94018048 0.93706071]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05164851248264313\n",
      "Predicción post entrenamiento : [[0.9341889]]\n",
      "PERDIDAAAA despues: 0.05122242867946625\n",
      "loss en el callback: 0.026672158390283585, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.93968171]\n",
      "  [0.94099474]\n",
      "  [0.94120032]\n",
      "  [0.94125468]\n",
      "  [0.94069922]\n",
      "  [0.94018048]\n",
      "  [0.93706071]\n",
      "  [0.93512827]]]\n",
      "ejemplar: [0.93968171 0.94099474 0.94120032 0.94125468 0.94069922 0.94018048\n",
      " 0.93706071 0.93512827]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9343474]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.93968171 0.94099474 0.94120032 0.94125468 0.94069922 0.94018048\n",
      "  0.93706071 0.93512827]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07262422144412994\n",
      "Predicción post entrenamiento : [[0.9324416]]\n",
      "PERDIDAAAA despues: 0.07160066813230515\n",
      "loss en el callback: 0.09522075951099396, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.94099474]\n",
      "  [0.94120032]\n",
      "  [0.94125468]\n",
      "  [0.94069922]\n",
      "  [0.94018048]\n",
      "  [0.93706071]\n",
      "  [0.93512827]\n",
      "  [0.93434739]]]\n",
      "ejemplar: [0.94099474 0.94120032 0.94125468 0.94069922 0.94018048 0.93706071\n",
      " 0.93512827 0.93434739]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9325424]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.94099474 0.94120032 0.94125468 0.94069922 0.94018048 0.93706071\n",
      "  0.93512827 0.93434739]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04892510920763016\n",
      "Predicción post entrenamiento : [[0.93094057]]\n",
      "PERDIDAAAA despues: 0.048219066113233566\n",
      "loss en el callback: 0.06710594892501831, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.94120032]\n",
      "  [0.94125468]\n",
      "  [0.94069922]\n",
      "  [0.94018048]\n",
      "  [0.93706071]\n",
      "  [0.93512827]\n",
      "  [0.93434739]\n",
      "  [0.93254238]]]\n",
      "ejemplar: [0.94120032 0.94125468 0.94069922 0.94018048 0.93706071 0.93512827\n",
      " 0.93434739 0.93254238]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9304942]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.94120032 0.94125468 0.94069922 0.94018048 0.93706071 0.93512827\n",
      "  0.93434739 0.93254238]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06412913650274277\n",
      "Predicción post entrenamiento : [[0.9284636]]\n",
      "PERDIDAAAA despues: 0.06310480087995529\n",
      "loss en el callback: 0.1092454269528389, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.94125468]\n",
      "  [0.94069922]\n",
      "  [0.94018048]\n",
      "  [0.93706071]\n",
      "  [0.93512827]\n",
      "  [0.93434739]\n",
      "  [0.93254238]\n",
      "  [0.93049419]]]\n",
      "ejemplar: [0.94125468 0.94069922 0.94018048 0.93706071 0.93512827 0.93434739\n",
      " 0.93254238 0.93049419]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9276674]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.94125468 0.94069922 0.94018048 0.93706071 0.93512827 0.93434739\n",
      "  0.93254238 0.93049419]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027409996837377548\n",
      "Predicción post entrenamiento : [[0.92766035]]\n",
      "PERDIDAAAA despues: 0.02740766853094101\n",
      "loss en el callback: 1.991820681723766e-06, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.94069922]\n",
      "  [0.94018048]\n",
      "  [0.93706071]\n",
      "  [0.93512827]\n",
      "  [0.93434739]\n",
      "  [0.93254238]\n",
      "  [0.93049419]\n",
      "  [0.92766738]]]\n",
      "ejemplar: [0.94069922 0.94018048 0.93706071 0.93512827 0.93434739 0.93254238\n",
      " 0.93049419 0.92766738]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9264614]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.94069922 0.94018048 0.93706071 0.93512827 0.93434739 0.93254238\n",
      "  0.93049419 0.92766738]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014258714392781258\n",
      "Predicción post entrenamiento : [[0.9262682]]\n",
      "PERDIDAAAA despues: 0.014212616719305515\n",
      "loss en el callback: 0.0013746515614911914, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.94018048]\n",
      "  [0.93706071]\n",
      "  [0.93512827]\n",
      "  [0.93434739]\n",
      "  [0.93254238]\n",
      "  [0.93049419]\n",
      "  [0.92766738]\n",
      "  [0.9264614 ]]]\n",
      "ejemplar: [0.94018048 0.93706071 0.93512827 0.93434739 0.93254238 0.93049419\n",
      " 0.92766738 0.9264614 ]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9247628]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.94018048 0.93706071 0.93512827 0.93434739 0.93254238 0.93049419\n",
      "  0.92766738 0.9264614 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012006648816168308\n",
      "Predicción post entrenamiento : [[0.9243541]]\n",
      "PERDIDAAAA despues: 0.01191724743694067\n",
      "loss en el callback: 0.005284496117383242, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.93706071]\n",
      "  [0.93512827]\n",
      "  [0.93434739]\n",
      "  [0.93254238]\n",
      "  [0.93049419]\n",
      "  [0.92766738]\n",
      "  [0.9264614 ]\n",
      "  [0.92476279]]]\n",
      "ejemplar: [0.93706071 0.93512827 0.93434739 0.93254238 0.93049419 0.92766738\n",
      " 0.9264614  0.92476279]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9224761]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.93706071 0.93512827 0.93434739 0.93254238 0.93049419 0.92766738\n",
      "  0.9264614  0.92476279]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002636795397847891\n",
      "Predicción post entrenamiento : [[0.9221996]]\n",
      "PERDIDAAAA despues: 0.00025477606686763465\n",
      "loss en el callback: 0.002092895330861211, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.93512827]\n",
      "  [0.93434739]\n",
      "  [0.93254238]\n",
      "  [0.93049419]\n",
      "  [0.92766738]\n",
      "  [0.9264614 ]\n",
      "  [0.92476279]\n",
      "  [0.92247611]]]\n",
      "ejemplar: [0.93512827 0.93434739 0.93254238 0.93049419 0.92766738 0.9264614\n",
      " 0.92476279 0.92247611]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9206725]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.93512827 0.93434739 0.93254238 0.93049419 0.92766738 0.9264614\n",
      "  0.92476279 0.92247611]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015235793543979526\n",
      "Predicción post entrenamiento : [[0.921116]]\n",
      "PERDIDAAAA despues: 0.0014891524333506823\n",
      "loss en el callback: 0.006626742426306009, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.93434739]\n",
      "  [0.93254238]\n",
      "  [0.93049419]\n",
      "  [0.92766738]\n",
      "  [0.9264614 ]\n",
      "  [0.92476279]\n",
      "  [0.92247611]\n",
      "  [0.92067248]]]\n",
      "ejemplar: [0.93434739 0.93254238 0.93049419 0.92766738 0.9264614  0.92476279\n",
      " 0.92247611 0.92067248]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9196306]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.93434739 0.93254238 0.93049419 0.92766738 0.9264614  0.92476279\n",
      "  0.92247611 0.92067248]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020002617966383696\n",
      "Predicción post entrenamiento : [[0.91904885]]\n",
      "PERDIDAAAA despues: 0.002052636118605733\n",
      "loss en el callback: 0.008801113814115524, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.93254238]\n",
      "  [0.93049419]\n",
      "  [0.92766738]\n",
      "  [0.9264614 ]\n",
      "  [0.92476279]\n",
      "  [0.92247611]\n",
      "  [0.92067248]\n",
      "  [0.91963059]]]\n",
      "ejemplar: [0.93254238 0.93049419 0.92766738 0.9264614  0.92476279 0.92247611\n",
      " 0.92067248 0.91963059]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9172635]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.93254238 0.93049419 0.92766738 0.9264614  0.92476279 0.92247611\n",
      "  0.92067248 0.91963059]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008547204197384417\n",
      "Predicción post entrenamiento : [[0.9166633]]\n",
      "PERDIDAAAA despues: 0.0008199851145036519\n",
      "loss en el callback: 0.010129417292773724, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.93049419]\n",
      "  [0.92766738]\n",
      "  [0.9264614 ]\n",
      "  [0.92476279]\n",
      "  [0.92247611]\n",
      "  [0.92067248]\n",
      "  [0.91963059]\n",
      "  [0.91726351]]]\n",
      "ejemplar: [0.93049419 0.92766738 0.9264614  0.92476279 0.92247611 0.92067248\n",
      " 0.91963059 0.91726351]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.91484296]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.93049419 0.92766738 0.9264614  0.92476279 0.92247611 0.92067248\n",
      "  0.91963059 0.91726351]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004913189332000911\n",
      "Predicción post entrenamiento : [[0.9152618]]\n",
      "PERDIDAAAA despues: 0.0005100622656755149\n",
      "loss en el callback: 0.0070204949006438255, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.92766738]\n",
      "  [0.9264614 ]\n",
      "  [0.92476279]\n",
      "  [0.92247611]\n",
      "  [0.92067248]\n",
      "  [0.91963059]\n",
      "  [0.91726351]\n",
      "  [0.91484296]]]\n",
      "ejemplar: [0.92766738 0.9264614  0.92476279 0.92247611 0.92067248 0.91963059\n",
      " 0.91726351 0.91484296]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.91347796]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.92766738 0.9264614  0.92476279 0.92247611 0.92067248 0.91963059\n",
      "  0.91726351 0.91484296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014619751600548625\n",
      "Predicción post entrenamiento : [[0.9122561]]\n",
      "PERDIDAAAA despues: 0.0013700323179364204\n",
      "loss en el callback: 0.03751152381300926, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.9264614 ]\n",
      "  [0.92476279]\n",
      "  [0.92247611]\n",
      "  [0.92067248]\n",
      "  [0.91963059]\n",
      "  [0.91726351]\n",
      "  [0.91484296]\n",
      "  [0.91347796]]]\n",
      "ejemplar: [0.9264614  0.92476279 0.92247611 0.92067248 0.91963059 0.91726351\n",
      " 0.91484296 0.91347796]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.91075176]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.9264614  0.92476279 0.92247611 0.92067248 0.91963059 0.91726351\n",
      "  0.91484296 0.91347796]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003590257838368416\n",
      "Predicción post entrenamiento : [[0.91079724]]\n",
      "PERDIDAAAA despues: 0.0035957100335508585\n",
      "loss en el callback: 7.767148781567812e-05, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.92476279]\n",
      "  [0.92247611]\n",
      "  [0.92067248]\n",
      "  [0.91963059]\n",
      "  [0.91726351]\n",
      "  [0.91484296]\n",
      "  [0.91347796]\n",
      "  [0.91075176]]]\n",
      "ejemplar: [0.92476279 0.92247611 0.92067248 0.91963059 0.91726351 0.91484296\n",
      " 0.91347796 0.91075176]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9091201]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.92476279 0.92247611 0.92067248 0.91963059 0.91726351 0.91484296\n",
      "  0.91347796 0.91075176]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036269656848162413\n",
      "Predicción post entrenamiento : [[0.9090623]]\n",
      "PERDIDAAAA despues: 0.0036200121976435184\n",
      "loss en el callback: 0.00013400233001448214, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.92247611]\n",
      "  [0.92067248]\n",
      "  [0.91963059]\n",
      "  [0.91726351]\n",
      "  [0.91484296]\n",
      "  [0.91347796]\n",
      "  [0.91075176]\n",
      "  [0.90912008]]]\n",
      "ejemplar: [0.92247611 0.92067248 0.91963059 0.91726351 0.91484296 0.91347796\n",
      " 0.91075176 0.90912008]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.90732646]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.92247611 0.92067248 0.91963059 0.91726351 0.91484296 0.91347796\n",
      "  0.91075176 0.90912008]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003035040572285652\n",
      "Predicción post entrenamiento : [[0.9072202]]\n",
      "PERDIDAAAA despues: 0.0030467614997178316\n",
      "loss en el callback: 0.0003515919961500913, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.92067248]\n",
      "  [0.91963059]\n",
      "  [0.91726351]\n",
      "  [0.91484296]\n",
      "  [0.91347796]\n",
      "  [0.91075176]\n",
      "  [0.90912008]\n",
      "  [0.90732646]]]\n",
      "ejemplar: [0.92067248 0.91963059 0.91726351 0.91484296 0.91347796 0.91075176\n",
      " 0.90912008 0.90732646]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9055886]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.92067248 0.91963059 0.91726351 0.91484296 0.91347796 0.91075176\n",
      "  0.90912008 0.90732646]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003875472815707326\n",
      "Predicción post entrenamiento : [[0.9050541]]\n",
      "PERDIDAAAA despues: 0.003942311741411686\n",
      "loss en el callback: 0.008547899313271046, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.91963059]\n",
      "  [0.91726351]\n",
      "  [0.91484296]\n",
      "  [0.91347796]\n",
      "  [0.91075176]\n",
      "  [0.90912008]\n",
      "  [0.90732646]\n",
      "  [0.90558863]]]\n",
      "ejemplar: [0.91963059 0.91726351 0.91484296 0.91347796 0.91075176 0.90912008\n",
      " 0.90732646 0.90558863]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.90339476]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.91963059 0.91726351 0.91484296 0.91347796 0.91075176 0.90912008\n",
      "  0.90732646 0.90558863]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001393224229104817\n",
      "Predicción post entrenamiento : [[0.9030998]]\n",
      "PERDIDAAAA despues: 0.0014153323136270046\n",
      "loss en el callback: 0.002763227326795459, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.91726351]\n",
      "  [0.91484296]\n",
      "  [0.91347796]\n",
      "  [0.91075176]\n",
      "  [0.90912008]\n",
      "  [0.90732646]\n",
      "  [0.90558863]\n",
      "  [0.90339476]]]\n",
      "ejemplar: [0.91726351 0.91484296 0.91347796 0.91075176 0.90912008 0.90732646\n",
      " 0.90558863 0.90339476]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.90117836]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.91726351 0.91484296 0.91347796 0.91075176 0.90912008 0.90732646\n",
      "  0.90558863 0.90339476]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00508553022518754\n",
      "Predicción post entrenamiento : [[0.9025904]]\n",
      "PERDIDAAAA despues: 0.0048861317336559296\n",
      "loss en el callback: 0.17196276783943176, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.91484296]\n",
      "  [0.91347796]\n",
      "  [0.91075176]\n",
      "  [0.90912008]\n",
      "  [0.90732646]\n",
      "  [0.90558863]\n",
      "  [0.90339476]\n",
      "  [0.90117836]]]\n",
      "ejemplar: [0.91484296 0.91347796 0.91075176 0.90912008 0.90732646 0.90558863\n",
      " 0.90339476 0.90117836]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9007648]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.91484296 0.91347796 0.91075176 0.90912008 0.90732646 0.90558863\n",
      "  0.90339476 0.90117836]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009242056868970394\n",
      "Predicción post entrenamiento : [[0.90159255]]\n",
      "PERDIDAAAA despues: 0.009083593264222145\n",
      "loss en el callback: 0.028072552755475044, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.91347796]\n",
      "  [0.91075176]\n",
      "  [0.90912008]\n",
      "  [0.90732646]\n",
      "  [0.90558863]\n",
      "  [0.90339476]\n",
      "  [0.90117836]\n",
      "  [0.90076482]]]\n",
      "ejemplar: [0.91347796 0.91075176 0.90912008 0.90732646 0.90558863 0.90339476\n",
      " 0.90117836 0.90076482]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.89990455]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.91347796 0.91075176 0.90912008 0.90732646 0.90558863 0.90339476\n",
      "  0.90117836 0.90076482]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026293471455574036\n",
      "Predicción post entrenamiento : [[0.90084463]]\n",
      "PERDIDAAAA despues: 0.0025338211562484503\n",
      "loss en el callback: 0.04305277764797211, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.91075176]\n",
      "  [0.90912008]\n",
      "  [0.90732646]\n",
      "  [0.90558863]\n",
      "  [0.90339476]\n",
      "  [0.90117836]\n",
      "  [0.90076482]\n",
      "  [0.89990455]]]\n",
      "ejemplar: [0.91075176 0.90912008 0.90732646 0.90558863 0.90339476 0.90117836\n",
      " 0.90076482 0.89990455]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.8990169]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.91075176 0.90912008 0.90732646 0.90558863 0.90339476 0.90117836\n",
      "  0.90076482 0.89990455]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0498302799533121e-05\n",
      "Predicción post entrenamiento : [[0.8983201]]\n",
      "PERDIDAAAA despues: 6.468225365097169e-06\n",
      "loss en el callback: 0.015018928796052933, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.90912008]\n",
      "  [0.90732646]\n",
      "  [0.90558863]\n",
      "  [0.90339476]\n",
      "  [0.90117836]\n",
      "  [0.90076482]\n",
      "  [0.89990455]\n",
      "  [0.89901692]]]\n",
      "ejemplar: [0.90912008 0.90732646 0.90558863 0.90339476 0.90117836 0.90076482\n",
      " 0.89990455 0.89901692]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.8967638]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.90912008 0.90732646 0.90558863 0.90339476 0.90117836 0.90076482\n",
      "  0.89990455 0.89901692]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023477920331060886\n",
      "Predicción post entrenamiento : [[0.8964958]]\n",
      "PERDIDAAAA despues: 0.0002266386873088777\n",
      "loss en el callback: 0.0025030539836734533, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.90732646]\n",
      "  [0.90558863]\n",
      "  [0.90339476]\n",
      "  [0.90117836]\n",
      "  [0.90076482]\n",
      "  [0.89990455]\n",
      "  [0.89901692]\n",
      "  [0.8967638 ]]]\n",
      "ejemplar: [0.90732646 0.90558863 0.90339476 0.90117836 0.90076482 0.89990455\n",
      " 0.89901692 0.8967638 ]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8949448]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.90732646 0.90558863 0.90339476 0.90117836 0.90076482 0.89990455\n",
      "  0.89901692 0.8967638 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004902520449832082\n",
      "Predicción post entrenamiento : [[0.8944388]]\n",
      "PERDIDAAAA despues: 0.0005129146738909185\n",
      "loss en el callback: 0.008146969601511955, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.90558863]\n",
      "  [0.90339476]\n",
      "  [0.90117836]\n",
      "  [0.90076482]\n",
      "  [0.89990455]\n",
      "  [0.89901692]\n",
      "  [0.8967638 ]\n",
      "  [0.89494479]]]\n",
      "ejemplar: [0.90558863 0.90339476 0.90117836 0.90076482 0.89990455 0.89901692\n",
      " 0.8967638  0.89494479]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.892955]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.90558863 0.90339476 0.90117836 0.90076482 0.89990455 0.89901692\n",
      "  0.8967638  0.89494479]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007205760339275002\n",
      "Predicción post entrenamiento : [[0.89265776]]\n",
      "PERDIDAAAA despues: 0.0007366228383034468\n",
      "loss en el callback: 0.003089098958298564, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.90339476]\n",
      "  [0.90117836]\n",
      "  [0.90076482]\n",
      "  [0.89990455]\n",
      "  [0.89901692]\n",
      "  [0.8967638 ]\n",
      "  [0.89494479]\n",
      "  [0.89295501]]]\n",
      "ejemplar: [0.90339476 0.90117836 0.90076482 0.89990455 0.89901692 0.8967638\n",
      " 0.89494479 0.89295501]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.89124066]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.90339476 0.90117836 0.90076482 0.89990455 0.89901692 0.8967638\n",
      "  0.89494479 0.89295501]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004956461954861879\n",
      "Predicción post entrenamiento : [[0.8910948]]\n",
      "PERDIDAAAA despues: 0.004977019969373941\n",
      "loss en el callback: 0.0007705761818215251, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.90117836]\n",
      "  [0.90076482]\n",
      "  [0.89990455]\n",
      "  [0.89901692]\n",
      "  [0.8967638 ]\n",
      "  [0.89494479]\n",
      "  [0.89295501]\n",
      "  [0.89124066]]]\n",
      "ejemplar: [0.90117836 0.90076482 0.89990455 0.89901692 0.8967638  0.89494479\n",
      " 0.89295501 0.89124066]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8898871]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.90117836 0.90076482 0.89990455 0.89901692 0.8967638  0.89494479\n",
      "  0.89295501 0.89124066]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006137509364634752\n",
      "Predicción post entrenamiento : [[0.89060646]]\n",
      "PERDIDAAAA despues: 0.006025312934070826\n",
      "loss en el callback: 0.02584572695195675, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.90076482]\n",
      "  [0.89990455]\n",
      "  [0.89901692]\n",
      "  [0.8967638 ]\n",
      "  [0.89494479]\n",
      "  [0.89295501]\n",
      "  [0.89124066]\n",
      "  [0.88988709]]]\n",
      "ejemplar: [0.90076482 0.89990455 0.89901692 0.8967638  0.89494479 0.89295501\n",
      " 0.89124066 0.88988709]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.88963294]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.90076482 0.89990455 0.89901692 0.8967638  0.89494479 0.89295501\n",
      "  0.89124066 0.88988709]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004642430227249861\n",
      "Predicción post entrenamiento : [[0.8900105]]\n",
      "PERDIDAAAA despues: 0.004591125529259443\n",
      "loss en el callback: 0.006157670635730028, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23048012]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033993758261203766\n",
      "Predicción post entrenamiento : [[0.18349233]]\n",
      "PERDIDAAAA despues: 0.018874960020184517\n",
      "loss en el callback: 0.038807742297649384, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23048012]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.23048012]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16779035]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.23048012]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004040786996483803\n",
      "Predicción post entrenamiento : [[0.15762576]]\n",
      "PERDIDAAAA despues: 0.002851837081834674\n",
      "loss en el callback: 0.002462426433339715, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23048012]\n",
      "  [0.16779035]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.23048012 0.16779035]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16138935]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.23048012 0.16779035]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.163210880709812e-05\n",
      "Predicción post entrenamiento : [[0.1592195]]\n",
      "PERDIDAAAA despues: 2.515725645935163e-05\n",
      "loss en el callback: 0.0002052207855740562, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23048012]\n",
      "  [0.16779035]\n",
      "  [0.16138935]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23048012\n",
      " 0.16779035 0.16138935]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1700888]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23048012\n",
      "  0.16779035 0.16138935]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020549839246086776\n",
      "Predicción post entrenamiento : [[0.16814362]]\n",
      "PERDIDAAAA despues: 0.00015351289766840637\n",
      "loss en el callback: 0.0002785421966109425, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23048012]\n",
      "  [0.16779035]\n",
      "  [0.16138935]\n",
      "  [0.1700888 ]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.23048012 0.16779035\n",
      " 0.16138935 0.1700888 ]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17974597]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.23048012 0.16779035\n",
      "  0.16138935 0.1700888 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002939073834568262\n",
      "Predicción post entrenamiento : [[0.17467763]]\n",
      "PERDIDAAAA despues: 0.0024152190890163183\n",
      "loss en el callback: 0.0031230500899255276, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23048012]\n",
      "  [0.16779035]\n",
      "  [0.16138935]\n",
      "  [0.1700888 ]\n",
      "  [0.17974597]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.23048012 0.16779035 0.16138935\n",
      " 0.1700888  0.17974597]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18297179]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.23048012 0.16779035 0.16138935\n",
      "  0.1700888  0.17974597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001390680205076933\n",
      "Predicción post entrenamiento : [[0.1774175]]\n",
      "PERDIDAAAA despues: 0.0010072712320834398\n",
      "loss en el callback: 0.004156799055635929, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23048012]\n",
      "  [0.16779035]\n",
      "  [0.16138935]\n",
      "  [0.1700888 ]\n",
      "  [0.17974597]\n",
      "  [0.18297179]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.23048012 0.16779035 0.16138935 0.1700888\n",
      " 0.17974597 0.18297179]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.196035]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.23048012 0.16779035 0.16138935 0.1700888\n",
      "  0.17974597 0.18297179]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00245819054543972\n",
      "Predicción post entrenamiento : [[0.19151928]]\n",
      "PERDIDAAAA despues: 0.002030801959335804\n",
      "loss en el callback: 0.004249107092618942, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.23048012]\n",
      "  [0.16779035]\n",
      "  [0.16138935]\n",
      "  [0.1700888 ]\n",
      "  [0.17974597]\n",
      "  [0.18297179]\n",
      "  [0.196035  ]]]\n",
      "ejemplar: [0.04223169 0.23048012 0.16779035 0.16138935 0.1700888  0.17974597\n",
      " 0.18297179 0.196035  ]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21381406]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.23048012 0.16779035 0.16138935 0.1700888  0.17974597\n",
      "  0.18297179 0.196035  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00031563176889903843\n",
      "Predicción post entrenamiento : [[0.21330038]]\n",
      "PERDIDAAAA despues: 0.00029764327337034047\n",
      "loss en el callback: 8.855275518726557e-05, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.23048012]\n",
      "  [0.16779035]\n",
      "  [0.16138935]\n",
      "  [0.1700888 ]\n",
      "  [0.17974597]\n",
      "  [0.18297179]\n",
      "  [0.196035  ]\n",
      "  [0.21381406]]]\n",
      "ejemplar: [0.23048012 0.16779035 0.16138935 0.1700888  0.17974597 0.18297179\n",
      " 0.196035   0.21381406]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.23956095]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.23048012 0.16779035 0.16138935 0.1700888  0.17974597 0.18297179\n",
      "  0.196035   0.21381406]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.15435778349638e-05\n",
      "Predicción post entrenamiento : [[0.23706949]]\n",
      "PERDIDAAAA despues: 4.275445462553762e-05\n",
      "loss en el callback: 0.0018396477680653334, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.16779035]\n",
      "  [0.16138935]\n",
      "  [0.1700888 ]\n",
      "  [0.17974597]\n",
      "  [0.18297179]\n",
      "  [0.196035  ]\n",
      "  [0.21381406]\n",
      "  [0.23956095]]]\n",
      "ejemplar: [0.16779035 0.16138935 0.1700888  0.17974597 0.18297179 0.196035\n",
      " 0.21381406 0.23956095]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.22724347]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.16779035 0.16138935 0.1700888  0.17974597 0.18297179 0.196035\n",
      "  0.21381406 0.23956095]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035333208506926894\n",
      "Predicción post entrenamiento : [[0.22645281]]\n",
      "PERDIDAAAA despues: 0.00032423308584839106\n",
      "loss en el callback: 0.0002754323068074882, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16138935]\n",
      "  [0.1700888 ]\n",
      "  [0.17974597]\n",
      "  [0.18297179]\n",
      "  [0.196035  ]\n",
      "  [0.21381406]\n",
      "  [0.23956095]\n",
      "  [0.22724347]]]\n",
      "ejemplar: [0.16138935 0.1700888  0.17974597 0.18297179 0.196035   0.21381406\n",
      " 0.23956095 0.22724347]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.22959603]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16138935 0.1700888  0.17974597 0.18297179 0.196035   0.21381406\n",
      "  0.23956095 0.22724347]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003119700704701245\n",
      "Predicción post entrenamiento : [[0.2286092]]\n",
      "PERDIDAAAA despues: 0.00027808381128124893\n",
      "loss en el callback: 0.0004979497171007097, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.1700888 ]\n",
      "  [0.17974597]\n",
      "  [0.18297179]\n",
      "  [0.196035  ]\n",
      "  [0.21381406]\n",
      "  [0.23956095]\n",
      "  [0.22724347]\n",
      "  [0.22959603]]]\n",
      "ejemplar: [0.1700888  0.17974597 0.18297179 0.196035   0.21381406 0.23956095\n",
      " 0.22724347 0.22959603]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.23482326]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.1700888  0.17974597 0.18297179 0.196035   0.21381406 0.23956095\n",
      "  0.22724347 0.22959603]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007584104896523058\n",
      "Predicción post entrenamiento : [[0.23448479]]\n",
      "PERDIDAAAA despues: 0.0007398828747682273\n",
      "loss en el callback: 9.252167365048081e-05, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.17974597]\n",
      "  [0.18297179]\n",
      "  [0.196035  ]\n",
      "  [0.21381406]\n",
      "  [0.23956095]\n",
      "  [0.22724347]\n",
      "  [0.22959603]\n",
      "  [0.23482326]]]\n",
      "ejemplar: [0.17974597 0.18297179 0.196035   0.21381406 0.23956095 0.22724347\n",
      " 0.22959603 0.23482326]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.24094717]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.17974597 0.18297179 0.196035   0.21381406 0.23956095 0.22724347\n",
      "  0.22959603 0.23482326]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002303874818608165\n",
      "Predicción post entrenamiento : [[0.23933065]]\n",
      "PERDIDAAAA despues: 0.0021513060200959444\n",
      "loss en el callback: 0.00204471661709249, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.18297179]\n",
      "  [0.196035  ]\n",
      "  [0.21381406]\n",
      "  [0.23956095]\n",
      "  [0.22724347]\n",
      "  [0.22959603]\n",
      "  [0.23482326]\n",
      "  [0.24094717]]]\n",
      "ejemplar: [0.18297179 0.196035   0.21381406 0.23956095 0.22724347 0.22959603\n",
      " 0.23482326 0.24094717]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.24574305]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.18297179 0.196035   0.21381406 0.23956095 0.22724347 0.22959603\n",
      "  0.23482326 0.24094717]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00239317724481225\n",
      "Predicción post entrenamiento : [[0.24403788]]\n",
      "PERDIDAAAA despues: 0.0022292505018413067\n",
      "loss en el callback: 0.0024501618463546038, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.196035  ]\n",
      "  [0.21381406]\n",
      "  [0.23956095]\n",
      "  [0.22724347]\n",
      "  [0.22959603]\n",
      "  [0.23482326]\n",
      "  [0.24094717]\n",
      "  [0.24574305]]]\n",
      "ejemplar: [0.196035   0.21381406 0.23956095 0.22724347 0.22959603 0.23482326\n",
      " 0.24094717 0.24574305]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2516764]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.196035   0.21381406 0.23956095 0.22724347 0.22959603 0.23482326\n",
      "  0.24094717 0.24574305]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014001340605318546\n",
      "Predicción post entrenamiento : [[0.25167826]]\n",
      "PERDIDAAAA despues: 0.001400272361934185\n",
      "loss en el callback: 4.4148418254508215e-09, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.21381406]\n",
      "  [0.23956095]\n",
      "  [0.22724347]\n",
      "  [0.22959603]\n",
      "  [0.23482326]\n",
      "  [0.24094717]\n",
      "  [0.24574305]\n",
      "  [0.25167641]]]\n",
      "ejemplar: [0.21381406 0.23956095 0.22724347 0.22959603 0.23482326 0.24094717\n",
      " 0.24574305 0.25167641]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.25838044]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.21381406 0.23956095 0.22724347 0.22959603 0.23482326 0.24094717\n",
      "  0.24574305 0.25167641]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005937531590461731\n",
      "Predicción post entrenamiento : [[0.25699908]]\n",
      "PERDIDAAAA despues: 0.005726556293666363\n",
      "loss en el callback: 0.002524792216718197, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.23956095]\n",
      "  [0.22724347]\n",
      "  [0.22959603]\n",
      "  [0.23482326]\n",
      "  [0.24094717]\n",
      "  [0.24574305]\n",
      "  [0.25167641]\n",
      "  [0.25838044]]]\n",
      "ejemplar: [0.23956095 0.22724347 0.22959603 0.23482326 0.24094717 0.24574305\n",
      " 0.25167641 0.25838044]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2613683]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.23956095 0.22724347 0.22959603 0.23482326 0.24094717 0.24574305\n",
      "  0.25167641 0.25838044]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0074377479031682014\n",
      "Predicción post entrenamiento : [[0.2610013]]\n",
      "PERDIDAAAA despues: 0.0073745776899158955\n",
      "loss en el callback: 0.00025965896202251315, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.22724347]\n",
      "  [0.22959603]\n",
      "  [0.23482326]\n",
      "  [0.24094717]\n",
      "  [0.24574305]\n",
      "  [0.25167641]\n",
      "  [0.25838044]\n",
      "  [0.2613683 ]]]\n",
      "ejemplar: [0.22724347 0.22959603 0.23482326 0.24094717 0.24574305 0.25167641\n",
      " 0.25838044 0.2613683 ]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.26077056]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.22724347 0.22959603 0.23482326 0.24094717 0.24574305 0.25167641\n",
      "  0.25838044 0.2613683 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012716149911284447\n",
      "Predicción post entrenamiento : [[0.25676605]]\n",
      "PERDIDAAAA despues: 0.011829041875898838\n",
      "loss en el callback: 0.018113024532794952, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.22959603]\n",
      "  [0.23482326]\n",
      "  [0.24094717]\n",
      "  [0.24574305]\n",
      "  [0.25167641]\n",
      "  [0.25838044]\n",
      "  [0.2613683 ]\n",
      "  [0.26077056]]]\n",
      "ejemplar: [0.22959603 0.23482326 0.24094717 0.24574305 0.25167641 0.25838044\n",
      " 0.2613683  0.26077056]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.25979915]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.22959603 0.23482326 0.24094717 0.24574305 0.25167641 0.25838044\n",
      "  0.2613683  0.26077056]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010190093889832497\n",
      "Predicción post entrenamiento : [[0.25780547]]\n",
      "PERDIDAAAA despues: 0.009791559539735317\n",
      "loss en el callback: 0.006713486276566982, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.23482326]\n",
      "  [0.24094717]\n",
      "  [0.24574305]\n",
      "  [0.25167641]\n",
      "  [0.25838044]\n",
      "  [0.2613683 ]\n",
      "  [0.26077056]\n",
      "  [0.25979915]]]\n",
      "ejemplar: [0.23482326 0.24094717 0.24574305 0.25167641 0.25838044 0.2613683\n",
      " 0.26077056 0.25979915]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2613388]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.23482326 0.24094717 0.24574305 0.25167641 0.25838044 0.2613683\n",
      "  0.26077056 0.25979915]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00478382920846343\n",
      "Predicción post entrenamiento : [[0.26053995]]\n",
      "PERDIDAAAA despues: 0.00467396154999733\n",
      "loss en el callback: 0.0013019386678934097, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.24094717]\n",
      "  [0.24574305]\n",
      "  [0.25167641]\n",
      "  [0.25838044]\n",
      "  [0.2613683 ]\n",
      "  [0.26077056]\n",
      "  [0.25979915]\n",
      "  [0.2613388 ]]]\n",
      "ejemplar: [0.24094717 0.24574305 0.25167641 0.25838044 0.2613683  0.26077056\n",
      " 0.25979915 0.2613388 ]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26392302]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.24094717 0.24574305 0.25167641 0.25838044 0.2613683  0.26077056\n",
      "  0.25979915 0.2613388 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006075982004404068\n",
      "Predicción post entrenamiento : [[0.26158714]]\n",
      "PERDIDAAAA despues: 0.0057172817178070545\n",
      "loss en el callback: 0.008685870096087456, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.24574305]\n",
      "  [0.25167641]\n",
      "  [0.25838044]\n",
      "  [0.2613683 ]\n",
      "  [0.26077056]\n",
      "  [0.25979915]\n",
      "  [0.2613388 ]\n",
      "  [0.26392302]]]\n",
      "ejemplar: [0.24574305 0.25167641 0.25838044 0.2613683  0.26077056 0.25979915\n",
      " 0.2613388  0.26392302]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26448795]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.24574305 0.25167641 0.25838044 0.2613683  0.26077056 0.25979915\n",
      "  0.2613388  0.26392302]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.0655520428554155e-06\n",
      "Predicción post entrenamiento : [[0.26458475]]\n",
      "PERDIDAAAA despues: 5.5981272453209385e-06\n",
      "loss en el callback: 1.895446257549338e-05, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.25167641]\n",
      "  [0.25838044]\n",
      "  [0.2613683 ]\n",
      "  [0.26077056]\n",
      "  [0.25979915]\n",
      "  [0.2613388 ]\n",
      "  [0.26392302]\n",
      "  [0.26448795]]]\n",
      "ejemplar: [0.25167641 0.25838044 0.2613683  0.26077056 0.25979915 0.2613388\n",
      " 0.26392302 0.26448795]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2671326]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.25167641 0.25838044 0.2613683  0.26077056 0.25979915 0.2613388\n",
      "  0.26392302 0.26448795]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000644635409116745\n",
      "Predicción post entrenamiento : [[0.2684291]]\n",
      "PERDIDAAAA despues: 0.0005804813699796796\n",
      "loss en el callback: 0.004674132913351059, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.25838044]\n",
      "  [0.2613683 ]\n",
      "  [0.26077056]\n",
      "  [0.25979915]\n",
      "  [0.2613388 ]\n",
      "  [0.26392302]\n",
      "  [0.26448795]\n",
      "  [0.26713261]]]\n",
      "ejemplar: [0.25838044 0.2613683  0.26077056 0.25979915 0.2613388  0.26392302\n",
      " 0.26448795 0.26713261]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27023393]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.25838044 0.2613683  0.26077056 0.25979915 0.2613388  0.26392302\n",
      "  0.26448795 0.26713261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002253627637401223\n",
      "Predicción post entrenamiento : [[0.2706632]]\n",
      "PERDIDAAAA despues: 0.0022130545694381\n",
      "loss en el callback: 0.0003846042091026902, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.2613683 ]\n",
      "  [0.26077056]\n",
      "  [0.25979915]\n",
      "  [0.2613388 ]\n",
      "  [0.26392302]\n",
      "  [0.26448795]\n",
      "  [0.26713261]\n",
      "  [0.27023393]]]\n",
      "ejemplar: [0.2613683  0.26077056 0.25979915 0.2613388  0.26392302 0.26448795\n",
      " 0.26713261 0.27023393]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27138934]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.2613683  0.26077056 0.25979915 0.2613388  0.26392302 0.26448795\n",
      "  0.26713261 0.27023393]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017040532547980547\n",
      "Predicción post entrenamiento : [[0.27263436]]\n",
      "PERDIDAAAA despues: 0.001602813950739801\n",
      "loss en el callback: 0.004971432965248823, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26077056]\n",
      "  [0.25979915]\n",
      "  [0.2613388 ]\n",
      "  [0.26392302]\n",
      "  [0.26448795]\n",
      "  [0.26713261]\n",
      "  [0.27023393]\n",
      "  [0.27138934]]]\n",
      "ejemplar: [0.26077056 0.25979915 0.2613388  0.26392302 0.26448795 0.26713261\n",
      " 0.27023393 0.27138934]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.272959]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26077056 0.25979915 0.2613388  0.26392302 0.26448795 0.26713261\n",
      "  0.27023393 0.27138934]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025844635092653334\n",
      "Predicción post entrenamiento : [[0.27268177]]\n",
      "PERDIDAAAA despues: 0.0002674365823622793\n",
      "loss en el callback: 0.00017512112390249968, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.25979915]\n",
      "  [0.2613388 ]\n",
      "  [0.26392302]\n",
      "  [0.26448795]\n",
      "  [0.26713261]\n",
      "  [0.27023393]\n",
      "  [0.27138934]\n",
      "  [0.27295899]]]\n",
      "ejemplar: [0.25979915 0.2613388  0.26392302 0.26448795 0.26713261 0.27023393\n",
      " 0.27138934 0.27295899]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27338928]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.25979915 0.2613388  0.26392302 0.26448795 0.26713261 0.27023393\n",
      "  0.27138934 0.27295899]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.92425887286663e-05\n",
      "Predicción post entrenamiento : [[0.27430066]]\n",
      "PERDIDAAAA despues: 7.285381434485316e-05\n",
      "loss en el callback: 0.003465933259576559, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.2613388 ]\n",
      "  [0.26392302]\n",
      "  [0.26448795]\n",
      "  [0.26713261]\n",
      "  [0.27023393]\n",
      "  [0.27138934]\n",
      "  [0.27295899]\n",
      "  [0.27338928]]]\n",
      "ejemplar: [0.2613388  0.26392302 0.26448795 0.26713261 0.27023393 0.27138934\n",
      " 0.27295899 0.27338928]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27556095]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.2613388  0.26392302 0.26448795 0.26713261 0.27023393 0.27138934\n",
      "  0.27295899 0.27338928]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005729023250751197\n",
      "Predicción post entrenamiento : [[0.27611122]]\n",
      "PERDIDAAAA despues: 0.0005468632443808019\n",
      "loss en el callback: 0.0010522070806473494, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26392302]\n",
      "  [0.26448795]\n",
      "  [0.26713261]\n",
      "  [0.27023393]\n",
      "  [0.27138934]\n",
      "  [0.27295899]\n",
      "  [0.27338928]\n",
      "  [0.27556095]]]\n",
      "ejemplar: [0.26392302 0.26448795 0.26713261 0.27023393 0.27138934 0.27295899\n",
      " 0.27338928 0.27556095]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27744207]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26392302 0.26448795 0.26713261 0.27023393 0.27138934 0.27295899\n",
      "  0.27338928 0.27556095]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.4963997020677198e-06\n",
      "Predicción post entrenamiento : [[0.27790567]]\n",
      "PERDIDAAAA despues: 4.176320999249583e-06\n",
      "loss en el callback: 0.000864814268425107, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26448795]\n",
      "  [0.26713261]\n",
      "  [0.27023393]\n",
      "  [0.27138934]\n",
      "  [0.27295899]\n",
      "  [0.27338928]\n",
      "  [0.27556095]\n",
      "  [0.27744207]]]\n",
      "ejemplar: [0.26448795 0.26713261 0.27023393 0.27138934 0.27295899 0.27338928\n",
      " 0.27556095 0.27744207]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27907047]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26448795 0.26713261 0.27023393 0.27138934 0.27295899 0.27338928\n",
      "  0.27556095 0.27744207]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.9103446902590804e-05\n",
      "Predicción post entrenamiento : [[0.27827796]]\n",
      "PERDIDAAAA despues: 1.2803841855202336e-05\n",
      "loss en el callback: 0.001743924804031849, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26713261]\n",
      "  [0.27023393]\n",
      "  [0.27138934]\n",
      "  [0.27295899]\n",
      "  [0.27338928]\n",
      "  [0.27556095]\n",
      "  [0.27744207]\n",
      "  [0.27907047]]]\n",
      "ejemplar: [0.26713261 0.27023393 0.27138934 0.27295899 0.27338928 0.27556095\n",
      " 0.27744207 0.27907047]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27970412]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26713261 0.27023393 0.27138934 0.27295899 0.27338928 0.27556095\n",
      "  0.27744207 0.27907047]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7888803995447233e-05\n",
      "Predicción post entrenamiento : [[0.27996016]]\n",
      "PERDIDAAAA despues: 2.0120136468904093e-05\n",
      "loss en el callback: 0.00028710084734484553, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27023393]\n",
      "  [0.27138934]\n",
      "  [0.27295899]\n",
      "  [0.27338928]\n",
      "  [0.27556095]\n",
      "  [0.27744207]\n",
      "  [0.27907047]\n",
      "  [0.27970412]]]\n",
      "ejemplar: [0.27023393 0.27138934 0.27295899 0.27338928 0.27556095 0.27744207\n",
      " 0.27907047 0.27970412]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.281201]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27023393 0.27138934 0.27295899 0.27338928 0.27556095 0.27744207\n",
      "  0.27907047 0.27970412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028679189272224903\n",
      "Predicción post entrenamiento : [[0.2822636]]\n",
      "PERDIDAAAA despues: 0.002755237277597189\n",
      "loss en el callback: 0.005141343921422958, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27138934]\n",
      "  [0.27295899]\n",
      "  [0.27338928]\n",
      "  [0.27556095]\n",
      "  [0.27744207]\n",
      "  [0.27907047]\n",
      "  [0.27970412]\n",
      "  [0.281201  ]]]\n",
      "ejemplar: [0.27138934 0.27295899 0.27338928 0.27556095 0.27744207 0.27907047\n",
      " 0.27970412 0.281201  ]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.28317034]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27138934 0.27295899 0.27338928 0.27556095 0.27744207 0.27907047\n",
      "  0.27970412 0.281201  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005257082637399435\n",
      "Predicción post entrenamiento : [[0.28429997]]\n",
      "PERDIDAAAA despues: 0.005094549618661404\n",
      "loss en el callback: 0.006158330012112856, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27295899]\n",
      "  [0.27338928]\n",
      "  [0.27556095]\n",
      "  [0.27744207]\n",
      "  [0.27907047]\n",
      "  [0.27970412]\n",
      "  [0.281201  ]\n",
      "  [0.28317034]]]\n",
      "ejemplar: [0.27295899 0.27338928 0.27556095 0.27744207 0.27907047 0.27970412\n",
      " 0.281201   0.28317034]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2852634]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27295899 0.27338928 0.27556095 0.27744207 0.27907047 0.27970412\n",
      "  0.281201   0.28317034]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002644819673150778\n",
      "Predicción post entrenamiento : [[0.28638482]]\n",
      "PERDIDAAAA despues: 0.0025307319592684507\n",
      "loss en el callback: 0.005898380186408758, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27338928]\n",
      "  [0.27556095]\n",
      "  [0.27744207]\n",
      "  [0.27907047]\n",
      "  [0.27970412]\n",
      "  [0.281201  ]\n",
      "  [0.28317034]\n",
      "  [0.28526339]]]\n",
      "ejemplar: [0.27338928 0.27556095 0.27744207 0.27907047 0.27970412 0.281201\n",
      " 0.28317034 0.28526339]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28732514]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27338928 0.27556095 0.27744207 0.27907047 0.27970412 0.281201\n",
      "  0.28317034 0.28526339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002140588592737913\n",
      "Predicción post entrenamiento : [[0.28831926]]\n",
      "PERDIDAAAA despues: 0.0020495883654803038\n",
      "loss en el callback: 0.005626401863992214, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27556095]\n",
      "  [0.27744207]\n",
      "  [0.27907047]\n",
      "  [0.27970412]\n",
      "  [0.281201  ]\n",
      "  [0.28317034]\n",
      "  [0.28526339]\n",
      "  [0.28732514]]]\n",
      "ejemplar: [0.27556095 0.27744207 0.27907047 0.27970412 0.281201   0.28317034\n",
      " 0.28526339 0.28732514]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28950372]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27556095 0.27744207 0.27907047 0.27970412 0.281201   0.28317034\n",
      "  0.28526339 0.28732514]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009068920277059078\n",
      "Predicción post entrenamiento : [[0.29046366]]\n",
      "PERDIDAAAA despues: 0.008887010626494884\n",
      "loss en el callback: 0.004025760106742382, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27744207]\n",
      "  [0.27907047]\n",
      "  [0.27970412]\n",
      "  [0.281201  ]\n",
      "  [0.28317034]\n",
      "  [0.28526339]\n",
      "  [0.28732514]\n",
      "  [0.28950372]]]\n",
      "ejemplar: [0.27744207 0.27907047 0.27970412 0.281201   0.28317034 0.28526339\n",
      " 0.28732514 0.28950372]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2915388]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27744207 0.27907047 0.27970412 0.281201   0.28317034 0.28526339\n",
      "  0.28732514 0.28950372]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07815249264240265\n",
      "Predicción post entrenamiento : [[0.2954037]]\n",
      "PERDIDAAAA despues: 0.07600651681423187\n",
      "loss en el callback: 0.07934198528528214, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27907047]\n",
      "  [0.27970412]\n",
      "  [0.281201  ]\n",
      "  [0.28317034]\n",
      "  [0.28526339]\n",
      "  [0.28732514]\n",
      "  [0.28950372]\n",
      "  [0.2915388 ]]]\n",
      "ejemplar: [0.27907047 0.27970412 0.281201   0.28317034 0.28526339 0.28732514\n",
      " 0.28950372 0.2915388 ]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.29643023]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27907047 0.27970412 0.281201   0.28317034 0.28526339 0.28732514\n",
      "  0.28950372 0.2915388 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08991019427776337\n",
      "Predicción post entrenamiento : [[0.30041853]]\n",
      "PERDIDAAAA despues: 0.08753431588411331\n",
      "loss en el callback: 0.12044993788003922, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27970412]\n",
      "  [0.281201  ]\n",
      "  [0.28317034]\n",
      "  [0.28526339]\n",
      "  [0.28732514]\n",
      "  [0.28950372]\n",
      "  [0.2915388 ]\n",
      "  [0.29643023]]]\n",
      "ejemplar: [0.27970412 0.281201   0.28317034 0.28526339 0.28732514 0.28950372\n",
      " 0.2915388  0.29643023]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.30147448]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27970412 0.281201   0.28317034 0.28526339 0.28732514 0.28950372\n",
      "  0.2915388  0.29643023]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07458852231502533\n",
      "Predicción post entrenamiento : [[0.30500063]]\n",
      "PERDIDAAAA despues: 0.07267490774393082\n",
      "loss en el callback: 0.07328538596630096, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.281201  ]\n",
      "  [0.28317034]\n",
      "  [0.28526339]\n",
      "  [0.28732514]\n",
      "  [0.28950372]\n",
      "  [0.2915388 ]\n",
      "  [0.29643023]\n",
      "  [0.30147448]]]\n",
      "ejemplar: [0.281201   0.28317034 0.28526339 0.28732514 0.28950372 0.2915388\n",
      " 0.29643023 0.30147448]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3063677]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.281201   0.28317034 0.28526339 0.28732514 0.28950372 0.2915388\n",
      "  0.29643023 0.30147448]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08999185264110565\n",
      "Predicción post entrenamiento : [[0.31021622]]\n",
      "PERDIDAAAA despues: 0.08769765496253967\n",
      "loss en el callback: 0.10612412542104721, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.28317034]\n",
      "  [0.28526339]\n",
      "  [0.28732514]\n",
      "  [0.28950372]\n",
      "  [0.2915388 ]\n",
      "  [0.29643023]\n",
      "  [0.30147448]\n",
      "  [0.3063677 ]]]\n",
      "ejemplar: [0.28317034 0.28526339 0.28732514 0.28950372 0.2915388  0.29643023\n",
      " 0.30147448 0.3063677 ]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.31180063]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.28317034 0.28526339 0.28732514 0.28950372 0.2915388  0.29643023\n",
      "  0.30147448 0.3063677 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07445067167282104\n",
      "Predicción post entrenamiento : [[0.3151588]]\n",
      "PERDIDAAAA despues: 0.07262933999300003\n",
      "loss en el callback: 0.07344896346330643, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.28526339]\n",
      "  [0.28732514]\n",
      "  [0.28950372]\n",
      "  [0.2915388 ]\n",
      "  [0.29643023]\n",
      "  [0.30147448]\n",
      "  [0.3063677 ]\n",
      "  [0.31180063]]]\n",
      "ejemplar: [0.28526339 0.28732514 0.28950372 0.2915388  0.29643023 0.30147448\n",
      " 0.3063677  0.31180063]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.31694773]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.28526339 0.28732514 0.28950372 0.2915388  0.29643023 0.30147448\n",
      "  0.3063677  0.31180063]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06341535598039627\n",
      "Predicción post entrenamiento : [[0.32011637]]\n",
      "PERDIDAAAA despues: 0.06182951107621193\n",
      "loss en el callback: 0.09655402600765228, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28732514]\n",
      "  [0.28950372]\n",
      "  [0.2915388 ]\n",
      "  [0.29643023]\n",
      "  [0.30147448]\n",
      "  [0.3063677 ]\n",
      "  [0.31180063]\n",
      "  [0.31694773]]]\n",
      "ejemplar: [0.28732514 0.28950372 0.2915388  0.29643023 0.30147448 0.3063677\n",
      " 0.31180063 0.31694773]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3221797]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28732514 0.28950372 0.2915388  0.29643023 0.30147448 0.3063677\n",
      "  0.31180063 0.31694773]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1027807667851448\n",
      "Predicción post entrenamiento : [[0.32615405]]\n",
      "PERDIDAAAA despues: 0.10024825483560562\n",
      "loss en el callback: 0.10007704794406891, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28950372]\n",
      "  [0.2915388 ]\n",
      "  [0.29643023]\n",
      "  [0.30147448]\n",
      "  [0.3063677 ]\n",
      "  [0.31180063]\n",
      "  [0.31694773]\n",
      "  [0.3221797 ]]]\n",
      "ejemplar: [0.28950372 0.2915388  0.29643023 0.30147448 0.3063677  0.31180063\n",
      " 0.31694773 0.3221797 ]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32860863]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28950372 0.2915388  0.29643023 0.30147448 0.3063677  0.31180063\n",
      "  0.31694773 0.3221797 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11098918318748474\n",
      "Predicción post entrenamiento : [[0.33240205]]\n",
      "PERDIDAAAA despues: 0.10847601294517517\n",
      "loss en el callback: 0.1598476618528366, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.2915388 ]\n",
      "  [0.29643023]\n",
      "  [0.30147448]\n",
      "  [0.3063677 ]\n",
      "  [0.31180063]\n",
      "  [0.31694773]\n",
      "  [0.3221797 ]\n",
      "  [0.32860863]]]\n",
      "ejemplar: [0.2915388  0.29643023 0.30147448 0.3063677  0.31180063 0.31694773\n",
      " 0.3221797  0.32860863]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33534384]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.2915388  0.29643023 0.30147448 0.3063677  0.31180063 0.31694773\n",
      "  0.3221797  0.32860863]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11400828510522842\n",
      "Predicción post entrenamiento : [[0.33923742]]\n",
      "PERDIDAAAA despues: 0.11139409989118576\n",
      "loss en el callback: 0.13666801154613495, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.29643023]\n",
      "  [0.30147448]\n",
      "  [0.3063677 ]\n",
      "  [0.31180063]\n",
      "  [0.31694773]\n",
      "  [0.3221797 ]\n",
      "  [0.32860863]\n",
      "  [0.33534384]]]\n",
      "ejemplar: [0.29643023 0.30147448 0.3063677  0.31180063 0.31694773 0.3221797\n",
      " 0.32860863 0.33534384]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3428323]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.29643023 0.30147448 0.3063677  0.31180063 0.31694773 0.3221797\n",
      "  0.32860863 0.33534384]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13523639738559723\n",
      "Predicción post entrenamiento : [[0.34690833]]\n",
      "PERDIDAAAA despues: 0.13225512206554413\n",
      "loss en el callback: 0.09883593767881393, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.30147448]\n",
      "  [0.3063677 ]\n",
      "  [0.31180063]\n",
      "  [0.31694773]\n",
      "  [0.3221797 ]\n",
      "  [0.32860863]\n",
      "  [0.33534384]\n",
      "  [0.3428323 ]]]\n",
      "ejemplar: [0.30147448 0.3063677  0.31180063 0.31694773 0.3221797  0.32860863\n",
      " 0.33534384 0.3428323 ]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35062698]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.30147448 0.3063677  0.31180063 0.31694773 0.3221797  0.32860863\n",
      "  0.33534384 0.3428323 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12486591935157776\n",
      "Predicción post entrenamiento : [[0.35443544]]\n",
      "PERDIDAAAA despues: 0.12218887358903885\n",
      "loss en el callback: 0.09902863204479218, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.3063677 ]\n",
      "  [0.31180063]\n",
      "  [0.31694773]\n",
      "  [0.3221797 ]\n",
      "  [0.32860863]\n",
      "  [0.33534384]\n",
      "  [0.3428323 ]\n",
      "  [0.35062698]]]\n",
      "ejemplar: [0.3063677  0.31180063 0.31694773 0.3221797  0.32860863 0.33534384\n",
      " 0.3428323  0.35062698]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3583027]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.3063677  0.31180063 0.31694773 0.3221797  0.32860863 0.33534384\n",
      "  0.3428323  0.35062698]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13611289858818054\n",
      "Predicción post entrenamiento : [[0.3625449]]\n",
      "PERDIDAAAA despues: 0.1330007165670395\n",
      "loss en el callback: 0.1420590877532959, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.31180063]\n",
      "  [0.31694773]\n",
      "  [0.3221797 ]\n",
      "  [0.32860863]\n",
      "  [0.33534384]\n",
      "  [0.3428323 ]\n",
      "  [0.35062698]\n",
      "  [0.35830271]]]\n",
      "ejemplar: [0.31180063 0.31694773 0.3221797  0.32860863 0.33534384 0.3428323\n",
      " 0.35062698 0.35830271]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3666706]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.31180063 0.31694773 0.3221797  0.32860863 0.33534384 0.3428323\n",
      "  0.35062698 0.35830271]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1266772747039795\n",
      "Predicción post entrenamiento : [[0.3705406]]\n",
      "PERDIDAAAA despues: 0.1239374652504921\n",
      "loss en el callback: 0.17500287294387817, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.31694773]\n",
      "  [0.3221797 ]\n",
      "  [0.32860863]\n",
      "  [0.33534384]\n",
      "  [0.3428323 ]\n",
      "  [0.35062698]\n",
      "  [0.35830271]\n",
      "  [0.36667061]]]\n",
      "ejemplar: [0.31694773 0.3221797  0.32860863 0.33534384 0.3428323  0.35062698\n",
      " 0.35830271 0.36667061]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.37488982]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.31694773 0.3221797  0.32860863 0.33534384 0.3428323  0.35062698\n",
      "  0.35830271 0.36667061]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15753285586833954\n",
      "Predicción post entrenamiento : [[0.3789384]]\n",
      "PERDIDAAAA despues: 0.15433543920516968\n",
      "loss en el callback: 0.24973957240581512, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.3221797 ]\n",
      "  [0.32860863]\n",
      "  [0.33534384]\n",
      "  [0.3428323 ]\n",
      "  [0.35062698]\n",
      "  [0.35830271]\n",
      "  [0.36667061]\n",
      "  [0.37488982]]]\n",
      "ejemplar: [0.3221797  0.32860863 0.33534384 0.3428323  0.35062698 0.35830271\n",
      " 0.36667061 0.37488982]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3836709]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.3221797  0.32860863 0.33534384 0.3428323  0.35062698 0.35830271\n",
      "  0.36667061 0.37488982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11618179082870483\n",
      "Predicción post entrenamiento : [[0.38714874]]\n",
      "PERDIDAAAA despues: 0.11382300406694412\n",
      "loss en el callback: 0.09796591848134995, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32860863]\n",
      "  [0.33534384]\n",
      "  [0.3428323 ]\n",
      "  [0.35062698]\n",
      "  [0.35830271]\n",
      "  [0.36667061]\n",
      "  [0.37488982]\n",
      "  [0.3836709 ]]]\n",
      "ejemplar: [0.32860863 0.33534384 0.3428323  0.35062698 0.35830271 0.36667061\n",
      " 0.37488982 0.3836709 ]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3923567]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32860863 0.33534384 0.3428323  0.35062698 0.35830271 0.36667061\n",
      "  0.37488982 0.3836709 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0776742547750473\n",
      "Predicción post entrenamiento : [[0.39532945]]\n",
      "PERDIDAAAA despues: 0.0760260745882988\n",
      "loss en el callback: 0.0925472304224968, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.33534384]\n",
      "  [0.3428323 ]\n",
      "  [0.35062698]\n",
      "  [0.35830271]\n",
      "  [0.36667061]\n",
      "  [0.37488982]\n",
      "  [0.3836709 ]\n",
      "  [0.39235669]]]\n",
      "ejemplar: [0.33534384 0.3428323  0.35062698 0.35830271 0.36667061 0.37488982\n",
      " 0.3836709  0.39235669]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.4008368]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.33534384 0.3428323  0.35062698 0.35830271 0.36667061 0.37488982\n",
      "  0.3836709  0.39235669]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0744924396276474\n",
      "Predicción post entrenamiento : [[0.40331614]]\n",
      "PERDIDAAAA despues: 0.07314519584178925\n",
      "loss en el callback: 0.047765180468559265, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.3428323 ]\n",
      "  [0.35062698]\n",
      "  [0.35830271]\n",
      "  [0.36667061]\n",
      "  [0.37488982]\n",
      "  [0.3836709 ]\n",
      "  [0.39235669]\n",
      "  [0.4008368 ]]]\n",
      "ejemplar: [0.3428323  0.35062698 0.35830271 0.36667061 0.37488982 0.3836709\n",
      " 0.39235669 0.4008368 ]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.40912542]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.3428323  0.35062698 0.35830271 0.36667061 0.37488982 0.3836709\n",
      "  0.39235669 0.4008368 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0932241901755333\n",
      "Predicción post entrenamiento : [[0.41198835]]\n",
      "PERDIDAAAA despues: 0.09148413687944412\n",
      "loss en el callback: 0.0606747642159462, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.35062698]\n",
      "  [0.35830271]\n",
      "  [0.36667061]\n",
      "  [0.37488982]\n",
      "  [0.3836709 ]\n",
      "  [0.39235669]\n",
      "  [0.4008368 ]\n",
      "  [0.40912542]]]\n",
      "ejemplar: [0.35062698 0.35830271 0.36667061 0.37488982 0.3836709  0.39235669\n",
      " 0.4008368  0.40912542]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41798255]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.35062698 0.35830271 0.36667061 0.37488982 0.3836709  0.39235669\n",
      "  0.4008368  0.40912542]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10622070729732513\n",
      "Predicción post entrenamiento : [[0.4212324]]\n",
      "PERDIDAAAA despues: 0.10411291569471359\n",
      "loss en el callback: 0.08620510250329971, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.35830271]\n",
      "  [0.36667061]\n",
      "  [0.37488982]\n",
      "  [0.3836709 ]\n",
      "  [0.39235669]\n",
      "  [0.4008368 ]\n",
      "  [0.40912542]\n",
      "  [0.41798255]]]\n",
      "ejemplar: [0.35830271 0.36667061 0.37488982 0.3836709  0.39235669 0.4008368\n",
      " 0.40912542 0.41798255]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4273787]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.35830271 0.36667061 0.37488982 0.3836709  0.39235669 0.4008368\n",
      "  0.40912542 0.41798255]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08714859187602997\n",
      "Predicción post entrenamiento : [[0.42993295]]\n",
      "PERDIDAAAA despues: 0.08564704656600952\n",
      "loss en el callback: 0.050031378865242004, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.36667061]\n",
      "  [0.37488982]\n",
      "  [0.3836709 ]\n",
      "  [0.39235669]\n",
      "  [0.4008368 ]\n",
      "  [0.40912542]\n",
      "  [0.41798255]\n",
      "  [0.42737871]]]\n",
      "ejemplar: [0.36667061 0.37488982 0.3836709  0.39235669 0.4008368  0.40912542\n",
      " 0.41798255 0.42737871]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4362958]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.36667061 0.37488982 0.3836709  0.39235669 0.4008368  0.40912542\n",
      "  0.41798255 0.42737871]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06919296085834503\n",
      "Predicción post entrenamiento : [[0.43901357]]\n",
      "PERDIDAAAA despues: 0.06777055561542511\n",
      "loss en el callback: 0.0719875767827034, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.37488982]\n",
      "  [0.3836709 ]\n",
      "  [0.39235669]\n",
      "  [0.4008368 ]\n",
      "  [0.40912542]\n",
      "  [0.41798255]\n",
      "  [0.42737871]\n",
      "  [0.43629581]]]\n",
      "ejemplar: [0.37488982 0.3836709  0.39235669 0.4008368  0.40912542 0.41798255\n",
      " 0.42737871 0.43629581]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.44546303]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.37488982 0.3836709  0.39235669 0.4008368  0.40912542 0.41798255\n",
      "  0.42737871 0.43629581]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08517531305551529\n",
      "Predicción post entrenamiento : [[0.4479466]]\n",
      "PERDIDAAAA despues: 0.08373182266950607\n",
      "loss en el callback: 0.04793520271778107, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.3836709 ]\n",
      "  [0.39235669]\n",
      "  [0.4008368 ]\n",
      "  [0.40912542]\n",
      "  [0.41798255]\n",
      "  [0.42737871]\n",
      "  [0.43629581]\n",
      "  [0.44546303]]]\n",
      "ejemplar: [0.3836709  0.39235669 0.4008368  0.40912542 0.41798255 0.42737871\n",
      " 0.43629581 0.44546303]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.45454103]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.3836709  0.39235669 0.4008368  0.40912542 0.41798255 0.42737871\n",
      "  0.43629581 0.44546303]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07122749835252762\n",
      "Predicción post entrenamiento : [[0.45706385]]\n",
      "PERDIDAAAA despues: 0.06988725811243057\n",
      "loss en el callback: 0.07237693667411804, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.39235669]\n",
      "  [0.4008368 ]\n",
      "  [0.40912542]\n",
      "  [0.41798255]\n",
      "  [0.42737871]\n",
      "  [0.43629581]\n",
      "  [0.44546303]\n",
      "  [0.45454103]]]\n",
      "ejemplar: [0.39235669 0.4008368  0.40912542 0.41798255 0.42737871 0.43629581\n",
      " 0.44546303 0.45454103]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4636912]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.39235669 0.4008368  0.40912542 0.41798255 0.42737871 0.43629581\n",
      "  0.44546303 0.45454103]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06503647565841675\n",
      "Predicción post entrenamiento : [[0.4664696]]\n",
      "PERDIDAAAA despues: 0.06362709403038025\n",
      "loss en el callback: 0.10318413376808167, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.4008368 ]\n",
      "  [0.40912542]\n",
      "  [0.41798255]\n",
      "  [0.42737871]\n",
      "  [0.43629581]\n",
      "  [0.44546303]\n",
      "  [0.45454103]\n",
      "  [0.4636912 ]]]\n",
      "ejemplar: [0.4008368  0.40912542 0.41798255 0.42737871 0.43629581 0.44546303\n",
      " 0.45454103 0.4636912 ]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.47316638]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.4008368  0.40912542 0.41798255 0.42737871 0.43629581 0.44546303\n",
      "  0.45454103 0.4636912 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04039736092090607\n",
      "Predicción post entrenamiento : [[0.47502482]]\n",
      "PERDIDAAAA despues: 0.039653751999139786\n",
      "loss en el callback: 0.04166977107524872, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.40912542]\n",
      "  [0.41798255]\n",
      "  [0.42737871]\n",
      "  [0.43629581]\n",
      "  [0.44546303]\n",
      "  [0.45454103]\n",
      "  [0.4636912 ]\n",
      "  [0.47316638]]]\n",
      "ejemplar: [0.40912542 0.41798255 0.42737871 0.43629581 0.44546303 0.45454103\n",
      " 0.4636912  0.47316638]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.48186147]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.40912542 0.41798255 0.42737871 0.43629581 0.44546303 0.45454103\n",
      "  0.4636912  0.47316638]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046961043030023575\n",
      "Predicción post entrenamiento : [[0.4833736]]\n",
      "PERDIDAAAA despues: 0.04630795121192932\n",
      "loss en el callback: 0.019286582246422768, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.41798255]\n",
      "  [0.42737871]\n",
      "  [0.43629581]\n",
      "  [0.44546303]\n",
      "  [0.45454103]\n",
      "  [0.4636912 ]\n",
      "  [0.47316638]\n",
      "  [0.48186147]]]\n",
      "ejemplar: [0.41798255 0.42737871 0.43629581 0.44546303 0.45454103 0.4636912\n",
      " 0.47316638 0.48186147]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.49042553]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.41798255 0.42737871 0.43629581 0.44546303 0.45454103 0.4636912\n",
      "  0.47316638 0.48186147]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053182270377874374\n",
      "Predicción post entrenamiento : [[0.492868]]\n",
      "PERDIDAAAA despues: 0.05206170305609703\n",
      "loss en el callback: 0.07547739148139954, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.42737871]\n",
      "  [0.43629581]\n",
      "  [0.44546303]\n",
      "  [0.45454103]\n",
      "  [0.4636912 ]\n",
      "  [0.47316638]\n",
      "  [0.48186147]\n",
      "  [0.49042553]]]\n",
      "ejemplar: [0.42737871 0.43629581 0.44546303 0.45454103 0.4636912  0.47316638\n",
      " 0.48186147 0.49042553]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.50002086]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.42737871 0.43629581 0.44546303 0.45454103 0.4636912  0.47316638\n",
      "  0.48186147 0.49042553]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04953618720173836\n",
      "Predicción post entrenamiento : [[0.5021516]]\n",
      "PERDIDAAAA despues: 0.048592258244752884\n",
      "loss en el callback: 0.058967236429452896, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.43629581]\n",
      "  [0.44546303]\n",
      "  [0.45454103]\n",
      "  [0.4636912 ]\n",
      "  [0.47316638]\n",
      "  [0.48186147]\n",
      "  [0.49042553]\n",
      "  [0.50002086]]]\n",
      "ejemplar: [0.43629581 0.44546303 0.45454103 0.4636912  0.47316638 0.48186147\n",
      " 0.49042553 0.50002086]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.5092718]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.43629581 0.44546303 0.45454103 0.4636912  0.47316638 0.48186147\n",
      "  0.49042553 0.50002086]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061020974069833755\n",
      "Predicción post entrenamiento : [[0.5107074]]\n",
      "PERDIDAAAA despues: 0.060313791036605835\n",
      "loss en el callback: 0.017806142568588257, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.44546303]\n",
      "  [0.45454103]\n",
      "  [0.4636912 ]\n",
      "  [0.47316638]\n",
      "  [0.48186147]\n",
      "  [0.49042553]\n",
      "  [0.50002086]\n",
      "  [0.5092718 ]]]\n",
      "ejemplar: [0.44546303 0.45454103 0.4636912  0.47316638 0.48186147 0.49042553\n",
      " 0.50002086 0.5092718 ]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5179055]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.44546303 0.45454103 0.4636912  0.47316638 0.48186147 0.49042553\n",
      "  0.50002086 0.5092718 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09590217471122742\n",
      "Predicción post entrenamiento : [[0.52085835]]\n",
      "PERDIDAAAA despues: 0.09408199787139893\n",
      "loss en el callback: 0.0952252447605133, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.45454103]\n",
      "  [0.4636912 ]\n",
      "  [0.47316638]\n",
      "  [0.48186147]\n",
      "  [0.49042553]\n",
      "  [0.50002086]\n",
      "  [0.5092718 ]\n",
      "  [0.51790547]]]\n",
      "ejemplar: [0.45454103 0.4636912  0.47316638 0.48186147 0.49042553 0.50002086\n",
      " 0.5092718  0.51790547]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5280782]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.45454103 0.4636912  0.47316638 0.48186147 0.49042553 0.50002086\n",
      "  0.5092718  0.51790547]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09656182676553726\n",
      "Predicción post entrenamiento : [[0.530712]]\n",
      "PERDIDAAAA despues: 0.09493187814950943\n",
      "loss en el callback: 0.07747205346822739, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.4636912 ]\n",
      "  [0.47316638]\n",
      "  [0.48186147]\n",
      "  [0.49042553]\n",
      "  [0.50002086]\n",
      "  [0.5092718 ]\n",
      "  [0.51790547]\n",
      "  [0.5280782 ]]]\n",
      "ejemplar: [0.4636912  0.47316638 0.48186147 0.49042553 0.50002086 0.5092718\n",
      " 0.51790547 0.5280782 ]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5379764]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.4636912  0.47316638 0.48186147 0.49042553 0.50002086 0.5092718\n",
      "  0.51790547 0.5280782 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06568426638841629\n",
      "Predicción post entrenamiento : [[0.5402014]]\n",
      "PERDIDAAAA despues: 0.06454870849847794\n",
      "loss en el callback: 0.055842332541942596, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.47316638]\n",
      "  [0.48186147]\n",
      "  [0.49042553]\n",
      "  [0.50002086]\n",
      "  [0.5092718 ]\n",
      "  [0.51790547]\n",
      "  [0.5280782 ]\n",
      "  [0.53797638]]]\n",
      "ejemplar: [0.47316638 0.48186147 0.49042553 0.50002086 0.5092718  0.51790547\n",
      " 0.5280782  0.53797638]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5475002]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.47316638 0.48186147 0.49042553 0.50002086 0.5092718  0.51790547\n",
      "  0.5280782  0.53797638]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05583982542157173\n",
      "Predicción post entrenamiento : [[0.5500934]]\n",
      "PERDIDAAAA despues: 0.05462097376585007\n",
      "loss en el callback: 0.12698973715305328, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.48186147]\n",
      "  [0.49042553]\n",
      "  [0.50002086]\n",
      "  [0.5092718 ]\n",
      "  [0.51790547]\n",
      "  [0.5280782 ]\n",
      "  [0.53797638]\n",
      "  [0.54750019]]]\n",
      "ejemplar: [0.48186147 0.49042553 0.50002086 0.5092718  0.51790547 0.5280782\n",
      " 0.53797638 0.54750019]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.55735415]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.48186147 0.49042553 0.50002086 0.5092718  0.51790547 0.5280782\n",
      "  0.53797638 0.54750019]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04433773085474968\n",
      "Predicción post entrenamiento : [[0.5594648]]\n",
      "PERDIDAAAA despues: 0.04345332458615303\n",
      "loss en el callback: 0.0627639964222908, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.49042553]\n",
      "  [0.50002086]\n",
      "  [0.5092718 ]\n",
      "  [0.51790547]\n",
      "  [0.5280782 ]\n",
      "  [0.53797638]\n",
      "  [0.54750019]\n",
      "  [0.55735415]]]\n",
      "ejemplar: [0.49042553 0.50002086 0.5092718  0.51790547 0.5280782  0.53797638\n",
      " 0.54750019 0.55735415]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5669027]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.49042553 0.50002086 0.5092718  0.51790547 0.5280782  0.53797638\n",
      "  0.54750019 0.55735415]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047383248805999756\n",
      "Predicción post entrenamiento : [[0.5684889]]\n",
      "PERDIDAAAA despues: 0.04669520631432533\n",
      "loss en el callback: 0.02569674514234066, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.50002086]\n",
      "  [0.5092718 ]\n",
      "  [0.51790547]\n",
      "  [0.5280782 ]\n",
      "  [0.53797638]\n",
      "  [0.54750019]\n",
      "  [0.55735415]\n",
      "  [0.5669027 ]]]\n",
      "ejemplar: [0.50002086 0.5092718  0.51790547 0.5280782  0.53797638 0.54750019\n",
      " 0.55735415 0.5669027 ]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5761789]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.50002086 0.5092718  0.51790547 0.5280782  0.53797638 0.54750019\n",
      "  0.55735415 0.5669027 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09153665602207184\n",
      "Predicción post entrenamiento : [[0.5792461]]\n",
      "PERDIDAAAA despues: 0.08969010412693024\n",
      "loss en el callback: 0.17998434603214264, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.5092718 ]\n",
      "  [0.51790547]\n",
      "  [0.5280782 ]\n",
      "  [0.53797638]\n",
      "  [0.54750019]\n",
      "  [0.55735415]\n",
      "  [0.5669027 ]\n",
      "  [0.57617891]]]\n",
      "ejemplar: [0.5092718  0.51790547 0.5280782  0.53797638 0.54750019 0.55735415\n",
      " 0.5669027  0.57617891]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5869591]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.5092718  0.51790547 0.5280782  0.53797638 0.54750019 0.55735415\n",
      "  0.5669027  0.57617891]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08333064615726471\n",
      "Predicción post entrenamiento : [[0.5891324]]\n",
      "PERDIDAAAA despues: 0.08208063244819641\n",
      "loss en el callback: 0.04922918230295181, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51790547]\n",
      "  [0.5280782 ]\n",
      "  [0.53797638]\n",
      "  [0.54750019]\n",
      "  [0.55735415]\n",
      "  [0.5669027 ]\n",
      "  [0.57617891]\n",
      "  [0.58695912]]]\n",
      "ejemplar: [0.51790547 0.5280782  0.53797638 0.54750019 0.55735415 0.5669027\n",
      " 0.57617891 0.58695912]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.59696823]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51790547 0.5280782  0.53797638 0.54750019 0.55735415 0.5669027\n",
      "  0.57617891 0.58695912]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06346749514341354\n",
      "Predicción post entrenamiento : [[0.59915984]]\n",
      "PERDIDAAAA despues: 0.06236804649233818\n",
      "loss en el callback: 0.06589839607477188, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.5280782 ]\n",
      "  [0.53797638]\n",
      "  [0.54750019]\n",
      "  [0.55735415]\n",
      "  [0.5669027 ]\n",
      "  [0.57617891]\n",
      "  [0.58695912]\n",
      "  [0.59696823]]]\n",
      "ejemplar: [0.5280782  0.53797638 0.54750019 0.55735415 0.5669027  0.57617891\n",
      " 0.58695912 0.59696823]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.60731375]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.5280782  0.53797638 0.54750019 0.55735415 0.5669027  0.57617891\n",
      "  0.58695912 0.59696823]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04450991749763489\n",
      "Predicción post entrenamiento : [[0.6093114]]\n",
      "PERDIDAAAA despues: 0.043671004474163055\n",
      "loss en el callback: 0.06259305030107498, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53797638]\n",
      "  [0.54750019]\n",
      "  [0.55735415]\n",
      "  [0.5669027 ]\n",
      "  [0.57617891]\n",
      "  [0.58695912]\n",
      "  [0.59696823]\n",
      "  [0.60731375]]]\n",
      "ejemplar: [0.53797638 0.54750019 0.55735415 0.5669027  0.57617891 0.58695912\n",
      " 0.59696823 0.60731375]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6174147]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53797638 0.54750019 0.55735415 0.5669027  0.57617891 0.58695912\n",
      "  0.59696823 0.60731375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04384693503379822\n",
      "Predicción post entrenamiento : [[0.6191184]]\n",
      "PERDIDAAAA despues: 0.0431363508105278\n",
      "loss en el callback: 0.04234682023525238, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54750019]\n",
      "  [0.55735415]\n",
      "  [0.5669027 ]\n",
      "  [0.57617891]\n",
      "  [0.58695912]\n",
      "  [0.59696823]\n",
      "  [0.60731375]\n",
      "  [0.61741471]]]\n",
      "ejemplar: [0.54750019 0.55735415 0.5669027  0.57617891 0.58695912 0.59696823\n",
      " 0.60731375 0.61741471]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6272417]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54750019 0.55735415 0.5669027  0.57617891 0.58695912 0.59696823\n",
      "  0.60731375 0.61741471]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02499966509640217\n",
      "Predicción post entrenamiento : [[0.62842345]]\n",
      "PERDIDAAAA despues: 0.024627352133393288\n",
      "loss en el callback: 0.01779777742922306, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55735415]\n",
      "  [0.5669027 ]\n",
      "  [0.57617891]\n",
      "  [0.58695912]\n",
      "  [0.59696823]\n",
      "  [0.60731375]\n",
      "  [0.61741471]\n",
      "  [0.62724167]]]\n",
      "ejemplar: [0.55735415 0.5669027  0.57617891 0.58695912 0.59696823 0.60731375\n",
      " 0.61741471 0.62724167]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.63667744]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55735415 0.5669027  0.57617891 0.58695912 0.59696823 0.60731375\n",
      "  0.61741471 0.62724167]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023271970450878143\n",
      "Predicción post entrenamiento : [[0.63834244]]\n",
      "PERDIDAAAA despues: 0.02276674658060074\n",
      "loss en el callback: 0.04686615243554115, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.5669027 ]\n",
      "  [0.57617891]\n",
      "  [0.58695912]\n",
      "  [0.59696823]\n",
      "  [0.60731375]\n",
      "  [0.61741471]\n",
      "  [0.62724167]\n",
      "  [0.63667744]]]\n",
      "ejemplar: [0.5669027  0.57617891 0.58695912 0.59696823 0.60731375 0.61741471\n",
      " 0.62724167 0.63667744]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6466594]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.5669027  0.57617891 0.58695912 0.59696823 0.60731375 0.61741471\n",
      "  0.62724167 0.63667744]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035161279141902924\n",
      "Predicción post entrenamiento : [[0.64805484]]\n",
      "PERDIDAAAA despues: 0.03463989123702049\n",
      "loss en el callback: 0.025129586458206177, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57617891]\n",
      "  [0.58695912]\n",
      "  [0.59696823]\n",
      "  [0.60731375]\n",
      "  [0.61741471]\n",
      "  [0.62724167]\n",
      "  [0.63667744]\n",
      "  [0.64665937]]]\n",
      "ejemplar: [0.57617891 0.58695912 0.59696823 0.60731375 0.61741471 0.62724167\n",
      " 0.63667744 0.64665937]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6565243]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57617891 0.58695912 0.59696823 0.60731375 0.61741471 0.62724167\n",
      "  0.63667744 0.64665937]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024320870637893677\n",
      "Predicción post entrenamiento : [[0.65779674]]\n",
      "PERDIDAAAA despues: 0.02392561174929142\n",
      "loss en el callback: 0.02085447683930397, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58695912]\n",
      "  [0.59696823]\n",
      "  [0.60731375]\n",
      "  [0.61741471]\n",
      "  [0.62724167]\n",
      "  [0.63667744]\n",
      "  [0.64665937]\n",
      "  [0.6565243 ]]]\n",
      "ejemplar: [0.58695912 0.59696823 0.60731375 0.61741471 0.62724167 0.63667744\n",
      " 0.64665937 0.6565243 ]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6665088]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58695912 0.59696823 0.60731375 0.61741471 0.62724167 0.63667744\n",
      "  0.64665937 0.6565243 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018152456730604172\n",
      "Predicción post entrenamiento : [[0.66803455]]\n",
      "PERDIDAAAA despues: 0.017743650823831558\n",
      "loss en el callback: 0.03513776883482933, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59696823]\n",
      "  [0.60731375]\n",
      "  [0.61741471]\n",
      "  [0.62724167]\n",
      "  [0.63667744]\n",
      "  [0.64665937]\n",
      "  [0.6565243 ]\n",
      "  [0.66650879]]]\n",
      "ejemplar: [0.59696823 0.60731375 0.61741471 0.62724167 0.63667744 0.64665937\n",
      " 0.6565243  0.66650879]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6765887]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59696823 0.60731375 0.61741471 0.62724167 0.63667744 0.64665937\n",
      "  0.6565243  0.66650879]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01602460816502571\n",
      "Predicción post entrenamiento : [[0.6780363]]\n",
      "PERDIDAAAA despues: 0.01566021703183651\n",
      "loss en el callback: 0.032025985419750214, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60731375]\n",
      "  [0.61741471]\n",
      "  [0.62724167]\n",
      "  [0.63667744]\n",
      "  [0.64665937]\n",
      "  [0.6565243 ]\n",
      "  [0.66650879]\n",
      "  [0.67658871]]]\n",
      "ejemplar: [0.60731375 0.61741471 0.62724167 0.63667744 0.64665937 0.6565243\n",
      " 0.66650879 0.67658871]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6866101]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60731375 0.61741471 0.62724167 0.63667744 0.64665937 0.6565243\n",
      "  0.66650879 0.67658871]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011423502117395401\n",
      "Predicción post entrenamiento : [[0.6872587]]\n",
      "PERDIDAAAA despues: 0.011285273358225822\n",
      "loss en el callback: 0.0051261018961668015, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61741471]\n",
      "  [0.62724167]\n",
      "  [0.63667744]\n",
      "  [0.64665937]\n",
      "  [0.6565243 ]\n",
      "  [0.66650879]\n",
      "  [0.67658871]\n",
      "  [0.6866101 ]]]\n",
      "ejemplar: [0.61741471 0.62724167 0.63667744 0.64665937 0.6565243  0.66650879\n",
      " 0.67658871 0.6866101 ]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6957485]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61741471 0.62724167 0.63667744 0.64665937 0.6565243  0.66650879\n",
      "  0.67658871 0.6866101 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004150188062340021\n",
      "Predicción post entrenamiento : [[0.6964853]]\n",
      "PERDIDAAAA despues: 0.0040558017790317535\n",
      "loss en el callback: 0.008081702515482903, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62724167]\n",
      "  [0.63667744]\n",
      "  [0.64665937]\n",
      "  [0.6565243 ]\n",
      "  [0.66650879]\n",
      "  [0.67658871]\n",
      "  [0.6866101 ]\n",
      "  [0.69574851]]]\n",
      "ejemplar: [0.62724167 0.63667744 0.64665937 0.6565243  0.66650879 0.67658871\n",
      " 0.6866101  0.69574851]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7049393]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62724167 0.63667744 0.64665937 0.6565243  0.66650879 0.67658871\n",
      "  0.6866101  0.69574851]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009262653766199946\n",
      "Predicción post entrenamiento : [[0.70466185]]\n",
      "PERDIDAAAA despues: 0.0009432311053387821\n",
      "loss en el callback: 0.0009057975839823484, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63667744]\n",
      "  [0.64665937]\n",
      "  [0.6565243 ]\n",
      "  [0.66650879]\n",
      "  [0.67658871]\n",
      "  [0.6866101 ]\n",
      "  [0.69574851]\n",
      "  [0.70493931]]]\n",
      "ejemplar: [0.63667744 0.64665937 0.6565243  0.66650879 0.67658871 0.6866101\n",
      " 0.69574851 0.70493931]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.71313894]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63667744 0.64665937 0.6565243  0.66650879 0.67658871 0.6866101\n",
      "  0.69574851 0.70493931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.697300472704228e-06\n",
      "Predicción post entrenamiento : [[0.71294266]]\n",
      "PERDIDAAAA despues: 7.578130862384569e-06\n",
      "loss en el callback: 0.0005569816567003727, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.64665937]\n",
      "  [0.6565243 ]\n",
      "  [0.66650879]\n",
      "  [0.67658871]\n",
      "  [0.6866101 ]\n",
      "  [0.69574851]\n",
      "  [0.70493931]\n",
      "  [0.71313894]]]\n",
      "ejemplar: [0.64665937 0.6565243  0.66650879 0.67658871 0.6866101  0.69574851\n",
      " 0.70493931 0.71313894]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.72153807]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.64665937 0.6565243  0.66650879 0.67658871 0.6866101  0.69574851\n",
      "  0.70493931 0.71313894]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.856649219524115e-05\n",
      "Predicción post entrenamiento : [[0.7218772]]\n",
      "PERDIDAAAA despues: 9.506499191047624e-05\n",
      "loss en el callback: 0.0017852620221674442, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.6565243 ]\n",
      "  [0.66650879]\n",
      "  [0.67658871]\n",
      "  [0.6866101 ]\n",
      "  [0.69574851]\n",
      "  [0.70493931]\n",
      "  [0.71313894]\n",
      "  [0.72153807]]]\n",
      "ejemplar: [0.6565243  0.66650879 0.67658871 0.6866101  0.69574851 0.70493931\n",
      " 0.71313894 0.72153807]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7304202]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.6565243  0.66650879 0.67658871 0.6866101  0.69574851 0.70493931\n",
      "  0.71313894 0.72153807]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.492825872963294e-05\n",
      "Predicción post entrenamiento : [[0.7309931]]\n",
      "PERDIDAAAA despues: 7.469683623639867e-05\n",
      "loss en el callback: 0.005287598818540573, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.66650879]\n",
      "  [0.67658871]\n",
      "  [0.6866101 ]\n",
      "  [0.69574851]\n",
      "  [0.70493931]\n",
      "  [0.71313894]\n",
      "  [0.72153807]\n",
      "  [0.73042017]]]\n",
      "ejemplar: [0.66650879 0.67658871 0.6866101  0.69574851 0.70493931 0.71313894\n",
      " 0.72153807 0.73042017]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.73946846]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.66650879 0.67658871 0.6866101  0.69574851 0.70493931 0.71313894\n",
      "  0.72153807 0.73042017]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.102027999877464e-05\n",
      "Predicción post entrenamiento : [[0.73875284]]\n",
      "PERDIDAAAA despues: 6.781166575819952e-06\n",
      "loss en el callback: 0.006185146979987621, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.67658871]\n",
      "  [0.6866101 ]\n",
      "  [0.69574851]\n",
      "  [0.70493931]\n",
      "  [0.71313894]\n",
      "  [0.72153807]\n",
      "  [0.73042017]\n",
      "  [0.73946846]]]\n",
      "ejemplar: [0.67658871 0.6866101  0.69574851 0.70493931 0.71313894 0.72153807\n",
      " 0.73042017 0.73946846]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.74707013]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.67658871 0.6866101  0.69574851 0.70493931 0.71313894 0.72153807\n",
      "  0.73042017 0.73946846]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006320158485323191\n",
      "Predicción post entrenamiento : [[0.74656016]]\n",
      "PERDIDAAAA despues: 0.006239332724362612\n",
      "loss en el callback: 0.003939542919397354, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.6866101 ]\n",
      "  [0.69574851]\n",
      "  [0.70493931]\n",
      "  [0.71313894]\n",
      "  [0.72153807]\n",
      "  [0.73042017]\n",
      "  [0.73946846]\n",
      "  [0.74707013]]]\n",
      "ejemplar: [0.6866101  0.69574851 0.70493931 0.71313894 0.72153807 0.73042017\n",
      " 0.73946846 0.74707013]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7546272]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.6866101  0.69574851 0.70493931 0.71313894 0.72153807 0.73042017\n",
      "  0.73946846 0.74707013]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007179480977356434\n",
      "Predicción post entrenamiento : [[0.75432956]]\n",
      "PERDIDAAAA despues: 0.007129125762730837\n",
      "loss en el callback: 0.0014742116909474134, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.69574851]\n",
      "  [0.70493931]\n",
      "  [0.71313894]\n",
      "  [0.72153807]\n",
      "  [0.73042017]\n",
      "  [0.73946846]\n",
      "  [0.74707013]\n",
      "  [0.75462723]]]\n",
      "ejemplar: [0.69574851 0.70493931 0.71313894 0.72153807 0.73042017 0.73946846\n",
      " 0.74707013 0.75462723]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.76208544]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.69574851 0.70493931 0.71313894 0.72153807 0.73042017 0.73946846\n",
      "  0.74707013 0.75462723]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042845155112445354\n",
      "Predicción post entrenamiento : [[0.7606608]]\n",
      "PERDIDAAAA despues: 0.004100046120584011\n",
      "loss en el callback: 0.02476024255156517, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70493931]\n",
      "  [0.71313894]\n",
      "  [0.72153807]\n",
      "  [0.73042017]\n",
      "  [0.73946846]\n",
      "  [0.74707013]\n",
      "  [0.75462723]\n",
      "  [0.76208544]]]\n",
      "ejemplar: [0.70493931 0.71313894 0.72153807 0.73042017 0.73946846 0.74707013\n",
      " 0.75462723 0.76208544]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7682747]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70493931 0.71313894 0.72153807 0.73042017 0.73946846 0.74707013\n",
      "  0.75462723 0.76208544]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012617443688213825\n",
      "Predicción post entrenamiento : [[0.7684158]]\n",
      "PERDIDAAAA despues: 0.01264915894716978\n",
      "loss en el callback: 0.0004401729383971542, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71313894]\n",
      "  [0.72153807]\n",
      "  [0.73042017]\n",
      "  [0.73946846]\n",
      "  [0.74707013]\n",
      "  [0.75462723]\n",
      "  [0.76208544]\n",
      "  [0.76827472]]]\n",
      "ejemplar: [0.71313894 0.72153807 0.73042017 0.73946846 0.74707013 0.75462723\n",
      " 0.76208544 0.76827472]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7758145]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71313894 0.72153807 0.73042017 0.73946846 0.74707013 0.75462723\n",
      "  0.76208544 0.76827472]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009410515427589417\n",
      "Predicción post entrenamiento : [[0.77576584]]\n",
      "PERDIDAAAA despues: 0.009401081129908562\n",
      "loss en el callback: 4.1322291508549824e-05, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.72153807]\n",
      "  [0.73042017]\n",
      "  [0.73946846]\n",
      "  [0.74707013]\n",
      "  [0.75462723]\n",
      "  [0.76208544]\n",
      "  [0.76827472]\n",
      "  [0.77581447]]]\n",
      "ejemplar: [0.72153807 0.73042017 0.73946846 0.74707013 0.75462723 0.76208544\n",
      " 0.76827472 0.77581447]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7831622]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.72153807 0.73042017 0.73946846 0.74707013 0.75462723 0.76208544\n",
      "  0.76827472 0.77581447]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011463480070233345\n",
      "Predicción post entrenamiento : [[0.7811451]]\n",
      "PERDIDAAAA despues: 0.011035621166229248\n",
      "loss en el callback: 0.05013938620686531, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.73042017]\n",
      "  [0.73946846]\n",
      "  [0.74707013]\n",
      "  [0.75462723]\n",
      "  [0.76208544]\n",
      "  [0.76827472]\n",
      "  [0.77581447]\n",
      "  [0.78316218]]]\n",
      "ejemplar: [0.73042017 0.73946846 0.74707013 0.75462723 0.76208544 0.76827472\n",
      " 0.77581447 0.78316218]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.78842974]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.73042017 0.73946846 0.74707013 0.75462723 0.76208544 0.76827472\n",
      "  0.77581447 0.78316218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003465391229838133\n",
      "Predicción post entrenamiento : [[0.78825974]]\n",
      "PERDIDAAAA despues: 0.0034454059787094593\n",
      "loss en el callback: 0.0005009282031096518, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.73946846]\n",
      "  [0.74707013]\n",
      "  [0.75462723]\n",
      "  [0.76208544]\n",
      "  [0.76827472]\n",
      "  [0.77581447]\n",
      "  [0.78316218]\n",
      "  [0.78842974]]]\n",
      "ejemplar: [0.73946846 0.74707013 0.75462723 0.76208544 0.76827472 0.77581447\n",
      " 0.78316218 0.78842974]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7952262]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.73946846 0.74707013 0.75462723 0.76208544 0.76827472 0.77581447\n",
      "  0.78316218 0.78842974]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008826160803437233\n",
      "Predicción post entrenamiento : [[0.79563254]]\n",
      "PERDIDAAAA despues: 0.008902672678232193\n",
      "loss en el callback: 0.003846584353595972, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74707013]\n",
      "  [0.75462723]\n",
      "  [0.76208544]\n",
      "  [0.76827472]\n",
      "  [0.77581447]\n",
      "  [0.78316218]\n",
      "  [0.78842974]\n",
      "  [0.79522622]]]\n",
      "ejemplar: [0.74707013 0.75462723 0.76208544 0.76827472 0.77581447 0.78316218\n",
      " 0.78842974 0.79522622]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8021357]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74707013 0.75462723 0.76208544 0.76827472 0.77581447 0.78316218\n",
      "  0.78842974 0.79522622]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011974170338362455\n",
      "Predicción post entrenamiento : [[0.8016539]]\n",
      "PERDIDAAAA despues: 0.0011643061880022287\n",
      "loss en el callback: 0.003506438573822379, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75462723]\n",
      "  [0.76208544]\n",
      "  [0.76827472]\n",
      "  [0.77581447]\n",
      "  [0.78316218]\n",
      "  [0.78842974]\n",
      "  [0.79522622]\n",
      "  [0.80213571]]]\n",
      "ejemplar: [0.75462723 0.76208544 0.76827472 0.77581447 0.78316218 0.78842974\n",
      " 0.79522622 0.80213571]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.8080122]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75462723 0.76208544 0.76827472 0.77581447 0.78316218 0.78842974\n",
      "  0.79522622 0.80213571]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027961356099694967\n",
      "Predicción post entrenamiento : [[0.80864036]]\n",
      "PERDIDAAAA despues: 0.0028629640582948923\n",
      "loss en el callback: 0.008489716798067093, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.76208544]\n",
      "  [0.76827472]\n",
      "  [0.77581447]\n",
      "  [0.78316218]\n",
      "  [0.78842974]\n",
      "  [0.79522622]\n",
      "  [0.80213571]\n",
      "  [0.80801219]]]\n",
      "ejemplar: [0.76208544 0.76827472 0.77581447 0.78316218 0.78842974 0.79522622\n",
      " 0.80213571 0.80801219]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8148205]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.76208544 0.76827472 0.77581447 0.78316218 0.78842974 0.79522622\n",
      "  0.80213571 0.80801219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004866527393460274\n",
      "Predicción post entrenamiento : [[0.8146961]]\n",
      "PERDIDAAAA despues: 0.004849179182201624\n",
      "loss en el callback: 0.0002889013849198818, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.76827472]\n",
      "  [0.77581447]\n",
      "  [0.78316218]\n",
      "  [0.78842974]\n",
      "  [0.79522622]\n",
      "  [0.80213571]\n",
      "  [0.80801219]\n",
      "  [0.81482053]]]\n",
      "ejemplar: [0.76827472 0.77581447 0.78316218 0.78842974 0.79522622 0.80213571\n",
      " 0.80801219 0.81482053]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8206775]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.76827472 0.77581447 0.78316218 0.78842974 0.79522622 0.80213571\n",
      "  0.80801219 0.81482053]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004711923189461231\n",
      "Predicción post entrenamiento : [[0.8206965]]\n",
      "PERDIDAAAA despues: 0.004714525770395994\n",
      "loss en el callback: 6.253266747080488e-06, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.77581447]\n",
      "  [0.78316218]\n",
      "  [0.78842974]\n",
      "  [0.79522622]\n",
      "  [0.80213571]\n",
      "  [0.80801219]\n",
      "  [0.81482053]\n",
      "  [0.82067752]]]\n",
      "ejemplar: [0.77581447 0.78316218 0.78842974 0.79522622 0.80213571 0.80801219\n",
      " 0.81482053 0.82067752]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8268071]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.77581447 0.78316218 0.78842974 0.79522622 0.80213571 0.80801219\n",
      "  0.81482053 0.82067752]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013690098188817501\n",
      "Predicción post entrenamiento : [[0.82599723]]\n",
      "PERDIDAAAA despues: 0.01350124180316925\n",
      "loss en el callback: 0.011689668521285057, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.78316218]\n",
      "  [0.78842974]\n",
      "  [0.79522622]\n",
      "  [0.80213571]\n",
      "  [0.80801219]\n",
      "  [0.81482053]\n",
      "  [0.82067752]\n",
      "  [0.82680708]]]\n",
      "ejemplar: [0.78316218 0.78842974 0.79522622 0.80213571 0.80801219 0.81482053\n",
      " 0.82067752 0.82680708]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.83183575]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.78316218 0.78842974 0.79522622 0.80213571 0.80801219 0.81482053\n",
      "  0.82067752 0.82680708]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019995572045445442\n",
      "Predicción post entrenamiento : [[0.8307561]]\n",
      "PERDIDAAAA despues: 0.019691409543156624\n",
      "loss en el callback: 0.018754344433546066, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.78842974]\n",
      "  [0.79522622]\n",
      "  [0.80213571]\n",
      "  [0.80801219]\n",
      "  [0.81482053]\n",
      "  [0.82067752]\n",
      "  [0.82680708]\n",
      "  [0.83183575]]]\n",
      "ejemplar: [0.78842974 0.79522622 0.80213571 0.80801219 0.81482053 0.82067752\n",
      " 0.82680708 0.83183575]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.83631605]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.78842974 0.79522622 0.80213571 0.80801219 0.81482053 0.82067752\n",
      "  0.82680708 0.83183575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006716995965689421\n",
      "Predicción post entrenamiento : [[0.83414483]]\n",
      "PERDIDAAAA despues: 0.00636581564322114\n",
      "loss en el callback: 0.06083974242210388, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.79522622]\n",
      "  [0.80213571]\n",
      "  [0.80801219]\n",
      "  [0.81482053]\n",
      "  [0.82067752]\n",
      "  [0.82680708]\n",
      "  [0.83183575]\n",
      "  [0.83631605]]]\n",
      "ejemplar: [0.79522622 0.80213571 0.80801219 0.81482053 0.82067752 0.82680708\n",
      " 0.83183575 0.83631605]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.839974]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.79522622 0.80213571 0.80801219 0.81482053 0.82067752 0.82680708\n",
      "  0.83183575 0.83631605]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013870548456907272\n",
      "Predicción post entrenamiento : [[0.8394706]]\n",
      "PERDIDAAAA despues: 0.01375223696231842\n",
      "loss en el callback: 0.004990139976143837, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.80213571]\n",
      "  [0.80801219]\n",
      "  [0.81482053]\n",
      "  [0.82067752]\n",
      "  [0.82680708]\n",
      "  [0.83183575]\n",
      "  [0.83631605]\n",
      "  [0.83997399]]]\n",
      "ejemplar: [0.80213571 0.80801219 0.81482053 0.82067752 0.82680708 0.83183575\n",
      " 0.83631605 0.83997399]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.84511244]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.80213571 0.80801219 0.81482053 0.82067752 0.82680708 0.83183575\n",
      "  0.83631605 0.83997399]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.153223911387613e-05\n",
      "Predicción post entrenamiento : [[0.84386945]]\n",
      "PERDIDAAAA despues: 2.1519488655030727e-05\n",
      "loss en el callback: 0.020417170599102974, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.80801219]\n",
      "  [0.81482053]\n",
      "  [0.82067752]\n",
      "  [0.82680708]\n",
      "  [0.83183575]\n",
      "  [0.83631605]\n",
      "  [0.83997399]\n",
      "  [0.84511244]]]\n",
      "ejemplar: [0.80801219 0.81482053 0.82067752 0.82680708 0.83183575 0.83631605\n",
      " 0.83997399 0.84511244]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.84920514]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.80801219 0.81482053 0.82067752 0.82680708 0.83183575 0.83631605\n",
      "  0.83997399 0.84511244]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003164944937452674\n",
      "Predicción post entrenamiento : [[0.84846216]]\n",
      "PERDIDAAAA despues: 0.00324909295886755\n",
      "loss en el callback: 0.007379057351499796, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81482053]\n",
      "  [0.82067752]\n",
      "  [0.82680708]\n",
      "  [0.83183575]\n",
      "  [0.83631605]\n",
      "  [0.83997399]\n",
      "  [0.84511244]\n",
      "  [0.84920514]]]\n",
      "ejemplar: [0.81482053 0.82067752 0.82680708 0.83183575 0.83631605 0.83997399\n",
      " 0.84511244 0.84920514]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.85369825]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81482053 0.82067752 0.82680708 0.83183575 0.83631605 0.83997399\n",
      "  0.84511244 0.84920514]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008132741204462945\n",
      "Predicción post entrenamiento : [[0.8542711]]\n",
      "PERDIDAAAA despues: 0.0007809287053532898\n",
      "loss en el callback: 0.006325969006866217, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.82067752]\n",
      "  [0.82680708]\n",
      "  [0.83183575]\n",
      "  [0.83631605]\n",
      "  [0.83997399]\n",
      "  [0.84511244]\n",
      "  [0.84920514]\n",
      "  [0.85369825]]]\n",
      "ejemplar: [0.82067752 0.82680708 0.83183575 0.83631605 0.83997399 0.84511244\n",
      " 0.84920514 0.85369825]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.85906434]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.82067752 0.82680708 0.83183575 0.83631605 0.83997399 0.84511244\n",
      "  0.84920514 0.85369825]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002373963827267289\n",
      "Predicción post entrenamiento : [[0.8592072]]\n",
      "PERDIDAAAA despues: 0.0023600617423653603\n",
      "loss en el callback: 0.0003239937941543758, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82680708]\n",
      "  [0.83183575]\n",
      "  [0.83631605]\n",
      "  [0.83997399]\n",
      "  [0.84511244]\n",
      "  [0.84920514]\n",
      "  [0.85369825]\n",
      "  [0.85906434]]]\n",
      "ejemplar: [0.82680708 0.83183575 0.83631605 0.83997399 0.84511244 0.84920514\n",
      " 0.85369825 0.85906434]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8637369]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82680708 0.83183575 0.83631605 0.83997399 0.84511244 0.84920514\n",
      "  0.85369825 0.85906434]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006677448400296271\n",
      "Predicción post entrenamiento : [[0.86321074]]\n",
      "PERDIDAAAA despues: 0.0006952160038053989\n",
      "loss en el callback: 0.004231076687574387, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.83183575]\n",
      "  [0.83631605]\n",
      "  [0.83997399]\n",
      "  [0.84511244]\n",
      "  [0.84920514]\n",
      "  [0.85369825]\n",
      "  [0.85906434]\n",
      "  [0.86373693]]]\n",
      "ejemplar: [0.83183575 0.83631605 0.83997399 0.84511244 0.84920514 0.85369825\n",
      " 0.85906434 0.86373693]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8673352]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.83183575 0.83631605 0.83997399 0.84511244 0.84920514 0.85369825\n",
      "  0.85906434 0.86373693]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.654263441101648e-05\n",
      "Predicción post entrenamiento : [[0.86637664]]\n",
      "PERDIDAAAA despues: 7.18772571417503e-05\n",
      "loss en el callback: 0.013600308448076248, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.83631605]\n",
      "  [0.83997399]\n",
      "  [0.84511244]\n",
      "  [0.84920514]\n",
      "  [0.85369825]\n",
      "  [0.85906434]\n",
      "  [0.86373693]\n",
      "  [0.8673352 ]]]\n",
      "ejemplar: [0.83631605 0.83997399 0.84511244 0.84920514 0.85369825 0.85906434\n",
      " 0.86373693 0.8673352 ]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.87035644]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.83631605 0.83997399 0.84511244 0.84920514 0.85369825 0.85906434\n",
      "  0.86373693 0.8673352 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018365939613431692\n",
      "Predicción post entrenamiento : [[0.8687421]]\n",
      "PERDIDAAAA despues: 0.0019775661639869213\n",
      "loss en el callback: 0.03442490100860596, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.83997399]\n",
      "  [0.84511244]\n",
      "  [0.84920514]\n",
      "  [0.85369825]\n",
      "  [0.85906434]\n",
      "  [0.86373693]\n",
      "  [0.8673352 ]\n",
      "  [0.87035644]]]\n",
      "ejemplar: [0.83997399 0.84511244 0.84920514 0.85369825 0.85906434 0.86373693\n",
      " 0.8673352  0.87035644]\n",
      "y: 1.0\n",
      "Predicción : [[0.87271124]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.83997399 0.84511244 0.84920514 0.85369825 0.85906434 0.86373693\n",
      "  0.8673352  0.87035644]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016202427446842194\n",
      "Predicción post entrenamiento : [[0.87406147]]\n",
      "PERDIDAAAA despues: 0.01586051471531391\n",
      "loss en el callback: 0.03884661942720413, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.84511244]\n",
      "  [0.84920514]\n",
      "  [0.85369825]\n",
      "  [0.85906434]\n",
      "  [0.86373693]\n",
      "  [0.8673352 ]\n",
      "  [0.87035644]\n",
      "  [0.87271124]]]\n",
      "ejemplar: [0.84511244 0.84920514 0.85369825 0.85906434 0.86373693 0.8673352\n",
      " 0.87035644 0.87271124]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8782467]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.84511244 0.84920514 0.85369825 0.85906434 0.86373693 0.8673352\n",
      "  0.87035644 0.87271124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008520643226802349\n",
      "Predicción post entrenamiento : [[0.87897754]]\n",
      "PERDIDAAAA despues: 0.008386258035898209\n",
      "loss en el callback: 0.01002561580389738, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.84920514]\n",
      "  [0.85369825]\n",
      "  [0.85906434]\n",
      "  [0.86373693]\n",
      "  [0.8673352 ]\n",
      "  [0.87035644]\n",
      "  [0.87271124]\n",
      "  [0.87824672]]]\n",
      "ejemplar: [0.84920514 0.85369825 0.85906434 0.86373693 0.8673352  0.87035644\n",
      " 0.87271124 0.87824672]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8829392]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.84920514 0.85369825 0.85906434 0.86373693 0.8673352  0.87035644\n",
      "  0.87271124 0.87824672]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.438118801568635e-05\n",
      "Predicción post entrenamiento : [[0.8827664]]\n",
      "PERDIDAAAA despues: 3.643741365522146e-05\n",
      "loss en el callback: 0.0005229689413681626, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.85369825]\n",
      "  [0.85906434]\n",
      "  [0.86373693]\n",
      "  [0.8673352 ]\n",
      "  [0.87035644]\n",
      "  [0.87271124]\n",
      "  [0.87824672]\n",
      "  [0.88293922]]]\n",
      "ejemplar: [0.85369825 0.85906434 0.86373693 0.8673352  0.87035644 0.87271124\n",
      " 0.87824672 0.88293922]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8867622]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.85369825 0.85906434 0.86373693 0.8673352  0.87035644 0.87271124\n",
      "  0.87824672 0.88293922]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.757906132610515e-05\n",
      "Predicción post entrenamiento : [[0.8866607]]\n",
      "PERDIDAAAA despues: 7.580123929074034e-05\n",
      "loss en el callback: 0.0002073601499432698, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.85906434]\n",
      "  [0.86373693]\n",
      "  [0.8673352 ]\n",
      "  [0.87035644]\n",
      "  [0.87271124]\n",
      "  [0.87824672]\n",
      "  [0.88293922]\n",
      "  [0.8867622 ]]]\n",
      "ejemplar: [0.85906434 0.86373693 0.8673352  0.87035644 0.87271124 0.87824672\n",
      " 0.88293922 0.8867622 ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.89055836]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.85906434 0.86373693 0.8673352  0.87035644 0.87271124 0.87824672\n",
      "  0.88293922 0.8867622 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001735770027153194\n",
      "Predicción post entrenamiento : [[0.8903715]]\n",
      "PERDIDAAAA despues: 0.001720234751701355\n",
      "loss en el callback: 0.0006722220568917692, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.86373693]\n",
      "  [0.8673352 ]\n",
      "  [0.87035644]\n",
      "  [0.87271124]\n",
      "  [0.87824672]\n",
      "  [0.88293922]\n",
      "  [0.8867622 ]\n",
      "  [0.89055836]]]\n",
      "ejemplar: [0.86373693 0.8673352  0.87035644 0.87271124 0.87824672 0.88293922\n",
      " 0.8867622  0.89055836]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8938819]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.86373693 0.8673352  0.87035644 0.87271124 0.87824672 0.88293922\n",
      "  0.8867622  0.89055836]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035651803482323885\n",
      "Predicción post entrenamiento : [[0.89387065]]\n",
      "PERDIDAAAA despues: 0.003563835285604\n",
      "loss en el callback: 2.8260615181352478e-06, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.8673352 ]\n",
      "  [0.87035644]\n",
      "  [0.87271124]\n",
      "  [0.87824672]\n",
      "  [0.88293922]\n",
      "  [0.8867622 ]\n",
      "  [0.89055836]\n",
      "  [0.89388192]]]\n",
      "ejemplar: [0.8673352  0.87035644 0.87271124 0.87824672 0.88293922 0.8867622\n",
      " 0.89055836 0.89388192]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8971436]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.8673352  0.87035644 0.87271124 0.87824672 0.88293922 0.8867622\n",
      "  0.89055836 0.89388192]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017680925084277987\n",
      "Predicción post entrenamiento : [[0.8968859]]\n",
      "PERDIDAAAA despues: 0.0017464845441281796\n",
      "loss en el callback: 0.0013507260009646416, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.87035644]\n",
      "  [0.87271124]\n",
      "  [0.87824672]\n",
      "  [0.88293922]\n",
      "  [0.8867622 ]\n",
      "  [0.89055836]\n",
      "  [0.89388192]\n",
      "  [0.8971436 ]]]\n",
      "ejemplar: [0.87035644 0.87271124 0.87824672 0.88293922 0.8867622  0.89055836\n",
      " 0.89388192 0.8971436 ]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.90021557]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.87035644 0.87271124 0.87824672 0.88293922 0.8867622  0.89055836\n",
      "  0.89388192 0.8971436 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000623670348431915\n",
      "Predicción post entrenamiento : [[0.90009063]]\n",
      "PERDIDAAAA despues: 0.0006174460286274552\n",
      "loss en el callback: 0.0003092713304795325, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.87271124]\n",
      "  [0.87824672]\n",
      "  [0.88293922]\n",
      "  [0.8867622 ]\n",
      "  [0.89055836]\n",
      "  [0.89388192]\n",
      "  [0.8971436 ]\n",
      "  [0.90021557]]]\n",
      "ejemplar: [0.87271124 0.87824672 0.88293922 0.8867622  0.89055836 0.89388192\n",
      " 0.8971436  0.90021557]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.9036585]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.87271124 0.87824672 0.88293922 0.8867622  0.89055836 0.89388192\n",
      "  0.8971436  0.90021557]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021740146912634373\n",
      "Predicción post entrenamiento : [[0.90232915]]\n",
      "PERDIDAAAA despues: 0.0020518151577562094\n",
      "loss en el callback: 0.02941330149769783, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.87824672]\n",
      "  [0.88293922]\n",
      "  [0.8867622 ]\n",
      "  [0.89055836]\n",
      "  [0.89388192]\n",
      "  [0.8971436 ]\n",
      "  [0.90021557]\n",
      "  [0.90365851]]]\n",
      "ejemplar: [0.87824672 0.88293922 0.8867622  0.89055836 0.89388192 0.8971436\n",
      " 0.90021557 0.90365851]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.906352]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.87824672 0.88293922 0.8867622  0.89055836 0.89388192 0.8971436\n",
      "  0.90021557 0.90365851]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003168996889144182\n",
      "Predicción post entrenamiento : [[0.9060249]]\n",
      "PERDIDAAAA despues: 0.003132275305688381\n",
      "loss en el callback: 0.0021607063245028257, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.88293922]\n",
      "  [0.8867622 ]\n",
      "  [0.89055836]\n",
      "  [0.89388192]\n",
      "  [0.8971436 ]\n",
      "  [0.90021557]\n",
      "  [0.90365851]\n",
      "  [0.90635198]]]\n",
      "ejemplar: [0.88293922 0.8867622  0.89055836 0.89388192 0.8971436  0.90021557\n",
      " 0.90365851 0.90635198]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.90957403]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.88293922 0.8867622  0.89055836 0.89388192 0.8971436  0.90021557\n",
      "  0.90365851 0.90635198]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004472590051591396\n",
      "Predicción post entrenamiento : [[0.90971893]]\n",
      "PERDIDAAAA despues: 0.004491991829127073\n",
      "loss en el callback: 0.0004730380023829639, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.8867622 ]\n",
      "  [0.89055836]\n",
      "  [0.89388192]\n",
      "  [0.8971436 ]\n",
      "  [0.90021557]\n",
      "  [0.90365851]\n",
      "  [0.90635198]\n",
      "  [0.90957403]]]\n",
      "ejemplar: [0.8867622  0.89055836 0.89388192 0.8971436  0.90021557 0.90365851\n",
      " 0.90635198 0.90957403]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9129422]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.8867622  0.89055836 0.89388192 0.8971436  0.90021557 0.90365851\n",
      "  0.90635198 0.90957403]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008100961335003376\n",
      "Predicción post entrenamiento : [[0.91239464]]\n",
      "PERDIDAAAA despues: 0.008002699352800846\n",
      "loss en el callback: 0.006273013073951006, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.89055836]\n",
      "  [0.89388192]\n",
      "  [0.8971436 ]\n",
      "  [0.90021557]\n",
      "  [0.90365851]\n",
      "  [0.90635198]\n",
      "  [0.90957403]\n",
      "  [0.91294217]]]\n",
      "ejemplar: [0.89055836 0.89388192 0.8971436  0.90021557 0.90365851 0.90635198\n",
      " 0.90957403 0.91294217]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.91548496]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.89055836 0.89388192 0.8971436  0.90021557 0.90365851 0.90635198\n",
      "  0.90957403 0.91294217]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0198750589042902\n",
      "Predicción post entrenamiento : [[0.91475016]]\n",
      "PERDIDAAAA despues: 0.019668415188789368\n",
      "loss en el callback: 0.012179112061858177, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.89388192]\n",
      "  [0.8971436 ]\n",
      "  [0.90021557]\n",
      "  [0.90365851]\n",
      "  [0.90635198]\n",
      "  [0.90957403]\n",
      "  [0.91294217]\n",
      "  [0.91548496]]]\n",
      "ejemplar: [0.89388192 0.8971436  0.90021557 0.90365851 0.90635198 0.90957403\n",
      " 0.91294217 0.91548496]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9176808]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.89388192 0.8971436  0.90021557 0.90365851 0.90635198 0.90957403\n",
      "  0.91294217 0.91548496]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017819220200181007\n",
      "Predicción post entrenamiento : [[0.91741824]]\n",
      "PERDIDAAAA despues: 0.01774919219315052\n",
      "loss en el callback: 0.001736982143484056, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.8971436 ]\n",
      "  [0.90021557]\n",
      "  [0.90365851]\n",
      "  [0.90635198]\n",
      "  [0.90957403]\n",
      "  [0.91294217]\n",
      "  [0.91548496]\n",
      "  [0.9176808 ]]]\n",
      "ejemplar: [0.8971436  0.90021557 0.90365851 0.90635198 0.90957403 0.91294217\n",
      " 0.91548496 0.9176808 ]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9202941]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.8971436  0.90021557 0.90365851 0.90635198 0.90957403 0.91294217\n",
      "  0.91548496 0.9176808 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036662777420133352\n",
      "Predicción post entrenamiento : [[0.9209702]]\n",
      "PERDIDAAAA despues: 0.003748609684407711\n",
      "loss en el callback: 0.013906077481806278, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.90021557]\n",
      "  [0.90365851]\n",
      "  [0.90635198]\n",
      "  [0.90957403]\n",
      "  [0.91294217]\n",
      "  [0.91548496]\n",
      "  [0.9176808 ]\n",
      "  [0.92029411]]]\n",
      "ejemplar: [0.90021557 0.90365851 0.90635198 0.90957403 0.91294217 0.91548496\n",
      " 0.9176808  0.92029411]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9237865]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.90021557 0.90365851 0.90635198 0.90957403 0.91294217 0.91548496\n",
      "  0.9176808  0.92029411]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004825590644031763\n",
      "Predicción post entrenamiento : [[0.9218735]]\n",
      "PERDIDAAAA despues: 0.004563469905406237\n",
      "loss en el callback: 0.059209663420915604, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.90365851]\n",
      "  [0.90635198]\n",
      "  [0.90957403]\n",
      "  [0.91294217]\n",
      "  [0.91548496]\n",
      "  [0.9176808 ]\n",
      "  [0.92029411]\n",
      "  [0.92378652]]]\n",
      "ejemplar: [0.90365851 0.90635198 0.90957403 0.91294217 0.91548496 0.9176808\n",
      " 0.92029411 0.92378652]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9246636]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.90365851 0.90635198 0.90957403 0.91294217 0.91548496 0.9176808\n",
      "  0.92029411 0.92378652]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007705098018050194\n",
      "Predicción post entrenamiento : [[0.92447066]]\n",
      "PERDIDAAAA despues: 0.0076712630689144135\n",
      "loss en el callback: 0.000977632007561624, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.90635198]\n",
      "  [0.90957403]\n",
      "  [0.91294217]\n",
      "  [0.91548496]\n",
      "  [0.9176808 ]\n",
      "  [0.92029411]\n",
      "  [0.92378652]\n",
      "  [0.9246636 ]]]\n",
      "ejemplar: [0.90635198 0.90957403 0.91294217 0.91548496 0.9176808  0.92029411\n",
      " 0.92378652 0.9246636 ]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9270988]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.90635198 0.90957403 0.91294217 0.91548496 0.9176808  0.92029411\n",
      "  0.92378652 0.9246636 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0094454949721694\n",
      "Predicción post entrenamiento : [[0.9263213]]\n",
      "PERDIDAAAA despues: 0.00929497554898262\n",
      "loss en el callback: 0.012956827878952026, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.90957403]\n",
      "  [0.91294217]\n",
      "  [0.91548496]\n",
      "  [0.9176808 ]\n",
      "  [0.92029411]\n",
      "  [0.92378652]\n",
      "  [0.9246636 ]\n",
      "  [0.92709881]]]\n",
      "ejemplar: [0.90957403 0.91294217 0.91548496 0.9176808  0.92029411 0.92378652\n",
      " 0.9246636  0.92709881]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9289671]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.90957403 0.91294217 0.91548496 0.9176808  0.92029411 0.92378652\n",
      "  0.9246636  0.92709881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017400687793269753\n",
      "Predicción post entrenamiento : [[0.92806613]]\n",
      "PERDIDAAAA despues: 0.001665713032707572\n",
      "loss en el callback: 0.015584331005811691, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.91294217]\n",
      "  [0.91548496]\n",
      "  [0.9176808 ]\n",
      "  [0.92029411]\n",
      "  [0.92378652]\n",
      "  [0.9246636 ]\n",
      "  [0.92709881]\n",
      "  [0.92896712]]]\n",
      "ejemplar: [0.91294217 0.91548496 0.9176808  0.92029411 0.92378652 0.9246636\n",
      " 0.92709881 0.92896712]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9305456]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.91294217 0.91548496 0.9176808  0.92029411 0.92378652 0.9246636\n",
      "  0.92709881 0.92896712]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005012826528400183\n",
      "Predicción post entrenamiento : [[0.9287073]]\n",
      "PERDIDAAAA despues: 0.004755894187837839\n",
      "loss en el callback: 0.060409970581531525, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.91548496]\n",
      "  [0.9176808 ]\n",
      "  [0.92029411]\n",
      "  [0.92378652]\n",
      "  [0.9246636 ]\n",
      "  [0.92709881]\n",
      "  [0.92896712]\n",
      "  [0.93054563]]]\n",
      "ejemplar: [0.91548496 0.9176808  0.92029411 0.92378652 0.9246636  0.92709881\n",
      " 0.92896712 0.93054563]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9309223]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.91548496 0.9176808  0.92029411 0.92378652 0.9246636  0.92709881\n",
      "  0.92896712 0.93054563]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008340307511389256\n",
      "Predicción post entrenamiento : [[0.9294128]]\n",
      "PERDIDAAAA despues: 0.008066866546869278\n",
      "loss en el callback: 0.04536133259534836, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.9176808 ]\n",
      "  [0.92029411]\n",
      "  [0.92378652]\n",
      "  [0.9246636 ]\n",
      "  [0.92709881]\n",
      "  [0.92896712]\n",
      "  [0.93054563]\n",
      "  [0.93092233]]]\n",
      "ejemplar: [0.9176808  0.92029411 0.92378652 0.9246636  0.92709881 0.92896712\n",
      " 0.93054563 0.93092233]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9315423]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.9176808  0.92029411 0.92378652 0.9246636  0.92709881 0.92896712\n",
      "  0.93054563 0.93092233]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02182638831436634\n",
      "Predicción post entrenamiento : [[0.93028426]]\n",
      "PERDIDAAAA despues: 0.02145625837147236\n",
      "loss en el callback: 0.03332679346203804, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.92029411]\n",
      "  [0.92378652]\n",
      "  [0.9246636 ]\n",
      "  [0.92709881]\n",
      "  [0.92896712]\n",
      "  [0.93054563]\n",
      "  [0.93092233]\n",
      "  [0.93154228]]]\n",
      "ejemplar: [0.92029411 0.92378652 0.9246636  0.92709881 0.92896712 0.93054563\n",
      " 0.93092233 0.93154228]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.93238103]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.92029411 0.92378652 0.9246636  0.92709881 0.92896712 0.93054563\n",
      "  0.93092233 0.93154228]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013017335906624794\n",
      "Predicción post entrenamiento : [[0.932724]]\n",
      "PERDIDAAAA despues: 0.013095714151859283\n",
      "loss en el callback: 0.003686842042952776, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.92378652]\n",
      "  [0.9246636 ]\n",
      "  [0.92709881]\n",
      "  [0.92896712]\n",
      "  [0.93054563]\n",
      "  [0.93092233]\n",
      "  [0.93154228]\n",
      "  [0.93238103]]]\n",
      "ejemplar: [0.92378652 0.9246636  0.92709881 0.92896712 0.93054563 0.93092233\n",
      " 0.93154228 0.93238103]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.93461037]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.92378652 0.9246636  0.92709881 0.92896712 0.93054563 0.93092233\n",
      "  0.93154228 0.93238103]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0205762330442667\n",
      "Predicción post entrenamiento : [[0.93308395]]\n",
      "PERDIDAAAA despues: 0.020140651613473892\n",
      "loss en el callback: 0.05023443326354027, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.9246636 ]\n",
      "  [0.92709881]\n",
      "  [0.92896712]\n",
      "  [0.93054563]\n",
      "  [0.93092233]\n",
      "  [0.93154228]\n",
      "  [0.93238103]\n",
      "  [0.93461037]]]\n",
      "ejemplar: [0.9246636  0.92709881 0.92896712 0.93054563 0.93092233 0.93154228\n",
      " 0.93238103 0.93461037]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.93442315]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.9246636  0.92709881 0.92896712 0.93054563 0.93092233 0.93154228\n",
      "  0.93238103 0.93461037]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030229106545448303\n",
      "Predicción post entrenamiento : [[0.93381953]]\n",
      "PERDIDAAAA despues: 0.030019575729966164\n",
      "loss en el callback: 0.00993198063224554, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.92709881]\n",
      "  [0.92896712]\n",
      "  [0.93054563]\n",
      "  [0.93092233]\n",
      "  [0.93154228]\n",
      "  [0.93238103]\n",
      "  [0.93461037]\n",
      "  [0.93442315]]]\n",
      "ejemplar: [0.92709881 0.92896712 0.93054563 0.93092233 0.93154228 0.93238103\n",
      " 0.93461037 0.93442315]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.93529314]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.92709881 0.92896712 0.93054563 0.93092233 0.93154228 0.93238103\n",
      "  0.93461037 0.93442315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02066103368997574\n",
      "Predicción post entrenamiento : [[0.9348923]]\n",
      "PERDIDAAAA despues: 0.02054595947265625\n",
      "loss en el callback: 0.0048891655169427395, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.92896712]\n",
      "  [0.93054563]\n",
      "  [0.93092233]\n",
      "  [0.93154228]\n",
      "  [0.93238103]\n",
      "  [0.93461037]\n",
      "  [0.93442315]\n",
      "  [0.93529314]]]\n",
      "ejemplar: [0.92896712 0.93054563 0.93092233 0.93154228 0.93238103 0.93461037\n",
      " 0.93442315 0.93529314]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9360219]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.92896712 0.93054563 0.93092233 0.93154228 0.93238103 0.93461037\n",
      "  0.93442315 0.93529314]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027998540550470352\n",
      "Predicción post entrenamiento : [[0.93501014]]\n",
      "PERDIDAAAA despues: 0.02766096405684948\n",
      "loss en el callback: 0.027064329013228416, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.93054563]\n",
      "  [0.93092233]\n",
      "  [0.93154228]\n",
      "  [0.93238103]\n",
      "  [0.93461037]\n",
      "  [0.93442315]\n",
      "  [0.93529314]\n",
      "  [0.93602192]]]\n",
      "ejemplar: [0.93054563 0.93092233 0.93154228 0.93238103 0.93461037 0.93442315\n",
      " 0.93529314 0.93602192]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9358949]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.93054563 0.93092233 0.93154228 0.93238103 0.93461037 0.93442315\n",
      "  0.93529314 0.93602192]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027956049889326096\n",
      "Predicción post entrenamiento : [[0.9352862]]\n",
      "PERDIDAAAA despues: 0.027752874419093132\n",
      "loss en el callback: 0.01075164694339037, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.93092233]\n",
      "  [0.93154228]\n",
      "  [0.93238103]\n",
      "  [0.93461037]\n",
      "  [0.93442315]\n",
      "  [0.93529314]\n",
      "  [0.93602192]\n",
      "  [0.93589491]]]\n",
      "ejemplar: [0.93092233 0.93154228 0.93238103 0.93461037 0.93442315 0.93529314\n",
      " 0.93602192 0.93589491]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9359632]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.93092233 0.93154228 0.93238103 0.93461037 0.93442315 0.93529314\n",
      "  0.93602192 0.93589491]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018782172352075577\n",
      "Predicción post entrenamiento : [[0.9355374]]\n",
      "PERDIDAAAA despues: 0.01866563968360424\n",
      "loss en el callback: 0.0049658408388495445, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.93154228]\n",
      "  [0.93238103]\n",
      "  [0.93461037]\n",
      "  [0.93442315]\n",
      "  [0.93529314]\n",
      "  [0.93602192]\n",
      "  [0.93589491]\n",
      "  [0.93596321]]]\n",
      "ejemplar: [0.93154228 0.93238103 0.93461037 0.93442315 0.93529314 0.93602192\n",
      " 0.93589491 0.93596321]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.936326]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.93154228 0.93238103 0.93461037 0.93442315 0.93529314 0.93602192\n",
      "  0.93589491 0.93596321]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02141016535460949\n",
      "Predicción post entrenamiento : [[0.9362756]]\n",
      "PERDIDAAAA despues: 0.02139541134238243\n",
      "loss en el callback: 8.387797424802557e-05, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.93238103]\n",
      "  [0.93461037]\n",
      "  [0.93442315]\n",
      "  [0.93529314]\n",
      "  [0.93602192]\n",
      "  [0.93589491]\n",
      "  [0.93596321]\n",
      "  [0.93632603]]]\n",
      "ejemplar: [0.93238103 0.93461037 0.93442315 0.93529314 0.93602192 0.93589491\n",
      " 0.93596321 0.93632603]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.93710005]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.93238103 0.93461037 0.93442315 0.93529314 0.93602192 0.93589491\n",
      "  0.93596321 0.93632603]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03130408003926277\n",
      "Predicción post entrenamiento : [[0.93555045]]\n",
      "PERDIDAAAA despues: 0.030758140608668327\n",
      "loss en el callback: 0.058649878948926926, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.93461037]\n",
      "  [0.93442315]\n",
      "  [0.93529314]\n",
      "  [0.93602192]\n",
      "  [0.93589491]\n",
      "  [0.93596321]\n",
      "  [0.93632603]\n",
      "  [0.93710005]]]\n",
      "ejemplar: [0.93461037 0.93442315 0.93529314 0.93602192 0.93589491 0.93596321\n",
      " 0.93632603 0.93710005]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9363271]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.93461037 0.93442315 0.93529314 0.93602192 0.93589491 0.93596321\n",
      "  0.93632603 0.93710005]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06296778470277786\n",
      "Predicción post entrenamiento : [[0.9343875]]\n",
      "PERDIDAAAA despues: 0.06199812889099121\n",
      "loss en el callback: 0.08632116764783859, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.93442315]\n",
      "  [0.93529314]\n",
      "  [0.93602192]\n",
      "  [0.93589491]\n",
      "  [0.93596321]\n",
      "  [0.93632603]\n",
      "  [0.93710005]\n",
      "  [0.9363271 ]]]\n",
      "ejemplar: [0.93442315 0.93529314 0.93602192 0.93589491 0.93596321 0.93632603\n",
      " 0.93710005 0.9363271 ]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.934664]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.93442315 0.93529314 0.93602192 0.93589491 0.93596321 0.93632603\n",
      "  0.93710005 0.9363271 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10855195671319962\n",
      "Predicción post entrenamiento : [[0.9331401]]\n",
      "PERDIDAAAA despues: 0.10755010694265366\n",
      "loss en el callback: 0.07084739953279495, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.93529314]\n",
      "  [0.93602192]\n",
      "  [0.93589491]\n",
      "  [0.93596321]\n",
      "  [0.93632603]\n",
      "  [0.93710005]\n",
      "  [0.9363271 ]\n",
      "  [0.93466401]]]\n",
      "ejemplar: [0.93529314 0.93602192 0.93589491 0.93596321 0.93632603 0.93710005\n",
      " 0.9363271  0.93466401]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.93354607]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.93529314 0.93602192 0.93589491 0.93596321 0.93632603 0.93710005\n",
      "  0.9363271  0.93466401]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0721929669380188\n",
      "Predicción post entrenamiento : [[0.931705]]\n",
      "PERDIDAAAA despues: 0.07120700925588608\n",
      "loss en el callback: 0.08484964817762375, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.93602192]\n",
      "  [0.93589491]\n",
      "  [0.93596321]\n",
      "  [0.93632603]\n",
      "  [0.93710005]\n",
      "  [0.9363271 ]\n",
      "  [0.93466401]\n",
      "  [0.93354607]]]\n",
      "ejemplar: [0.93602192 0.93589491 0.93596321 0.93632603 0.93710005 0.9363271\n",
      " 0.93466401 0.93354607]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9319063]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.93602192 0.93589491 0.93596321 0.93632603 0.93710005 0.9363271\n",
      "  0.93466401 0.93354607]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05019441619515419\n",
      "Predicción post entrenamiento : [[0.9308072]]\n",
      "PERDIDAAAA despues: 0.04970313236117363\n",
      "loss en el callback: 0.0349503792822361, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.93589491]\n",
      "  [0.93596321]\n",
      "  [0.93632603]\n",
      "  [0.93710005]\n",
      "  [0.9363271 ]\n",
      "  [0.93466401]\n",
      "  [0.93354607]\n",
      "  [0.93190628]]]\n",
      "ejemplar: [0.93589491 0.93596321 0.93632603 0.93710005 0.9363271  0.93466401\n",
      " 0.93354607 0.93190628]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.93077314]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.93589491 0.93596321 0.93632603 0.93710005 0.9363271  0.93466401\n",
      "  0.93354607 0.93190628]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07071055471897125\n",
      "Predicción post entrenamiento : [[0.9296012]]\n",
      "PERDIDAAAA despues: 0.07008865475654602\n",
      "loss en el callback: 0.044128432869911194, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.93596321]\n",
      "  [0.93632603]\n",
      "  [0.93710005]\n",
      "  [0.9363271 ]\n",
      "  [0.93466401]\n",
      "  [0.93354607]\n",
      "  [0.93190628]\n",
      "  [0.93077314]]]\n",
      "ejemplar: [0.93596321 0.93632603 0.93710005 0.9363271  0.93466401 0.93354607\n",
      " 0.93190628 0.93077314]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9295105]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.93596321 0.93632603 0.93710005 0.9363271  0.93466401 0.93354607\n",
      "  0.93190628 0.93077314]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047593045979738235\n",
      "Predicción post entrenamiento : [[0.9272553]]\n",
      "PERDIDAAAA despues: 0.0466141514480114\n",
      "loss en el callback: 0.12212517112493515, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.93632603]\n",
      "  [0.93710005]\n",
      "  [0.9363271 ]\n",
      "  [0.93466401]\n",
      "  [0.93354607]\n",
      "  [0.93190628]\n",
      "  [0.93077314]\n",
      "  [0.92951047]]]\n",
      "ejemplar: [0.93632603 0.93710005 0.9363271  0.93466401 0.93354607 0.93190628\n",
      " 0.93077314 0.92951047]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.92699474]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.93632603 0.93710005 0.9363271  0.93466401 0.93354607 0.93190628\n",
      "  0.93077314 0.92951047]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06236899644136429\n",
      "Predicción post entrenamiento : [[0.9253579]]\n",
      "PERDIDAAAA despues: 0.06155410408973694\n",
      "loss en el callback: 0.07226473093032837, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.93710005]\n",
      "  [0.9363271 ]\n",
      "  [0.93466401]\n",
      "  [0.93354607]\n",
      "  [0.93190628]\n",
      "  [0.93077314]\n",
      "  [0.92951047]\n",
      "  [0.92699474]]]\n",
      "ejemplar: [0.93710005 0.9363271  0.93466401 0.93354607 0.93190628 0.93077314\n",
      " 0.92951047 0.92699474]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9247633]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.93710005 0.9363271  0.93466401 0.93354607 0.93190628 0.93077314\n",
      "  0.92951047 0.92699474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026456842198967934\n",
      "Predicción post entrenamiento : [[0.92293346]]\n",
      "PERDIDAAAA despues: 0.025864915922284126\n",
      "loss en el callback: 0.08015500009059906, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.9363271 ]\n",
      "  [0.93466401]\n",
      "  [0.93354607]\n",
      "  [0.93190628]\n",
      "  [0.93077314]\n",
      "  [0.92951047]\n",
      "  [0.92699474]\n",
      "  [0.92476332]]]\n",
      "ejemplar: [0.9363271  0.93466401 0.93354607 0.93190628 0.93077314 0.92951047\n",
      " 0.92699474 0.92476332]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.92178744]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.9363271  0.93466401 0.93354607 0.93190628 0.93077314 0.92951047\n",
      "  0.92699474 0.92476332]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01316432747989893\n",
      "Predicción post entrenamiento : [[0.92096823]]\n",
      "PERDIDAAAA despues: 0.012977013364434242\n",
      "loss en el callback: 0.02109820954501629, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.93466401]\n",
      "  [0.93354607]\n",
      "  [0.93190628]\n",
      "  [0.93077314]\n",
      "  [0.92951047]\n",
      "  [0.92699474]\n",
      "  [0.92476332]\n",
      "  [0.92178744]]]\n",
      "ejemplar: [0.93466401 0.93354607 0.93190628 0.93077314 0.92951047 0.92699474\n",
      " 0.92476332 0.92178744]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9196183]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.93466401 0.93354607 0.93190628 0.93077314 0.92951047 0.92699474\n",
      "  0.92476332 0.92178744]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010905703529715538\n",
      "Predicción post entrenamiento : [[0.9193104]]\n",
      "PERDIDAAAA despues: 0.010841486975550652\n",
      "loss en el callback: 0.0030584721826016903, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.93354607]\n",
      "  [0.93190628]\n",
      "  [0.93077314]\n",
      "  [0.92951047]\n",
      "  [0.92699474]\n",
      "  [0.92476332]\n",
      "  [0.92178744]\n",
      "  [0.91961831]]]\n",
      "ejemplar: [0.93354607 0.93190628 0.93077314 0.92951047 0.92699474 0.92476332\n",
      " 0.92178744 0.91961831]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.91796273]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.93354607 0.93190628 0.93077314 0.92951047 0.92699474 0.92476332\n",
      "  0.92178744 0.91961831]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013747163757216185\n",
      "Predicción post entrenamiento : [[0.9172897]]\n",
      "PERDIDAAAA despues: 0.00012214170419611037\n",
      "loss en el callback: 0.011841329745948315, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.93190628]\n",
      "  [0.93077314]\n",
      "  [0.92951047]\n",
      "  [0.92699474]\n",
      "  [0.92476332]\n",
      "  [0.92178744]\n",
      "  [0.91961831]\n",
      "  [0.91796273]]]\n",
      "ejemplar: [0.93190628 0.93077314 0.92951047 0.92699474 0.92476332 0.92178744\n",
      " 0.91961831 0.91796273]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.91575354]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.93190628 0.93077314 0.92951047 0.92699474 0.92476332 0.92178744\n",
      "  0.91961831 0.91796273]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001931777223944664\n",
      "Predicción post entrenamiento : [[0.915857]]\n",
      "PERDIDAAAA despues: 0.00192269217222929\n",
      "loss en el callback: 0.0003349335165694356, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.93077314]\n",
      "  [0.92951047]\n",
      "  [0.92699474]\n",
      "  [0.92476332]\n",
      "  [0.92178744]\n",
      "  [0.91961831]\n",
      "  [0.91796273]\n",
      "  [0.91575354]]]\n",
      "ejemplar: [0.93077314 0.92951047 0.92699474 0.92476332 0.92178744 0.91961831\n",
      " 0.91796273 0.91575354]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.91423607]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.93077314 0.92951047 0.92699474 0.92476332 0.92178744 0.91961831\n",
      "  0.91796273 0.91575354]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025118945632129908\n",
      "Predicción post entrenamiento : [[0.91504043]]\n",
      "PERDIDAAAA despues: 0.0024319139774888754\n",
      "loss en el callback: 0.025931579992175102, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.92951047]\n",
      "  [0.92699474]\n",
      "  [0.92476332]\n",
      "  [0.92178744]\n",
      "  [0.91961831]\n",
      "  [0.91796273]\n",
      "  [0.91575354]\n",
      "  [0.91423607]]]\n",
      "ejemplar: [0.92951047 0.92699474 0.92476332 0.92178744 0.91961831 0.91796273\n",
      " 0.91575354 0.91423607]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.91315645]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.92951047 0.92699474 0.92476332 0.92178744 0.91961831 0.91796273\n",
      "  0.91575354 0.91423607]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000631443690508604\n",
      "Predicción post entrenamiento : [[0.91305256]]\n",
      "PERDIDAAAA despues: 0.000626233231741935\n",
      "loss en el callback: 0.0003864615282509476, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.92699474]\n",
      "  [0.92476332]\n",
      "  [0.92178744]\n",
      "  [0.91961831]\n",
      "  [0.91796273]\n",
      "  [0.91575354]\n",
      "  [0.91423607]\n",
      "  [0.91315645]]]\n",
      "ejemplar: [0.92699474 0.92476332 0.92178744 0.91961831 0.91796273 0.91575354\n",
      " 0.91423607 0.91315645]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9109122]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.92699474 0.92476332 0.92178744 0.91961831 0.91796273 0.91575354\n",
      "  0.91423607 0.91315645]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003325140569359064\n",
      "Predicción post entrenamiento : [[0.9107703]]\n",
      "PERDIDAAAA despues: 0.00032735842978581786\n",
      "loss en el callback: 0.0006888312054798007, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.92476332]\n",
      "  [0.92178744]\n",
      "  [0.91961831]\n",
      "  [0.91796273]\n",
      "  [0.91575354]\n",
      "  [0.91423607]\n",
      "  [0.91315645]\n",
      "  [0.91091222]]]\n",
      "ejemplar: [0.92476332 0.92178744 0.91961831 0.91796273 0.91575354 0.91423607\n",
      " 0.91315645 0.91091222]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.90873]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.92476332 0.92178744 0.91961831 0.91796273 0.91575354 0.91423607\n",
      "  0.91315645 0.91091222]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011214325204491615\n",
      "Predicción post entrenamiento : [[0.9082258]]\n",
      "PERDIDAAAA despues: 0.001087917946279049\n",
      "loss en el callback: 0.008183799684047699, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.92178744]\n",
      "  [0.91961831]\n",
      "  [0.91796273]\n",
      "  [0.91575354]\n",
      "  [0.91423607]\n",
      "  [0.91315645]\n",
      "  [0.91091222]\n",
      "  [0.90872997]]]\n",
      "ejemplar: [0.92178744 0.91961831 0.91796273 0.91575354 0.91423607 0.91315645\n",
      " 0.91091222 0.90872997]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9062351]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.92178744 0.91961831 0.91796273 0.91575354 0.91423607 0.91315645\n",
      "  0.91091222 0.90872997]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030693926382809877\n",
      "Predicción post entrenamiento : [[0.9056221]]\n",
      "PERDIDAAAA despues: 0.0030018482357263565\n",
      "loss en el callback: 0.011454522609710693, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.91961831]\n",
      "  [0.91796273]\n",
      "  [0.91575354]\n",
      "  [0.91423607]\n",
      "  [0.91315645]\n",
      "  [0.91091222]\n",
      "  [0.90872997]\n",
      "  [0.9062351 ]]]\n",
      "ejemplar: [0.91961831 0.91796273 0.91575354 0.91423607 0.91315645 0.91091222\n",
      " 0.90872997 0.9062351 ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9039215]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.91961831 0.91796273 0.91575354 0.91423607 0.91315645 0.91091222\n",
      "  0.90872997 0.9062351 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030278272461146116\n",
      "Predicción post entrenamiento : [[0.90351844]]\n",
      "PERDIDAAAA despues: 0.0029836338944733143\n",
      "loss en el callback: 0.005146426614373922, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.91796273]\n",
      "  [0.91575354]\n",
      "  [0.91423607]\n",
      "  [0.91315645]\n",
      "  [0.91091222]\n",
      "  [0.90872997]\n",
      "  [0.9062351 ]\n",
      "  [0.90392148]]]\n",
      "ejemplar: [0.91796273 0.91575354 0.91423607 0.91315645 0.91091222 0.90872997\n",
      " 0.9062351  0.90392148]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9019059]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.91796273 0.91575354 0.91423607 0.91315645 0.91091222 0.90872997\n",
      "  0.9062351  0.90392148]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036616739816963673\n",
      "Predicción post entrenamiento : [[0.90206003]]\n",
      "PERDIDAAAA despues: 0.0036430435720831156\n",
      "loss en el callback: 0.0007908272091299295, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.91575354]\n",
      "  [0.91423607]\n",
      "  [0.91315645]\n",
      "  [0.91091222]\n",
      "  [0.90872997]\n",
      "  [0.9062351 ]\n",
      "  [0.90392148]\n",
      "  [0.90190589]]]\n",
      "ejemplar: [0.91575354 0.91423607 0.91315645 0.91091222 0.90872997 0.9062351\n",
      " 0.90392148 0.90190589]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9003823]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.91575354 0.91423607 0.91315645 0.91091222 0.90872997 0.9062351\n",
      "  0.90392148 0.90190589]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004550803452730179\n",
      "Predicción post entrenamiento : [[0.9006608]]\n",
      "PERDIDAAAA despues: 0.00451330142095685\n",
      "loss en el callback: 0.00273001566529274, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.91423607]\n",
      "  [0.91315645]\n",
      "  [0.91091222]\n",
      "  [0.90872997]\n",
      "  [0.9062351 ]\n",
      "  [0.90392148]\n",
      "  [0.90190589]\n",
      "  [0.90038228]]]\n",
      "ejemplar: [0.91423607 0.91315645 0.91091222 0.90872997 0.9062351  0.90392148\n",
      " 0.90190589 0.90038228]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.89906174]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.91423607 0.91315645 0.91091222 0.90872997 0.9062351  0.90392148\n",
      "  0.90190589 0.90038228]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017354671144858003\n",
      "Predicción post entrenamiento : [[0.8994424]]\n",
      "PERDIDAAAA despues: 0.001703898306004703\n",
      "loss en el callback: 0.005491695832461119, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.91315645]\n",
      "  [0.91091222]\n",
      "  [0.90872997]\n",
      "  [0.9062351 ]\n",
      "  [0.90392148]\n",
      "  [0.90190589]\n",
      "  [0.90038228]\n",
      "  [0.89906174]]]\n",
      "ejemplar: [0.91315645 0.91091222 0.90872997 0.9062351  0.90392148 0.90190589\n",
      " 0.90038228 0.89906174]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.89772135]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.91315645 0.91091222 0.90872997 0.9062351  0.90392148 0.90190589\n",
      "  0.90038228 0.89906174]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005590539891272783\n",
      "Predicción post entrenamiento : [[0.898303]]\n",
      "PERDIDAAAA despues: 0.005503902677446604\n",
      "loss en el callback: 0.014003385789692402, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.91091222]\n",
      "  [0.90872997]\n",
      "  [0.9062351 ]\n",
      "  [0.90392148]\n",
      "  [0.90190589]\n",
      "  [0.90038228]\n",
      "  [0.89906174]\n",
      "  [0.89772135]]]\n",
      "ejemplar: [0.91091222 0.90872997 0.9062351  0.90392148 0.90190589 0.90038228\n",
      " 0.89906174 0.89772135]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8963151]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.91091222 0.90872997 0.9062351  0.90392148 0.90190589 0.90038228\n",
      "  0.89906174 0.89772135]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01011741068214178\n",
      "Predicción post entrenamiento : [[0.89580643]]\n",
      "PERDIDAAAA despues: 0.0102199986577034\n",
      "loss en el callback: 0.007447137031704187, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.90872997]\n",
      "  [0.9062351 ]\n",
      "  [0.90392148]\n",
      "  [0.90190589]\n",
      "  [0.90038228]\n",
      "  [0.89906174]\n",
      "  [0.89772135]\n",
      "  [0.8963151 ]]]\n",
      "ejemplar: [0.90872997 0.9062351  0.90392148 0.90190589 0.90038228 0.89906174\n",
      " 0.89772135 0.8963151 ]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.89388156]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.90872997 0.9062351  0.90392148 0.90190589 0.90038228 0.89906174\n",
      "  0.89772135 0.8963151 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032833071891218424\n",
      "Predicción post entrenamiento : [[0.8943515]]\n",
      "PERDIDAAAA despues: 0.0032296746503561735\n",
      "loss en el callback: 0.009896170347929, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.9062351 ]\n",
      "  [0.90392148]\n",
      "  [0.90190589]\n",
      "  [0.90038228]\n",
      "  [0.89906174]\n",
      "  [0.89772135]\n",
      "  [0.8963151 ]\n",
      "  [0.89388156]]]\n",
      "ejemplar: [0.9062351  0.90392148 0.90190589 0.90038228 0.89906174 0.89772135\n",
      " 0.8963151  0.89388156]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.89249986]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.9062351  0.90392148 0.90190589 0.90038228 0.89906174 0.89772135\n",
      "  0.8963151  0.89388156]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0738363016571384e-05\n",
      "Predicción post entrenamiento : [[0.89166915]]\n",
      "PERDIDAAAA despues: 1.6872822016011924e-05\n",
      "loss en el callback: 0.020286578685045242, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.90392148]\n",
      "  [0.90190589]\n",
      "  [0.90038228]\n",
      "  [0.89906174]\n",
      "  [0.89772135]\n",
      "  [0.8963151 ]\n",
      "  [0.89388156]\n",
      "  [0.89249986]]]\n",
      "ejemplar: [0.90392148 0.90190589 0.90038228 0.89906174 0.89772135 0.8963151\n",
      " 0.89388156 0.89249986]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.8900143]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.90392148 0.90190589 0.90038228 0.89906174 0.89772135 0.8963151\n",
      "  0.89388156 0.89249986]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.34962522983551e-05\n",
      "Predicción post entrenamiento : [[0.8889799]]\n",
      "PERDIDAAAA despues: 5.68307405046653e-05\n",
      "loss en el callback: 0.033161841332912445, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.90190589]\n",
      "  [0.90038228]\n",
      "  [0.89906174]\n",
      "  [0.89772135]\n",
      "  [0.8963151 ]\n",
      "  [0.89388156]\n",
      "  [0.89249986]\n",
      "  [0.89001429]]]\n",
      "ejemplar: [0.90190589 0.90038228 0.89906174 0.89772135 0.8963151  0.89388156\n",
      " 0.89249986 0.89001429]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.88750166]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.90190589 0.90038228 0.89906174 0.89772135 0.8963151  0.89388156\n",
      "  0.89249986 0.89001429]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008752583526074886\n",
      "Predicción post entrenamiento : [[0.8875449]]\n",
      "PERDIDAAAA despues: 0.000872703327331692\n",
      "loss en el callback: 7.756330887787044e-05, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.90038228]\n",
      "  [0.89906174]\n",
      "  [0.89772135]\n",
      "  [0.8963151 ]\n",
      "  [0.89388156]\n",
      "  [0.89249986]\n",
      "  [0.89001429]\n",
      "  [0.88750166]]]\n",
      "ejemplar: [0.90038228 0.89906174 0.89772135 0.8963151  0.89388156 0.89249986\n",
      " 0.89001429 0.88750166]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8861688]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.90038228 0.89906174 0.89772135 0.8963151  0.89388156 0.89249986\n",
      "  0.89001429 0.88750166]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001130961813032627\n",
      "Predicción post entrenamiento : [[0.88638586]]\n",
      "PERDIDAAAA despues: 0.0011164081515744328\n",
      "loss en el callback: 0.002144423546269536, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.89906174]\n",
      "  [0.89772135]\n",
      "  [0.8963151 ]\n",
      "  [0.89388156]\n",
      "  [0.89249986]\n",
      "  [0.89001429]\n",
      "  [0.88750166]\n",
      "  [0.88616878]]]\n",
      "ejemplar: [0.89906174 0.89772135 0.8963151  0.89388156 0.89249986 0.89001429\n",
      " 0.88750166 0.88616878]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8849641]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.89906174 0.89772135 0.8963151  0.89388156 0.89249986 0.89001429\n",
      "  0.88750166 0.88616878]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0058796219527721405\n",
      "Predicción post entrenamiento : [[0.88587457]]\n",
      "PERDIDAAAA despues: 0.0057408250868320465\n",
      "loss en el callback: 0.04364873841404915, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.89772135]\n",
      "  [0.8963151 ]\n",
      "  [0.89388156]\n",
      "  [0.89249986]\n",
      "  [0.89001429]\n",
      "  [0.88750166]\n",
      "  [0.88616878]\n",
      "  [0.88496411]]]\n",
      "ejemplar: [0.89772135 0.8963151  0.89388156 0.89249986 0.89001429 0.88750166\n",
      " 0.88616878 0.88496411]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8843279]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.89772135 0.8963151  0.89388156 0.89249986 0.89001429 0.88750166\n",
      "  0.88616878 0.88496411]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007039455696940422\n",
      "Predicción post entrenamiento : [[0.88492924]]\n",
      "PERDIDAAAA despues: 0.006938908714801073\n",
      "loss en el callback: 0.016025681048631668, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.8963151 ]\n",
      "  [0.89388156]\n",
      "  [0.89249986]\n",
      "  [0.89001429]\n",
      "  [0.88750166]\n",
      "  [0.88616878]\n",
      "  [0.88496411]\n",
      "  [0.88432789]]]\n",
      "ejemplar: [0.8963151  0.89388156 0.89249986 0.89001429 0.88750166 0.88616878\n",
      " 0.88496411 0.88432789]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8832467]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.8963151  0.89388156 0.89249986 0.89001429 0.88750166 0.88616878\n",
      "  0.88496411 0.88432789]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0055534690618515015\n",
      "Predicción post entrenamiento : [[0.8837237]]\n",
      "PERDIDAAAA despues: 0.005482609383761883\n",
      "loss en el callback: 0.010280814953148365, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22691922]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03269336372613907\n",
      "Predicción post entrenamiento : [[0.1798524]]\n",
      "PERDIDAAAA despues: 0.017888056114315987\n",
      "loss en el callback: 0.038268689066171646, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22691922]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.22691922]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16408932]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.22691922]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003583956276997924\n",
      "Predicción post entrenamiento : [[0.14510654]]\n",
      "PERDIDAAAA despues: 0.0016714499797672033\n",
      "loss en el callback: 0.006333114113658667, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22691922]\n",
      "  [0.16408932]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.22691922 0.16408932]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.14881437]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.22691922 0.16408932]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.9046032068436034e-05\n",
      "Predicción post entrenamiento : [[0.14985804]]\n",
      "PERDIDAAAA despues: 1.8885628378484398e-05\n",
      "loss en el callback: 4.91356840939261e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22691922]\n",
      "  [0.16408932]\n",
      "  [0.14881437]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22691922\n",
      " 0.16408932 0.14881437]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1605855]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22691922\n",
      "  0.16408932 0.14881437]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.3347354726865888e-05\n",
      "Predicción post entrenamiento : [[0.15930143]]\n",
      "PERDIDAAAA despues: 1.2587220226123463e-05\n",
      "loss en el callback: 0.0001224769075633958, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22691922]\n",
      "  [0.16408932]\n",
      "  [0.14881437]\n",
      "  [0.16058549]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.22691922 0.16408932\n",
      " 0.14881437 0.16058549]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17060608]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.22691922 0.16408932\n",
      "  0.14881437 0.16058549]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00203160522505641\n",
      "Predicción post entrenamiento : [[0.16796748]]\n",
      "PERDIDAAAA despues: 0.0018007069593295455\n",
      "loss en el callback: 0.0010788100771605968, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22691922]\n",
      "  [0.16408932]\n",
      "  [0.14881437]\n",
      "  [0.16058549]\n",
      "  [0.17060608]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.22691922 0.16408932 0.14881437\n",
      " 0.16058549 0.17060608]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.17575061]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.22691922 0.16408932 0.14881437\n",
      "  0.16058549 0.17060608]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009042438468895853\n",
      "Predicción post entrenamiento : [[0.1752659]]\n",
      "PERDIDAAAA despues: 0.0008753270958550274\n",
      "loss en el callback: 6.0317597672110423e-05, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22691922]\n",
      "  [0.16408932]\n",
      "  [0.14881437]\n",
      "  [0.16058549]\n",
      "  [0.17060608]\n",
      "  [0.17575061]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.22691922 0.16408932 0.14881437 0.16058549\n",
      " 0.17060608 0.17575061]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.19315511]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.22691922 0.16408932 0.14881437 0.16058549\n",
      "  0.17060608 0.17575061]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002180913696065545\n",
      "Predicción post entrenamiento : [[0.18807903]]\n",
      "PERDIDAAAA despues: 0.0017325718654319644\n",
      "loss en el callback: 0.0050225816667079926, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.22691922]\n",
      "  [0.16408932]\n",
      "  [0.14881437]\n",
      "  [0.16058549]\n",
      "  [0.17060608]\n",
      "  [0.17575061]\n",
      "  [0.19315511]]]\n",
      "ejemplar: [0.04223169 0.22691922 0.16408932 0.14881437 0.16058549 0.17060608\n",
      " 0.17575061 0.19315511]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.20935947]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.22691922 0.16408932 0.14881437 0.16058549 0.17060608\n",
      "  0.17575061 0.19315511]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017719418974593282\n",
      "Predicción post entrenamiento : [[0.20839956]]\n",
      "PERDIDAAAA despues: 0.0001525602419860661\n",
      "loss en el callback: 0.00028793467208743095, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.22691922]\n",
      "  [0.16408932]\n",
      "  [0.14881437]\n",
      "  [0.16058549]\n",
      "  [0.17060608]\n",
      "  [0.17575061]\n",
      "  [0.19315511]\n",
      "  [0.20935947]]]\n",
      "ejemplar: [0.22691922 0.16408932 0.14881437 0.16058549 0.17060608 0.17575061\n",
      " 0.19315511 0.20935947]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2333567]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.22691922 0.16408932 0.14881437 0.16058549 0.17060608 0.17575061\n",
      "  0.19315511 0.20935947]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.985716365510598e-06\n",
      "Predicción post entrenamiento : [[0.23333898]]\n",
      "PERDIDAAAA despues: 7.885893865022808e-06\n",
      "loss en el callback: 1.1055924886704815e-07, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.16408932]\n",
      "  [0.14881437]\n",
      "  [0.16058549]\n",
      "  [0.17060608]\n",
      "  [0.17575061]\n",
      "  [0.19315511]\n",
      "  [0.20935947]\n",
      "  [0.2333567 ]]]\n",
      "ejemplar: [0.16408932 0.14881437 0.16058549 0.17060608 0.17575061 0.19315511\n",
      " 0.20935947 0.2333567 ]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.22273754]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.16408932 0.14881437 0.16058549 0.17060608 0.17575061 0.19315511\n",
      "  0.20935947 0.2333567 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020423831301741302\n",
      "Predicción post entrenamiento : [[0.22213216]]\n",
      "PERDIDAAAA despues: 0.000187301731784828\n",
      "loss en el callback: 0.00017282157205045223, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.14881437]\n",
      "  [0.16058549]\n",
      "  [0.17060608]\n",
      "  [0.17575061]\n",
      "  [0.19315511]\n",
      "  [0.20935947]\n",
      "  [0.2333567 ]\n",
      "  [0.22273754]]]\n",
      "ejemplar: [0.14881437 0.16058549 0.17060608 0.17575061 0.19315511 0.20935947\n",
      " 0.2333567  0.22273754]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.22446683]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.14881437 0.16058549 0.17060608 0.17575061 0.19315511 0.20935947\n",
      "  0.2333567  0.22273754]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001570878957863897\n",
      "Predicción post entrenamiento : [[0.2244166]]\n",
      "PERDIDAAAA despues: 0.0001558312651468441\n",
      "loss en el callback: 1.596016204530315e-06, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.16058549]\n",
      "  [0.17060608]\n",
      "  [0.17575061]\n",
      "  [0.19315511]\n",
      "  [0.20935947]\n",
      "  [0.2333567 ]\n",
      "  [0.22273754]\n",
      "  [0.22446683]]]\n",
      "ejemplar: [0.16058549 0.17060608 0.17575061 0.19315511 0.20935947 0.2333567\n",
      " 0.22273754 0.22446683]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.23173006]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.16058549 0.17060608 0.17575061 0.19315511 0.20935947 0.2333567\n",
      "  0.22273754 0.22446683]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005976096144877374\n",
      "Predicción post entrenamiento : [[0.23044448]]\n",
      "PERDIDAAAA despues: 0.0005364074604585767\n",
      "loss en el callback: 0.001042565912939608, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.17060608]\n",
      "  [0.17575061]\n",
      "  [0.19315511]\n",
      "  [0.20935947]\n",
      "  [0.2333567 ]\n",
      "  [0.22273754]\n",
      "  [0.22446683]\n",
      "  [0.23173006]]]\n",
      "ejemplar: [0.17060608 0.17575061 0.19315511 0.20935947 0.2333567  0.22273754\n",
      " 0.22446683 0.23173006]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.23760614]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.17060608 0.17575061 0.19315511 0.20935947 0.2333567  0.22273754\n",
      "  0.22446683 0.23173006]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001994306920096278\n",
      "Predicción post entrenamiento : [[0.23651737]]\n",
      "PERDIDAAAA despues: 0.0018982485635206103\n",
      "loss en el callback: 0.0009691567393019795, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.17575061]\n",
      "  [0.19315511]\n",
      "  [0.20935947]\n",
      "  [0.2333567 ]\n",
      "  [0.22273754]\n",
      "  [0.22446683]\n",
      "  [0.23173006]\n",
      "  [0.23760614]]]\n",
      "ejemplar: [0.17575061 0.19315511 0.20935947 0.2333567  0.22273754 0.22446683\n",
      " 0.23173006 0.23760614]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.24373665]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.17575061 0.19315511 0.20935947 0.2333567  0.22273754 0.22446683\n",
      "  0.23173006 0.23760614]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022008963860571384\n",
      "Predicción post entrenamiento : [[0.24173006]]\n",
      "PERDIDAAAA despues: 0.002016649581491947\n",
      "loss en el callback: 0.003132008481770754, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.19315511]\n",
      "  [0.20935947]\n",
      "  [0.2333567 ]\n",
      "  [0.22273754]\n",
      "  [0.22446683]\n",
      "  [0.23173006]\n",
      "  [0.23760614]\n",
      "  [0.24373665]]]\n",
      "ejemplar: [0.19315511 0.20935947 0.2333567  0.22273754 0.22446683 0.23173006\n",
      " 0.23760614 0.24373665]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.24993679]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.19315511 0.20935947 0.2333567  0.22273754 0.22446683 0.23173006\n",
      "  0.23760614 0.24373665]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001272972789593041\n",
      "Predicción post entrenamiento : [[0.24881385]]\n",
      "PERDIDAAAA despues: 0.001194103853777051\n",
      "loss en el callback: 0.0012598176253959537, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.20935947]\n",
      "  [0.2333567 ]\n",
      "  [0.22273754]\n",
      "  [0.22446683]\n",
      "  [0.23173006]\n",
      "  [0.23760614]\n",
      "  [0.24373665]\n",
      "  [0.24993679]]]\n",
      "ejemplar: [0.20935947 0.2333567  0.22273754 0.22446683 0.23173006 0.23760614\n",
      " 0.24373665 0.24993679]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.25523755]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.20935947 0.2333567  0.22273754 0.22446683 0.23173006 0.23760614\n",
      "  0.24373665 0.24993679]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0054630558006465435\n",
      "Predicción post entrenamiento : [[0.25424972]]\n",
      "PERDIDAAAA despues: 0.005318006034940481\n",
      "loss en el callback: 0.0014030438615009189, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.2333567 ]\n",
      "  [0.22273754]\n",
      "  [0.22446683]\n",
      "  [0.23173006]\n",
      "  [0.23760614]\n",
      "  [0.24373665]\n",
      "  [0.24993679]\n",
      "  [0.25523755]]]\n",
      "ejemplar: [0.2333567  0.22273754 0.22446683 0.23173006 0.23760614 0.24373665\n",
      " 0.24993679 0.25523755]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2586895]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.2333567  0.22273754 0.22446683 0.23173006 0.23760614 0.24373665\n",
      "  0.24993679 0.25523755]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00698286946862936\n",
      "Predicción post entrenamiento : [[0.2560139]]\n",
      "PERDIDAAAA despues: 0.006542864255607128\n",
      "loss en el callback: 0.00855889730155468, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.22273754]\n",
      "  [0.22446683]\n",
      "  [0.23173006]\n",
      "  [0.23760614]\n",
      "  [0.24373665]\n",
      "  [0.24993679]\n",
      "  [0.25523755]\n",
      "  [0.25868949]]]\n",
      "ejemplar: [0.22273754 0.22446683 0.23173006 0.23760614 0.24373665 0.24993679\n",
      " 0.25523755 0.25868949]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2563011]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.22273754 0.22446683 0.23173006 0.23760614 0.24373665 0.24993679\n",
      "  0.25523755 0.25868949]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011728121899068356\n",
      "Predicción post entrenamiento : [[0.25284487]]\n",
      "PERDIDAAAA despues: 0.010991471819579601\n",
      "loss en el callback: 0.014897916465997696, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.22446683]\n",
      "  [0.23173006]\n",
      "  [0.23760614]\n",
      "  [0.24373665]\n",
      "  [0.24993679]\n",
      "  [0.25523755]\n",
      "  [0.25868949]\n",
      "  [0.25630111]]]\n",
      "ejemplar: [0.22446683 0.23173006 0.23760614 0.24373665 0.24993679 0.25523755\n",
      " 0.25868949 0.25630111]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.25613675]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.22446683 0.23173006 0.23760614 0.24373665 0.24993679 0.25523755\n",
      "  0.25868949 0.25630111]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009464096277952194\n",
      "Predicción post entrenamiento : [[0.2543801]]\n",
      "PERDIDAAAA despues: 0.00912539754062891\n",
      "loss en el callback: 0.005823974963277578, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.23173006]\n",
      "  [0.23760614]\n",
      "  [0.24373665]\n",
      "  [0.24993679]\n",
      "  [0.25523755]\n",
      "  [0.25868949]\n",
      "  [0.25630111]\n",
      "  [0.25613675]]]\n",
      "ejemplar: [0.23173006 0.23760614 0.24373665 0.24993679 0.25523755 0.25868949\n",
      " 0.25630111 0.25613675]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.25836852]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.23173006 0.23760614 0.24373665 0.24993679 0.25523755 0.25868949\n",
      "  0.25630111 0.25613675]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004381771665066481\n",
      "Predicción post entrenamiento : [[0.25746927]]\n",
      "PERDIDAAAA despues: 0.004263528157025576\n",
      "loss en el callback: 0.0016123995883390307, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.23760614]\n",
      "  [0.24373665]\n",
      "  [0.24993679]\n",
      "  [0.25523755]\n",
      "  [0.25868949]\n",
      "  [0.25630111]\n",
      "  [0.25613675]\n",
      "  [0.25836852]]]\n",
      "ejemplar: [0.23760614 0.24373665 0.24993679 0.25523755 0.25868949 0.25630111\n",
      " 0.25613675 0.25836852]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26091358]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.23760614 0.24373665 0.24993679 0.25523755 0.25868949 0.25630111\n",
      "  0.25613675 0.25836852]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005615875590592623\n",
      "Predicción post entrenamiento : [[0.25912994]]\n",
      "PERDIDAAAA despues: 0.005351728294044733\n",
      "loss en el callback: 0.005515527445822954, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.24373665]\n",
      "  [0.24993679]\n",
      "  [0.25523755]\n",
      "  [0.25868949]\n",
      "  [0.25630111]\n",
      "  [0.25613675]\n",
      "  [0.25836852]\n",
      "  [0.26091358]]]\n",
      "ejemplar: [0.24373665 0.24993679 0.25523755 0.25868949 0.25630111 0.25613675\n",
      " 0.25836852 0.26091358]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26214093]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.24373665 0.24993679 0.25523755 0.25868949 0.25630111 0.25613675\n",
      "  0.25836852 0.26091358]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.3134718503570184e-05\n",
      "Predicción post entrenamiento : [[0.2618677]]\n",
      "PERDIDAAAA despues: 2.583774403319694e-05\n",
      "loss en el callback: 0.0001253961818292737, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.24993679]\n",
      "  [0.25523755]\n",
      "  [0.25868949]\n",
      "  [0.25630111]\n",
      "  [0.25613675]\n",
      "  [0.25836852]\n",
      "  [0.26091358]\n",
      "  [0.26214093]]]\n",
      "ejemplar: [0.24993679 0.25523755 0.25868949 0.25630111 0.25613675 0.25836852\n",
      " 0.26091358 0.26214093]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26422313]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.24993679 0.25523755 0.25868949 0.25630111 0.25613675 0.25836852\n",
      "  0.26091358 0.26214093]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008008420700207353\n",
      "Predicción post entrenamiento : [[0.2648979]]\n",
      "PERDIDAAAA despues: 0.0007631057524122298\n",
      "loss en el callback: 0.001115663442760706, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.25523755]\n",
      "  [0.25868949]\n",
      "  [0.25630111]\n",
      "  [0.25613675]\n",
      "  [0.25836852]\n",
      "  [0.26091358]\n",
      "  [0.26214093]\n",
      "  [0.26422313]]]\n",
      "ejemplar: [0.25523755 0.25868949 0.25630111 0.25613675 0.25836852 0.26091358\n",
      " 0.26214093 0.26422313]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.2664073]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.25523755 0.25868949 0.25630111 0.25613675 0.25836852 0.26091358\n",
      "  0.26214093 0.26422313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026315879076719284\n",
      "Predicción post entrenamiento : [[0.2671232]]\n",
      "PERDIDAAAA despues: 0.0025586525443941355\n",
      "loss en el callback: 0.0010915816528722644, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.25868949]\n",
      "  [0.25630111]\n",
      "  [0.25613675]\n",
      "  [0.25836852]\n",
      "  [0.26091358]\n",
      "  [0.26214093]\n",
      "  [0.26422313]\n",
      "  [0.26640731]]]\n",
      "ejemplar: [0.25868949 0.25630111 0.25613675 0.25836852 0.26091358 0.26214093\n",
      " 0.26422313 0.26640731]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26782495]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.25868949 0.25630111 0.25613675 0.25836852 0.26091358 0.26214093\n",
      "  0.26422313 0.26640731]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020110353361815214\n",
      "Predicción post entrenamiento : [[0.26842317]]\n",
      "PERDIDAAAA despues: 0.0019577390048652887\n",
      "loss en el callback: 0.0008460349054075778, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.25630111]\n",
      "  [0.25613675]\n",
      "  [0.25836852]\n",
      "  [0.26091358]\n",
      "  [0.26214093]\n",
      "  [0.26422313]\n",
      "  [0.26640731]\n",
      "  [0.26782495]]]\n",
      "ejemplar: [0.25630111 0.25613675 0.25836852 0.26091358 0.26214093 0.26422313\n",
      " 0.26640731 0.26782495]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.26861697]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.25630111 0.25613675 0.25836852 0.26091358 0.26214093 0.26422313\n",
      "  0.26640731 0.26782495]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004169064050074667\n",
      "Predicción post entrenamiento : [[0.26944765]]\n",
      "PERDIDAAAA despues: 0.0003836743126157671\n",
      "loss en el callback: 0.0021294248290359974, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.25613675]\n",
      "  [0.25836852]\n",
      "  [0.26091358]\n",
      "  [0.26214093]\n",
      "  [0.26422313]\n",
      "  [0.26640731]\n",
      "  [0.26782495]\n",
      "  [0.26861697]]]\n",
      "ejemplar: [0.25613675 0.25836852 0.26091358 0.26214093 0.26422313 0.26640731\n",
      " 0.26782495 0.26861697]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27041367]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.25613675 0.25836852 0.26091358 0.26214093 0.26422313 0.26640731\n",
      "  0.26782495 0.26861697]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001543170801596716\n",
      "Predicción post entrenamiento : [[0.2712376]]\n",
      "PERDIDAAAA despues: 0.0001345251512248069\n",
      "loss en el callback: 0.0024834629148244858, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.25836852]\n",
      "  [0.26091358]\n",
      "  [0.26214093]\n",
      "  [0.26422313]\n",
      "  [0.26640731]\n",
      "  [0.26782495]\n",
      "  [0.26861697]\n",
      "  [0.27041367]]]\n",
      "ejemplar: [0.25836852 0.26091358 0.26214093 0.26422313 0.26640731 0.26782495\n",
      " 0.26861697 0.27041367]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27260944]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.25836852 0.26091358 0.26214093 0.26422313 0.26640731 0.26782495\n",
      "  0.26861697 0.27041367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007229043403640389\n",
      "Predicción post entrenamiento : [[0.2725598]]\n",
      "PERDIDAAAA despues: 0.0007255767122842371\n",
      "loss en el callback: 6.312280220299726e-06, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26091358]\n",
      "  [0.26214093]\n",
      "  [0.26422313]\n",
      "  [0.26640731]\n",
      "  [0.26782495]\n",
      "  [0.26861697]\n",
      "  [0.27041367]\n",
      "  [0.27260944]]]\n",
      "ejemplar: [0.26091358 0.26214093 0.26422313 0.26640731 0.26782495 0.26861697\n",
      " 0.27041367 0.27260944]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2738502]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26091358 0.26214093 0.26422313 0.26640731 0.26782495 0.26861697\n",
      "  0.27041367 0.27260944]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.047602487844415e-06\n",
      "Predicción post entrenamiento : [[0.27390778]]\n",
      "PERDIDAAAA despues: 3.819238827418303e-06\n",
      "loss en el callback: 1.1150264981552027e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26214093]\n",
      "  [0.26422313]\n",
      "  [0.26640731]\n",
      "  [0.26782495]\n",
      "  [0.26861697]\n",
      "  [0.27041367]\n",
      "  [0.27260944]\n",
      "  [0.2738502 ]]]\n",
      "ejemplar: [0.26214093 0.26422313 0.26640731 0.26782495 0.26861697 0.27041367\n",
      " 0.27260944 0.2738502 ]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27502236]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26214093 0.26422313 0.26640731 0.26782495 0.26861697 0.27041367\n",
      "  0.27260944 0.2738502 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0409652873022424e-07\n",
      "Predicción post entrenamiento : [[0.27510816]]\n",
      "PERDIDAAAA despues: 1.668239093532975e-07\n",
      "loss en el callback: 2.582532397354953e-05, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26422313]\n",
      "  [0.26640731]\n",
      "  [0.26782495]\n",
      "  [0.26861697]\n",
      "  [0.27041367]\n",
      "  [0.27260944]\n",
      "  [0.2738502 ]\n",
      "  [0.27502236]]]\n",
      "ejemplar: [0.26422313 0.26640731 0.26782495 0.26861697 0.27041367 0.27260944\n",
      " 0.2738502  0.27502236]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27631372]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26422313 0.26640731 0.26782495 0.26861697 0.27041367 0.27260944\n",
      "  0.2738502  0.27502236]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.041126082185656e-07\n",
      "Predicción post entrenamiento : [[0.27623057]]\n",
      "PERDIDAAAA despues: 5.714841790904757e-07\n",
      "loss en el callback: 2.4924311219365336e-05, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26640731]\n",
      "  [0.26782495]\n",
      "  [0.26861697]\n",
      "  [0.27041367]\n",
      "  [0.27260944]\n",
      "  [0.2738502 ]\n",
      "  [0.27502236]\n",
      "  [0.27631372]]]\n",
      "ejemplar: [0.26640731 0.26782495 0.26861697 0.27041367 0.27260944 0.2738502\n",
      " 0.27502236 0.27631372]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27733812]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26640731 0.26782495 0.26861697 0.27041367 0.27260944 0.2738502\n",
      "  0.27502236 0.27631372]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032965790014714003\n",
      "Predicción post entrenamiento : [[0.2787294]]\n",
      "PERDIDAAAA despues: 0.0031387503258883953\n",
      "loss en el callback: 0.012889022938907146, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26782495]\n",
      "  [0.26861697]\n",
      "  [0.27041367]\n",
      "  [0.27260944]\n",
      "  [0.2738502 ]\n",
      "  [0.27502236]\n",
      "  [0.27631372]\n",
      "  [0.27733812]]]\n",
      "ejemplar: [0.26782495 0.26861697 0.27041367 0.27260944 0.2738502  0.27502236\n",
      " 0.27631372 0.27733812]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.2796911]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26782495 0.26861697 0.27041367 0.27260944 0.2738502  0.27502236\n",
      "  0.27631372 0.27733812]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005773718003183603\n",
      "Predicción post entrenamiento : [[0.28073922]]\n",
      "PERDIDAAAA despues: 0.005615533795207739\n",
      "loss en el callback: 0.004183928016573191, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26861697]\n",
      "  [0.27041367]\n",
      "  [0.27260944]\n",
      "  [0.2738502 ]\n",
      "  [0.27502236]\n",
      "  [0.27631372]\n",
      "  [0.27733812]\n",
      "  [0.2796911 ]]]\n",
      "ejemplar: [0.26861697 0.27041367 0.27260944 0.2738502  0.27502236 0.27631372\n",
      " 0.27733812 0.2796911 ]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.28170612]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26861697 0.27041367 0.27260944 0.2738502  0.27502236 0.27631372\n",
      "  0.27733812 0.2796911 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003023358527570963\n",
      "Predicción post entrenamiento : [[0.2825322]]\n",
      "PERDIDAAAA despues: 0.0029331990517675877\n",
      "loss en el callback: 0.003274020738899708, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27041367]\n",
      "  [0.27260944]\n",
      "  [0.2738502 ]\n",
      "  [0.27502236]\n",
      "  [0.27631372]\n",
      "  [0.27733812]\n",
      "  [0.2796911 ]\n",
      "  [0.28170612]]]\n",
      "ejemplar: [0.27041367 0.27260944 0.2738502  0.27502236 0.27631372 0.27733812\n",
      " 0.2796911  0.28170612]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28365368]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27041367 0.27260944 0.2738502  0.27502236 0.27631372 0.27733812\n",
      "  0.2796911  0.28170612]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024938001297414303\n",
      "Predicción post entrenamiento : [[0.28431484]]\n",
      "PERDIDAAAA despues: 0.0024282028898596764\n",
      "loss en el callback: 0.002201595576480031, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27260944]\n",
      "  [0.2738502 ]\n",
      "  [0.27502236]\n",
      "  [0.27631372]\n",
      "  [0.27733812]\n",
      "  [0.2796911 ]\n",
      "  [0.28170612]\n",
      "  [0.28365368]]]\n",
      "ejemplar: [0.27260944 0.2738502  0.27502236 0.27631372 0.27733812 0.2796911\n",
      " 0.28170612 0.28365368]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.2853891]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27260944 0.2738502  0.27502236 0.27631372 0.27733812 0.2796911\n",
      "  0.28170612 0.28365368]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009869529865682125\n",
      "Predicción post entrenamiento : [[0.28633773]]\n",
      "PERDIDAAAA despues: 0.00968194380402565\n",
      "loss en el callback: 0.003850222798064351, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.2738502 ]\n",
      "  [0.27502236]\n",
      "  [0.27631372]\n",
      "  [0.27733812]\n",
      "  [0.2796911 ]\n",
      "  [0.28170612]\n",
      "  [0.28365368]\n",
      "  [0.2853891 ]]]\n",
      "ejemplar: [0.2738502  0.27502236 0.27631372 0.27733812 0.2796911  0.28170612\n",
      " 0.28365368 0.2853891 ]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.28727117]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.2738502  0.27502236 0.27631372 0.27733812 0.2796911  0.28170612\n",
      "  0.28365368 0.2853891 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08055680245161057\n",
      "Predicción post entrenamiento : [[0.29112023]]\n",
      "PERDIDAAAA despues: 0.07838670164346695\n",
      "loss en el callback: 0.0860891342163086, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27502236]\n",
      "  [0.27631372]\n",
      "  [0.27733812]\n",
      "  [0.2796911 ]\n",
      "  [0.28170612]\n",
      "  [0.28365368]\n",
      "  [0.2853891 ]\n",
      "  [0.28727117]]]\n",
      "ejemplar: [0.27502236 0.27631372 0.27733812 0.2796911  0.28170612 0.28365368\n",
      " 0.2853891  0.28727117]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.29212376]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27502236 0.27631372 0.27733812 0.2796911  0.28170612 0.28365368\n",
      "  0.2853891  0.28727117]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09251132607460022\n",
      "Predicción post entrenamiento : [[0.29622114]]\n",
      "PERDIDAAAA despues: 0.09003563225269318\n",
      "loss en el callback: 0.10020874440670013, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27631372]\n",
      "  [0.27733812]\n",
      "  [0.2796911 ]\n",
      "  [0.28170612]\n",
      "  [0.28365368]\n",
      "  [0.2853891 ]\n",
      "  [0.28727117]\n",
      "  [0.29212376]]]\n",
      "ejemplar: [0.27631372 0.27733812 0.2796911  0.28170612 0.28365368 0.2853891\n",
      " 0.28727117 0.29212376]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.29734862]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27631372 0.27733812 0.2796911  0.28170612 0.28365368 0.2853891\n",
      "  0.28727117 0.29212376]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07685916125774384\n",
      "Predicción post entrenamiento : [[0.30075562]]\n",
      "PERDIDAAAA despues: 0.074981689453125\n",
      "loss en el callback: 0.05465470254421234, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27733812]\n",
      "  [0.2796911 ]\n",
      "  [0.28170612]\n",
      "  [0.28365368]\n",
      "  [0.2853891 ]\n",
      "  [0.28727117]\n",
      "  [0.29212376]\n",
      "  [0.29734862]]]\n",
      "ejemplar: [0.27733812 0.2796911  0.28170612 0.28365368 0.2853891  0.28727117\n",
      " 0.29212376 0.29734862]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.30204147]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27733812 0.2796911  0.28170612 0.28365368 0.2853891  0.28727117\n",
      "  0.29212376 0.29734862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09260618686676025\n",
      "Predicción post entrenamiento : [[0.3056704]]\n",
      "PERDIDAAAA despues: 0.09041069447994232\n",
      "loss en el callback: 0.08008693903684616, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.2796911 ]\n",
      "  [0.28170612]\n",
      "  [0.28365368]\n",
      "  [0.2853891 ]\n",
      "  [0.28727117]\n",
      "  [0.29212376]\n",
      "  [0.29734862]\n",
      "  [0.30204147]]]\n",
      "ejemplar: [0.2796911  0.28170612 0.28365368 0.2853891  0.28727117 0.29212376\n",
      " 0.29734862 0.30204147]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.30725724]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.2796911  0.28170612 0.28365368 0.2853891  0.28727117 0.29212376\n",
      "  0.29734862 0.30204147]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07695070654153824\n",
      "Predicción post entrenamiento : [[0.3105127]]\n",
      "PERDIDAAAA despues: 0.07515517622232437\n",
      "loss en el callback: 0.05864434689283371, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.28170612]\n",
      "  [0.28365368]\n",
      "  [0.2853891 ]\n",
      "  [0.28727117]\n",
      "  [0.29212376]\n",
      "  [0.29734862]\n",
      "  [0.30204147]\n",
      "  [0.30725724]]]\n",
      "ejemplar: [0.28170612 0.28365368 0.2853891  0.28727117 0.29212376 0.29734862\n",
      " 0.30204147 0.30725724]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3121995]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.28170612 0.28365368 0.2853891  0.28727117 0.29212376 0.29734862\n",
      "  0.30204147 0.30725724]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.065829336643219\n",
      "Predicción post entrenamiento : [[0.31532744]]\n",
      "PERDIDAAAA despues: 0.06423403322696686\n",
      "loss en el callback: 0.05160193890333176, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28365368]\n",
      "  [0.2853891 ]\n",
      "  [0.28727117]\n",
      "  [0.29212376]\n",
      "  [0.29734862]\n",
      "  [0.30204147]\n",
      "  [0.30725724]\n",
      "  [0.3121995 ]]]\n",
      "ejemplar: [0.28365368 0.2853891  0.28727117 0.29212376 0.29734862 0.30204147\n",
      " 0.30725724 0.3121995 ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31727463]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28365368 0.2853891  0.28727117 0.29212376 0.29734862 0.30204147\n",
      "  0.30725724 0.3121995 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10594990849494934\n",
      "Predicción post entrenamiento : [[0.32104215]]\n",
      "PERDIDAAAA despues: 0.10351145267486572\n",
      "loss en el callback: 0.10528993606567383, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.2853891 ]\n",
      "  [0.28727117]\n",
      "  [0.29212376]\n",
      "  [0.29734862]\n",
      "  [0.30204147]\n",
      "  [0.30725724]\n",
      "  [0.3121995 ]\n",
      "  [0.31727463]]]\n",
      "ejemplar: [0.2853891  0.28727117 0.29212376 0.29734862 0.30204147 0.30725724\n",
      " 0.3121995  0.31727463]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32337332]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.2853891  0.28727117 0.29212376 0.29734862 0.30204147 0.30725724\n",
      "  0.3121995  0.31727463]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11450488120317459\n",
      "Predicción post entrenamiento : [[0.32737443]]\n",
      "PERDIDAAAA despues: 0.11181305348873138\n",
      "loss en el callback: 0.16572098433971405, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28727117]\n",
      "  [0.29212376]\n",
      "  [0.29734862]\n",
      "  [0.30204147]\n",
      "  [0.30725724]\n",
      "  [0.3121995 ]\n",
      "  [0.31727463]\n",
      "  [0.32337332]]]\n",
      "ejemplar: [0.28727117 0.29212376 0.29734862 0.30204147 0.30725724 0.3121995\n",
      " 0.31727463 0.32337332]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3302622]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28727117 0.29212376 0.29734862 0.30204147 0.30725724 0.3121995\n",
      "  0.31727463 0.32337332]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11746574193239212\n",
      "Predicción post entrenamiento : [[0.33428532]]\n",
      "PERDIDAAAA despues: 0.11472422629594803\n",
      "loss en el callback: 0.13095730543136597, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.29212376]\n",
      "  [0.29734862]\n",
      "  [0.30204147]\n",
      "  [0.30725724]\n",
      "  [0.3121995 ]\n",
      "  [0.31727463]\n",
      "  [0.32337332]\n",
      "  [0.33026221]]]\n",
      "ejemplar: [0.29212376 0.29734862 0.30204147 0.30725724 0.3121995  0.31727463\n",
      " 0.32337332 0.33026221]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.337838]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.29212376 0.29734862 0.30204147 0.30725724 0.3121995  0.31727463\n",
      "  0.32337332 0.33026221]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13893459737300873\n",
      "Predicción post entrenamiento : [[0.34207234]]\n",
      "PERDIDAAAA despues: 0.13579592108726501\n",
      "loss en el callback: 0.11006186157464981, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29734862]\n",
      "  [0.30204147]\n",
      "  [0.30725724]\n",
      "  [0.3121995 ]\n",
      "  [0.31727463]\n",
      "  [0.32337332]\n",
      "  [0.33026221]\n",
      "  [0.33783799]]]\n",
      "ejemplar: [0.29734862 0.30204147 0.30725724 0.3121995  0.31727463 0.32337332\n",
      " 0.33026221 0.33783799]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34573358]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29734862 0.30204147 0.30725724 0.3121995  0.31727463 0.32337332\n",
      "  0.33026221 0.33783799]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12834815680980682\n",
      "Predicción post entrenamiento : [[0.3494187]]\n",
      "PERDIDAAAA despues: 0.1257213056087494\n",
      "loss en el callback: 0.09405874460935593, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.30204147]\n",
      "  [0.30725724]\n",
      "  [0.3121995 ]\n",
      "  [0.31727463]\n",
      "  [0.32337332]\n",
      "  [0.33026221]\n",
      "  [0.33783799]\n",
      "  [0.34573358]]]\n",
      "ejemplar: [0.30204147 0.30725724 0.3121995  0.31727463 0.32337332 0.33026221\n",
      " 0.33783799 0.34573358]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35315907]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.30204147 0.30725724 0.3121995  0.31727463 0.32337332 0.33026221\n",
      "  0.33783799 0.34573358]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1399346888065338\n",
      "Predicción post entrenamiento : [[0.35719857]]\n",
      "PERDIDAAAA despues: 0.13692882657051086\n",
      "loss en el callback: 0.16772538423538208, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.30725724]\n",
      "  [0.3121995 ]\n",
      "  [0.31727463]\n",
      "  [0.32337332]\n",
      "  [0.33026221]\n",
      "  [0.33783799]\n",
      "  [0.34573358]\n",
      "  [0.35315907]]]\n",
      "ejemplar: [0.30725724 0.3121995  0.31727463 0.32337332 0.33026221 0.33783799\n",
      " 0.34573358 0.35315907]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.36121145]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.30725724 0.3121995  0.31727463 0.32337332 0.33026221 0.33783799\n",
      "  0.34573358 0.35315907]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13059310615062714\n",
      "Predicción post entrenamiento : [[0.3649121]]\n",
      "PERDIDAAAA despues: 0.12793214619159698\n",
      "loss en el callback: 0.0920218750834465, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.3121995 ]\n",
      "  [0.31727463]\n",
      "  [0.32337332]\n",
      "  [0.33026221]\n",
      "  [0.33783799]\n",
      "  [0.34573358]\n",
      "  [0.35315907]\n",
      "  [0.36121145]]]\n",
      "ejemplar: [0.3121995  0.31727463 0.32337332 0.33026221 0.33783799 0.34573358\n",
      " 0.35315907 0.36121145]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36917198]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.3121995  0.31727463 0.32337332 0.33026221 0.33783799 0.34573358\n",
      "  0.35315907 0.36121145]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16210441291332245\n",
      "Predicción post entrenamiento : [[0.37371257]]\n",
      "PERDIDAAAA despues: 0.15846875309944153\n",
      "loss en el callback: 0.19534680247306824, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31727463]\n",
      "  [0.32337332]\n",
      "  [0.33026221]\n",
      "  [0.33783799]\n",
      "  [0.34573358]\n",
      "  [0.35315907]\n",
      "  [0.36121145]\n",
      "  [0.36917198]]]\n",
      "ejemplar: [0.31727463 0.32337332 0.33026221 0.33783799 0.34573358 0.35315907\n",
      " 0.36121145 0.36917198]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3783817]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31727463 0.32337332 0.33026221 0.33783799 0.34573358 0.35315907\n",
      "  0.36121145 0.36917198]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11981545388698578\n",
      "Predicción post entrenamiento : [[0.38211063]]\n",
      "PERDIDAAAA despues: 0.11724787205457687\n",
      "loss en el callback: 0.12033544480800629, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32337332]\n",
      "  [0.33026221]\n",
      "  [0.33783799]\n",
      "  [0.34573358]\n",
      "  [0.35315907]\n",
      "  [0.36121145]\n",
      "  [0.36917198]\n",
      "  [0.3783817 ]]]\n",
      "ejemplar: [0.32337332 0.33026221 0.33783799 0.34573358 0.35315907 0.36121145\n",
      " 0.36917198 0.3783817 ]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38727438]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32337332 0.33026221 0.33783799 0.34573358 0.35315907 0.36121145\n",
      "  0.36917198 0.3783817 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.080532968044281\n",
      "Predicción post entrenamiento : [[0.39021432]]\n",
      "PERDIDAAAA despues: 0.07887300103902817\n",
      "loss en el callback: 0.07208772003650665, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.33026221]\n",
      "  [0.33783799]\n",
      "  [0.34573358]\n",
      "  [0.35315907]\n",
      "  [0.36121145]\n",
      "  [0.36917198]\n",
      "  [0.3783817 ]\n",
      "  [0.38727438]]]\n",
      "ejemplar: [0.33026221 0.33783799 0.34573358 0.35315907 0.36121145 0.36917198\n",
      " 0.3783817  0.38727438]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39574412]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.33026221 0.33783799 0.34573358 0.35315907 0.36121145 0.36917198\n",
      "  0.3783817  0.38727438]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07729829847812653\n",
      "Predicción post entrenamiento : [[0.3985186]]\n",
      "PERDIDAAAA despues: 0.07576324790716171\n",
      "loss en el callback: 0.07180965691804886, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33783799]\n",
      "  [0.34573358]\n",
      "  [0.35315907]\n",
      "  [0.36121145]\n",
      "  [0.36917198]\n",
      "  [0.3783817 ]\n",
      "  [0.38727438]\n",
      "  [0.39574412]]]\n",
      "ejemplar: [0.33783799 0.34573358 0.35315907 0.36121145 0.36917198 0.3783817\n",
      " 0.38727438 0.39574412]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.4043108]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33783799 0.34573358 0.35315907 0.36121145 0.36917198 0.3783817\n",
      "  0.38727438 0.39574412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09618743509054184\n",
      "Predicción post entrenamiento : [[0.4075001]]\n",
      "PERDIDAAAA despues: 0.09421934932470322\n",
      "loss en el callback: 0.09769434481859207, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34573358]\n",
      "  [0.35315907]\n",
      "  [0.36121145]\n",
      "  [0.36917198]\n",
      "  [0.3783817 ]\n",
      "  [0.38727438]\n",
      "  [0.39574412]\n",
      "  [0.40431079]]]\n",
      "ejemplar: [0.34573358 0.35315907 0.36121145 0.36917198 0.3783817  0.38727438\n",
      " 0.39574412 0.40431079]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41345084]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34573358 0.35315907 0.36121145 0.36917198 0.3783817  0.38727438\n",
      "  0.39574412 0.40431079]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10919515043497086\n",
      "Predicción post entrenamiento : [[0.41678822]]\n",
      "PERDIDAAAA despues: 0.10700063407421112\n",
      "loss en el callback: 0.09141836315393448, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.35315907]\n",
      "  [0.36121145]\n",
      "  [0.36917198]\n",
      "  [0.3783817 ]\n",
      "  [0.38727438]\n",
      "  [0.39574412]\n",
      "  [0.40431079]\n",
      "  [0.41345084]]]\n",
      "ejemplar: [0.35315907 0.36121145 0.36917198 0.3783817  0.38727438 0.39574412\n",
      " 0.40431079 0.41345084]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42286316]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.35315907 0.36121145 0.36917198 0.3783817  0.38727438 0.39574412\n",
      "  0.40431079 0.41345084]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08983505517244339\n",
      "Predicción post entrenamiento : [[0.42593843]]\n",
      "PERDIDAAAA despues: 0.08800104260444641\n",
      "loss en el callback: 0.09163326770067215, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.36121145]\n",
      "  [0.36917198]\n",
      "  [0.3783817 ]\n",
      "  [0.38727438]\n",
      "  [0.39574412]\n",
      "  [0.40431079]\n",
      "  [0.41345084]\n",
      "  [0.42286316]]]\n",
      "ejemplar: [0.36121145 0.36917198 0.3783817  0.38727438 0.39574412 0.40431079\n",
      " 0.41345084 0.42286316]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4322946]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.36121145 0.36917198 0.3783817  0.38727438 0.39574412 0.40431079\n",
      "  0.41345084 0.42286316]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07131396979093552\n",
      "Predicción post entrenamiento : [[0.43492135]]\n",
      "PERDIDAAAA despues: 0.0699179396033287\n",
      "loss en el callback: 0.07118859142065048, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36917198]\n",
      "  [0.3783817 ]\n",
      "  [0.38727438]\n",
      "  [0.39574412]\n",
      "  [0.40431079]\n",
      "  [0.41345084]\n",
      "  [0.42286316]\n",
      "  [0.43229461]]]\n",
      "ejemplar: [0.36917198 0.3783817  0.38727438 0.39574412 0.40431079 0.41345084\n",
      " 0.42286316 0.43229461]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.44146335]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36917198 0.3783817  0.38727438 0.39574412 0.40431079 0.41345084\n",
      "  0.42286316 0.43229461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08752590417861938\n",
      "Predicción post entrenamiento : [[0.44455904]]\n",
      "PERDIDAAAA despues: 0.0857037827372551\n",
      "loss en el callback: 0.19149090349674225, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.3783817 ]\n",
      "  [0.38727438]\n",
      "  [0.39574412]\n",
      "  [0.40431079]\n",
      "  [0.41345084]\n",
      "  [0.42286316]\n",
      "  [0.43229461]\n",
      "  [0.44146335]]]\n",
      "ejemplar: [0.3783817  0.38727438 0.39574412 0.40431079 0.41345084 0.42286316\n",
      " 0.43229461 0.44146335]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.45135373]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.3783817  0.38727438 0.39574412 0.40431079 0.41345084 0.42286316\n",
      "  0.43229461 0.44146335]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0729389414191246\n",
      "Predicción post entrenamiento : [[0.45367935]]\n",
      "PERDIDAAAA despues: 0.07168817520141602\n",
      "loss en el callback: 0.04499142989516258, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38727438]\n",
      "  [0.39574412]\n",
      "  [0.40431079]\n",
      "  [0.41345084]\n",
      "  [0.42286316]\n",
      "  [0.43229461]\n",
      "  [0.44146335]\n",
      "  [0.45135373]]]\n",
      "ejemplar: [0.38727438 0.39574412 0.40431079 0.41345084 0.42286316 0.43229461\n",
      " 0.44146335 0.45135373]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.46045828]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38727438 0.39574412 0.40431079 0.41345084 0.42286316 0.43229461\n",
      "  0.44146335 0.45135373]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06669586151838303\n",
      "Predicción post entrenamiento : [[0.46323806]]\n",
      "PERDIDAAAA despues: 0.06526780128479004\n",
      "loss en el callback: 0.10501374304294586, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.39574412]\n",
      "  [0.40431079]\n",
      "  [0.41345084]\n",
      "  [0.42286316]\n",
      "  [0.43229461]\n",
      "  [0.44146335]\n",
      "  [0.45135373]\n",
      "  [0.46045828]]]\n",
      "ejemplar: [0.39574412 0.40431079 0.41345084 0.42286316 0.43229461 0.44146335\n",
      " 0.45135373 0.46045828]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4700898]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.39574412 0.40431079 0.41345084 0.42286316 0.43229461 0.44146335\n",
      "  0.45135373 0.46045828]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04164355620741844\n",
      "Predicción post entrenamiento : [[0.472127]]\n",
      "PERDIDAAAA despues: 0.040816254913806915\n",
      "loss en el callback: 0.04883904382586479, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.40431079]\n",
      "  [0.41345084]\n",
      "  [0.42286316]\n",
      "  [0.43229461]\n",
      "  [0.44146335]\n",
      "  [0.45135373]\n",
      "  [0.46045828]\n",
      "  [0.47008979]]]\n",
      "ejemplar: [0.40431079 0.41345084 0.42286316 0.43229461 0.44146335 0.45135373\n",
      " 0.46045828 0.47008979]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4791813]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.40431079 0.41345084 0.42286316 0.43229461 0.44146335 0.45135373\n",
      "  0.46045828 0.47008979]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.048129841685295105\n",
      "Predicción post entrenamiento : [[0.48077473]]\n",
      "PERDIDAAAA despues: 0.04743322730064392\n",
      "loss en el callback: 0.02153606154024601, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.41345084]\n",
      "  [0.42286316]\n",
      "  [0.43229461]\n",
      "  [0.44146335]\n",
      "  [0.45135373]\n",
      "  [0.46045828]\n",
      "  [0.47008979]\n",
      "  [0.47918129]]]\n",
      "ejemplar: [0.41345084 0.42286316 0.43229461 0.44146335 0.45135373 0.46045828\n",
      " 0.47008979 0.47918129]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4880441]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.41345084 0.42286316 0.43229461 0.44146335 0.45135373 0.46045828\n",
      "  0.47008979 0.47918129]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05428631231188774\n",
      "Predicción post entrenamiento : [[0.49060187]]\n",
      "PERDIDAAAA despues: 0.05310096964240074\n",
      "loss en el callback: 0.14443950355052948, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.42286316]\n",
      "  [0.43229461]\n",
      "  [0.44146335]\n",
      "  [0.45135373]\n",
      "  [0.46045828]\n",
      "  [0.47008979]\n",
      "  [0.47918129]\n",
      "  [0.48804411]]]\n",
      "ejemplar: [0.42286316 0.43229461 0.44146335 0.45135373 0.46045828 0.47008979\n",
      " 0.47918129 0.48804411]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49797088]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.42286316 0.43229461 0.44146335 0.45135373 0.46045828 0.47008979\n",
      "  0.47918129 0.48804411]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050452906638383865\n",
      "Predicción post entrenamiento : [[0.49937963]]\n",
      "PERDIDAAAA despues: 0.04982202872633934\n",
      "loss en el callback: 0.016930773854255676, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.43229461]\n",
      "  [0.44146335]\n",
      "  [0.45135373]\n",
      "  [0.46045828]\n",
      "  [0.47008979]\n",
      "  [0.47918129]\n",
      "  [0.48804411]\n",
      "  [0.49797088]]]\n",
      "ejemplar: [0.43229461 0.44146335 0.45135373 0.46045828 0.47008979 0.47918129\n",
      " 0.48804411 0.49797088]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.50678146]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.43229461 0.44146335 0.45135373 0.46045828 0.47008979 0.47918129\n",
      "  0.48804411 0.49797088]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06225752457976341\n",
      "Predicción post entrenamiento : [[0.50895274]]\n",
      "PERDIDAAAA despues: 0.06117871031165123\n",
      "loss en el callback: 0.04921751841902733, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.44146335]\n",
      "  [0.45135373]\n",
      "  [0.46045828]\n",
      "  [0.47008979]\n",
      "  [0.47918129]\n",
      "  [0.48804411]\n",
      "  [0.49797088]\n",
      "  [0.50678146]]]\n",
      "ejemplar: [0.44146335 0.45135373 0.46045828 0.47008979 0.47918129 0.48804411\n",
      " 0.49797088 0.50678146]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.51637906]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.44146335 0.45135373 0.46045828 0.47008979 0.47918129 0.48804411\n",
      "  0.49797088 0.50678146]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09684990346431732\n",
      "Predicción post entrenamiento : [[0.51936007]]\n",
      "PERDIDAAAA despues: 0.09500337392091751\n",
      "loss en el callback: 0.10301186889410019, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.45135373]\n",
      "  [0.46045828]\n",
      "  [0.47008979]\n",
      "  [0.47918129]\n",
      "  [0.48804411]\n",
      "  [0.49797088]\n",
      "  [0.50678146]\n",
      "  [0.51637906]]]\n",
      "ejemplar: [0.45135373 0.46045828 0.47008979 0.47918129 0.48804411 0.49797088\n",
      " 0.50678146 0.51637906]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5268765]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.45135373 0.46045828 0.47008979 0.47918129 0.48804411 0.49797088\n",
      "  0.50678146 0.51637906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09731010347604752\n",
      "Predicción post entrenamiento : [[0.52976066]]\n",
      "PERDIDAAAA despues: 0.09551902860403061\n",
      "loss en el callback: 0.10386703908443451, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.46045828]\n",
      "  [0.47008979]\n",
      "  [0.47918129]\n",
      "  [0.48804411]\n",
      "  [0.49797088]\n",
      "  [0.50678146]\n",
      "  [0.51637906]\n",
      "  [0.52687651]]]\n",
      "ejemplar: [0.46045828 0.47008979 0.47918129 0.48804411 0.49797088 0.50678146\n",
      " 0.51637906 0.52687651]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.53718674]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.46045828 0.47008979 0.47918129 0.48804411 0.49797088 0.50678146\n",
      "  0.51637906 0.52687651]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06608964502811432\n",
      "Predicción post entrenamiento : [[0.5400229]]\n",
      "PERDIDAAAA despues: 0.06463944911956787\n",
      "loss en el callback: 0.12035827338695526, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.47008979]\n",
      "  [0.47918129]\n",
      "  [0.48804411]\n",
      "  [0.49797088]\n",
      "  [0.50678146]\n",
      "  [0.51637906]\n",
      "  [0.52687651]\n",
      "  [0.53718674]]]\n",
      "ejemplar: [0.47008979 0.47918129 0.48804411 0.49797088 0.50678146 0.51637906\n",
      " 0.52687651 0.53718674]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.54755807]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.47008979 0.47918129 0.48804411 0.49797088 0.50678146 0.51637906\n",
      "  0.52687651 0.53718674]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05581247806549072\n",
      "Predicción post entrenamiento : [[0.54941076]]\n",
      "PERDIDAAAA despues: 0.05494052544236183\n",
      "loss en el callback: 0.03755524009466171, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47918129]\n",
      "  [0.48804411]\n",
      "  [0.49797088]\n",
      "  [0.50678146]\n",
      "  [0.51637906]\n",
      "  [0.52687651]\n",
      "  [0.53718674]\n",
      "  [0.54755807]]]\n",
      "ejemplar: [0.47918129 0.48804411 0.49797088 0.50678146 0.51637906 0.52687651\n",
      " 0.53718674 0.54755807]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5569439]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47918129 0.48804411 0.49797088 0.50678146 0.51637906 0.52687651\n",
      "  0.53718674 0.54755807]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044510673731565475\n",
      "Predicción post entrenamiento : [[0.55859613]]\n",
      "PERDIDAAAA despues: 0.04381623864173889\n",
      "loss en el callback: 0.029360435903072357, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48804411]\n",
      "  [0.49797088]\n",
      "  [0.50678146]\n",
      "  [0.51637906]\n",
      "  [0.52687651]\n",
      "  [0.53718674]\n",
      "  [0.54755807]\n",
      "  [0.55694389]]]\n",
      "ejemplar: [0.48804411 0.49797088 0.50678146 0.51637906 0.52687651 0.53718674\n",
      " 0.54755807 0.55694389]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.56628746]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48804411 0.49797088 0.50678146 0.51637906 0.52687651 0.53718674\n",
      "  0.54755807 0.55694389]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04765147343277931\n",
      "Predicción post entrenamiento : [[0.5680507]]\n",
      "PERDIDAAAA despues: 0.04688478633761406\n",
      "loss en el callback: 0.03689024597406387, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49797088]\n",
      "  [0.50678146]\n",
      "  [0.51637906]\n",
      "  [0.52687651]\n",
      "  [0.53718674]\n",
      "  [0.54755807]\n",
      "  [0.55694389]\n",
      "  [0.56628746]]]\n",
      "ejemplar: [0.49797088 0.50678146 0.51637906 0.52687651 0.53718674 0.54755807\n",
      " 0.55694389 0.56628746]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.57599884]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49797088 0.50678146 0.51637906 0.52687651 0.53718674 0.54755807\n",
      "  0.55694389 0.56628746]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09164565056562424\n",
      "Predicción post entrenamiento : [[0.57864636]]\n",
      "PERDIDAAAA despues: 0.09004969149827957\n",
      "loss en el callback: 0.09111620485782623, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50678146]\n",
      "  [0.51637906]\n",
      "  [0.52687651]\n",
      "  [0.53718674]\n",
      "  [0.54755807]\n",
      "  [0.55694389]\n",
      "  [0.56628746]\n",
      "  [0.57599884]]]\n",
      "ejemplar: [0.50678146 0.51637906 0.52687651 0.53718674 0.54755807 0.55694389\n",
      " 0.56628746 0.57599884]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.58660764]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50678146 0.51637906 0.52687651 0.53718674 0.54755807 0.55694389\n",
      "  0.56628746 0.57599884]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08353369683027267\n",
      "Predicción post entrenamiento : [[0.5891604]]\n",
      "PERDIDAAAA despues: 0.08206461369991302\n",
      "loss en el callback: 0.07760217040777206, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51637906]\n",
      "  [0.52687651]\n",
      "  [0.53718674]\n",
      "  [0.54755807]\n",
      "  [0.55694389]\n",
      "  [0.56628746]\n",
      "  [0.57599884]\n",
      "  [0.58660764]]]\n",
      "ejemplar: [0.51637906 0.52687651 0.53718674 0.54755807 0.55694389 0.56628746\n",
      " 0.57599884 0.58660764]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5974395]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51637906 0.52687651 0.53718674 0.54755807 0.55694389 0.56628746\n",
      "  0.57599884 0.58660764]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0632302537560463\n",
      "Predicción post entrenamiento : [[0.5990775]]\n",
      "PERDIDAAAA despues: 0.0624091662466526\n",
      "loss en el callback: 0.0269992183893919, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52687651]\n",
      "  [0.53718674]\n",
      "  [0.54755807]\n",
      "  [0.55694389]\n",
      "  [0.56628746]\n",
      "  [0.57599884]\n",
      "  [0.58660764]\n",
      "  [0.59743953]]]\n",
      "ejemplar: [0.52687651 0.53718674 0.54755807 0.55694389 0.56628746 0.57599884\n",
      " 0.58660764 0.59743953]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.60750514]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52687651 0.53718674 0.54755807 0.55694389 0.56628746 0.57599884\n",
      "  0.58660764 0.59743953]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044429197907447815\n",
      "Predicción post entrenamiento : [[0.60958457]]\n",
      "PERDIDAAAA despues: 0.04355691000819206\n",
      "loss en el callback: 0.05479515716433525, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53718674]\n",
      "  [0.54755807]\n",
      "  [0.55694389]\n",
      "  [0.56628746]\n",
      "  [0.57599884]\n",
      "  [0.58660764]\n",
      "  [0.59743953]\n",
      "  [0.60750514]]]\n",
      "ejemplar: [0.53718674 0.54755807 0.55694389 0.56628746 0.57599884 0.58660764\n",
      " 0.59743953 0.60750514]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6179321]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53718674 0.54755807 0.55694389 0.56628746 0.57599884 0.58660764\n",
      "  0.59743953 0.60750514]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043630532920360565\n",
      "Predicción post entrenamiento : [[0.6199734]]\n",
      "PERDIDAAAA despues: 0.04278191551566124\n",
      "loss en el callback: 0.06450701504945755, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54755807]\n",
      "  [0.55694389]\n",
      "  [0.56628746]\n",
      "  [0.57599884]\n",
      "  [0.58660764]\n",
      "  [0.59743953]\n",
      "  [0.60750514]\n",
      "  [0.61793208]]]\n",
      "ejemplar: [0.54755807 0.55694389 0.56628746 0.57599884 0.58660764 0.59743953\n",
      " 0.60750514 0.61793208]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6282808]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54755807 0.55694389 0.56628746 0.57599884 0.58660764 0.59743953\n",
      "  0.60750514 0.61793208]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024672139436006546\n",
      "Predicción post entrenamiento : [[0.6292909]]\n",
      "PERDIDAAAA despues: 0.024355852976441383\n",
      "loss en el callback: 0.011303998529911041, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55694389]\n",
      "  [0.56628746]\n",
      "  [0.57599884]\n",
      "  [0.58660764]\n",
      "  [0.59743953]\n",
      "  [0.60750514]\n",
      "  [0.61793208]\n",
      "  [0.62828082]]]\n",
      "ejemplar: [0.55694389 0.56628746 0.57599884 0.58660764 0.59743953 0.60750514\n",
      " 0.61793208 0.62828082]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6375375]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55694389 0.56628746 0.57599884 0.58660764 0.59743953 0.60750514\n",
      "  0.61793208 0.62828082]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023010309785604477\n",
      "Predicción post entrenamiento : [[0.6395341]]\n",
      "PERDIDAAAA despues: 0.02240855060517788\n",
      "loss en el callback: 0.08996226638555527, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56628746]\n",
      "  [0.57599884]\n",
      "  [0.58660764]\n",
      "  [0.59743953]\n",
      "  [0.60750514]\n",
      "  [0.61793208]\n",
      "  [0.62828082]\n",
      "  [0.63753748]]]\n",
      "ejemplar: [0.56628746 0.57599884 0.58660764 0.59743953 0.60750514 0.61793208\n",
      " 0.62828082 0.63753748]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.647996]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56628746 0.57599884 0.58660764 0.59743953 0.60750514 0.61793208\n",
      "  0.62828082 0.63753748]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03466179221868515\n",
      "Predicción post entrenamiento : [[0.6494113]]\n",
      "PERDIDAAAA despues: 0.03413679823279381\n",
      "loss en el callback: 0.024166272953152657, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57599884]\n",
      "  [0.58660764]\n",
      "  [0.59743953]\n",
      "  [0.60750514]\n",
      "  [0.61793208]\n",
      "  [0.62828082]\n",
      "  [0.63753748]\n",
      "  [0.64799601]]]\n",
      "ejemplar: [0.57599884 0.58660764 0.59743953 0.60750514 0.61793208 0.62828082\n",
      " 0.63753748 0.64799601]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6581347]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57599884 0.58660764 0.59743953 0.60750514 0.61793208 0.62828082\n",
      "  0.63753748 0.64799601]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02382117509841919\n",
      "Predicción post entrenamiento : [[0.6593111]]\n",
      "PERDIDAAAA despues: 0.0234594214707613\n",
      "loss en el callback: 0.01705295965075493, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58660764]\n",
      "  [0.59743953]\n",
      "  [0.60750514]\n",
      "  [0.61793208]\n",
      "  [0.62828082]\n",
      "  [0.63753748]\n",
      "  [0.64799601]\n",
      "  [0.6581347 ]]]\n",
      "ejemplar: [0.58660764 0.59743953 0.60750514 0.61793208 0.62828082 0.63753748\n",
      " 0.64799601 0.6581347 ]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.66822404]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58660764 0.59743953 0.60750514 0.61793208 0.62828082 0.63753748\n",
      "  0.64799601 0.6581347 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017693206667900085\n",
      "Predicción post entrenamiento : [[0.6691824]]\n",
      "PERDIDAAAA despues: 0.017439164221286774\n",
      "loss en el callback: 0.011330033652484417, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59743953]\n",
      "  [0.60750514]\n",
      "  [0.61793208]\n",
      "  [0.62828082]\n",
      "  [0.63753748]\n",
      "  [0.64799601]\n",
      "  [0.6581347 ]\n",
      "  [0.66822404]]]\n",
      "ejemplar: [0.59743953 0.60750514 0.61793208 0.62828082 0.63753748 0.64799601\n",
      " 0.6581347  0.66822404]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6780442]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59743953 0.60750514 0.61793208 0.62828082 0.63753748 0.64799601\n",
      "  0.6581347  0.66822404]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01565823145210743\n",
      "Predicción post entrenamiento : [[0.67966914]]\n",
      "PERDIDAAAA despues: 0.015254205092787743\n",
      "loss en el callback: 0.05005912482738495, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60750514]\n",
      "  [0.61793208]\n",
      "  [0.62828082]\n",
      "  [0.63753748]\n",
      "  [0.64799601]\n",
      "  [0.6581347 ]\n",
      "  [0.66822404]\n",
      "  [0.6780442 ]]]\n",
      "ejemplar: [0.60750514 0.61793208 0.62828082 0.63753748 0.64799601 0.6581347\n",
      " 0.66822404 0.6780442 ]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.68839234]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60750514 0.61793208 0.62828082 0.63753748 0.64799601 0.6581347\n",
      "  0.66822404 0.6780442 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01104570459574461\n",
      "Predicción post entrenamiento : [[0.68985903]]\n",
      "PERDIDAAAA despues: 0.010739561170339584\n",
      "loss en el callback: 0.03494839742779732, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61793208]\n",
      "  [0.62828082]\n",
      "  [0.63753748]\n",
      "  [0.64799601]\n",
      "  [0.6581347 ]\n",
      "  [0.66822404]\n",
      "  [0.6780442 ]\n",
      "  [0.68839234]]]\n",
      "ejemplar: [0.61793208 0.62828082 0.63753748 0.64799601 0.6581347  0.66822404\n",
      " 0.6780442  0.68839234]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6986271]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61793208 0.62828082 0.63753748 0.64799601 0.6581347  0.66822404\n",
      "  0.6780442  0.68839234]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003787583438679576\n",
      "Predicción post entrenamiento : [[0.69876397]]\n",
      "PERDIDAAAA despues: 0.0037707574665546417\n",
      "loss en el callback: 0.00021398166427388787, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62828082]\n",
      "  [0.63753748]\n",
      "  [0.64799601]\n",
      "  [0.6581347 ]\n",
      "  [0.66822404]\n",
      "  [0.6780442 ]\n",
      "  [0.68839234]\n",
      "  [0.69862711]]]\n",
      "ejemplar: [0.62828082 0.63753748 0.64799601 0.6581347  0.66822404 0.6780442\n",
      " 0.68839234 0.69862711]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7074693]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62828082 0.63753748 0.64799601 0.6581347  0.66822404 0.6780442\n",
      "  0.68839234 0.69862711]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007786683854646981\n",
      "Predicción post entrenamiento : [[0.70740247]]\n",
      "PERDIDAAAA despues: 0.0007824018248356879\n",
      "loss en el callback: 5.6730135838733986e-05, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63753748]\n",
      "  [0.64799601]\n",
      "  [0.6581347 ]\n",
      "  [0.66822404]\n",
      "  [0.6780442 ]\n",
      "  [0.68839234]\n",
      "  [0.69862711]\n",
      "  [0.70746928]]]\n",
      "ejemplar: [0.63753748 0.64799601 0.6581347  0.66822404 0.6780442  0.68839234\n",
      " 0.69862711 0.70746928]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.71604687]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63753748 0.64799601 0.6581347  0.66822404 0.6780442  0.68839234\n",
      "  0.69862711 0.70746928]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.4305037843296304e-05\n",
      "Predicción post entrenamiento : [[0.71473527]]\n",
      "PERDIDAAAA despues: 2.066111846943386e-05\n",
      "loss en el callback: 0.01868504099547863, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.64799601]\n",
      "  [0.6581347 ]\n",
      "  [0.66822404]\n",
      "  [0.6780442 ]\n",
      "  [0.68839234]\n",
      "  [0.69862711]\n",
      "  [0.70746928]\n",
      "  [0.71604687]]]\n",
      "ejemplar: [0.64799601 0.6581347  0.66822404 0.6780442  0.68839234 0.69862711\n",
      " 0.70746928 0.71604687]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7236004]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.64799601 0.6581347  0.66822404 0.6780442  0.68839234 0.69862711\n",
      "  0.70746928 0.71604687]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013163656694814563\n",
      "Predicción post entrenamiento : [[0.7228959]]\n",
      "PERDIDAAAA despues: 0.00011596771946642548\n",
      "loss en el callback: 0.0061672343872487545, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.6581347 ]\n",
      "  [0.66822404]\n",
      "  [0.6780442 ]\n",
      "  [0.68839234]\n",
      "  [0.69862711]\n",
      "  [0.70746928]\n",
      "  [0.71604687]\n",
      "  [0.72360039]]]\n",
      "ejemplar: [0.6581347  0.66822404 0.6780442  0.68839234 0.69862711 0.70746928\n",
      " 0.71604687 0.72360039]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7316331]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.6581347  0.66822404 0.6780442  0.68839234 0.69862711 0.70746928\n",
      "  0.71604687 0.72360039]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.404318264685571e-05\n",
      "Predicción post entrenamiento : [[0.7319165]]\n",
      "PERDIDAAAA despues: 5.958817928330973e-05\n",
      "loss en el callback: 0.0011301561025902629, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.66822404]\n",
      "  [0.6780442 ]\n",
      "  [0.68839234]\n",
      "  [0.69862711]\n",
      "  [0.70746928]\n",
      "  [0.71604687]\n",
      "  [0.72360039]\n",
      "  [0.73163313]]]\n",
      "ejemplar: [0.66822404 0.6780442  0.68839234 0.69862711 0.70746928 0.71604687\n",
      " 0.72360039 0.73163313]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7405483]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.66822404 0.6780442  0.68839234 0.69862711 0.70746928 0.71604687\n",
      "  0.72360039 0.73163313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.9355935364728794e-05\n",
      "Predicción post entrenamiento : [[0.7406532]]\n",
      "PERDIDAAAA despues: 2.0289999156375416e-05\n",
      "loss en el callback: 0.00016475777374580503, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.6780442 ]\n",
      "  [0.68839234]\n",
      "  [0.69862711]\n",
      "  [0.70746928]\n",
      "  [0.71604687]\n",
      "  [0.72360039]\n",
      "  [0.73163313]\n",
      "  [0.74054831]]]\n",
      "ejemplar: [0.6780442  0.68839234 0.69862711 0.70746928 0.71604687 0.72360039\n",
      " 0.73163313 0.74054831]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.74912083]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.6780442  0.68839234 0.69862711 0.70746928 0.71604687 0.72360039\n",
      "  0.73163313 0.74054831]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0066504222340881824\n",
      "Predicción post entrenamiento : [[0.74776316]]\n",
      "PERDIDAAAA despues: 0.006430828478187323\n",
      "loss en el callback: 0.024113820865750313, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.68839234]\n",
      "  [0.69862711]\n",
      "  [0.70746928]\n",
      "  [0.71604687]\n",
      "  [0.72360039]\n",
      "  [0.73163313]\n",
      "  [0.74054831]\n",
      "  [0.74912083]]]\n",
      "ejemplar: [0.68839234 0.69862711 0.70746928 0.71604687 0.72360039 0.73163313\n",
      " 0.74054831 0.74912083]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.75606096]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.68839234 0.69862711 0.70746928 0.71604687 0.72360039 0.73163313\n",
      "  0.74054831 0.74912083]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0074245017021894455\n",
      "Predicción post entrenamiento : [[0.75630724]]\n",
      "PERDIDAAAA despues: 0.007467004936188459\n",
      "loss en el callback: 0.0011925421422347426, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.69862711]\n",
      "  [0.70746928]\n",
      "  [0.71604687]\n",
      "  [0.72360039]\n",
      "  [0.73163313]\n",
      "  [0.74054831]\n",
      "  [0.74912083]\n",
      "  [0.75606096]]]\n",
      "ejemplar: [0.69862711 0.70746928 0.71604687 0.72360039 0.73163313 0.74054831\n",
      " 0.74912083 0.75606096]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.76420784]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.69862711 0.70746928 0.71604687 0.72360039 0.73163313 0.74054831\n",
      "  0.74912083 0.75606096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004566869232803583\n",
      "Predicción post entrenamiento : [[0.76397336]]\n",
      "PERDIDAAAA despues: 0.004535231739282608\n",
      "loss en el callback: 0.0008713093120604753, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70746928]\n",
      "  [0.71604687]\n",
      "  [0.72360039]\n",
      "  [0.73163313]\n",
      "  [0.74054831]\n",
      "  [0.74912083]\n",
      "  [0.75606096]\n",
      "  [0.76420784]]]\n",
      "ejemplar: [0.70746928 0.71604687 0.72360039 0.73163313 0.74054831 0.74912083\n",
      " 0.75606096 0.76420784]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.77140486]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70746928 0.71604687 0.72360039 0.73163313 0.74054831 0.74912083\n",
      "  0.75606096 0.76420784]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013330441899597645\n",
      "Predicción post entrenamiento : [[0.77106154]]\n",
      "PERDIDAAAA despues: 0.013251282274723053\n",
      "loss en el callback: 0.001960364170372486, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71604687]\n",
      "  [0.72360039]\n",
      "  [0.73163313]\n",
      "  [0.74054831]\n",
      "  [0.74912083]\n",
      "  [0.75606096]\n",
      "  [0.76420784]\n",
      "  [0.77140486]]]\n",
      "ejemplar: [0.71604687 0.72360039 0.73163313 0.74054831 0.74912083 0.75606096\n",
      " 0.76420784 0.77140486]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.77833]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71604687 0.72360039 0.73163313 0.74054831 0.74912083 0.75606096\n",
      "  0.76420784 0.77140486]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009904900565743446\n",
      "Predicción post entrenamiento : [[0.7773861]]\n",
      "PERDIDAAAA despues: 0.0097179114818573\n",
      "loss en el callback: 0.01360384002327919, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.72360039]\n",
      "  [0.73163313]\n",
      "  [0.74054831]\n",
      "  [0.74912083]\n",
      "  [0.75606096]\n",
      "  [0.76420784]\n",
      "  [0.77140486]\n",
      "  [0.77833003]]]\n",
      "ejemplar: [0.72360039 0.73163313 0.74054831 0.74912083 0.75606096 0.76420784\n",
      " 0.77140486 0.77833003]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.78451735]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.72360039 0.73163313 0.74054831 0.74912083 0.75606096 0.76420784\n",
      "  0.77140486 0.77833003]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011755507439374924\n",
      "Predicción post entrenamiento : [[0.7838713]]\n",
      "PERDIDAAAA despues: 0.011615830473601818\n",
      "loss en el callback: 0.0062699164263904095, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.73163313]\n",
      "  [0.74054831]\n",
      "  [0.74912083]\n",
      "  [0.75606096]\n",
      "  [0.76420784]\n",
      "  [0.77140486]\n",
      "  [0.77833003]\n",
      "  [0.78451735]]]\n",
      "ejemplar: [0.73163313 0.74054831 0.74912083 0.75606096 0.76420784 0.77140486\n",
      " 0.77833003 0.78451735]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.79111344]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.73163313 0.74054831 0.74912083 0.75606096 0.76420784 0.77140486\n",
      "  0.77833003 0.78451735]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037885592319071293\n",
      "Predicción post entrenamiento : [[0.7908192]]\n",
      "PERDIDAAAA despues: 0.003752427874132991\n",
      "loss en el callback: 0.0013118807692080736, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.74054831]\n",
      "  [0.74912083]\n",
      "  [0.75606096]\n",
      "  [0.76420784]\n",
      "  [0.77140486]\n",
      "  [0.77833003]\n",
      "  [0.78451735]\n",
      "  [0.79111344]]]\n",
      "ejemplar: [0.74054831 0.74912083 0.75606096 0.76420784 0.77140486 0.77833003\n",
      " 0.78451735 0.79111344]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.79800504]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.74054831 0.74912083 0.75606096 0.76420784 0.77140486 0.77833003\n",
      "  0.78451735 0.79111344]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009356011636555195\n",
      "Predicción post entrenamiento : [[0.79692304]]\n",
      "PERDIDAAAA despues: 0.009147865697741508\n",
      "loss en el callback: 0.01726255752146244, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74912083]\n",
      "  [0.75606096]\n",
      "  [0.76420784]\n",
      "  [0.77140486]\n",
      "  [0.77833003]\n",
      "  [0.78451735]\n",
      "  [0.79111344]\n",
      "  [0.79800504]]]\n",
      "ejemplar: [0.74912083 0.75606096 0.76420784 0.77140486 0.77833003 0.78451735\n",
      " 0.79111344 0.79800504]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8037307]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74912083 0.75606096 0.76420784 0.77140486 0.77833003 0.78451735\n",
      "  0.79111344 0.79800504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013103483943268657\n",
      "Predicción post entrenamiento : [[0.8042877]]\n",
      "PERDIDAAAA despues: 0.0013509801356121898\n",
      "loss en el callback: 0.005968262907117605, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75606096]\n",
      "  [0.76420784]\n",
      "  [0.77140486]\n",
      "  [0.77833003]\n",
      "  [0.78451735]\n",
      "  [0.79111344]\n",
      "  [0.79800504]\n",
      "  [0.80373073]]]\n",
      "ejemplar: [0.75606096 0.76420784 0.77140486 0.77833003 0.78451735 0.79111344\n",
      " 0.79800504 0.80373073]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.8107196]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75606096 0.76420784 0.77140486 0.77833003 0.78451735 0.79111344\n",
      "  0.79800504 0.80373073]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030897946562618017\n",
      "Predicción post entrenamiento : [[0.8094801]]\n",
      "PERDIDAAAA despues: 0.0029535293579101562\n",
      "loss en el callback: 0.020629122853279114, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.76420784]\n",
      "  [0.77140486]\n",
      "  [0.77833003]\n",
      "  [0.78451735]\n",
      "  [0.79111344]\n",
      "  [0.79800504]\n",
      "  [0.80373073]\n",
      "  [0.81071961]]]\n",
      "ejemplar: [0.76420784 0.77140486 0.77833003 0.78451735 0.79111344 0.79800504\n",
      " 0.80373073 0.81071961]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.81592375]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.76420784 0.77140486 0.77833003 0.78451735 0.79111344 0.79800504\n",
      "  0.80373073 0.81071961]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0050216675736010075\n",
      "Predicción post entrenamiento : [[0.81572205]]\n",
      "PERDIDAAAA despues: 0.004993121139705181\n",
      "loss en el callback: 0.0007385556236840785, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.77140486]\n",
      "  [0.77833003]\n",
      "  [0.78451735]\n",
      "  [0.79111344]\n",
      "  [0.79800504]\n",
      "  [0.80373073]\n",
      "  [0.81071961]\n",
      "  [0.81592375]]]\n",
      "ejemplar: [0.77140486 0.77833003 0.78451735 0.79111344 0.79800504 0.80373073\n",
      " 0.81071961 0.81592375]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8217898]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.77140486 0.77833003 0.78451735 0.79111344 0.79800504 0.80373073\n",
      "  0.81071961 0.81592375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004865862429141998\n",
      "Predicción post entrenamiento : [[0.8208509]]\n",
      "PERDIDAAAA despues: 0.0047357575967907906\n",
      "loss en el callback: 0.013493319973349571, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.77833003]\n",
      "  [0.78451735]\n",
      "  [0.79111344]\n",
      "  [0.79800504]\n",
      "  [0.80373073]\n",
      "  [0.81071961]\n",
      "  [0.81592375]\n",
      "  [0.8217898 ]]]\n",
      "ejemplar: [0.77833003 0.78451735 0.79111344 0.79800504 0.80373073 0.81071961\n",
      " 0.81592375 0.8217898 ]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.82673514]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.77833003 0.78451735 0.79111344 0.79800504 0.80373073 0.81071961\n",
      "  0.81592375 0.8217898 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013673268258571625\n",
      "Predicción post entrenamiento : [[0.82446605]]\n",
      "PERDIDAAAA despues: 0.013147754594683647\n",
      "loss en el callback: 0.06610708683729172, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.78451735]\n",
      "  [0.79111344]\n",
      "  [0.79800504]\n",
      "  [0.80373073]\n",
      "  [0.81071961]\n",
      "  [0.81592375]\n",
      "  [0.8217898 ]\n",
      "  [0.82673514]]]\n",
      "ejemplar: [0.78451735 0.79111344 0.79800504 0.80373073 0.81071961 0.81592375\n",
      " 0.8217898  0.82673514]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.830187]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.78451735 0.79111344 0.79800504 0.80373073 0.81071961 0.81592375\n",
      "  0.8217898  0.82673514]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019532013684511185\n",
      "Predicción post entrenamiento : [[0.82964367]]\n",
      "PERDIDAAAA despues: 0.01938043162226677\n",
      "loss en el callback: 0.005471555050462484, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.79111344]\n",
      "  [0.79800504]\n",
      "  [0.80373073]\n",
      "  [0.81071961]\n",
      "  [0.81592375]\n",
      "  [0.8217898 ]\n",
      "  [0.82673514]\n",
      "  [0.83018702]]]\n",
      "ejemplar: [0.79111344 0.79800504 0.80373073 0.81071961 0.81592375 0.8217898\n",
      " 0.82673514 0.83018702]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.83535844]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.79111344 0.79800504 0.80373073 0.81071961 0.81592375 0.8217898\n",
      "  0.82673514 0.83018702]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006560946814715862\n",
      "Predicción post entrenamiento : [[0.8332564]]\n",
      "PERDIDAAAA despues: 0.006224839948117733\n",
      "loss en el callback: 0.05358831584453583, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.79800504]\n",
      "  [0.80373073]\n",
      "  [0.81071961]\n",
      "  [0.81592375]\n",
      "  [0.8217898 ]\n",
      "  [0.82673514]\n",
      "  [0.83018702]\n",
      "  [0.83535844]]]\n",
      "ejemplar: [0.79800504 0.80373073 0.81071961 0.81592375 0.8217898  0.82673514\n",
      " 0.83018702 0.83535844]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8387882]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.79800504 0.80373073 0.81071961 0.81592375 0.8217898  0.82673514\n",
      "  0.83018702 0.83535844]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013592650182545185\n",
      "Predicción post entrenamiento : [[0.8375575]]\n",
      "PERDIDAAAA despues: 0.013307192362844944\n",
      "loss en el callback: 0.024380359798669815, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.80373073]\n",
      "  [0.81071961]\n",
      "  [0.81592375]\n",
      "  [0.8217898 ]\n",
      "  [0.82673514]\n",
      "  [0.83018702]\n",
      "  [0.83535844]\n",
      "  [0.83878821]]]\n",
      "ejemplar: [0.80373073 0.81071961 0.81592375 0.8217898  0.82673514 0.83018702\n",
      " 0.83535844 0.83878821]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8427322]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.80373073 0.81071961 0.81592375 0.8217898  0.82673514 0.83018702\n",
      "  0.83535844 0.83878821]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.336410372867249e-05\n",
      "Predicción post entrenamiento : [[0.8432345]]\n",
      "PERDIDAAAA despues: 2.7813795895781368e-05\n",
      "loss en el callback: 0.004536010324954987, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.81071961]\n",
      "  [0.81592375]\n",
      "  [0.8217898 ]\n",
      "  [0.82673514]\n",
      "  [0.83018702]\n",
      "  [0.83535844]\n",
      "  [0.83878821]\n",
      "  [0.84273219]]]\n",
      "ejemplar: [0.81071961 0.81592375 0.8217898  0.82673514 0.83018702 0.83535844\n",
      " 0.83878821 0.84273219]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.84828854]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.81071961 0.81592375 0.8217898  0.82673514 0.83018702 0.83535844\n",
      "  0.83878821 0.84273219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003268917091190815\n",
      "Predicción post entrenamiento : [[0.84767884]]\n",
      "PERDIDAAAA despues: 0.0033390067983418703\n",
      "loss en el callback: 0.005142596084624529, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81592375]\n",
      "  [0.8217898 ]\n",
      "  [0.82673514]\n",
      "  [0.83018702]\n",
      "  [0.83535844]\n",
      "  [0.83878821]\n",
      "  [0.84273219]\n",
      "  [0.84828854]]]\n",
      "ejemplar: [0.81592375 0.8217898  0.82673514 0.83018702 0.83535844 0.83878821\n",
      " 0.84273219 0.84828854]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.852166]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81592375 0.8217898  0.82673514 0.83018702 0.83535844 0.83878821\n",
      "  0.84273219 0.84828854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009030156070366502\n",
      "Predicción post entrenamiento : [[0.85282385]]\n",
      "PERDIDAAAA despues: 0.0008639109437353909\n",
      "loss en el callback: 0.008658025413751602, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.8217898 ]\n",
      "  [0.82673514]\n",
      "  [0.83018702]\n",
      "  [0.83535844]\n",
      "  [0.83878821]\n",
      "  [0.84273219]\n",
      "  [0.84828854]\n",
      "  [0.852166  ]]]\n",
      "ejemplar: [0.8217898  0.82673514 0.83018702 0.83535844 0.83878821 0.84273219\n",
      " 0.84828854 0.852166  ]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8571599]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.8217898  0.82673514 0.83018702 0.83535844 0.83878821 0.84273219\n",
      "  0.84828854 0.852166  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025631708558648825\n",
      "Predicción post entrenamiento : [[0.8580975]]\n",
      "PERDIDAAAA despues: 0.002469114726409316\n",
      "loss en el callback: 0.018112054094672203, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82673514]\n",
      "  [0.83018702]\n",
      "  [0.83535844]\n",
      "  [0.83878821]\n",
      "  [0.84273219]\n",
      "  [0.84828854]\n",
      "  [0.852166  ]\n",
      "  [0.85715991]]]\n",
      "ejemplar: [0.82673514 0.83018702 0.83535844 0.83878821 0.84273219 0.84828854\n",
      " 0.852166   0.85715991]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8620456]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82673514 0.83018702 0.83535844 0.83878821 0.84273219 0.84828854\n",
      "  0.852166   0.85715991]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007580165402032435\n",
      "Predicción post entrenamiento : [[0.86254287]]\n",
      "PERDIDAAAA despues: 0.000730881467461586\n",
      "loss en el callback: 0.004802340641617775, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.83018702]\n",
      "  [0.83535844]\n",
      "  [0.83878821]\n",
      "  [0.84273219]\n",
      "  [0.84828854]\n",
      "  [0.852166  ]\n",
      "  [0.85715991]\n",
      "  [0.86204559]]]\n",
      "ejemplar: [0.83018702 0.83535844 0.83878821 0.84273219 0.84828854 0.852166\n",
      " 0.85715991 0.86204559]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8663225]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.83018702 0.83535844 0.83878821 0.84273219 0.84828854 0.852166\n",
      "  0.85715991 0.86204559]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.279786223080009e-05\n",
      "Predicción post entrenamiento : [[0.8662301]]\n",
      "PERDIDAAAA despues: 7.438395550707355e-05\n",
      "loss en el callback: 0.0001523023092886433, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.83535844]\n",
      "  [0.83878821]\n",
      "  [0.84273219]\n",
      "  [0.84828854]\n",
      "  [0.852166  ]\n",
      "  [0.85715991]\n",
      "  [0.86204559]\n",
      "  [0.86632252]]]\n",
      "ejemplar: [0.83535844 0.83878821 0.84273219 0.84828854 0.852166   0.85715991\n",
      " 0.86204559 0.86632252]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8702762]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.83535844 0.83878821 0.84273219 0.84828854 0.852166   0.85715991\n",
      "  0.86204559 0.86632252]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001843476784415543\n",
      "Predicción post entrenamiento : [[0.8703178]]\n",
      "PERDIDAAAA despues: 0.0018399059772491455\n",
      "loss en el callback: 3.1695071811554953e-05, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.83878821]\n",
      "  [0.84273219]\n",
      "  [0.84828854]\n",
      "  [0.852166  ]\n",
      "  [0.85715991]\n",
      "  [0.86204559]\n",
      "  [0.86632252]\n",
      "  [0.87027621]]]\n",
      "ejemplar: [0.83878821 0.84273219 0.84828854 0.852166   0.85715991 0.86204559\n",
      " 0.86632252 0.87027621]\n",
      "y: 1.0\n",
      "Predicción : [[0.8741613]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.83878821 0.84273219 0.84828854 0.852166   0.85715991 0.86204559\n",
      "  0.86632252 0.87027621]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01583537831902504\n",
      "Predicción post entrenamiento : [[0.8752557]]\n",
      "PERDIDAAAA despues: 0.015561139211058617\n",
      "loss en el callback: 0.0226239375770092, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.84273219]\n",
      "  [0.84828854]\n",
      "  [0.852166  ]\n",
      "  [0.85715991]\n",
      "  [0.86204559]\n",
      "  [0.86632252]\n",
      "  [0.87027621]\n",
      "  [0.8741613 ]]]\n",
      "ejemplar: [0.84273219 0.84828854 0.852166   0.85715991 0.86204559 0.86632252\n",
      " 0.87027621 0.8741613 ]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.87939304]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.84273219 0.84828854 0.852166   0.85715991 0.86204559 0.86632252\n",
      "  0.87027621 0.8741613 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008310330100357533\n",
      "Predicción post entrenamiento : [[0.88068736]]\n",
      "PERDIDAAAA despues: 0.008076023310422897\n",
      "loss en el callback: 0.03797724097967148, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.84828854]\n",
      "  [0.852166  ]\n",
      "  [0.85715991]\n",
      "  [0.86204559]\n",
      "  [0.86632252]\n",
      "  [0.87027621]\n",
      "  [0.8741613 ]\n",
      "  [0.87939304]]]\n",
      "ejemplar: [0.84828854 0.852166   0.85715991 0.86204559 0.86632252 0.87027621\n",
      " 0.8741613  0.87939304]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.88500553]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.84828854 0.852166   0.85715991 0.86204559 0.86632252 0.87027621\n",
      "  0.8741613  0.87939304]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4418978935282212e-05\n",
      "Predicción post entrenamiento : [[0.8856028]]\n",
      "PERDIDAAAA despues: 1.023996537696803e-05\n",
      "loss en el callback: 0.007847157306969166, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.852166  ]\n",
      "  [0.85715991]\n",
      "  [0.86204559]\n",
      "  [0.86632252]\n",
      "  [0.87027621]\n",
      "  [0.8741613 ]\n",
      "  [0.87939304]\n",
      "  [0.88500553]]]\n",
      "ejemplar: [0.852166   0.85715991 0.86204559 0.86632252 0.87027621 0.8741613\n",
      " 0.87939304 0.88500553]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8896394]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.852166   0.85715991 0.86204559 0.86632252 0.87027621 0.8741613\n",
      "  0.87939304 0.88500553]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001365409407299012\n",
      "Predicción post entrenamiento : [[0.88871443]]\n",
      "PERDIDAAAA despues: 0.00011578036355786026\n",
      "loss en el callback: 0.013321676291525364, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.85715991]\n",
      "  [0.86204559]\n",
      "  [0.86632252]\n",
      "  [0.87027621]\n",
      "  [0.8741613 ]\n",
      "  [0.87939304]\n",
      "  [0.88500553]\n",
      "  [0.88963938]]]\n",
      "ejemplar: [0.85715991 0.86204559 0.86632252 0.87027621 0.8741613  0.87939304\n",
      " 0.88500553 0.88963938]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.89293647]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.85715991 0.86204559 0.86632252 0.87027621 0.8741613  0.87939304\n",
      "  0.88500553 0.88963938]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001939581474289298\n",
      "Predicción post entrenamiento : [[0.89261174]]\n",
      "PERDIDAAAA despues: 0.00191108463332057\n",
      "loss en el callback: 0.001956855645403266, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.86204559]\n",
      "  [0.86632252]\n",
      "  [0.87027621]\n",
      "  [0.8741613 ]\n",
      "  [0.87939304]\n",
      "  [0.88500553]\n",
      "  [0.88963938]\n",
      "  [0.89293647]]]\n",
      "ejemplar: [0.86204559 0.86632252 0.87027621 0.8741613  0.87939304 0.88500553\n",
      " 0.88963938 0.89293647]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8967113]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.86204559 0.86632252 0.87027621 0.8741613  0.87939304 0.88500553\n",
      "  0.88963938 0.89293647]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003911064472049475\n",
      "Predicción post entrenamiento : [[0.89556295]]\n",
      "PERDIDAAAA despues: 0.0037687518633902073\n",
      "loss en el callback: 0.021330734714865685, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.86632252]\n",
      "  [0.87027621]\n",
      "  [0.8741613 ]\n",
      "  [0.87939304]\n",
      "  [0.88500553]\n",
      "  [0.88963938]\n",
      "  [0.89293647]\n",
      "  [0.89671129]]]\n",
      "ejemplar: [0.86632252 0.87027621 0.8741613  0.87939304 0.88500553 0.88963938\n",
      " 0.89293647 0.89671129]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.89954734]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.86632252 0.87027621 0.8741613  0.87939304 0.88500553 0.88963938\n",
      "  0.89293647 0.89671129]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001976018538698554\n",
      "Predicción post entrenamiento : [[0.8987539]]\n",
      "PERDIDAAAA despues: 0.0019061057828366756\n",
      "loss en el callback: 0.01105250883847475, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.87027621]\n",
      "  [0.8741613 ]\n",
      "  [0.87939304]\n",
      "  [0.88500553]\n",
      "  [0.88963938]\n",
      "  [0.89293647]\n",
      "  [0.89671129]\n",
      "  [0.89954734]]]\n",
      "ejemplar: [0.87027621 0.8741613  0.87939304 0.88500553 0.88963938 0.89293647\n",
      " 0.89671129 0.89954734]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9027774]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.87027621 0.8741613  0.87939304 0.88500553 0.88963938 0.89293647\n",
      "  0.89671129 0.89954734]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007581872632727027\n",
      "Predicción post entrenamiento : [[0.9022762]]\n",
      "PERDIDAAAA despues: 0.0007308395579457283\n",
      "loss en el callback: 0.00496670650318265, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.8741613 ]\n",
      "  [0.87939304]\n",
      "  [0.88500553]\n",
      "  [0.88963938]\n",
      "  [0.89293647]\n",
      "  [0.89671129]\n",
      "  [0.89954734]\n",
      "  [0.90277737]]]\n",
      "ejemplar: [0.8741613  0.87939304 0.88500553 0.88963938 0.89293647 0.89671129\n",
      " 0.89954734 0.90277737]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.90641695]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.8741613  0.87939304 0.88500553 0.88963938 0.89293647 0.89671129\n",
      "  0.89954734 0.90277737]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024388558231294155\n",
      "Predicción post entrenamiento : [[0.90555793]]\n",
      "PERDIDAAAA despues: 0.002354748547077179\n",
      "loss en el callback: 0.012557459063827991, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.87939304]\n",
      "  [0.88500553]\n",
      "  [0.88963938]\n",
      "  [0.89293647]\n",
      "  [0.89671129]\n",
      "  [0.89954734]\n",
      "  [0.90277737]\n",
      "  [0.90641695]]]\n",
      "ejemplar: [0.87939304 0.88500553 0.88963938 0.89293647 0.89671129 0.89954734\n",
      " 0.90277737 0.90641695]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9098138]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.87939304 0.88500553 0.88963938 0.89293647 0.89671129 0.89954734\n",
      "  0.90277737 0.90641695]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003570741740986705\n",
      "Predicción post entrenamiento : [[0.9101229]]\n",
      "PERDIDAAAA despues: 0.003607772057875991\n",
      "loss en el callback: 0.0023433028254657984, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.88500553]\n",
      "  [0.88963938]\n",
      "  [0.89293647]\n",
      "  [0.89671129]\n",
      "  [0.89954734]\n",
      "  [0.90277737]\n",
      "  [0.90641695]\n",
      "  [0.90981382]]]\n",
      "ejemplar: [0.88500553 0.88963938 0.89293647 0.89671129 0.89954734 0.90277737\n",
      " 0.90641695 0.90981382]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9140565]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.88500553 0.88963938 0.89293647 0.89671129 0.89954734 0.90277737\n",
      "  0.90641695 0.90981382]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005092231556773186\n",
      "Predicción post entrenamiento : [[0.91428065]]\n",
      "PERDIDAAAA despues: 0.0051242755725979805\n",
      "loss en el callback: 0.001246448839083314, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.88963938]\n",
      "  [0.89293647]\n",
      "  [0.89671129]\n",
      "  [0.89954734]\n",
      "  [0.90277737]\n",
      "  [0.90641695]\n",
      "  [0.90981382]\n",
      "  [0.91405648]]]\n",
      "ejemplar: [0.88963938 0.89293647 0.89671129 0.89954734 0.90277737 0.90641695\n",
      " 0.90981382 0.91405648]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.91769063]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.88963938 0.89293647 0.89671129 0.89954734 0.90277737 0.90641695\n",
      "  0.90981382 0.91405648]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008978283032774925\n",
      "Predicción post entrenamiento : [[0.91794753]]\n",
      "PERDIDAAAA despues: 0.009027033112943172\n",
      "loss en el callback: 0.0018756826175376773, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.89293647]\n",
      "  [0.89671129]\n",
      "  [0.89954734]\n",
      "  [0.90277737]\n",
      "  [0.90641695]\n",
      "  [0.90981382]\n",
      "  [0.91405648]\n",
      "  [0.91769063]]]\n",
      "ejemplar: [0.89293647 0.89671129 0.89954734 0.90277737 0.90641695 0.90981382\n",
      " 0.91405648 0.91769063]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9210396]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.89293647 0.89671129 0.89954734 0.90277737 0.90641695 0.90981382\n",
      "  0.91405648 0.91769063]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021472081542015076\n",
      "Predicción post entrenamiento : [[0.9204725]]\n",
      "PERDIDAAAA despues: 0.02130621112883091\n",
      "loss en el callback: 0.007415639702230692, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.89671129]\n",
      "  [0.89954734]\n",
      "  [0.90277737]\n",
      "  [0.90641695]\n",
      "  [0.90981382]\n",
      "  [0.91405648]\n",
      "  [0.91769063]\n",
      "  [0.92103958]]]\n",
      "ejemplar: [0.89671129 0.89954734 0.90277737 0.90641695 0.90981382 0.91405648\n",
      " 0.91769063 0.92103958]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.92360806]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.89671129 0.89954734 0.90277737 0.90641695 0.90981382 0.91405648\n",
      "  0.91769063 0.92103958]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019436798989772797\n",
      "Predicción post entrenamiento : [[0.92323184]]\n",
      "PERDIDAAAA despues: 0.01933203637599945\n",
      "loss en el callback: 0.003504109336063266, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.89954734]\n",
      "  [0.90277737]\n",
      "  [0.90641695]\n",
      "  [0.90981382]\n",
      "  [0.91405648]\n",
      "  [0.91769063]\n",
      "  [0.92103958]\n",
      "  [0.92360806]]]\n",
      "ejemplar: [0.89954734 0.90277737 0.90641695 0.90981382 0.91405648 0.91769063\n",
      " 0.92103958 0.92360806]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9262756]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.89954734 0.90277737 0.90641695 0.90981382 0.91405648 0.91769063\n",
      "  0.92103958 0.92360806]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004426414147019386\n",
      "Predicción post entrenamiento : [[0.9250848]]\n",
      "PERDIDAAAA despues: 0.004269383382052183\n",
      "loss en el callback: 0.027101092040538788, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.90277737]\n",
      "  [0.90641695]\n",
      "  [0.90981382]\n",
      "  [0.91405648]\n",
      "  [0.91769063]\n",
      "  [0.92103958]\n",
      "  [0.92360806]\n",
      "  [0.92627561]]]\n",
      "ejemplar: [0.90277737 0.90641695 0.90981382 0.91405648 0.91769063 0.92103958\n",
      " 0.92360806 0.92627561]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9283045]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.90277737 0.90641695 0.90981382 0.91405648 0.91769063 0.92103958\n",
      "  0.92360806 0.92627561]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005473698023706675\n",
      "Predicción post entrenamiento : [[0.92820317]]\n",
      "PERDIDAAAA despues: 0.005458714906126261\n",
      "loss en el callback: 0.0002543272275943309, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.90641695]\n",
      "  [0.90981382]\n",
      "  [0.91405648]\n",
      "  [0.91769063]\n",
      "  [0.92103958]\n",
      "  [0.92360806]\n",
      "  [0.92627561]\n",
      "  [0.92830449]]]\n",
      "ejemplar: [0.90641695 0.90981382 0.91405648 0.91769063 0.92103958 0.92360806\n",
      " 0.92627561 0.92830449]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9314869]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.90641695 0.90981382 0.91405648 0.91769063 0.92103958 0.92360806\n",
      "  0.92627561 0.92830449]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00894953589886427\n",
      "Predicción post entrenamiento : [[0.9307598]]\n",
      "PERDIDAAAA despues: 0.008812491782009602\n",
      "loss en el callback: 0.01151785347610712, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.90981382]\n",
      "  [0.91405648]\n",
      "  [0.91769063]\n",
      "  [0.92103958]\n",
      "  [0.92360806]\n",
      "  [0.92627561]\n",
      "  [0.92830449]\n",
      "  [0.9314869 ]]]\n",
      "ejemplar: [0.90981382 0.91405648 0.91769063 0.92103958 0.92360806 0.92627561\n",
      " 0.92830449 0.9314869 ]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.93396306]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.90981382 0.91405648 0.91769063 0.92103958 0.92360806 0.92627561\n",
      "  0.92830449 0.9314869 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010826857760548592\n",
      "Predicción post entrenamiento : [[0.9318165]]\n",
      "PERDIDAAAA despues: 0.010384759865701199\n",
      "loss en el callback: 0.07833390682935715, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.91405648]\n",
      "  [0.91769063]\n",
      "  [0.92103958]\n",
      "  [0.92360806]\n",
      "  [0.92627561]\n",
      "  [0.92830449]\n",
      "  [0.9314869 ]\n",
      "  [0.93396306]]]\n",
      "ejemplar: [0.91405648 0.91769063 0.92103958 0.92360806 0.92627561 0.92830449\n",
      " 0.9314869  0.93396306]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9349652]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.91405648 0.91769063 0.92103958 0.92360806 0.92627561 0.92830449\n",
      "  0.9314869  0.93396306]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002276454586535692\n",
      "Predicción post entrenamiento : [[0.93497366]]\n",
      "PERDIDAAAA despues: 0.002277262508869171\n",
      "loss en el callback: 1.8036807887256145e-06, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.91769063]\n",
      "  [0.92103958]\n",
      "  [0.92360806]\n",
      "  [0.92627561]\n",
      "  [0.92830449]\n",
      "  [0.9314869 ]\n",
      "  [0.93396306]\n",
      "  [0.93496519]]]\n",
      "ejemplar: [0.91769063 0.92103958 0.92360806 0.92627561 0.92830449 0.9314869\n",
      " 0.93396306 0.93496519]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9377625]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.91769063 0.92103958 0.92360806 0.92627561 0.92830449 0.9314869\n",
      "  0.93396306 0.93496519]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006086837500333786\n",
      "Predicción post entrenamiento : [[0.936762]]\n",
      "PERDIDAAAA despues: 0.005931720603257418\n",
      "loss en el callback: 0.020759230479598045, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.92103958]\n",
      "  [0.92360806]\n",
      "  [0.92627561]\n",
      "  [0.92830449]\n",
      "  [0.9314869 ]\n",
      "  [0.93396306]\n",
      "  [0.93496519]\n",
      "  [0.9377625 ]]]\n",
      "ejemplar: [0.92103958 0.92360806 0.92627561 0.92830449 0.9314869  0.93396306\n",
      " 0.93496519 0.9377625 ]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9392866]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.92103958 0.92360806 0.92627561 0.92830449 0.9314869  0.93396306\n",
      "  0.93496519 0.9377625 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009938005357980728\n",
      "Predicción post entrenamiento : [[0.9388357]]\n",
      "PERDIDAAAA despues: 0.009848306886851788\n",
      "loss en el callback: 0.005250399000942707, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.92360806]\n",
      "  [0.92627561]\n",
      "  [0.92830449]\n",
      "  [0.9314869 ]\n",
      "  [0.93396306]\n",
      "  [0.93496519]\n",
      "  [0.9377625 ]\n",
      "  [0.93928659]]]\n",
      "ejemplar: [0.92360806 0.92627561 0.92830449 0.9314869  0.93396306 0.93496519\n",
      " 0.9377625  0.93928659]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9411172]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.92360806 0.92627561 0.92830449 0.9314869  0.93396306 0.93496519\n",
      "  0.9377625  0.93928659]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024747226387262344\n",
      "Predicción post entrenamiento : [[0.94049776]]\n",
      "PERDIDAAAA despues: 0.024552708491683006\n",
      "loss en el callback: 0.0099250553175807, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.92627561]\n",
      "  [0.92830449]\n",
      "  [0.9314869 ]\n",
      "  [0.93396306]\n",
      "  [0.93496519]\n",
      "  [0.9377625 ]\n",
      "  [0.93928659]\n",
      "  [0.94111723]]]\n",
      "ejemplar: [0.92627561 0.92830449 0.9314869  0.93396306 0.93496519 0.9377625\n",
      " 0.93928659 0.94111723]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9427155]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.92627561 0.92830449 0.9314869  0.93396306 0.93496519 0.9377625\n",
      "  0.93928659 0.94111723]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015482335351407528\n",
      "Predicción post entrenamiento : [[0.94101787]]\n",
      "PERDIDAAAA despues: 0.015062744729220867\n",
      "loss en el callback: 0.05923623591661453, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.92830449]\n",
      "  [0.9314869 ]\n",
      "  [0.93396306]\n",
      "  [0.93496519]\n",
      "  [0.9377625 ]\n",
      "  [0.93928659]\n",
      "  [0.94111723]\n",
      "  [0.94271553]]]\n",
      "ejemplar: [0.92830449 0.9314869  0.93396306 0.93496519 0.9377625  0.93928659\n",
      " 0.94111723 0.94271553]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.94310915]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.92830449 0.9314869  0.93396306 0.93496519 0.9377625  0.93928659\n",
      "  0.94111723 0.94271553]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0230866651982069\n",
      "Predicción post entrenamiento : [[0.9414797]]\n",
      "PERDIDAAAA despues: 0.0225941464304924\n",
      "loss en el callback: 0.05348937585949898, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.9314869 ]\n",
      "  [0.93396306]\n",
      "  [0.93496519]\n",
      "  [0.9377625 ]\n",
      "  [0.93928659]\n",
      "  [0.94111723]\n",
      "  [0.94271553]\n",
      "  [0.94310915]]]\n",
      "ejemplar: [0.9314869  0.93396306 0.93496519 0.9377625  0.93928659 0.94111723\n",
      " 0.94271553 0.94310915]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9435908]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.9314869  0.93396306 0.93496519 0.9377625  0.93928659 0.94111723\n",
      "  0.94271553 0.94310915]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0335010327398777\n",
      "Predicción post entrenamiento : [[0.9429735]]\n",
      "PERDIDAAAA despues: 0.033275432884693146\n",
      "loss en el callback: 0.010392974130809307, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.93396306]\n",
      "  [0.93496519]\n",
      "  [0.9377625 ]\n",
      "  [0.93928659]\n",
      "  [0.94111723]\n",
      "  [0.94271553]\n",
      "  [0.94310915]\n",
      "  [0.94359082]]]\n",
      "ejemplar: [0.93396306 0.93496519 0.9377625  0.93928659 0.94111723 0.94271553\n",
      " 0.94310915 0.94359082]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.94471836]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.93396306 0.93496519 0.9377625  0.93928659 0.94111723 0.94271553\n",
      "  0.94310915 0.94359082]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0234594214707613\n",
      "Predicción post entrenamiento : [[0.9433673]]\n",
      "PERDIDAAAA despues: 0.023047376424074173\n",
      "loss en el callback: 0.0446355827152729, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.93496519]\n",
      "  [0.9377625 ]\n",
      "  [0.93928659]\n",
      "  [0.94111723]\n",
      "  [0.94271553]\n",
      "  [0.94310915]\n",
      "  [0.94359082]\n",
      "  [0.94471836]]]\n",
      "ejemplar: [0.93496519 0.9377625  0.93928659 0.94111723 0.94271553 0.94310915\n",
      " 0.94359082 0.94471836]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9448694]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.93496519 0.9377625  0.93928659 0.94111723 0.94271553 0.94310915\n",
      "  0.94359082 0.94471836]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031037671491503716\n",
      "Predicción post entrenamiento : [[0.94424313]]\n",
      "PERDIDAAAA despues: 0.03081739880144596\n",
      "loss en el callback: 0.011990966275334358, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.9377625 ]\n",
      "  [0.93928659]\n",
      "  [0.94111723]\n",
      "  [0.94271553]\n",
      "  [0.94310915]\n",
      "  [0.94359082]\n",
      "  [0.94471836]\n",
      "  [0.9448694 ]]]\n",
      "ejemplar: [0.9377625  0.93928659 0.94111723 0.94271553 0.94310915 0.94359082\n",
      " 0.94471836 0.9448694 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9458797]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.9377625  0.93928659 0.94111723 0.94271553 0.94310915 0.94359082\n",
      "  0.94471836 0.9448694 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03139467164874077\n",
      "Predicción post entrenamiento : [[0.94491357]]\n",
      "PERDIDAAAA despues: 0.03105323575437069\n",
      "loss en el callback: 0.023903729394078255, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.93928659]\n",
      "  [0.94111723]\n",
      "  [0.94271553]\n",
      "  [0.94310915]\n",
      "  [0.94359082]\n",
      "  [0.94471836]\n",
      "  [0.9448694 ]\n",
      "  [0.9458797 ]]]\n",
      "ejemplar: [0.93928659 0.94111723 0.94271553 0.94310915 0.94359082 0.94471836\n",
      " 0.9448694  0.9458797 ]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.94612]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.93928659 0.94111723 0.94271553 0.94310915 0.94359082 0.94471836\n",
      "  0.9448694  0.9458797 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02166927605867386\n",
      "Predicción post entrenamiento : [[0.94609934]]\n",
      "PERDIDAAAA despues: 0.021663187071681023\n",
      "loss en el callback: 1.4555553207173944e-05, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.94111723]\n",
      "  [0.94271553]\n",
      "  [0.94310915]\n",
      "  [0.94359082]\n",
      "  [0.94471836]\n",
      "  [0.9448694 ]\n",
      "  [0.9458797 ]\n",
      "  [0.94612002]]]\n",
      "ejemplar: [0.94111723 0.94271553 0.94310915 0.94359082 0.94471836 0.9448694\n",
      " 0.9458797  0.94612002]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.94716525]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.94111723 0.94271553 0.94310915 0.94359082 0.94471836 0.9448694\n",
      "  0.9458797  0.94612002]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02469969168305397\n",
      "Predicción post entrenamiento : [[0.9453178]]\n",
      "PERDIDAAAA despues: 0.024122409522533417\n",
      "loss en el callback: 0.07514620572328568, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.94271553]\n",
      "  [0.94310915]\n",
      "  [0.94359082]\n",
      "  [0.94471836]\n",
      "  [0.9448694 ]\n",
      "  [0.9458797 ]\n",
      "  [0.94612002]\n",
      "  [0.94716525]]]\n",
      "ejemplar: [0.94271553 0.94310915 0.94359082 0.94471836 0.9448694  0.9458797\n",
      " 0.94612002 0.94716525]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.94610596]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.94271553 0.94310915 0.94359082 0.94471836 0.9448694  0.9458797\n",
      "  0.94612002 0.94716525]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03457200899720192\n",
      "Predicción post entrenamiento : [[0.9457407]]\n",
      "PERDIDAAAA despues: 0.034436315298080444\n",
      "loss en el callback: 0.004420546814799309, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.94310915]\n",
      "  [0.94359082]\n",
      "  [0.94471836]\n",
      "  [0.9448694 ]\n",
      "  [0.9458797 ]\n",
      "  [0.94612002]\n",
      "  [0.94716525]\n",
      "  [0.94610596]]]\n",
      "ejemplar: [0.94310915 0.94359082 0.94471836 0.9448694  0.9458797  0.94612002\n",
      " 0.94716525 0.94610596]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.94626]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.94310915 0.94359082 0.94471836 0.9448694  0.9458797  0.94612002\n",
      "  0.94716525 0.94610596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06805143505334854\n",
      "Predicción post entrenamiento : [[0.94332415]]\n",
      "PERDIDAAAA despues: 0.0665283352136612\n",
      "loss en el callback: 0.18288098275661469, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.94359082]\n",
      "  [0.94471836]\n",
      "  [0.9448694 ]\n",
      "  [0.9458797 ]\n",
      "  [0.94612002]\n",
      "  [0.94716525]\n",
      "  [0.94610596]\n",
      "  [0.94625998]]]\n",
      "ejemplar: [0.94359082 0.94471836 0.9448694  0.9458797  0.94612002 0.94716525\n",
      " 0.94610596 0.94625998]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9438847]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.94359082 0.94471836 0.9448694  0.9458797  0.94612002 0.94716525\n",
      "  0.94610596 0.94625998]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11471288651227951\n",
      "Predicción post entrenamiento : [[0.9413942]]\n",
      "PERDIDAAAA despues: 0.11303208023309708\n",
      "loss en el callback: 0.15681569278240204, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.94471836]\n",
      "  [0.9448694 ]\n",
      "  [0.9458797 ]\n",
      "  [0.94612002]\n",
      "  [0.94716525]\n",
      "  [0.94610596]\n",
      "  [0.94625998]\n",
      "  [0.94388467]]]\n",
      "ejemplar: [0.94471836 0.9448694  0.9458797  0.94612002 0.94716525 0.94610596\n",
      " 0.94625998 0.94388467]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.94194156]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.94471836 0.9448694  0.9458797  0.94612002 0.94716525 0.94610596\n",
      "  0.94625998 0.94388467]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0767749771475792\n",
      "Predicción post entrenamiento : [[0.939952]]\n",
      "PERDIDAAAA despues: 0.07567639648914337\n",
      "loss en el callback: 0.09905976802110672, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.9448694 ]\n",
      "  [0.9458797 ]\n",
      "  [0.94612002]\n",
      "  [0.94716525]\n",
      "  [0.94610596]\n",
      "  [0.94625998]\n",
      "  [0.94388467]\n",
      "  [0.94194156]]]\n",
      "ejemplar: [0.9448694  0.9458797  0.94612002 0.94716525 0.94610596 0.94625998\n",
      " 0.94388467 0.94194156]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9402365]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.9448694  0.9458797  0.94612002 0.94716525 0.94610596 0.94625998\n",
      "  0.94388467 0.94194156]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053996436297893524\n",
      "Predicción post entrenamiento : [[0.9371853]]\n",
      "PERDIDAAAA despues: 0.05258771404623985\n",
      "loss en el callback: 0.20441250503063202, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.9458797 ]\n",
      "  [0.94612002]\n",
      "  [0.94716525]\n",
      "  [0.94610596]\n",
      "  [0.94625998]\n",
      "  [0.94388467]\n",
      "  [0.94194156]\n",
      "  [0.94023651]]]\n",
      "ejemplar: [0.9458797  0.94612002 0.94716525 0.94610596 0.94625998 0.94388467\n",
      " 0.94194156 0.94023651]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.93740094]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.9458797  0.94612002 0.94716525 0.94610596 0.94625998 0.94388467\n",
      "  0.94194156 0.94023651]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07427933812141418\n",
      "Predicción post entrenamiento : [[0.93569463]]\n",
      "PERDIDAAAA despues: 0.07335216552019119\n",
      "loss en el callback: 0.07403210550546646, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.94612002]\n",
      "  [0.94716525]\n",
      "  [0.94610596]\n",
      "  [0.94625998]\n",
      "  [0.94388467]\n",
      "  [0.94194156]\n",
      "  [0.94023651]\n",
      "  [0.93740094]]]\n",
      "ejemplar: [0.94612002 0.94716525 0.94610596 0.94625998 0.94388467 0.94194156\n",
      " 0.94023651 0.93740094]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9354961]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.94612002 0.94716525 0.94610596 0.94625998 0.94388467 0.94194156\n",
      "  0.94023651 0.93740094]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050240498036146164\n",
      "Predicción post entrenamiento : [[0.932632]]\n",
      "PERDIDAAAA despues: 0.04896477609872818\n",
      "loss en el callback: 0.17504678666591644, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.94716525]\n",
      "  [0.94610596]\n",
      "  [0.94625998]\n",
      "  [0.94388467]\n",
      "  [0.94194156]\n",
      "  [0.94023651]\n",
      "  [0.93740094]\n",
      "  [0.93549609]]]\n",
      "ejemplar: [0.94716525 0.94610596 0.94625998 0.94388467 0.94194156 0.94023651\n",
      " 0.93740094 0.93549609]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9321174]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.94716525 0.94610596 0.94625998 0.94388467 0.94194156 0.94023651\n",
      "  0.93740094 0.93549609]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06495388597249985\n",
      "Predicción post entrenamiento : [[0.9303279]]\n",
      "PERDIDAAAA despues: 0.06404493749141693\n",
      "loss en el callback: 0.08588102459907532, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.94610596]\n",
      "  [0.94625998]\n",
      "  [0.94388467]\n",
      "  [0.94194156]\n",
      "  [0.94023651]\n",
      "  [0.93740094]\n",
      "  [0.93549609]\n",
      "  [0.9321174 ]]]\n",
      "ejemplar: [0.94610596 0.94625998 0.94388467 0.94194156 0.94023651 0.93740094\n",
      " 0.93549609 0.9321174 ]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.92913693]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.94610596 0.94625998 0.94388467 0.94194156 0.94023651 0.93740094\n",
      "  0.93549609 0.9321174 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02789875492453575\n",
      "Predicción post entrenamiento : [[0.9282807]]\n",
      "PERDIDAAAA despues: 0.027613459154963493\n",
      "loss en el callback: 0.021937375888228416, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.94625998]\n",
      "  [0.94388467]\n",
      "  [0.94194156]\n",
      "  [0.94023651]\n",
      "  [0.93740094]\n",
      "  [0.93549609]\n",
      "  [0.9321174 ]\n",
      "  [0.92913693]]]\n",
      "ejemplar: [0.94625998 0.94388467 0.94194156 0.94023651 0.93740094 0.93549609\n",
      " 0.9321174  0.92913693]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.92688906]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.94625998 0.94388467 0.94194156 0.94023651 0.93740094 0.93549609\n",
      "  0.9321174  0.92913693]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014361031353473663\n",
      "Predicción post entrenamiento : [[0.9254441]]\n",
      "PERDIDAAAA despues: 0.014016804285347462\n",
      "loss en el callback: 0.052538927644491196, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.94388467]\n",
      "  [0.94194156]\n",
      "  [0.94023651]\n",
      "  [0.93740094]\n",
      "  [0.93549609]\n",
      "  [0.9321174 ]\n",
      "  [0.92913693]\n",
      "  [0.92688906]]]\n",
      "ejemplar: [0.94388467 0.94194156 0.94023651 0.93740094 0.93549609 0.9321174\n",
      " 0.92913693 0.92688906]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.92341405]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.94388467 0.94194156 0.94023651 0.93740094 0.93549609 0.9321174\n",
      "  0.92913693 0.92688906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011712892912328243\n",
      "Predicción post entrenamiento : [[0.92355967]]\n",
      "PERDIDAAAA despues: 0.011744433082640171\n",
      "loss en el callback: 0.0008255964494310319, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.94194156]\n",
      "  [0.94023651]\n",
      "  [0.93740094]\n",
      "  [0.93549609]\n",
      "  [0.9321174 ]\n",
      "  [0.92913693]\n",
      "  [0.92688906]\n",
      "  [0.92341405]]]\n",
      "ejemplar: [0.94194156 0.94023651 0.93740094 0.93549609 0.9321174  0.92913693\n",
      " 0.92688906 0.92341405]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9215266]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.94194156 0.94023651 0.93740094 0.93549609 0.9321174  0.92913693\n",
      "  0.92688906 0.92341405]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002337446785531938\n",
      "Predicción post entrenamiento : [[0.92247856]]\n",
      "PERDIDAAAA despues: 0.0002637589059304446\n",
      "loss en el callback: 0.046332236379384995, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.94023651]\n",
      "  [0.93740094]\n",
      "  [0.93549609]\n",
      "  [0.9321174 ]\n",
      "  [0.92913693]\n",
      "  [0.92688906]\n",
      "  [0.92341405]\n",
      "  [0.92152661]]]\n",
      "ejemplar: [0.94023651 0.93740094 0.93549609 0.9321174  0.92913693 0.92688906\n",
      " 0.92341405 0.92152661]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.92029184]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.94023651 0.93740094 0.93549609 0.9321174  0.92913693 0.92688906\n",
      "  0.92341405 0.92152661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015534389531239867\n",
      "Predicción post entrenamiento : [[0.92007226]]\n",
      "PERDIDAAAA despues: 0.0015707963611930609\n",
      "loss en el callback: 0.0014055276988074183, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.93740094]\n",
      "  [0.93549609]\n",
      "  [0.9321174 ]\n",
      "  [0.92913693]\n",
      "  [0.92688906]\n",
      "  [0.92341405]\n",
      "  [0.92152661]\n",
      "  [0.92029184]]]\n",
      "ejemplar: [0.93740094 0.93549609 0.9321174  0.92913693 0.92688906 0.92341405\n",
      " 0.92152661 0.92029184]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.91763496]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.93740094 0.93549609 0.9321174  0.92913693 0.92688906 0.92341405\n",
      "  0.92152661 0.92029184]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021827497985213995\n",
      "Predicción post entrenamiento : [[0.9179987]]\n",
      "PERDIDAAAA despues: 0.002148897387087345\n",
      "loss en el callback: 0.004204297438263893, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.93549609]\n",
      "  [0.9321174 ]\n",
      "  [0.92913693]\n",
      "  [0.92688906]\n",
      "  [0.92341405]\n",
      "  [0.92152661]\n",
      "  [0.92029184]\n",
      "  [0.91763496]]]\n",
      "ejemplar: [0.93549609 0.9321174  0.92913693 0.92688906 0.92341405 0.92152661\n",
      " 0.92029184 0.91763496]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9156218]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.93549609 0.9321174  0.92913693 0.92688906 0.92341405 0.92152661\n",
      "  0.92029184 0.91763496]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000761423900257796\n",
      "Predicción post entrenamiento : [[0.91519296]]\n",
      "PERDIDAAAA despues: 0.0007379402522929013\n",
      "loss en el callback: 0.005380617920309305, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.9321174 ]\n",
      "  [0.92913693]\n",
      "  [0.92688906]\n",
      "  [0.92341405]\n",
      "  [0.92152661]\n",
      "  [0.92029184]\n",
      "  [0.91763496]\n",
      "  [0.91562182]]]\n",
      "ejemplar: [0.9321174  0.92913693 0.92688906 0.92341405 0.92152661 0.92029184\n",
      " 0.91763496 0.91562182]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9126241]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.9321174  0.92913693 0.92688906 0.92341405 0.92152661 0.92029184\n",
      "  0.91763496 0.91562182]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039787773857824504\n",
      "Predicción post entrenamiento : [[0.91224277]]\n",
      "PERDIDAAAA despues: 0.000382809666916728\n",
      "loss en el callback: 0.004577396437525749, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.92913693]\n",
      "  [0.92688906]\n",
      "  [0.92341405]\n",
      "  [0.92152661]\n",
      "  [0.92029184]\n",
      "  [0.91763496]\n",
      "  [0.91562182]\n",
      "  [0.91262412]]]\n",
      "ejemplar: [0.92913693 0.92688906 0.92341405 0.92152661 0.92029184 0.91763496\n",
      " 0.91562182 0.91262412]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.90991575]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.92913693 0.92688906 0.92341405 0.92152661 0.92029184 0.91763496\n",
      "  0.91562182 0.91262412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001202256535179913\n",
      "Predicción post entrenamiento : [[0.9108009]]\n",
      "PERDIDAAAA despues: 0.001264421152882278\n",
      "loss en el callback: 0.041361335664987564, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.92688906]\n",
      "  [0.92341405]\n",
      "  [0.92152661]\n",
      "  [0.92029184]\n",
      "  [0.91763496]\n",
      "  [0.91562182]\n",
      "  [0.91262412]\n",
      "  [0.90991575]]]\n",
      "ejemplar: [0.92688906 0.92341405 0.92152661 0.92029184 0.91763496 0.91562182\n",
      " 0.91262412 0.90991575]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9086414]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.92688906 0.92341405 0.92152661 0.92029184 0.91763496 0.91562182\n",
      "  0.91262412 0.90991575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033418110106140375\n",
      "Predicción post entrenamiento : [[0.909067]]\n",
      "PERDIDAAAA despues: 0.003391196019947529\n",
      "loss en el callback: 0.009277043864130974, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.92341405]\n",
      "  [0.92152661]\n",
      "  [0.92029184]\n",
      "  [0.91763496]\n",
      "  [0.91562182]\n",
      "  [0.91262412]\n",
      "  [0.90991575]\n",
      "  [0.9086414 ]]]\n",
      "ejemplar: [0.92341405 0.92152661 0.92029184 0.91763496 0.91562182 0.91262412\n",
      " 0.90991575 0.9086414 ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.90688753]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.92341405 0.92152661 0.92029184 0.91763496 0.91562182 0.91262412\n",
      "  0.90991575 0.9086414 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033630423713475466\n",
      "Predicción post entrenamiento : [[0.90681684]]\n",
      "PERDIDAAAA despues: 0.003354848362505436\n",
      "loss en el callback: 0.00017970427870750427, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.92152661]\n",
      "  [0.92029184]\n",
      "  [0.91763496]\n",
      "  [0.91562182]\n",
      "  [0.91262412]\n",
      "  [0.90991575]\n",
      "  [0.9086414 ]\n",
      "  [0.90688753]]]\n",
      "ejemplar: [0.92152661 0.92029184 0.91763496 0.91562182 0.91262412 0.90991575\n",
      " 0.9086414  0.90688753]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.90499145]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.92152661 0.92029184 0.91763496 0.91562182 0.91262412 0.90991575\n",
      "  0.9086414  0.90688753]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032977701630443335\n",
      "Predicción post entrenamiento : [[0.90545774]]\n",
      "PERDIDAAAA despues: 0.003244433319196105\n",
      "loss en el callback: 0.008348343893885612, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.92029184]\n",
      "  [0.91763496]\n",
      "  [0.91562182]\n",
      "  [0.91262412]\n",
      "  [0.90991575]\n",
      "  [0.9086414 ]\n",
      "  [0.90688753]\n",
      "  [0.90499145]]]\n",
      "ejemplar: [0.92029184 0.91763496 0.91562182 0.91262412 0.90991575 0.9086414\n",
      " 0.90688753 0.90499145]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9035634]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.92029184 0.91763496 0.91562182 0.91262412 0.90991575 0.9086414\n",
      "  0.90688753 0.90499145]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004131731111556292\n",
      "Predicción post entrenamiento : [[0.9037029]]\n",
      "PERDIDAAAA despues: 0.00411381246522069\n",
      "loss en el callback: 0.0006323666893877089, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.91763496]\n",
      "  [0.91562182]\n",
      "  [0.91262412]\n",
      "  [0.90991575]\n",
      "  [0.9086414 ]\n",
      "  [0.90688753]\n",
      "  [0.90499145]\n",
      "  [0.90356338]]]\n",
      "ejemplar: [0.91763496 0.91562182 0.91262412 0.90991575 0.9086414  0.90688753\n",
      " 0.90499145 0.90356338]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.90154153]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.91763496 0.91562182 0.91262412 0.90991575 0.9086414  0.90688753\n",
      "  0.90499145 0.90356338]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015350055182352662\n",
      "Predicción post entrenamiento : [[0.9014913]]\n",
      "PERDIDAAAA despues: 0.0015389452455565333\n",
      "loss en el callback: 8.545639866497368e-05, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.91562182]\n",
      "  [0.91262412]\n",
      "  [0.90991575]\n",
      "  [0.9086414 ]\n",
      "  [0.90688753]\n",
      "  [0.90499145]\n",
      "  [0.90356338]\n",
      "  [0.90154153]]]\n",
      "ejemplar: [0.91562182 0.91262412 0.90991575 0.9086414  0.90688753 0.90499145\n",
      " 0.90356338 0.90154153]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.89946896]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.91562182 0.91262412 0.90991575 0.9086414  0.90688753 0.90499145\n",
      "  0.90356338 0.90154153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005332257132977247\n",
      "Predicción post entrenamiento : [[0.9001368]]\n",
      "PERDIDAAAA despues: 0.005235164426267147\n",
      "loss en el callback: 0.017110124230384827, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.91262412]\n",
      "  [0.90991575]\n",
      "  [0.9086414 ]\n",
      "  [0.90688753]\n",
      "  [0.90499145]\n",
      "  [0.90356338]\n",
      "  [0.90154153]\n",
      "  [0.89946896]]]\n",
      "ejemplar: [0.91262412 0.90991575 0.9086414  0.90688753 0.90499145 0.90356338\n",
      " 0.90154153 0.89946896]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8980995]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.91262412 0.90991575 0.9086414  0.90688753 0.90499145 0.90356338\n",
      "  0.90154153 0.89946896]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009761628694832325\n",
      "Predicción post entrenamiento : [[0.89859444]]\n",
      "PERDIDAAAA despues: 0.00966406986117363\n",
      "loss en el callback: 0.00862703938037157, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.90991575]\n",
      "  [0.9086414 ]\n",
      "  [0.90688753]\n",
      "  [0.90499145]\n",
      "  [0.90356338]\n",
      "  [0.90154153]\n",
      "  [0.89946896]\n",
      "  [0.89809948]]]\n",
      "ejemplar: [0.90991575 0.9086414  0.90688753 0.90499145 0.90356338 0.90154153\n",
      " 0.89946896 0.89809948]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.8968536]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.90991575 0.9086414  0.90688753 0.90499145 0.90356338 0.90154153\n",
      "  0.89946896 0.89809948]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029515407513827085\n",
      "Predicción post entrenamiento : [[0.89656734]]\n",
      "PERDIDAAAA despues: 0.0029827288817614317\n",
      "loss en el callback: 0.0024794680066406727, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.9086414 ]\n",
      "  [0.90688753]\n",
      "  [0.90499145]\n",
      "  [0.90356338]\n",
      "  [0.90154153]\n",
      "  [0.89946896]\n",
      "  [0.89809948]\n",
      "  [0.89685363]]]\n",
      "ejemplar: [0.9086414  0.90688753 0.90499145 0.90356338 0.90154153 0.89946896\n",
      " 0.89809948 0.89685363]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.89509404]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.9086414  0.90688753 0.90499145 0.90356338 0.90154153 0.89946896\n",
      "  0.89809948 0.89685363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.661765160562936e-07\n",
      "Predicción post entrenamiento : [[0.8954302]]\n",
      "PERDIDAAAA despues: 1.201322561428242e-07\n",
      "loss en el callback: 0.004732886794954538, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.90688753]\n",
      "  [0.90499145]\n",
      "  [0.90356338]\n",
      "  [0.90154153]\n",
      "  [0.89946896]\n",
      "  [0.89809948]\n",
      "  [0.89685363]\n",
      "  [0.89509404]]]\n",
      "ejemplar: [0.90688753 0.90499145 0.90356338 0.90154153 0.89946896 0.89809948\n",
      " 0.89685363 0.89509404]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.89383656]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.90688753 0.90499145 0.90356338 0.90154153 0.89946896 0.89809948\n",
      "  0.89685363 0.89509404]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001536425406811759\n",
      "Predicción post entrenamiento : [[0.89362246]]\n",
      "PERDIDAAAA despues: 0.00014838072820566595\n",
      "loss en el callback: 0.0016853583510965109, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.90499145]\n",
      "  [0.90356338]\n",
      "  [0.90154153]\n",
      "  [0.89946896]\n",
      "  [0.89809948]\n",
      "  [0.89685363]\n",
      "  [0.89509404]\n",
      "  [0.89383656]]]\n",
      "ejemplar: [0.90499145 0.90356338 0.90154153 0.89946896 0.89809948 0.89685363\n",
      " 0.89509404 0.89383656]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.89204097]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.90499145 0.90356338 0.90154153 0.89946896 0.89809948 0.89685363\n",
      "  0.89509404 0.89383656]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006272747996263206\n",
      "Predicción post entrenamiento : [[0.8926212]]\n",
      "PERDIDAAAA despues: 0.0005985461757518351\n",
      "loss en el callback: 0.015330272726714611, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.90356338]\n",
      "  [0.90154153]\n",
      "  [0.89946896]\n",
      "  [0.89809948]\n",
      "  [0.89685363]\n",
      "  [0.89509404]\n",
      "  [0.89383656]\n",
      "  [0.89204097]]]\n",
      "ejemplar: [0.90356338 0.90154153 0.89946896 0.89809948 0.89685363 0.89509404\n",
      " 0.89383656 0.89204097]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8911037]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.90356338 0.90154153 0.89946896 0.89809948 0.89685363 0.89509404\n",
      "  0.89383656 0.89204097]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000823395443148911\n",
      "Predicción post entrenamiento : [[0.89152557]]\n",
      "PERDIDAAAA despues: 0.000799361732788384\n",
      "loss en el callback: 0.007907179184257984, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.90154153]\n",
      "  [0.89946896]\n",
      "  [0.89809948]\n",
      "  [0.89685363]\n",
      "  [0.89509404]\n",
      "  [0.89383656]\n",
      "  [0.89204097]\n",
      "  [0.89110368]]]\n",
      "ejemplar: [0.90154153 0.89946896 0.89809948 0.89685363 0.89509404 0.89383656\n",
      " 0.89204097 0.89110368]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.88995165]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.90154153 0.89946896 0.89809948 0.89685363 0.89509404 0.89383656\n",
      "  0.89204097 0.89110368]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005139621905982494\n",
      "Predicción post entrenamiento : [[0.88972473]]\n",
      "PERDIDAAAA despues: 0.00517220888286829\n",
      "loss en el callback: 0.0016794712282717228, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.89946896]\n",
      "  [0.89809948]\n",
      "  [0.89685363]\n",
      "  [0.89509404]\n",
      "  [0.89383656]\n",
      "  [0.89204097]\n",
      "  [0.89110368]\n",
      "  [0.88995165]]]\n",
      "ejemplar: [0.89946896 0.89809948 0.89685363 0.89509404 0.89383656 0.89204097\n",
      " 0.89110368 0.88995165]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.88827837]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.89946896 0.89809948 0.89685363 0.89509404 0.89383656 0.89204097\n",
      "  0.89110368 0.88995165]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006392160430550575\n",
      "Predicción post entrenamiento : [[0.8883615]]\n",
      "PERDIDAAAA despues: 0.006378871854394674\n",
      "loss en el callback: 0.0002417159266769886, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.89809948]\n",
      "  [0.89685363]\n",
      "  [0.89509404]\n",
      "  [0.89383656]\n",
      "  [0.89204097]\n",
      "  [0.89110368]\n",
      "  [0.88995165]\n",
      "  [0.88827837]]]\n",
      "ejemplar: [0.89809948 0.89685363 0.89509404 0.89383656 0.89204097 0.89110368\n",
      " 0.88995165 0.88827837]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.88708645]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.89809948 0.89685363 0.89509404 0.89383656 0.89204097 0.89110368\n",
      "  0.88995165 0.88827837]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00499592674896121\n",
      "Predicción post entrenamiento : [[0.8869615]]\n",
      "PERDIDAAAA despues: 0.005013603251427412\n",
      "loss en el callback: 0.0005203360924497247, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.2252467]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032091330736875534\n",
      "Predicción post entrenamiento : [[0.18600677]]\n",
      "PERDIDAAAA despues: 0.0195721797645092\n",
      "loss en el callback: 0.030294887721538544, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2252467 ]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.2252467 ]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.1701244]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.2252467 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004342971835285425\n",
      "Predicción post entrenamiento : [[0.164107]]\n",
      "PERDIDAAAA despues: 0.003586072474718094\n",
      "loss en el callback: 0.0010871106060221791, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2252467 ]\n",
      "  [0.1701244 ]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.2252467  0.1701244 ]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16787933]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.2252467  0.1701244 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018702000670600682\n",
      "Predicción post entrenamiento : [[0.16672406]]\n",
      "PERDIDAAAA despues: 0.000156756752403453\n",
      "loss en el callback: 6.437321280827746e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2252467 ]\n",
      "  [0.1701244 ]\n",
      "  [0.16787933]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.2252467\n",
      " 0.1701244  0.16787933]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17769985]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.2252467\n",
      "  0.1701244  0.16787933]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004816385917365551\n",
      "Predicción post entrenamiento : [[0.17847292]]\n",
      "PERDIDAAAA despues: 0.0005161683657206595\n",
      "loss en el callback: 6.608065450564027e-05, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2252467 ]\n",
      "  [0.1701244 ]\n",
      "  [0.16787933]\n",
      "  [0.17769985]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.2252467  0.1701244\n",
      " 0.16787933 0.17769985]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.1902585]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.2252467  0.1701244\n",
      "  0.16787933 0.17769985]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004189423751085997\n",
      "Predicción post entrenamiento : [[0.18338117]]\n",
      "PERDIDAAAA despues: 0.0033464401494711637\n",
      "loss en el callback: 0.005576194263994694, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2252467 ]\n",
      "  [0.1701244 ]\n",
      "  [0.16787933]\n",
      "  [0.17769985]\n",
      "  [0.1902585 ]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.2252467  0.1701244  0.16787933\n",
      " 0.17769985 0.1902585 ]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19192417]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.2252467  0.1701244  0.16787933\n",
      "  0.17769985 0.1902585 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002138526411727071\n",
      "Predicción post entrenamiento : [[0.18943784]]\n",
      "PERDIDAAAA despues: 0.0019147512502968311\n",
      "loss en el callback: 0.0012144924839958549, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2252467 ]\n",
      "  [0.1701244 ]\n",
      "  [0.16787933]\n",
      "  [0.17769985]\n",
      "  [0.1902585 ]\n",
      "  [0.19192417]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.2252467  0.1701244  0.16787933 0.17769985\n",
      " 0.1902585  0.19192417]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20865871]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.2252467  0.1701244  0.16787933 0.17769985\n",
      "  0.1902585  0.19192417]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038693195674568415\n",
      "Predicción post entrenamiento : [[0.2029574]]\n",
      "PERDIDAAAA despues: 0.0031925381626933813\n",
      "loss en el callback: 0.006317931227385998, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.2252467 ]\n",
      "  [0.1701244 ]\n",
      "  [0.16787933]\n",
      "  [0.17769985]\n",
      "  [0.1902585 ]\n",
      "  [0.19192417]\n",
      "  [0.20865871]]]\n",
      "ejemplar: [0.04223169 0.2252467  0.1701244  0.16787933 0.17769985 0.1902585\n",
      " 0.19192417 0.20865871]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22616883]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.2252467  0.1701244  0.16787933 0.17769985 0.1902585\n",
      "  0.19192417 0.20865871]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009072619723156095\n",
      "Predicción post entrenamiento : [[0.22512309]]\n",
      "PERDIDAAAA despues: 0.0008453588816337287\n",
      "loss en el callback: 0.0003503586631268263, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.2252467 ]\n",
      "  [0.1701244 ]\n",
      "  [0.16787933]\n",
      "  [0.17769985]\n",
      "  [0.1902585 ]\n",
      "  [0.19192417]\n",
      "  [0.20865871]\n",
      "  [0.22616883]]]\n",
      "ejemplar: [0.2252467  0.1701244  0.16787933 0.17769985 0.1902585  0.19192417\n",
      " 0.20865871 0.22616883]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.25270584]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.2252467  0.1701244  0.16787933 0.17769985 0.1902585  0.19192417\n",
      "  0.20865871 0.22616883]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004917325568385422\n",
      "Predicción post entrenamiento : [[0.25160006]]\n",
      "PERDIDAAAA despues: 0.0004439136537257582\n",
      "loss en el callback: 0.0004035859019495547, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.1701244 ]\n",
      "  [0.16787933]\n",
      "  [0.17769985]\n",
      "  [0.1902585 ]\n",
      "  [0.19192417]\n",
      "  [0.20865871]\n",
      "  [0.22616883]\n",
      "  [0.25270584]]]\n",
      "ejemplar: [0.1701244  0.16787933 0.17769985 0.1902585  0.19192417 0.20865871\n",
      " 0.22616883 0.25270584]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24409406]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.1701244  0.16787933 0.17769985 0.1902585  0.19192417 0.20865871\n",
      "  0.22616883 0.25270584]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012707599671557546\n",
      "Predicción post entrenamiento : [[0.24184315]]\n",
      "PERDIDAAAA despues: 0.0011153469095006585\n",
      "loss en el callback: 0.0020158507395535707, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16787933]\n",
      "  [0.17769985]\n",
      "  [0.1902585 ]\n",
      "  [0.19192417]\n",
      "  [0.20865871]\n",
      "  [0.22616883]\n",
      "  [0.25270584]\n",
      "  [0.24409406]]]\n",
      "ejemplar: [0.16787933 0.17769985 0.1902585  0.19192417 0.20865871 0.22616883\n",
      " 0.25270584 0.24409406]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24644665]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16787933 0.17769985 0.1902585  0.19192417 0.20865871 0.22616883\n",
      "  0.25270584 0.24409406]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011911675101146102\n",
      "Predicción post entrenamiento : [[0.24617983]]\n",
      "PERDIDAAAA despues: 0.0011728210374712944\n",
      "loss en el callback: 4.3796848331112415e-05, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17769985]\n",
      "  [0.1902585 ]\n",
      "  [0.19192417]\n",
      "  [0.20865871]\n",
      "  [0.22616883]\n",
      "  [0.25270584]\n",
      "  [0.24409406]\n",
      "  [0.24644665]]]\n",
      "ejemplar: [0.17769985 0.1902585  0.19192417 0.20865871 0.22616883 0.25270584\n",
      " 0.24409406 0.24644665]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25338393]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17769985 0.1902585  0.19192417 0.20865871 0.22616883 0.25270584\n",
      "  0.24409406 0.24644665]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021252036094665527\n",
      "Predicción post entrenamiento : [[0.25170127]]\n",
      "PERDIDAAAA despues: 0.001972893252968788\n",
      "loss en el callback: 0.0018879178678616881, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.1902585 ]\n",
      "  [0.19192417]\n",
      "  [0.20865871]\n",
      "  [0.22616883]\n",
      "  [0.25270584]\n",
      "  [0.24409406]\n",
      "  [0.24644665]\n",
      "  [0.25338393]]]\n",
      "ejemplar: [0.1902585  0.19192417 0.20865871 0.22616883 0.25270584 0.24409406\n",
      " 0.24644665 0.25338393]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25920534]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.1902585  0.19192417 0.20865871 0.22616883 0.25270584 0.24409406\n",
      "  0.24644665 0.25338393]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004389972425997257\n",
      "Predicción post entrenamiento : [[0.25800854]]\n",
      "PERDIDAAAA despues: 0.004232811741530895\n",
      "loss en el callback: 0.0011915501672774553, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19192417]\n",
      "  [0.20865871]\n",
      "  [0.22616883]\n",
      "  [0.25270584]\n",
      "  [0.24409406]\n",
      "  [0.24644665]\n",
      "  [0.25338393]\n",
      "  [0.25920534]]]\n",
      "ejemplar: [0.19192417 0.20865871 0.22616883 0.25270584 0.24409406 0.24644665\n",
      " 0.25338393 0.25920534]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2651135]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19192417 0.20865871 0.22616883 0.25270584 0.24409406 0.24644665\n",
      "  0.25338393 0.25920534]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0046636005863547325\n",
      "Predicción post entrenamiento : [[0.26166266]]\n",
      "PERDIDAAAA despues: 0.004204189404845238\n",
      "loss en el callback: 0.008795891888439655, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20865871]\n",
      "  [0.22616883]\n",
      "  [0.25270584]\n",
      "  [0.24409406]\n",
      "  [0.24644665]\n",
      "  [0.25338393]\n",
      "  [0.25920534]\n",
      "  [0.2651135 ]]]\n",
      "ejemplar: [0.20865871 0.22616883 0.25270584 0.24409406 0.24644665 0.25338393\n",
      " 0.25920534 0.2651135 ]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27061057]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20865871 0.22616883 0.25270584 0.24409406 0.24644665 0.25338393\n",
      "  0.25920534 0.2651135 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031756071839481592\n",
      "Predicción post entrenamiento : [[0.26949242]]\n",
      "PERDIDAAAA despues: 0.0030508358031511307\n",
      "loss en el callback: 0.0012049685465171933, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22616883]\n",
      "  [0.25270584]\n",
      "  [0.24409406]\n",
      "  [0.24644665]\n",
      "  [0.25338393]\n",
      "  [0.25920534]\n",
      "  [0.2651135 ]\n",
      "  [0.27061057]]]\n",
      "ejemplar: [0.22616883 0.25270584 0.24409406 0.24644665 0.25338393 0.25920534\n",
      " 0.2651135  0.27061057]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27697015]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22616883 0.25270584 0.24409406 0.24644665 0.25338393 0.25920534\n",
      "  0.2651135  0.27061057]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009147982113063335\n",
      "Predicción post entrenamiento : [[0.27319425]]\n",
      "PERDIDAAAA despues: 0.008439947851002216\n",
      "loss en el callback: 0.012197250500321388, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.25270584]\n",
      "  [0.24409406]\n",
      "  [0.24644665]\n",
      "  [0.25338393]\n",
      "  [0.25920534]\n",
      "  [0.2651135 ]\n",
      "  [0.27061057]\n",
      "  [0.27697015]]]\n",
      "ejemplar: [0.25270584 0.24409406 0.24644665 0.25338393 0.25920534 0.2651135\n",
      " 0.27061057 0.27697015]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2785613]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.25270584 0.24409406 0.24644665 0.25338393 0.25920534 0.2651135\n",
      "  0.27061057 0.27697015]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010698875412344933\n",
      "Predicción post entrenamiento : [[0.2741859]]\n",
      "PERDIDAAAA despues: 0.009812877513468266\n",
      "loss en el callback: 0.020139729604125023, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.24409406]\n",
      "  [0.24644665]\n",
      "  [0.25338393]\n",
      "  [0.25920534]\n",
      "  [0.2651135 ]\n",
      "  [0.27061057]\n",
      "  [0.27697015]\n",
      "  [0.27856129]]]\n",
      "ejemplar: [0.24409406 0.24644665 0.25338393 0.25920534 0.2651135  0.27061057\n",
      " 0.27697015 0.27856129]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2749004]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.24409406 0.24644665 0.25338393 0.25920534 0.2651135  0.27061057\n",
      "  0.27697015 0.27856129]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016102531924843788\n",
      "Predicción post entrenamiento : [[0.2716526]]\n",
      "PERDIDAAAA despues: 0.015288817696273327\n",
      "loss en el callback: 0.014228546060621738, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.24644665]\n",
      "  [0.25338393]\n",
      "  [0.25920534]\n",
      "  [0.2651135 ]\n",
      "  [0.27061057]\n",
      "  [0.27697015]\n",
      "  [0.27856129]\n",
      "  [0.27490041]]]\n",
      "ejemplar: [0.24644665 0.25338393 0.25920534 0.2651135  0.27061057 0.27697015\n",
      " 0.27856129 0.27490041]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.27501115]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.24644665 0.25338393 0.25920534 0.2651135  0.27061057 0.27697015\n",
      "  0.27856129 0.27490041]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013492679223418236\n",
      "Predicción post entrenamiento : [[0.27278566]]\n",
      "PERDIDAAAA despues: 0.012980615720152855\n",
      "loss en el callback: 0.008626521565020084, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.25338393]\n",
      "  [0.25920534]\n",
      "  [0.2651135 ]\n",
      "  [0.27061057]\n",
      "  [0.27697015]\n",
      "  [0.27856129]\n",
      "  [0.27490041]\n",
      "  [0.27501115]]]\n",
      "ejemplar: [0.25338393 0.25920534 0.2651135  0.27061057 0.27697015 0.27856129\n",
      " 0.27490041 0.27501115]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.27666566]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.25338393 0.25920534 0.2651135  0.27061057 0.27697015 0.27856129\n",
      "  0.27490041 0.27501115]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007138913031667471\n",
      "Predicción post entrenamiento : [[0.27617186]]\n",
      "PERDIDAAAA despues: 0.007055713329464197\n",
      "loss en el callback: 0.000589472649153322, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25920534]\n",
      "  [0.2651135 ]\n",
      "  [0.27061057]\n",
      "  [0.27697015]\n",
      "  [0.27856129]\n",
      "  [0.27490041]\n",
      "  [0.27501115]\n",
      "  [0.27666566]]]\n",
      "ejemplar: [0.25920534 0.2651135  0.27061057 0.27697015 0.27856129 0.27490041\n",
      " 0.27501115 0.27666566]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.27948916]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25920534 0.2651135  0.27061057 0.27697015 0.27856129 0.27490041\n",
      "  0.27501115 0.27666566]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008745003491640091\n",
      "Predicción post entrenamiento : [[0.27688715]]\n",
      "PERDIDAAAA despues: 0.008265121839940548\n",
      "loss en el callback: 0.01150206197053194, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.2651135 ]\n",
      "  [0.27061057]\n",
      "  [0.27697015]\n",
      "  [0.27856129]\n",
      "  [0.27490041]\n",
      "  [0.27501115]\n",
      "  [0.27666566]\n",
      "  [0.27948916]]]\n",
      "ejemplar: [0.2651135  0.27061057 0.27697015 0.27856129 0.27490041 0.27501115\n",
      " 0.27666566 0.27948916]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.27968454]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.2651135  0.27061057 0.27697015 0.27856129 0.27490041 0.27501115\n",
      "  0.27666566 0.27948916]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001621485862415284\n",
      "Predicción post entrenamiento : [[0.2790376]]\n",
      "PERDIDAAAA despues: 0.00014609094068873674\n",
      "loss en el callback: 0.0007030472042970359, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.27061057]\n",
      "  [0.27697015]\n",
      "  [0.27856129]\n",
      "  [0.27490041]\n",
      "  [0.27501115]\n",
      "  [0.27666566]\n",
      "  [0.27948916]\n",
      "  [0.27968454]]]\n",
      "ejemplar: [0.27061057 0.27697015 0.27856129 0.27490041 0.27501115 0.27666566\n",
      " 0.27948916 0.27968454]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.28111428]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.27061057 0.27697015 0.27856129 0.27490041 0.27501115 0.27666566\n",
      "  0.27948916 0.27968454]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013014249270781875\n",
      "Predicción post entrenamiento : [[0.28173274]]\n",
      "PERDIDAAAA despues: 0.00011641424498520792\n",
      "loss en el callback: 0.0009192637517116964, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.27697015]\n",
      "  [0.27856129]\n",
      "  [0.27490041]\n",
      "  [0.27501115]\n",
      "  [0.27666566]\n",
      "  [0.27948916]\n",
      "  [0.27968454]\n",
      "  [0.28111428]]]\n",
      "ejemplar: [0.27697015 0.27856129 0.27490041 0.27501115 0.27666566 0.27948916\n",
      " 0.27968454 0.28111428]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.28299785]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.27697015 0.27856129 0.27490041 0.27501115 0.27666566 0.27948916\n",
      "  0.27968454 0.28111428]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012046778574585915\n",
      "Predicción post entrenamiento : [[0.28391492]]\n",
      "PERDIDAAAA despues: 0.0011418582871556282\n",
      "loss en el callback: 0.0022933585569262505, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.27856129]\n",
      "  [0.27490041]\n",
      "  [0.27501115]\n",
      "  [0.27666566]\n",
      "  [0.27948916]\n",
      "  [0.27968454]\n",
      "  [0.28111428]\n",
      "  [0.28299785]]]\n",
      "ejemplar: [0.27856129 0.27490041 0.27501115 0.27666566 0.27948916 0.27968454\n",
      " 0.28111428 0.28299785]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.28400892]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.27856129 0.27490041 0.27501115 0.27666566 0.27948916 0.27968454\n",
      "  0.28111428 0.28299785]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008214297122322023\n",
      "Predicción post entrenamiento : [[0.2844272]]\n",
      "PERDIDAAAA despues: 0.0007976286578923464\n",
      "loss en el callback: 0.0004128466243855655, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.27490041]\n",
      "  [0.27501115]\n",
      "  [0.27666566]\n",
      "  [0.27948916]\n",
      "  [0.27968454]\n",
      "  [0.28111428]\n",
      "  [0.28299785]\n",
      "  [0.28400892]]]\n",
      "ejemplar: [0.27490041 0.27501115 0.27666566 0.27948916 0.27968454 0.28111428\n",
      " 0.28299785 0.28400892]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.28428167]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.27490041 0.27501115 0.27666566 0.27948916 0.27968454 0.28111428\n",
      "  0.28299785 0.28400892]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2596614144276828e-05\n",
      "Predicción post entrenamiento : [[0.28430408]]\n",
      "PERDIDAAAA despues: 2.238404704257846e-05\n",
      "loss en el callback: 1.4549647175954306e-06, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.27501115]\n",
      "  [0.27666566]\n",
      "  [0.27948916]\n",
      "  [0.27968454]\n",
      "  [0.28111428]\n",
      "  [0.28299785]\n",
      "  [0.28400892]\n",
      "  [0.28428167]]]\n",
      "ejemplar: [0.27501115 0.27666566 0.27948916 0.27968454 0.28111428 0.28299785\n",
      " 0.28400892 0.28428167]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.2851302]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.27501115 0.27666566 0.27948916 0.27968454 0.28111428 0.28299785\n",
      "  0.28400892 0.28428167]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.262864306132542e-06\n",
      "Predicción post entrenamiento : [[0.2851704]]\n",
      "PERDIDAAAA despues: 5.4489410103997216e-06\n",
      "loss en el callback: 4.951870323566254e-06, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.27666566]\n",
      "  [0.27948916]\n",
      "  [0.27968454]\n",
      "  [0.28111428]\n",
      "  [0.28299785]\n",
      "  [0.28400892]\n",
      "  [0.28428167]\n",
      "  [0.2851302 ]]]\n",
      "ejemplar: [0.27666566 0.27948916 0.27968454 0.28111428 0.28299785 0.28400892\n",
      " 0.28428167 0.2851302 ]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2862612]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.27666566 0.27948916 0.27968454 0.28111428 0.28299785 0.28400892\n",
      "  0.28428167 0.2851302 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017516844673082232\n",
      "Predicción post entrenamiento : [[0.28538477]]\n",
      "PERDIDAAAA despues: 0.000199135800357908\n",
      "loss en el callback: 0.00170268549118191, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.27948916]\n",
      "  [0.27968454]\n",
      "  [0.28111428]\n",
      "  [0.28299785]\n",
      "  [0.28400892]\n",
      "  [0.28428167]\n",
      "  [0.2851302 ]\n",
      "  [0.2862612 ]]]\n",
      "ejemplar: [0.27948916 0.27968454 0.28111428 0.28299785 0.28400892 0.28428167\n",
      " 0.2851302  0.2862612 ]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2864111]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.27948916 0.27968454 0.28111428 0.28299785 0.28400892 0.28428167\n",
      "  0.2851302  0.2862612 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011128221376566216\n",
      "Predicción post entrenamiento : [[0.28662878]]\n",
      "PERDIDAAAA despues: 0.00011592215014388785\n",
      "loss en el callback: 0.00018031205399893224, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.27968454]\n",
      "  [0.28111428]\n",
      "  [0.28299785]\n",
      "  [0.28400892]\n",
      "  [0.28428167]\n",
      "  [0.2851302 ]\n",
      "  [0.2862612 ]\n",
      "  [0.28641111]]]\n",
      "ejemplar: [0.27968454 0.28111428 0.28299785 0.28400892 0.28428167 0.2851302\n",
      " 0.2862612  0.28641111]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.2872898]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.27968454 0.28111428 0.28299785 0.28400892 0.28428167 0.2851302\n",
      "  0.2862612  0.28641111]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015851012722123414\n",
      "Predicción post entrenamiento : [[0.2870788]]\n",
      "PERDIDAAAA despues: 0.00015324162086471915\n",
      "loss en el callback: 0.0001516608172096312, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.28111428]\n",
      "  [0.28299785]\n",
      "  [0.28400892]\n",
      "  [0.28428167]\n",
      "  [0.2851302 ]\n",
      "  [0.2862612 ]\n",
      "  [0.28641111]\n",
      "  [0.2872898 ]]]\n",
      "ejemplar: [0.28111428 0.28299785 0.28400892 0.28428167 0.2851302  0.2862612\n",
      " 0.28641111 0.2872898 ]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.28791294]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.28111428 0.28299785 0.28400892 0.28428167 0.2851302  0.2862612\n",
      "  0.28641111 0.2872898 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001547119754832238\n",
      "Predicción post entrenamiento : [[0.28762978]]\n",
      "PERDIDAAAA despues: 0.0001477482874179259\n",
      "loss en el callback: 0.0003172720898874104, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.28299785]\n",
      "  [0.28400892]\n",
      "  [0.28428167]\n",
      "  [0.2851302 ]\n",
      "  [0.2862612 ]\n",
      "  [0.28641111]\n",
      "  [0.2872898 ]\n",
      "  [0.28791294]]]\n",
      "ejemplar: [0.28299785 0.28400892 0.28428167 0.2851302  0.2862612  0.28641111\n",
      " 0.2872898  0.28791294]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.28836623]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.28299785 0.28400892 0.28428167 0.2851302  0.2862612  0.28641111\n",
      "  0.2872898  0.28791294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021518217399716377\n",
      "Predicción post entrenamiento : [[0.28858224]]\n",
      "PERDIDAAAA despues: 0.0021318281069397926\n",
      "loss en el callback: 0.0001555389753775671, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.28400892]\n",
      "  [0.28428167]\n",
      "  [0.2851302 ]\n",
      "  [0.2862612 ]\n",
      "  [0.28641111]\n",
      "  [0.2872898 ]\n",
      "  [0.28791294]\n",
      "  [0.28836623]]]\n",
      "ejemplar: [0.28400892 0.28428167 0.2851302  0.2862612  0.28641111 0.2872898\n",
      " 0.28791294 0.28836623]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.2890868]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.28400892 0.28428167 0.2851302  0.2862612  0.28641111 0.2872898\n",
      "  0.28791294 0.28836623]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004434134345501661\n",
      "Predicción post entrenamiento : [[0.29016942]]\n",
      "PERDIDAAAA despues: 0.004291123244911432\n",
      "loss en el callback: 0.00490786274895072, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.28428167]\n",
      "  [0.2851302 ]\n",
      "  [0.2862612 ]\n",
      "  [0.28641111]\n",
      "  [0.2872898 ]\n",
      "  [0.28791294]\n",
      "  [0.28836623]\n",
      "  [0.28908679]]]\n",
      "ejemplar: [0.28428167 0.2851302  0.2862612  0.28641111 0.2872898  0.28791294\n",
      " 0.28836623 0.28908679]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.29060113]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.28428167 0.2851302  0.2862612  0.28641111 0.2872898  0.28791294\n",
      "  0.28836623 0.28908679]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021242941729724407\n",
      "Predicción post entrenamiento : [[0.29092628]]\n",
      "PERDIDAAAA despues: 0.002094428287819028\n",
      "loss en el callback: 0.0004213823995087296, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.2851302 ]\n",
      "  [0.2862612 ]\n",
      "  [0.28641111]\n",
      "  [0.2872898 ]\n",
      "  [0.28791294]\n",
      "  [0.28836623]\n",
      "  [0.28908679]\n",
      "  [0.29060113]]]\n",
      "ejemplar: [0.2851302  0.2862612  0.28641111 0.2872898  0.28791294 0.28836623\n",
      " 0.28908679 0.29060113]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2914478]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.2851302  0.2862612  0.28641111 0.2872898  0.28791294 0.28836623\n",
      "  0.28908679 0.29060113]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017761042108759284\n",
      "Predicción post entrenamiento : [[0.29166928]]\n",
      "PERDIDAAAA despues: 0.0017574842786416411\n",
      "loss en el callback: 0.0002063314605038613, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.2862612 ]\n",
      "  [0.28641111]\n",
      "  [0.2872898 ]\n",
      "  [0.28791294]\n",
      "  [0.28836623]\n",
      "  [0.28908679]\n",
      "  [0.29060113]\n",
      "  [0.29144779]]]\n",
      "ejemplar: [0.2862612  0.28641111 0.2872898  0.28791294 0.28836623 0.28908679\n",
      " 0.29060113 0.29144779]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.29216504]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.2862612  0.28641111 0.2872898  0.28791294 0.28836623 0.28908679\n",
      "  0.29060113 0.29144779]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008569123223423958\n",
      "Predicción post entrenamiento : [[0.29368368]]\n",
      "PERDIDAAAA despues: 0.00829027034342289\n",
      "loss en el callback: 0.012213439680635929, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.28641111]\n",
      "  [0.2872898 ]\n",
      "  [0.28791294]\n",
      "  [0.28836623]\n",
      "  [0.28908679]\n",
      "  [0.29060113]\n",
      "  [0.29144779]\n",
      "  [0.29216504]]]\n",
      "ejemplar: [0.28641111 0.2872898  0.28791294 0.28836623 0.28908679 0.29060113\n",
      " 0.29144779 0.29216504]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.29408845]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.28641111 0.2872898  0.28791294 0.28836623 0.28908679 0.29060113\n",
      "  0.29144779 0.29216504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07673344761133194\n",
      "Predicción post entrenamiento : [[0.2979365]]\n",
      "PERDIDAAAA despues: 0.07461637258529663\n",
      "loss en el callback: 0.08616713434457779, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.2872898 ]\n",
      "  [0.28791294]\n",
      "  [0.28836623]\n",
      "  [0.28908679]\n",
      "  [0.29060113]\n",
      "  [0.29144779]\n",
      "  [0.29216504]\n",
      "  [0.29408845]]]\n",
      "ejemplar: [0.2872898  0.28791294 0.28836623 0.28908679 0.29060113 0.29144779\n",
      " 0.29216504 0.29408845]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.2984767]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.2872898  0.28791294 0.28836623 0.28908679 0.29060113 0.29144779\n",
      "  0.29216504 0.29408845]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08868711441755295\n",
      "Predicción post entrenamiento : [[0.30268216]]\n",
      "PERDIDAAAA despues: 0.08619999140501022\n",
      "loss en el callback: 0.07687912881374359, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.28791294]\n",
      "  [0.28836623]\n",
      "  [0.28908679]\n",
      "  [0.29060113]\n",
      "  [0.29144779]\n",
      "  [0.29216504]\n",
      "  [0.29408845]\n",
      "  [0.2984767 ]]]\n",
      "ejemplar: [0.28791294 0.28836623 0.28908679 0.29060113 0.29144779 0.29216504\n",
      " 0.29408845 0.2984767 ]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.30323768]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.28791294 0.28836623 0.28908679 0.29060113 0.29144779 0.29216504\n",
      "  0.29408845 0.2984767 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07362853735685349\n",
      "Predicción post entrenamiento : [[0.3067263]]\n",
      "PERDIDAAAA despues: 0.07174745947122574\n",
      "loss en el callback: 0.07203621417284012, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.28836623]\n",
      "  [0.28908679]\n",
      "  [0.29060113]\n",
      "  [0.29144779]\n",
      "  [0.29216504]\n",
      "  [0.29408845]\n",
      "  [0.2984767 ]\n",
      "  [0.30323768]]]\n",
      "ejemplar: [0.28836623 0.28908679 0.29060113 0.29144779 0.29216504 0.29408845\n",
      " 0.2984767  0.30323768]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.30740795]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.28836623 0.28908679 0.29060113 0.29144779 0.29216504 0.29408845\n",
      "  0.2984767  0.30323768]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08936881273984909\n",
      "Predicción post entrenamiento : [[0.311169]]\n",
      "PERDIDAAAA despues: 0.08713425695896149\n",
      "loss en el callback: 0.10367743670940399, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.28908679]\n",
      "  [0.29060113]\n",
      "  [0.29144779]\n",
      "  [0.29216504]\n",
      "  [0.29408845]\n",
      "  [0.2984767 ]\n",
      "  [0.30323768]\n",
      "  [0.30740795]]]\n",
      "ejemplar: [0.28908679 0.29060113 0.29144779 0.29216504 0.29408845 0.2984767\n",
      " 0.30323768 0.30740795]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.31210232]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.28908679 0.29060113 0.29144779 0.29216504 0.29408845 0.2984767\n",
      "  0.30323768 0.30740795]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07428612560033798\n",
      "Predicción post entrenamiento : [[0.31557506]]\n",
      "PERDIDAAAA despues: 0.07240515947341919\n",
      "loss en el callback: 0.07884684205055237, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.29060113]\n",
      "  [0.29144779]\n",
      "  [0.29216504]\n",
      "  [0.29408845]\n",
      "  [0.2984767 ]\n",
      "  [0.30323768]\n",
      "  [0.30740795]\n",
      "  [0.31210232]]]\n",
      "ejemplar: [0.29060113 0.29144779 0.29216504 0.29408845 0.2984767  0.30323768\n",
      " 0.30740795 0.31210232]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.31681195]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.29060113 0.29144779 0.29216504 0.29408845 0.2984767  0.30323768\n",
      "  0.30740795 0.31210232]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06348375976085663\n",
      "Predicción post entrenamiento : [[0.31974313]]\n",
      "PERDIDAAAA despues: 0.062015268951654434\n",
      "loss en el callback: 0.04697398468852043, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.29144779]\n",
      "  [0.29216504]\n",
      "  [0.29408845]\n",
      "  [0.2984767 ]\n",
      "  [0.30323768]\n",
      "  [0.30740795]\n",
      "  [0.31210232]\n",
      "  [0.31681195]]]\n",
      "ejemplar: [0.29144779 0.29216504 0.29408845 0.2984767  0.30323768 0.30740795\n",
      " 0.31210232 0.31681195]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32122102]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.29144779 0.29216504 0.29408845 0.2984767  0.30323768 0.30740795\n",
      "  0.31210232 0.31681195]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10339638590812683\n",
      "Predicción post entrenamiento : [[0.3249065]]\n",
      "PERDIDAAAA despues: 0.1010398119688034\n",
      "loss en el callback: 0.07033061981201172, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.29216504]\n",
      "  [0.29408845]\n",
      "  [0.2984767 ]\n",
      "  [0.30323768]\n",
      "  [0.30740795]\n",
      "  [0.31210232]\n",
      "  [0.31681195]\n",
      "  [0.32122102]]]\n",
      "ejemplar: [0.29216504 0.29408845 0.2984767  0.30323768 0.30740795 0.31210232\n",
      " 0.31681195 0.32122102]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32689455]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.29216504 0.29408845 0.2984767  0.30323768 0.30740795 0.31210232\n",
      "  0.31681195 0.32122102]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11213421076536179\n",
      "Predicción post entrenamiento : [[0.33107328]]\n",
      "PERDIDAAAA despues: 0.10935305804014206\n",
      "loss en el callback: 0.1217978447675705, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.29408845]\n",
      "  [0.2984767 ]\n",
      "  [0.30323768]\n",
      "  [0.30740795]\n",
      "  [0.31210232]\n",
      "  [0.31681195]\n",
      "  [0.32122102]\n",
      "  [0.32689455]]]\n",
      "ejemplar: [0.29408845 0.2984767  0.30323768 0.30740795 0.31210232 0.31681195\n",
      " 0.32122102 0.32689455]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33374947]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.29408845 0.2984767  0.30323768 0.30740795 0.31210232 0.31681195\n",
      "  0.32122102 0.32689455]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11508750915527344\n",
      "Predicción post entrenamiento : [[0.3376951]]\n",
      "PERDIDAAAA despues: 0.11242601275444031\n",
      "loss en el callback: 0.09616229683160782, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.2984767 ]\n",
      "  [0.30323768]\n",
      "  [0.30740795]\n",
      "  [0.31210232]\n",
      "  [0.31681195]\n",
      "  [0.32122102]\n",
      "  [0.32689455]\n",
      "  [0.33374947]]]\n",
      "ejemplar: [0.2984767  0.30323768 0.30740795 0.31210232 0.31681195 0.32122102\n",
      " 0.32689455 0.33374947]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34093624]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.2984767  0.30323768 0.30740795 0.31210232 0.31681195 0.32122102\n",
      "  0.32689455 0.33374947]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13663451373577118\n",
      "Predicción post entrenamiento : [[0.3451037]]\n",
      "PERDIDAAAA despues: 0.13357095420360565\n",
      "loss en el callback: 0.16658279299736023, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.30323768]\n",
      "  [0.30740795]\n",
      "  [0.31210232]\n",
      "  [0.31681195]\n",
      "  [0.32122102]\n",
      "  [0.32689455]\n",
      "  [0.33374947]\n",
      "  [0.34093624]]]\n",
      "ejemplar: [0.30323768 0.30740795 0.31210232 0.31681195 0.32122102 0.32689455\n",
      " 0.33374947 0.34093624]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34845513]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.30323768 0.30740795 0.31210232 0.31681195 0.32122102 0.32689455\n",
      "  0.33374947 0.34093624]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1264055371284485\n",
      "Predicción post entrenamiento : [[0.35227734]]\n",
      "PERDIDAAAA despues: 0.1237022876739502\n",
      "loss en el callback: 0.15565361082553864, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.30740795]\n",
      "  [0.31210232]\n",
      "  [0.31681195]\n",
      "  [0.32122102]\n",
      "  [0.32689455]\n",
      "  [0.33374947]\n",
      "  [0.34093624]\n",
      "  [0.34845513]]]\n",
      "ejemplar: [0.30740795 0.31210232 0.31681195 0.32122102 0.32689455 0.33374947\n",
      " 0.34093624 0.34845513]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35571402]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.30740795 0.31210232 0.31681195 0.32122102 0.32689455 0.33374947\n",
      "  0.34093624 0.34845513]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13802970945835114\n",
      "Predicción post entrenamiento : [[0.35979104]]\n",
      "PERDIDAAAA despues: 0.13501691818237305\n",
      "loss en el callback: 0.14263419806957245, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.31210232]\n",
      "  [0.31681195]\n",
      "  [0.32122102]\n",
      "  [0.32689455]\n",
      "  [0.33374947]\n",
      "  [0.34093624]\n",
      "  [0.34845513]\n",
      "  [0.35571402]]]\n",
      "ejemplar: [0.31210232 0.31681195 0.32122102 0.32689455 0.33374947 0.34093624\n",
      " 0.34845513 0.35571402]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.36352724]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.31210232 0.31681195 0.32122102 0.32689455 0.33374947 0.34093624\n",
      "  0.34845513 0.35571402]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12892471253871918\n",
      "Predicción post entrenamiento : [[0.36752772]]\n",
      "PERDIDAAAA despues: 0.1260678917169571\n",
      "loss en el callback: 0.15459759533405304, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.31681195]\n",
      "  [0.32122102]\n",
      "  [0.32689455]\n",
      "  [0.33374947]\n",
      "  [0.34093624]\n",
      "  [0.34845513]\n",
      "  [0.35571402]\n",
      "  [0.36352724]]]\n",
      "ejemplar: [0.31681195 0.32122102 0.32689455 0.33374947 0.34093624 0.34845513\n",
      " 0.35571402 0.36352724]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3715466]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.31681195 0.32122102 0.32689455 0.33374947 0.34093624 0.34845513\n",
      "  0.35571402 0.36352724]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1601978987455368\n",
      "Predicción post entrenamiento : [[0.3757759]]\n",
      "PERDIDAAAA despues: 0.15683025121688843\n",
      "loss en el callback: 0.15121135115623474, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.32122102]\n",
      "  [0.32689455]\n",
      "  [0.33374947]\n",
      "  [0.34093624]\n",
      "  [0.34845513]\n",
      "  [0.35571402]\n",
      "  [0.36352724]\n",
      "  [0.3715466 ]]]\n",
      "ejemplar: [0.32122102 0.32689455 0.33374947 0.34093624 0.34845513 0.35571402\n",
      " 0.36352724 0.3715466 ]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3801809]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.32122102 0.32689455 0.33374947 0.34093624 0.34845513 0.35571402\n",
      "  0.36352724 0.3715466 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1185731291770935\n",
      "Predicción post entrenamiento : [[0.3838498]]\n",
      "PERDIDAAAA despues: 0.11605986207723618\n",
      "loss en el callback: 0.13232474029064178, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32689455]\n",
      "  [0.33374947]\n",
      "  [0.34093624]\n",
      "  [0.34845513]\n",
      "  [0.35571402]\n",
      "  [0.36352724]\n",
      "  [0.3715466 ]\n",
      "  [0.3801809 ]]]\n",
      "ejemplar: [0.32689455 0.33374947 0.34093624 0.34845513 0.35571402 0.36352724\n",
      " 0.3715466  0.3801809 ]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38883352]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32689455 0.33374947 0.34093624 0.34845513 0.35571402 0.36352724\n",
      "  0.3715466  0.3801809 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07965048402547836\n",
      "Predicción post entrenamiento : [[0.39171666]]\n",
      "PERDIDAAAA despues: 0.07803142070770264\n",
      "loss en el callback: 0.0873182862997055, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.33374947]\n",
      "  [0.34093624]\n",
      "  [0.34845513]\n",
      "  [0.35571402]\n",
      "  [0.36352724]\n",
      "  [0.3715466 ]\n",
      "  [0.3801809 ]\n",
      "  [0.38883352]]]\n",
      "ejemplar: [0.33374947 0.34093624 0.34845513 0.35571402 0.36352724 0.3715466\n",
      " 0.3801809  0.38883352]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39710656]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.33374947 0.34093624 0.34845513 0.35571402 0.36352724 0.3715466\n",
      "  0.3801809  0.38883352]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07654256373643875\n",
      "Predicción post entrenamiento : [[0.399917]]\n",
      "PERDIDAAAA despues: 0.07499536871910095\n",
      "loss en el callback: 0.07242593169212341, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.34093624]\n",
      "  [0.34845513]\n",
      "  [0.35571402]\n",
      "  [0.36352724]\n",
      "  [0.3715466 ]\n",
      "  [0.3801809 ]\n",
      "  [0.38883352]\n",
      "  [0.39710656]]]\n",
      "ejemplar: [0.34093624 0.34845513 0.35571402 0.36352724 0.3715466  0.3801809\n",
      " 0.38883352 0.39710656]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.40551862]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.34093624 0.34845513 0.35571402 0.36352724 0.3715466  0.3801809\n",
      "  0.38883352 0.39710656]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09543970227241516\n",
      "Predicción post entrenamiento : [[0.4086661]]\n",
      "PERDIDAAAA despues: 0.0935048833489418\n",
      "loss en el callback: 0.08332651853561401, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34845513]\n",
      "  [0.35571402]\n",
      "  [0.36352724]\n",
      "  [0.3715466 ]\n",
      "  [0.3801809 ]\n",
      "  [0.38883352]\n",
      "  [0.39710656]\n",
      "  [0.40551862]]]\n",
      "ejemplar: [0.34845513 0.35571402 0.36352724 0.3715466  0.3801809  0.38883352\n",
      " 0.39710656 0.40551862]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41445586]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34845513 0.35571402 0.36352724 0.3715466  0.3801809  0.38883352\n",
      "  0.39710656 0.40551862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10853195190429688\n",
      "Predicción post entrenamiento : [[0.4177266]]\n",
      "PERDIDAAAA despues: 0.10638760775327682\n",
      "loss en el callback: 0.08437240868806839, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.35571402]\n",
      "  [0.36352724]\n",
      "  [0.3715466 ]\n",
      "  [0.3801809 ]\n",
      "  [0.38883352]\n",
      "  [0.39710656]\n",
      "  [0.40551862]\n",
      "  [0.41445586]]]\n",
      "ejemplar: [0.35571402 0.36352724 0.3715466  0.3801809  0.38883352 0.39710656\n",
      " 0.40551862 0.41445586]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42367312]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.35571402 0.36352724 0.3715466  0.3801809  0.38883352 0.39710656\n",
      "  0.40551862 0.41445586]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08935017883777618\n",
      "Predicción post entrenamiento : [[0.42629474]]\n",
      "PERDIDAAAA despues: 0.08778976649045944\n",
      "loss en el callback: 0.05607879161834717, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.36352724]\n",
      "  [0.3715466 ]\n",
      "  [0.3801809 ]\n",
      "  [0.38883352]\n",
      "  [0.39710656]\n",
      "  [0.40551862]\n",
      "  [0.41445586]\n",
      "  [0.42367312]]]\n",
      "ejemplar: [0.36352724 0.3715466  0.3801809  0.38883352 0.39710656 0.40551862\n",
      " 0.41445586 0.42367312]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.43250793]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.36352724 0.3715466  0.3801809  0.38883352 0.39710656 0.40551862\n",
      "  0.41445586 0.42367312]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07120007276535034\n",
      "Predicción post entrenamiento : [[0.43521902]]\n",
      "PERDIDAAAA despues: 0.06976060569286346\n",
      "loss en el callback: 0.08446318656206131, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.3715466 ]\n",
      "  [0.3801809 ]\n",
      "  [0.38883352]\n",
      "  [0.39710656]\n",
      "  [0.40551862]\n",
      "  [0.41445586]\n",
      "  [0.42367312]\n",
      "  [0.43250793]]]\n",
      "ejemplar: [0.3715466  0.3801809  0.38883352 0.39710656 0.40551862 0.41445586\n",
      " 0.42367312 0.43250793]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.44161856]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.3715466  0.3801809  0.38883352 0.39710656 0.40551862 0.41445586\n",
      "  0.42367312 0.43250793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08743409067392349\n",
      "Predicción post entrenamiento : [[0.4443567]]\n",
      "PERDIDAAAA despues: 0.08582229167222977\n",
      "loss en el callback: 0.06625726073980331, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.3801809 ]\n",
      "  [0.38883352]\n",
      "  [0.39710656]\n",
      "  [0.40551862]\n",
      "  [0.41445586]\n",
      "  [0.42367312]\n",
      "  [0.43250793]\n",
      "  [0.44161856]]]\n",
      "ejemplar: [0.3801809  0.38883352 0.39710656 0.40551862 0.41445586 0.42367312\n",
      " 0.43250793 0.44161856]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4509324]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.3801809  0.38883352 0.39710656 0.40551862 0.41445586 0.42367312\n",
      "  0.43250793 0.44161856]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07316669076681137\n",
      "Predicción post entrenamiento : [[0.45308268]]\n",
      "PERDIDAAAA despues: 0.07200804352760315\n",
      "loss en el callback: 0.042310815304517746, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38883352]\n",
      "  [0.39710656]\n",
      "  [0.40551862]\n",
      "  [0.41445586]\n",
      "  [0.42367312]\n",
      "  [0.43250793]\n",
      "  [0.44161856]\n",
      "  [0.45093241]]]\n",
      "ejemplar: [0.38883352 0.39710656 0.40551862 0.41445586 0.42367312 0.43250793\n",
      " 0.44161856 0.45093241]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45971373]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38883352 0.39710656 0.40551862 0.41445586 0.42367312 0.43250793\n",
      "  0.44161856 0.45093241]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06708098948001862\n",
      "Predicción post entrenamiento : [[0.46168306]]\n",
      "PERDIDAAAA despues: 0.0660647451877594\n",
      "loss en el callback: 0.03305811434984207, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.39710656]\n",
      "  [0.40551862]\n",
      "  [0.41445586]\n",
      "  [0.42367312]\n",
      "  [0.43250793]\n",
      "  [0.44161856]\n",
      "  [0.45093241]\n",
      "  [0.45971373]]]\n",
      "ejemplar: [0.39710656 0.40551862 0.41445586 0.42367312 0.43250793 0.44161856\n",
      " 0.45093241 0.45971373]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4683802]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.39710656 0.40551862 0.41445586 0.42367312 0.43250793 0.44161856\n",
      "  0.45093241 0.45971373]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042344219982624054\n",
      "Predicción post entrenamiento : [[0.47008833]]\n",
      "PERDIDAAAA despues: 0.041644152253866196\n",
      "loss en el callback: 0.029389100149273872, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.40551862]\n",
      "  [0.41445586]\n",
      "  [0.42367312]\n",
      "  [0.43250793]\n",
      "  [0.44161856]\n",
      "  [0.45093241]\n",
      "  [0.45971373]\n",
      "  [0.46838021]]]\n",
      "ejemplar: [0.40551862 0.41445586 0.42367312 0.43250793 0.44161856 0.45093241\n",
      " 0.45971373 0.46838021]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4769638]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.40551862 0.41445586 0.42367312 0.43250793 0.44161856 0.45093241\n",
      "  0.45971373 0.46838021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049107734113931656\n",
      "Predicción post entrenamiento : [[0.47876906]]\n",
      "PERDIDAAAA despues: 0.04831088334321976\n",
      "loss en el callback: 0.031000740826129913, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.41445586]\n",
      "  [0.42367312]\n",
      "  [0.43250793]\n",
      "  [0.44161856]\n",
      "  [0.45093241]\n",
      "  [0.45971373]\n",
      "  [0.46838021]\n",
      "  [0.47696379]]]\n",
      "ejemplar: [0.41445586 0.42367312 0.43250793 0.44161856 0.45093241 0.45971373\n",
      " 0.46838021 0.47696379]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.48581344]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.41445586 0.42367312 0.43250793 0.44161856 0.45093241 0.45971373\n",
      "  0.46838021 0.47696379]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055330753326416016\n",
      "Predicción post entrenamiento : [[0.4883311]]\n",
      "PERDIDAAAA despues: 0.054152656346559525\n",
      "loss en el callback: 0.08769479393959045, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.42367312]\n",
      "  [0.43250793]\n",
      "  [0.44161856]\n",
      "  [0.45093241]\n",
      "  [0.45971373]\n",
      "  [0.46838021]\n",
      "  [0.47696379]\n",
      "  [0.48581344]]]\n",
      "ejemplar: [0.42367312 0.43250793 0.44161856 0.45093241 0.45971373 0.46838021\n",
      " 0.47696379 0.48581344]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49542677]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.42367312 0.43250793 0.44161856 0.45093241 0.45971373 0.46838021\n",
      "  0.47696379 0.48581344]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05160227790474892\n",
      "Predicción post entrenamiento : [[0.49781168]]\n",
      "PERDIDAAAA despues: 0.050524450838565826\n",
      "loss en el callback: 0.07883420586585999, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.43250793]\n",
      "  [0.44161856]\n",
      "  [0.45093241]\n",
      "  [0.45971373]\n",
      "  [0.46838021]\n",
      "  [0.47696379]\n",
      "  [0.48581344]\n",
      "  [0.49542677]]]\n",
      "ejemplar: [0.43250793 0.44161856 0.45093241 0.45971373 0.46838021 0.47696379\n",
      " 0.48581344 0.49542677]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.5048831]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.43250793 0.44161856 0.45093241 0.45971373 0.46838021 0.47696379\n",
      "  0.48581344 0.49542677]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06320846080780029\n",
      "Predicción post entrenamiento : [[0.5055094]]\n",
      "PERDIDAAAA despues: 0.06289394944906235\n",
      "loss en el callback: 0.00274652149528265, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.44161856]\n",
      "  [0.45093241]\n",
      "  [0.45971373]\n",
      "  [0.46838021]\n",
      "  [0.47696379]\n",
      "  [0.48581344]\n",
      "  [0.49542677]\n",
      "  [0.50488311]]]\n",
      "ejemplar: [0.44161856 0.45093241 0.45971373 0.46838021 0.47696379 0.48581344\n",
      " 0.49542677 0.50488311]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5126427]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.44161856 0.45093241 0.45971373 0.46838021 0.47696379 0.48581344\n",
      "  0.49542677 0.50488311]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09918943792581558\n",
      "Predicción post entrenamiento : [[0.5152519]]\n",
      "PERDIDAAAA despues: 0.09755275398492813\n",
      "loss en el callback: 0.06105852499604225, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.45093241]\n",
      "  [0.45971373]\n",
      "  [0.46838021]\n",
      "  [0.47696379]\n",
      "  [0.48581344]\n",
      "  [0.49542677]\n",
      "  [0.50488311]\n",
      "  [0.51264268]]]\n",
      "ejemplar: [0.45093241 0.45971373 0.46838021 0.47696379 0.48581344 0.49542677\n",
      " 0.50488311 0.51264268]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5223831]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.45093241 0.45971373 0.46838021 0.47696379 0.48581344 0.49542677\n",
      "  0.50488311 0.51264268]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10013370215892792\n",
      "Predicción post entrenamiento : [[0.52552557]]\n",
      "PERDIDAAAA despues: 0.09815476834774017\n",
      "loss en el callback: 0.1461668610572815, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45971373]\n",
      "  [0.46838021]\n",
      "  [0.47696379]\n",
      "  [0.48581344]\n",
      "  [0.49542677]\n",
      "  [0.50488311]\n",
      "  [0.51264268]\n",
      "  [0.52238309]]]\n",
      "ejemplar: [0.45971373 0.46838021 0.47696379 0.48581344 0.49542677 0.50488311\n",
      " 0.51264268 0.52238309]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5325963]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45971373 0.46838021 0.47696379 0.48581344 0.49542677 0.50488311\n",
      "  0.51264268 0.52238309]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06847093254327774\n",
      "Predicción post entrenamiento : [[0.53485465]]\n",
      "PERDIDAAAA despues: 0.0672941505908966\n",
      "loss en el callback: 0.0607069656252861, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46838021]\n",
      "  [0.47696379]\n",
      "  [0.48581344]\n",
      "  [0.49542677]\n",
      "  [0.50488311]\n",
      "  [0.51264268]\n",
      "  [0.52238309]\n",
      "  [0.53259629]]]\n",
      "ejemplar: [0.46838021 0.47696379 0.48581344 0.49542677 0.50488311 0.51264268\n",
      " 0.52238309 0.53259629]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.54200035]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46838021 0.47696379 0.48581344 0.49542677 0.50488311 0.51264268\n",
      "  0.52238309 0.53259629]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05846934765577316\n",
      "Predicción post entrenamiento : [[0.5440952]]\n",
      "PERDIDAAAA despues: 0.05746064335107803\n",
      "loss en el callback: 0.054036080837249756, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47696379]\n",
      "  [0.48581344]\n",
      "  [0.49542677]\n",
      "  [0.50488311]\n",
      "  [0.51264268]\n",
      "  [0.52238309]\n",
      "  [0.53259629]\n",
      "  [0.54200035]]]\n",
      "ejemplar: [0.47696379 0.48581344 0.49542677 0.50488311 0.51264268 0.52238309\n",
      " 0.53259629 0.54200035]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5513697]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47696379 0.48581344 0.49542677 0.50488311 0.51264268 0.52238309\n",
      "  0.53259629 0.54200035]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04689377173781395\n",
      "Predicción post entrenamiento : [[0.5536772]]\n",
      "PERDIDAAAA despues: 0.045899730175733566\n",
      "loss en el callback: 0.07951502501964569, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48581344]\n",
      "  [0.49542677]\n",
      "  [0.50488311]\n",
      "  [0.51264268]\n",
      "  [0.52238309]\n",
      "  [0.53259629]\n",
      "  [0.54200035]\n",
      "  [0.55136973]]]\n",
      "ejemplar: [0.48581344 0.49542677 0.50488311 0.51264268 0.52238309 0.53259629\n",
      " 0.54200035 0.55136973]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.56113416]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48581344 0.49542677 0.50488311 0.51264268 0.52238309 0.53259629\n",
      "  0.54200035 0.55136973]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04992787912487984\n",
      "Predicción post entrenamiento : [[0.5628276]]\n",
      "PERDIDAAAA despues: 0.04917396977543831\n",
      "loss en el callback: 0.031882189214229584, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49542677]\n",
      "  [0.50488311]\n",
      "  [0.51264268]\n",
      "  [0.52238309]\n",
      "  [0.53259629]\n",
      "  [0.54200035]\n",
      "  [0.55136973]\n",
      "  [0.56113416]]]\n",
      "ejemplar: [0.49542677 0.50488311 0.51264268 0.52238309 0.53259629 0.54200035\n",
      " 0.55136973 0.56113416]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5704318]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49542677 0.50488311 0.51264268 0.52238309 0.53259629 0.54200035\n",
      "  0.55136973 0.56113416]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0950472503900528\n",
      "Predicción post entrenamiento : [[0.5734318]]\n",
      "PERDIDAAAA despues: 0.093206487596035\n",
      "loss en el callback: 0.13402730226516724, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50488311]\n",
      "  [0.51264268]\n",
      "  [0.52238309]\n",
      "  [0.53259629]\n",
      "  [0.54200035]\n",
      "  [0.55136973]\n",
      "  [0.56113416]\n",
      "  [0.57043183]]]\n",
      "ejemplar: [0.50488311 0.51264268 0.52238309 0.53259629 0.54200035 0.55136973\n",
      " 0.56113416 0.57043183]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5810083]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50488311 0.51264268 0.52238309 0.53259629 0.54200035 0.55136973\n",
      "  0.56113416 0.57043183]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08680170029401779\n",
      "Predicción post entrenamiento : [[0.5836665]]\n",
      "PERDIDAAAA despues: 0.08524245023727417\n",
      "loss en el callback: 0.09557849913835526, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51264268]\n",
      "  [0.52238309]\n",
      "  [0.53259629]\n",
      "  [0.54200035]\n",
      "  [0.55136973]\n",
      "  [0.56113416]\n",
      "  [0.57043183]\n",
      "  [0.58100832]]]\n",
      "ejemplar: [0.51264268 0.52238309 0.53259629 0.54200035 0.55136973 0.56113416\n",
      " 0.57043183 0.58100832]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.59126174]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51264268 0.52238309 0.53259629 0.54200035 0.55136973 0.56113416\n",
      "  0.57043183 0.58100832]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06637530028820038\n",
      "Predicción post entrenamiento : [[0.5929385]]\n",
      "PERDIDAAAA despues: 0.06551413983106613\n",
      "loss en el callback: 0.02789974957704544, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52238309]\n",
      "  [0.53259629]\n",
      "  [0.54200035]\n",
      "  [0.55136973]\n",
      "  [0.56113416]\n",
      "  [0.57043183]\n",
      "  [0.58100832]\n",
      "  [0.59126174]]]\n",
      "ejemplar: [0.52238309 0.53259629 0.54200035 0.55136973 0.56113416 0.57043183\n",
      " 0.58100832 0.59126174]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6010338]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52238309 0.53259629 0.54200035 0.55136973 0.56113416 0.57043183\n",
      "  0.58100832 0.59126174]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04719916358590126\n",
      "Predicción post entrenamiento : [[0.6026007]]\n",
      "PERDIDAAAA despues: 0.04652079567313194\n",
      "loss en el callback: 0.0317896232008934, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53259629]\n",
      "  [0.54200035]\n",
      "  [0.55136973]\n",
      "  [0.56113416]\n",
      "  [0.57043183]\n",
      "  [0.58100832]\n",
      "  [0.59126174]\n",
      "  [0.60103381]]]\n",
      "ejemplar: [0.53259629 0.54200035 0.55136973 0.56113416 0.57043183 0.58100832\n",
      " 0.59126174 0.60103381]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6107377]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53259629 0.54200035 0.55136973 0.56113416 0.57043183 0.58100832\n",
      "  0.59126174 0.60103381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046687815338373184\n",
      "Predicción post entrenamiento : [[0.6120742]]\n",
      "PERDIDAAAA despues: 0.04611203074455261\n",
      "loss en el callback: 0.01900067925453186, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54200035]\n",
      "  [0.55136973]\n",
      "  [0.56113416]\n",
      "  [0.57043183]\n",
      "  [0.58100832]\n",
      "  [0.59126174]\n",
      "  [0.60103381]\n",
      "  [0.61073768]]]\n",
      "ejemplar: [0.54200035 0.55136973 0.56113416 0.57043183 0.58100832 0.59126174\n",
      " 0.60103381 0.61073768]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6201279]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54200035 0.55136973 0.56113416 0.57043183 0.58100832 0.59126174\n",
      "  0.60103381 0.61073768]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027299823239445686\n",
      "Predicción post entrenamiento : [[0.622192]]\n",
      "PERDIDAAAA despues: 0.026621991768479347\n",
      "loss en el callback: 0.0763937458395958, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55136973]\n",
      "  [0.56113416]\n",
      "  [0.57043183]\n",
      "  [0.58100832]\n",
      "  [0.59126174]\n",
      "  [0.60103381]\n",
      "  [0.61073768]\n",
      "  [0.62012792]]]\n",
      "ejemplar: [0.55136973 0.56113416 0.57043183 0.58100832 0.59126174 0.60103381\n",
      " 0.61073768 0.62012792]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6303768]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55136973 0.56113416 0.57043183 0.58100832 0.59126174 0.60103381\n",
      "  0.61073768 0.62012792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025234008207917213\n",
      "Predicción post entrenamiento : [[0.63143694]]\n",
      "PERDIDAAAA despues: 0.02489832602441311\n",
      "loss en el callback: 0.014024751260876656, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56113416]\n",
      "  [0.57043183]\n",
      "  [0.58100832]\n",
      "  [0.59126174]\n",
      "  [0.60103381]\n",
      "  [0.61073768]\n",
      "  [0.62012792]\n",
      "  [0.63037682]]]\n",
      "ejemplar: [0.56113416 0.57043183 0.58100832 0.59126174 0.60103381 0.61073768\n",
      " 0.62012792 0.63037682]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.63978016]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56113416 0.57043183 0.58100832 0.59126174 0.60103381 0.61073768\n",
      "  0.62012792 0.63037682]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03778849169611931\n",
      "Predicción post entrenamiento : [[0.64119387]]\n",
      "PERDIDAAAA despues: 0.03724086284637451\n",
      "loss en el callback: 0.024478329345583916, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57043183]\n",
      "  [0.58100832]\n",
      "  [0.59126174]\n",
      "  [0.60103381]\n",
      "  [0.61073768]\n",
      "  [0.62012792]\n",
      "  [0.63037682]\n",
      "  [0.63978016]]]\n",
      "ejemplar: [0.57043183 0.58100832 0.59126174 0.60103381 0.61073768 0.62012792\n",
      " 0.63037682 0.63978016]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.64960474]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57043183 0.58100832 0.59126174 0.60103381 0.61073768 0.62012792\n",
      "  0.63037682 0.63978016]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026526983827352524\n",
      "Predicción post entrenamiento : [[0.6504573]]\n",
      "PERDIDAAAA despues: 0.02624998800456524\n",
      "loss en el callback: 0.008157571777701378, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58100832]\n",
      "  [0.59126174]\n",
      "  [0.60103381]\n",
      "  [0.61073768]\n",
      "  [0.62012792]\n",
      "  [0.63037682]\n",
      "  [0.63978016]\n",
      "  [0.64960474]]]\n",
      "ejemplar: [0.58100832 0.59126174 0.60103381 0.61073768 0.62012792 0.63037682\n",
      " 0.63978016 0.64960474]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.65906405]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58100832 0.59126174 0.60103381 0.61073768 0.62012792 0.63037682\n",
      "  0.63978016 0.64960474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020213956013321877\n",
      "Predicción post entrenamiento : [[0.6599445]]\n",
      "PERDIDAAAA despues: 0.01996438205242157\n",
      "loss en el callback: 0.009193232282996178, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59126174]\n",
      "  [0.60103381]\n",
      "  [0.61073768]\n",
      "  [0.62012792]\n",
      "  [0.63037682]\n",
      "  [0.63978016]\n",
      "  [0.64960474]\n",
      "  [0.65906405]]]\n",
      "ejemplar: [0.59126174 0.60103381 0.61073768 0.62012792 0.63037682 0.63978016\n",
      " 0.64960474 0.65906405]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.66839874]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59126174 0.60103381 0.61073768 0.62012792 0.63037682 0.63978016\n",
      "  0.64960474 0.65906405]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018165195360779762\n",
      "Predicción post entrenamiento : [[0.67013]]\n",
      "PERDIDAAAA despues: 0.017701515927910805\n",
      "loss en el callback: 0.05584055930376053, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60103381]\n",
      "  [0.61073768]\n",
      "  [0.62012792]\n",
      "  [0.63037682]\n",
      "  [0.63978016]\n",
      "  [0.64960474]\n",
      "  [0.65906405]\n",
      "  [0.66839874]]]\n",
      "ejemplar: [0.60103381 0.61073768 0.62012792 0.63037682 0.63978016 0.64960474\n",
      " 0.65906405 0.66839874]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6784844]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60103381 0.61073768 0.62012792 0.63037682 0.63978016 0.64960474\n",
      "  0.65906405 0.66839874]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013226496987044811\n",
      "Predicción post entrenamiento : [[0.67956173]]\n",
      "PERDIDAAAA despues: 0.01297985203564167\n",
      "loss en el callback: 0.017483271658420563, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61073768]\n",
      "  [0.62012792]\n",
      "  [0.63037682]\n",
      "  [0.63978016]\n",
      "  [0.64960474]\n",
      "  [0.65906405]\n",
      "  [0.66839874]\n",
      "  [0.67848438]]]\n",
      "ejemplar: [0.61073768 0.62012792 0.63037682 0.63978016 0.64960474 0.65906405\n",
      " 0.66839874 0.67848438]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.68792474]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61073768 0.62012792 0.63037682 0.63978016 0.64960474 0.65906405\n",
      "  0.66839874 0.67848438]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005219443701207638\n",
      "Predicción post entrenamiento : [[0.6884348]]\n",
      "PERDIDAAAA despues: 0.005146007984876633\n",
      "loss en el callback: 0.003579537384212017, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62012792]\n",
      "  [0.63037682]\n",
      "  [0.63978016]\n",
      "  [0.64960474]\n",
      "  [0.65906405]\n",
      "  [0.66839874]\n",
      "  [0.67848438]\n",
      "  [0.68792474]]]\n",
      "ejemplar: [0.62012792 0.63037682 0.63978016 0.64960474 0.65906405 0.66839874\n",
      " 0.67848438 0.68792474]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6968171]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62012792 0.63037682 0.63978016 0.64960474 0.65906405 0.66839874\n",
      "  0.67848438 0.68792474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014866279670968652\n",
      "Predicción post entrenamiento : [[0.69679093]]\n",
      "PERDIDAAAA despues: 0.0014886463759467006\n",
      "loss en el callback: 9.228653652826324e-06, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63037682]\n",
      "  [0.63978016]\n",
      "  [0.64960474]\n",
      "  [0.65906405]\n",
      "  [0.66839874]\n",
      "  [0.67848438]\n",
      "  [0.68792474]\n",
      "  [0.6968171 ]]]\n",
      "ejemplar: [0.63037682 0.63978016 0.64960474 0.65906405 0.66839874 0.67848438\n",
      " 0.68792474 0.6968171 ]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7052714]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63037682 0.63978016 0.64960474 0.65906405 0.66839874 0.67848438\n",
      "  0.68792474 0.6968171 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.419062366243452e-05\n",
      "Predicción post entrenamiento : [[0.7055449]]\n",
      "PERDIDAAAA despues: 2.1575378923444077e-05\n",
      "loss en el callback: 0.001036454807035625, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.63978016]\n",
      "  [0.64960474]\n",
      "  [0.65906405]\n",
      "  [0.66839874]\n",
      "  [0.67848438]\n",
      "  [0.68792474]\n",
      "  [0.6968171 ]\n",
      "  [0.70527142]]]\n",
      "ejemplar: [0.63978016 0.64960474 0.65906405 0.66839874 0.67848438 0.68792474\n",
      " 0.6968171  0.70527142]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7138729]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.63978016 0.64960474 0.65906405 0.66839874 0.67848438 0.68792474\n",
      "  0.6968171  0.70527142]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.047887730645016e-06\n",
      "Predicción post entrenamiento : [[0.713873]]\n",
      "PERDIDAAAA despues: 3.048303824471077e-06\n",
      "loss en el callback: 6.001279473366594e-10, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.64960474]\n",
      "  [0.65906405]\n",
      "  [0.66839874]\n",
      "  [0.67848438]\n",
      "  [0.68792474]\n",
      "  [0.6968171 ]\n",
      "  [0.70527142]\n",
      "  [0.71387291]]]\n",
      "ejemplar: [0.64960474 0.65906405 0.66839874 0.67848438 0.68792474 0.6968171\n",
      " 0.70527142 0.71387291]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.72224146]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.64960474 0.65906405 0.66839874 0.67848438 0.68792474 0.6968171\n",
      "  0.70527142 0.71387291]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003025638870894909\n",
      "Predicción post entrenamiento : [[0.7215207]]\n",
      "PERDIDAAAA despues: 0.00032815695158205926\n",
      "loss en el callback: 0.006289045792073011, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.65906405]\n",
      "  [0.66839874]\n",
      "  [0.67848438]\n",
      "  [0.68792474]\n",
      "  [0.6968171 ]\n",
      "  [0.70527142]\n",
      "  [0.71387291]\n",
      "  [0.72224146]]]\n",
      "ejemplar: [0.65906405 0.66839874 0.67848438 0.68792474 0.6968171  0.70527142\n",
      " 0.71387291 0.72224146]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7297799]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.65906405 0.66839874 0.67848438 0.68792474 0.6968171  0.70527142\n",
      "  0.71387291 0.72224146]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.056257603224367e-05\n",
      "Predicción post entrenamiento : [[0.72987926]]\n",
      "PERDIDAAAA despues: 3.930681123165414e-05\n",
      "loss en el callback: 0.00014140881830826402, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.66839874]\n",
      "  [0.67848438]\n",
      "  [0.68792474]\n",
      "  [0.6968171 ]\n",
      "  [0.70527142]\n",
      "  [0.71387291]\n",
      "  [0.72224146]\n",
      "  [0.7297799 ]]]\n",
      "ejemplar: [0.66839874 0.67848438 0.68792474 0.6968171  0.70527142 0.71387291\n",
      " 0.72224146 0.7297799 ]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7380814]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.66839874 0.67848438 0.68792474 0.6968171  0.70527142 0.71387291\n",
      "  0.72224146 0.7297799 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004971756599843502\n",
      "Predicción post entrenamiento : [[0.73847663]]\n",
      "PERDIDAAAA despues: 0.00502764992415905\n",
      "loss en el callback: 0.0030706741381436586, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.67848438]\n",
      "  [0.68792474]\n",
      "  [0.6968171 ]\n",
      "  [0.70527142]\n",
      "  [0.71387291]\n",
      "  [0.72224146]\n",
      "  [0.7297799 ]\n",
      "  [0.7380814 ]]]\n",
      "ejemplar: [0.67848438 0.68792474 0.6968171  0.70527142 0.71387291 0.72224146\n",
      " 0.7297799  0.7380814 ]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7466067]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.67848438 0.68792474 0.6968171  0.70527142 0.71387291 0.72224146\n",
      "  0.7297799  0.7380814 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005884623154997826\n",
      "Predicción post entrenamiento : [[0.7470956]]\n",
      "PERDIDAAAA despues: 0.005959867034107447\n",
      "loss en el callback: 0.005235216114670038, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.68792474]\n",
      "  [0.6968171 ]\n",
      "  [0.70527142]\n",
      "  [0.71387291]\n",
      "  [0.72224146]\n",
      "  [0.7297799 ]\n",
      "  [0.7380814 ]\n",
      "  [0.74660671]]]\n",
      "ejemplar: [0.68792474 0.6968171  0.70527142 0.71387291 0.72224146 0.7297799\n",
      " 0.7380814  0.74660671]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.75488204]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.68792474 0.6968171  0.70527142 0.71387291 0.72224146 0.7297799\n",
      "  0.7380814  0.74660671]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033933899831026793\n",
      "Predicción post entrenamiento : [[0.7545222]]\n",
      "PERDIDAAAA despues: 0.0033515968825668097\n",
      "loss en el callback: 0.002081964397802949, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.6968171 ]\n",
      "  [0.70527142]\n",
      "  [0.71387291]\n",
      "  [0.72224146]\n",
      "  [0.7297799 ]\n",
      "  [0.7380814 ]\n",
      "  [0.74660671]\n",
      "  [0.75488204]]]\n",
      "ejemplar: [0.6968171  0.70527142 0.71387291 0.72224146 0.7297799  0.7380814\n",
      " 0.74660671 0.75488204]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.76206714]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.6968171  0.70527142 0.71387291 0.72224146 0.7297799  0.7380814\n",
      "  0.74660671 0.75488204]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011261414736509323\n",
      "Predicción post entrenamiento : [[0.76055247]]\n",
      "PERDIDAAAA despues: 0.01094223465770483\n",
      "loss en el callback: 0.028228921815752983, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.70527142]\n",
      "  [0.71387291]\n",
      "  [0.72224146]\n",
      "  [0.7297799 ]\n",
      "  [0.7380814 ]\n",
      "  [0.74660671]\n",
      "  [0.75488204]\n",
      "  [0.76206714]]]\n",
      "ejemplar: [0.70527142 0.71387291 0.72224146 0.7297799  0.7380814  0.74660671\n",
      " 0.75488204 0.76206714]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7679527]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.70527142 0.71387291 0.72224146 0.7297799  0.7380814  0.74660671\n",
      "  0.75488204 0.76206714]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007947012782096863\n",
      "Predicción post entrenamiento : [[0.7683125]]\n",
      "PERDIDAAAA despues: 0.008011297322809696\n",
      "loss en el callback: 0.0026602086145430803, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.71387291]\n",
      "  [0.72224146]\n",
      "  [0.7297799 ]\n",
      "  [0.7380814 ]\n",
      "  [0.74660671]\n",
      "  [0.75488204]\n",
      "  [0.76206714]\n",
      "  [0.76795268]]]\n",
      "ejemplar: [0.71387291 0.72224146 0.7297799  0.7380814  0.74660671 0.75488204\n",
      " 0.76206714 0.76795268]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.77564996]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.71387291 0.72224146 0.7297799  0.7380814  0.74660671 0.75488204\n",
      "  0.76206714 0.76795268]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00991128385066986\n",
      "Predicción post entrenamiento : [[0.7751207]]\n",
      "PERDIDAAAA despues: 0.009806176647543907\n",
      "loss en el callback: 0.004381874110549688, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.72224146]\n",
      "  [0.7297799 ]\n",
      "  [0.7380814 ]\n",
      "  [0.74660671]\n",
      "  [0.75488204]\n",
      "  [0.76206714]\n",
      "  [0.76795268]\n",
      "  [0.77564996]]]\n",
      "ejemplar: [0.72224146 0.7297799  0.7380814  0.74660671 0.75488204 0.76206714\n",
      " 0.76795268 0.77564996]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.78230625]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.72224146 0.7297799  0.7380814  0.74660671 0.75488204 0.76206714\n",
      "  0.76795268 0.77564996]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027819389943033457\n",
      "Predicción post entrenamiento : [[0.7807257]]\n",
      "PERDIDAAAA despues: 0.0026177093386650085\n",
      "loss en el callback: 0.03207263723015785, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.7297799 ]\n",
      "  [0.7380814 ]\n",
      "  [0.74660671]\n",
      "  [0.75488204]\n",
      "  [0.76206714]\n",
      "  [0.76795268]\n",
      "  [0.77564996]\n",
      "  [0.78230625]]]\n",
      "ejemplar: [0.7297799  0.7380814  0.74660671 0.75488204 0.76206714 0.76795268\n",
      " 0.77564996 0.78230625]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.787765]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.7297799  0.7380814  0.74660671 0.75488204 0.76206714 0.76795268\n",
      "  0.77564996 0.78230625]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007479907479137182\n",
      "Predicción post entrenamiento : [[0.786417]]\n",
      "PERDIDAAAA despues: 0.007248553913086653\n",
      "loss en el callback: 0.024513741955161095, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.7380814 ]\n",
      "  [0.74660671]\n",
      "  [0.75488204]\n",
      "  [0.76206714]\n",
      "  [0.76795268]\n",
      "  [0.77564996]\n",
      "  [0.78230625]\n",
      "  [0.78776503]]]\n",
      "ejemplar: [0.7380814  0.74660671 0.75488204 0.76206714 0.76795268 0.77564996\n",
      " 0.78230625 0.78776503]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7934879]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.7380814  0.74660671 0.75488204 0.76206714 0.76795268 0.77564996\n",
      "  0.78230625 0.78776503]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006737095536664128\n",
      "Predicción post entrenamiento : [[0.79302794]]\n",
      "PERDIDAAAA despues: 0.0006500433082692325\n",
      "loss en el callback: 0.003269544104114175, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.74660671]\n",
      "  [0.75488204]\n",
      "  [0.76206714]\n",
      "  [0.76795268]\n",
      "  [0.77564996]\n",
      "  [0.78230625]\n",
      "  [0.78776503]\n",
      "  [0.79348791]]]\n",
      "ejemplar: [0.74660671 0.75488204 0.76206714 0.76795268 0.77564996 0.78230625\n",
      " 0.78776503 0.79348791]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.799855]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.74660671 0.75488204 0.76206714 0.76795268 0.77564996 0.78230625\n",
      "  0.78776503 0.79348791]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001999995205551386\n",
      "Predicción post entrenamiento : [[0.79939]]\n",
      "PERDIDAAAA despues: 0.001958622597157955\n",
      "loss en el callback: 0.0033989616204053164, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.75488204]\n",
      "  [0.76206714]\n",
      "  [0.76795268]\n",
      "  [0.77564996]\n",
      "  [0.78230625]\n",
      "  [0.78776503]\n",
      "  [0.79348791]\n",
      "  [0.79985499]]]\n",
      "ejemplar: [0.75488204 0.76206714 0.76795268 0.77564996 0.78230625 0.78776503\n",
      " 0.79348791 0.79985499]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8058114]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.75488204 0.76206714 0.76795268 0.77564996 0.78230625 0.78776503\n",
      "  0.79348791 0.79985499]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003690730081871152\n",
      "Predicción post entrenamiento : [[0.8048332]]\n",
      "PERDIDAAAA despues: 0.0035728290677070618\n",
      "loss en el callback: 0.014317693188786507, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.76206714]\n",
      "  [0.76795268]\n",
      "  [0.77564996]\n",
      "  [0.78230625]\n",
      "  [0.78776503]\n",
      "  [0.79348791]\n",
      "  [0.79985499]\n",
      "  [0.80581141]]]\n",
      "ejemplar: [0.76206714 0.76795268 0.77564996 0.78230625 0.78776503 0.79348791\n",
      " 0.79985499 0.80581141]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8108133]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.76206714 0.76795268 0.77564996 0.78230625 0.78776503 0.79348791\n",
      "  0.79985499 0.80581141]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003454999066889286\n",
      "Predicción post entrenamiento : [[0.8109024]]\n",
      "PERDIDAAAA despues: 0.003465482499450445\n",
      "loss en el callback: 0.00013710148050449789, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.76795268]\n",
      "  [0.77564996]\n",
      "  [0.78230625]\n",
      "  [0.78776503]\n",
      "  [0.79348791]\n",
      "  [0.79985499]\n",
      "  [0.80581141]\n",
      "  [0.81081331]]]\n",
      "ejemplar: [0.76795268 0.77564996 0.78230625 0.78776503 0.79348791 0.79985499\n",
      " 0.80581141 0.81081331]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.81666344]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.76795268 0.77564996 0.78230625 0.78776503 0.79348791 0.79985499\n",
      "  0.80581141 0.81081331]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011419285088777542\n",
      "Predicción post entrenamiento : [[0.8163243]]\n",
      "PERDIDAAAA despues: 0.011346915736794472\n",
      "loss en el callback: 0.0023417449556291103, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.77564996]\n",
      "  [0.78230625]\n",
      "  [0.78776503]\n",
      "  [0.79348791]\n",
      "  [0.79985499]\n",
      "  [0.80581141]\n",
      "  [0.81081331]\n",
      "  [0.81666344]]]\n",
      "ejemplar: [0.77564996 0.78230625 0.78776503 0.79348791 0.79985499 0.80581141\n",
      " 0.81081331 0.81666344]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.8221888]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.77564996 0.78230625 0.78776503 0.79348791 0.79985499 0.80581141\n",
      "  0.81081331 0.81666344]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017360368743538857\n",
      "Predicción post entrenamiento : [[0.82141227]]\n",
      "PERDIDAAAA despues: 0.017156342044472694\n",
      "loss en el callback: 0.01024626288563013, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.78230625]\n",
      "  [0.78776503]\n",
      "  [0.79348791]\n",
      "  [0.79985499]\n",
      "  [0.80581141]\n",
      "  [0.81081331]\n",
      "  [0.81666344]\n",
      "  [0.82218879]]]\n",
      "ejemplar: [0.78230625 0.78776503 0.79348791 0.79985499 0.80581141 0.81081331\n",
      " 0.81666344 0.82218879]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.826824]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.78230625 0.78776503 0.79348791 0.79985499 0.80581141 0.81081331\n",
      "  0.81666344 0.82218879]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005251211114227772\n",
      "Predicción post entrenamiento : [[0.8267488]]\n",
      "PERDIDAAAA despues: 0.005240315105766058\n",
      "loss en el callback: 0.00010502772056497633, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.78776503]\n",
      "  [0.79348791]\n",
      "  [0.79985499]\n",
      "  [0.80581141]\n",
      "  [0.81081331]\n",
      "  [0.81666344]\n",
      "  [0.82218879]\n",
      "  [0.82682401]]]\n",
      "ejemplar: [0.78776503 0.79348791 0.79985499 0.80581141 0.81081331 0.81666344\n",
      " 0.82218879 0.82682401]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8319243]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.78776503 0.79348791 0.79985499 0.80581141 0.81081331 0.81666344\n",
      "  0.82218879 0.82682401]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012039274908602238\n",
      "Predicción post entrenamiento : [[0.8309978]]\n",
      "PERDIDAAAA despues: 0.011836816556751728\n",
      "loss en el callback: 0.014264124445617199, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.79348791]\n",
      "  [0.79985499]\n",
      "  [0.80581141]\n",
      "  [0.81081331]\n",
      "  [0.81666344]\n",
      "  [0.82218879]\n",
      "  [0.82682401]\n",
      "  [0.83192432]]]\n",
      "ejemplar: [0.79348791 0.79985499 0.80581141 0.81081331 0.81666344 0.82218879\n",
      " 0.82682401 0.83192432]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8362364]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.79348791 0.79985499 0.80581141 0.81081331 0.81666344 0.82218879\n",
      "  0.82682401 0.83192432]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015060053556226194\n",
      "Predicción post entrenamiento : [[0.836017]]\n",
      "PERDIDAAAA despues: 0.00015603371139150113\n",
      "loss en el callback: 0.0008413656032644212, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.79985499]\n",
      "  [0.80581141]\n",
      "  [0.81081331]\n",
      "  [0.81666344]\n",
      "  [0.82218879]\n",
      "  [0.82682401]\n",
      "  [0.83192432]\n",
      "  [0.83623642]]]\n",
      "ejemplar: [0.79985499 0.80581141 0.81081331 0.81666344 0.82218879 0.82682401\n",
      " 0.83192432 0.83623642]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.84122247]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.79985499 0.80581141 0.81081331 0.81666344 0.82218879 0.82682401\n",
      "  0.83192432 0.83623642]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004126843996345997\n",
      "Predicción post entrenamiento : [[0.8420215]]\n",
      "PERDIDAAAA despues: 0.0040248180739581585\n",
      "loss en el callback: 0.012434408999979496, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.80581141]\n",
      "  [0.81081331]\n",
      "  [0.81666344]\n",
      "  [0.82218879]\n",
      "  [0.82682401]\n",
      "  [0.83192432]\n",
      "  [0.83623642]\n",
      "  [0.84122247]]]\n",
      "ejemplar: [0.80581141 0.81081331 0.81666344 0.82218879 0.82682401 0.83192432\n",
      " 0.83623642 0.84122247]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8469663]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.80581141 0.81081331 0.81666344 0.82218879 0.82682401 0.83192432\n",
      "  0.83623642 0.84122247]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012425546301528811\n",
      "Predicción post entrenamiento : [[0.8473421]]\n",
      "PERDIDAAAA despues: 0.0012162057682871819\n",
      "loss en el callback: 0.0025969340931624174, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.81081331]\n",
      "  [0.81666344]\n",
      "  [0.82218879]\n",
      "  [0.82682401]\n",
      "  [0.83192432]\n",
      "  [0.83623642]\n",
      "  [0.84122247]\n",
      "  [0.84696633]]]\n",
      "ejemplar: [0.81081331 0.81666344 0.82218879 0.82682401 0.83192432 0.83623642\n",
      " 0.84122247 0.84696633]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8520863]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.81081331 0.81666344 0.82218879 0.82682401 0.83192432 0.83623642\n",
      "  0.84122247 0.84696633]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003102643182501197\n",
      "Predicción post entrenamiento : [[0.85210025]]\n",
      "PERDIDAAAA despues: 0.0031010895036160946\n",
      "loss en el callback: 2.928782350863912e-06, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.81666344]\n",
      "  [0.82218879]\n",
      "  [0.82682401]\n",
      "  [0.83192432]\n",
      "  [0.83623642]\n",
      "  [0.84122247]\n",
      "  [0.84696633]\n",
      "  [0.85208631]]]\n",
      "ejemplar: [0.81666344 0.82218879 0.82682401 0.83192432 0.83623642 0.84122247\n",
      " 0.84696633 0.85208631]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.85688835]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.81666344 0.82218879 0.82682401 0.83192432 0.83623642 0.84122247\n",
      "  0.84696633 0.85208631]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010685925371944904\n",
      "Predicción post entrenamiento : [[0.8558569]]\n",
      "PERDIDAAAA despues: 0.0011370917782187462\n",
      "loss en el callback: 0.013985222205519676, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.82218879]\n",
      "  [0.82682401]\n",
      "  [0.83192432]\n",
      "  [0.83623642]\n",
      "  [0.84122247]\n",
      "  [0.84696633]\n",
      "  [0.85208631]\n",
      "  [0.85688835]]]\n",
      "ejemplar: [0.82218879 0.82682401 0.83192432 0.83623642 0.84122247 0.84696633\n",
      " 0.85208631 0.85688835]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8604288]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.82218879 0.82682401 0.83192432 0.83623642 0.84122247 0.84696633\n",
      "  0.85208631 0.85688835]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000208105833735317\n",
      "Predicción post entrenamiento : [[0.86047363]]\n",
      "PERDIDAAAA despues: 0.00020681462774518877\n",
      "loss en el callback: 3.65079686162062e-05, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.82682401]\n",
      "  [0.83192432]\n",
      "  [0.83623642]\n",
      "  [0.84122247]\n",
      "  [0.84696633]\n",
      "  [0.85208631]\n",
      "  [0.85688835]\n",
      "  [0.86042881]]]\n",
      "ejemplar: [0.82682401 0.83192432 0.83623642 0.84122247 0.84696633 0.85208631\n",
      " 0.85688835 0.86042881]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8648863]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.82682401 0.83192432 0.83623642 0.84122247 0.84696633 0.85208631\n",
      "  0.85688835 0.86042881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023353691212832928\n",
      "Predicción post entrenamiento : [[0.86530054]]\n",
      "PERDIDAAAA despues: 0.002295502694323659\n",
      "loss en el callback: 0.0032564494758844376, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.83192432]\n",
      "  [0.83623642]\n",
      "  [0.84122247]\n",
      "  [0.84696633]\n",
      "  [0.85208631]\n",
      "  [0.85688835]\n",
      "  [0.86042881]\n",
      "  [0.86488628]]]\n",
      "ejemplar: [0.83192432 0.83623642 0.84122247 0.84696633 0.85208631 0.85688835\n",
      " 0.86042881 0.86488628]\n",
      "y: 1.0\n",
      "Predicción : [[0.8697884]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.83192432 0.83623642 0.84122247 0.84696633 0.85208631 0.85688835\n",
      "  0.86042881 0.86488628]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01695505902171135\n",
      "Predicción post entrenamiento : [[0.87116385]]\n",
      "PERDIDAAAA despues: 0.01659875549376011\n",
      "loss en el callback: 0.04147361218929291, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.83623642]\n",
      "  [0.84122247]\n",
      "  [0.84696633]\n",
      "  [0.85208631]\n",
      "  [0.85688835]\n",
      "  [0.86042881]\n",
      "  [0.86488628]\n",
      "  [0.86978841]]]\n",
      "ejemplar: [0.83623642 0.84122247 0.84696633 0.85208631 0.85688835 0.86042881\n",
      " 0.86488628 0.86978841]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.87558866]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.83623642 0.84122247 0.84696633 0.85208631 0.85688835 0.86042881\n",
      "  0.86488628 0.86978841]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00901842676103115\n",
      "Predicción post entrenamiento : [[0.876233]]\n",
      "PERDIDAAAA despues: 0.008896464481949806\n",
      "loss en el callback: 0.007580352481454611, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.84122247]\n",
      "  [0.84696633]\n",
      "  [0.85208631]\n",
      "  [0.85688835]\n",
      "  [0.86042881]\n",
      "  [0.86488628]\n",
      "  [0.86978841]\n",
      "  [0.87558866]]]\n",
      "ejemplar: [0.84122247 0.84696633 0.85208631 0.85688835 0.86042881 0.86488628\n",
      " 0.86978841 0.87558866]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8808145]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.84122247 0.84696633 0.85208631 0.85688835 0.86042881 0.86488628\n",
      "  0.86978841 0.87558866]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.381252023857087e-05\n",
      "Predicción post entrenamiento : [[0.8804326]]\n",
      "PERDIDAAAA despues: 7.005959923844784e-05\n",
      "loss en el callback: 0.002381072612479329, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.84696633]\n",
      "  [0.85208631]\n",
      "  [0.85688835]\n",
      "  [0.86042881]\n",
      "  [0.86488628]\n",
      "  [0.86978841]\n",
      "  [0.87558866]\n",
      "  [0.88081449]]]\n",
      "ejemplar: [0.84696633 0.85208631 0.85688835 0.86042881 0.86488628 0.86978841\n",
      " 0.87558866 0.88081449]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8849835]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.84696633 0.85208631 0.85688835 0.86042881 0.86488628 0.86978841\n",
      "  0.87558866 0.88081449]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.94093110319227e-05\n",
      "Predicción post entrenamiento : [[0.8847389]]\n",
      "PERDIDAAAA despues: 4.603104025591165e-05\n",
      "loss en el callback: 0.0010868643876165152, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.85208631]\n",
      "  [0.85688835]\n",
      "  [0.86042881]\n",
      "  [0.86488628]\n",
      "  [0.86978841]\n",
      "  [0.87558866]\n",
      "  [0.88081449]\n",
      "  [0.88498348]]]\n",
      "ejemplar: [0.85208631 0.85688835 0.86042881 0.86488628 0.86978841 0.87558866\n",
      " 0.88081449 0.88498348]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.88902044]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.85208631 0.85688835 0.86042881 0.86488628 0.86978841 0.87558866\n",
      "  0.88081449 0.88498348]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001609987928532064\n",
      "Predicción post entrenamiento : [[0.8889533]]\n",
      "PERDIDAAAA despues: 0.001604606513865292\n",
      "loss en el callback: 8.537487155990675e-05, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.85688835]\n",
      "  [0.86042881]\n",
      "  [0.86488628]\n",
      "  [0.86978841]\n",
      "  [0.87558866]\n",
      "  [0.88081449]\n",
      "  [0.88498348]\n",
      "  [0.88902044]]]\n",
      "ejemplar: [0.85688835 0.86042881 0.86488628 0.86978841 0.87558866 0.88081449\n",
      " 0.88498348 0.88902044]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.89311314]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.85688835 0.86042881 0.86488628 0.86978841 0.87558866 0.88081449\n",
      "  0.88498348 0.88902044]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003473964985460043\n",
      "Predicción post entrenamiento : [[0.8924531]]\n",
      "PERDIDAAAA despues: 0.003396592102944851\n",
      "loss en el callback: 0.007693675346672535, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.86042881]\n",
      "  [0.86488628]\n",
      "  [0.86978841]\n",
      "  [0.87558866]\n",
      "  [0.88081449]\n",
      "  [0.88498348]\n",
      "  [0.88902044]\n",
      "  [0.89311314]]]\n",
      "ejemplar: [0.86042881 0.86488628 0.86978841 0.87558866 0.88081449 0.88498348\n",
      " 0.88902044 0.89311314]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.89656943]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.86042881 0.86488628 0.86978841 0.87558866 0.88081449 0.88498348\n",
      "  0.88902044 0.89311314]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001720135915093124\n",
      "Predicción post entrenamiento : [[0.8966528]]\n",
      "PERDIDAAAA despues: 0.0017270597163587809\n",
      "loss en el callback: 0.00015837582759559155, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.86488628]\n",
      "  [0.86978841]\n",
      "  [0.87558866]\n",
      "  [0.88081449]\n",
      "  [0.88498348]\n",
      "  [0.88902044]\n",
      "  [0.89311314]\n",
      "  [0.89656943]]]\n",
      "ejemplar: [0.86488628 0.86978841 0.87558866 0.88081449 0.88498348 0.88902044\n",
      " 0.89311314 0.89656943]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9010953]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.86488628 0.86978841 0.87558866 0.88081449 0.88498348 0.88902044\n",
      "  0.89311314 0.89656943]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000668382621370256\n",
      "Predicción post entrenamiento : [[0.901262]]\n",
      "PERDIDAAAA despues: 0.0006770305917598307\n",
      "loss en el callback: 0.0005885902210138738, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.86978841]\n",
      "  [0.87558866]\n",
      "  [0.88081449]\n",
      "  [0.88498348]\n",
      "  [0.88902044]\n",
      "  [0.89311314]\n",
      "  [0.89656943]\n",
      "  [0.90109527]]]\n",
      "ejemplar: [0.86978841 0.87558866 0.88081449 0.88498348 0.88902044 0.89311314\n",
      " 0.89656943 0.90109527]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.905779]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.86978841 0.87558866 0.88081449 0.88498348 0.88902044 0.89311314\n",
      "  0.89656943 0.90109527]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023762527853250504\n",
      "Predicción post entrenamiento : [[0.90468645]]\n",
      "PERDIDAAAA despues: 0.002270929515361786\n",
      "loss en el callback: 0.020296581089496613, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.87558866]\n",
      "  [0.88081449]\n",
      "  [0.88498348]\n",
      "  [0.88902044]\n",
      "  [0.89311314]\n",
      "  [0.89656943]\n",
      "  [0.90109527]\n",
      "  [0.905779  ]]]\n",
      "ejemplar: [0.87558866 0.88081449 0.88498348 0.88902044 0.89311314 0.89656943\n",
      " 0.90109527 0.905779  ]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.90912175]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.87558866 0.88081449 0.88498348 0.88902044 0.89311314 0.89656943\n",
      "  0.90109527 0.905779  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034885103814303875\n",
      "Predicción post entrenamiento : [[0.90937066]]\n",
      "PERDIDAAAA despues: 0.0035179753322154284\n",
      "loss en el callback: 0.0015614178264513612, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.88081449]\n",
      "  [0.88498348]\n",
      "  [0.88902044]\n",
      "  [0.89311314]\n",
      "  [0.89656943]\n",
      "  [0.90109527]\n",
      "  [0.905779  ]\n",
      "  [0.90912175]]]\n",
      "ejemplar: [0.88081449 0.88498348 0.88902044 0.89311314 0.89656943 0.90109527\n",
      " 0.905779   0.90912175]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.91340935]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.88081449 0.88498348 0.88902044 0.89311314 0.89656943 0.90109527\n",
      "  0.905779   0.90912175]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00500029232352972\n",
      "Predicción post entrenamiento : [[0.91377336]]\n",
      "PERDIDAAAA despues: 0.005051904357969761\n",
      "loss en el callback: 0.0035962604451924562, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.88498348]\n",
      "  [0.88902044]\n",
      "  [0.89311314]\n",
      "  [0.89656943]\n",
      "  [0.90109527]\n",
      "  [0.905779  ]\n",
      "  [0.90912175]\n",
      "  [0.91340935]]]\n",
      "ejemplar: [0.88498348 0.88902044 0.89311314 0.89656943 0.90109527 0.905779\n",
      " 0.90912175 0.91340935]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9175122]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.88498348 0.88902044 0.89311314 0.89656943 0.90109527 0.905779\n",
      "  0.90912175 0.91340935]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00894449558109045\n",
      "Predicción post entrenamiento : [[0.91576433]]\n",
      "PERDIDAAAA despues: 0.008616944774985313\n",
      "loss en el callback: 0.04753797873854637, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.88902044]\n",
      "  [0.89311314]\n",
      "  [0.89656943]\n",
      "  [0.90109527]\n",
      "  [0.905779  ]\n",
      "  [0.90912175]\n",
      "  [0.91340935]\n",
      "  [0.91751218]]]\n",
      "ejemplar: [0.88902044 0.89311314 0.89656943 0.90109527 0.905779   0.90912175\n",
      " 0.91340935 0.91751218]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.919473]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.88902044 0.89311314 0.89656943 0.90109527 0.905779   0.90912175\n",
      "  0.91340935 0.91751218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02101541869342327\n",
      "Predicción post entrenamiento : [[0.9186767]]\n",
      "PERDIDAAAA despues: 0.020785173401236534\n",
      "loss en el callback: 0.013800159096717834, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.89311314]\n",
      "  [0.89656943]\n",
      "  [0.90109527]\n",
      "  [0.905779  ]\n",
      "  [0.90912175]\n",
      "  [0.91340935]\n",
      "  [0.91751218]\n",
      "  [0.91947299]]]\n",
      "ejemplar: [0.89311314 0.89656943 0.90109527 0.905779   0.90912175 0.91340935\n",
      " 0.91751218 0.91947299]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9223811]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.89311314 0.89656943 0.90109527 0.905779   0.90912175 0.91340935\n",
      "  0.91751218 0.91947299]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019096188247203827\n",
      "Predicción post entrenamiento : [[0.9201609]]\n",
      "PERDIDAAAA despues: 0.01848750002682209\n",
      "loss en el callback: 0.0822858139872551, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.89656943]\n",
      "  [0.90109527]\n",
      "  [0.905779  ]\n",
      "  [0.90912175]\n",
      "  [0.91340935]\n",
      "  [0.91751218]\n",
      "  [0.91947299]\n",
      "  [0.9223811 ]]]\n",
      "ejemplar: [0.89656943 0.90109527 0.905779   0.90912175 0.91340935 0.91751218\n",
      " 0.91947299 0.9223811 ]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.92382044]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.89656943 0.90109527 0.905779   0.90912175 0.91340935 0.91751218\n",
      "  0.91947299 0.9223811 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004105750005692244\n",
      "Predicción post entrenamiento : [[0.9229252]]\n",
      "PERDIDAAAA despues: 0.003991821780800819\n",
      "loss en el callback: 0.015420632436871529, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.90109527]\n",
      "  [0.905779  ]\n",
      "  [0.90912175]\n",
      "  [0.91340935]\n",
      "  [0.91751218]\n",
      "  [0.91947299]\n",
      "  [0.9223811 ]\n",
      "  [0.92382044]]]\n",
      "ejemplar: [0.90109527 0.905779   0.90912175 0.91340935 0.91751218 0.91947299\n",
      " 0.9223811  0.92382044]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9266878]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.90109527 0.905779   0.90912175 0.91340935 0.91751218 0.91947299\n",
      "  0.9223811  0.92382044]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005237088073045015\n",
      "Predicción post entrenamiento : [[0.92629147]]\n",
      "PERDIDAAAA despues: 0.005179884843528271\n",
      "loss en el callback: 0.003580778371542692, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.905779  ]\n",
      "  [0.90912175]\n",
      "  [0.91340935]\n",
      "  [0.91751218]\n",
      "  [0.91947299]\n",
      "  [0.9223811 ]\n",
      "  [0.92382044]\n",
      "  [0.92668778]]]\n",
      "ejemplar: [0.905779   0.90912175 0.91340935 0.91751218 0.91947299 0.9223811\n",
      " 0.92382044 0.92668778]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.929794]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.905779   0.90912175 0.91340935 0.91751218 0.91947299 0.9223811\n",
      "  0.92382044 0.92668778]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008632100187242031\n",
      "Predicción post entrenamiento : [[0.92799807]]\n",
      "PERDIDAAAA despues: 0.00830160640180111\n",
      "loss en el callback: 0.05567799508571625, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.90912175]\n",
      "  [0.91340935]\n",
      "  [0.91751218]\n",
      "  [0.91947299]\n",
      "  [0.9223811 ]\n",
      "  [0.92382044]\n",
      "  [0.92668778]\n",
      "  [0.92979401]]]\n",
      "ejemplar: [0.90912175 0.91340935 0.91751218 0.91947299 0.9223811  0.92382044\n",
      " 0.92668778 0.92979401]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.93110186]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.90912175 0.91340935 0.91751218 0.91947299 0.9223811  0.92382044\n",
      "  0.92668778 0.92979401]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010239615105092525\n",
      "Predicción post entrenamiento : [[0.9304731]]\n",
      "PERDIDAAAA despues: 0.010112758725881577\n",
      "loss en el callback: 0.00881347618997097, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.91340935]\n",
      "  [0.91751218]\n",
      "  [0.91947299]\n",
      "  [0.9223811 ]\n",
      "  [0.92382044]\n",
      "  [0.92668778]\n",
      "  [0.92979401]\n",
      "  [0.93110186]]]\n",
      "ejemplar: [0.91340935 0.91751218 0.91947299 0.9223811  0.92382044 0.92668778\n",
      " 0.92979401 0.93110186]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9334832]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.91340935 0.91751218 0.91947299 0.9223811  0.92382044 0.92668778\n",
      "  0.92979401 0.93110186]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021372311748564243\n",
      "Predicción post entrenamiento : [[0.93300766]]\n",
      "PERDIDAAAA despues: 0.002093489980325103\n",
      "loss en el callback: 0.0045999824069440365, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.91751218]\n",
      "  [0.91947299]\n",
      "  [0.9223811 ]\n",
      "  [0.92382044]\n",
      "  [0.92668778]\n",
      "  [0.92979401]\n",
      "  [0.93110186]\n",
      "  [0.93348318]]]\n",
      "ejemplar: [0.91751218 0.91947299 0.9223811  0.92382044 0.92668778 0.92979401\n",
      " 0.93110186 0.93348318]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9355812]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.91751218 0.91947299 0.9223811  0.92382044 0.92668778 0.92979401\n",
      "  0.93110186 0.93348318]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005751234944909811\n",
      "Predicción post entrenamiento : [[0.93532664]]\n",
      "PERDIDAAAA despues: 0.005712687969207764\n",
      "loss en el callback: 0.0016519048949703574, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.91947299]\n",
      "  [0.9223811 ]\n",
      "  [0.92382044]\n",
      "  [0.92668778]\n",
      "  [0.92979401]\n",
      "  [0.93110186]\n",
      "  [0.93348318]\n",
      "  [0.93558121]]]\n",
      "ejemplar: [0.91947299 0.9223811  0.92382044 0.92668778 0.92979401 0.93110186\n",
      " 0.93348318 0.93558121]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.93742806]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.91947299 0.9223811  0.92382044 0.92668778 0.92979401 0.93110186\n",
      "  0.93348318 0.93558121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00957090687006712\n",
      "Predicción post entrenamiento : [[0.9373636]]\n",
      "PERDIDAAAA despues: 0.009558304212987423\n",
      "loss en el callback: 0.00011878316581714898, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.9223811 ]\n",
      "  [0.92382044]\n",
      "  [0.92668778]\n",
      "  [0.92979401]\n",
      "  [0.93110186]\n",
      "  [0.93348318]\n",
      "  [0.93558121]\n",
      "  [0.93742806]]]\n",
      "ejemplar: [0.9223811  0.92382044 0.92668778 0.92979401 0.93110186 0.93348318\n",
      " 0.93558121 0.93742806]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.93956375]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.9223811  0.92382044 0.92668778 0.92979401 0.93110186 0.93348318\n",
      "  0.93558121 0.93742806]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024260876700282097\n",
      "Predicción post entrenamiento : [[0.9383956]]\n",
      "PERDIDAAAA despues: 0.023898348212242126\n",
      "loss en el callback: 0.02951086312532425, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.92382044]\n",
      "  [0.92668778]\n",
      "  [0.92979401]\n",
      "  [0.93110186]\n",
      "  [0.93348318]\n",
      "  [0.93558121]\n",
      "  [0.93742806]\n",
      "  [0.93956375]]]\n",
      "ejemplar: [0.92382044 0.92668778 0.92979401 0.93110186 0.93348318 0.93558121\n",
      " 0.93742806 0.93956375]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9404102]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.92382044 0.92668778 0.92979401 0.93110186 0.93348318 0.93558121\n",
      "  0.93742806 0.93956375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014913954772055149\n",
      "Predicción post entrenamiento : [[0.9401911]]\n",
      "PERDIDAAAA despues: 0.014860487543046474\n",
      "loss en el callback: 0.0013379500014707446, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.92668778]\n",
      "  [0.92979401]\n",
      "  [0.93110186]\n",
      "  [0.93348318]\n",
      "  [0.93558121]\n",
      "  [0.93742806]\n",
      "  [0.93956375]\n",
      "  [0.9404102 ]]]\n",
      "ejemplar: [0.92668778 0.92979401 0.93110186 0.93348318 0.93558121 0.93742806\n",
      " 0.93956375 0.9404102 ]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9424246]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.92668778 0.92979401 0.93110186 0.93348318 0.93558121 0.93742806\n",
      "  0.93956375 0.9404102 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022879106923937798\n",
      "Predicción post entrenamiento : [[0.9413862]]\n",
      "PERDIDAAAA despues: 0.022566059604287148\n",
      "loss en el callback: 0.024644136428833008, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.92979401]\n",
      "  [0.93110186]\n",
      "  [0.93348318]\n",
      "  [0.93558121]\n",
      "  [0.93742806]\n",
      "  [0.93956375]\n",
      "  [0.9404102 ]\n",
      "  [0.9424246 ]]]\n",
      "ejemplar: [0.92979401 0.93110186 0.93348318 0.93558121 0.93742806 0.93956375\n",
      " 0.9404102  0.9424246 ]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9434127]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.92979401 0.93110186 0.93348318 0.93558121 0.93742806 0.93956375\n",
      "  0.9404102  0.9424246 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03343586623668671\n",
      "Predicción post entrenamiento : [[0.9423563]]\n",
      "PERDIDAAAA despues: 0.03305063769221306\n",
      "loss en el callback: 0.028268853202462196, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.93110186]\n",
      "  [0.93348318]\n",
      "  [0.93558121]\n",
      "  [0.93742806]\n",
      "  [0.93956375]\n",
      "  [0.9404102 ]\n",
      "  [0.9424246 ]\n",
      "  [0.94341272]]]\n",
      "ejemplar: [0.93110186 0.93348318 0.93558121 0.93742806 0.93956375 0.9404102\n",
      " 0.9424246  0.94341272]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9440468]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.93110186 0.93348318 0.93558121 0.93742806 0.93956375 0.9404102\n",
      "  0.9424246  0.94341272]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02325415052473545\n",
      "Predicción post entrenamiento : [[0.9433761]]\n",
      "PERDIDAAAA despues: 0.023050054907798767\n",
      "loss en el callback: 0.010931450873613358, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.93348318]\n",
      "  [0.93558121]\n",
      "  [0.93742806]\n",
      "  [0.93956375]\n",
      "  [0.9404102 ]\n",
      "  [0.9424246 ]\n",
      "  [0.94341272]\n",
      "  [0.9440468 ]]]\n",
      "ejemplar: [0.93348318 0.93558121 0.93742806 0.93956375 0.9404102  0.9424246\n",
      " 0.94341272 0.9440468 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9452069]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.93348318 0.93558121 0.93742806 0.93956375 0.9404102  0.9424246\n",
      "  0.94341272 0.9440468 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031156698241829872\n",
      "Predicción post entrenamiento : [[0.9445745]]\n",
      "PERDIDAAAA despues: 0.030933842062950134\n",
      "loss en el callback: 0.011274207383394241, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.93558121]\n",
      "  [0.93742806]\n",
      "  [0.93956375]\n",
      "  [0.9404102 ]\n",
      "  [0.9424246 ]\n",
      "  [0.94341272]\n",
      "  [0.9440468 ]\n",
      "  [0.94520688]]]\n",
      "ejemplar: [0.93558121 0.93742806 0.93956375 0.9404102  0.9424246  0.94341272\n",
      " 0.9440468  0.94520688]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9462113]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.93558121 0.93742806 0.93956375 0.9404102  0.9424246  0.94341272\n",
      "  0.9440468  0.94520688]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03151228278875351\n",
      "Predicción post entrenamiento : [[0.9457509]]\n",
      "PERDIDAAAA despues: 0.03134904429316521\n",
      "loss en el callback: 0.006009380333125591, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.93742806]\n",
      "  [0.93956375]\n",
      "  [0.9404102 ]\n",
      "  [0.9424246 ]\n",
      "  [0.94341272]\n",
      "  [0.9440468 ]\n",
      "  [0.94520688]\n",
      "  [0.94621128]]]\n",
      "ejemplar: [0.93742806 0.93956375 0.9404102  0.9424246  0.94341272 0.9440468\n",
      " 0.94520688 0.94621128]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.94722134]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.93742806 0.93956375 0.9404102  0.9424246  0.94341272 0.9440468\n",
      "  0.94520688 0.94621128]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021994726732373238\n",
      "Predicción post entrenamiento : [[0.94623196]]\n",
      "PERDIDAAAA despues: 0.021702243015170097\n",
      "loss en el callback: 0.02493906579911709, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.93956375]\n",
      "  [0.9404102 ]\n",
      "  [0.9424246 ]\n",
      "  [0.94341272]\n",
      "  [0.9440468 ]\n",
      "  [0.94520688]\n",
      "  [0.94621128]\n",
      "  [0.94722134]]]\n",
      "ejemplar: [0.93956375 0.9404102  0.9424246  0.94341272 0.9440468  0.94520688\n",
      " 0.94621128 0.94722134]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9475636]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.93956375 0.9404102  0.9424246  0.94341272 0.9440468  0.94520688\n",
      "  0.94621128 0.94722134]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02482505701482296\n",
      "Predicción post entrenamiento : [[0.9468173]]\n",
      "PERDIDAAAA despues: 0.02459043636918068\n",
      "loss en el callback: 0.015350943431258202, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.9404102 ]\n",
      "  [0.9424246 ]\n",
      "  [0.94341272]\n",
      "  [0.9440468 ]\n",
      "  [0.94520688]\n",
      "  [0.94621128]\n",
      "  [0.94722134]\n",
      "  [0.94756359]]]\n",
      "ejemplar: [0.9404102  0.9424246  0.94341272 0.9440468  0.94520688 0.94621128\n",
      " 0.94722134 0.94756359]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9478785]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.9404102  0.9424246  0.94341272 0.9440468  0.94520688 0.94621128\n",
      "  0.94722134 0.94756359]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035234302282333374\n",
      "Predicción post entrenamiento : [[0.94714373]]\n",
      "PERDIDAAAA despues: 0.03495900332927704\n",
      "loss en el callback: 0.01573772169649601, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.9424246 ]\n",
      "  [0.94341272]\n",
      "  [0.9440468 ]\n",
      "  [0.94520688]\n",
      "  [0.94621128]\n",
      "  [0.94722134]\n",
      "  [0.94756359]\n",
      "  [0.94787848]]]\n",
      "ejemplar: [0.9424246  0.94341272 0.9440468  0.94520688 0.94621128 0.94722134\n",
      " 0.94756359 0.94787848]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.94826716]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.9424246  0.94341272 0.9440468  0.94520688 0.94621128 0.94722134\n",
      "  0.94756359 0.94787848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0691026821732521\n",
      "Predicción post entrenamiento : [[0.9469962]]\n",
      "PERDIDAAAA despues: 0.06843609362840652\n",
      "loss en el callback: 0.04810769483447075, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.94341272]\n",
      "  [0.9440468 ]\n",
      "  [0.94520688]\n",
      "  [0.94621128]\n",
      "  [0.94722134]\n",
      "  [0.94756359]\n",
      "  [0.94787848]\n",
      "  [0.94826716]]]\n",
      "ejemplar: [0.94341272 0.9440468  0.94520688 0.94621128 0.94722134 0.94756359\n",
      " 0.94787848 0.94826716]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.94781315]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.94341272 0.9440468  0.94520688 0.94621128 0.94722134 0.94756359\n",
      "  0.94787848 0.94826716]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11738941073417664\n",
      "Predicción post entrenamiento : [[0.9460695]]\n",
      "PERDIDAAAA despues: 0.1161976158618927\n",
      "loss en el callback: 0.08709504455327988, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.9440468 ]\n",
      "  [0.94520688]\n",
      "  [0.94621128]\n",
      "  [0.94722134]\n",
      "  [0.94756359]\n",
      "  [0.94787848]\n",
      "  [0.94826716]\n",
      "  [0.94781315]]]\n",
      "ejemplar: [0.9440468  0.94520688 0.94621128 0.94722134 0.94756359 0.94787848\n",
      " 0.94826716 0.94781315]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.94682354]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.9440468  0.94520688 0.94621128 0.94722134 0.94756359 0.94787848\n",
      "  0.94826716 0.94781315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07950423657894135\n",
      "Predicción post entrenamiento : [[0.9448011]]\n",
      "PERDIDAAAA despues: 0.07836780697107315\n",
      "loss en el callback: 0.11362984031438828, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.94520688]\n",
      "  [0.94621128]\n",
      "  [0.94722134]\n",
      "  [0.94756359]\n",
      "  [0.94787848]\n",
      "  [0.94826716]\n",
      "  [0.94781315]\n",
      "  [0.94682354]]]\n",
      "ejemplar: [0.94520688 0.94621128 0.94722134 0.94756359 0.94787848 0.94826716\n",
      " 0.94781315 0.94682354]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.94555914]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.94520688 0.94621128 0.94722134 0.94756359 0.94787848 0.94826716\n",
      "  0.94781315 0.94682354]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05649841949343681\n",
      "Predicción post entrenamiento : [[0.94325167]]\n",
      "PERDIDAAAA despues: 0.05540680140256882\n",
      "loss en el callback: 0.12293528765439987, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.94621128]\n",
      "  [0.94722134]\n",
      "  [0.94756359]\n",
      "  [0.94787848]\n",
      "  [0.94826716]\n",
      "  [0.94781315]\n",
      "  [0.94682354]\n",
      "  [0.94555914]]]\n",
      "ejemplar: [0.94621128 0.94722134 0.94756359 0.94787848 0.94826716 0.94781315\n",
      " 0.94682354 0.94555914]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9438096]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.94621128 0.94722134 0.94756359 0.94787848 0.94826716 0.94781315\n",
      "  0.94682354 0.94555914]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07781368494033813\n",
      "Predicción post entrenamiento : [[0.9427607]]\n",
      "PERDIDAAAA despues: 0.0772295892238617\n",
      "loss en el callback: 0.0372893288731575, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.94722134]\n",
      "  [0.94756359]\n",
      "  [0.94787848]\n",
      "  [0.94826716]\n",
      "  [0.94781315]\n",
      "  [0.94682354]\n",
      "  [0.94555914]\n",
      "  [0.94380963]]]\n",
      "ejemplar: [0.94722134 0.94756359 0.94787848 0.94826716 0.94781315 0.94682354\n",
      " 0.94555914 0.94380963]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.94308084]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.94722134 0.94756359 0.94787848 0.94826716 0.94781315 0.94682354\n",
      "  0.94555914 0.94380963]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05369817838072777\n",
      "Predicción post entrenamiento : [[0.941509]]\n",
      "PERDIDAAAA despues: 0.05297217145562172\n",
      "loss en el callback: 0.06465420871973038, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.94756359]\n",
      "  [0.94787848]\n",
      "  [0.94826716]\n",
      "  [0.94781315]\n",
      "  [0.94682354]\n",
      "  [0.94555914]\n",
      "  [0.94380963]\n",
      "  [0.94308084]]]\n",
      "ejemplar: [0.94756359 0.94787848 0.94826716 0.94781315 0.94682354 0.94555914\n",
      " 0.94380963 0.94308084]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9415002]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.94756359 0.94787848 0.94826716 0.94781315 0.94682354 0.94555914\n",
      "  0.94380963 0.94308084]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06982452422380447\n",
      "Predicción post entrenamiento : [[0.94005245]]\n",
      "PERDIDAAAA despues: 0.0690615102648735\n",
      "loss en el callback: 0.05987054109573364, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.94787848]\n",
      "  [0.94826716]\n",
      "  [0.94781315]\n",
      "  [0.94682354]\n",
      "  [0.94555914]\n",
      "  [0.94380963]\n",
      "  [0.94308084]\n",
      "  [0.94150019]]]\n",
      "ejemplar: [0.94787848 0.94826716 0.94781315 0.94682354 0.94555914 0.94380963\n",
      " 0.94308084 0.94150019]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.93981934]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.94787848 0.94826716 0.94781315 0.94682354 0.94555914 0.94380963\n",
      "  0.94308084 0.94150019]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031581416726112366\n",
      "Predicción post entrenamiento : [[0.9399454]]\n",
      "PERDIDAAAA despues: 0.03162623569369316\n",
      "loss en el callback: 0.0007580559467896819, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.94826716]\n",
      "  [0.94781315]\n",
      "  [0.94682354]\n",
      "  [0.94555914]\n",
      "  [0.94380963]\n",
      "  [0.94308084]\n",
      "  [0.94150019]\n",
      "  [0.93981934]]]\n",
      "ejemplar: [0.94826716 0.94781315 0.94682354 0.94555914 0.94380963 0.94308084\n",
      " 0.94150019 0.93981934]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9394167]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.94826716 0.94781315 0.94682354 0.94555914 0.94380963 0.94308084\n",
      "  0.94150019 0.93981934]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017520537599921227\n",
      "Predicción post entrenamiento : [[0.9379511]]\n",
      "PERDIDAAAA despues: 0.017134692519903183\n",
      "loss en el callback: 0.053704310208559036, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.94781315]\n",
      "  [0.94682354]\n",
      "  [0.94555914]\n",
      "  [0.94380963]\n",
      "  [0.94308084]\n",
      "  [0.94150019]\n",
      "  [0.93981934]\n",
      "  [0.93941671]]]\n",
      "ejemplar: [0.94781315 0.94682354 0.94555914 0.94380963 0.94308084 0.94150019\n",
      " 0.93981934 0.93941671]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.93703073]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.94781315 0.94682354 0.94555914 0.94380963 0.94308084 0.94150019\n",
      "  0.93981934 0.93941671]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014845668338239193\n",
      "Predicción post entrenamiento : [[0.9353033]]\n",
      "PERDIDAAAA despues: 0.014427694492042065\n",
      "loss en el callback: 0.06743885576725006, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.94682354]\n",
      "  [0.94555914]\n",
      "  [0.94380963]\n",
      "  [0.94308084]\n",
      "  [0.94150019]\n",
      "  [0.93981934]\n",
      "  [0.93941671]\n",
      "  [0.93703073]]]\n",
      "ejemplar: [0.94682354 0.94555914 0.94380963 0.94308084 0.94150019 0.93981934\n",
      " 0.93941671 0.93703073]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.93416965]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.94682354 0.94555914 0.94380963 0.94308084 0.94150019 0.93981934\n",
      "  0.93941671 0.93703073]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007801826577633619\n",
      "Predicción post entrenamiento : [[0.9343364]]\n",
      "PERDIDAAAA despues: 0.0007895270246081054\n",
      "loss en el callback: 0.0009024031460285187, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.94555914]\n",
      "  [0.94380963]\n",
      "  [0.94308084]\n",
      "  [0.94150019]\n",
      "  [0.93981934]\n",
      "  [0.93941671]\n",
      "  [0.93703073]\n",
      "  [0.93416965]]]\n",
      "ejemplar: [0.94555914 0.94380963 0.94308084 0.94150019 0.93981934 0.93941671\n",
      " 0.93703073 0.93416965]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9331003]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.94555914 0.94380963 0.94308084 0.94150019 0.93981934 0.93941671\n",
      "  0.93703073 0.93416965]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000707839266397059\n",
      "Predicción post entrenamiento : [[0.93326443]]\n",
      "PERDIDAAAA despues: 0.0006991316331550479\n",
      "loss en el callback: 0.0008811225998215377, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.94380963]\n",
      "  [0.94308084]\n",
      "  [0.94150019]\n",
      "  [0.93981934]\n",
      "  [0.93941671]\n",
      "  [0.93703073]\n",
      "  [0.93416965]\n",
      "  [0.93310028]]]\n",
      "ejemplar: [0.94380963 0.94308084 0.94150019 0.93981934 0.93941671 0.93703073\n",
      " 0.93416965 0.93310028]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.93197936]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.94380963 0.94308084 0.94150019 0.93981934 0.93941671 0.93703073\n",
      "  0.93416965 0.93310028]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001048173988237977\n",
      "Predicción post entrenamiento : [[0.9313585]]\n",
      "PERDIDAAAA despues: 0.0010887595126405358\n",
      "loss en el callback: 0.00965084321796894, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.94308084]\n",
      "  [0.94150019]\n",
      "  [0.93981934]\n",
      "  [0.93941671]\n",
      "  [0.93703073]\n",
      "  [0.93416965]\n",
      "  [0.93310028]\n",
      "  [0.93197936]]]\n",
      "ejemplar: [0.94308084 0.94150019 0.93981934 0.93941671 0.93703073 0.93416965\n",
      " 0.93310028 0.93197936]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9301533]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.94308084 0.94150019 0.93981934 0.93941671 0.93703073 0.93416965\n",
      "  0.93310028 0.93197936]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017745496006682515\n",
      "Predicción post entrenamiento : [[0.9293673]]\n",
      "PERDIDAAAA despues: 0.0017089457251131535\n",
      "loss en el callback: 0.0181443952023983, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.94150019]\n",
      "  [0.93981934]\n",
      "  [0.93941671]\n",
      "  [0.93703073]\n",
      "  [0.93416965]\n",
      "  [0.93310028]\n",
      "  [0.93197936]\n",
      "  [0.93015331]]]\n",
      "ejemplar: [0.94150019 0.93981934 0.93941671 0.93703073 0.93416965 0.93310028\n",
      " 0.93197936 0.93015331]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9279316]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.94150019 0.93981934 0.93941671 0.93703073 0.93416965 0.93310028\n",
      "  0.93197936 0.93015331]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012428698828443885\n",
      "Predicción post entrenamiento : [[0.9275354]]\n",
      "PERDIDAAAA despues: 0.00121509179007262\n",
      "loss en el callback: 0.004501624498516321, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.93981934]\n",
      "  [0.93941671]\n",
      "  [0.93703073]\n",
      "  [0.93416965]\n",
      "  [0.93310028]\n",
      "  [0.93197936]\n",
      "  [0.93015331]\n",
      "  [0.92793161]]]\n",
      "ejemplar: [0.93981934 0.93941671 0.93703073 0.93416965 0.93310028 0.93197936\n",
      " 0.93015331 0.92793161]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9260826]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.93981934 0.93941671 0.93703073 0.93416965 0.93310028 0.93197936\n",
      "  0.93015331 0.92793161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025847500655800104\n",
      "Predicción post entrenamiento : [[0.9253682]]\n",
      "PERDIDAAAA despues: 0.002512617502361536\n",
      "loss en el callback: 0.015202423557639122, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.93941671]\n",
      "  [0.93703073]\n",
      "  [0.93416965]\n",
      "  [0.93310028]\n",
      "  [0.93197936]\n",
      "  [0.93015331]\n",
      "  [0.92793161]\n",
      "  [0.92608261]]]\n",
      "ejemplar: [0.93941671 0.93703073 0.93416965 0.93310028 0.93197936 0.93015331\n",
      " 0.92793161 0.92608261]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9239177]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.93941671 0.93703073 0.93416965 0.93310028 0.93197936 0.93015331\n",
      "  0.92793161 0.92608261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00534137524664402\n",
      "Predicción post entrenamiento : [[0.92183304]]\n",
      "PERDIDAAAA despues: 0.005041005555540323\n",
      "loss en el callback: 0.09947246313095093, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.93703073]\n",
      "  [0.93416965]\n",
      "  [0.93310028]\n",
      "  [0.93197936]\n",
      "  [0.93015331]\n",
      "  [0.92793161]\n",
      "  [0.92608261]\n",
      "  [0.92391771]]]\n",
      "ejemplar: [0.93703073 0.93416965 0.93310028 0.93197936 0.93015331 0.92793161\n",
      " 0.92608261 0.92391771]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.91999096]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.93703073 0.93416965 0.93310028 0.93197936 0.93015331 0.92793161\n",
      "  0.92608261 0.92391771]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005054522771388292\n",
      "Predicción post entrenamiento : [[0.92006534]]\n",
      "PERDIDAAAA despues: 0.005065105389803648\n",
      "loss en el callback: 0.00022326128964778036, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.93416965]\n",
      "  [0.93310028]\n",
      "  [0.93197936]\n",
      "  [0.93015331]\n",
      "  [0.92793161]\n",
      "  [0.92608261]\n",
      "  [0.92391771]\n",
      "  [0.91999096]]]\n",
      "ejemplar: [0.93416965 0.93310028 0.93197936 0.93015331 0.92793161 0.92608261\n",
      " 0.92391771 0.91999096]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9183593]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.93416965 0.93310028 0.93197936 0.93015331 0.92793161 0.92608261\n",
      "  0.92391771 0.91999096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019411410903558135\n",
      "Predicción post entrenamiento : [[0.9181169]]\n",
      "PERDIDAAAA despues: 0.001962555106729269\n",
      "loss en el callback: 0.001966750482097268, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.93310028]\n",
      "  [0.93197936]\n",
      "  [0.93015331]\n",
      "  [0.92793161]\n",
      "  [0.92608261]\n",
      "  [0.92391771]\n",
      "  [0.91999096]\n",
      "  [0.91835928]]]\n",
      "ejemplar: [0.93310028 0.93197936 0.93015331 0.92793161 0.92608261 0.92391771\n",
      " 0.91999096 0.91835928]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.91669345]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.93310028 0.93197936 0.93015331 0.92793161 0.92608261 0.92391771\n",
      "  0.91999096 0.91835928]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026161663699895144\n",
      "Predicción post entrenamiento : [[0.9170321]]\n",
      "PERDIDAAAA despues: 0.00258163595572114\n",
      "loss en el callback: 0.004060730803757906, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.93197936]\n",
      "  [0.93015331]\n",
      "  [0.92793161]\n",
      "  [0.92608261]\n",
      "  [0.92391771]\n",
      "  [0.91999096]\n",
      "  [0.91835928]\n",
      "  [0.91669345]]]\n",
      "ejemplar: [0.93197936 0.93015331 0.92793161 0.92608261 0.92391771 0.91999096\n",
      " 0.91835928 0.91669345]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9153664]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.93197936 0.93015331 0.92793161 0.92608261 0.92391771 0.91999096\n",
      "  0.91835928 0.91669345]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006428388296626508\n",
      "Predicción post entrenamiento : [[0.91583055]]\n",
      "PERDIDAAAA despues: 0.0006195183377712965\n",
      "loss en el callback: 0.009170522913336754, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.93015331]\n",
      "  [0.92793161]\n",
      "  [0.92608261]\n",
      "  [0.92391771]\n",
      "  [0.91999096]\n",
      "  [0.91835928]\n",
      "  [0.91669345]\n",
      "  [0.91536641]]]\n",
      "ejemplar: [0.93015331 0.92793161 0.92608261 0.92391771 0.91999096 0.91835928\n",
      " 0.91669345 0.91536641]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.91388714]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.93015331 0.92793161 0.92608261 0.92391771 0.91999096 0.91835928\n",
      "  0.91669345 0.91536641]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003434442915022373\n",
      "Predicción post entrenamiento : [[0.9139383]]\n",
      "PERDIDAAAA despues: 0.003428451484069228\n",
      "loss en el callback: 8.164722385117784e-05, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.92793161]\n",
      "  [0.92608261]\n",
      "  [0.92391771]\n",
      "  [0.91999096]\n",
      "  [0.91835928]\n",
      "  [0.91669345]\n",
      "  [0.91536641]\n",
      "  [0.91388714]]]\n",
      "ejemplar: [0.92793161 0.92608261 0.92391771 0.91999096 0.91835928 0.91669345\n",
      " 0.91536641 0.91388714]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9118936]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.92793161 0.92608261 0.92391771 0.91999096 0.91835928 0.91669345\n",
      "  0.91536641 0.91388714]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0072261616587638855\n",
      "Predicción post entrenamiento : [[0.91274416]]\n",
      "PERDIDAAAA despues: 0.007082278374582529\n",
      "loss en el callback: 0.02904953621327877, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.92608261]\n",
      "  [0.92391771]\n",
      "  [0.91999096]\n",
      "  [0.91835928]\n",
      "  [0.91669345]\n",
      "  [0.91536641]\n",
      "  [0.91388714]\n",
      "  [0.91189361]]]\n",
      "ejemplar: [0.92608261 0.92391771 0.91999096 0.91835928 0.91669345 0.91536641\n",
      " 0.91388714 0.91189361]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9107175]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.92608261 0.92391771 0.91999096 0.91835928 0.91669345 0.91536641\n",
      "  0.91388714 0.91189361]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001637353328987956\n",
      "Predicción post entrenamiento : [[0.91046894]]\n",
      "PERDIDAAAA despues: 0.001657529966905713\n",
      "loss en el callback: 0.0020327712409198284, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.92391771]\n",
      "  [0.91999096]\n",
      "  [0.91835928]\n",
      "  [0.91669345]\n",
      "  [0.91536641]\n",
      "  [0.91388714]\n",
      "  [0.91189361]\n",
      "  [0.91071749]]]\n",
      "ejemplar: [0.92391771 0.91999096 0.91835928 0.91669345 0.91536641 0.91388714\n",
      " 0.91189361 0.91071749]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.908376]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.92391771 0.91999096 0.91835928 0.91669345 0.91536641 0.91388714\n",
      "  0.91189361 0.91071749]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015873908705543727\n",
      "Predicción post entrenamiento : [[0.90853083]]\n",
      "PERDIDAAAA despues: 0.00016266510647255927\n",
      "loss en el callback: 0.0009678350761532784, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.91999096]\n",
      "  [0.91835928]\n",
      "  [0.91669345]\n",
      "  [0.91536641]\n",
      "  [0.91388714]\n",
      "  [0.91189361]\n",
      "  [0.91071749]\n",
      "  [0.90837598]]]\n",
      "ejemplar: [0.91999096 0.91835928 0.91669345 0.91536641 0.91388714 0.91189361\n",
      " 0.91071749 0.90837598]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9064819]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.91999096 0.91835928 0.91669345 0.91536641 0.91388714 0.91189361\n",
      "  0.91071749 0.90837598]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006270330050028861\n",
      "Predicción post entrenamiento : [[0.9059406]]\n",
      "PERDIDAAAA despues: 0.0006002155714668334\n",
      "loss en el callback: 0.010064086876809597, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.91835928]\n",
      "  [0.91669345]\n",
      "  [0.91536641]\n",
      "  [0.91388714]\n",
      "  [0.91189361]\n",
      "  [0.91071749]\n",
      "  [0.90837598]\n",
      "  [0.90648192]]]\n",
      "ejemplar: [0.91835928 0.91669345 0.91536641 0.91388714 0.91189361 0.91071749\n",
      " 0.90837598 0.90648192]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9044933]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.91835928 0.91669345 0.91536641 0.91388714 0.91189361 0.91071749\n",
      "  0.90837598 0.90648192]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015858742699492723\n",
      "Predicción post entrenamiento : [[0.904306]]\n",
      "PERDIDAAAA despues: 0.0001633393403608352\n",
      "loss en el callback: 0.001283512800000608, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.91669345]\n",
      "  [0.91536641]\n",
      "  [0.91388714]\n",
      "  [0.91189361]\n",
      "  [0.91071749]\n",
      "  [0.90837598]\n",
      "  [0.90648192]\n",
      "  [0.90449327]]]\n",
      "ejemplar: [0.91669345 0.91536641 0.91388714 0.91189361 0.91071749 0.90837598\n",
      " 0.90648192 0.90449327]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9028562]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.91669345 0.91536641 0.91388714 0.91189361 0.91071749 0.90837598\n",
      "  0.90648192 0.90449327]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002870442986022681\n",
      "Predicción post entrenamiento : [[0.90254915]]\n",
      "PERDIDAAAA despues: 0.00029754199204035103\n",
      "loss en el callback: 0.0030174131970852613, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.91536641]\n",
      "  [0.91388714]\n",
      "  [0.91189361]\n",
      "  [0.91071749]\n",
      "  [0.90837598]\n",
      "  [0.90648192]\n",
      "  [0.90449327]\n",
      "  [0.90285617]]]\n",
      "ejemplar: [0.91536641 0.91388714 0.91189361 0.91071749 0.90837598 0.90648192\n",
      " 0.90449327 0.90285617]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9010964]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.91536641 0.91388714 0.91189361 0.91071749 0.90837598 0.90648192\n",
      "  0.90449327 0.90285617]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003665866330265999\n",
      "Predicción post entrenamiento : [[0.90100753]]\n",
      "PERDIDAAAA despues: 0.0036766359116882086\n",
      "loss en el callback: 0.0002924479194916785, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.91388714]\n",
      "  [0.91189361]\n",
      "  [0.91071749]\n",
      "  [0.90837598]\n",
      "  [0.90648192]\n",
      "  [0.90449327]\n",
      "  [0.90285617]\n",
      "  [0.9010964 ]]]\n",
      "ejemplar: [0.91388714 0.91189361 0.91071749 0.90837598 0.90648192 0.90449327\n",
      " 0.90285617 0.9010964 ]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.89943916]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.91388714 0.91189361 0.91071749 0.90837598 0.90648192 0.90449327\n",
      "  0.90285617 0.9010964 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004732091445475817\n",
      "Predicción post entrenamiento : [[0.89997756]]\n",
      "PERDIDAAAA despues: 0.004658306483179331\n",
      "loss en el callback: 0.01275789737701416, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.91189361]\n",
      "  [0.91071749]\n",
      "  [0.90837598]\n",
      "  [0.90648192]\n",
      "  [0.90449327]\n",
      "  [0.90285617]\n",
      "  [0.9010964 ]\n",
      "  [0.89943916]]]\n",
      "ejemplar: [0.91189361 0.91071749 0.90837598 0.90648192 0.90449327 0.90285617\n",
      " 0.9010964  0.89943916]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8983175]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.91189361 0.91071749 0.90837598 0.90648192 0.90449327 0.90285617\n",
      "  0.9010964  0.89943916]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035343982744961977\n",
      "Predicción post entrenamiento : [[0.8986361]]\n",
      "PERDIDAAAA despues: 0.003496619174256921\n",
      "loss en el callback: 0.004050292074680328, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22264095]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03116453066468239\n",
      "Predicción post entrenamiento : [[0.18414077]]\n",
      "PERDIDAAAA despues: 0.01905355416238308\n",
      "loss en el callback: 0.028951356187462807, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22264095]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.22264095]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16819158]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.22264095]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004091957584023476\n",
      "Predicción post entrenamiento : [[0.15603223]]\n",
      "PERDIDAAAA despues: 0.002684179227799177\n",
      "loss en el callback: 0.0031049202661961317, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22264095]\n",
      "  [0.16819158]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.22264095 0.16819158]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15977485]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.22264095 0.16819158]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.103662675130181e-05\n",
      "Predicción post entrenamiento : [[0.15561467]]\n",
      "PERDIDAAAA despues: 1.9905589851987315e-06\n",
      "loss en el callback: 0.000694232527166605, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22264095]\n",
      "  [0.16819158]\n",
      "  [0.15977485]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22264095\n",
      " 0.16819158 0.15977485]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.16648881]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22264095\n",
      "  0.16819158 0.15977485]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011524513683980331\n",
      "Predicción post entrenamiento : [[0.16826676]]\n",
      "PERDIDAAAA despues: 0.0001565795682836324\n",
      "loss en el callback: 0.0003254497132729739, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22264095]\n",
      "  [0.16819158]\n",
      "  [0.15977485]\n",
      "  [0.16648881]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.22264095 0.16819158\n",
      " 0.15977485 0.16648881]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17983179]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.22264095 0.16819158\n",
      "  0.15977485 0.16648881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029483858961611986\n",
      "Predicción post entrenamiento : [[0.17499447]]\n",
      "PERDIDAAAA despues: 0.0024464619345963\n",
      "loss en el callback: 0.0030555110424757004, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22264095]\n",
      "  [0.16819158]\n",
      "  [0.15977485]\n",
      "  [0.16648881]\n",
      "  [0.17983179]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.22264095 0.16819158 0.15977485\n",
      " 0.16648881 0.17983179]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18313444]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.22264095 0.16819158 0.15977485\n",
      "  0.16648881 0.17983179]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014028373407199979\n",
      "Predicción post entrenamiento : [[0.18179886]]\n",
      "PERDIDAAAA despues: 0.0013045745436102152\n",
      "loss en el callback: 0.00037740491097792983, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22264095]\n",
      "  [0.16819158]\n",
      "  [0.15977485]\n",
      "  [0.16648881]\n",
      "  [0.17983179]\n",
      "  [0.18313444]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.22264095 0.16819158 0.15977485 0.16648881\n",
      " 0.17983179 0.18313444]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20037138]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.22264095 0.16819158 0.15977485 0.16648881\n",
      "  0.17983179 0.18313444]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029069921001791954\n",
      "Predicción post entrenamiento : [[0.19772752]]\n",
      "PERDIDAAAA despues: 0.0026288856752216816\n",
      "loss en el callback: 0.0017803506925702095, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.22264095]\n",
      "  [0.16819158]\n",
      "  [0.15977485]\n",
      "  [0.16648881]\n",
      "  [0.17983179]\n",
      "  [0.18313444]\n",
      "  [0.20037138]]]\n",
      "ejemplar: [0.04223169 0.22264095 0.16819158 0.15977485 0.16648881 0.17983179\n",
      " 0.18313444 0.20037138]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22001559]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.22264095 0.16819158 0.15977485 0.16648881 0.17983179\n",
      "  0.18313444 0.20037138]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005744434311054647\n",
      "Predicción post entrenamiento : [[0.21736985]]\n",
      "PERDIDAAAA despues: 0.00045461993431672454\n",
      "loss en el callback: 0.001832772046327591, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.22264095]\n",
      "  [0.16819158]\n",
      "  [0.15977485]\n",
      "  [0.16648881]\n",
      "  [0.17983179]\n",
      "  [0.18313444]\n",
      "  [0.20037138]\n",
      "  [0.22001559]]]\n",
      "ejemplar: [0.22264095 0.16819158 0.15977485 0.16648881 0.17983179 0.18313444\n",
      " 0.20037138 0.22001559]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24367073]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.22264095 0.16819158 0.15977485 0.16648881 0.17983179 0.18313444\n",
      "  0.20037138 0.22001559]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017265784845221788\n",
      "Predicción post entrenamiento : [[0.24195649]]\n",
      "PERDIDAAAA despues: 0.00013054636656306684\n",
      "loss en el callback: 0.0009533409029245377, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.16819158]\n",
      "  [0.15977485]\n",
      "  [0.16648881]\n",
      "  [0.17983179]\n",
      "  [0.18313444]\n",
      "  [0.20037138]\n",
      "  [0.22001559]\n",
      "  [0.24367073]]]\n",
      "ejemplar: [0.16819158 0.15977485 0.16648881 0.17983179 0.18313444 0.20037138\n",
      " 0.22001559 0.24367073]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23346543]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.16819158 0.15977485 0.16648881 0.17983179 0.18313444 0.20037138\n",
      "  0.22001559 0.24367073]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006259550573304296\n",
      "Predicción post entrenamiento : [[0.23523502]]\n",
      "PERDIDAAAA despues: 0.0007176334620453417\n",
      "loss en el callback: 0.0024333354085683823, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.15977485]\n",
      "  [0.16648881]\n",
      "  [0.17983179]\n",
      "  [0.18313444]\n",
      "  [0.20037138]\n",
      "  [0.22001559]\n",
      "  [0.24367073]\n",
      "  [0.23346543]]]\n",
      "ejemplar: [0.15977485 0.16648881 0.17983179 0.18313444 0.20037138 0.22001559\n",
      " 0.24367073 0.23346543]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.2384696]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.15977485 0.16648881 0.17983179 0.18313444 0.20037138 0.22001559\n",
      "  0.24367073 0.23346543]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007041720673441887\n",
      "Predicción post entrenamiento : [[0.23614821]]\n",
      "PERDIDAAAA despues: 0.000586358888540417\n",
      "loss en el callback: 0.0024525346234440804, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.16648881]\n",
      "  [0.17983179]\n",
      "  [0.18313444]\n",
      "  [0.20037138]\n",
      "  [0.22001559]\n",
      "  [0.24367073]\n",
      "  [0.23346543]\n",
      "  [0.2384696 ]]]\n",
      "ejemplar: [0.16648881 0.17983179 0.18313444 0.20037138 0.22001559 0.24367073\n",
      " 0.23346543 0.2384696 ]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24311377]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.16648881 0.17983179 0.18313444 0.20037138 0.22001559 0.24367073\n",
      "  0.23346543 0.2384696 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012837722897529602\n",
      "Predicción post entrenamiento : [[0.24268235]]\n",
      "PERDIDAAAA despues: 0.0012530430685728788\n",
      "loss en el callback: 0.00014277794980444014, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.17983179]\n",
      "  [0.18313444]\n",
      "  [0.20037138]\n",
      "  [0.22001559]\n",
      "  [0.24367073]\n",
      "  [0.23346543]\n",
      "  [0.2384696 ]\n",
      "  [0.24311377]]]\n",
      "ejemplar: [0.17983179 0.18313444 0.20037138 0.22001559 0.24367073 0.23346543\n",
      " 0.2384696  0.24311377]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25062886]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.17983179 0.18313444 0.20037138 0.22001559 0.24367073 0.23346543\n",
      "  0.2384696  0.24311377]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003327026730403304\n",
      "Predicción post entrenamiento : [[0.2489252]]\n",
      "PERDIDAAAA despues: 0.0031333931256085634\n",
      "loss en el callback: 0.002203429350629449, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.18313444]\n",
      "  [0.20037138]\n",
      "  [0.22001559]\n",
      "  [0.24367073]\n",
      "  [0.23346543]\n",
      "  [0.2384696 ]\n",
      "  [0.24311377]\n",
      "  [0.25062886]]]\n",
      "ejemplar: [0.18313444 0.20037138 0.22001559 0.24367073 0.23346543 0.2384696\n",
      " 0.24311377 0.25062886]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.25637904]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.18313444 0.20037138 0.22001559 0.24367073 0.23346543 0.2384696\n",
      "  0.24311377 0.25062886]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035469287540763617\n",
      "Predicción post entrenamiento : [[0.25301093]]\n",
      "PERDIDAAAA despues: 0.0031570899300277233\n",
      "loss en el callback: 0.008307244628667831, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20037138]\n",
      "  [0.22001559]\n",
      "  [0.24367073]\n",
      "  [0.23346543]\n",
      "  [0.2384696 ]\n",
      "  [0.24311377]\n",
      "  [0.25062886]\n",
      "  [0.25637904]]]\n",
      "ejemplar: [0.20037138 0.22001559 0.24367073 0.23346543 0.2384696  0.24311377\n",
      " 0.25062886 0.25637904]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2619847]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20037138 0.22001559 0.24367073 0.23346543 0.2384696  0.24311377\n",
      "  0.25062886 0.25637904]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022778341080993414\n",
      "Predicción post entrenamiento : [[0.2594136]]\n",
      "PERDIDAAAA despues: 0.0020390241406857967\n",
      "loss en el callback: 0.005479242652654648, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22001559]\n",
      "  [0.24367073]\n",
      "  [0.23346543]\n",
      "  [0.2384696 ]\n",
      "  [0.24311377]\n",
      "  [0.25062886]\n",
      "  [0.25637904]\n",
      "  [0.26198471]]]\n",
      "ejemplar: [0.22001559 0.24367073 0.23346543 0.2384696  0.24311377 0.25062886\n",
      " 0.25637904 0.26198471]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26679015]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22001559 0.24367073 0.23346543 0.2384696  0.24311377 0.25062886\n",
      "  0.25637904 0.26198471]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007304281461983919\n",
      "Predicción post entrenamiento : [[0.26327986]]\n",
      "PERDIDAAAA despues: 0.006716588046401739\n",
      "loss en el callback: 0.012127717025578022, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24367073]\n",
      "  [0.23346543]\n",
      "  [0.2384696 ]\n",
      "  [0.24311377]\n",
      "  [0.25062886]\n",
      "  [0.25637904]\n",
      "  [0.26198471]\n",
      "  [0.26679015]]]\n",
      "ejemplar: [0.24367073 0.23346543 0.2384696  0.24311377 0.25062886 0.25637904\n",
      " 0.26198471 0.26679015]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26802954]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24367073 0.23346543 0.2384696  0.24311377 0.25062886 0.25637904\n",
      "  0.26198471 0.26679015]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008631081320345402\n",
      "Predicción post entrenamiento : [[0.2645577]]\n",
      "PERDIDAAAA despues: 0.007998039945960045\n",
      "loss en el callback: 0.012680350802838802, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23346543]\n",
      "  [0.2384696 ]\n",
      "  [0.24311377]\n",
      "  [0.25062886]\n",
      "  [0.25637904]\n",
      "  [0.26198471]\n",
      "  [0.26679015]\n",
      "  [0.26802954]]]\n",
      "ejemplar: [0.23346543 0.2384696  0.24311377 0.25062886 0.25637904 0.26198471\n",
      " 0.26679015 0.26802954]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.26521704]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23346543 0.2384696  0.24311377 0.25062886 0.25637904 0.26198471\n",
      "  0.26679015 0.26802954]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013738743029534817\n",
      "Predicción post entrenamiento : [[0.2610432]]\n",
      "PERDIDAAAA despues: 0.012777711264789104\n",
      "loss en el callback: 0.019192613661289215, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.2384696 ]\n",
      "  [0.24311377]\n",
      "  [0.25062886]\n",
      "  [0.25637904]\n",
      "  [0.26198471]\n",
      "  [0.26679015]\n",
      "  [0.26802954]\n",
      "  [0.26521704]]]\n",
      "ejemplar: [0.2384696  0.24311377 0.25062886 0.25637904 0.26198471 0.26679015\n",
      " 0.26802954 0.26521704]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26468864]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.2384696  0.24311377 0.25062886 0.25637904 0.26198471 0.26679015\n",
      "  0.26802954 0.26521704]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01120114978402853\n",
      "Predicción post entrenamiento : [[0.26110935]]\n",
      "PERDIDAAAA despues: 0.010456329211592674\n",
      "loss en el callback: 0.015753550454974174, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.24311377]\n",
      "  [0.25062886]\n",
      "  [0.25637904]\n",
      "  [0.26198471]\n",
      "  [0.26679015]\n",
      "  [0.26802954]\n",
      "  [0.26521704]\n",
      "  [0.26468864]]]\n",
      "ejemplar: [0.24311377 0.25062886 0.25637904 0.26198471 0.26679015 0.26802954\n",
      " 0.26521704 0.26468864]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.26469517]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.24311377 0.25062886 0.25637904 0.26198471 0.26679015 0.26802954\n",
      "  0.26521704 0.26468864]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005259382072836161\n",
      "Predicción post entrenamiento : [[0.26159665]]\n",
      "PERDIDAAAA despues: 0.004819564055651426\n",
      "loss en el callback: 0.012650225311517715, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25062886]\n",
      "  [0.25637904]\n",
      "  [0.26198471]\n",
      "  [0.26679015]\n",
      "  [0.26802954]\n",
      "  [0.26521704]\n",
      "  [0.26468864]\n",
      "  [0.26469517]]]\n",
      "ejemplar: [0.25062886 0.25637904 0.26198471 0.26679015 0.26802954 0.26521704\n",
      " 0.26468864 0.26469517]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.265067]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25062886 0.25637904 0.26198471 0.26679015 0.26802954 0.26521704\n",
      "  0.26468864 0.26469517]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006255635526031256\n",
      "Predicción post entrenamiento : [[0.26295066]]\n",
      "PERDIDAAAA despues: 0.005925339180976152\n",
      "loss en el callback: 0.007698384113609791, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25637904]\n",
      "  [0.26198471]\n",
      "  [0.26679015]\n",
      "  [0.26802954]\n",
      "  [0.26521704]\n",
      "  [0.26468864]\n",
      "  [0.26469517]\n",
      "  [0.26506701]]]\n",
      "ejemplar: [0.25637904 0.26198471 0.26679015 0.26802954 0.26521704 0.26468864\n",
      " 0.26469517 0.26506701]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26548916]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25637904 0.26198471 0.26679015 0.26802954 0.26521704 0.26468864\n",
      "  0.26469517 0.26506701]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.136348030035151e-06\n",
      "Predicción post entrenamiento : [[0.26524216]]\n",
      "PERDIDAAAA despues: 2.9194054604886333e-06\n",
      "loss en el callback: 0.00010902392386924475, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26198471]\n",
      "  [0.26679015]\n",
      "  [0.26802954]\n",
      "  [0.26521704]\n",
      "  [0.26468864]\n",
      "  [0.26469517]\n",
      "  [0.26506701]\n",
      "  [0.26548916]]]\n",
      "ejemplar: [0.26198471 0.26679015 0.26802954 0.26521704 0.26468864 0.26469517\n",
      " 0.26506701 0.26548916]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2669833]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26198471 0.26679015 0.26802954 0.26521704 0.26468864 0.26469517\n",
      "  0.26506701 0.26548916]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006522395415231586\n",
      "Predicción post entrenamiento : [[0.26679635]]\n",
      "PERDIDAAAA despues: 0.0006618235493078828\n",
      "loss en el callback: 6.0422957176342607e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26679015]\n",
      "  [0.26802954]\n",
      "  [0.26521704]\n",
      "  [0.26468864]\n",
      "  [0.26469517]\n",
      "  [0.26506701]\n",
      "  [0.26548916]\n",
      "  [0.2669833 ]]]\n",
      "ejemplar: [0.26679015 0.26802954 0.26521704 0.26468864 0.26469517 0.26506701\n",
      " 0.26548916 0.2669833 ]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26756507]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26679015 0.26802954 0.26521704 0.26468864 0.26469517 0.26506701\n",
      "  0.26548916 0.2669833 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002514144405722618\n",
      "Predicción post entrenamiento : [[0.26826626]]\n",
      "PERDIDAAAA despues: 0.0024443191941827536\n",
      "loss en el callback: 0.0010740960715338588, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26802954]\n",
      "  [0.26521704]\n",
      "  [0.26468864]\n",
      "  [0.26469517]\n",
      "  [0.26506701]\n",
      "  [0.26548916]\n",
      "  [0.2669833 ]\n",
      "  [0.26756507]]]\n",
      "ejemplar: [0.26802954 0.26521704 0.26468864 0.26469517 0.26506701 0.26548916\n",
      " 0.2669833  0.26756507]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26805657]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26802954 0.26521704 0.26468864 0.26469517 0.26506701 0.26548916\n",
      "  0.2669833  0.26756507]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001990314805880189\n",
      "Predicción post entrenamiento : [[0.2693389]]\n",
      "PERDIDAAAA despues: 0.0018775417702272534\n",
      "loss en el callback: 0.0045911818742752075, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26521704]\n",
      "  [0.26468864]\n",
      "  [0.26469517]\n",
      "  [0.26506701]\n",
      "  [0.26548916]\n",
      "  [0.2669833 ]\n",
      "  [0.26756507]\n",
      "  [0.26805657]]]\n",
      "ejemplar: [0.26521704 0.26468864 0.26469517 0.26506701 0.26548916 0.2669833\n",
      " 0.26756507 0.26805657]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.2688253]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26521704 0.26468864 0.26469517 0.26506701 0.26548916 0.2669833\n",
      "  0.26756507 0.26805657]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004084428073838353\n",
      "Predicción post entrenamiento : [[0.268835]]\n",
      "PERDIDAAAA despues: 0.000408050196710974\n",
      "loss en el callback: 2.3690758155225922e-07, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26468864]\n",
      "  [0.26469517]\n",
      "  [0.26506701]\n",
      "  [0.26548916]\n",
      "  [0.2669833 ]\n",
      "  [0.26756507]\n",
      "  [0.26805657]\n",
      "  [0.26882529]]]\n",
      "ejemplar: [0.26468864 0.26469517 0.26506701 0.26548916 0.2669833  0.26756507\n",
      " 0.26805657 0.26882529]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.26893637]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26468864 0.26469517 0.26506701 0.26548916 0.2669833  0.26756507\n",
      "  0.26805657 0.26882529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019320286810398102\n",
      "Predicción post entrenamiento : [[0.2695425]]\n",
      "PERDIDAAAA despues: 0.0001767204375937581\n",
      "loss en el callback: 0.001150418189354241, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26469517]\n",
      "  [0.26506701]\n",
      "  [0.26548916]\n",
      "  [0.2669833 ]\n",
      "  [0.26756507]\n",
      "  [0.26805657]\n",
      "  [0.26882529]\n",
      "  [0.26893637]]]\n",
      "ejemplar: [0.26469517 0.26506701 0.26548916 0.2669833  0.26756507 0.26805657\n",
      " 0.26882529 0.26893637]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.26985395]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26469517 0.26506701 0.26548916 0.2669833  0.26756507 0.26805657\n",
      "  0.26882529 0.26893637]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008786703110672534\n",
      "Predicción post entrenamiento : [[0.27042374]]\n",
      "PERDIDAAAA despues: 0.0008452150505036116\n",
      "loss en el callback: 0.001048216363415122, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26506701]\n",
      "  [0.26548916]\n",
      "  [0.2669833 ]\n",
      "  [0.26756507]\n",
      "  [0.26805657]\n",
      "  [0.26882529]\n",
      "  [0.26893637]\n",
      "  [0.26985395]]]\n",
      "ejemplar: [0.26506701 0.26548916 0.2669833  0.26756507 0.26805657 0.26882529\n",
      " 0.26893637 0.26985395]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27086347]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26506701 0.26548916 0.2669833  0.26756507 0.26805657 0.26882529\n",
      "  0.26893637 0.26985395]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.4985947675304487e-05\n",
      "Predicción post entrenamiento : [[0.27000505]]\n",
      "PERDIDAAAA despues: 3.430469223530963e-05\n",
      "loss en el callback: 0.0019301638239994645, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26548916]\n",
      "  [0.2669833 ]\n",
      "  [0.26756507]\n",
      "  [0.26805657]\n",
      "  [0.26882529]\n",
      "  [0.26893637]\n",
      "  [0.26985395]\n",
      "  [0.27086347]]]\n",
      "ejemplar: [0.26548916 0.2669833  0.26756507 0.26805657 0.26882529 0.26893637\n",
      " 0.26985395 0.27086347]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27051198]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26548916 0.2669833  0.26756507 0.26805657 0.26882529 0.26893637\n",
      "  0.26985395 0.27086347]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7537107851239853e-05\n",
      "Predicción post entrenamiento : [[0.26992264]]\n",
      "PERDIDAAAA despues: 2.2820435333414935e-05\n",
      "loss en el callback: 0.0009513819240964949, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.2669833 ]\n",
      "  [0.26756507]\n",
      "  [0.26805657]\n",
      "  [0.26882529]\n",
      "  [0.26893637]\n",
      "  [0.26985395]\n",
      "  [0.27086347]\n",
      "  [0.27051198]]]\n",
      "ejemplar: [0.2669833  0.26756507 0.26805657 0.26882529 0.26893637 0.26985395\n",
      " 0.27086347 0.27051198]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27049115]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.2669833  0.26756507 0.26805657 0.26882529 0.26893637 0.26985395\n",
      "  0.27086347 0.27051198]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.483482239767909e-05\n",
      "Predicción post entrenamiento : [[0.2708335]]\n",
      "PERDIDAAAA despues: 2.1539954104810022e-05\n",
      "loss en el callback: 0.00046359619591385126, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26756507]\n",
      "  [0.26805657]\n",
      "  [0.26882529]\n",
      "  [0.26893637]\n",
      "  [0.26985395]\n",
      "  [0.27086347]\n",
      "  [0.27051198]\n",
      "  [0.27049115]]]\n",
      "ejemplar: [0.26756507 0.26805657 0.26882529 0.26893637 0.26985395 0.27086347\n",
      " 0.27051198 0.27049115]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2712153]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26756507 0.26805657 0.26882529 0.26893637 0.26985395 0.27086347\n",
      "  0.27051198 0.27049115]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004037162754684687\n",
      "Predicción post entrenamiento : [[0.27182183]]\n",
      "PERDIDAAAA despues: 0.003960453439503908\n",
      "loss en el callback: 0.0013135176850482821, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26805657]\n",
      "  [0.26882529]\n",
      "  [0.26893637]\n",
      "  [0.26985395]\n",
      "  [0.27086347]\n",
      "  [0.27051198]\n",
      "  [0.27049115]\n",
      "  [0.27121529]]]\n",
      "ejemplar: [0.26805657 0.26882529 0.26893637 0.26985395 0.27086347 0.27051198\n",
      " 0.27049115 0.27121529]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.272189]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26805657 0.26882529 0.26893637 0.26985395 0.27086347 0.27051198\n",
      "  0.27049115 0.27121529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006970094982534647\n",
      "Predicción post entrenamiento : [[0.27342036]]\n",
      "PERDIDAAAA despues: 0.006766003556549549\n",
      "loss en el callback: 0.006891756784170866, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26882529]\n",
      "  [0.26893637]\n",
      "  [0.26985395]\n",
      "  [0.27086347]\n",
      "  [0.27051198]\n",
      "  [0.27049115]\n",
      "  [0.27121529]\n",
      "  [0.27218899]]]\n",
      "ejemplar: [0.26882529 0.26893637 0.26985395 0.27086347 0.27051198 0.27049115\n",
      " 0.27121529 0.27218899]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.27378872]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26882529 0.26893637 0.26985395 0.27086347 0.27051198 0.27049115\n",
      "  0.27121529 0.27218899]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003956722095608711\n",
      "Predicción post entrenamiento : [[0.2749765]]\n",
      "PERDIDAAAA despues: 0.0038087053690105677\n",
      "loss en el callback: 0.008402557112276554, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.26893637]\n",
      "  [0.26985395]\n",
      "  [0.27086347]\n",
      "  [0.27051198]\n",
      "  [0.27049115]\n",
      "  [0.27121529]\n",
      "  [0.27218899]\n",
      "  [0.27378872]]]\n",
      "ejemplar: [0.26893637 0.26985395 0.27086347 0.27051198 0.27049115 0.27121529\n",
      " 0.27218899 0.27378872]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.27528617]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.26893637 0.26985395 0.27086347 0.27051198 0.27049115 0.27121529\n",
      "  0.27218899 0.27378872]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033995280973613262\n",
      "Predicción post entrenamiento : [[0.27644098]]\n",
      "PERDIDAAAA despues: 0.003266198094934225\n",
      "loss en el callback: 0.007398429326713085, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.26985395]\n",
      "  [0.27086347]\n",
      "  [0.27051198]\n",
      "  [0.27049115]\n",
      "  [0.27121529]\n",
      "  [0.27218899]\n",
      "  [0.27378872]\n",
      "  [0.27528617]]]\n",
      "ejemplar: [0.26985395 0.27086347 0.27051198 0.27049115 0.27121529 0.27218899\n",
      " 0.27378872 0.27528617]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.27684695]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.26985395 0.27086347 0.27051198 0.27049115 0.27121529 0.27218899\n",
      "  0.27378872 0.27528617]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011639745905995369\n",
      "Predicción post entrenamiento : [[0.27792412]]\n",
      "PERDIDAAAA despues: 0.011408478952944279\n",
      "loss en el callback: 0.005068907048553228, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27086347]\n",
      "  [0.27051198]\n",
      "  [0.27049115]\n",
      "  [0.27121529]\n",
      "  [0.27218899]\n",
      "  [0.27378872]\n",
      "  [0.27528617]\n",
      "  [0.27684695]]]\n",
      "ejemplar: [0.27086347 0.27051198 0.27049115 0.27121529 0.27218899 0.27378872\n",
      " 0.27528617 0.27684695]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27827317]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27086347 0.27051198 0.27049115 0.27121529 0.27218899 0.27378872\n",
      "  0.27528617 0.27684695]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08574549108743668\n",
      "Predicción post entrenamiento : [[0.28234124]]\n",
      "PERDIDAAAA despues: 0.0833795890212059\n",
      "loss en el callback: 0.12539906799793243, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27051198]\n",
      "  [0.27049115]\n",
      "  [0.27121529]\n",
      "  [0.27218899]\n",
      "  [0.27378872]\n",
      "  [0.27528617]\n",
      "  [0.27684695]\n",
      "  [0.27827317]]]\n",
      "ejemplar: [0.27051198 0.27049115 0.27121529 0.27218899 0.27378872 0.27528617\n",
      " 0.27684695 0.27827317]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.282626]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27051198 0.27049115 0.27121529 0.27218899 0.27378872 0.27528617\n",
      "  0.27684695 0.27827317]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09837915003299713\n",
      "Predicción post entrenamiento : [[0.28654814]]\n",
      "PERDIDAAAA despues: 0.09593414515256882\n",
      "loss en el callback: 0.10351409763097763, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27049115]\n",
      "  [0.27121529]\n",
      "  [0.27218899]\n",
      "  [0.27378872]\n",
      "  [0.27528617]\n",
      "  [0.27684695]\n",
      "  [0.27827317]\n",
      "  [0.282626  ]]]\n",
      "ejemplar: [0.27049115 0.27121529 0.27218899 0.27378872 0.27528617 0.27684695\n",
      " 0.27827317 0.282626  ]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28711516]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27049115 0.27121529 0.27218899 0.27378872 0.27528617 0.27684695\n",
      "  0.27827317 0.282626  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08263803273439407\n",
      "Predicción post entrenamiento : [[0.2909597]]\n",
      "PERDIDAAAA despues: 0.08044245094060898\n",
      "loss en el callback: 0.08770916610956192, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27121529]\n",
      "  [0.27218899]\n",
      "  [0.27378872]\n",
      "  [0.27528617]\n",
      "  [0.27684695]\n",
      "  [0.27827317]\n",
      "  [0.282626  ]\n",
      "  [0.28711516]]]\n",
      "ejemplar: [0.27121529 0.27218899 0.27378872 0.27528617 0.27684695 0.27827317\n",
      " 0.282626   0.28711516]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.2918323]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27121529 0.27218899 0.27378872 0.27528617 0.27684695 0.27827317\n",
      "  0.282626   0.28711516]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09892397373914719\n",
      "Predicción post entrenamiento : [[0.29593867]]\n",
      "PERDIDAAAA despues: 0.09635774791240692\n",
      "loss en el callback: 0.13645122945308685, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27218899]\n",
      "  [0.27378872]\n",
      "  [0.27528617]\n",
      "  [0.27684695]\n",
      "  [0.27827317]\n",
      "  [0.282626  ]\n",
      "  [0.28711516]\n",
      "  [0.2918323 ]]]\n",
      "ejemplar: [0.27218899 0.27378872 0.27528617 0.27684695 0.27827317 0.282626\n",
      " 0.28711516 0.2918323 ]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29705495]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27218899 0.27378872 0.27528617 0.27684695 0.27827317 0.282626\n",
      "  0.28711516 0.2918323 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08271501958370209\n",
      "Predicción post entrenamiento : [[0.3004613]]\n",
      "PERDIDAAAA despues: 0.08076727390289307\n",
      "loss en el callback: 0.05895369127392769, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27378872]\n",
      "  [0.27528617]\n",
      "  [0.27684695]\n",
      "  [0.27827317]\n",
      "  [0.282626  ]\n",
      "  [0.28711516]\n",
      "  [0.2918323 ]\n",
      "  [0.29705495]]]\n",
      "ejemplar: [0.27378872 0.27528617 0.27684695 0.27827317 0.282626   0.28711516\n",
      " 0.2918323  0.29705495]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.30187252]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27378872 0.27528617 0.27684695 0.27827317 0.282626   0.28711516\n",
      "  0.2918323  0.29705495]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07123521715402603\n",
      "Predicción post entrenamiento : [[0.3051425]]\n",
      "PERDIDAAAA despues: 0.0695004016160965\n",
      "loss en el callback: 0.059141747653484344, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27528617]\n",
      "  [0.27684695]\n",
      "  [0.27827317]\n",
      "  [0.282626  ]\n",
      "  [0.28711516]\n",
      "  [0.2918323 ]\n",
      "  [0.29705495]\n",
      "  [0.30187252]]]\n",
      "ejemplar: [0.27528617 0.27684695 0.27827317 0.282626   0.28711516 0.2918323\n",
      " 0.29705495 0.30187252]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30682254]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27528617 0.27684695 0.27827317 0.282626   0.28711516 0.2918323\n",
      "  0.29705495 0.30187252]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1128634586930275\n",
      "Predicción post entrenamiento : [[0.31046736]]\n",
      "PERDIDAAAA despues: 0.11042777448892593\n",
      "loss en el callback: 0.07178683578968048, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27684695]\n",
      "  [0.27827317]\n",
      "  [0.282626  ]\n",
      "  [0.28711516]\n",
      "  [0.2918323 ]\n",
      "  [0.29705495]\n",
      "  [0.30187252]\n",
      "  [0.30682254]]]\n",
      "ejemplar: [0.27684695 0.27827317 0.282626   0.28711516 0.2918323  0.29705495\n",
      " 0.30187252 0.30682254]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31255534]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27684695 0.27827317 0.282626   0.28711516 0.2918323  0.29705495\n",
      "  0.30187252 0.30682254]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12194320559501648\n",
      "Predicción post entrenamiento : [[0.31666884]]\n",
      "PERDIDAAAA despues: 0.11908723413944244\n",
      "loss en el callback: 0.12805914878845215, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27827317]\n",
      "  [0.282626  ]\n",
      "  [0.28711516]\n",
      "  [0.2918323 ]\n",
      "  [0.29705495]\n",
      "  [0.30187252]\n",
      "  [0.30682254]\n",
      "  [0.31255534]]]\n",
      "ejemplar: [0.27827317 0.282626   0.28711516 0.2918323  0.29705495 0.30187252\n",
      " 0.30682254 0.31255534]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3192817]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27827317 0.282626   0.28711516 0.2918323  0.29705495 0.30187252\n",
      "  0.30682254 0.31255534]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1251130849123001\n",
      "Predicción post entrenamiento : [[0.3231665]]\n",
      "PERDIDAAAA despues: 0.12237996608018875\n",
      "loss en el callback: 0.13406389951705933, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.282626  ]\n",
      "  [0.28711516]\n",
      "  [0.2918323 ]\n",
      "  [0.29705495]\n",
      "  [0.30187252]\n",
      "  [0.30682254]\n",
      "  [0.31255534]\n",
      "  [0.3192817 ]]]\n",
      "ejemplar: [0.282626   0.28711516 0.2918323  0.29705495 0.30187252 0.30682254\n",
      " 0.31255534 0.3192817 ]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3264794]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.282626   0.28711516 0.2918323  0.29705495 0.30187252 0.30682254\n",
      "  0.31255534 0.3192817 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.147531196475029\n",
      "Predicción post entrenamiento : [[0.33081418]]\n",
      "PERDIDAAAA despues: 0.1442200392484665\n",
      "loss en el callback: 0.16815422475337982, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28711516]\n",
      "  [0.2918323 ]\n",
      "  [0.29705495]\n",
      "  [0.30187252]\n",
      "  [0.30682254]\n",
      "  [0.31255534]\n",
      "  [0.3192817 ]\n",
      "  [0.32647941]]]\n",
      "ejemplar: [0.28711516 0.2918323  0.29705495 0.30187252 0.30682254 0.31255534\n",
      " 0.3192817  0.32647941]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33429134]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28711516 0.2918323  0.29705495 0.30187252 0.30682254 0.31255534\n",
      "  0.3192817  0.32647941]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13667762279510498\n",
      "Predicción post entrenamiento : [[0.33847246]]\n",
      "PERDIDAAAA despues: 0.13360358774662018\n",
      "loss en el callback: 0.1913829892873764, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.2918323 ]\n",
      "  [0.29705495]\n",
      "  [0.30187252]\n",
      "  [0.30682254]\n",
      "  [0.31255534]\n",
      "  [0.3192817 ]\n",
      "  [0.32647941]\n",
      "  [0.33429134]]]\n",
      "ejemplar: [0.2918323  0.29705495 0.30187252 0.30682254 0.31255534 0.3192817\n",
      " 0.32647941 0.33429134]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34215286]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.2918323  0.29705495 0.30187252 0.30682254 0.31255534 0.3192817\n",
      "  0.32647941 0.33429134]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14829018712043762\n",
      "Predicción post entrenamiento : [[0.34618768]]\n",
      "PERDIDAAAA despues: 0.1451989859342575\n",
      "loss en el callback: 0.18446111679077148, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29705495]\n",
      "  [0.30187252]\n",
      "  [0.30682254]\n",
      "  [0.31255534]\n",
      "  [0.3192817 ]\n",
      "  [0.32647941]\n",
      "  [0.33429134]\n",
      "  [0.34215286]]]\n",
      "ejemplar: [0.29705495 0.30187252 0.30682254 0.31255534 0.3192817  0.32647941\n",
      " 0.33429134 0.34215286]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35010388]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29705495 0.30187252 0.30682254 0.31255534 0.3192817  0.32647941\n",
      "  0.33429134 0.34215286]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1387445032596588\n",
      "Predicción post entrenamiento : [[0.3543939]]\n",
      "PERDIDAAAA despues: 0.13556697964668274\n",
      "loss en el callback: 0.14771370589733124, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30187252]\n",
      "  [0.30682254]\n",
      "  [0.31255534]\n",
      "  [0.3192817 ]\n",
      "  [0.32647941]\n",
      "  [0.33429134]\n",
      "  [0.34215286]\n",
      "  [0.35010388]]]\n",
      "ejemplar: [0.30187252 0.30682254 0.31255534 0.3192817  0.32647941 0.33429134\n",
      " 0.34215286 0.35010388]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.35852045]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30187252 0.30682254 0.31255534 0.3192817  0.32647941 0.33429134\n",
      "  0.34215286 0.35010388]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.17079494893550873\n",
      "Predicción post entrenamiento : [[0.36283022]]\n",
      "PERDIDAAAA despues: 0.16725128889083862\n",
      "loss en el callback: 0.2062479704618454, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30682254]\n",
      "  [0.31255534]\n",
      "  [0.3192817 ]\n",
      "  [0.32647941]\n",
      "  [0.33429134]\n",
      "  [0.34215286]\n",
      "  [0.35010388]\n",
      "  [0.35852045]]]\n",
      "ejemplar: [0.30682254 0.31255534 0.3192817  0.32647941 0.33429134 0.34215286\n",
      " 0.35010388 0.35852045]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36736113]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30682254 0.31255534 0.3192817  0.32647941 0.33429134 0.34215286\n",
      "  0.35010388 0.35852045]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12756630778312683\n",
      "Predicción post entrenamiento : [[0.37104267]]\n",
      "PERDIDAAAA despues: 0.12495003640651703\n",
      "loss en el callback: 0.09720642119646072, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31255534]\n",
      "  [0.3192817 ]\n",
      "  [0.32647941]\n",
      "  [0.33429134]\n",
      "  [0.34215286]\n",
      "  [0.35010388]\n",
      "  [0.35852045]\n",
      "  [0.36736113]]]\n",
      "ejemplar: [0.31255534 0.3192817  0.32647941 0.33429134 0.34215286 0.35010388\n",
      " 0.35852045 0.36736113]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3760702]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31255534 0.3192817  0.32647941 0.33429134 0.34215286 0.35010388\n",
      "  0.35852045 0.36736113]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08701762557029724\n",
      "Predicción post entrenamiento : [[0.37904897]]\n",
      "PERDIDAAAA despues: 0.08526909351348877\n",
      "loss en el callback: 0.08024159073829651, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.3192817 ]\n",
      "  [0.32647941]\n",
      "  [0.33429134]\n",
      "  [0.34215286]\n",
      "  [0.35010388]\n",
      "  [0.35852045]\n",
      "  [0.36736113]\n",
      "  [0.3760702 ]]]\n",
      "ejemplar: [0.3192817  0.32647941 0.33429134 0.34215286 0.35010388 0.35852045\n",
      " 0.36736113 0.3760702 ]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38451004]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.3192817  0.32647941 0.33429134 0.34215286 0.35010388 0.35852045\n",
      "  0.36736113 0.3760702 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08367122709751129\n",
      "Predicción post entrenamiento : [[0.38741666]]\n",
      "PERDIDAAAA despues: 0.08199813961982727\n",
      "loss en el callback: 0.0957583412528038, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32647941]\n",
      "  [0.33429134]\n",
      "  [0.34215286]\n",
      "  [0.35010388]\n",
      "  [0.35852045]\n",
      "  [0.36736113]\n",
      "  [0.3760702 ]\n",
      "  [0.38451004]]]\n",
      "ejemplar: [0.32647941 0.33429134 0.34215286 0.35010388 0.35852045 0.36736113\n",
      " 0.3760702  0.38451004]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3931721]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32647941 0.33429134 0.34215286 0.35010388 0.35852045 0.36736113\n",
      "  0.3760702  0.38451004]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10322064906358719\n",
      "Predicción post entrenamiento : [[0.39646202]]\n",
      "PERDIDAAAA despues: 0.10111749172210693\n",
      "loss en el callback: 0.10033893585205078, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33429134]\n",
      "  [0.34215286]\n",
      "  [0.35010388]\n",
      "  [0.35852045]\n",
      "  [0.36736113]\n",
      "  [0.3760702 ]\n",
      "  [0.38451004]\n",
      "  [0.39317209]]]\n",
      "ejemplar: [0.33429134 0.34215286 0.35010388 0.35852045 0.36736113 0.3760702\n",
      " 0.38451004 0.39317209]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40246797]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33429134 0.34215286 0.35010388 0.35852045 0.36736113 0.3760702\n",
      "  0.38451004 0.39317209]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11657428741455078\n",
      "Predicción post entrenamiento : [[0.40598547]]\n",
      "PERDIDAAAA despues: 0.11418469995260239\n",
      "loss en el callback: 0.14237067103385925, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34215286]\n",
      "  [0.35010388]\n",
      "  [0.35852045]\n",
      "  [0.36736113]\n",
      "  [0.3760702 ]\n",
      "  [0.38451004]\n",
      "  [0.39317209]\n",
      "  [0.40246797]]]\n",
      "ejemplar: [0.34215286 0.35010388 0.35852045 0.36736113 0.3760702  0.38451004\n",
      " 0.39317209 0.40246797]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4121489]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34215286 0.35010388 0.35852045 0.36736113 0.3760702  0.38451004\n",
      "  0.39317209 0.40246797]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09637251496315002\n",
      "Predicción post entrenamiento : [[0.41518587]]\n",
      "PERDIDAAAA despues: 0.09449614584445953\n",
      "loss en el callback: 0.10149190574884415, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35010388]\n",
      "  [0.35852045]\n",
      "  [0.36736113]\n",
      "  [0.3760702 ]\n",
      "  [0.38451004]\n",
      "  [0.39317209]\n",
      "  [0.40246797]\n",
      "  [0.41214889]]]\n",
      "ejemplar: [0.35010388 0.35852045 0.36736113 0.3760702  0.38451004 0.39317209\n",
      " 0.40246797 0.41214889]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42153648]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35010388 0.35852045 0.36736113 0.3760702  0.38451004 0.39317209\n",
      "  0.40246797 0.41214889]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0771755501627922\n",
      "Predicción post entrenamiento : [[0.42405698]]\n",
      "PERDIDAAAA despues: 0.07578148692846298\n",
      "loss en el callback: 0.05961684137582779, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.35852045]\n",
      "  [0.36736113]\n",
      "  [0.3760702 ]\n",
      "  [0.38451004]\n",
      "  [0.39317209]\n",
      "  [0.40246797]\n",
      "  [0.41214889]\n",
      "  [0.42153648]]]\n",
      "ejemplar: [0.35852045 0.36736113 0.3760702  0.38451004 0.39317209 0.40246797\n",
      " 0.41214889 0.42153648]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43061963]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.35852045 0.36736113 0.3760702  0.38451004 0.39317209 0.40246797\n",
      "  0.41214889 0.42153648]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09405967593193054\n",
      "Predicción post entrenamiento : [[0.43357652]]\n",
      "PERDIDAAAA despues: 0.09225470572710037\n",
      "loss en el callback: 0.08476398885250092, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36736113]\n",
      "  [0.3760702 ]\n",
      "  [0.38451004]\n",
      "  [0.39317209]\n",
      "  [0.40246797]\n",
      "  [0.41214889]\n",
      "  [0.42153648]\n",
      "  [0.43061963]]]\n",
      "ejemplar: [0.36736113 0.3760702  0.38451004 0.39317209 0.40246797 0.41214889\n",
      " 0.42153648 0.43061963]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4402832]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36736113 0.3760702  0.38451004 0.39317209 0.40246797 0.41214889\n",
      "  0.42153648 0.43061963]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07904117554426193\n",
      "Predicción post entrenamiento : [[0.4423913]]\n",
      "PERDIDAAAA despues: 0.0778602659702301\n",
      "loss en el callback: 0.033331383019685745, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.3760702 ]\n",
      "  [0.38451004]\n",
      "  [0.39317209]\n",
      "  [0.40246797]\n",
      "  [0.41214889]\n",
      "  [0.42153648]\n",
      "  [0.43061963]\n",
      "  [0.44028321]]]\n",
      "ejemplar: [0.3760702  0.38451004 0.39317209 0.40246797 0.41214889 0.42153648\n",
      " 0.43061963 0.44028321]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.44916674]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.3760702  0.38451004 0.39317209 0.40246797 0.41214889 0.42153648\n",
      "  0.43061963 0.44028321]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0726555585861206\n",
      "Predicción post entrenamiento : [[0.45158598]]\n",
      "PERDIDAAAA despues: 0.07135722041130066\n",
      "loss en el callback: 0.05789681524038315, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38451004]\n",
      "  [0.39317209]\n",
      "  [0.40246797]\n",
      "  [0.41214889]\n",
      "  [0.42153648]\n",
      "  [0.43061963]\n",
      "  [0.44028321]\n",
      "  [0.44916674]]]\n",
      "ejemplar: [0.38451004 0.39317209 0.40246797 0.41214889 0.42153648 0.43061963\n",
      " 0.44028321 0.44916674]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4584849]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38451004 0.39317209 0.40246797 0.41214889 0.42153648 0.43061963\n",
      "  0.44028321 0.44916674]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0465145967900753\n",
      "Predicción post entrenamiento : [[0.46045056]]\n",
      "PERDIDAAAA despues: 0.04567058011889458\n",
      "loss en el callback: 0.03323914855718613, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39317209]\n",
      "  [0.40246797]\n",
      "  [0.41214889]\n",
      "  [0.42153648]\n",
      "  [0.43061963]\n",
      "  [0.44028321]\n",
      "  [0.44916674]\n",
      "  [0.45848489]]]\n",
      "ejemplar: [0.39317209 0.40246797 0.41214889 0.42153648 0.43061963 0.44028321\n",
      " 0.44916674 0.45848489]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46756613]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39317209 0.40246797 0.41214889 0.42153648 0.43061963 0.44028321\n",
      "  0.44916674 0.45848489]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05336114019155502\n",
      "Predicción post entrenamiento : [[0.46965915]]\n",
      "PERDIDAAAA despues: 0.052398547530174255\n",
      "loss en el callback: 0.053715210407972336, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40246797]\n",
      "  [0.41214889]\n",
      "  [0.42153648]\n",
      "  [0.43061963]\n",
      "  [0.44028321]\n",
      "  [0.44916674]\n",
      "  [0.45848489]\n",
      "  [0.46756613]]]\n",
      "ejemplar: [0.40246797 0.41214889 0.42153648 0.43061963 0.44028321 0.44916674\n",
      " 0.45848489 0.46756613]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47696868]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40246797 0.41214889 0.42153648 0.43061963 0.44028321 0.44916674\n",
      "  0.45848489 0.46756613]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05957000330090523\n",
      "Predicción post entrenamiento : [[0.4786593]]\n",
      "PERDIDAAAA despues: 0.05874759703874588\n",
      "loss en el callback: 0.024658678099513054, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41214889]\n",
      "  [0.42153648]\n",
      "  [0.43061963]\n",
      "  [0.44028321]\n",
      "  [0.44916674]\n",
      "  [0.45848489]\n",
      "  [0.46756613]\n",
      "  [0.47696868]]]\n",
      "ejemplar: [0.41214889 0.42153648 0.43061963 0.44028321 0.44916674 0.45848489\n",
      " 0.46756613 0.47696868]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.48601907]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41214889 0.42153648 0.43061963 0.44028321 0.44916674 0.45848489\n",
      "  0.46756613 0.47696868]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055964913219213486\n",
      "Predicción post entrenamiento : [[0.48862183]]\n",
      "PERDIDAAAA despues: 0.05474022403359413\n",
      "loss en el callback: 0.1034940779209137, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42153648]\n",
      "  [0.43061963]\n",
      "  [0.44028321]\n",
      "  [0.44916674]\n",
      "  [0.45848489]\n",
      "  [0.46756613]\n",
      "  [0.47696868]\n",
      "  [0.48601907]]]\n",
      "ejemplar: [0.42153648 0.43061963 0.44028321 0.44916674 0.45848489 0.46756613\n",
      " 0.47696868 0.48601907]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.49592933]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42153648 0.43061963 0.44028321 0.44916674 0.45848489 0.46756613\n",
      "  0.47696868 0.48601907]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06779082119464874\n",
      "Predicción post entrenamiento : [[0.49865398]]\n",
      "PERDIDAAAA despues: 0.06637942790985107\n",
      "loss en el callback: 0.12020713835954666, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43061963]\n",
      "  [0.44028321]\n",
      "  [0.44916674]\n",
      "  [0.45848489]\n",
      "  [0.46756613]\n",
      "  [0.47696868]\n",
      "  [0.48601907]\n",
      "  [0.49592933]]]\n",
      "ejemplar: [0.43061963 0.44028321 0.44916674 0.45848489 0.46756613 0.47696868\n",
      " 0.48601907 0.49592933]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5059704]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43061963 0.44028321 0.44916674 0.45848489 0.46756613 0.47696868\n",
      "  0.48601907 0.49592933]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10343673080205917\n",
      "Predicción post entrenamiento : [[0.50884956]]\n",
      "PERDIDAAAA despues: 0.10159306973218918\n",
      "loss en el callback: 0.08803658187389374, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44028321]\n",
      "  [0.44916674]\n",
      "  [0.45848489]\n",
      "  [0.46756613]\n",
      "  [0.47696868]\n",
      "  [0.48601907]\n",
      "  [0.49592933]\n",
      "  [0.50597042]]]\n",
      "ejemplar: [0.44028321 0.44916674 0.45848489 0.46756613 0.47696868 0.48601907\n",
      " 0.49592933 0.50597042]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.51625794]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44028321 0.44916674 0.45848489 0.46756613 0.47696868 0.48601907\n",
      "  0.49592933 0.50597042]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10404769331216812\n",
      "Predicción post entrenamiento : [[0.5193741]]\n",
      "PERDIDAAAA despues: 0.10204710066318512\n",
      "loss en el callback: 0.1336503028869629, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.44916674]\n",
      "  [0.45848489]\n",
      "  [0.46756613]\n",
      "  [0.47696868]\n",
      "  [0.48601907]\n",
      "  [0.49592933]\n",
      "  [0.50597042]\n",
      "  [0.51625794]]]\n",
      "ejemplar: [0.44916674 0.45848489 0.46756613 0.47696868 0.48601907 0.49592933\n",
      " 0.50597042 0.51625794]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5267431]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.44916674 0.45848489 0.46756613 0.47696868 0.48601907 0.49592933\n",
      "  0.50597042 0.51625794]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07156839221715927\n",
      "Predicción post entrenamiento : [[0.5292253]]\n",
      "PERDIDAAAA despues: 0.07024647295475006\n",
      "loss en el callback: 0.08652561902999878, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.45848489]\n",
      "  [0.46756613]\n",
      "  [0.47696868]\n",
      "  [0.48601907]\n",
      "  [0.49592933]\n",
      "  [0.50597042]\n",
      "  [0.51625794]\n",
      "  [0.52674311]]]\n",
      "ejemplar: [0.45848489 0.46756613 0.47696868 0.48601907 0.49592933 0.50597042\n",
      " 0.51625794 0.52674311]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.53677106]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.45848489 0.46756613 0.47696868 0.48601907 0.49592933 0.50597042\n",
      "  0.51625794 0.52674311]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061025626957416534\n",
      "Predicción post entrenamiento : [[0.5391933]]\n",
      "PERDIDAAAA despues: 0.05983475595712662\n",
      "loss en el callback: 0.07816494256258011, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.46756613]\n",
      "  [0.47696868]\n",
      "  [0.48601907]\n",
      "  [0.49592933]\n",
      "  [0.50597042]\n",
      "  [0.51625794]\n",
      "  [0.52674311]\n",
      "  [0.53677106]]]\n",
      "ejemplar: [0.46756613 0.47696868 0.48601907 0.49592933 0.50597042 0.51625794\n",
      " 0.52674311 0.53677106]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.54684734]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.46756613 0.47696868 0.48601907 0.49592933 0.50597042 0.51625794\n",
      "  0.52674311 0.53677106]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04887286201119423\n",
      "Predicción post entrenamiento : [[0.5475041]]\n",
      "PERDIDAAAA despues: 0.04858290031552315\n",
      "loss en el callback: 0.003454074263572693, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.47696868]\n",
      "  [0.48601907]\n",
      "  [0.49592933]\n",
      "  [0.50597042]\n",
      "  [0.51625794]\n",
      "  [0.52674311]\n",
      "  [0.53677106]\n",
      "  [0.54684734]]]\n",
      "ejemplar: [0.47696868 0.48601907 0.49592933 0.50597042 0.51625794 0.52674311\n",
      " 0.53677106 0.54684734]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5553598]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.47696868 0.48601907 0.49592933 0.50597042 0.51625794 0.52674311\n",
      "  0.53677106 0.54684734]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052541740238666534\n",
      "Predicción post entrenamiento : [[0.5574179]]\n",
      "PERDIDAAAA despues: 0.05160244181752205\n",
      "loss en el callback: 0.05116729438304901, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.48601907]\n",
      "  [0.49592933]\n",
      "  [0.50597042]\n",
      "  [0.51625794]\n",
      "  [0.52674311]\n",
      "  [0.53677106]\n",
      "  [0.54684734]\n",
      "  [0.55535978]]]\n",
      "ejemplar: [0.48601907 0.49592933 0.50597042 0.51625794 0.52674311 0.53677106\n",
      " 0.54684734 0.55535978]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.56543124]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.48601907 0.49592933 0.50597042 0.51625794 0.52674311 0.53677106\n",
      "  0.54684734 0.55535978]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09815558791160583\n",
      "Predicción post entrenamiento : [[0.5679628]]\n",
      "PERDIDAAAA despues: 0.09657571464776993\n",
      "loss en el callback: 0.07313556224107742, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.49592933]\n",
      "  [0.50597042]\n",
      "  [0.51625794]\n",
      "  [0.52674311]\n",
      "  [0.53677106]\n",
      "  [0.54684734]\n",
      "  [0.55535978]\n",
      "  [0.56543124]]]\n",
      "ejemplar: [0.49592933 0.50597042 0.51625794 0.52674311 0.53677106 0.54684734\n",
      " 0.55535978 0.56543124]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5762522]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.49592933 0.50597042 0.51625794 0.52674311 0.53677106 0.54684734\n",
      "  0.55535978 0.56543124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08962681889533997\n",
      "Predicción post entrenamiento : [[0.5792866]]\n",
      "PERDIDAAAA despues: 0.0878191888332367\n",
      "loss en el callback: 0.17481686174869537, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.50597042]\n",
      "  [0.51625794]\n",
      "  [0.52674311]\n",
      "  [0.53677106]\n",
      "  [0.54684734]\n",
      "  [0.55535978]\n",
      "  [0.56543124]\n",
      "  [0.57625222]]]\n",
      "ejemplar: [0.50597042 0.51625794 0.52674311 0.53677106 0.54684734 0.55535978\n",
      " 0.56543124 0.57625222]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.58765346]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.50597042 0.51625794 0.52674311 0.53677106 0.54684734 0.55535978\n",
      "  0.56543124 0.57625222]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06824755668640137\n",
      "Predicción post entrenamiento : [[0.58958817]]\n",
      "PERDIDAAAA despues: 0.06724044680595398\n",
      "loss en el callback: 0.04043075442314148, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.51625794]\n",
      "  [0.52674311]\n",
      "  [0.53677106]\n",
      "  [0.54684734]\n",
      "  [0.55535978]\n",
      "  [0.56543124]\n",
      "  [0.57625222]\n",
      "  [0.58765346]]]\n",
      "ejemplar: [0.51625794 0.52674311 0.53677106 0.54684734 0.55535978 0.56543124\n",
      " 0.57625222 0.58765346]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5980004]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.51625794 0.52674311 0.53677106 0.54684734 0.55535978 0.56543124\n",
      "  0.57625222 0.58765346]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.048526398837566376\n",
      "Predicción post entrenamiento : [[0.59969807]]\n",
      "PERDIDAAAA despues: 0.047781337052583694\n",
      "loss en el callback: 0.03637908399105072, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.52674311]\n",
      "  [0.53677106]\n",
      "  [0.54684734]\n",
      "  [0.55535978]\n",
      "  [0.56543124]\n",
      "  [0.57625222]\n",
      "  [0.58765346]\n",
      "  [0.59800041]]]\n",
      "ejemplar: [0.52674311 0.53677106 0.54684734 0.55535978 0.56543124 0.57625222\n",
      " 0.58765346 0.59800041]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6080952]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.52674311 0.53677106 0.54684734 0.55535978 0.56543124 0.57625222\n",
      "  0.58765346 0.59800041]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047836724668741226\n",
      "Predicción post entrenamiento : [[0.6099359]]\n",
      "PERDIDAAAA despues: 0.04703495278954506\n",
      "loss en el callback: 0.045603182166814804, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.53677106]\n",
      "  [0.54684734]\n",
      "  [0.55535978]\n",
      "  [0.56543124]\n",
      "  [0.57625222]\n",
      "  [0.58765346]\n",
      "  [0.59800041]\n",
      "  [0.60809523]]]\n",
      "ejemplar: [0.53677106 0.54684734 0.55535978 0.56543124 0.57625222 0.58765346\n",
      " 0.59800041 0.60809523]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6182667]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.53677106 0.54684734 0.55535978 0.56543124 0.57625222 0.58765346\n",
      "  0.59800041 0.60809523]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02791833132505417\n",
      "Predicción post entrenamiento : [[0.6197989]]\n",
      "PERDIDAAAA despues: 0.027408655732870102\n",
      "loss en el callback: 0.03282811492681503, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.54684734]\n",
      "  [0.55535978]\n",
      "  [0.56543124]\n",
      "  [0.57625222]\n",
      "  [0.58765346]\n",
      "  [0.59800041]\n",
      "  [0.60809523]\n",
      "  [0.6182667 ]]]\n",
      "ejemplar: [0.54684734 0.55535978 0.56543124 0.57625222 0.58765346 0.59800041\n",
      " 0.60809523 0.6182667 ]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6281888]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.54684734 0.55535978 0.56543124 0.57625222 0.58765346 0.59800041\n",
      "  0.60809523 0.6182667 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025933941826224327\n",
      "Predicción post entrenamiento : [[0.62923324]]\n",
      "PERDIDAAAA despues: 0.025598635897040367\n",
      "loss en el callback: 0.012575259432196617, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.55535978]\n",
      "  [0.56543124]\n",
      "  [0.57625222]\n",
      "  [0.58765346]\n",
      "  [0.59800041]\n",
      "  [0.60809523]\n",
      "  [0.6182667 ]\n",
      "  [0.62818879]]]\n",
      "ejemplar: [0.55535978 0.56543124 0.57625222 0.58765346 0.59800041 0.60809523\n",
      " 0.6182667  0.62818879]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.63768476]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.55535978 0.56543124 0.57625222 0.58765346 0.59800041 0.60809523\n",
      "  0.6182667  0.62818879]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03860754147171974\n",
      "Predicción post entrenamiento : [[0.6395295]]\n",
      "PERDIDAAAA despues: 0.03788599744439125\n",
      "loss en el callback: 0.0463930182158947, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.56543124]\n",
      "  [0.57625222]\n",
      "  [0.58765346]\n",
      "  [0.59800041]\n",
      "  [0.60809523]\n",
      "  [0.6182667 ]\n",
      "  [0.62818879]\n",
      "  [0.63768476]]]\n",
      "ejemplar: [0.56543124 0.57625222 0.58765346 0.59800041 0.60809523 0.6182667\n",
      " 0.62818879 0.63768476]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.64849406]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.56543124 0.57625222 0.58765346 0.59800041 0.60809523 0.6182667\n",
      "  0.62818879 0.63768476]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02689000964164734\n",
      "Predicción post entrenamiento : [[0.6493414]]\n",
      "PERDIDAAAA despues: 0.02661283127963543\n",
      "loss en el callback: 0.009029320441186428, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.57625222]\n",
      "  [0.58765346]\n",
      "  [0.59800041]\n",
      "  [0.60809523]\n",
      "  [0.6182667 ]\n",
      "  [0.62818879]\n",
      "  [0.63768476]\n",
      "  [0.64849406]]]\n",
      "ejemplar: [0.57625222 0.58765346 0.59800041 0.60809523 0.6182667  0.62818879\n",
      " 0.63768476 0.64849406]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6584437]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.57625222 0.58765346 0.59800041 0.60809523 0.6182667  0.62818879\n",
      "  0.63768476 0.64849406]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020390743389725685\n",
      "Predicción post entrenamiento : [[0.65996754]]\n",
      "PERDIDAAAA despues: 0.01995786465704441\n",
      "loss en el callback: 0.03557974100112915, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.58765346]\n",
      "  [0.59800041]\n",
      "  [0.60809523]\n",
      "  [0.6182667 ]\n",
      "  [0.62818879]\n",
      "  [0.63768476]\n",
      "  [0.64849406]\n",
      "  [0.65844369]]]\n",
      "ejemplar: [0.58765346 0.59800041 0.60809523 0.6182667  0.62818879 0.63768476\n",
      " 0.64849406 0.65844369]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.668994]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.58765346 0.59800041 0.60809523 0.6182667  0.62818879 0.63768476\n",
      "  0.64849406 0.65844369]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018005089834332466\n",
      "Predicción post entrenamiento : [[0.670331]]\n",
      "PERDIDAAAA despues: 0.01764807477593422\n",
      "loss en el callback: 0.027752835303544998, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.59800041]\n",
      "  [0.60809523]\n",
      "  [0.6182667 ]\n",
      "  [0.62818879]\n",
      "  [0.63768476]\n",
      "  [0.64849406]\n",
      "  [0.65844369]\n",
      "  [0.66899401]]]\n",
      "ejemplar: [0.59800041 0.60809523 0.6182667  0.62818879 0.63768476 0.64849406\n",
      " 0.65844369 0.66899401]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.67908263]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.59800041 0.60809523 0.6182667  0.62818879 0.63768476 0.64849406\n",
      "  0.65844369 0.66899401]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013089248910546303\n",
      "Predicción post entrenamiento : [[0.6802101]]\n",
      "PERDIDAAAA despues: 0.012832533568143845\n",
      "loss en el callback: 0.018685253337025642, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.60809523]\n",
      "  [0.6182667 ]\n",
      "  [0.62818879]\n",
      "  [0.63768476]\n",
      "  [0.64849406]\n",
      "  [0.65844369]\n",
      "  [0.66899401]\n",
      "  [0.67908263]]]\n",
      "ejemplar: [0.60809523 0.6182667  0.62818879 0.63768476 0.64849406 0.65844369\n",
      " 0.66899401 0.67908263]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6889338]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.60809523 0.6182667  0.62818879 0.63768476 0.64849406 0.65844369\n",
      "  0.66899401 0.67908263]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005074663087725639\n",
      "Predicción post entrenamiento : [[0.6889671]]\n",
      "PERDIDAAAA despues: 0.005069917067885399\n",
      "loss en el callback: 1.3509450582205318e-05, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.6182667 ]\n",
      "  [0.62818879]\n",
      "  [0.63768476]\n",
      "  [0.64849406]\n",
      "  [0.65844369]\n",
      "  [0.66899401]\n",
      "  [0.67908263]\n",
      "  [0.68893379]]]\n",
      "ejemplar: [0.6182667  0.62818879 0.63768476 0.64849406 0.65844369 0.66899401\n",
      " 0.67908263 0.68893379]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6977227]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.6182667  0.62818879 0.63768476 0.64849406 0.65844369 0.66899401\n",
      "  0.67908263 0.68893379]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014176159165799618\n",
      "Predicción post entrenamiento : [[0.69787186]]\n",
      "PERDIDAAAA despues: 0.0014064038405194879\n",
      "loss en el callback: 0.00029903053655289114, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.62818879]\n",
      "  [0.63768476]\n",
      "  [0.64849406]\n",
      "  [0.65844369]\n",
      "  [0.66899401]\n",
      "  [0.67908263]\n",
      "  [0.68893379]\n",
      "  [0.69772267]]]\n",
      "ejemplar: [0.62818879 0.63768476 0.64849406 0.65844369 0.66899401 0.67908263\n",
      " 0.68893379 0.69772267]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7066326]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.62818879 0.63768476 0.64849406 0.65844369 0.66899401 0.67908263\n",
      "  0.68893379 0.69772267]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2653708836296573e-05\n",
      "Predicción post entrenamiento : [[0.7071891]]\n",
      "PERDIDAAAA despues: 9.004417734104209e-06\n",
      "loss en el callback: 0.005165695212781429, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.63768476]\n",
      "  [0.64849406]\n",
      "  [0.65844369]\n",
      "  [0.66899401]\n",
      "  [0.67908263]\n",
      "  [0.68893379]\n",
      "  [0.69772267]\n",
      "  [0.70663261]]]\n",
      "ejemplar: [0.63768476 0.64849406 0.65844369 0.66899401 0.67908263 0.68893379\n",
      " 0.69772267 0.70663261]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.71600914]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.63768476 0.64849406 0.65844369 0.66899401 0.67908263 0.68893379\n",
      "  0.69772267 0.70663261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.5070316294441e-05\n",
      "Predicción post entrenamiento : [[0.7165769]]\n",
      "PERDIDAAAA despues: 1.980058368644677e-05\n",
      "loss en el callback: 0.006265678908675909, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.64849406]\n",
      "  [0.65844369]\n",
      "  [0.66899401]\n",
      "  [0.67908263]\n",
      "  [0.68893379]\n",
      "  [0.69772267]\n",
      "  [0.70663261]\n",
      "  [0.71600914]]]\n",
      "ejemplar: [0.64849406 0.65844369 0.66899401 0.67908263 0.68893379 0.69772267\n",
      " 0.70663261 0.71600914]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.72556007]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.64849406 0.65844369 0.66899401 0.67908263 0.68893379 0.69772267\n",
      "  0.70663261 0.71600914]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019812691607512534\n",
      "Predicción post entrenamiento : [[0.7261132]]\n",
      "PERDIDAAAA despues: 0.0001828613894758746\n",
      "loss en el callback: 0.005641890689730644, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.65844369]\n",
      "  [0.66899401]\n",
      "  [0.67908263]\n",
      "  [0.68893379]\n",
      "  [0.69772267]\n",
      "  [0.70663261]\n",
      "  [0.71600914]\n",
      "  [0.72556007]]]\n",
      "ejemplar: [0.65844369 0.66899401 0.67908263 0.68893379 0.69772267 0.70663261\n",
      " 0.71600914 0.72556007]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7348681]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.65844369 0.66899401 0.67908263 0.68893379 0.69772267 0.70663261\n",
      "  0.71600914 0.72556007]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.64010384651192e-06\n",
      "Predicción post entrenamiento : [[0.7346249]]\n",
      "PERDIDAAAA despues: 2.3221259652927984e-06\n",
      "loss en el callback: 0.0008054061909206212, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.66899401]\n",
      "  [0.67908263]\n",
      "  [0.68893379]\n",
      "  [0.69772267]\n",
      "  [0.70663261]\n",
      "  [0.71600914]\n",
      "  [0.72556007]\n",
      "  [0.73486811]]]\n",
      "ejemplar: [0.66899401 0.67908263 0.68893379 0.69772267 0.70663261 0.71600914\n",
      " 0.72556007 0.73486811]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7433298]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.66899401 0.67908263 0.68893379 0.69772267 0.70663261 0.71600914\n",
      "  0.72556007 0.73486811]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005739443004131317\n",
      "Predicción post entrenamiento : [[0.7427739]]\n",
      "PERDIDAAAA despues: 0.005655518267303705\n",
      "loss en el callback: 0.004302731715142727, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.67908263]\n",
      "  [0.68893379]\n",
      "  [0.69772267]\n",
      "  [0.70663261]\n",
      "  [0.71600914]\n",
      "  [0.72556007]\n",
      "  [0.73486811]\n",
      "  [0.74332982]]]\n",
      "ejemplar: [0.67908263 0.68893379 0.69772267 0.70663261 0.71600914 0.72556007\n",
      " 0.73486811 0.74332982]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7512127]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.67908263 0.68893379 0.69772267 0.70663261 0.71600914 0.72556007\n",
      "  0.73486811 0.74332982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006612504366785288\n",
      "Predicción post entrenamiento : [[0.75007737]]\n",
      "PERDIDAAAA despues: 0.00642914604395628\n",
      "loss en el callback: 0.01753491535782814, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.68893379]\n",
      "  [0.69772267]\n",
      "  [0.70663261]\n",
      "  [0.71600914]\n",
      "  [0.72556007]\n",
      "  [0.73486811]\n",
      "  [0.74332982]\n",
      "  [0.75121272]]]\n",
      "ejemplar: [0.68893379 0.69772267 0.70663261 0.71600914 0.72556007 0.73486811\n",
      " 0.74332982 0.75121272]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.75831026]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.68893379 0.69772267 0.70663261 0.71600914 0.72556007 0.73486811\n",
      "  0.74332982 0.75121272]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038045498076826334\n",
      "Predicción post entrenamiento : [[0.75770396]]\n",
      "PERDIDAAAA despues: 0.0037301231641322374\n",
      "loss en el callback: 0.005216231569647789, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.69772267]\n",
      "  [0.70663261]\n",
      "  [0.71600914]\n",
      "  [0.72556007]\n",
      "  [0.73486811]\n",
      "  [0.74332982]\n",
      "  [0.75121272]\n",
      "  [0.75831026]]]\n",
      "ejemplar: [0.69772267 0.70663261 0.71600914 0.72556007 0.73486811 0.74332982\n",
      " 0.75121272 0.75831026]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.76573575]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.69772267 0.70663261 0.71600914 0.72556007 0.73486811 0.74332982\n",
      "  0.75121272 0.75831026]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01205349713563919\n",
      "Predicción post entrenamiento : [[0.7644176]]\n",
      "PERDIDAAAA despues: 0.01176579762250185\n",
      "loss en el callback: 0.024097921326756477, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.70663261]\n",
      "  [0.71600914]\n",
      "  [0.72556007]\n",
      "  [0.73486811]\n",
      "  [0.74332982]\n",
      "  [0.75121272]\n",
      "  [0.75831026]\n",
      "  [0.76573575]]]\n",
      "ejemplar: [0.70663261 0.71600914 0.72556007 0.73486811 0.74332982 0.75121272\n",
      " 0.75831026 0.76573575]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.77248603]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.70663261 0.71600914 0.72556007 0.73486811 0.74332982 0.75121272\n",
      "  0.75831026 0.76573575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008775823749601841\n",
      "Predicción post entrenamiento : [[0.7720024]]\n",
      "PERDIDAAAA despues: 0.008685445412993431\n",
      "loss en el callback: 0.0036689634434878826, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.71600914]\n",
      "  [0.72556007]\n",
      "  [0.73486811]\n",
      "  [0.74332982]\n",
      "  [0.75121272]\n",
      "  [0.75831026]\n",
      "  [0.76573575]\n",
      "  [0.77248603]]]\n",
      "ejemplar: [0.71600914 0.72556007 0.73486811 0.74332982 0.75121272 0.75831026\n",
      " 0.76573575 0.77248603]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7800256]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.71600914 0.72556007 0.73486811 0.74332982 0.75121272 0.75831026\n",
      "  0.76573575 0.77248603]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010801667347550392\n",
      "Predicción post entrenamiento : [[0.7780527]]\n",
      "PERDIDAAAA despues: 0.010395465418696404\n",
      "loss en el callback: 0.04673393443226814, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.72556007]\n",
      "  [0.73486811]\n",
      "  [0.74332982]\n",
      "  [0.75121272]\n",
      "  [0.75831026]\n",
      "  [0.76573575]\n",
      "  [0.77248603]\n",
      "  [0.7800256 ]]]\n",
      "ejemplar: [0.72556007 0.73486811 0.74332982 0.75121272 0.75831026 0.76573575\n",
      " 0.77248603 0.7800256 ]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.78581846]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.72556007 0.73486811 0.74332982 0.75121272 0.75831026 0.76573575\n",
      "  0.77248603 0.7800256 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003164770547300577\n",
      "Predicción post entrenamiento : [[0.7859338]]\n",
      "PERDIDAAAA despues: 0.003177760634571314\n",
      "loss en el callback: 0.0002358032070333138, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.73486811]\n",
      "  [0.74332982]\n",
      "  [0.75121272]\n",
      "  [0.75831026]\n",
      "  [0.76573575]\n",
      "  [0.77248603]\n",
      "  [0.7800256 ]\n",
      "  [0.78581846]]]\n",
      "ejemplar: [0.73486811 0.74332982 0.75121272 0.75831026 0.76573575 0.77248603\n",
      " 0.7800256  0.78581846]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.79329056]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.73486811 0.74332982 0.75121272 0.75831026 0.76573575 0.77248603\n",
      "  0.7800256  0.78581846]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008466205559670925\n",
      "Predicción post entrenamiento : [[0.7935266]]\n",
      "PERDIDAAAA despues: 0.008509697392582893\n",
      "loss en el callback: 0.0011238170554861426, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74332982]\n",
      "  [0.75121272]\n",
      "  [0.75831026]\n",
      "  [0.76573575]\n",
      "  [0.77248603]\n",
      "  [0.7800256 ]\n",
      "  [0.78581846]\n",
      "  [0.79329056]]]\n",
      "ejemplar: [0.74332982 0.75121272 0.75831026 0.76573575 0.77248603 0.7800256\n",
      " 0.78581846 0.79329056]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8004278]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74332982 0.75121272 0.75831026 0.76573575 0.77248603 0.7800256\n",
      "  0.78581846 0.79329056]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010821338510140777\n",
      "Predicción post entrenamiento : [[0.7986454]]\n",
      "PERDIDAAAA despues: 0.0009680428192950785\n",
      "loss en el callback: 0.03824871778488159, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75121272]\n",
      "  [0.75831026]\n",
      "  [0.76573575]\n",
      "  [0.77248603]\n",
      "  [0.7800256 ]\n",
      "  [0.78581846]\n",
      "  [0.79329056]\n",
      "  [0.80042779]]]\n",
      "ejemplar: [0.75121272 0.75831026 0.76573575 0.77248603 0.7800256  0.78581846\n",
      " 0.79329056 0.80042779]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.80522984]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75121272 0.75831026 0.76573575 0.77248603 0.7800256  0.78581846\n",
      "  0.79329056 0.80042779]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002509624697268009\n",
      "Predicción post entrenamiento : [[0.80477136]]\n",
      "PERDIDAAAA despues: 0.002463898854330182\n",
      "loss en el callback: 0.003325532888993621, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.75831026]\n",
      "  [0.76573575]\n",
      "  [0.77248603]\n",
      "  [0.7800256 ]\n",
      "  [0.78581846]\n",
      "  [0.79329056]\n",
      "  [0.80042779]\n",
      "  [0.80522984]]]\n",
      "ejemplar: [0.75831026 0.76573575 0.77248603 0.7800256  0.78581846 0.79329056\n",
      " 0.80042779 0.80522984]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.81113476]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.75831026 0.76573575 0.77248603 0.7800256  0.78581846 0.79329056\n",
      "  0.80042779 0.80522984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004365869797766209\n",
      "Predicción post entrenamiento : [[0.80971485]]\n",
      "PERDIDAAAA despues: 0.004180246498435736\n",
      "loss en el callback: 0.025835705921053886, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.76573575]\n",
      "  [0.77248603]\n",
      "  [0.7800256 ]\n",
      "  [0.78581846]\n",
      "  [0.79329056]\n",
      "  [0.80042779]\n",
      "  [0.80522984]\n",
      "  [0.81113476]]]\n",
      "ejemplar: [0.76573575 0.77248603 0.7800256  0.78581846 0.79329056 0.80042779\n",
      " 0.80522984 0.81113476]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8160225]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.76573575 0.77248603 0.7800256  0.78581846 0.79329056 0.80042779\n",
      "  0.80522984 0.81113476]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004094521515071392\n",
      "Predicción post entrenamiento : [[0.81433326]]\n",
      "PERDIDAAAA despues: 0.0038811892736703157\n",
      "loss en el callback: 0.03543418273329735, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.77248603]\n",
      "  [0.7800256 ]\n",
      "  [0.78581846]\n",
      "  [0.79329056]\n",
      "  [0.80042779]\n",
      "  [0.80522984]\n",
      "  [0.81113476]\n",
      "  [0.81602252]]]\n",
      "ejemplar: [0.77248603 0.7800256  0.78581846 0.79329056 0.80042779 0.80522984\n",
      " 0.81113476 0.81602252]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8204375]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.77248603 0.7800256  0.78581846 0.79329056 0.80042779 0.80522984\n",
      "  0.81113476 0.81602252]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012240125797688961\n",
      "Predicción post entrenamiento : [[0.8191541]]\n",
      "PERDIDAAAA despues: 0.01195779349654913\n",
      "loss en el callback: 0.02418130449950695, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.7800256 ]\n",
      "  [0.78581846]\n",
      "  [0.79329056]\n",
      "  [0.80042779]\n",
      "  [0.80522984]\n",
      "  [0.81113476]\n",
      "  [0.81602252]\n",
      "  [0.82043749]]]\n",
      "ejemplar: [0.7800256  0.78581846 0.79329056 0.80042779 0.80522984 0.81113476\n",
      " 0.81602252 0.82043749]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.8251758]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.7800256  0.78581846 0.79329056 0.80042779 0.80522984 0.81113476\n",
      "  0.81602252 0.82043749]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018156424164772034\n",
      "Predicción post entrenamiento : [[0.82462454]]\n",
      "PERDIDAAAA despues: 0.018008161336183548\n",
      "loss en el callback: 0.005959793459624052, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.78581846]\n",
      "  [0.79329056]\n",
      "  [0.80042779]\n",
      "  [0.80522984]\n",
      "  [0.81113476]\n",
      "  [0.81602252]\n",
      "  [0.82043749]\n",
      "  [0.82517582]]]\n",
      "ejemplar: [0.78581846 0.79329056 0.80042779 0.80522984 0.81113476 0.81602252\n",
      " 0.82043749 0.82517582]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8302585]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.78581846 0.79329056 0.80042779 0.80522984 0.81113476 0.81602252\n",
      "  0.82043749 0.82517582]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005760767497122288\n",
      "Predicción post entrenamiento : [[0.82998484]]\n",
      "PERDIDAAAA despues: 0.005719303153455257\n",
      "loss en el callback: 0.0014986532041803002, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.79329056]\n",
      "  [0.80042779]\n",
      "  [0.80522984]\n",
      "  [0.81113476]\n",
      "  [0.81602252]\n",
      "  [0.82043749]\n",
      "  [0.82517582]\n",
      "  [0.83025849]]]\n",
      "ejemplar: [0.79329056 0.80042779 0.80522984 0.81113476 0.81602252 0.82043749\n",
      " 0.82517582 0.83025849]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8356404]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.79329056 0.80042779 0.80522984 0.81113476 0.81602252 0.82043749\n",
      "  0.82517582 0.83025849]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01286856085062027\n",
      "Predicción post entrenamiento : [[0.8354622]]\n",
      "PERDIDAAAA despues: 0.01282817218452692\n",
      "loss en el callback: 0.0006671997252851725, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.80042779]\n",
      "  [0.80522984]\n",
      "  [0.81113476]\n",
      "  [0.81602252]\n",
      "  [0.82043749]\n",
      "  [0.82517582]\n",
      "  [0.83025849]\n",
      "  [0.83564037]]]\n",
      "ejemplar: [0.80042779 0.80522984 0.81113476 0.81602252 0.82043749 0.82517582\n",
      " 0.83025849 0.83564037]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8405887]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.80042779 0.80522984 0.81113476 0.81602252 0.82043749 0.82517582\n",
      "  0.83025849 0.83564037]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.272116297623143e-05\n",
      "Predicción post entrenamiento : [[0.8407009]]\n",
      "PERDIDAAAA despues: 6.0956019297009334e-05\n",
      "loss en el callback: 0.00021863475558348, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.80522984]\n",
      "  [0.81113476]\n",
      "  [0.81602252]\n",
      "  [0.82043749]\n",
      "  [0.82517582]\n",
      "  [0.83025849]\n",
      "  [0.83564037]\n",
      "  [0.84058869]]]\n",
      "ejemplar: [0.80522984 0.81113476 0.81602252 0.82043749 0.82517582 0.83025849\n",
      " 0.83564037 0.84058869]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8452852]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.80522984 0.81113476 0.81602252 0.82043749 0.82517582 0.83025849\n",
      "  0.83564037 0.84058869]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003621367970481515\n",
      "Predicción post entrenamiento : [[0.84533477]]\n",
      "PERDIDAAAA despues: 0.003615401918068528\n",
      "loss en el callback: 3.939430462196469e-05, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81113476]\n",
      "  [0.81602252]\n",
      "  [0.82043749]\n",
      "  [0.82517582]\n",
      "  [0.83025849]\n",
      "  [0.83564037]\n",
      "  [0.84058869]\n",
      "  [0.84528518]]]\n",
      "ejemplar: [0.81113476 0.81602252 0.82043749 0.82517582 0.83025849 0.83564037\n",
      " 0.84058869 0.84528518]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.84998274]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81113476 0.81602252 0.82043749 0.82517582 0.83025849 0.83564037\n",
      "  0.84058869 0.84528518]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010389969684183598\n",
      "Predicción post entrenamiento : [[0.8504083]]\n",
      "PERDIDAAAA despues: 0.0010117425117641687\n",
      "loss en el callback: 0.003188649658113718, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.81602252]\n",
      "  [0.82043749]\n",
      "  [0.82517582]\n",
      "  [0.83025849]\n",
      "  [0.83564037]\n",
      "  [0.84058869]\n",
      "  [0.84528518]\n",
      "  [0.84998274]]]\n",
      "ejemplar: [0.81602252 0.82043749 0.82517582 0.83025849 0.83564037 0.84058869\n",
      " 0.84528518 0.84998274]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8547914]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.81602252 0.82043749 0.82517582 0.83025849 0.83564037 0.84058869\n",
      "  0.84528518 0.84998274]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028086055535823107\n",
      "Predicción post entrenamiento : [[0.8557878]]\n",
      "PERDIDAAAA despues: 0.002703986130654812\n",
      "loss en el callback: 0.021412014961242676, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82043749]\n",
      "  [0.82517582]\n",
      "  [0.83025849]\n",
      "  [0.83564037]\n",
      "  [0.84058869]\n",
      "  [0.84528518]\n",
      "  [0.84998274]\n",
      "  [0.8547914 ]]]\n",
      "ejemplar: [0.82043749 0.82517582 0.83025849 0.83564037 0.84058869 0.84528518\n",
      " 0.84998274 0.8547914 ]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8601713]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82043749 0.82517582 0.83025849 0.83564037 0.84058869 0.84528518\n",
      "  0.84998274 0.8547914 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008647345239296556\n",
      "Predicción post entrenamiento : [[0.86016953]]\n",
      "PERDIDAAAA despues: 0.0008648397051729262\n",
      "loss en el callback: 5.481547304952983e-08, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.82517582]\n",
      "  [0.83025849]\n",
      "  [0.83564037]\n",
      "  [0.84058869]\n",
      "  [0.84528518]\n",
      "  [0.84998274]\n",
      "  [0.8547914 ]\n",
      "  [0.86017132]]]\n",
      "ejemplar: [0.82517582 0.83025849 0.83564037 0.84058869 0.84528518 0.84998274\n",
      " 0.8547914  0.86017132]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.86469835]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.82517582 0.83025849 0.83564037 0.84058869 0.84528518 0.84998274\n",
      "  0.8547914  0.86017132]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010315110557712615\n",
      "Predicción post entrenamiento : [[0.86485875]]\n",
      "PERDIDAAAA despues: 9.991876140702516e-05\n",
      "loss en el callback: 0.00047513004392385483, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.83025849]\n",
      "  [0.83564037]\n",
      "  [0.84058869]\n",
      "  [0.84528518]\n",
      "  [0.84998274]\n",
      "  [0.8547914 ]\n",
      "  [0.86017132]\n",
      "  [0.86469835]]]\n",
      "ejemplar: [0.83025849 0.83564037 0.84058869 0.84528518 0.84998274 0.8547914\n",
      " 0.86017132 0.86469835]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8694547]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.83025849 0.83564037 0.84058869 0.84528518 0.84998274 0.8547914\n",
      "  0.86017132 0.86469835]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019146978156641126\n",
      "Predicción post entrenamiento : [[0.86988693]]\n",
      "PERDIDAAAA despues: 0.0018770562019199133\n",
      "loss en el callback: 0.0035711689852178097, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.83564037]\n",
      "  [0.84058869]\n",
      "  [0.84528518]\n",
      "  [0.84998274]\n",
      "  [0.8547914 ]\n",
      "  [0.86017132]\n",
      "  [0.86469835]\n",
      "  [0.86945468]]]\n",
      "ejemplar: [0.83564037 0.84058869 0.84528518 0.84998274 0.8547914  0.86017132\n",
      " 0.86469835 0.86945468]\n",
      "y: 1.0\n",
      "Predicción : [[0.87444925]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.83564037 0.84058869 0.84528518 0.84998274 0.8547914  0.86017132\n",
      "  0.86469835 0.86945468]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015762990340590477\n",
      "Predicción post entrenamiento : [[0.8749834]]\n",
      "PERDIDAAAA despues: 0.015629157423973083\n",
      "loss en el callback: 0.004799334332346916, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.84058869]\n",
      "  [0.84528518]\n",
      "  [0.84998274]\n",
      "  [0.8547914 ]\n",
      "  [0.86017132]\n",
      "  [0.86469835]\n",
      "  [0.86945468]\n",
      "  [0.87444925]]]\n",
      "ejemplar: [0.84058869 0.84528518 0.84998274 0.8547914  0.86017132 0.86469835\n",
      " 0.86945468 0.87444925]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8794102]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.84058869 0.84528518 0.84998274 0.8547914  0.86017132 0.86469835\n",
      "  0.86945468 0.87444925]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008307200856506824\n",
      "Predicción post entrenamiento : [[0.88000447]]\n",
      "PERDIDAAAA despues: 0.008199227973818779\n",
      "loss en el callback: 0.006679979152977467, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.84528518]\n",
      "  [0.84998274]\n",
      "  [0.8547914 ]\n",
      "  [0.86017132]\n",
      "  [0.86469835]\n",
      "  [0.86945468]\n",
      "  [0.87444925]\n",
      "  [0.87941021]]]\n",
      "ejemplar: [0.84528518 0.84998274 0.8547914  0.86017132 0.86469835 0.86945468\n",
      " 0.87444925 0.87941021]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.88440555]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.84528518 0.84998274 0.8547914  0.86017132 0.86469835 0.86945468\n",
      "  0.87444925 0.87941021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.933548628585413e-05\n",
      "Predicción post entrenamiento : [[0.88480425]]\n",
      "PERDIDAAAA despues: 1.5988145605660975e-05\n",
      "loss en el callback: 0.0032373210415244102, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.84998274]\n",
      "  [0.8547914 ]\n",
      "  [0.86017132]\n",
      "  [0.86469835]\n",
      "  [0.86945468]\n",
      "  [0.87444925]\n",
      "  [0.87941021]\n",
      "  [0.88440555]]]\n",
      "ejemplar: [0.84998274 0.8547914  0.86017132 0.86469835 0.86945468 0.87444925\n",
      " 0.87941021 0.88440555]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8892548]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.84998274 0.8547914  0.86017132 0.86469835 0.86945468 0.87444925\n",
      "  0.87941021 0.88440555]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012770139437634498\n",
      "Predicción post entrenamiento : [[0.8889322]]\n",
      "PERDIDAAAA despues: 0.00012051481462549418\n",
      "loss en el callback: 0.001970818033441901, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.8547914 ]\n",
      "  [0.86017132]\n",
      "  [0.86469835]\n",
      "  [0.86945468]\n",
      "  [0.87444925]\n",
      "  [0.87941021]\n",
      "  [0.88440555]\n",
      "  [0.88925481]]]\n",
      "ejemplar: [0.8547914  0.86017132 0.86469835 0.86945468 0.87444925 0.87941021\n",
      " 0.88440555 0.88925481]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8934397]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.8547914  0.86017132 0.86469835 0.86945468 0.87444925 0.87941021\n",
      "  0.88440555 0.88925481]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001984161091968417\n",
      "Predicción post entrenamiento : [[0.8938151]]\n",
      "PERDIDAAAA despues: 0.0020177445840090513\n",
      "loss en el callback: 0.003398523898795247, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.86017132]\n",
      "  [0.86469835]\n",
      "  [0.86945468]\n",
      "  [0.87444925]\n",
      "  [0.87941021]\n",
      "  [0.88440555]\n",
      "  [0.88925481]\n",
      "  [0.89343971]]]\n",
      "ejemplar: [0.86017132 0.86469835 0.86945468 0.87444925 0.87941021 0.88440555\n",
      " 0.88925481 0.89343971]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8983516]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.86017132 0.86469835 0.86945468 0.87444925 0.87941021 0.88440555\n",
      "  0.88925481 0.89343971]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00411892170086503\n",
      "Predicción post entrenamiento : [[0.8982178]]\n",
      "PERDIDAAAA despues: 0.004101763479411602\n",
      "loss en el callback: 0.00036319103674031794, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.86469835]\n",
      "  [0.86945468]\n",
      "  [0.87444925]\n",
      "  [0.87941021]\n",
      "  [0.88440555]\n",
      "  [0.88925481]\n",
      "  [0.89343971]\n",
      "  [0.89835161]]]\n",
      "ejemplar: [0.86469835 0.86945468 0.87444925 0.87941021 0.88440555 0.88925481\n",
      " 0.89343971 0.89835161]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.902606]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.86469835 0.86945468 0.87444925 0.87941021 0.88440555 0.88925481\n",
      "  0.89343971 0.89835161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022573047317564487\n",
      "Predicción post entrenamiento : [[0.9020133]]\n",
      "PERDIDAAAA despues: 0.0022013355046510696\n",
      "loss en el callback: 0.006445807870477438, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.86945468]\n",
      "  [0.87444925]\n",
      "  [0.87941021]\n",
      "  [0.88440555]\n",
      "  [0.88925481]\n",
      "  [0.89343971]\n",
      "  [0.89835161]\n",
      "  [0.90260601]]]\n",
      "ejemplar: [0.86945468 0.87444925 0.87941021 0.88440555 0.88925481 0.89343971\n",
      " 0.89835161 0.90260601]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.90648323]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.86945468 0.87444925 0.87941021 0.88440555 0.88925481 0.89343971\n",
      "  0.89835161 0.90260601]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009760037646628916\n",
      "Predicción post entrenamiento : [[0.9057567]]\n",
      "PERDIDAAAA despues: 0.0009311370668001473\n",
      "loss en el callback: 0.009369057603180408, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.87444925]\n",
      "  [0.87941021]\n",
      "  [0.88440555]\n",
      "  [0.88925481]\n",
      "  [0.89343971]\n",
      "  [0.89835161]\n",
      "  [0.90260601]\n",
      "  [0.90648323]]]\n",
      "ejemplar: [0.87444925 0.87941021 0.88440555 0.88925481 0.89343971 0.89835161\n",
      " 0.90260601 0.90648323]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.91023594]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.87444925 0.87941021 0.88440555 0.88925481 0.89343971 0.89835161\n",
      "  0.90260601 0.90648323]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028306401800364256\n",
      "Predicción post entrenamiento : [[0.91024]]\n",
      "PERDIDAAAA despues: 0.002831071615219116\n",
      "loss en el callback: 3.9512610783276614e-07, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.87941021]\n",
      "  [0.88440555]\n",
      "  [0.88925481]\n",
      "  [0.89343971]\n",
      "  [0.89835161]\n",
      "  [0.90260601]\n",
      "  [0.90648323]\n",
      "  [0.91023594]]]\n",
      "ejemplar: [0.87941021 0.88440555 0.88925481 0.89343971 0.89835161 0.90260601\n",
      " 0.90648323 0.91023594]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9146353]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.87941021 0.88440555 0.88925481 0.89343971 0.89835161 0.90260601\n",
      "  0.90648323 0.91023594]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004170210100710392\n",
      "Predicción post entrenamiento : [[0.9148217]]\n",
      "PERDIDAAAA despues: 0.004194316919893026\n",
      "loss en el callback: 0.0007948316633701324, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.88440555]\n",
      "  [0.88925481]\n",
      "  [0.89343971]\n",
      "  [0.89835161]\n",
      "  [0.90260601]\n",
      "  [0.90648323]\n",
      "  [0.91023594]\n",
      "  [0.9146353 ]]]\n",
      "ejemplar: [0.88440555 0.88925481 0.89343971 0.89835161 0.90260601 0.90648323\n",
      " 0.91023594 0.9146353 ]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9191059]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.88440555 0.88925481 0.89343971 0.89835161 0.90260601 0.90648323\n",
      "  0.91023594 0.9146353 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005838378332555294\n",
      "Predicción post entrenamiento : [[0.9187363]]\n",
      "PERDIDAAAA despues: 0.005782031919807196\n",
      "loss en el callback: 0.0027412946801632643, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.88925481]\n",
      "  [0.89343971]\n",
      "  [0.89835161]\n",
      "  [0.90260601]\n",
      "  [0.90648323]\n",
      "  [0.91023594]\n",
      "  [0.9146353 ]\n",
      "  [0.91910589]]]\n",
      "ejemplar: [0.88925481 0.89343971 0.89835161 0.90260601 0.90648323 0.91023594\n",
      " 0.9146353  0.91910589]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9228614]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.88925481 0.89343971 0.89835161 0.90260601 0.90648323 0.91023594\n",
      "  0.9146353  0.91910589]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009984918870031834\n",
      "Predicción post entrenamiento : [[0.9211723]]\n",
      "PERDIDAAAA despues: 0.009650210849940777\n",
      "loss en el callback: 0.04690833017230034, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.89343971]\n",
      "  [0.89835161]\n",
      "  [0.90260601]\n",
      "  [0.90648323]\n",
      "  [0.91023594]\n",
      "  [0.9146353 ]\n",
      "  [0.91910589]\n",
      "  [0.9228614 ]]]\n",
      "ejemplar: [0.89343971 0.89835161 0.90260601 0.90648323 0.91023594 0.9146353\n",
      " 0.91910589 0.9228614 ]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.92513996]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.89343971 0.89835161 0.90260601 0.90648323 0.91023594 0.9146353\n",
      "  0.91910589 0.9228614 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022690581157803535\n",
      "Predicción post entrenamiento : [[0.9241226]]\n",
      "PERDIDAAAA despues: 0.022385109215974808\n",
      "loss en el callback: 0.02087526023387909, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.89835161]\n",
      "  [0.90260601]\n",
      "  [0.90648323]\n",
      "  [0.91023594]\n",
      "  [0.9146353 ]\n",
      "  [0.91910589]\n",
      "  [0.9228614 ]\n",
      "  [0.92513996]]]\n",
      "ejemplar: [0.89835161 0.90260601 0.90648323 0.91023594 0.9146353  0.91910589\n",
      " 0.9228614  0.92513996]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9280918]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.89835161 0.90260601 0.90648323 0.91023594 0.9146353  0.91910589\n",
      "  0.9228614  0.92513996]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02070711739361286\n",
      "Predicción post entrenamiento : [[0.92663544]]\n",
      "PERDIDAAAA despues: 0.02029009349644184\n",
      "loss en el callback: 0.039332158863544464, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.90260601]\n",
      "  [0.90648323]\n",
      "  [0.91023594]\n",
      "  [0.9146353 ]\n",
      "  [0.91910589]\n",
      "  [0.9228614 ]\n",
      "  [0.92513996]\n",
      "  [0.92809182]]]\n",
      "ejemplar: [0.90260601 0.90648323 0.91023594 0.9146353  0.91910589 0.9228614\n",
      " 0.92513996 0.92809182]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.93035406]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.90260601 0.90648323 0.91023594 0.9146353  0.91910589 0.9228614\n",
      "  0.92513996 0.92809182]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004985736683011055\n",
      "Predicción post entrenamiento : [[0.9288721]]\n",
      "PERDIDAAAA despues: 0.00477865245193243\n",
      "loss en el callback: 0.038252703845500946, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.90648323]\n",
      "  [0.91023594]\n",
      "  [0.9146353 ]\n",
      "  [0.91910589]\n",
      "  [0.9228614 ]\n",
      "  [0.92513996]\n",
      "  [0.92809182]\n",
      "  [0.93035406]]]\n",
      "ejemplar: [0.90648323 0.91023594 0.9146353  0.91910589 0.9228614  0.92513996\n",
      " 0.92809182 0.93035406]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9324671]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.90648323 0.91023594 0.9146353  0.91910589 0.9228614  0.92513996\n",
      "  0.92809182 0.93035406]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006106961984187365\n",
      "Predicción post entrenamiento : [[0.9315108]]\n",
      "PERDIDAAAA despues: 0.005958412773907185\n",
      "loss en el callback: 0.01939409226179123, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.91023594]\n",
      "  [0.9146353 ]\n",
      "  [0.91910589]\n",
      "  [0.9228614 ]\n",
      "  [0.92513996]\n",
      "  [0.92809182]\n",
      "  [0.93035406]\n",
      "  [0.9324671 ]]]\n",
      "ejemplar: [0.91023594 0.9146353  0.91910589 0.9228614  0.92513996 0.92809182\n",
      " 0.93035406 0.9324671 ]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9350364]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.91023594 0.9146353  0.91910589 0.9228614  0.92513996 0.92809182\n",
      "  0.93035406 0.9324671 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009633718058466911\n",
      "Predicción post entrenamiento : [[0.93496275]]\n",
      "PERDIDAAAA despues: 0.009619261138141155\n",
      "loss en el callback: 0.00013584672706201673, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.9146353 ]\n",
      "  [0.91910589]\n",
      "  [0.9228614 ]\n",
      "  [0.92513996]\n",
      "  [0.92809182]\n",
      "  [0.93035406]\n",
      "  [0.9324671 ]\n",
      "  [0.93503642]]]\n",
      "ejemplar: [0.9146353  0.91910589 0.9228614  0.92513996 0.92809182 0.93035406\n",
      " 0.9324671  0.93503642]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9383975]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.9146353  0.91910589 0.9228614  0.92513996 0.92809182 0.93035406\n",
      "  0.9324671  0.93503642]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011769353412091732\n",
      "Predicción post entrenamiento : [[0.9379693]]\n",
      "PERDIDAAAA despues: 0.011676629073917866\n",
      "loss en el callback: 0.004396374337375164, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.91910589]\n",
      "  [0.9228614 ]\n",
      "  [0.92513996]\n",
      "  [0.92809182]\n",
      "  [0.93035406]\n",
      "  [0.9324671 ]\n",
      "  [0.93503642]\n",
      "  [0.93839753]]]\n",
      "ejemplar: [0.91910589 0.9228614  0.92513996 0.92809182 0.93035406 0.9324671\n",
      " 0.93503642 0.93839753]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9410549]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.91910589 0.9228614  0.92513996 0.92809182 0.93035406 0.9324671\n",
      "  0.93503642 0.93839753]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028946439269930124\n",
      "Predicción post entrenamiento : [[0.94057006]]\n",
      "PERDIDAAAA despues: 0.0028427098877727985\n",
      "loss en el callback: 0.005081832874566317, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.9228614 ]\n",
      "  [0.92513996]\n",
      "  [0.92809182]\n",
      "  [0.93035406]\n",
      "  [0.9324671 ]\n",
      "  [0.93503642]\n",
      "  [0.93839753]\n",
      "  [0.94105488]]]\n",
      "ejemplar: [0.9228614  0.92513996 0.92809182 0.93035406 0.9324671  0.93503642\n",
      " 0.93839753 0.94105488]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.94319826]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.9228614  0.92513996 0.92809182 0.93035406 0.9324671  0.93503642\n",
      "  0.93839753 0.94105488]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006964562460780144\n",
      "Predicción post entrenamiento : [[0.9425015]]\n",
      "PERDIDAAAA despues: 0.0068487501703202724\n",
      "loss en el callback: 0.011075642891228199, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.92513996]\n",
      "  [0.92809182]\n",
      "  [0.93035406]\n",
      "  [0.9324671 ]\n",
      "  [0.93503642]\n",
      "  [0.93839753]\n",
      "  [0.94105488]\n",
      "  [0.94319826]]]\n",
      "ejemplar: [0.92513996 0.92809182 0.93035406 0.9324671  0.93503642 0.93839753\n",
      " 0.94105488 0.94319826]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.94480705]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.92513996 0.92809182 0.93035406 0.9324671  0.93503642 0.93839753\n",
      "  0.94105488 0.94319826]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011069145053625107\n",
      "Predicción post entrenamiento : [[0.9423961]]\n",
      "PERDIDAAAA despues: 0.010567646473646164\n",
      "loss en el callback: 0.09805545210838318, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.92809182]\n",
      "  [0.93035406]\n",
      "  [0.9324671 ]\n",
      "  [0.93503642]\n",
      "  [0.93839753]\n",
      "  [0.94105488]\n",
      "  [0.94319826]\n",
      "  [0.94480705]]]\n",
      "ejemplar: [0.92809182 0.93035406 0.9324671  0.93503642 0.93839753 0.94105488\n",
      " 0.94319826 0.94480705]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9447751]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.92809182 0.93035406 0.9324671  0.93503642 0.93839753 0.94105488\n",
      "  0.94319826 0.94480705]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025911467149853706\n",
      "Predicción post entrenamiento : [[0.94536746]]\n",
      "PERDIDAAAA despues: 0.026102518662810326\n",
      "loss en el callback: 0.013779161497950554, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.93035406]\n",
      "  [0.9324671 ]\n",
      "  [0.93503642]\n",
      "  [0.93839753]\n",
      "  [0.94105488]\n",
      "  [0.94319826]\n",
      "  [0.94480705]\n",
      "  [0.9447751 ]]]\n",
      "ejemplar: [0.93035406 0.9324671  0.93503642 0.93839753 0.94105488 0.94319826\n",
      " 0.94480705 0.9447751 ]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.94760615]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.93035406 0.9324671  0.93503642 0.93839753 0.94105488 0.94319826\n",
      "  0.94480705 0.9447751 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01672331430017948\n",
      "Predicción post entrenamiento : [[0.94709086]]\n",
      "PERDIDAAAA despues: 0.016590308398008347\n",
      "loss en el callback: 0.006602436304092407, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.9324671 ]\n",
      "  [0.93503642]\n",
      "  [0.93839753]\n",
      "  [0.94105488]\n",
      "  [0.94319826]\n",
      "  [0.94480705]\n",
      "  [0.9447751 ]\n",
      "  [0.94760615]]]\n",
      "ejemplar: [0.9324671  0.93503642 0.93839753 0.94105488 0.94319826 0.94480705\n",
      " 0.9447751  0.94760615]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.94935477]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.9324671  0.93503642 0.93839753 0.94105488 0.94319826 0.94480705\n",
      "  0.9447751  0.94760615]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025023628026247025\n",
      "Predicción post entrenamiento : [[0.948834]]\n",
      "PERDIDAAAA despues: 0.024859139695763588\n",
      "loss en el callback: 0.007435784209519625, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.93503642]\n",
      "  [0.93839753]\n",
      "  [0.94105488]\n",
      "  [0.94319826]\n",
      "  [0.94480705]\n",
      "  [0.9447751 ]\n",
      "  [0.94760615]\n",
      "  [0.94935477]]]\n",
      "ejemplar: [0.93503642 0.93839753 0.94105488 0.94319826 0.94480705 0.9447751\n",
      " 0.94760615 0.94935477]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9511453]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.93503642 0.93839753 0.94105488 0.94319826 0.94480705 0.9447751\n",
      "  0.94760615 0.94935477]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036323536187410355\n",
      "Predicción post entrenamiento : [[0.9501349]]\n",
      "PERDIDAAAA despues: 0.03593941032886505\n",
      "loss en el callback: 0.02415643446147442, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.93839753]\n",
      "  [0.94105488]\n",
      "  [0.94319826]\n",
      "  [0.94480705]\n",
      "  [0.9447751 ]\n",
      "  [0.94760615]\n",
      "  [0.94935477]\n",
      "  [0.95114529]]]\n",
      "ejemplar: [0.93839753 0.94105488 0.94319826 0.94480705 0.9447751  0.94760615\n",
      " 0.94935477 0.95114529]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9523281]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.93839753 0.94105488 0.94319826 0.94480705 0.9447751  0.94760615\n",
      "  0.94935477 0.95114529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02584841102361679\n",
      "Predicción post entrenamiento : [[0.95116407]]\n",
      "PERDIDAAAA despues: 0.025475475937128067\n",
      "loss en el callback: 0.03031918965280056, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.94105488]\n",
      "  [0.94319826]\n",
      "  [0.94480705]\n",
      "  [0.9447751 ]\n",
      "  [0.94760615]\n",
      "  [0.94935477]\n",
      "  [0.95114529]\n",
      "  [0.95232809]]]\n",
      "ejemplar: [0.94105488 0.94319826 0.94480705 0.9447751  0.94760615 0.94935477\n",
      " 0.95114529 0.95232809]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.95294595]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.94105488 0.94319826 0.94480705 0.9447751  0.94760615 0.94935477\n",
      "  0.95114529 0.95232809]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03394867479801178\n",
      "Predicción post entrenamiento : [[0.9511988]]\n",
      "PERDIDAAAA despues: 0.03330790624022484\n",
      "loss en el callback: 0.06507893651723862, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.94319826]\n",
      "  [0.94480705]\n",
      "  [0.9447751 ]\n",
      "  [0.94760615]\n",
      "  [0.94935477]\n",
      "  [0.95114529]\n",
      "  [0.95232809]\n",
      "  [0.95294595]]]\n",
      "ejemplar: [0.94319826 0.94480705 0.9447751  0.94760615 0.94935477 0.95114529\n",
      " 0.95232809 0.95294595]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.95269966]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.94319826 0.94480705 0.9447751  0.94760615 0.94935477 0.95114529\n",
      "  0.95232809 0.95294595]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033857978880405426\n",
      "Predicción post entrenamiento : [[0.95247763]]\n",
      "PERDIDAAAA despues: 0.03377632051706314\n",
      "loss en el callback: 0.0015292242169380188, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.94480705]\n",
      "  [0.9447751 ]\n",
      "  [0.94760615]\n",
      "  [0.94935477]\n",
      "  [0.95114529]\n",
      "  [0.95232809]\n",
      "  [0.95294595]\n",
      "  [0.95269966]]]\n",
      "ejemplar: [0.94480705 0.9447751  0.94760615 0.94935477 0.95114529 0.95232809\n",
      " 0.95294595 0.95269966]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9537912]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.94480705 0.9447751  0.94760615 0.94935477 0.95114529 0.95232809\n",
      "  0.95294595 0.95269966]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023986591026186943\n",
      "Predicción post entrenamiento : [[0.9512094]]\n",
      "PERDIDAAAA despues: 0.023193547502160072\n",
      "loss en el callback: 0.1203702837228775, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.9447751 ]\n",
      "  [0.94760615]\n",
      "  [0.94935477]\n",
      "  [0.95114529]\n",
      "  [0.95232809]\n",
      "  [0.95294595]\n",
      "  [0.95269966]\n",
      "  [0.9537912 ]]]\n",
      "ejemplar: [0.9447751  0.94760615 0.94935477 0.95114529 0.95232809 0.95294595\n",
      " 0.95269966 0.9537912 ]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.95244974]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.9447751  0.94760615 0.94935477 0.95114529 0.95232809 0.95294595\n",
      "  0.95269966 0.9537912 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026388652622699738\n",
      "Predicción post entrenamiento : [[0.9517696]]\n",
      "PERDIDAAAA despues: 0.026168139651417732\n",
      "loss en el callback: 0.013103163801133633, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.94760615]\n",
      "  [0.94935477]\n",
      "  [0.95114529]\n",
      "  [0.95232809]\n",
      "  [0.95294595]\n",
      "  [0.95269966]\n",
      "  [0.9537912 ]\n",
      "  [0.95244974]]]\n",
      "ejemplar: [0.94760615 0.94935477 0.95114529 0.95232809 0.95294595 0.95269966\n",
      " 0.9537912  0.95244974]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9533908]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.94760615 0.94935477 0.95114529 0.95232809 0.95294595 0.95269966\n",
      "  0.9537912  0.95244974]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03733409196138382\n",
      "Predicción post entrenamiento : [[0.9517751]]\n",
      "PERDIDAAAA despues: 0.03671232983469963\n",
      "loss en el callback: 0.06486562639474869, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.94935477]\n",
      "  [0.95114529]\n",
      "  [0.95232809]\n",
      "  [0.95294595]\n",
      "  [0.95269966]\n",
      "  [0.9537912 ]\n",
      "  [0.95244974]\n",
      "  [0.95339078]]]\n",
      "ejemplar: [0.94935477 0.95114529 0.95232809 0.95294595 0.95269966 0.9537912\n",
      " 0.95244974 0.95339078]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.95290416]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.94935477 0.95114529 0.95232809 0.95294595 0.95269966 0.9537912\n",
      "  0.95244974 0.95339078]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07156207412481308\n",
      "Predicción post entrenamiento : [[0.95127845]]\n",
      "PERDIDAAAA despues: 0.0706949234008789\n",
      "loss en el callback: 0.07248546928167343, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.95114529]\n",
      "  [0.95232809]\n",
      "  [0.95294595]\n",
      "  [0.95269966]\n",
      "  [0.9537912 ]\n",
      "  [0.95244974]\n",
      "  [0.95339078]\n",
      "  [0.95290416]]]\n",
      "ejemplar: [0.95114529 0.95232809 0.95294595 0.95269966 0.9537912  0.95244974\n",
      " 0.95339078 0.95290416]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9521215]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.95114529 0.95232809 0.95294595 0.95269966 0.9537912  0.95244974\n",
      "  0.95339078 0.95290416]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12036024034023285\n",
      "Predicción post entrenamiento : [[0.95016223]]\n",
      "PERDIDAAAA despues: 0.11900462210178375\n",
      "loss en el callback: 0.09691012650728226, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.95232809]\n",
      "  [0.95294595]\n",
      "  [0.95269966]\n",
      "  [0.9537912 ]\n",
      "  [0.95244974]\n",
      "  [0.95339078]\n",
      "  [0.95290416]\n",
      "  [0.9521215 ]]]\n",
      "ejemplar: [0.95232809 0.95294595 0.95269966 0.9537912  0.95244974 0.95339078\n",
      " 0.95290416 0.9521215 ]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9506186]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.95232809 0.95294595 0.95269966 0.9537912  0.95244974 0.95339078\n",
      "  0.95290416 0.9521215 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08165880292654037\n",
      "Predicción post entrenamiento : [[0.94951886]]\n",
      "PERDIDAAAA despues: 0.08103147149085999\n",
      "loss en el callback: 0.03808936849236488, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.95294595]\n",
      "  [0.95269966]\n",
      "  [0.9537912 ]\n",
      "  [0.95244974]\n",
      "  [0.95339078]\n",
      "  [0.95290416]\n",
      "  [0.9521215 ]\n",
      "  [0.95061862]]]\n",
      "ejemplar: [0.95294595 0.95269966 0.9537912  0.95244974 0.95339078 0.95290416\n",
      " 0.9521215  0.95061862]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9496758]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.95294595 0.95269966 0.9537912  0.95244974 0.95339078 0.95290416\n",
      "  0.9521215  0.95061862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05847237631678581\n",
      "Predicción post entrenamiento : [[0.9483828]]\n",
      "PERDIDAAAA despues: 0.0578487254679203\n",
      "loss en el callback: 0.05064735561609268, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.95269966]\n",
      "  [0.9537912 ]\n",
      "  [0.95244974]\n",
      "  [0.95339078]\n",
      "  [0.95290416]\n",
      "  [0.9521215 ]\n",
      "  [0.95061862]\n",
      "  [0.9496758 ]]]\n",
      "ejemplar: [0.95269966 0.9537912  0.95244974 0.95339078 0.95290416 0.9521215\n",
      " 0.95061862 0.9496758 ]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9483317]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.95269966 0.9537912  0.95244974 0.95339078 0.95290416 0.9521215\n",
      "  0.95061862 0.9496758 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08035701513290405\n",
      "Predicción post entrenamiento : [[0.94726276]]\n",
      "PERDIDAAAA despues: 0.0797521248459816\n",
      "loss en el callback: 0.0367254875600338, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.9537912 ]\n",
      "  [0.95244974]\n",
      "  [0.95339078]\n",
      "  [0.95290416]\n",
      "  [0.9521215 ]\n",
      "  [0.95061862]\n",
      "  [0.9496758 ]\n",
      "  [0.94833171]]]\n",
      "ejemplar: [0.9537912  0.95244974 0.95339078 0.95290416 0.9521215  0.95061862\n",
      " 0.9496758  0.94833171]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9472]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.9537912  0.95244974 0.95339078 0.95290416 0.9521215  0.95061862\n",
      "  0.9496758  0.94833171]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05562419816851616\n",
      "Predicción post entrenamiento : [[0.9437416]]\n",
      "PERDIDAAAA despues: 0.05400485545396805\n",
      "loss en el callback: 0.22771549224853516, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.95244974]\n",
      "  [0.95339078]\n",
      "  [0.95290416]\n",
      "  [0.9521215 ]\n",
      "  [0.95061862]\n",
      "  [0.9496758 ]\n",
      "  [0.94833171]\n",
      "  [0.9472    ]]]\n",
      "ejemplar: [0.95244974 0.95339078 0.95290416 0.9521215  0.95061862 0.9496758\n",
      " 0.94833171 0.9472    ]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.94322073]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.95244974 0.95339078 0.95290416 0.9521215  0.95061862 0.9496758\n",
      "  0.94833171 0.9472    ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07073677331209183\n",
      "Predicción post entrenamiento : [[0.9422619]]\n",
      "PERDIDAAAA despues: 0.07022764533758163\n",
      "loss en el callback: 0.02988032065331936, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.95339078]\n",
      "  [0.95290416]\n",
      "  [0.9521215 ]\n",
      "  [0.95061862]\n",
      "  [0.9496758 ]\n",
      "  [0.94833171]\n",
      "  [0.9472    ]\n",
      "  [0.94322073]]]\n",
      "ejemplar: [0.95339078 0.95290416 0.9521215  0.95061862 0.9496758  0.94833171\n",
      " 0.9472     0.94322073]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9419075]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.95339078 0.95290416 0.9521215  0.95061862 0.9496758  0.94833171\n",
      "  0.9472     0.94322073]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03232796490192413\n",
      "Predicción post entrenamiento : [[0.9407305]]\n",
      "PERDIDAAAA despues: 0.03190609812736511\n",
      "loss en el callback: 0.03617414832115173, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.95290416]\n",
      "  [0.9521215 ]\n",
      "  [0.95061862]\n",
      "  [0.9496758 ]\n",
      "  [0.94833171]\n",
      "  [0.9472    ]\n",
      "  [0.94322073]\n",
      "  [0.94190753]]]\n",
      "ejemplar: [0.95290416 0.9521215  0.95061862 0.9496758  0.94833171 0.9472\n",
      " 0.94322073 0.94190753]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9398206]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.95290416 0.9521215  0.95061862 0.9496758  0.94833171 0.9472\n",
      "  0.94322073 0.94190753]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017627621069550514\n",
      "Predicción post entrenamiento : [[0.9385729]]\n",
      "PERDIDAAAA despues: 0.017297863960266113\n",
      "loss en el callback: 0.04149968922138214, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.9521215 ]\n",
      "  [0.95061862]\n",
      "  [0.9496758 ]\n",
      "  [0.94833171]\n",
      "  [0.9472    ]\n",
      "  [0.94322073]\n",
      "  [0.94190753]\n",
      "  [0.93982059]]]\n",
      "ejemplar: [0.9521215  0.95061862 0.9496758  0.94833171 0.9472     0.94322073\n",
      " 0.94190753 0.93982059]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9374148]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.9521215  0.95061862 0.9496758  0.94833171 0.9472     0.94322073\n",
      "  0.94190753 0.93982059]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014939413405954838\n",
      "Predicción post entrenamiento : [[0.93671113]]\n",
      "PERDIDAAAA despues: 0.014767888933420181\n",
      "loss en el callback: 0.015040851198136806, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.95061862]\n",
      "  [0.9496758 ]\n",
      "  [0.94833171]\n",
      "  [0.9472    ]\n",
      "  [0.94322073]\n",
      "  [0.94190753]\n",
      "  [0.93982059]\n",
      "  [0.93741482]]]\n",
      "ejemplar: [0.95061862 0.9496758  0.94833171 0.9472     0.94322073 0.94190753\n",
      " 0.93982059 0.93741482]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.935322]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.95061862 0.9496758  0.94833171 0.9472     0.94322073 0.94190753\n",
      "  0.93982059 0.93741482]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000845884089358151\n",
      "Predicción post entrenamiento : [[0.93497777]]\n",
      "PERDIDAAAA despues: 0.0008259800961241126\n",
      "loss en el callback: 0.0032912425231188536, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.9496758 ]\n",
      "  [0.94833171]\n",
      "  [0.9472    ]\n",
      "  [0.94322073]\n",
      "  [0.94190753]\n",
      "  [0.93982059]\n",
      "  [0.93741482]\n",
      "  [0.93532199]]]\n",
      "ejemplar: [0.9496758  0.94833171 0.9472     0.94322073 0.94190753 0.93982059\n",
      " 0.93741482 0.93532199]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9335118]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.9496758  0.94833171 0.9472     0.94322073 0.94190753 0.93982059\n",
      "  0.93741482 0.93532199]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006861119181849062\n",
      "Predicción post entrenamiento : [[0.9339586]]\n",
      "PERDIDAAAA despues: 0.0006629049894399941\n",
      "loss en el callback: 0.007143838796764612, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.94833171]\n",
      "  [0.9472    ]\n",
      "  [0.94322073]\n",
      "  [0.94190753]\n",
      "  [0.93982059]\n",
      "  [0.93741482]\n",
      "  [0.93532199]\n",
      "  [0.93351179]]]\n",
      "ejemplar: [0.94833171 0.9472     0.94322073 0.94190753 0.93982059 0.93741482\n",
      " 0.93532199 0.93351179]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9322117]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.94833171 0.9472     0.94322073 0.94190753 0.93982059 0.93741482\n",
      "  0.93532199 0.93351179]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010331837693229318\n",
      "Predicción post entrenamiento : [[0.9321279]]\n",
      "PERDIDAAAA despues: 0.0010385782225057483\n",
      "loss en el callback: 0.00021577456209342927, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.9472    ]\n",
      "  [0.94322073]\n",
      "  [0.94190753]\n",
      "  [0.93982059]\n",
      "  [0.93741482]\n",
      "  [0.93532199]\n",
      "  [0.93351179]\n",
      "  [0.9322117 ]]]\n",
      "ejemplar: [0.9472     0.94322073 0.94190753 0.93982059 0.93741482 0.93532199\n",
      " 0.93351179 0.9322117 ]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9301746]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.9472     0.94322073 0.94190753 0.93982059 0.93741482 0.93532199\n",
      "  0.93351179 0.9322117 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017763428622856736\n",
      "Predicción post entrenamiento : [[0.9294654]]\n",
      "PERDIDAAAA despues: 0.0017170669743791223\n",
      "loss en el callback: 0.015047678723931313, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.94322073]\n",
      "  [0.94190753]\n",
      "  [0.93982059]\n",
      "  [0.93741482]\n",
      "  [0.93532199]\n",
      "  [0.93351179]\n",
      "  [0.9322117 ]\n",
      "  [0.93017459]]]\n",
      "ejemplar: [0.94322073 0.94190753 0.93982059 0.93741482 0.93532199 0.93351179\n",
      " 0.9322117  0.93017459]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9272193]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.94322073 0.94190753 0.93982059 0.93741482 0.93532199 0.93351179\n",
      "  0.9322117  0.93017459]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011931514600291848\n",
      "Predicción post entrenamiento : [[0.9278879]]\n",
      "PERDIDAAAA despues: 0.0012397911632433534\n",
      "loss en el callback: 0.01900491863489151, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.94190753]\n",
      "  [0.93982059]\n",
      "  [0.93741482]\n",
      "  [0.93532199]\n",
      "  [0.93351179]\n",
      "  [0.9322117 ]\n",
      "  [0.93017459]\n",
      "  [0.92721927]]]\n",
      "ejemplar: [0.94190753 0.93982059 0.93741482 0.93532199 0.93351179 0.9322117\n",
      " 0.93017459 0.92721927]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9261802]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.94190753 0.93982059 0.93741482 0.93532199 0.93351179 0.9322117\n",
      "  0.93017459 0.92721927]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002594680991023779\n",
      "Predicción post entrenamiento : [[0.92561907]]\n",
      "PERDIDAAAA despues: 0.002537831198424101\n",
      "loss en el callback: 0.009549145586788654, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.93982059]\n",
      "  [0.93741482]\n",
      "  [0.93532199]\n",
      "  [0.93351179]\n",
      "  [0.9322117 ]\n",
      "  [0.93017459]\n",
      "  [0.92721927]\n",
      "  [0.92618018]]]\n",
      "ejemplar: [0.93982059 0.93741482 0.93532199 0.93351179 0.9322117  0.93017459\n",
      " 0.92721927 0.92618018]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9237276]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.93982059 0.93741482 0.93532199 0.93351179 0.9322117  0.93017459\n",
      "  0.92721927 0.92618018]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005313618574291468\n",
      "Predicción post entrenamiento : [[0.9240488]]\n",
      "PERDIDAAAA despues: 0.0053605507127940655\n",
      "loss en el callback: 0.0043062432669103146, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.93741482]\n",
      "  [0.93532199]\n",
      "  [0.93351179]\n",
      "  [0.9322117 ]\n",
      "  [0.93017459]\n",
      "  [0.92721927]\n",
      "  [0.92618018]\n",
      "  [0.92372757]]]\n",
      "ejemplar: [0.93741482 0.93532199 0.93351179 0.9322117  0.93017459 0.92721927\n",
      " 0.92618018 0.92372757]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.92218184]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.93741482 0.93532199 0.93351179 0.9322117  0.93017459 0.92721927\n",
      "  0.92618018 0.92372757]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005370846018195152\n",
      "Predicción post entrenamiento : [[0.92250013]]\n",
      "PERDIDAAAA despues: 0.005417599808424711\n",
      "loss en el callback: 0.004572195466607809, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.93532199]\n",
      "  [0.93351179]\n",
      "  [0.9322117 ]\n",
      "  [0.93017459]\n",
      "  [0.92721927]\n",
      "  [0.92618018]\n",
      "  [0.92372757]\n",
      "  [0.92218184]]]\n",
      "ejemplar: [0.93532199 0.93351179 0.9322117  0.93017459 0.92721927 0.92618018\n",
      " 0.92372757 0.92218184]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.920762]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.93532199 0.93351179 0.9322117  0.93017459 0.92721927 0.92618018\n",
      "  0.92372757 0.92218184]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017351940041407943\n",
      "Predicción post entrenamiento : [[0.92106503]]\n",
      "PERDIDAAAA despues: 0.0017100400291383266\n",
      "loss en el callback: 0.0033949734643101692, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.93351179]\n",
      "  [0.9322117 ]\n",
      "  [0.93017459]\n",
      "  [0.92721927]\n",
      "  [0.92618018]\n",
      "  [0.92372757]\n",
      "  [0.92218184]\n",
      "  [0.920762  ]]]\n",
      "ejemplar: [0.93351179 0.9322117  0.93017459 0.92721927 0.92618018 0.92372757\n",
      " 0.92218184 0.920762  ]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9193842]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.93351179 0.9322117  0.93017459 0.92721927 0.92618018 0.92372757\n",
      "  0.92218184 0.920762  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023481526877731085\n",
      "Predicción post entrenamiento : [[0.9190169]]\n",
      "PERDIDAAAA despues: 0.002383883111178875\n",
      "loss en el callback: 0.004025347530841827, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.9322117 ]\n",
      "  [0.93017459]\n",
      "  [0.92721927]\n",
      "  [0.92618018]\n",
      "  [0.92372757]\n",
      "  [0.92218184]\n",
      "  [0.920762  ]\n",
      "  [0.91938418]]]\n",
      "ejemplar: [0.9322117  0.93017459 0.92721927 0.92618018 0.92372757 0.92218184\n",
      " 0.920762   0.91938418]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.91732115]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.9322117  0.93017459 0.92721927 0.92618018 0.92372757 0.92218184\n",
      "  0.920762   0.91938418]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005475381040014327\n",
      "Predicción post entrenamiento : [[0.9183963]]\n",
      "PERDIDAAAA despues: 0.0004983780672773719\n",
      "loss en el callback: 0.06329216808080673, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.93017459]\n",
      "  [0.92721927]\n",
      "  [0.92618018]\n",
      "  [0.92372757]\n",
      "  [0.92218184]\n",
      "  [0.920762  ]\n",
      "  [0.91938418]\n",
      "  [0.91732115]]]\n",
      "ejemplar: [0.93017459 0.92721927 0.92618018 0.92372757 0.92218184 0.920762\n",
      " 0.91938418 0.91732115]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.91653436]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.93017459 0.92721927 0.92618018 0.92372757 0.92218184 0.920762\n",
      "  0.91938418 0.91732115]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031311747152358294\n",
      "Predicción post entrenamiento : [[0.91704375]]\n",
      "PERDIDAAAA despues: 0.003074427368119359\n",
      "loss en el callback: 0.010320148430764675, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.92721927]\n",
      "  [0.92618018]\n",
      "  [0.92372757]\n",
      "  [0.92218184]\n",
      "  [0.920762  ]\n",
      "  [0.91938418]\n",
      "  [0.91732115]\n",
      "  [0.91653436]]]\n",
      "ejemplar: [0.92721927 0.92618018 0.92372757 0.92218184 0.920762   0.91938418\n",
      " 0.91732115 0.91653436]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9152334]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.92721927 0.92618018 0.92372757 0.92218184 0.920762   0.91938418\n",
      "  0.91732115 0.91653436]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006669509690254927\n",
      "Predicción post entrenamiento : [[0.91477764]]\n",
      "PERDIDAAAA despues: 0.00674415472894907\n",
      "loss en el callback: 0.00639298977330327, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.92618018]\n",
      "  [0.92372757]\n",
      "  [0.92218184]\n",
      "  [0.920762  ]\n",
      "  [0.91938418]\n",
      "  [0.91732115]\n",
      "  [0.91653436]\n",
      "  [0.91523337]]]\n",
      "ejemplar: [0.92618018 0.92372757 0.92218184 0.920762   0.91938418 0.91732115\n",
      " 0.91653436 0.91523337]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.91332555]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.92618018 0.92372757 0.92218184 0.920762   0.91938418 0.91732115\n",
      "  0.91653436 0.91523337]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014330890262499452\n",
      "Predicción post entrenamiento : [[0.91379553]]\n",
      "PERDIDAAAA despues: 0.00139772635884583\n",
      "loss en el callback: 0.009217697195708752, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.92372757]\n",
      "  [0.92218184]\n",
      "  [0.920762  ]\n",
      "  [0.91938418]\n",
      "  [0.91732115]\n",
      "  [0.91653436]\n",
      "  [0.91523337]\n",
      "  [0.91332555]]]\n",
      "ejemplar: [0.92372757 0.92218184 0.920762   0.91938418 0.91732115 0.91653436\n",
      " 0.91523337 0.91332555]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.91218555]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.92372757 0.92218184 0.920762   0.91938418 0.91732115 0.91653436\n",
      "  0.91523337 0.91332555]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002692467824090272\n",
      "Predicción post entrenamiento : [[0.911798]]\n",
      "PERDIDAAAA despues: 0.00025667858426459134\n",
      "loss en el callback: 0.005408469587564468, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.92218184]\n",
      "  [0.920762  ]\n",
      "  [0.91938418]\n",
      "  [0.91732115]\n",
      "  [0.91653436]\n",
      "  [0.91523337]\n",
      "  [0.91332555]\n",
      "  [0.91218555]]]\n",
      "ejemplar: [0.92218184 0.920762   0.91938418 0.91732115 0.91653436 0.91523337\n",
      " 0.91332555 0.91218555]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.91044563]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.92218184 0.920762   0.91938418 0.91732115 0.91653436 0.91523337\n",
      "  0.91332555 0.91218555]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008412514580413699\n",
      "Predicción post entrenamiento : [[0.9108589]]\n",
      "PERDIDAAAA despues: 0.0008653972181491554\n",
      "loss en el callback: 0.008251966908574104, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.920762  ]\n",
      "  [0.91938418]\n",
      "  [0.91732115]\n",
      "  [0.91653436]\n",
      "  [0.91523337]\n",
      "  [0.91332555]\n",
      "  [0.91218555]\n",
      "  [0.91044563]]]\n",
      "ejemplar: [0.920762   0.91938418 0.91732115 0.91653436 0.91523337 0.91332555\n",
      " 0.91218555 0.91044563]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.90953225]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.920762   0.91938418 0.91732115 0.91653436 0.91523337 0.91332555\n",
      "  0.91218555 0.91044563]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.7065535656875e-05\n",
      "Predicción post entrenamiento : [[0.90964615]]\n",
      "PERDIDAAAA despues: 5.535760283237323e-05\n",
      "loss en el callback: 0.0005003653932362795, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.91938418]\n",
      "  [0.91732115]\n",
      "  [0.91653436]\n",
      "  [0.91523337]\n",
      "  [0.91332555]\n",
      "  [0.91218555]\n",
      "  [0.91044563]\n",
      "  [0.90953225]]]\n",
      "ejemplar: [0.91938418 0.91732115 0.91653436 0.91523337 0.91332555 0.91218555\n",
      " 0.91044563 0.90953225]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.90831345]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.91938418 0.91732115 0.91653436 0.91523337 0.91332555 0.91218555\n",
      "  0.91044563 0.90953225]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013190752360969782\n",
      "Predicción post entrenamiento : [[0.9086956]]\n",
      "PERDIDAAAA despues: 0.0001232760405400768\n",
      "loss en el callback: 0.007020065560936928, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.91732115]\n",
      "  [0.91653436]\n",
      "  [0.91523337]\n",
      "  [0.91332555]\n",
      "  [0.91218555]\n",
      "  [0.91044563]\n",
      "  [0.90953225]\n",
      "  [0.90831345]]]\n",
      "ejemplar: [0.91732115 0.91653436 0.91523337 0.91332555 0.91218555 0.91044563\n",
      " 0.90953225 0.90831345]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9073486]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.91732115 0.91653436 0.91523337 0.91332555 0.91218555 0.91044563\n",
      "  0.90953225 0.90831345]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029478631913661957\n",
      "Predicción post entrenamiento : [[0.9077962]]\n",
      "PERDIDAAAA despues: 0.0028994560707360506\n",
      "loss en el callback: 0.008429358713328838, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.91653436]\n",
      "  [0.91523337]\n",
      "  [0.91332555]\n",
      "  [0.91218555]\n",
      "  [0.91044563]\n",
      "  [0.90953225]\n",
      "  [0.90831345]\n",
      "  [0.90734857]]]\n",
      "ejemplar: [0.91653436 0.91523337 0.91332555 0.91218555 0.91044563 0.90953225\n",
      " 0.90831345 0.90734857]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9066476]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.91653436 0.91523337 0.91332555 0.91218555 0.91044563 0.90953225\n",
      "  0.90831345 0.90734857]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003792309667915106\n",
      "Predicción post entrenamiento : [[0.907242]]\n",
      "PERDIDAAAA despues: 0.0037194571923464537\n",
      "loss en el callback: 0.014853847213089466, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.91523337]\n",
      "  [0.91332555]\n",
      "  [0.91218555]\n",
      "  [0.91044563]\n",
      "  [0.90953225]\n",
      "  [0.90831345]\n",
      "  [0.90734857]\n",
      "  [0.90664762]]]\n",
      "ejemplar: [0.91523337 0.91332555 0.91218555 0.91044563 0.90953225 0.90831345\n",
      " 0.90734857 0.90664762]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.90594345]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.91523337 0.91332555 0.91218555 0.91044563 0.90953225 0.90831345\n",
      "  0.90734857 0.90664762]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026858169585466385\n",
      "Predicción post entrenamiento : [[0.9057197]]\n",
      "PERDIDAAAA despues: 0.002709059277549386\n",
      "loss en el callback: 0.0016366250347346067, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22367331]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031530093401670456\n",
      "Predicción post entrenamiento : [[0.17321557]]\n",
      "PERDIDAAAA despues: 0.01615680195391178\n",
      "loss en el callback: 0.041082713752985, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22367331]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.22367331]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.15730862]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.22367331]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028180654626339674\n",
      "Predicción post entrenamiento : [[0.14704984]]\n",
      "PERDIDAAAA despues: 0.001834124093875289\n",
      "loss en el callback: 0.0022755952086299658, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22367331]\n",
      "  [0.15730862]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.22367331 0.15730862]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15075094]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.22367331 0.15730862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1922292287636083e-05\n",
      "Predicción post entrenamiento : [[0.148796]]\n",
      "PERDIDAAAA despues: 2.9244250981719233e-05\n",
      "loss en el callback: 0.00015700834046583623, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22367331]\n",
      "  [0.15730862]\n",
      "  [0.15075094]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22367331\n",
      " 0.15730862 0.15075094]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.15953484]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22367331\n",
      "  0.15730862 0.15075094]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4297919733508024e-05\n",
      "Predicción post entrenamiento : [[0.15694581]]\n",
      "PERDIDAAAA despues: 1.4214052725947113e-06\n",
      "loss en el callback: 0.000465610675746575, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22367331]\n",
      "  [0.15730862]\n",
      "  [0.15075094]\n",
      "  [0.15953484]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.22367331 0.15730862\n",
      " 0.15075094 0.15953484]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.16820164]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.22367331 0.15730862\n",
      "  0.15075094 0.15953484]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001820634468458593\n",
      "Predicción post entrenamiento : [[0.16652493]]\n",
      "PERDIDAAAA despues: 0.0016803592443466187\n",
      "loss en el callback: 0.0004976312047801912, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22367331]\n",
      "  [0.15730862]\n",
      "  [0.15075094]\n",
      "  [0.15953484]\n",
      "  [0.16820164]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.22367331 0.15730862 0.15075094\n",
      " 0.15953484 0.16820164]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.17416279]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.22367331 0.15730862 0.15075094\n",
      "  0.15953484 0.16820164]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000811271311249584\n",
      "Predicción post entrenamiento : [[0.17146282]]\n",
      "PERDIDAAAA despues: 0.000664755527395755\n",
      "loss en el callback: 0.00124163250438869, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22367331]\n",
      "  [0.15730862]\n",
      "  [0.15075094]\n",
      "  [0.15953484]\n",
      "  [0.16820164]\n",
      "  [0.17416279]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.22367331 0.15730862 0.15075094 0.15953484\n",
      " 0.16820164 0.17416279]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.18922558]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.22367331 0.15730862 0.15075094 0.15953484\n",
      "  0.16820164 0.17416279]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018293352331966162\n",
      "Predicción post entrenamiento : [[0.18490274]]\n",
      "PERDIDAAAA despues: 0.0014782400103285909\n",
      "loss en el callback: 0.0036587838549166918, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.22367331]\n",
      "  [0.15730862]\n",
      "  [0.15075094]\n",
      "  [0.15953484]\n",
      "  [0.16820164]\n",
      "  [0.17416279]\n",
      "  [0.18922558]]]\n",
      "ejemplar: [0.04223169 0.22367331 0.15730862 0.15075094 0.15953484 0.16820164\n",
      " 0.17416279 0.18922558]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.2060164]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.22367331 0.15730862 0.15075094 0.15953484 0.16820164\n",
      "  0.17416279 0.18922558]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.936840797308832e-05\n",
      "Predicción post entrenamiento : [[0.20213333]]\n",
      "PERDIDAAAA despues: 3.703077163663693e-05\n",
      "loss en el callback: 0.0032181122805923223, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.22367331]\n",
      "  [0.15730862]\n",
      "  [0.15075094]\n",
      "  [0.15953484]\n",
      "  [0.16820164]\n",
      "  [0.17416279]\n",
      "  [0.18922558]\n",
      "  [0.20601641]]]\n",
      "ejemplar: [0.22367331 0.15730862 0.15075094 0.15953484 0.16820164 0.17416279\n",
      " 0.18922558 0.20601641]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.22683148]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.22367331 0.15730862 0.15075094 0.15953484 0.16820164 0.17416279\n",
      "  0.18922558 0.20601641]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.368495031783823e-05\n",
      "Predicción post entrenamiento : [[0.22766972]]\n",
      "PERDIDAAAA despues: 8.185793376469519e-06\n",
      "loss en el callback: 0.00026648753555491567, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.15730862]\n",
      "  [0.15075094]\n",
      "  [0.15953484]\n",
      "  [0.16820164]\n",
      "  [0.17416279]\n",
      "  [0.18922558]\n",
      "  [0.20601641]\n",
      "  [0.22683148]]]\n",
      "ejemplar: [0.15730862 0.15075094 0.15953484 0.16820164 0.17416279 0.18922558\n",
      " 0.20601641 0.22683148]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.21714793]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.15730862 0.15075094 0.15953484 0.16820164 0.17416279 0.18922558\n",
      "  0.20601641 0.22683148]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.571771857328713e-05\n",
      "Predicción post entrenamiento : [[0.21708065]]\n",
      "PERDIDAAAA despues: 7.455137529177591e-05\n",
      "loss en el callback: 1.9954816252720775e-06, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.15075094]\n",
      "  [0.15953484]\n",
      "  [0.16820164]\n",
      "  [0.17416279]\n",
      "  [0.18922558]\n",
      "  [0.20601641]\n",
      "  [0.22683148]\n",
      "  [0.21714793]]]\n",
      "ejemplar: [0.15075094 0.15953484 0.16820164 0.17416279 0.18922558 0.20601641\n",
      " 0.22683148 0.21714793]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.22036596]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.15075094 0.15953484 0.16820164 0.17416279 0.18922558 0.20601641\n",
      "  0.22683148 0.21714793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.11086904630065e-05\n",
      "Predicción post entrenamiento : [[0.21923141]]\n",
      "PERDIDAAAA despues: 5.326156679075211e-05\n",
      "loss en el callback: 0.0006734280032105744, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.15953484]\n",
      "  [0.16820164]\n",
      "  [0.17416279]\n",
      "  [0.18922558]\n",
      "  [0.20601641]\n",
      "  [0.22683148]\n",
      "  [0.21714793]\n",
      "  [0.22036596]]]\n",
      "ejemplar: [0.15953484 0.16820164 0.17416279 0.18922558 0.20601641 0.22683148\n",
      " 0.21714793 0.22036596]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.22568397]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.15953484 0.16820164 0.17416279 0.18922558 0.20601641 0.22683148\n",
      "  0.21714793 0.22036596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033855883521027863\n",
      "Predicción post entrenamiento : [[0.22544082]]\n",
      "PERDIDAAAA despues: 0.00032966979779303074\n",
      "loss en el callback: 4.024772715638392e-05, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.16820164]\n",
      "  [0.17416279]\n",
      "  [0.18922558]\n",
      "  [0.20601641]\n",
      "  [0.22683148]\n",
      "  [0.21714793]\n",
      "  [0.22036596]\n",
      "  [0.22568397]]]\n",
      "ejemplar: [0.16820164 0.17416279 0.18922558 0.20601641 0.22683148 0.21714793\n",
      " 0.22036596 0.22568397]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.23216633]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.16820164 0.17416279 0.18922558 0.20601641 0.22683148 0.21714793\n",
      "  0.22036596 0.22568397]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015380404656752944\n",
      "Predicción post entrenamiento : [[0.23012717]]\n",
      "PERDIDAAAA despues: 0.0013822553446516395\n",
      "loss en el callback: 0.002929819980636239, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.17416279]\n",
      "  [0.18922558]\n",
      "  [0.20601641]\n",
      "  [0.22683148]\n",
      "  [0.21714793]\n",
      "  [0.22036596]\n",
      "  [0.22568397]\n",
      "  [0.23216633]]]\n",
      "ejemplar: [0.17416279 0.18922558 0.20601641 0.22683148 0.21714793 0.22036596\n",
      " 0.22568397 0.23216633]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.23706184]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.17416279 0.18922558 0.20601641 0.22683148 0.21714793 0.22036596\n",
      "  0.22568397 0.23216633]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016191692557185888\n",
      "Predicción post entrenamiento : [[0.23481697]]\n",
      "PERDIDAAAA despues: 0.0014435461489483714\n",
      "loss en el callback: 0.0036533039528876543, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.18922558]\n",
      "  [0.20601641]\n",
      "  [0.22683148]\n",
      "  [0.21714793]\n",
      "  [0.22036596]\n",
      "  [0.22568397]\n",
      "  [0.23216633]\n",
      "  [0.23706184]]]\n",
      "ejemplar: [0.18922558 0.20601641 0.22683148 0.21714793 0.22036596 0.22568397\n",
      " 0.23216633 0.23706184]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.24244705]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.18922558 0.20601641 0.22683148 0.21714793 0.22036596 0.22568397\n",
      "  0.23216633 0.23706184]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007946199038997293\n",
      "Predicción post entrenamiento : [[0.24330631]]\n",
      "PERDIDAAAA despues: 0.0008438016520813107\n",
      "loss en el callback: 0.001074369647540152, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.20601641]\n",
      "  [0.22683148]\n",
      "  [0.21714793]\n",
      "  [0.22036596]\n",
      "  [0.22568397]\n",
      "  [0.23216633]\n",
      "  [0.23706184]\n",
      "  [0.24244705]]]\n",
      "ejemplar: [0.20601641 0.22683148 0.21714793 0.22036596 0.22568397 0.23216633\n",
      " 0.23706184 0.24244705]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.24952124]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.20601641 0.22683148 0.21714793 0.22036596 0.22568397 0.23216633\n",
      "  0.23706184 0.24244705]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004650718532502651\n",
      "Predicción post entrenamiento : [[0.24873054]]\n",
      "PERDIDAAAA despues: 0.004543498158454895\n",
      "loss en el callback: 0.0008991437498480082, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.22683148]\n",
      "  [0.21714793]\n",
      "  [0.22036596]\n",
      "  [0.22568397]\n",
      "  [0.23216633]\n",
      "  [0.23706184]\n",
      "  [0.24244705]\n",
      "  [0.24952124]]]\n",
      "ejemplar: [0.22683148 0.21714793 0.22036596 0.22568397 0.23216633 0.23706184\n",
      " 0.24244705 0.24952124]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.25273535]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.22683148 0.21714793 0.22036596 0.22568397 0.23216633 0.23706184\n",
      "  0.24244705 0.24952124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006023222114890814\n",
      "Predicción post entrenamiento : [[0.25212124]]\n",
      "PERDIDAAAA despues: 0.005928278435021639\n",
      "loss en el callback: 0.0006891941884532571, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.21714793]\n",
      "  [0.22036596]\n",
      "  [0.22568397]\n",
      "  [0.23216633]\n",
      "  [0.23706184]\n",
      "  [0.24244705]\n",
      "  [0.24952124]\n",
      "  [0.25273535]]]\n",
      "ejemplar: [0.21714793 0.22036596 0.22568397 0.23216633 0.23706184 0.24244705\n",
      " 0.24952124 0.25273535]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.25256842]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.21714793 0.22036596 0.22568397 0.23216633 0.23706184 0.24244705\n",
      "  0.24952124 0.25273535]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010933582670986652\n",
      "Predicción post entrenamiento : [[0.24886093]]\n",
      "PERDIDAAAA despues: 0.010171988047659397\n",
      "loss en el callback: 0.016046082600951195, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.22036596]\n",
      "  [0.22568397]\n",
      "  [0.23216633]\n",
      "  [0.23706184]\n",
      "  [0.24244705]\n",
      "  [0.24952124]\n",
      "  [0.25273535]\n",
      "  [0.25256842]]]\n",
      "ejemplar: [0.22036596 0.22568397 0.23216633 0.23706184 0.24244705 0.24952124\n",
      " 0.25273535 0.25256842]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.25214309]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.22036596 0.22568397 0.23216633 0.23706184 0.24244705 0.24952124\n",
      "  0.25273535 0.25256842]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008703010156750679\n",
      "Predicción post entrenamiento : [[0.24862583]]\n",
      "PERDIDAAAA despues: 0.008059132844209671\n",
      "loss en el callback: 0.01489635556936264, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.22568397]\n",
      "  [0.23216633]\n",
      "  [0.23706184]\n",
      "  [0.24244705]\n",
      "  [0.24952124]\n",
      "  [0.25273535]\n",
      "  [0.25256842]\n",
      "  [0.25214309]]]\n",
      "ejemplar: [0.22568397 0.23216633 0.23706184 0.24244705 0.24952124 0.25273535\n",
      " 0.25256842 0.25214309]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.25226745]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.22568397 0.23216633 0.23706184 0.24244705 0.24952124 0.25273535\n",
      "  0.25256842 0.25214309]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036112742964178324\n",
      "Predicción post entrenamiento : [[0.2499728]]\n",
      "PERDIDAAAA despues: 0.0033407516311854124\n",
      "loss en el callback: 0.007382355164736509, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.23216633]\n",
      "  [0.23706184]\n",
      "  [0.24244705]\n",
      "  [0.24952124]\n",
      "  [0.25273535]\n",
      "  [0.25256842]\n",
      "  [0.25214309]\n",
      "  [0.25226745]]]\n",
      "ejemplar: [0.23216633 0.23706184 0.24244705 0.24952124 0.25273535 0.25256842\n",
      " 0.25214309 0.25226745]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.25346535]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.23216633 0.23706184 0.24244705 0.24952124 0.25273535 0.25256842\n",
      "  0.25214309 0.25226745]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004555024206638336\n",
      "Predicción post entrenamiento : [[0.25250348]]\n",
      "PERDIDAAAA despues: 0.004426114726811647\n",
      "loss en el callback: 0.001796793658286333, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.23706184]\n",
      "  [0.24244705]\n",
      "  [0.24952124]\n",
      "  [0.25273535]\n",
      "  [0.25256842]\n",
      "  [0.25214309]\n",
      "  [0.25226745]\n",
      "  [0.25346535]]]\n",
      "ejemplar: [0.23706184 0.24244705 0.24952124 0.25273535 0.25256842 0.25214309\n",
      " 0.25226745 0.25346535]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2554449]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.23706184 0.24244705 0.24952124 0.25273535 0.25256842 0.25214309\n",
      "  0.25226745 0.25346535]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013238508836366236\n",
      "Predicción post entrenamiento : [[0.254722]]\n",
      "PERDIDAAAA despues: 0.0001495432370575145\n",
      "loss en el callback: 0.0007625180296599865, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.24244705]\n",
      "  [0.24952124]\n",
      "  [0.25273535]\n",
      "  [0.25256842]\n",
      "  [0.25214309]\n",
      "  [0.25226745]\n",
      "  [0.25346535]\n",
      "  [0.25544491]]]\n",
      "ejemplar: [0.24244705 0.24952124 0.25273535 0.25256842 0.25214309 0.25226745\n",
      " 0.25346535 0.25544491]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.25728044]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.24244705 0.24952124 0.25273535 0.25256842 0.25214309 0.25226745\n",
      "  0.25346535 0.25544491]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012419874547049403\n",
      "Predicción post entrenamiento : [[0.2571749]]\n",
      "PERDIDAAAA despues: 0.001249436754733324\n",
      "loss en el callback: 1.896198773465585e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.24952124]\n",
      "  [0.25273535]\n",
      "  [0.25256842]\n",
      "  [0.25214309]\n",
      "  [0.25226745]\n",
      "  [0.25346535]\n",
      "  [0.25544491]\n",
      "  [0.25728044]]]\n",
      "ejemplar: [0.24952124 0.25273535 0.25256842 0.25214309 0.25226745 0.25346535\n",
      " 0.25544491 0.25728044]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.25909328]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.24952124 0.25273535 0.25256842 0.25214309 0.25226745 0.25346535\n",
      "  0.25544491 0.25728044]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003435487626120448\n",
      "Predicción post entrenamiento : [[0.26053485]]\n",
      "PERDIDAAAA despues: 0.0032685762271285057\n",
      "loss en el callback: 0.005296613555401564, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.25273535]\n",
      "  [0.25256842]\n",
      "  [0.25214309]\n",
      "  [0.25226745]\n",
      "  [0.25346535]\n",
      "  [0.25544491]\n",
      "  [0.25728044]\n",
      "  [0.25909328]]]\n",
      "ejemplar: [0.25273535 0.25256842 0.25214309 0.25226745 0.25346535 0.25544491\n",
      " 0.25728044 0.25909328]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26126897]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.25273535 0.25256842 0.25214309 0.25226745 0.25346535 0.25544491\n",
      "  0.25728044 0.25909328]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026420156937092543\n",
      "Predicción post entrenamiento : [[0.2620299]]\n",
      "PERDIDAAAA despues: 0.0025643720291554928\n",
      "loss en el callback: 0.0012341918190941215, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.25256842]\n",
      "  [0.25214309]\n",
      "  [0.25226745]\n",
      "  [0.25346535]\n",
      "  [0.25544491]\n",
      "  [0.25728044]\n",
      "  [0.25909328]\n",
      "  [0.26126897]]]\n",
      "ejemplar: [0.25256842 0.25214309 0.25226745 0.25346535 0.25544491 0.25728044\n",
      " 0.25909328 0.26126897]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.26226947]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.25256842 0.25214309 0.25226745 0.25346535 0.25544491 0.25728044\n",
      "  0.25909328 0.26126897]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007164077251218259\n",
      "Predicción post entrenamiento : [[0.26275933]]\n",
      "PERDIDAAAA despues: 0.0006904246401973069\n",
      "loss en el callback: 0.0006328478921204805, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.25214309]\n",
      "  [0.25226745]\n",
      "  [0.25346535]\n",
      "  [0.25544491]\n",
      "  [0.25728044]\n",
      "  [0.25909328]\n",
      "  [0.26126897]\n",
      "  [0.26226947]]]\n",
      "ejemplar: [0.25214309 0.25226745 0.25346535 0.25544491 0.25728044 0.25909328\n",
      " 0.26126897 0.26226947]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.26323035]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.25214309 0.25226745 0.25346535 0.25544491 0.25728044 0.25909328\n",
      "  0.26126897 0.26226947]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003843856684397906\n",
      "Predicción post entrenamiento : [[0.26362258]]\n",
      "PERDIDAAAA despues: 0.0003691596502903849\n",
      "loss en el callback: 0.00042718963231891394, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.25226745]\n",
      "  [0.25346535]\n",
      "  [0.25544491]\n",
      "  [0.25728044]\n",
      "  [0.25909328]\n",
      "  [0.26126897]\n",
      "  [0.26226947]\n",
      "  [0.26323035]]]\n",
      "ejemplar: [0.25226745 0.25346535 0.25544491 0.25728044 0.25909328 0.26126897\n",
      " 0.26226947 0.26323035]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.26444945]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.25226745 0.25346535 0.25544491 0.25728044 0.25909328 0.26126897\n",
      "  0.26226947 0.26323035]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012282835086807609\n",
      "Predicción post entrenamiento : [[0.26388744]]\n",
      "PERDIDAAAA despues: 0.0012679928913712502\n",
      "loss en el callback: 0.000743962824344635, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.25346535]\n",
      "  [0.25544491]\n",
      "  [0.25728044]\n",
      "  [0.25909328]\n",
      "  [0.26126897]\n",
      "  [0.26226947]\n",
      "  [0.26323035]\n",
      "  [0.26444945]]]\n",
      "ejemplar: [0.25346535 0.25544491 0.25728044 0.25909328 0.26126897 0.26226947\n",
      " 0.26323035 0.26444945]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.26501194]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.25346535 0.25544491 0.25728044 0.25909328 0.26126897 0.26226947\n",
      "  0.26323035 0.26444945]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011772535071941093\n",
      "Predicción post entrenamiento : [[0.26520205]]\n",
      "PERDIDAAAA despues: 0.00011363608064129949\n",
      "loss en el callback: 0.0001240542042069137, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.25544491]\n",
      "  [0.25728044]\n",
      "  [0.25909328]\n",
      "  [0.26126897]\n",
      "  [0.26226947]\n",
      "  [0.26323035]\n",
      "  [0.26444945]\n",
      "  [0.26501194]]]\n",
      "ejemplar: [0.25544491 0.25728044 0.25909328 0.26126897 0.26226947 0.26323035\n",
      " 0.26444945 0.26501194]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.26641777]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.25544491 0.25728044 0.25909328 0.26126897 0.26226947 0.26323035\n",
      "  0.26444945 0.26501194]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.859063432784751e-05\n",
      "Predicción post entrenamiento : [[0.26619297]]\n",
      "PERDIDAAAA despues: 7.236470992211252e-05\n",
      "loss en el callback: 0.00016813588445074856, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.25728044]\n",
      "  [0.25909328]\n",
      "  [0.26126897]\n",
      "  [0.26226947]\n",
      "  [0.26323035]\n",
      "  [0.26444945]\n",
      "  [0.26501194]\n",
      "  [0.26641777]]]\n",
      "ejemplar: [0.25728044 0.25909328 0.26126897 0.26226947 0.26323035 0.26444945\n",
      " 0.26501194 0.26641777]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.26731735]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.25728044 0.25909328 0.26126897 0.26226947 0.26323035 0.26444945\n",
      "  0.26501194 0.26641777]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.654077878920361e-05\n",
      "Predicción post entrenamiento : [[0.26752228]]\n",
      "PERDIDAAAA despues: 6.323958950815722e-05\n",
      "loss en el callback: 0.00018693890888243914, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.25909328]\n",
      "  [0.26126897]\n",
      "  [0.26226947]\n",
      "  [0.26323035]\n",
      "  [0.26444945]\n",
      "  [0.26501194]\n",
      "  [0.26641777]\n",
      "  [0.26731735]]]\n",
      "ejemplar: [0.25909328 0.26126897 0.26226947 0.26323035 0.26444945 0.26501194\n",
      " 0.26641777 0.26731735]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.26855567]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.25909328 0.26126897 0.26226947 0.26323035 0.26444945 0.26501194\n",
      "  0.26641777 0.26731735]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004382213577628136\n",
      "Predicción post entrenamiento : [[0.2697413]]\n",
      "PERDIDAAAA despues: 0.004226646386086941\n",
      "loss en el callback: 0.006165231112390757, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26126897]\n",
      "  [0.26226947]\n",
      "  [0.26323035]\n",
      "  [0.26444945]\n",
      "  [0.26501194]\n",
      "  [0.26641777]\n",
      "  [0.26731735]\n",
      "  [0.26855567]]]\n",
      "ejemplar: [0.26126897 0.26226947 0.26323035 0.26444945 0.26501194 0.26641777\n",
      " 0.26731735 0.26855567]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27066058]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26126897 0.26226947 0.26323035 0.26444945 0.26501194 0.26641777\n",
      "  0.26731735 0.26855567]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007227636408060789\n",
      "Predicción post entrenamiento : [[0.27175683]]\n",
      "PERDIDAAAA despues: 0.007042441517114639\n",
      "loss en el callback: 0.004108878318220377, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26226947]\n",
      "  [0.26323035]\n",
      "  [0.26444945]\n",
      "  [0.26501194]\n",
      "  [0.26641777]\n",
      "  [0.26731735]\n",
      "  [0.26855567]\n",
      "  [0.27066058]]]\n",
      "ejemplar: [0.26226947 0.26323035 0.26444945 0.26501194 0.26641777 0.26731735\n",
      " 0.26855567 0.27066058]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2724548]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26226947 0.26323035 0.26444945 0.26501194 0.26641777 0.26731735\n",
      "  0.26855567 0.27066058]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004126315470784903\n",
      "Predicción post entrenamiento : [[0.27309042]]\n",
      "PERDIDAAAA despues: 0.004045058973133564\n",
      "loss en el callback: 0.0015852609649300575, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.26323035]\n",
      "  [0.26444945]\n",
      "  [0.26501194]\n",
      "  [0.26641777]\n",
      "  [0.26731735]\n",
      "  [0.26855567]\n",
      "  [0.27066058]\n",
      "  [0.2724548 ]]]\n",
      "ejemplar: [0.26323035 0.26444945 0.26501194 0.26641777 0.26731735 0.26855567\n",
      " 0.27066058 0.2724548 ]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2738107]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.26323035 0.26444945 0.26501194 0.26641777 0.26731735 0.26855567\n",
      "  0.27066058 0.2724548 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035737589932978153\n",
      "Predicción post entrenamiento : [[0.274508]]\n",
      "PERDIDAAAA despues: 0.0034908766392618418\n",
      "loss en el callback: 0.00232944218441844, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.26444945]\n",
      "  [0.26501194]\n",
      "  [0.26641777]\n",
      "  [0.26731735]\n",
      "  [0.26855567]\n",
      "  [0.27066058]\n",
      "  [0.2724548 ]\n",
      "  [0.27381071]]]\n",
      "ejemplar: [0.26444945 0.26501194 0.26641777 0.26731735 0.26855567 0.27066058\n",
      " 0.2724548  0.27381071]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.27527684]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.26444945 0.26501194 0.26641777 0.26731735 0.26855567 0.27066058\n",
      "  0.2724548  0.27381071]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011981001123785973\n",
      "Predicción post entrenamiento : [[0.27686062]]\n",
      "PERDIDAAAA despues: 0.011636794544756413\n",
      "loss en el callback: 0.012640472501516342, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.26501194]\n",
      "  [0.26641777]\n",
      "  [0.26731735]\n",
      "  [0.26855567]\n",
      "  [0.27066058]\n",
      "  [0.2724548 ]\n",
      "  [0.27381071]\n",
      "  [0.27527684]]]\n",
      "ejemplar: [0.26501194 0.26641777 0.26731735 0.26855567 0.27066058 0.2724548\n",
      " 0.27381071 0.27527684]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27763918]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.26501194 0.26641777 0.26731735 0.26855567 0.27066058 0.2724548\n",
      "  0.27381071 0.27527684]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08611718565225601\n",
      "Predicción post entrenamiento : [[0.28157192]]\n",
      "PERDIDAAAA despues: 0.08382447063922882\n",
      "loss en el callback: 0.07012277096509933, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.26641777]\n",
      "  [0.26731735]\n",
      "  [0.26855567]\n",
      "  [0.27066058]\n",
      "  [0.2724548 ]\n",
      "  [0.27381071]\n",
      "  [0.27527684]\n",
      "  [0.27763918]]]\n",
      "ejemplar: [0.26641777 0.26731735 0.26855567 0.27066058 0.2724548  0.27381071\n",
      " 0.27527684 0.27763918]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28253102]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.26641777 0.26731735 0.26855567 0.27066058 0.2724548  0.27381071\n",
      "  0.27527684 0.27763918]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09843874722719193\n",
      "Predicción post entrenamiento : [[0.28655684]]\n",
      "PERDIDAAAA despues: 0.09592875838279724\n",
      "loss en el callback: 0.09647710621356964, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.26731735]\n",
      "  [0.26855567]\n",
      "  [0.27066058]\n",
      "  [0.2724548 ]\n",
      "  [0.27381071]\n",
      "  [0.27527684]\n",
      "  [0.27763918]\n",
      "  [0.28253102]]]\n",
      "ejemplar: [0.26731735 0.26855567 0.27066058 0.2724548  0.27381071 0.27527684\n",
      " 0.27763918 0.28253102]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.2875575]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.26731735 0.26855567 0.27066058 0.2724548  0.27381071 0.27527684\n",
      "  0.27763918 0.28253102]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0823839008808136\n",
      "Predicción post entrenamiento : [[0.2912431]]\n",
      "PERDIDAAAA despues: 0.08028176426887512\n",
      "loss en el callback: 0.07975493371486664, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.26855567]\n",
      "  [0.27066058]\n",
      "  [0.2724548 ]\n",
      "  [0.27381071]\n",
      "  [0.27527684]\n",
      "  [0.27763918]\n",
      "  [0.28253102]\n",
      "  [0.28755751]]]\n",
      "ejemplar: [0.26855567 0.27066058 0.2724548  0.27381071 0.27527684 0.27763918\n",
      " 0.28253102 0.28755751]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29245493]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.26855567 0.27066058 0.2724548  0.27381071 0.27527684 0.27763918\n",
      "  0.28253102 0.28755751]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09853269904851913\n",
      "Predicción post entrenamiento : [[0.29649618]]\n",
      "PERDIDAAAA despues: 0.0960119366645813\n",
      "loss en el callback: 0.09256704896688461, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27066058]\n",
      "  [0.2724548 ]\n",
      "  [0.27381071]\n",
      "  [0.27527684]\n",
      "  [0.27763918]\n",
      "  [0.28253102]\n",
      "  [0.28755751]\n",
      "  [0.29245493]]]\n",
      "ejemplar: [0.27066058 0.2724548  0.27381071 0.27527684 0.27763918 0.28253102\n",
      " 0.28755751 0.29245493]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.297933]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27066058 0.2724548  0.27381071 0.27527684 0.27763918 0.28253102\n",
      "  0.28755751 0.29245493]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0822107195854187\n",
      "Predicción post entrenamiento : [[0.3013653]]\n",
      "PERDIDAAAA despues: 0.08025427162647247\n",
      "loss en el callback: 0.09345263987779617, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.2724548 ]\n",
      "  [0.27381071]\n",
      "  [0.27527684]\n",
      "  [0.27763918]\n",
      "  [0.28253102]\n",
      "  [0.28755751]\n",
      "  [0.29245493]\n",
      "  [0.29793301]]]\n",
      "ejemplar: [0.2724548  0.27381071 0.27527684 0.27763918 0.28253102 0.28755751\n",
      " 0.29245493 0.29793301]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3029283]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.2724548  0.27381071 0.27527684 0.27763918 0.28253102 0.28755751\n",
      "  0.29245493 0.29793301]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07067275792360306\n",
      "Predicción post entrenamiento : [[0.30616108]]\n",
      "PERDIDAAAA despues: 0.068964384496212\n",
      "loss en el callback: 0.08572237193584442, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27381071]\n",
      "  [0.27527684]\n",
      "  [0.27763918]\n",
      "  [0.28253102]\n",
      "  [0.28755751]\n",
      "  [0.29245493]\n",
      "  [0.29793301]\n",
      "  [0.3029283 ]]]\n",
      "ejemplar: [0.27381071 0.27527684 0.27763918 0.28253102 0.28755751 0.29245493\n",
      " 0.29793301 0.3029283 ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.308018]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27381071 0.27527684 0.27763918 0.28253102 0.28755751 0.29245493\n",
      "  0.29793301 0.3029283 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11206164956092834\n",
      "Predicción post entrenamiento : [[0.311782]]\n",
      "PERDIDAAAA despues: 0.10955577343702316\n",
      "loss en el callback: 0.07372532039880753, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27527684]\n",
      "  [0.27763918]\n",
      "  [0.28253102]\n",
      "  [0.28755751]\n",
      "  [0.29245493]\n",
      "  [0.29793301]\n",
      "  [0.3029283 ]\n",
      "  [0.308018  ]]]\n",
      "ejemplar: [0.27527684 0.27763918 0.28253102 0.28755751 0.29245493 0.29793301\n",
      " 0.3029283  0.308018  ]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31415758]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27527684 0.27763918 0.28253102 0.28755751 0.29245493 0.29793301\n",
      "  0.3029283  0.308018  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12082676589488983\n",
      "Predicción post entrenamiento : [[0.31837177]]\n",
      "PERDIDAAAA despues: 0.11791480332612991\n",
      "loss en el callback: 0.1364242136478424, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27763918]\n",
      "  [0.28253102]\n",
      "  [0.28755751]\n",
      "  [0.29245493]\n",
      "  [0.29793301]\n",
      "  [0.3029283 ]\n",
      "  [0.308018  ]\n",
      "  [0.31415758]]]\n",
      "ejemplar: [0.27763918 0.28253102 0.28755751 0.29245493 0.29793301 0.3029283\n",
      " 0.308018   0.31415758]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32138863]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27763918 0.28253102 0.28755751 0.29245493 0.29793301 0.3029283\n",
      "  0.308018   0.31415758]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12362701445817947\n",
      "Predicción post entrenamiento : [[0.32551646]]\n",
      "PERDIDAAAA despues: 0.12074131518602371\n",
      "loss en el callback: 0.11087578535079956, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28253102]\n",
      "  [0.28755751]\n",
      "  [0.29245493]\n",
      "  [0.29793301]\n",
      "  [0.3029283 ]\n",
      "  [0.308018  ]\n",
      "  [0.31415758]\n",
      "  [0.32138863]]]\n",
      "ejemplar: [0.28253102 0.28755751 0.29245493 0.29793301 0.3029283  0.308018\n",
      " 0.31415758 0.32138863]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.32911858]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28253102 0.28755751 0.29245493 0.29793301 0.3029283  0.308018\n",
      "  0.31415758 0.32138863]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14551076292991638\n",
      "Predicción post entrenamiento : [[0.3333146]]\n",
      "PERDIDAAAA despues: 0.14232715964317322\n",
      "loss en el callback: 0.11829613149166107, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28755751]\n",
      "  [0.29245493]\n",
      "  [0.29793301]\n",
      "  [0.3029283 ]\n",
      "  [0.308018  ]\n",
      "  [0.31415758]\n",
      "  [0.32138863]\n",
      "  [0.32911858]]]\n",
      "ejemplar: [0.28755751 0.29245493 0.29793301 0.3029283  0.308018   0.31415758\n",
      " 0.32138863 0.32911858]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33703545]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28755751 0.29245493 0.29793301 0.3029283  0.308018   0.31415758\n",
      "  0.32138863 0.32911858]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13465616106987\n",
      "Predicción post entrenamiento : [[0.3409227]]\n",
      "PERDIDAAAA despues: 0.13181835412979126\n",
      "loss en el callback: 0.12231700122356415, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29245493]\n",
      "  [0.29793301]\n",
      "  [0.3029283 ]\n",
      "  [0.308018  ]\n",
      "  [0.31415758]\n",
      "  [0.32138863]\n",
      "  [0.32911858]\n",
      "  [0.33703545]]]\n",
      "ejemplar: [0.29245493 0.29793301 0.3029283  0.308018   0.31415758 0.32138863\n",
      " 0.32911858 0.33703545]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34479415]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29245493 0.29793301 0.3029283  0.308018   0.31415758 0.32138863\n",
      "  0.32911858 0.33703545]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14626292884349823\n",
      "Predicción post entrenamiento : [[0.34883076]]\n",
      "PERDIDAAAA despues: 0.14319168031215668\n",
      "loss en el callback: 0.13686996698379517, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29793301]\n",
      "  [0.3029283 ]\n",
      "  [0.308018  ]\n",
      "  [0.31415758]\n",
      "  [0.32138863]\n",
      "  [0.32911858]\n",
      "  [0.33703545]\n",
      "  [0.34479415]]]\n",
      "ejemplar: [0.29793301 0.3029283  0.308018   0.31415758 0.32138863 0.32911858\n",
      " 0.33703545 0.34479415]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.352963]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29793301 0.3029283  0.308018   0.31415758 0.32138863 0.32911858\n",
      "  0.33703545 0.34479415]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13662272691726685\n",
      "Predicción post entrenamiento : [[0.35685855]]\n",
      "PERDIDAAAA despues: 0.13375811278820038\n",
      "loss en el callback: 0.14923712611198425, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.3029283 ]\n",
      "  [0.308018  ]\n",
      "  [0.31415758]\n",
      "  [0.32138863]\n",
      "  [0.32911858]\n",
      "  [0.33703545]\n",
      "  [0.34479415]\n",
      "  [0.352963  ]]]\n",
      "ejemplar: [0.3029283  0.308018   0.31415758 0.32138863 0.32911858 0.33703545\n",
      " 0.34479415 0.352963  ]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3612103]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.3029283  0.308018   0.31415758 0.32138863 0.32911858 0.33703545\n",
      "  0.34479415 0.352963  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16857890784740448\n",
      "Predicción post entrenamiento : [[0.36550152]]\n",
      "PERDIDAAAA despues: 0.16507349908351898\n",
      "loss en el callback: 0.17257718741893768, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.308018  ]\n",
      "  [0.31415758]\n",
      "  [0.32138863]\n",
      "  [0.32911858]\n",
      "  [0.33703545]\n",
      "  [0.34479415]\n",
      "  [0.352963  ]\n",
      "  [0.36121029]]]\n",
      "ejemplar: [0.308018   0.31415758 0.32138863 0.32911858 0.33703545 0.34479415\n",
      " 0.352963   0.36121029]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37028414]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.308018   0.31415758 0.32138863 0.32911858 0.33703545 0.34479415\n",
      "  0.352963   0.36121029]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12548686563968658\n",
      "Predicción post entrenamiento : [[0.37423798]]\n",
      "PERDIDAAAA despues: 0.1227012649178505\n",
      "loss en el callback: 0.1602429747581482, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31415758]\n",
      "  [0.32138863]\n",
      "  [0.32911858]\n",
      "  [0.33703545]\n",
      "  [0.34479415]\n",
      "  [0.352963  ]\n",
      "  [0.36121029]\n",
      "  [0.37028414]]]\n",
      "ejemplar: [0.31415758 0.32138863 0.32911858 0.33703545 0.34479415 0.352963\n",
      " 0.36121029 0.37028414]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37955147]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31415758 0.32138863 0.32911858 0.33703545 0.34479415 0.352963\n",
      "  0.36121029 0.37028414]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08497588336467743\n",
      "Predicción post entrenamiento : [[0.38266006]]\n",
      "PERDIDAAAA despues: 0.08317320048809052\n",
      "loss en el callback: 0.0847991332411766, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32138863]\n",
      "  [0.32911858]\n",
      "  [0.33703545]\n",
      "  [0.34479415]\n",
      "  [0.352963  ]\n",
      "  [0.36121029]\n",
      "  [0.37028414]\n",
      "  [0.37955147]]]\n",
      "ejemplar: [0.32138863 0.32911858 0.33703545 0.34479415 0.352963   0.36121029\n",
      " 0.37028414 0.37955147]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38837484]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32138863 0.32911858 0.33703545 0.34479415 0.352963   0.36121029\n",
      "  0.37028414 0.37955147]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08145030587911606\n",
      "Predicción post entrenamiento : [[0.3915668]]\n",
      "PERDIDAAAA despues: 0.0796385407447815\n",
      "loss en el callback: 0.1480783224105835, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32911858]\n",
      "  [0.33703545]\n",
      "  [0.34479415]\n",
      "  [0.352963  ]\n",
      "  [0.36121029]\n",
      "  [0.37028414]\n",
      "  [0.37955147]\n",
      "  [0.38837484]]]\n",
      "ejemplar: [0.32911858 0.33703545 0.34479415 0.352963   0.36121029 0.37028414\n",
      " 0.37955147 0.38837484]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39750984]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32911858 0.33703545 0.34479415 0.352963   0.36121029 0.37028414\n",
      "  0.37955147 0.38837484]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10045219957828522\n",
      "Predicción post entrenamiento : [[0.40096125]]\n",
      "PERDIDAAAA despues: 0.09827631711959839\n",
      "loss en el callback: 0.13312043249607086, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33703545]\n",
      "  [0.34479415]\n",
      "  [0.352963  ]\n",
      "  [0.36121029]\n",
      "  [0.37028414]\n",
      "  [0.37955147]\n",
      "  [0.38837484]\n",
      "  [0.39750984]]]\n",
      "ejemplar: [0.33703545 0.34479415 0.352963   0.36121029 0.37028414 0.37955147\n",
      " 0.38837484 0.39750984]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40707192]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33703545 0.34479415 0.352963   0.36121029 0.37028414 0.37955147\n",
      "  0.38837484 0.39750984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11345162987709045\n",
      "Predicción post entrenamiento : [[0.4106138]]\n",
      "PERDIDAAAA despues: 0.111078180372715\n",
      "loss en el callback: 0.11017405241727829, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34479415]\n",
      "  [0.352963  ]\n",
      "  [0.36121029]\n",
      "  [0.37028414]\n",
      "  [0.37955147]\n",
      "  [0.38837484]\n",
      "  [0.39750984]\n",
      "  [0.40707192]]]\n",
      "ejemplar: [0.34479415 0.352963   0.36121029 0.37028414 0.37955147 0.38837484\n",
      " 0.39750984 0.40707192]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41689757]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34479415 0.352963   0.36121029 0.37028414 0.37955147 0.38837484\n",
      "  0.39750984 0.40707192]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09344671666622162\n",
      "Predicción post entrenamiento : [[0.42006615]]\n",
      "PERDIDAAAA despues: 0.0915195420384407\n",
      "loss en el callback: 0.11535888910293579, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.352963  ]\n",
      "  [0.36121029]\n",
      "  [0.37028414]\n",
      "  [0.37955147]\n",
      "  [0.38837484]\n",
      "  [0.39750984]\n",
      "  [0.40707192]\n",
      "  [0.41689757]]]\n",
      "ejemplar: [0.352963   0.36121029 0.37028414 0.37955147 0.38837484 0.39750984\n",
      " 0.40707192 0.41689757]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4266159]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.352963   0.36121029 0.37028414 0.37955147 0.38837484 0.39750984\n",
      "  0.40707192 0.41689757]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07437917590141296\n",
      "Predicción post entrenamiento : [[0.428997]]\n",
      "PERDIDAAAA despues: 0.07308606803417206\n",
      "loss en el callback: 0.05133621022105217, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36121029]\n",
      "  [0.37028414]\n",
      "  [0.37955147]\n",
      "  [0.38837484]\n",
      "  [0.39750984]\n",
      "  [0.40707192]\n",
      "  [0.41689757]\n",
      "  [0.42661589]]]\n",
      "ejemplar: [0.36121029 0.37028414 0.37955147 0.38837484 0.39750984 0.40707192\n",
      " 0.41689757 0.42661589]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43577334]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36121029 0.37028414 0.37955147 0.38837484 0.39750984 0.40707192\n",
      "  0.41689757 0.42661589]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09092503041028976\n",
      "Predicción post entrenamiento : [[0.43905148]]\n",
      "PERDIDAAAA despues: 0.08895881474018097\n",
      "loss en el callback: 0.11772342771291733, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.37028414]\n",
      "  [0.37955147]\n",
      "  [0.38837484]\n",
      "  [0.39750984]\n",
      "  [0.40707192]\n",
      "  [0.41689757]\n",
      "  [0.42661589]\n",
      "  [0.43577334]]]\n",
      "ejemplar: [0.37028414 0.37955147 0.38837484 0.39750984 0.40707192 0.41689757\n",
      " 0.42661589 0.43577334]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44608936]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.37028414 0.37955147 0.38837484 0.39750984 0.40707192 0.41689757\n",
      "  0.42661589 0.43577334]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07581017166376114\n",
      "Predicción post entrenamiento : [[0.44857386]]\n",
      "PERDIDAAAA despues: 0.07444819808006287\n",
      "loss en el callback: 0.05946749821305275, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37955147]\n",
      "  [0.38837484]\n",
      "  [0.39750984]\n",
      "  [0.40707192]\n",
      "  [0.41689757]\n",
      "  [0.42661589]\n",
      "  [0.43577334]\n",
      "  [0.44608936]]]\n",
      "ejemplar: [0.37955147 0.38837484 0.39750984 0.40707192 0.41689757 0.42661589\n",
      " 0.43577334 0.44608936]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45571408]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37955147 0.38837484 0.39750984 0.40707192 0.41689757 0.42661589\n",
      "  0.43577334 0.44608936]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06916879862546921\n",
      "Predicción post entrenamiento : [[0.45818052]]\n",
      "PERDIDAAAA despues: 0.06787753850221634\n",
      "loss en el callback: 0.06089793145656586, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38837484]\n",
      "  [0.39750984]\n",
      "  [0.40707192]\n",
      "  [0.41689757]\n",
      "  [0.42661589]\n",
      "  [0.43577334]\n",
      "  [0.44608936]\n",
      "  [0.45571408]]]\n",
      "ejemplar: [0.38837484 0.39750984 0.40707192 0.41689757 0.42661589 0.43577334\n",
      " 0.44608936 0.45571408]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4653977]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38837484 0.39750984 0.40707192 0.41689757 0.42661589 0.43577334\n",
      "  0.44608936 0.45571408]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04358058422803879\n",
      "Predicción post entrenamiento : [[0.4673092]]\n",
      "PERDIDAAAA despues: 0.042786143720149994\n",
      "loss en el callback: 0.037704408168792725, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39750984]\n",
      "  [0.40707192]\n",
      "  [0.41689757]\n",
      "  [0.42661589]\n",
      "  [0.43577334]\n",
      "  [0.44608936]\n",
      "  [0.45571408]\n",
      "  [0.46539769]]]\n",
      "ejemplar: [0.39750984 0.40707192 0.41689757 0.42661589 0.43577334 0.44608936\n",
      " 0.45571408 0.46539769]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47473636]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39750984 0.40707192 0.41689757 0.42661589 0.43577334 0.44608936\n",
      "  0.45571408 0.46539769]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05009990185499191\n",
      "Predicción post entrenamiento : [[0.47670916]]\n",
      "PERDIDAAAA despues: 0.049220651388168335\n",
      "loss en el callback: 0.0414697527885437, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40707192]\n",
      "  [0.41689757]\n",
      "  [0.42661589]\n",
      "  [0.43577334]\n",
      "  [0.44608936]\n",
      "  [0.45571408]\n",
      "  [0.46539769]\n",
      "  [0.47473636]]]\n",
      "ejemplar: [0.40707192 0.41689757 0.42661589 0.43577334 0.44608936 0.45571408\n",
      " 0.46539769 0.47473636]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.48430106]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40707192 0.41689757 0.42661589 0.43577334 0.44608936 0.45571408\n",
      "  0.46539769 0.47473636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05604454129934311\n",
      "Predicción post entrenamiento : [[0.4865879]]\n",
      "PERDIDAAAA despues: 0.0549670048058033\n",
      "loss en el callback: 0.05560997501015663, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41689757]\n",
      "  [0.42661589]\n",
      "  [0.43577334]\n",
      "  [0.44608936]\n",
      "  [0.45571408]\n",
      "  [0.46539769]\n",
      "  [0.47473636]\n",
      "  [0.48430106]]]\n",
      "ejemplar: [0.41689757 0.42661589 0.43577334 0.44608936 0.45571408 0.46539769\n",
      " 0.47473636 0.48430106]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49425372]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41689757 0.42661589 0.43577334 0.44608936 0.45571408 0.46539769\n",
      "  0.47473636 0.48430106]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05213659629225731\n",
      "Predicción post entrenamiento : [[0.4965658]]\n",
      "PERDIDAAAA despues: 0.05108609423041344\n",
      "loss en el callback: 0.06557710468769073, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42661589]\n",
      "  [0.43577334]\n",
      "  [0.44608936]\n",
      "  [0.45571408]\n",
      "  [0.46539769]\n",
      "  [0.47473636]\n",
      "  [0.48430106]\n",
      "  [0.49425372]]]\n",
      "ejemplar: [0.42661589 0.43577334 0.44608936 0.45571408 0.46539769 0.47473636\n",
      " 0.48430106 0.49425372]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.50423986]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42661589 0.43577334 0.44608936 0.45571408 0.46539769 0.47473636\n",
      "  0.48430106 0.49425372]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06353231519460678\n",
      "Predicción post entrenamiento : [[0.5063287]]\n",
      "PERDIDAAAA despues: 0.06248366832733154\n",
      "loss en el callback: 0.0483316145837307, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43577334]\n",
      "  [0.44608936]\n",
      "  [0.45571408]\n",
      "  [0.46539769]\n",
      "  [0.47473636]\n",
      "  [0.48430106]\n",
      "  [0.49425372]\n",
      "  [0.50423986]]]\n",
      "ejemplar: [0.43577334 0.44608936 0.45571408 0.46539769 0.47473636 0.48430106\n",
      " 0.49425372 0.50423986]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5140336]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43577334 0.44608936 0.45571408 0.46539769 0.47473636 0.48430106\n",
      "  0.49425372 0.50423986]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09831524640321732\n",
      "Predicción post entrenamiento : [[0.5163892]]\n",
      "PERDIDAAAA despues: 0.09684360027313232\n",
      "loss en el callback: 0.046513546258211136, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44608936]\n",
      "  [0.45571408]\n",
      "  [0.46539769]\n",
      "  [0.47473636]\n",
      "  [0.48430106]\n",
      "  [0.49425372]\n",
      "  [0.50423986]\n",
      "  [0.51403362]]]\n",
      "ejemplar: [0.44608936 0.45571408 0.46539769 0.47473636 0.48430106 0.49425372\n",
      " 0.50423986 0.51403362]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.52427626]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44608936 0.45571408 0.46539769 0.47473636 0.48430106 0.49425372\n",
      "  0.50423986 0.51403362]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09893914312124252\n",
      "Predicción post entrenamiento : [[0.5270432]]\n",
      "PERDIDAAAA despues: 0.09720612317323685\n",
      "loss en el callback: 0.08532834053039551, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45571408]\n",
      "  [0.46539769]\n",
      "  [0.47473636]\n",
      "  [0.48430106]\n",
      "  [0.49425372]\n",
      "  [0.50423986]\n",
      "  [0.51403362]\n",
      "  [0.52427626]]]\n",
      "ejemplar: [0.45571408 0.46539769 0.47473636 0.48430106 0.49425372 0.50423986\n",
      " 0.51403362 0.52427626]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5348306]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45571408 0.46539769 0.47473636 0.48430106 0.49425372 0.50423986\n",
      "  0.51403362 0.52427626]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06730664521455765\n",
      "Predicción post entrenamiento : [[0.5371521]]\n",
      "PERDIDAAAA despues: 0.06610745191574097\n",
      "loss en el callback: 0.0673815980553627, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46539769]\n",
      "  [0.47473636]\n",
      "  [0.48430106]\n",
      "  [0.49425372]\n",
      "  [0.50423986]\n",
      "  [0.51403362]\n",
      "  [0.52427626]\n",
      "  [0.53483057]]]\n",
      "ejemplar: [0.46539769 0.47473636 0.48430106 0.49425372 0.50423986 0.51403362\n",
      " 0.52427626 0.53483057]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.545011]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46539769 0.47473636 0.48430106 0.49425372 0.50423986 0.51403362\n",
      "  0.52427626 0.53483057]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057022444903850555\n",
      "Predicción post entrenamiento : [[0.54734176]]\n",
      "PERDIDAAAA despues: 0.05591472610831261\n",
      "loss en el callback: 0.06497989594936371, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47473636]\n",
      "  [0.48430106]\n",
      "  [0.49425372]\n",
      "  [0.50423986]\n",
      "  [0.51403362]\n",
      "  [0.52427626]\n",
      "  [0.53483057]\n",
      "  [0.54501098]]]\n",
      "ejemplar: [0.47473636 0.48430106 0.49425372 0.50423986 0.51403362 0.52427626\n",
      " 0.53483057 0.54501098]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5552769]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47473636 0.48430106 0.49425372 0.50423986 0.51403362 0.52427626\n",
      "  0.53483057 0.54501098]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04521685466170311\n",
      "Predicción post entrenamiento : [[0.556804]]\n",
      "PERDIDAAAA despues: 0.0445697195827961\n",
      "loss en el callback: 0.023066818714141846, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48430106]\n",
      "  [0.49425372]\n",
      "  [0.50423986]\n",
      "  [0.51403362]\n",
      "  [0.52427626]\n",
      "  [0.53483057]\n",
      "  [0.54501098]\n",
      "  [0.55527687]]]\n",
      "ejemplar: [0.48430106 0.49425372 0.50423986 0.51403362 0.52427626 0.53483057\n",
      " 0.54501098 0.55527687]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5649293]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48430106 0.49425372 0.50423986 0.51403362 0.52427626 0.53483057\n",
      "  0.54501098 0.55527687]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.048246268182992935\n",
      "Predicción post entrenamiento : [[0.5672585]]\n",
      "PERDIDAAAA despues: 0.047228485345840454\n",
      "loss en el callback: 0.07499697059392929, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49425372]\n",
      "  [0.50423986]\n",
      "  [0.51403362]\n",
      "  [0.52427626]\n",
      "  [0.53483057]\n",
      "  [0.54501098]\n",
      "  [0.55527687]\n",
      "  [0.56492931]]]\n",
      "ejemplar: [0.49425372 0.50423986 0.51403362 0.52427626 0.53483057 0.54501098\n",
      " 0.55527687 0.56492931]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5755504]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49425372 0.50423986 0.51403362 0.52427626 0.53483057 0.54501098\n",
      "  0.55527687 0.56492931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09191738069057465\n",
      "Predicción post entrenamiento : [[0.57790256]]\n",
      "PERDIDAAAA despues: 0.09049665182828903\n",
      "loss en el callback: 0.057910870760679245, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50423986]\n",
      "  [0.51403362]\n",
      "  [0.52427626]\n",
      "  [0.53483057]\n",
      "  [0.54501098]\n",
      "  [0.55527687]\n",
      "  [0.56492931]\n",
      "  [0.57555038]]]\n",
      "ejemplar: [0.50423986 0.51403362 0.52427626 0.53483057 0.54501098 0.55527687\n",
      " 0.56492931 0.57555038]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.58628243]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50423986 0.51403362 0.52427626 0.53483057 0.54501098 0.55527687\n",
      "  0.56492931 0.57555038]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08372178673744202\n",
      "Predicción post entrenamiento : [[0.58852553]]\n",
      "PERDIDAAAA despues: 0.08242874592542648\n",
      "loss en el callback: 0.05095123499631882, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51403362]\n",
      "  [0.52427626]\n",
      "  [0.53483057]\n",
      "  [0.54501098]\n",
      "  [0.55527687]\n",
      "  [0.56492931]\n",
      "  [0.57555038]\n",
      "  [0.58628243]]]\n",
      "ejemplar: [0.51403362 0.52427626 0.53483057 0.54501098 0.55527687 0.56492931\n",
      " 0.57555038 0.58628243]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5969979]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51403362 0.52427626 0.53483057 0.54501098 0.55527687 0.56492931\n",
      "  0.57555038 0.58628243]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06345253437757492\n",
      "Predicción post entrenamiento : [[0.5992543]]\n",
      "PERDIDAAAA despues: 0.06232086941599846\n",
      "loss en el callback: 0.06447537243366241, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52427626]\n",
      "  [0.53483057]\n",
      "  [0.54501098]\n",
      "  [0.55527687]\n",
      "  [0.56492931]\n",
      "  [0.57555038]\n",
      "  [0.58628243]\n",
      "  [0.59699792]]]\n",
      "ejemplar: [0.52427626 0.53483057 0.54501098 0.55527687 0.56492931 0.57555038\n",
      " 0.58628243 0.59699792]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6078896]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52427626 0.53483057 0.54501098 0.55527687 0.56492931 0.57555038\n",
      "  0.58628243 0.59699792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04426727443933487\n",
      "Predicción post entrenamiento : [[0.6103062]]\n",
      "PERDIDAAAA despues: 0.04325621575117111\n",
      "loss en el callback: 0.11796611547470093, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53483057]\n",
      "  [0.54501098]\n",
      "  [0.55527687]\n",
      "  [0.56492931]\n",
      "  [0.57555038]\n",
      "  [0.58628243]\n",
      "  [0.59699792]\n",
      "  [0.60788959]]]\n",
      "ejemplar: [0.53483057 0.54501098 0.55527687 0.56492931 0.57555038 0.58628243\n",
      " 0.59699792 0.60788959]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.61900955]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53483057 0.54501098 0.55527687 0.56492931 0.57555038 0.58628243\n",
      "  0.59699792 0.60788959]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04318157210946083\n",
      "Predicción post entrenamiento : [[0.6207837]]\n",
      "PERDIDAAAA despues: 0.04244738444685936\n",
      "loss en el callback: 0.039633553475141525, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54501098]\n",
      "  [0.55527687]\n",
      "  [0.56492931]\n",
      "  [0.57555038]\n",
      "  [0.58628243]\n",
      "  [0.59699792]\n",
      "  [0.60788959]\n",
      "  [0.61900955]]]\n",
      "ejemplar: [0.54501098 0.55527687 0.56492931 0.57555038 0.58628243 0.59699792\n",
      " 0.60788959 0.61900955]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.62948334]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54501098 0.55527687 0.56492931 0.57555038 0.58628243 0.59699792\n",
      "  0.60788959 0.61900955]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02429581619799137\n",
      "Predicción post entrenamiento : [[0.630513]]\n",
      "PERDIDAAAA despues: 0.023975884541869164\n",
      "loss en el callback: 0.012382209300994873, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55527687]\n",
      "  [0.56492931]\n",
      "  [0.57555038]\n",
      "  [0.58628243]\n",
      "  [0.59699792]\n",
      "  [0.60788959]\n",
      "  [0.61900955]\n",
      "  [0.62948334]]]\n",
      "ejemplar: [0.55527687 0.56492931 0.57555038 0.58628243 0.59699792 0.60788959\n",
      " 0.61900955 0.62948334]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.63932025]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55527687 0.56492931 0.57555038 0.58628243 0.59699792 0.60788959\n",
      "  0.61900955 0.62948334]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022472625598311424\n",
      "Predicción post entrenamiento : [[0.64101315]]\n",
      "PERDIDAAAA despues: 0.02196793258190155\n",
      "loss en el callback: 0.04608656093478203, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56492931]\n",
      "  [0.57555038]\n",
      "  [0.58628243]\n",
      "  [0.59699792]\n",
      "  [0.60788959]\n",
      "  [0.61900955]\n",
      "  [0.62948334]\n",
      "  [0.63932025]]]\n",
      "ejemplar: [0.56492931 0.57555038 0.58628243 0.59699792 0.60788959 0.61900955\n",
      " 0.62948334 0.63932025]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.64992887]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56492931 0.57555038 0.58628243 0.59699792 0.60788959 0.61900955\n",
      "  0.62948334 0.63932025]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03394582122564316\n",
      "Predicción post entrenamiento : [[0.6520539]]\n",
      "PERDIDAAAA despues: 0.033167291432619095\n",
      "loss en el callback: 0.08220137655735016, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57555038]\n",
      "  [0.58628243]\n",
      "  [0.59699792]\n",
      "  [0.60788959]\n",
      "  [0.61900955]\n",
      "  [0.62948334]\n",
      "  [0.63932025]\n",
      "  [0.64992887]]]\n",
      "ejemplar: [0.57555038 0.58628243 0.59699792 0.60788959 0.61900955 0.62948334\n",
      " 0.63932025 0.64992887]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6612695]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57555038 0.58628243 0.59699792 0.60788959 0.61900955 0.62948334\n",
      "  0.63932025 0.64992887]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022863348945975304\n",
      "Predicción post entrenamiento : [[0.6623039]]\n",
      "PERDIDAAAA despues: 0.02255159243941307\n",
      "loss en el callback: 0.013446860015392303, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58628243]\n",
      "  [0.59699792]\n",
      "  [0.60788959]\n",
      "  [0.61900955]\n",
      "  [0.62948334]\n",
      "  [0.63932025]\n",
      "  [0.64992887]\n",
      "  [0.66126949]]]\n",
      "ejemplar: [0.58628243 0.59699792 0.60788959 0.61900955 0.62948334 0.63932025\n",
      " 0.64992887 0.66126949]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6715808]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58628243 0.59699792 0.60788959 0.61900955 0.62948334 0.63932025\n",
      "  0.64992887 0.66126949]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016811471432447433\n",
      "Predicción post entrenamiento : [[0.6718902]]\n",
      "PERDIDAAAA despues: 0.01673133112490177\n",
      "loss en el callback: 0.0009916856652125716, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59699792]\n",
      "  [0.60788959]\n",
      "  [0.61900955]\n",
      "  [0.62948334]\n",
      "  [0.63932025]\n",
      "  [0.64992887]\n",
      "  [0.66126949]\n",
      "  [0.67158079]]]\n",
      "ejemplar: [0.59699792 0.60788959 0.61900955 0.62948334 0.63932025 0.64992887\n",
      " 0.66126949 0.67158079]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.68119174]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59699792 0.60788959 0.61900955 0.62948334 0.63932025 0.64992887\n",
      "  0.66126949 0.67158079]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014880417846143246\n",
      "Predicción post entrenamiento : [[0.68199766]]\n",
      "PERDIDAAAA despues: 0.014684447087347507\n",
      "loss en el callback: 0.008408237248659134, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60788959]\n",
      "  [0.61900955]\n",
      "  [0.62948334]\n",
      "  [0.63932025]\n",
      "  [0.64992887]\n",
      "  [0.66126949]\n",
      "  [0.67158079]\n",
      "  [0.68119174]]]\n",
      "ejemplar: [0.60788959 0.61900955 0.62948334 0.63932025 0.64992887 0.66126949\n",
      " 0.67158079 0.68119174]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.69131696]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60788959 0.61900955 0.62948334 0.63932025 0.64992887 0.66126949\n",
      "  0.67158079 0.68119174]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010439510457217693\n",
      "Predicción post entrenamiento : [[0.6911679]]\n",
      "PERDIDAAAA despues: 0.010469995439052582\n",
      "loss en el callback: 0.00023353694996330887, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61900955]\n",
      "  [0.62948334]\n",
      "  [0.63932025]\n",
      "  [0.64992887]\n",
      "  [0.66126949]\n",
      "  [0.67158079]\n",
      "  [0.68119174]\n",
      "  [0.69131696]]]\n",
      "ejemplar: [0.61900955 0.62948334 0.63932025 0.64992887 0.66126949 0.67158079\n",
      " 0.68119174 0.69131696]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.70043206]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61900955 0.62948334 0.63932025 0.64992887 0.66126949 0.67158079\n",
      "  0.68119174 0.69131696]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035686760675162077\n",
      "Predicción post entrenamiento : [[0.7013099]]\n",
      "PERDIDAAAA despues: 0.0034645632840692997\n",
      "loss en el callback: 0.012060761451721191, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62948334]\n",
      "  [0.63932025]\n",
      "  [0.64992887]\n",
      "  [0.66126949]\n",
      "  [0.67158079]\n",
      "  [0.68119174]\n",
      "  [0.69131696]\n",
      "  [0.70043206]]]\n",
      "ejemplar: [0.62948334 0.63932025 0.64992887 0.66126949 0.67158079 0.68119174\n",
      " 0.69131696 0.70043206]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7104215]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62948334 0.63932025 0.64992887 0.66126949 0.67158079 0.68119174\n",
      "  0.69131696 0.70043206]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006226228433661163\n",
      "Predicción post entrenamiento : [[0.71057445]]\n",
      "PERDIDAAAA despues: 0.0006150135304778814\n",
      "loss en el callback: 0.0003095921711064875, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63932025]\n",
      "  [0.64992887]\n",
      "  [0.66126949]\n",
      "  [0.67158079]\n",
      "  [0.68119174]\n",
      "  [0.69131696]\n",
      "  [0.70043206]\n",
      "  [0.7104215 ]]]\n",
      "ejemplar: [0.63932025 0.64992887 0.66126949 0.67158079 0.68119174 0.69131696\n",
      " 0.70043206 0.7104215 ]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7196679]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63932025 0.64992887 0.66126949 0.67158079 0.68119174 0.69131696\n",
      "  0.70043206 0.7104215 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.983423322206363e-05\n",
      "Predicción post entrenamiento : [[0.7202114]]\n",
      "PERDIDAAAA despues: 0.00010043181100627407\n",
      "loss en el callback: 0.005303708370774984, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.64992887]\n",
      "  [0.66126949]\n",
      "  [0.67158079]\n",
      "  [0.68119174]\n",
      "  [0.69131696]\n",
      "  [0.70043206]\n",
      "  [0.7104215 ]\n",
      "  [0.71966791]]]\n",
      "ejemplar: [0.64992887 0.66126949 0.67158079 0.68119174 0.69131696 0.70043206\n",
      " 0.7104215  0.71966791]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7294417]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.64992887 0.66126949 0.67158079 0.68119174 0.69131696 0.70043206\n",
      "  0.7104215  0.71966791]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00029979582177475095\n",
      "Predicción post entrenamiento : [[0.7283153]]\n",
      "PERDIDAAAA despues: 0.00026205796166323125\n",
      "loss en el callback: 0.014647691510617733, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.66126949]\n",
      "  [0.67158079]\n",
      "  [0.68119174]\n",
      "  [0.69131696]\n",
      "  [0.70043206]\n",
      "  [0.7104215 ]\n",
      "  [0.71966791]\n",
      "  [0.7294417 ]]]\n",
      "ejemplar: [0.66126949 0.67158079 0.68119174 0.69131696 0.70043206 0.7104215\n",
      " 0.71966791 0.7294417 ]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7374367]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.66126949 0.67158079 0.68119174 0.69131696 0.70043206 0.7104215\n",
      "  0.71966791 0.7294417 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.836099833482876e-06\n",
      "Predicción post entrenamiento : [[0.73773]]\n",
      "PERDIDAAAA despues: 3.632069592640619e-06\n",
      "loss en el callback: 0.0012293532490730286, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.67158079]\n",
      "  [0.68119174]\n",
      "  [0.69131696]\n",
      "  [0.70043206]\n",
      "  [0.7104215 ]\n",
      "  [0.71966791]\n",
      "  [0.7294417 ]\n",
      "  [0.73743671]]]\n",
      "ejemplar: [0.67158079 0.68119174 0.69131696 0.70043206 0.7104215  0.71966791\n",
      " 0.7294417  0.73743671]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.74647504]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.67158079 0.68119174 0.69131696 0.70043206 0.7104215  0.71966791\n",
      "  0.7294417  0.73743671]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010663177818059921\n",
      "Predicción post entrenamiento : [[0.7468415]]\n",
      "PERDIDAAAA despues: 0.0001143341651186347\n",
      "loss en el callback: 0.00206941831856966, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.68119174]\n",
      "  [0.69131696]\n",
      "  [0.70043206]\n",
      "  [0.7104215 ]\n",
      "  [0.71966791]\n",
      "  [0.7294417 ]\n",
      "  [0.73743671]\n",
      "  [0.74647504]]]\n",
      "ejemplar: [0.68119174 0.69131696 0.70043206 0.7104215  0.71966791 0.7294417\n",
      " 0.73743671 0.74647504]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7554173]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.68119174 0.69131696 0.70043206 0.7104215  0.71966791 0.7294417\n",
      "  0.73743671 0.74647504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0077170212753117085\n",
      "Predicción post entrenamiento : [[0.7545366]]\n",
      "PERDIDAAAA despues: 0.007563070859760046\n",
      "loss en el callback: 0.01142863743007183, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.69131696]\n",
      "  [0.70043206]\n",
      "  [0.7104215 ]\n",
      "  [0.71966791]\n",
      "  [0.7294417 ]\n",
      "  [0.73743671]\n",
      "  [0.74647504]\n",
      "  [0.75541729]]]\n",
      "ejemplar: [0.69131696 0.70043206 0.7104215  0.71966791 0.7294417  0.73743671\n",
      " 0.74647504 0.75541729]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7630884]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.69131696 0.70043206 0.7104215  0.71966791 0.7294417  0.73743671\n",
      "  0.74647504 0.75541729]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008684934116899967\n",
      "Predicción post entrenamiento : [[0.76149464]]\n",
      "PERDIDAAAA despues: 0.008390418253839016\n",
      "loss en el callback: 0.031020432710647583, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.70043206]\n",
      "  [0.7104215 ]\n",
      "  [0.71966791]\n",
      "  [0.7294417 ]\n",
      "  [0.73743671]\n",
      "  [0.74647504]\n",
      "  [0.75541729]\n",
      "  [0.76308841]]]\n",
      "ejemplar: [0.70043206 0.7104215  0.71966791 0.7294417  0.73743671 0.74647504\n",
      " 0.75541729 0.76308841]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7698293]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.70043206 0.7104215  0.71966791 0.7294417  0.73743671 0.74647504\n",
      "  0.75541729 0.76308841]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005358247086405754\n",
      "Predicción post entrenamiento : [[0.76910114]]\n",
      "PERDIDAAAA despues: 0.005252178758382797\n",
      "loss en el callback: 0.007524171844124794, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.7104215 ]\n",
      "  [0.71966791]\n",
      "  [0.7294417 ]\n",
      "  [0.73743671]\n",
      "  [0.74647504]\n",
      "  [0.75541729]\n",
      "  [0.76308841]\n",
      "  [0.76982927]]]\n",
      "ejemplar: [0.7104215  0.71966791 0.7294417  0.73743671 0.74647504 0.75541729\n",
      " 0.76308841 0.76982927]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7774409]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.7104215  0.71966791 0.7294417  0.73743671 0.74647504 0.75541729\n",
      "  0.76308841 0.76982927]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014760689809918404\n",
      "Predicción post entrenamiento : [[0.7773132]]\n",
      "PERDIDAAAA despues: 0.014729668386280537\n",
      "loss en el callback: 0.0003135543956886977, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71966791]\n",
      "  [0.7294417 ]\n",
      "  [0.73743671]\n",
      "  [0.74647504]\n",
      "  [0.75541729]\n",
      "  [0.76308841]\n",
      "  [0.76982927]\n",
      "  [0.77744091]]]\n",
      "ejemplar: [0.71966791 0.7294417  0.73743671 0.74647504 0.75541729 0.76308841\n",
      " 0.76982927 0.77744091]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7853478]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71966791 0.7294417  0.73743671 0.74647504 0.75541729 0.76308841\n",
      "  0.76982927 0.77744091]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011351018212735653\n",
      "Predicción post entrenamiento : [[0.7841882]]\n",
      "PERDIDAAAA despues: 0.011105271056294441\n",
      "loss en el callback: 0.019887801259756088, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.7294417 ]\n",
      "  [0.73743671]\n",
      "  [0.74647504]\n",
      "  [0.75541729]\n",
      "  [0.76308841]\n",
      "  [0.76982927]\n",
      "  [0.77744091]\n",
      "  [0.78534782]]]\n",
      "ejemplar: [0.7294417  0.73743671 0.74647504 0.75541729 0.76308841 0.76982927\n",
      " 0.77744091 0.78534782]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7920346]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.7294417  0.73743671 0.74647504 0.75541729 0.76308841 0.76982927\n",
      "  0.77744091 0.78534782]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013442105613648891\n",
      "Predicción post entrenamiento : [[0.7911619]]\n",
      "PERDIDAAAA despues: 0.013240497559309006\n",
      "loss en el callback: 0.010947959497570992, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.73743671]\n",
      "  [0.74647504]\n",
      "  [0.75541729]\n",
      "  [0.76308841]\n",
      "  [0.76982927]\n",
      "  [0.77744091]\n",
      "  [0.78534782]\n",
      "  [0.79203463]]]\n",
      "ejemplar: [0.73743671 0.74647504 0.75541729 0.76308841 0.76982927 0.77744091\n",
      " 0.78534782 0.79203463]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.79858494]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.73743671 0.74647504 0.75541729 0.76308841 0.76982927 0.77744091\n",
      "  0.78534782 0.79203463]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004764143377542496\n",
      "Predicción post entrenamiento : [[0.79803705]]\n",
      "PERDIDAAAA despues: 0.004688810557126999\n",
      "loss en el callback: 0.0042096711695194244, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.74647504]\n",
      "  [0.75541729]\n",
      "  [0.76308841]\n",
      "  [0.76982927]\n",
      "  [0.77744091]\n",
      "  [0.78534782]\n",
      "  [0.79203463]\n",
      "  [0.79858494]]]\n",
      "ejemplar: [0.74647504 0.75541729 0.76308841 0.76982927 0.77744091 0.78534782\n",
      " 0.79203463 0.79858494]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.80545557]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.74647504 0.75541729 0.76308841 0.76982927 0.77744091 0.78534782\n",
      "  0.79203463 0.79858494]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010852847248315811\n",
      "Predicción post entrenamiento : [[0.8043627]]\n",
      "PERDIDAAAA despues: 0.010626341216266155\n",
      "loss en el callback: 0.01693299226462841, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.75541729]\n",
      "  [0.76308841]\n",
      "  [0.76982927]\n",
      "  [0.77744091]\n",
      "  [0.78534782]\n",
      "  [0.79203463]\n",
      "  [0.79858494]\n",
      "  [0.80545557]]]\n",
      "ejemplar: [0.75541729 0.76308841 0.76982927 0.77744091 0.78534782 0.79203463\n",
      " 0.79858494 0.80545557]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8114157]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.75541729 0.76308841 0.76982927 0.77744091 0.78534782 0.79203463\n",
      "  0.79858494 0.80545557]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019257775275036693\n",
      "Predicción post entrenamiento : [[0.812127]]\n",
      "PERDIDAAAA despues: 0.0019887143280357122\n",
      "loss en el callback: 0.009813414886593819, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.76308841]\n",
      "  [0.76982927]\n",
      "  [0.77744091]\n",
      "  [0.78534782]\n",
      "  [0.79203463]\n",
      "  [0.79858494]\n",
      "  [0.80545557]\n",
      "  [0.81141567]]]\n",
      "ejemplar: [0.76308841 0.76982927 0.77744091 0.78534782 0.79203463 0.79858494\n",
      " 0.80545557 0.81141567]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.8187476]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.76308841 0.76982927 0.77744091 0.78534782 0.79203463 0.79858494\n",
      "  0.80545557 0.81141567]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0040467269718647\n",
      "Predicción post entrenamiento : [[0.81925905]]\n",
      "PERDIDAAAA despues: 0.004112061578780413\n",
      "loss en el callback: 0.0054141078144311905, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.76982927]\n",
      "  [0.77744091]\n",
      "  [0.78534782]\n",
      "  [0.79203463]\n",
      "  [0.79858494]\n",
      "  [0.80545557]\n",
      "  [0.81141567]\n",
      "  [0.81874758]]]\n",
      "ejemplar: [0.76982927 0.77744091 0.78534782 0.79203463 0.79858494 0.80545557\n",
      " 0.81141567 0.81874758]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8257328]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.76982927 0.77744091 0.78534782 0.79203463 0.79858494 0.80545557\n",
      "  0.81141567 0.81874758]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006508100777864456\n",
      "Predicción post entrenamiento : [[0.8257228]]\n",
      "PERDIDAAAA despues: 0.006506485398858786\n",
      "loss en el callback: 1.7730726540321484e-06, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.77744091]\n",
      "  [0.78534782]\n",
      "  [0.79203463]\n",
      "  [0.79858494]\n",
      "  [0.80545557]\n",
      "  [0.81141567]\n",
      "  [0.81874758]\n",
      "  [0.82573283]]]\n",
      "ejemplar: [0.77744091 0.78534782 0.79203463 0.79858494 0.80545557 0.81141567\n",
      " 0.81874758 0.82573283]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8322866]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.77744091 0.78534782 0.79203463 0.79858494 0.80545557 0.81141567\n",
      "  0.81874758 0.82573283]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00644046813249588\n",
      "Predicción post entrenamiento : [[0.83033454]]\n",
      "PERDIDAAAA despues: 0.006130964495241642\n",
      "loss en el callback: 0.04727385938167572, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.78534782]\n",
      "  [0.79203463]\n",
      "  [0.79858494]\n",
      "  [0.80545557]\n",
      "  [0.81141567]\n",
      "  [0.81874758]\n",
      "  [0.82573283]\n",
      "  [0.8322866 ]]]\n",
      "ejemplar: [0.78534782 0.79203463 0.79858494 0.80545557 0.81141567 0.81874758\n",
      " 0.82573283 0.8322866 ]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8367152]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.78534782 0.79203463 0.79858494 0.80545557 0.81141567 0.81874758\n",
      "  0.82573283 0.8322866 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01610686630010605\n",
      "Predicción post entrenamiento : [[0.8352781]]\n",
      "PERDIDAAAA despues: 0.015744151547551155\n",
      "loss en el callback: 0.029348691925406456, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.79203463]\n",
      "  [0.79858494]\n",
      "  [0.80545557]\n",
      "  [0.81141567]\n",
      "  [0.81874758]\n",
      "  [0.82573283]\n",
      "  [0.8322866 ]\n",
      "  [0.83671522]]]\n",
      "ejemplar: [0.79203463 0.79858494 0.80545557 0.81141567 0.81874758 0.82573283\n",
      " 0.8322866  0.83671522]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.84133357]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.79203463 0.79858494 0.80545557 0.81141567 0.81874758 0.82573283\n",
      "  0.8322866  0.83671522]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022771872580051422\n",
      "Predicción post entrenamiento : [[0.8405111]]\n",
      "PERDIDAAAA despues: 0.022524317726492882\n",
      "loss en el callback: 0.011052433401346207, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.79858494]\n",
      "  [0.80545557]\n",
      "  [0.81141567]\n",
      "  [0.81874758]\n",
      "  [0.82573283]\n",
      "  [0.8322866 ]\n",
      "  [0.83671522]\n",
      "  [0.84133357]]]\n",
      "ejemplar: [0.79858494 0.80545557 0.81141567 0.81874758 0.82573283 0.8322866\n",
      " 0.83671522 0.84133357]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8465288]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.79858494 0.80545557 0.81141567 0.81874758 0.82573283 0.8322866\n",
      "  0.83671522 0.84133357]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00849531963467598\n",
      "Predicción post entrenamiento : [[0.84591025]]\n",
      "PERDIDAAAA despues: 0.008381674066185951\n",
      "loss en el callback: 0.006501899100840092, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.80545557]\n",
      "  [0.81141567]\n",
      "  [0.81874758]\n",
      "  [0.82573283]\n",
      "  [0.8322866 ]\n",
      "  [0.83671522]\n",
      "  [0.84133357]\n",
      "  [0.84652883]]]\n",
      "ejemplar: [0.80545557 0.81141567 0.81874758 0.82573283 0.8322866  0.83671522\n",
      " 0.84133357 0.84652883]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.85188586]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.80545557 0.81141567 0.81874758 0.82573283 0.8322866  0.83671522\n",
      "  0.84133357 0.84652883]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016818242147564888\n",
      "Predicción post entrenamiento : [[0.85068893]]\n",
      "PERDIDAAAA despues: 0.016509229317307472\n",
      "loss en el callback: 0.021536149084568024, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.81141567]\n",
      "  [0.81874758]\n",
      "  [0.82573283]\n",
      "  [0.8322866 ]\n",
      "  [0.83671522]\n",
      "  [0.84133357]\n",
      "  [0.84652883]\n",
      "  [0.85188586]]]\n",
      "ejemplar: [0.81141567 0.81874758 0.82573283 0.8322866  0.83671522 0.84133357\n",
      " 0.84652883 0.85188586]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.85646987]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.81141567 0.81874758 0.82573283 0.8322866  0.83671522 0.84133357\n",
      "  0.84652883 0.85188586]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.338566890917718e-05\n",
      "Predicción post entrenamiento : [[0.8558105]]\n",
      "PERDIDAAAA despues: 5.332161526894197e-05\n",
      "loss en el callback: 0.006346427369862795, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.81874758]\n",
      "  [0.82573283]\n",
      "  [0.8322866 ]\n",
      "  [0.83671522]\n",
      "  [0.84133357]\n",
      "  [0.84652883]\n",
      "  [0.85188586]\n",
      "  [0.85646987]]]\n",
      "ejemplar: [0.81874758 0.82573283 0.8322866  0.83671522 0.84133357 0.84652883\n",
      " 0.85188586 0.85646987]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8615907]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.81874758 0.82573283 0.8322866  0.83671522 0.84133357 0.84652883\n",
      "  0.85188586 0.85646987]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019247784512117505\n",
      "Predicción post entrenamiento : [[0.8625821]]\n",
      "PERDIDAAAA despues: 0.001838770927861333\n",
      "loss en el callback: 0.018154464662075043, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.82573283]\n",
      "  [0.8322866 ]\n",
      "  [0.83671522]\n",
      "  [0.84133357]\n",
      "  [0.84652883]\n",
      "  [0.85188586]\n",
      "  [0.85646987]\n",
      "  [0.86159068]]]\n",
      "ejemplar: [0.82573283 0.8322866  0.83671522 0.84133357 0.84652883 0.85188586\n",
      " 0.85646987 0.86159068]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.86789626]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.82573283 0.8322866  0.83671522 0.84133357 0.84652883 0.85188586\n",
      "  0.85646987 0.86159068]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020506115106400102\n",
      "Predicción post entrenamiento : [[0.8678812]]\n",
      "PERDIDAAAA despues: 0.00020549327018670738\n",
      "loss en el callback: 3.7228235214570304e-06, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.8322866 ]\n",
      "  [0.83671522]\n",
      "  [0.84133357]\n",
      "  [0.84652883]\n",
      "  [0.85188586]\n",
      "  [0.85646987]\n",
      "  [0.86159068]\n",
      "  [0.86789626]]]\n",
      "ejemplar: [0.8322866  0.83671522 0.84133357 0.84652883 0.85188586 0.85646987\n",
      " 0.86159068 0.86789626]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8727292]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.8322866  0.83671522 0.84133357 0.84652883 0.85188586 0.85646987\n",
      "  0.86159068 0.86789626]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012290982995182276\n",
      "Predicción post entrenamiento : [[0.87386155]]\n",
      "PERDIDAAAA despues: 0.0011509822215884924\n",
      "loss en el callback: 0.02580149471759796, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.83671522]\n",
      "  [0.84133357]\n",
      "  [0.84652883]\n",
      "  [0.85188586]\n",
      "  [0.85646987]\n",
      "  [0.86159068]\n",
      "  [0.86789626]\n",
      "  [0.87272918]]]\n",
      "ejemplar: [0.83671522 0.84133357 0.84652883 0.85188586 0.85646987 0.86159068\n",
      " 0.86789626 0.87272918]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.87829685]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.83671522 0.84133357 0.84652883 0.85188586 0.85646987 0.86159068\n",
      "  0.86789626 0.87272918]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012725722626782954\n",
      "Predicción post entrenamiento : [[0.8785025]]\n",
      "PERDIDAAAA despues: 0.00012266002886462957\n",
      "loss en el callback: 0.0007242703577503562, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.84133357]\n",
      "  [0.84652883]\n",
      "  [0.85188586]\n",
      "  [0.85646987]\n",
      "  [0.86159068]\n",
      "  [0.86789626]\n",
      "  [0.87272918]\n",
      "  [0.87829685]]]\n",
      "ejemplar: [0.84133357 0.84652883 0.85188586 0.85646987 0.86159068 0.86789626\n",
      " 0.87272918 0.87829685]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.88312]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.84133357 0.84652883 0.85188586 0.85646987 0.86159068 0.86789626\n",
      "  0.87272918 0.87829685]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.83154576108791e-05\n",
      "Predicción post entrenamiento : [[0.8833883]]\n",
      "PERDIDAAAA despues: 7.282228034455329e-05\n",
      "loss en el callback: 0.0013082262594252825, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.84652883]\n",
      "  [0.85188586]\n",
      "  [0.85646987]\n",
      "  [0.86159068]\n",
      "  [0.86789626]\n",
      "  [0.87272918]\n",
      "  [0.87829685]\n",
      "  [0.88312   ]]]\n",
      "ejemplar: [0.84652883 0.85188586 0.85646987 0.86159068 0.86789626 0.87272918\n",
      " 0.87829685 0.88312   ]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8881695]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.84652883 0.85188586 0.85646987 0.86159068 0.86789626 0.87272918\n",
      "  0.87829685 0.88312   ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000627122528385371\n",
      "Predicción post entrenamiento : [[0.8872677]]\n",
      "PERDIDAAAA despues: 0.0006731032044626772\n",
      "loss en el callback: 0.011050578206777573, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.85188586]\n",
      "  [0.85646987]\n",
      "  [0.86159068]\n",
      "  [0.86789626]\n",
      "  [0.87272918]\n",
      "  [0.87829685]\n",
      "  [0.88312   ]\n",
      "  [0.88816953]]]\n",
      "ejemplar: [0.85188586 0.85646987 0.86159068 0.86789626 0.87272918 0.87829685\n",
      " 0.88312    0.88816953]\n",
      "y: 1.0\n",
      "Predicción : [[0.89206254]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.85188586 0.85646987 0.86159068 0.86789626 0.87272918 0.87829685\n",
      "  0.88312    0.88816953]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011650494299829006\n",
      "Predicción post entrenamiento : [[0.89372736]]\n",
      "PERDIDAAAA despues: 0.011293873190879822\n",
      "loss en el callback: 0.07328870892524719, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.85646987]\n",
      "  [0.86159068]\n",
      "  [0.86789626]\n",
      "  [0.87272918]\n",
      "  [0.87829685]\n",
      "  [0.88312   ]\n",
      "  [0.88816953]\n",
      "  [0.89206254]]]\n",
      "ejemplar: [0.85646987 0.86159068 0.86789626 0.87272918 0.87829685 0.88312\n",
      " 0.88816953 0.89206254]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.89848506]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.85646987 0.86159068 0.86789626 0.87272918 0.87829685 0.88312\n",
      "  0.88816953 0.89206254]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005193939432501793\n",
      "Predicción post entrenamiento : [[0.8994378]]\n",
      "PERDIDAAAA despues: 0.005057523492723703\n",
      "loss en el callback: 0.017692048102617264, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.86159068]\n",
      "  [0.86789626]\n",
      "  [0.87272918]\n",
      "  [0.87829685]\n",
      "  [0.88312   ]\n",
      "  [0.88816953]\n",
      "  [0.89206254]\n",
      "  [0.89848506]]]\n",
      "ejemplar: [0.86159068 0.86789626 0.87272918 0.87829685 0.88312    0.88816953\n",
      " 0.89206254 0.89848506]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.9043826]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.86159068 0.86789626 0.87272918 0.87829685 0.88312    0.88816953\n",
      "  0.89206254 0.89848506]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002427307772450149\n",
      "Predicción post entrenamiento : [[0.9043353]]\n",
      "PERDIDAAAA despues: 0.00024126020434778184\n",
      "loss en el callback: 4.2023344576591626e-05, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.86789626]\n",
      "  [0.87272918]\n",
      "  [0.87829685]\n",
      "  [0.88312   ]\n",
      "  [0.88816953]\n",
      "  [0.89206254]\n",
      "  [0.89848506]\n",
      "  [0.90438259]]]\n",
      "ejemplar: [0.86789626 0.87272918 0.87829685 0.88312    0.88816953 0.89206254\n",
      " 0.89848506 0.90438259]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.90932494]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.86789626 0.87272918 0.87829685 0.88312    0.88816953 0.89206254\n",
      "  0.89848506 0.90438259]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009841170394793153\n",
      "Predicción post entrenamiento : [[0.9096392]]\n",
      "PERDIDAAAA despues: 0.001003931276500225\n",
      "loss en el callback: 0.002081523882225156, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.87272918]\n",
      "  [0.87829685]\n",
      "  [0.88312   ]\n",
      "  [0.88816953]\n",
      "  [0.89206254]\n",
      "  [0.89848506]\n",
      "  [0.90438259]\n",
      "  [0.90932494]]]\n",
      "ejemplar: [0.87272918 0.87829685 0.88312    0.88816953 0.89206254 0.89848506\n",
      " 0.90438259 0.90932494]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9143132]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.87272918 0.87829685 0.88312    0.88816953 0.89206254 0.89848506\n",
      "  0.90438259 0.90932494]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042794374749064445\n",
      "Predicción post entrenamiento : [[0.9135095]]\n",
      "PERDIDAAAA despues: 0.004174930043518543\n",
      "loss en el callback: 0.011239059269428253, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.87829685]\n",
      "  [0.88312   ]\n",
      "  [0.88816953]\n",
      "  [0.89206254]\n",
      "  [0.89848506]\n",
      "  [0.90438259]\n",
      "  [0.90932494]\n",
      "  [0.9143132 ]]]\n",
      "ejemplar: [0.87829685 0.88312    0.88816953 0.89206254 0.89848506 0.90438259\n",
      " 0.90932494 0.9143132 ]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.91827303]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.87829685 0.88312    0.88816953 0.89206254 0.89848506 0.90438259\n",
      "  0.90932494 0.9143132 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007072851527482271\n",
      "Predicción post entrenamiento : [[0.9177148]]\n",
      "PERDIDAAAA despues: 0.006979263853281736\n",
      "loss en el callback: 0.006161609198898077, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.88312   ]\n",
      "  [0.88816953]\n",
      "  [0.89206254]\n",
      "  [0.89848506]\n",
      "  [0.90438259]\n",
      "  [0.90932494]\n",
      "  [0.9143132 ]\n",
      "  [0.91827303]]]\n",
      "ejemplar: [0.88312    0.88816953 0.89206254 0.89848506 0.90438259 0.90932494\n",
      " 0.9143132  0.91827303]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9223558]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.88312    0.88816953 0.89206254 0.89848506 0.90438259 0.90932494\n",
      "  0.9143132  0.91827303]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004524023272097111\n",
      "Predicción post entrenamiento : [[0.9225712]]\n",
      "PERDIDAAAA despues: 0.004553047474473715\n",
      "loss en el callback: 0.0011129057966172695, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.88816953]\n",
      "  [0.89206254]\n",
      "  [0.89848506]\n",
      "  [0.90438259]\n",
      "  [0.90932494]\n",
      "  [0.9143132 ]\n",
      "  [0.91827303]\n",
      "  [0.92235577]]]\n",
      "ejemplar: [0.88816953 0.89206254 0.89848506 0.90438259 0.90932494 0.9143132\n",
      " 0.91827303 0.92235577]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.927292]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.88816953 0.89206254 0.89848506 0.90438259 0.90932494 0.9143132\n",
      "  0.91827303 0.92235577]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027091833762824535\n",
      "Predicción post entrenamiento : [[0.92755914]]\n",
      "PERDIDAAAA despues: 0.0027370646130293608\n",
      "loss en el callback: 0.0014982009306550026, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.89206254]\n",
      "  [0.89848506]\n",
      "  [0.90438259]\n",
      "  [0.90932494]\n",
      "  [0.9143132 ]\n",
      "  [0.91827303]\n",
      "  [0.92235577]\n",
      "  [0.92729199]]]\n",
      "ejemplar: [0.89206254 0.89848506 0.90438259 0.90932494 0.9143132  0.91827303\n",
      " 0.92235577 0.92729199]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.93228793]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.89206254 0.89848506 0.90438259 0.90932494 0.9143132  0.91827303\n",
      "  0.92235577 0.92729199]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0056634279899299145\n",
      "Predicción post entrenamiento : [[0.9324194]]\n",
      "PERDIDAAAA despues: 0.005683235824108124\n",
      "loss en el callback: 0.0003949844394810498, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.89848506]\n",
      "  [0.90438259]\n",
      "  [0.90932494]\n",
      "  [0.9143132 ]\n",
      "  [0.91827303]\n",
      "  [0.92235577]\n",
      "  [0.92729199]\n",
      "  [0.93228793]]]\n",
      "ejemplar: [0.89848506 0.90438259 0.90932494 0.9143132  0.91827303 0.92235577\n",
      " 0.92729199 0.93228793]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.93749166]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.89848506 0.90438259 0.90932494 0.9143132  0.91827303 0.92235577\n",
      "  0.92729199 0.93228793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007644619792699814\n",
      "Predicción post entrenamiento : [[0.9363569]]\n",
      "PERDIDAAAA despues: 0.007447476498782635\n",
      "loss en el callback: 0.023271769285202026, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.90438259]\n",
      "  [0.90932494]\n",
      "  [0.9143132 ]\n",
      "  [0.91827303]\n",
      "  [0.92235577]\n",
      "  [0.92729199]\n",
      "  [0.93228793]\n",
      "  [0.93749166]]]\n",
      "ejemplar: [0.90438259 0.90932494 0.9143132  0.91827303 0.92235577 0.92729199\n",
      " 0.93228793 0.93749166]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.94101703]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.90438259 0.90932494 0.9143132  0.91827303 0.92235577 0.92729199\n",
      "  0.93228793 0.93749166]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009666905738413334\n",
      "Predicción post entrenamiento : [[0.941806]]\n",
      "PERDIDAAAA despues: 0.00982267502695322\n",
      "loss en el callback: 0.023023929446935654, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.90932494]\n",
      "  [0.9143132 ]\n",
      "  [0.91827303]\n",
      "  [0.92235577]\n",
      "  [0.92729199]\n",
      "  [0.93228793]\n",
      "  [0.93749166]\n",
      "  [0.94101703]]]\n",
      "ejemplar: [0.90932494 0.9143132  0.91827303 0.92235577 0.92729199 0.93228793\n",
      " 0.93749166 0.94101703]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9461334]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.90932494 0.9143132  0.91827303 0.92235577 0.92729199 0.93228793\n",
      "  0.93749166 0.94101703]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015177387744188309\n",
      "Predicción post entrenamiento : [[0.94415045]]\n",
      "PERDIDAAAA despues: 0.014692740514874458\n",
      "loss en el callback: 0.06479086726903915, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.9143132 ]\n",
      "  [0.91827303]\n",
      "  [0.92235577]\n",
      "  [0.92729199]\n",
      "  [0.93228793]\n",
      "  [0.93749166]\n",
      "  [0.94101703]\n",
      "  [0.94613338]]]\n",
      "ejemplar: [0.9143132  0.91827303 0.92235577 0.92729199 0.93228793 0.93749166\n",
      " 0.94101703 0.94613338]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.94837815]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.9143132  0.91827303 0.92235577 0.92729199 0.93228793 0.93749166\n",
      "  0.94101703 0.94613338]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03023151122033596\n",
      "Predicción post entrenamiento : [[0.9467529]]\n",
      "PERDIDAAAA despues: 0.029668984934687614\n",
      "loss en el callback: 0.048350825905799866, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.91827303]\n",
      "  [0.92235577]\n",
      "  [0.92729199]\n",
      "  [0.93228793]\n",
      "  [0.93749166]\n",
      "  [0.94101703]\n",
      "  [0.94613338]\n",
      "  [0.94837815]]]\n",
      "ejemplar: [0.91827303 0.92235577 0.92729199 0.93228793 0.93749166 0.94101703\n",
      " 0.94613338 0.94837815]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9508419]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.91827303 0.92235577 0.92729199 0.93228793 0.93749166 0.94101703\n",
      "  0.94613338 0.94837815]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027772141620516777\n",
      "Predicción post entrenamiento : [[0.9496492]]\n",
      "PERDIDAAAA despues: 0.027376042678952217\n",
      "loss en el callback: 0.02713363990187645, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.92235577]\n",
      "  [0.92729199]\n",
      "  [0.93228793]\n",
      "  [0.93749166]\n",
      "  [0.94101703]\n",
      "  [0.94613338]\n",
      "  [0.94837815]\n",
      "  [0.9508419 ]]]\n",
      "ejemplar: [0.92235577 0.92729199 0.93228793 0.93749166 0.94101703 0.94613338\n",
      " 0.94837815 0.9508419 ]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9538722]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.92235577 0.92729199 0.93228793 0.93749166 0.94101703 0.94613338\n",
      "  0.94837815 0.9508419 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008860060013830662\n",
      "Predicción post entrenamiento : [[0.9518957]]\n",
      "PERDIDAAAA despues: 0.0084918811917305\n",
      "loss en el callback: 0.05871976166963577, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.92729199]\n",
      "  [0.93228793]\n",
      "  [0.93749166]\n",
      "  [0.94101703]\n",
      "  [0.94613338]\n",
      "  [0.94837815]\n",
      "  [0.9508419 ]\n",
      "  [0.9538722 ]]]\n",
      "ejemplar: [0.92729199 0.93228793 0.93749166 0.94101703 0.94613338 0.94837815\n",
      " 0.9508419  0.9538722 ]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.95619106]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.92729199 0.93228793 0.93749166 0.94101703 0.94613338 0.94837815\n",
      "  0.9508419  0.9538722 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010377703234553337\n",
      "Predicción post entrenamiento : [[0.9535957]]\n",
      "PERDIDAAAA despues: 0.009855654090642929\n",
      "loss en el callback: 0.09716453403234482, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.93228793]\n",
      "  [0.93749166]\n",
      "  [0.94101703]\n",
      "  [0.94613338]\n",
      "  [0.94837815]\n",
      "  [0.9508419 ]\n",
      "  [0.9538722 ]\n",
      "  [0.95619106]]]\n",
      "ejemplar: [0.93228793 0.93749166 0.94101703 0.94613338 0.94837815 0.9508419\n",
      " 0.9538722  0.95619106]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9576479]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.93228793 0.93749166 0.94101703 0.94613338 0.94837815 0.9508419\n",
      "  0.9538722  0.95619106]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014583703130483627\n",
      "Predicción post entrenamiento : [[0.9567287]]\n",
      "PERDIDAAAA despues: 0.014362531714141369\n",
      "loss en el callback: 0.018491195514798164, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.93749166]\n",
      "  [0.94101703]\n",
      "  [0.94613338]\n",
      "  [0.94837815]\n",
      "  [0.9508419 ]\n",
      "  [0.9538722 ]\n",
      "  [0.95619106]\n",
      "  [0.95764792]]]\n",
      "ejemplar: [0.93749166 0.94101703 0.94613338 0.94837815 0.9508419  0.9538722\n",
      " 0.95619106 0.95764792]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.96041214]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.93749166 0.94101703 0.94613338 0.94837815 0.9508419  0.9538722\n",
      "  0.95619106 0.95764792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017030581831932068\n",
      "Predicción post entrenamiento : [[0.9596829]]\n",
      "PERDIDAAAA despues: 0.016840774565935135\n",
      "loss en el callback: 0.012237580493092537, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.94101703]\n",
      "  [0.94613338]\n",
      "  [0.94837815]\n",
      "  [0.9508419 ]\n",
      "  [0.9538722 ]\n",
      "  [0.95619106]\n",
      "  [0.95764792]\n",
      "  [0.96041214]]]\n",
      "ejemplar: [0.94101703 0.94613338 0.94837815 0.9508419  0.9538722  0.95619106\n",
      " 0.95764792 0.96041214]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.96281254]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.94101703 0.94613338 0.94837815 0.9508419  0.9538722  0.95619106\n",
      "  0.95764792 0.96041214]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0057092467322945595\n",
      "Predicción post entrenamiento : [[0.96178746]]\n",
      "PERDIDAAAA despues: 0.005555388052016497\n",
      "loss en el callback: 0.020095473155379295, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.94613338]\n",
      "  [0.94837815]\n",
      "  [0.9508419 ]\n",
      "  [0.9538722 ]\n",
      "  [0.95619106]\n",
      "  [0.95764792]\n",
      "  [0.96041214]\n",
      "  [0.96281254]]]\n",
      "ejemplar: [0.94613338 0.94837815 0.9508419  0.9538722  0.95619106 0.95764792\n",
      " 0.96041214 0.96281254]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.96474683]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.94613338 0.94837815 0.9508419  0.9538722  0.95619106 0.95764792\n",
      "  0.96041214 0.96281254]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011025529354810715\n",
      "Predicción post entrenamiento : [[0.9645908]]\n",
      "PERDIDAAAA despues: 0.010992784053087234\n",
      "loss en el callback: 0.0006692273891530931, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.94837815]\n",
      "  [0.9508419 ]\n",
      "  [0.9538722 ]\n",
      "  [0.95619106]\n",
      "  [0.95764792]\n",
      "  [0.96041214]\n",
      "  [0.96281254]\n",
      "  [0.96474683]]]\n",
      "ejemplar: [0.94837815 0.9508419  0.9538722  0.95619106 0.95764792 0.96041214\n",
      " 0.96281254 0.96474683]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9668266]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.94837815 0.9508419  0.9538722  0.95619106 0.95764792 0.96041214\n",
      "  0.96281254 0.96474683]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016187364235520363\n",
      "Predicción post entrenamiento : [[0.96493036]]\n",
      "PERDIDAAAA despues: 0.01570843905210495\n",
      "loss en el callback: 0.06566324830055237, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.9508419 ]\n",
      "  [0.9538722 ]\n",
      "  [0.95619106]\n",
      "  [0.95764792]\n",
      "  [0.96041214]\n",
      "  [0.96281254]\n",
      "  [0.96474683]\n",
      "  [0.96682662]]]\n",
      "ejemplar: [0.9508419  0.9538722  0.95619106 0.95764792 0.96041214 0.96281254\n",
      " 0.96474683 0.96682662]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9671999]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.9508419  0.9538722  0.95619106 0.95764792 0.96041214 0.96281254\n",
      "  0.96474683 0.96682662]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03363380208611488\n",
      "Predicción post entrenamiento : [[0.96603847]]\n",
      "PERDIDAAAA despues: 0.033209141343832016\n",
      "loss en el callback: 0.028318019583821297, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.9538722 ]\n",
      "  [0.95619106]\n",
      "  [0.95764792]\n",
      "  [0.96041214]\n",
      "  [0.96281254]\n",
      "  [0.96474683]\n",
      "  [0.96682662]\n",
      "  [0.96719992]]]\n",
      "ejemplar: [0.9538722  0.95619106 0.95764792 0.96041214 0.96281254 0.96474683\n",
      " 0.96682662 0.96719992]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.96825844]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.9538722  0.95619106 0.95764792 0.96041214 0.96281254 0.96474683\n",
      "  0.96682662 0.96719992]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02249128557741642\n",
      "Predicción post entrenamiento : [[0.9671515]]\n",
      "PERDIDAAAA despues: 0.022160500288009644\n",
      "loss en el callback: 0.02921104244887829, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.95619106]\n",
      "  [0.95764792]\n",
      "  [0.96041214]\n",
      "  [0.96281254]\n",
      "  [0.96474683]\n",
      "  [0.96682662]\n",
      "  [0.96719992]\n",
      "  [0.96825844]]]\n",
      "ejemplar: [0.95619106 0.95764792 0.96041214 0.96281254 0.96474683 0.96682662\n",
      " 0.96719992 0.96825844]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.96910894]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.95619106 0.95764792 0.96041214 0.96281254 0.96474683 0.96682662\n",
      "  0.96719992 0.96825844]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031663622707128525\n",
      "Predicción post entrenamiento : [[0.96827966]]\n",
      "PERDIDAAAA despues: 0.03136918321251869\n",
      "loss en el callback: 0.01575649529695511, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.95764792]\n",
      "  [0.96041214]\n",
      "  [0.96281254]\n",
      "  [0.96474683]\n",
      "  [0.96682662]\n",
      "  [0.96719992]\n",
      "  [0.96825844]\n",
      "  [0.96910894]]]\n",
      "ejemplar: [0.95764792 0.96041214 0.96281254 0.96474683 0.96682662 0.96719992\n",
      " 0.96825844 0.96910894]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9701223]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.95764792 0.96041214 0.96281254 0.96474683 0.96682662 0.96719992\n",
      "  0.96825844 0.96910894]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0439172089099884\n",
      "Predicción post entrenamiento : [[0.9677824]]\n",
      "PERDIDAAAA despues: 0.04294196516275406\n",
      "loss en el callback: 0.10800216346979141, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.96041214]\n",
      "  [0.96281254]\n",
      "  [0.96474683]\n",
      "  [0.96682662]\n",
      "  [0.96719992]\n",
      "  [0.96825844]\n",
      "  [0.96910894]\n",
      "  [0.97012228]]]\n",
      "ejemplar: [0.96041214 0.96281254 0.96474683 0.96682662 0.96719992 0.96825844\n",
      " 0.96910894 0.97012228]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.96972114]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.96041214 0.96281254 0.96474683 0.96682662 0.96719992 0.96825844\n",
      "  0.96910894 0.97012228]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031743645668029785\n",
      "Predicción post entrenamiento : [[0.9691468]]\n",
      "PERDIDAAAA despues: 0.03153931349515915\n",
      "loss en el callback: 0.00863725133240223, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.96281254]\n",
      "  [0.96474683]\n",
      "  [0.96682662]\n",
      "  [0.96719992]\n",
      "  [0.96825844]\n",
      "  [0.96910894]\n",
      "  [0.97012228]\n",
      "  [0.96972114]]]\n",
      "ejemplar: [0.96281254 0.96474683 0.96682662 0.96719992 0.96825844 0.96910894\n",
      " 0.97012228 0.96972114]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9707439]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.96281254 0.96474683 0.96682662 0.96719992 0.96825844 0.96910894\n",
      "  0.97012228 0.96972114]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040824044495821\n",
      "Predicción post entrenamiento : [[0.9687909]]\n",
      "PERDIDAAAA despues: 0.04003865271806717\n",
      "loss en el callback: 0.0795912817120552, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.96474683]\n",
      "  [0.96682662]\n",
      "  [0.96719992]\n",
      "  [0.96825844]\n",
      "  [0.96910894]\n",
      "  [0.97012228]\n",
      "  [0.96972114]\n",
      "  [0.97074389]]]\n",
      "ejemplar: [0.96474683 0.96682662 0.96719992 0.96825844 0.96910894 0.97012228\n",
      " 0.96972114 0.97074389]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9700604]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.96474683 0.96682662 0.96719992 0.96825844 0.96910894 0.97012228\n",
      "  0.96972114 0.97074389]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04054831713438034\n",
      "Predicción post entrenamiento : [[0.9686975]]\n",
      "PERDIDAAAA despues: 0.0400012843310833\n",
      "loss en el callback: 0.04519016668200493, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.96682662]\n",
      "  [0.96719992]\n",
      "  [0.96825844]\n",
      "  [0.96910894]\n",
      "  [0.97012228]\n",
      "  [0.96972114]\n",
      "  [0.97074389]\n",
      "  [0.97006041]]]\n",
      "ejemplar: [0.96682662 0.96719992 0.96825844 0.96910894 0.97012228 0.96972114\n",
      " 0.97074389 0.97006041]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.96969163]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.96682662 0.96719992 0.96825844 0.96910894 0.97012228 0.96972114\n",
      "  0.97074389 0.97006041]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02916460856795311\n",
      "Predicción post entrenamiento : [[0.9693041]]\n",
      "PERDIDAAAA despues: 0.0290323905646801\n",
      "loss en el callback: 0.004536010324954987, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.96719992]\n",
      "  [0.96825844]\n",
      "  [0.96910894]\n",
      "  [0.97012228]\n",
      "  [0.96972114]\n",
      "  [0.97074389]\n",
      "  [0.97006041]\n",
      "  [0.96969163]]]\n",
      "ejemplar: [0.96719992 0.96825844 0.96910894 0.97012228 0.96972114 0.97074389\n",
      " 0.97006041 0.96969163]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.96989876]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.96719992 0.96825844 0.96910894 0.97012228 0.96972114 0.97074389\n",
      "  0.97006041 0.96969163]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032362163066864014\n",
      "Predicción post entrenamiento : [[0.96822464]]\n",
      "PERDIDAAAA despues: 0.031762637197971344\n",
      "loss en el callback: 0.06258824467658997, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.96825844]\n",
      "  [0.96910894]\n",
      "  [0.97012228]\n",
      "  [0.96972114]\n",
      "  [0.97074389]\n",
      "  [0.97006041]\n",
      "  [0.96969163]\n",
      "  [0.96989876]]]\n",
      "ejemplar: [0.96825844 0.96910894 0.97012228 0.96972114 0.97074389 0.97006041\n",
      " 0.96969163 0.96989876]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9688559]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.96825844 0.96910894 0.97012228 0.96972114 0.97074389 0.97006041\n",
      "  0.96969163 0.96989876]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04354961961507797\n",
      "Predicción post entrenamiento : [[0.96769905]]\n",
      "PERDIDAAAA despues: 0.043068114668130875\n",
      "loss en el callback: 0.037253011018037796, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.96910894]\n",
      "  [0.97012228]\n",
      "  [0.96972114]\n",
      "  [0.97074389]\n",
      "  [0.97006041]\n",
      "  [0.96969163]\n",
      "  [0.96989876]\n",
      "  [0.96885592]]]\n",
      "ejemplar: [0.96910894 0.97012228 0.96972114 0.97074389 0.97006041 0.96969163\n",
      " 0.96989876 0.96885592]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.96812785]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.96910894 0.97012228 0.96972114 0.97074389 0.97006041 0.96969163\n",
      "  0.96989876 0.96885592]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07993883639574051\n",
      "Predicción post entrenamiento : [[0.9676095]]\n",
      "PERDIDAAAA despues: 0.07964601367712021\n",
      "loss en el callback: 0.010360393673181534, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.97012228]\n",
      "  [0.96972114]\n",
      "  [0.97074389]\n",
      "  [0.97006041]\n",
      "  [0.96969163]\n",
      "  [0.96989876]\n",
      "  [0.96885592]\n",
      "  [0.96812785]]]\n",
      "ejemplar: [0.97012228 0.96972114 0.97074389 0.97006041 0.96969163 0.96989876\n",
      " 0.96885592 0.96812785]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9678333]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.97012228 0.96972114 0.97074389 0.97006041 0.96969163 0.96989876\n",
      "  0.96885592 0.96812785]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13150887191295624\n",
      "Predicción post entrenamiento : [[0.96612316]]\n",
      "PERDIDAAAA despues: 0.13027147948741913\n",
      "loss en el callback: 0.08627396076917648, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.96972114]\n",
      "  [0.97074389]\n",
      "  [0.97006041]\n",
      "  [0.96969163]\n",
      "  [0.96989876]\n",
      "  [0.96885592]\n",
      "  [0.96812785]\n",
      "  [0.96783328]]]\n",
      "ejemplar: [0.96972114 0.97074389 0.97006041 0.96969163 0.96989876 0.96885592\n",
      " 0.96812785 0.96783328]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.96603155]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.96972114 0.97074389 0.97006041 0.96969163 0.96989876 0.96885592\n",
      "  0.96812785 0.96783328]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09070515632629395\n",
      "Predicción post entrenamiento : [[0.9633423]]\n",
      "PERDIDAAAA despues: 0.08909253776073456\n",
      "loss en el callback: 0.15998834371566772, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.97074389]\n",
      "  [0.97006041]\n",
      "  [0.96969163]\n",
      "  [0.96989876]\n",
      "  [0.96885592]\n",
      "  [0.96812785]\n",
      "  [0.96783328]\n",
      "  [0.96603155]]]\n",
      "ejemplar: [0.97074389 0.97006041 0.96969163 0.96989876 0.96885592 0.96812785\n",
      " 0.96783328 0.96603155]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9632936]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.97074389 0.97006041 0.96969163 0.96989876 0.96885592 0.96812785\n",
      "  0.96783328 0.96603155]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0652436837553978\n",
      "Predicción post entrenamiento : [[0.9615237]]\n",
      "PERDIDAAAA despues: 0.06434264779090881\n",
      "loss en el callback: 0.0807558223605156, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.97006041]\n",
      "  [0.96969163]\n",
      "  [0.96989876]\n",
      "  [0.96885592]\n",
      "  [0.96812785]\n",
      "  [0.96783328]\n",
      "  [0.96603155]\n",
      "  [0.96329361]]]\n",
      "ejemplar: [0.97006041 0.96969163 0.96989876 0.96885592 0.96812785 0.96783328\n",
      " 0.96603155 0.96329361]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.96104604]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.97006041 0.96969163 0.96989876 0.96885592 0.96812785 0.96783328\n",
      "  0.96603155 0.96329361]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08772701025009155\n",
      "Predicción post entrenamiento : [[0.95886326]]\n",
      "PERDIDAAAA despues: 0.08643875271081924\n",
      "loss en el callback: 0.1240963414311409, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.96969163]\n",
      "  [0.96989876]\n",
      "  [0.96885592]\n",
      "  [0.96812785]\n",
      "  [0.96783328]\n",
      "  [0.96603155]\n",
      "  [0.96329361]\n",
      "  [0.96104604]]]\n",
      "ejemplar: [0.96969163 0.96989876 0.96885592 0.96812785 0.96783328 0.96603155\n",
      " 0.96329361 0.96104604]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9583712]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.96969163 0.96989876 0.96885592 0.96812785 0.96783328 0.96603155\n",
      "  0.96329361 0.96104604]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061018411070108414\n",
      "Predicción post entrenamiento : [[0.95724094]]\n",
      "PERDIDAAAA despues: 0.06046128645539284\n",
      "loss en el callback: 0.040192533284425735, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.96989876]\n",
      "  [0.96885592]\n",
      "  [0.96812785]\n",
      "  [0.96783328]\n",
      "  [0.96603155]\n",
      "  [0.96329361]\n",
      "  [0.96104604]\n",
      "  [0.95837122]]]\n",
      "ejemplar: [0.96989876 0.96885592 0.96812785 0.96783328 0.96603155 0.96329361\n",
      " 0.96104604 0.95837122]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.95658046]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.96989876 0.96885592 0.96812785 0.96783328 0.96603155 0.96329361\n",
      "  0.96104604 0.95837122]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07802166044712067\n",
      "Predicción post entrenamiento : [[0.95547575]]\n",
      "PERDIDAAAA despues: 0.07740573585033417\n",
      "loss en el callback: 0.03853779658675194, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.96885592]\n",
      "  [0.96812785]\n",
      "  [0.96783328]\n",
      "  [0.96603155]\n",
      "  [0.96329361]\n",
      "  [0.96104604]\n",
      "  [0.95837122]\n",
      "  [0.95658046]]]\n",
      "ejemplar: [0.96885592 0.96812785 0.96783328 0.96603155 0.96329361 0.96104604\n",
      " 0.95837122 0.95658046]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9543895]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.96885592 0.96812785 0.96783328 0.96603155 0.96329361 0.96104604\n",
      "  0.95837122 0.95658046]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0369722843170166\n",
      "Predicción post entrenamiento : [[0.9536574]]\n",
      "PERDIDAAAA despues: 0.036691270768642426\n",
      "loss en el callback: 0.016779553145170212, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.96812785]\n",
      "  [0.96783328]\n",
      "  [0.96603155]\n",
      "  [0.96329361]\n",
      "  [0.96104604]\n",
      "  [0.95837122]\n",
      "  [0.95658046]\n",
      "  [0.95438951]]]\n",
      "ejemplar: [0.96812785 0.96783328 0.96603155 0.96329361 0.96104604 0.95837122\n",
      " 0.95658046 0.95438951]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.95241714]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.96812785 0.96783328 0.96603155 0.96329361 0.96104604 0.95837122\n",
      "  0.95658046 0.95438951]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021131156012415886\n",
      "Predicción post entrenamiento : [[0.9517908]]\n",
      "PERDIDAAAA despues: 0.020949456840753555\n",
      "loss en el callback: 0.010898571461439133, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.96783328]\n",
      "  [0.96603155]\n",
      "  [0.96329361]\n",
      "  [0.96104604]\n",
      "  [0.95837122]\n",
      "  [0.95658046]\n",
      "  [0.95438951]\n",
      "  [0.95241714]]]\n",
      "ejemplar: [0.96783328 0.96603155 0.96329361 0.96104604 0.95837122 0.95658046\n",
      " 0.95438951 0.95241714]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.95024]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.96783328 0.96603155 0.96329361 0.96104604 0.95837122 0.95658046\n",
      "  0.95438951 0.95241714]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018239066004753113\n",
      "Predicción post entrenamiento : [[0.9485419]]\n",
      "PERDIDAAAA despues: 0.01778327487409115\n",
      "loss en el callback: 0.06806894391775131, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.96603155]\n",
      "  [0.96329361]\n",
      "  [0.96104604]\n",
      "  [0.95837122]\n",
      "  [0.95658046]\n",
      "  [0.95438951]\n",
      "  [0.95241714]\n",
      "  [0.95024002]]]\n",
      "ejemplar: [0.96603155 0.96329361 0.96104604 0.95837122 0.95658046 0.95438951\n",
      " 0.95241714 0.95024002]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.94647956]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.96603155 0.96329361 0.96104604 0.95837122 0.95658046 0.95438951\n",
      "  0.95241714 0.95024002]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001619391143321991\n",
      "Predicción post entrenamiento : [[0.9467203]]\n",
      "PERDIDAAAA despues: 0.0016388248186558485\n",
      "loss en el callback: 0.002190788509324193, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.96329361]\n",
      "  [0.96104604]\n",
      "  [0.95837122]\n",
      "  [0.95658046]\n",
      "  [0.95438951]\n",
      "  [0.95241714]\n",
      "  [0.95024002]\n",
      "  [0.94647956]]]\n",
      "ejemplar: [0.96329361 0.96104604 0.95837122 0.95658046 0.95438951 0.95241714\n",
      " 0.95024002 0.94647956]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.94451815]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.96329361 0.96104604 0.95837122 0.95658046 0.95438951 0.95241714\n",
      "  0.95024002 0.94647956]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023065658751875162\n",
      "Predicción post entrenamiento : [[0.94559836]]\n",
      "PERDIDAAAA despues: 0.00019901218183804303\n",
      "loss en el callback: 0.04577173665165901, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.96104604]\n",
      "  [0.95837122]\n",
      "  [0.95658046]\n",
      "  [0.95438951]\n",
      "  [0.95241714]\n",
      "  [0.95024002]\n",
      "  [0.94647956]\n",
      "  [0.94451815]]]\n",
      "ejemplar: [0.96104604 0.95837122 0.95658046 0.95438951 0.95241714 0.95024002\n",
      " 0.94647956 0.94451815]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.94351846]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.96104604 0.95837122 0.95658046 0.95438951 0.95241714 0.95024002\n",
      "  0.94647956 0.94451815]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043415609980002046\n",
      "Predicción post entrenamiento : [[0.9434166]]\n",
      "PERDIDAAAA despues: 0.00043841145816259086\n",
      "loss en el callback: 0.0002766597899608314, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.95837122]\n",
      "  [0.95658046]\n",
      "  [0.95438951]\n",
      "  [0.95241714]\n",
      "  [0.95024002]\n",
      "  [0.94647956]\n",
      "  [0.94451815]\n",
      "  [0.94351846]]]\n",
      "ejemplar: [0.95837122 0.95658046 0.95438951 0.95241714 0.95024002 0.94647956\n",
      " 0.94451815 0.94351846]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9413309]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.95837122 0.95658046 0.95438951 0.95241714 0.95024002 0.94647956\n",
      "  0.94451815 0.94351846]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002841210225597024\n",
      "Predicción post entrenamiento : [[0.94162816]]\n",
      "PERDIDAAAA despues: 0.002872986951842904\n",
      "loss en el callback: 0.0036378505174070597, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.95658046]\n",
      "  [0.95438951]\n",
      "  [0.95241714]\n",
      "  [0.95024002]\n",
      "  [0.94647956]\n",
      "  [0.94451815]\n",
      "  [0.94351846]\n",
      "  [0.94133091]]]\n",
      "ejemplar: [0.95658046 0.95438951 0.95241714 0.95024002 0.94647956 0.94451815\n",
      " 0.94351846 0.94133091]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9396687]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.95658046 0.95438951 0.95241714 0.95024002 0.94647956 0.94451815\n",
      "  0.94351846 0.94133091]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002208197955042124\n",
      "Predicción post entrenamiento : [[0.9389493]]\n",
      "PERDIDAAAA despues: 0.0021411015186458826\n",
      "loss en el callback: 0.014798297546803951, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.95438951]\n",
      "  [0.95241714]\n",
      "  [0.95024002]\n",
      "  [0.94647956]\n",
      "  [0.94451815]\n",
      "  [0.94351846]\n",
      "  [0.94133091]\n",
      "  [0.93966872]]]\n",
      "ejemplar: [0.95438951 0.95241714 0.95024002 0.94647956 0.94451815 0.94351846\n",
      " 0.94133091 0.93966872]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9368722]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.95438951 0.95241714 0.95024002 0.94647956 0.94451815 0.94351846\n",
      "  0.94133091 0.93966872]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037982582580298185\n",
      "Predicción post entrenamiento : [[0.93659973]]\n",
      "PERDIDAAAA despues: 0.0037647499702870846\n",
      "loss en el callback: 0.0026175568345934153, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.95241714]\n",
      "  [0.95024002]\n",
      "  [0.94647956]\n",
      "  [0.94451815]\n",
      "  [0.94351846]\n",
      "  [0.94133091]\n",
      "  [0.93966872]\n",
      "  [0.93687218]]]\n",
      "ejemplar: [0.95241714 0.95024002 0.94647956 0.94451815 0.94351846 0.94133091\n",
      " 0.93966872 0.93687218]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.93451506]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.95241714 0.95024002 0.94647956 0.94451815 0.94351846 0.94133091\n",
      "  0.93966872 0.93687218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007002687081694603\n",
      "Predicción post entrenamiento : [[0.9334076]]\n",
      "PERDIDAAAA despues: 0.0068185655400156975\n",
      "loss en el callback: 0.03556771203875542, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.95024002]\n",
      "  [0.94647956]\n",
      "  [0.94451815]\n",
      "  [0.94351846]\n",
      "  [0.94133091]\n",
      "  [0.93966872]\n",
      "  [0.93687218]\n",
      "  [0.93451506]]]\n",
      "ejemplar: [0.95024002 0.94647956 0.94451815 0.94351846 0.94133091 0.93966872\n",
      " 0.93687218 0.93451506]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9312553]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.95024002 0.94647956 0.94451815 0.94351846 0.94133091 0.93966872\n",
      "  0.93687218 0.93451506]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006783085875213146\n",
      "Predicción post entrenamiento : [[0.9310427]]\n",
      "PERDIDAAAA despues: 0.006748110521584749\n",
      "loss en el callback: 0.0017463499680161476, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.94647956]\n",
      "  [0.94451815]\n",
      "  [0.94351846]\n",
      "  [0.94133091]\n",
      "  [0.93966872]\n",
      "  [0.93687218]\n",
      "  [0.93451506]\n",
      "  [0.93125528]]]\n",
      "ejemplar: [0.94647956 0.94451815 0.94351846 0.94133091 0.93966872 0.93687218\n",
      " 0.93451506 0.93125528]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9288764]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.94647956 0.94451815 0.94351846 0.94133091 0.93966872 0.93687218\n",
      "  0.93451506 0.93125528]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011250162497162819\n",
      "Predicción post entrenamiento : [[0.9283625]]\n",
      "PERDIDAAAA despues: 0.001159754814580083\n",
      "loss en el callback: 0.007890122011303902, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.94451815]\n",
      "  [0.94351846]\n",
      "  [0.94133091]\n",
      "  [0.93966872]\n",
      "  [0.93687218]\n",
      "  [0.93451506]\n",
      "  [0.93125528]\n",
      "  [0.9288764 ]]]\n",
      "ejemplar: [0.94451815 0.94351846 0.94133091 0.93966872 0.93687218 0.93451506\n",
      " 0.93125528 0.9288764 ]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.92665607]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.94451815 0.94351846 0.94133091 0.93966872 0.93687218 0.93451506\n",
      "  0.93125528 0.9288764 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016962747322395444\n",
      "Predicción post entrenamiento : [[0.9270192]]\n",
      "PERDIDAAAA despues: 0.0016664965078234673\n",
      "loss en el callback: 0.004754948895424604, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.94351846]\n",
      "  [0.94133091]\n",
      "  [0.93966872]\n",
      "  [0.93687218]\n",
      "  [0.93451506]\n",
      "  [0.93125528]\n",
      "  [0.9288764 ]\n",
      "  [0.92665607]]]\n",
      "ejemplar: [0.94351846 0.94133091 0.93966872 0.93687218 0.93451506 0.93125528\n",
      " 0.9288764  0.92665607]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.92527264]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.94351846 0.94133091 0.93966872 0.93687218 0.93451506 0.93125528\n",
      "  0.9288764  0.92665607]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023864174727350473\n",
      "Predicción post entrenamiento : [[0.92483413]]\n",
      "PERDIDAAAA despues: 0.00025238230591639876\n",
      "loss en el callback: 0.005714138504117727, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.94133091]\n",
      "  [0.93966872]\n",
      "  [0.93687218]\n",
      "  [0.93451506]\n",
      "  [0.93125528]\n",
      "  [0.9288764 ]\n",
      "  [0.92665607]\n",
      "  [0.92527264]]]\n",
      "ejemplar: [0.94133091 0.93966872 0.93687218 0.93451506 0.93125528 0.9288764\n",
      " 0.92665607 0.92527264]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9227308]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.94133091 0.93966872 0.93687218 0.93451506 0.93125528 0.9288764\n",
      "  0.92665607 0.92527264]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024761033710092306\n",
      "Predicción post entrenamiento : [[0.92374855]]\n",
      "PERDIDAAAA despues: 0.0023758518509566784\n",
      "loss en el callback: 0.0483928807079792, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.93966872]\n",
      "  [0.93687218]\n",
      "  [0.93451506]\n",
      "  [0.93125528]\n",
      "  [0.9288764 ]\n",
      "  [0.92665607]\n",
      "  [0.92527264]\n",
      "  [0.9227308 ]]]\n",
      "ejemplar: [0.93966872 0.93687218 0.93451506 0.93125528 0.9288764  0.92665607\n",
      " 0.92527264 0.9227308 ]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9215901]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.93966872 0.93687218 0.93451506 0.93125528 0.9288764  0.92665607\n",
      "  0.92527264 0.9227308 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005671648774296045\n",
      "Predicción post entrenamiento : [[0.92142195]]\n",
      "PERDIDAAAA despues: 0.005697003100067377\n",
      "loss en el callback: 0.0008436873904429376, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.93687218]\n",
      "  [0.93451506]\n",
      "  [0.93125528]\n",
      "  [0.9288764 ]\n",
      "  [0.92665607]\n",
      "  [0.92527264]\n",
      "  [0.9227308 ]\n",
      "  [0.92159009]]]\n",
      "ejemplar: [0.93687218 0.93451506 0.93125528 0.9288764  0.92665607 0.92527264\n",
      " 0.9227308  0.92159009]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.91905296]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.93687218 0.93451506 0.93125528 0.9288764  0.92665607 0.92527264\n",
      "  0.9227308  0.92159009]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001032256637699902\n",
      "Predicción post entrenamiento : [[0.91920066]]\n",
      "PERDIDAAAA despues: 0.0010227876482531428\n",
      "loss en el callback: 0.0007606149301864207, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.93451506]\n",
      "  [0.93125528]\n",
      "  [0.9288764 ]\n",
      "  [0.92665607]\n",
      "  [0.92527264]\n",
      "  [0.9227308 ]\n",
      "  [0.92159009]\n",
      "  [0.91905296]]]\n",
      "ejemplar: [0.93451506 0.93125528 0.9288764  0.92665607 0.92527264 0.9227308\n",
      " 0.92159009 0.91905296]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9169534]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.93451506 0.93125528 0.9288764  0.92665607 0.92527264 0.9227308\n",
      "  0.92159009 0.91905296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00044844739022664726\n",
      "Predicción post entrenamiento : [[0.91732377]]\n",
      "PERDIDAAAA despues: 0.00046427149209193885\n",
      "loss en el callback: 0.006038626655936241, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.93125528]\n",
      "  [0.9288764 ]\n",
      "  [0.92665607]\n",
      "  [0.92527264]\n",
      "  [0.9227308 ]\n",
      "  [0.92159009]\n",
      "  [0.91905296]\n",
      "  [0.91695338]]]\n",
      "ejemplar: [0.93125528 0.9288764  0.92665607 0.92527264 0.9227308  0.92159009\n",
      " 0.91905296 0.91695338]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.91510373]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.93125528 0.9288764  0.92665607 0.92527264 0.9227308  0.92159009\n",
      "  0.91905296 0.91695338]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011331597343087196\n",
      "Predicción post entrenamiento : [[0.91537756]]\n",
      "PERDIDAAAA despues: 0.001151669886894524\n",
      "loss en el callback: 0.0032438901253044605, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.9288764 ]\n",
      "  [0.92665607]\n",
      "  [0.92527264]\n",
      "  [0.9227308 ]\n",
      "  [0.92159009]\n",
      "  [0.91905296]\n",
      "  [0.91695338]\n",
      "  [0.91510373]]]\n",
      "ejemplar: [0.9288764  0.92665607 0.92527264 0.9227308  0.92159009 0.91905296\n",
      " 0.91695338 0.91510373]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.91348034]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.9288764  0.92665607 0.92527264 0.9227308  0.92159009 0.91905296\n",
      "  0.91695338 0.91510373]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3003820640733466e-05\n",
      "Predicción post entrenamiento : [[0.9117385]]\n",
      "PERDIDAAAA despues: 2.8600115911103785e-05\n",
      "loss en el callback: 0.07536672055721283, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.92665607]\n",
      "  [0.92527264]\n",
      "  [0.9227308 ]\n",
      "  [0.92159009]\n",
      "  [0.91905296]\n",
      "  [0.91695338]\n",
      "  [0.91510373]\n",
      "  [0.91348034]]]\n",
      "ejemplar: [0.92665607 0.92527264 0.9227308  0.92159009 0.91905296 0.91695338\n",
      " 0.91510373 0.91348034]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9099561]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.92665607 0.92527264 0.9227308  0.92159009 0.91905296 0.91695338\n",
      "  0.91510373 0.91348034]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.687392594059929e-05\n",
      "Predicción post entrenamiento : [[0.91032815]]\n",
      "PERDIDAAAA despues: 8.968853944679722e-05\n",
      "loss en el callback: 0.006323257926851511, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.92527264]\n",
      "  [0.9227308 ]\n",
      "  [0.92159009]\n",
      "  [0.91905296]\n",
      "  [0.91695338]\n",
      "  [0.91510373]\n",
      "  [0.91348034]\n",
      "  [0.9099561 ]]]\n",
      "ejemplar: [0.92527264 0.9227308  0.92159009 0.91905296 0.91695338 0.91510373\n",
      " 0.91348034 0.9099561 ]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.90861946]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.92527264 0.9227308  0.92159009 0.91905296 0.91695338 0.91510373\n",
      "  0.91348034 0.9099561 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028114744927734137\n",
      "Predicción post entrenamiento : [[0.9089059]]\n",
      "PERDIDAAAA despues: 0.0027811783365905285\n",
      "loss en el callback: 0.003138710279017687, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.9227308 ]\n",
      "  [0.92159009]\n",
      "  [0.91905296]\n",
      "  [0.91695338]\n",
      "  [0.91510373]\n",
      "  [0.91348034]\n",
      "  [0.9099561 ]\n",
      "  [0.90861946]]]\n",
      "ejemplar: [0.9227308  0.92159009 0.91905296 0.91695338 0.91510373 0.91348034\n",
      " 0.9099561  0.90861946]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.90702003]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.9227308  0.92159009 0.91905296 0.91695338 0.91510373 0.91348034\n",
      "  0.9099561  0.90861946]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003746581031009555\n",
      "Predicción post entrenamiento : [[0.9065314]]\n",
      "PERDIDAAAA despues: 0.0038066382985562086\n",
      "loss en el callback: 0.007623205427080393, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.92159009]\n",
      "  [0.91905296]\n",
      "  [0.91695338]\n",
      "  [0.91510373]\n",
      "  [0.91348034]\n",
      "  [0.9099561 ]\n",
      "  [0.90861946]\n",
      "  [0.90702003]]]\n",
      "ejemplar: [0.92159009 0.91905296 0.91695338 0.91510373 0.91348034 0.9099561\n",
      " 0.90861946 0.90702003]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9047907]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.92159009 0.91905296 0.91695338 0.91510373 0.91348034 0.9099561\n",
      "  0.90861946 0.90702003]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002806628355756402\n",
      "Predicción post entrenamiento : [[0.90400606]]\n",
      "PERDIDAAAA despues: 0.0028903803322464228\n",
      "loss en el callback: 0.018882110714912415, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21778296]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029472922906279564\n",
      "Predicción post entrenamiento : [[0.16756119]]\n",
      "PERDIDAAAA despues: 0.01475132443010807\n",
      "loss en el callback: 0.03960804641246796, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21778296]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.21778296]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.15165834]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.21778296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002250095596536994\n",
      "Predicción post entrenamiento : [[0.14242977]]\n",
      "PERDIDAAAA despues: 0.001459744293242693\n",
      "loss en el callback: 0.001809251494705677, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21778296]\n",
      "  [0.15165834]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.21778296 0.15165834]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.14604782]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.21778296 0.15165834]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.652011506957933e-05\n",
      "Predicción post entrenamiento : [[0.14834943]]\n",
      "PERDIDAAAA despues: 3.4273627534275874e-05\n",
      "loss en el callback: 0.0002625425695441663, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21778296]\n",
      "  [0.15165834]\n",
      "  [0.14604782]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.21778296\n",
      " 0.15165834 0.14604782]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1589282]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.21778296\n",
      "  0.15165834 0.14604782]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.007819901133189e-05\n",
      "Predicción post entrenamiento : [[0.15933746]]\n",
      "PERDIDAAAA despues: 1.2844183402194176e-05\n",
      "loss en el callback: 1.7384680177201517e-05, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21778296]\n",
      "  [0.15165834]\n",
      "  [0.14604782]\n",
      "  [0.1589282 ]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.21778296 0.15165834\n",
      " 0.14604782 0.1589282 ]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17034258]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.21778296 0.15165834\n",
      "  0.14604782 0.1589282 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002007921226322651\n",
      "Predicción post entrenamiento : [[0.16593587]]\n",
      "PERDIDAAAA despues: 0.0016324127791449428\n",
      "loss en el callback: 0.0022786720655858517, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21778296]\n",
      "  [0.15165834]\n",
      "  [0.14604782]\n",
      "  [0.1589282 ]\n",
      "  [0.17034258]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.21778296 0.15165834 0.14604782\n",
      " 0.1589282  0.17034258]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.17320974]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.21778296 0.15165834 0.14604782\n",
      "  0.1589282  0.17034258]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007578885997645557\n",
      "Predicción post entrenamiento : [[0.17043485]]\n",
      "PERDIDAAAA despues: 0.0006128042005002499\n",
      "loss en el callback: 0.0013017666060477495, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21778296]\n",
      "  [0.15165834]\n",
      "  [0.14604782]\n",
      "  [0.1589282 ]\n",
      "  [0.17034258]\n",
      "  [0.17320974]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.21778296 0.15165834 0.14604782 0.1589282\n",
      " 0.17034258 0.17320974]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.18775108]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.21778296 0.15165834 0.14604782 0.1589282\n",
      "  0.17034258 0.17320974]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017053785268217325\n",
      "Predicción post entrenamiento : [[0.18141206]]\n",
      "PERDIDAAAA despues: 0.0012220058124512434\n",
      "loss en el callback: 0.00692057516425848, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.21778296]\n",
      "  [0.15165834]\n",
      "  [0.14604782]\n",
      "  [0.1589282 ]\n",
      "  [0.17034258]\n",
      "  [0.17320974]\n",
      "  [0.18775108]]]\n",
      "ejemplar: [0.04223169 0.21778296 0.15165834 0.14604782 0.1589282  0.17034258\n",
      " 0.17320974 0.18775108]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.20198512]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.21778296 0.15165834 0.14604782 0.1589282  0.17034258\n",
      "  0.17320974 0.18775108]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.524897329043597e-05\n",
      "Predicción post entrenamiento : [[0.20336924]]\n",
      "PERDIDAAAA despues: 5.3600095270667225e-05\n",
      "loss en el callback: 0.0007457619649358094, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.21778296]\n",
      "  [0.15165834]\n",
      "  [0.14604782]\n",
      "  [0.1589282 ]\n",
      "  [0.17034258]\n",
      "  [0.17320974]\n",
      "  [0.18775108]\n",
      "  [0.20198512]]]\n",
      "ejemplar: [0.21778296 0.15165834 0.14604782 0.1589282  0.17034258 0.17320974\n",
      " 0.18775108 0.20198512]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2275125]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.21778296 0.15165834 0.14604782 0.1589282  0.17034258 0.17320974\n",
      "  0.18775108 0.20198512]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.110162864089943e-06\n",
      "Predicción post entrenamiento : [[0.22774002]]\n",
      "PERDIDAAAA despues: 7.78844696469605e-06\n",
      "loss en el callback: 1.8074322724714875e-05, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.15165834]\n",
      "  [0.14604782]\n",
      "  [0.1589282 ]\n",
      "  [0.17034258]\n",
      "  [0.17320974]\n",
      "  [0.18775108]\n",
      "  [0.20198512]\n",
      "  [0.22751249]]]\n",
      "ejemplar: [0.15165834 0.14604782 0.1589282  0.17034258 0.17320974 0.18775108\n",
      " 0.20198512 0.22751249]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.21791339]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.15165834 0.14604782 0.1589282  0.17034258 0.17320974 0.18775108\n",
      "  0.20198512 0.22751249]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.962504216469824e-05\n",
      "Predicción post entrenamiento : [[0.21686931]]\n",
      "PERDIDAAAA despues: 7.09464366082102e-05\n",
      "loss en el callback: 0.00045196578139439225, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.14604782]\n",
      "  [0.1589282 ]\n",
      "  [0.17034258]\n",
      "  [0.17320974]\n",
      "  [0.18775108]\n",
      "  [0.20198512]\n",
      "  [0.22751249]\n",
      "  [0.21791339]]]\n",
      "ejemplar: [0.14604782 0.1589282  0.17034258 0.17320974 0.18775108 0.20198512\n",
      " 0.22751249 0.21791339]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.22097644]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.14604782 0.1589282  0.17034258 0.17320974 0.18775108 0.20198512\n",
      "  0.22751249 0.21791339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.177733980119228e-05\n",
      "Predicción post entrenamiento : [[0.21980274]]\n",
      "PERDIDAAAA despues: 6.192710861796513e-05\n",
      "loss en el callback: 0.0006863617454655468, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.1589282 ]\n",
      "  [0.17034258]\n",
      "  [0.17320974]\n",
      "  [0.18775108]\n",
      "  [0.20198512]\n",
      "  [0.22751249]\n",
      "  [0.21791339]\n",
      "  [0.22097644]]]\n",
      "ejemplar: [0.1589282  0.17034258 0.17320974 0.18775108 0.20198512 0.22751249\n",
      " 0.21791339 0.22097644]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.22705267]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.1589282  0.17034258 0.17320974 0.18775108 0.20198512 0.22751249\n",
      "  0.21791339 0.22097644]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039080032729543746\n",
      "Predicción post entrenamiento : [[0.22554454]]\n",
      "PERDIDAAAA despues: 0.0003334472712595016\n",
      "loss en el callback: 0.001332845538854599, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.17034258]\n",
      "  [0.17320974]\n",
      "  [0.18775108]\n",
      "  [0.20198512]\n",
      "  [0.22751249]\n",
      "  [0.21791339]\n",
      "  [0.22097644]\n",
      "  [0.22705267]]]\n",
      "ejemplar: [0.17034258 0.17320974 0.18775108 0.20198512 0.22751249 0.21791339\n",
      " 0.22097644 0.22705267]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2323085]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.17034258 0.17320974 0.18775108 0.20198512 0.22751249 0.21791339\n",
      "  0.22097644 0.22705267]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015492120292037725\n",
      "Predicción post entrenamiento : [[0.23085193]]\n",
      "PERDIDAAAA despues: 0.0014366721734404564\n",
      "loss en el callback: 0.001640773843973875, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.17320974]\n",
      "  [0.18775108]\n",
      "  [0.20198512]\n",
      "  [0.22751249]\n",
      "  [0.21791339]\n",
      "  [0.22097644]\n",
      "  [0.22705267]\n",
      "  [0.23230851]]]\n",
      "ejemplar: [0.17320974 0.18775108 0.20198512 0.22751249 0.21791339 0.22097644\n",
      " 0.22705267 0.23230851]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.23723313]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.17320974 0.18775108 0.20198512 0.22751249 0.21791339 0.22097644\n",
      "  0.22705267 0.23230851]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016329835634678602\n",
      "Predicción post entrenamiento : [[0.23486769]]\n",
      "PERDIDAAAA despues: 0.0014474031049758196\n",
      "loss en el callback: 0.004067456349730492, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.18775108]\n",
      "  [0.20198512]\n",
      "  [0.22751249]\n",
      "  [0.21791339]\n",
      "  [0.22097644]\n",
      "  [0.22705267]\n",
      "  [0.23230851]\n",
      "  [0.23723313]]]\n",
      "ejemplar: [0.18775108 0.20198512 0.22751249 0.21791339 0.22097644 0.22705267\n",
      " 0.23230851 0.23723313]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.24257916]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.18775108 0.20198512 0.22751249 0.21791339 0.22097644 0.22705267\n",
      "  0.23230851 0.23723313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008020856766961515\n",
      "Predicción post entrenamiento : [[0.24101458]]\n",
      "PERDIDAAAA despues: 0.0007159124361351132\n",
      "loss en el callback: 0.0020856293849647045, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.20198512]\n",
      "  [0.22751249]\n",
      "  [0.21791339]\n",
      "  [0.22097644]\n",
      "  [0.22705267]\n",
      "  [0.23230851]\n",
      "  [0.23723313]\n",
      "  [0.24257916]]]\n",
      "ejemplar: [0.20198512 0.22751249 0.21791339 0.22097644 0.22705267 0.23230851\n",
      " 0.23723313 0.24257916]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2474753]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.20198512 0.22751249 0.21791339 0.22097644 0.22705267 0.23230851\n",
      "  0.23723313 0.24257916]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004375853575766087\n",
      "Predicción post entrenamiento : [[0.24631241]]\n",
      "PERDIDAAAA despues: 0.00422335509210825\n",
      "loss en el callback: 0.0017946177395060658, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.22751249]\n",
      "  [0.21791339]\n",
      "  [0.22097644]\n",
      "  [0.22705267]\n",
      "  [0.23230851]\n",
      "  [0.23723313]\n",
      "  [0.24257916]\n",
      "  [0.2474753 ]]]\n",
      "ejemplar: [0.22751249 0.21791339 0.22097644 0.22705267 0.23230851 0.23723313\n",
      " 0.24257916 0.2474753 ]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.25120723]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.22751249 0.21791339 0.22097644 0.22705267 0.23230851 0.23723313\n",
      "  0.24257916 0.2474753 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005788364913314581\n",
      "Predicción post entrenamiento : [[0.2494107]]\n",
      "PERDIDAAAA despues: 0.005518228281289339\n",
      "loss en el callback: 0.004223827738314867, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.21791339]\n",
      "  [0.22097644]\n",
      "  [0.22705267]\n",
      "  [0.23230851]\n",
      "  [0.23723313]\n",
      "  [0.24257916]\n",
      "  [0.2474753 ]\n",
      "  [0.25120723]]]\n",
      "ejemplar: [0.21791339 0.22097644 0.22705267 0.23230851 0.23723313 0.24257916\n",
      " 0.2474753  0.25120723]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.24980305]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.21791339 0.22097644 0.22705267 0.23230851 0.23723313 0.24257916\n",
      "  0.2474753  0.25120723]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010362914763391018\n",
      "Predicción post entrenamiento : [[0.245852]]\n",
      "PERDIDAAAA despues: 0.009574102237820625\n",
      "loss en el callback: 0.01711556687951088, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.22097644]\n",
      "  [0.22705267]\n",
      "  [0.23230851]\n",
      "  [0.23723313]\n",
      "  [0.24257916]\n",
      "  [0.2474753 ]\n",
      "  [0.25120723]\n",
      "  [0.24980305]]]\n",
      "ejemplar: [0.22097644 0.22705267 0.23230851 0.23723313 0.24257916 0.2474753\n",
      " 0.25120723 0.24980305]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.24900265]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.22097644 0.22705267 0.23230851 0.23723313 0.24257916 0.2474753\n",
      "  0.25120723 0.24980305]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008126931264996529\n",
      "Predicción post entrenamiento : [[0.24674389]]\n",
      "PERDIDAAAA despues: 0.00772478012368083\n",
      "loss en el callback: 0.007432932034134865, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.22705267]\n",
      "  [0.23230851]\n",
      "  [0.23723313]\n",
      "  [0.24257916]\n",
      "  [0.2474753 ]\n",
      "  [0.25120723]\n",
      "  [0.24980305]\n",
      "  [0.24900265]]]\n",
      "ejemplar: [0.22705267 0.23230851 0.23723313 0.24257916 0.2474753  0.25120723\n",
      " 0.24980305 0.24900265]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.25020874]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.22705267 0.23230851 0.23723313 0.24257916 0.2474753  0.25120723\n",
      "  0.24980305 0.24900265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003368080360814929\n",
      "Predicción post entrenamiento : [[0.24887353]]\n",
      "PERDIDAAAA despues: 0.003214885713532567\n",
      "loss en el callback: 0.0031917772721499205, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.23230851]\n",
      "  [0.23723313]\n",
      "  [0.24257916]\n",
      "  [0.2474753 ]\n",
      "  [0.25120723]\n",
      "  [0.24980305]\n",
      "  [0.24900265]\n",
      "  [0.25020874]]]\n",
      "ejemplar: [0.23230851 0.23723313 0.24257916 0.2474753  0.25120723 0.24980305\n",
      " 0.24900265 0.25020874]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.25192404]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.23230851 0.23723313 0.24257916 0.2474753  0.25120723 0.24980305\n",
      "  0.24900265 0.25020874]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004349350463598967\n",
      "Predicción post entrenamiento : [[0.24912082]]\n",
      "PERDIDAAAA despues: 0.0039874655194580555\n",
      "loss en el callback: 0.010254732333123684, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.23723313]\n",
      "  [0.24257916]\n",
      "  [0.2474753 ]\n",
      "  [0.25120723]\n",
      "  [0.24980305]\n",
      "  [0.24900265]\n",
      "  [0.25020874]\n",
      "  [0.25192404]]]\n",
      "ejemplar: [0.23723313 0.24257916 0.2474753  0.25120723 0.24980305 0.24900265\n",
      " 0.25020874 0.25192404]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.25177178]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.23723313 0.24257916 0.2474753  0.25120723 0.24980305 0.24900265\n",
      "  0.25020874 0.25192404]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002304022928001359\n",
      "Predicción post entrenamiento : [[0.25219208]]\n",
      "PERDIDAAAA despues: 0.0002178194117732346\n",
      "loss en el callback: 0.0003583551733754575, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.24257916]\n",
      "  [0.2474753 ]\n",
      "  [0.25120723]\n",
      "  [0.24980305]\n",
      "  [0.24900265]\n",
      "  [0.25020874]\n",
      "  [0.25192404]\n",
      "  [0.25177178]]]\n",
      "ejemplar: [0.24257916 0.2474753  0.25120723 0.24980305 0.24900265 0.25020874\n",
      " 0.25192404 0.25177178]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.25436217]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.24257916 0.2474753  0.25120723 0.24980305 0.24900265 0.25020874\n",
      "  0.25192404 0.25177178]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014561944408342242\n",
      "Predicción post entrenamiento : [[0.25432333]]\n",
      "PERDIDAAAA despues: 0.001459159655496478\n",
      "loss en el callback: 2.665775355126243e-06, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.2474753 ]\n",
      "  [0.25120723]\n",
      "  [0.24980305]\n",
      "  [0.24900265]\n",
      "  [0.25020874]\n",
      "  [0.25192404]\n",
      "  [0.25177178]\n",
      "  [0.25436217]]]\n",
      "ejemplar: [0.2474753  0.25120723 0.24980305 0.24900265 0.25020874 0.25192404\n",
      " 0.25177178 0.25436217]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.25576374]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.2474753  0.25120723 0.24980305 0.24900265 0.25020874 0.25192404\n",
      "  0.25177178 0.25436217]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038368829991668463\n",
      "Predicción post entrenamiento : [[0.25634208]]\n",
      "PERDIDAAAA despues: 0.003765569068491459\n",
      "loss en el callback: 0.0006462102755904198, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.25120723]\n",
      "  [0.24980305]\n",
      "  [0.24900265]\n",
      "  [0.25020874]\n",
      "  [0.25192404]\n",
      "  [0.25177178]\n",
      "  [0.25436217]\n",
      "  [0.25576374]]]\n",
      "ejemplar: [0.25120723 0.24980305 0.24900265 0.25020874 0.25192404 0.25177178\n",
      " 0.25436217 0.25576374]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.2569975]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.25120723 0.24980305 0.24900265 0.25020874 0.25192404 0.25177178\n",
      "  0.25436217 0.25576374]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030993737746030092\n",
      "Predicción post entrenamiento : [[0.2573681]]\n",
      "PERDIDAAAA despues: 0.0030582479666918516\n",
      "loss en el callback: 0.00030798022635281086, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.24980305]\n",
      "  [0.24900265]\n",
      "  [0.25020874]\n",
      "  [0.25192404]\n",
      "  [0.25177178]\n",
      "  [0.25436217]\n",
      "  [0.25576374]\n",
      "  [0.2569975 ]]]\n",
      "ejemplar: [0.24980305 0.24900265 0.25020874 0.25192404 0.25177178 0.25436217\n",
      " 0.25576374 0.2569975 ]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.25737524]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.24980305 0.24900265 0.25020874 0.25192404 0.25177178 0.25436217\n",
      "  0.25576374 0.2569975 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010023568756878376\n",
      "Predicción post entrenamiento : [[0.25839838]]\n",
      "PERDIDAAAA despues: 0.0009386182064190507\n",
      "loss en el callback: 0.004018592648208141, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.24900265]\n",
      "  [0.25020874]\n",
      "  [0.25192404]\n",
      "  [0.25177178]\n",
      "  [0.25436217]\n",
      "  [0.25576374]\n",
      "  [0.2569975 ]\n",
      "  [0.25737524]]]\n",
      "ejemplar: [0.24900265 0.25020874 0.25192404 0.25177178 0.25436217 0.25576374\n",
      " 0.2569975  0.25737524]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.25885394]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.24900265 0.25020874 0.25192404 0.25177178 0.25436217 0.25576374\n",
      "  0.2569975  0.25737524]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005751443677581847\n",
      "Predicción post entrenamiento : [[0.25901756]]\n",
      "PERDIDAAAA despues: 0.0005673234700225294\n",
      "loss en el callback: 7.439526234520599e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.25020874]\n",
      "  [0.25192404]\n",
      "  [0.25177178]\n",
      "  [0.25436217]\n",
      "  [0.25576374]\n",
      "  [0.2569975 ]\n",
      "  [0.25737524]\n",
      "  [0.25885394]]]\n",
      "ejemplar: [0.25020874 0.25192404 0.25177178 0.25436217 0.25576374 0.2569975\n",
      " 0.25737524 0.25885394]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2598768]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.25020874 0.25192404 0.25177178 0.25436217 0.25576374 0.2569975\n",
      "  0.25737524 0.25885394]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015697075286880136\n",
      "Predicción post entrenamiento : [[0.26103187]]\n",
      "PERDIDAAAA despues: 0.0014795144088566303\n",
      "loss en el callback: 0.004360887221992016, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.25192404]\n",
      "  [0.25177178]\n",
      "  [0.25436217]\n",
      "  [0.25576374]\n",
      "  [0.2569975 ]\n",
      "  [0.25737524]\n",
      "  [0.25885394]\n",
      "  [0.25987679]]]\n",
      "ejemplar: [0.25192404 0.25177178 0.25436217 0.25576374 0.2569975  0.25737524\n",
      " 0.25885394 0.25987679]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2619027]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.25192404 0.25177178 0.25436217 0.25576374 0.2569975  0.25737524\n",
      "  0.25885394 0.25987679]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001948642311617732\n",
      "Predicción post entrenamiento : [[0.2621684]]\n",
      "PERDIDAAAA despues: 0.00018751634343061596\n",
      "loss en el callback: 0.00024457761901430786, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.25177178]\n",
      "  [0.25436217]\n",
      "  [0.25576374]\n",
      "  [0.2569975 ]\n",
      "  [0.25737524]\n",
      "  [0.25885394]\n",
      "  [0.25987679]\n",
      "  [0.26190269]]]\n",
      "ejemplar: [0.25177178 0.25436217 0.25576374 0.2569975  0.25737524 0.25885394\n",
      " 0.25987679 0.26190269]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.26293486]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.25177178 0.25436217 0.25576374 0.2569975  0.25737524 0.25885394\n",
      "  0.25987679 0.26190269]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013841179315932095\n",
      "Predicción post entrenamiento : [[0.26285797]]\n",
      "PERDIDAAAA despues: 0.00014022691175341606\n",
      "loss en el callback: 1.8273281966685317e-05, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.25436217]\n",
      "  [0.25576374]\n",
      "  [0.2569975 ]\n",
      "  [0.25737524]\n",
      "  [0.25885394]\n",
      "  [0.25987679]\n",
      "  [0.26190269]\n",
      "  [0.26293486]]]\n",
      "ejemplar: [0.25436217 0.25576374 0.2569975  0.25737524 0.25885394 0.25987679\n",
      " 0.26190269 0.26293486]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.26393503]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.25436217 0.25576374 0.2569975  0.25737524 0.25885394 0.25987679\n",
      "  0.26190269 0.26293486]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013316186959855258\n",
      "Predicción post entrenamiento : [[0.2637364]]\n",
      "PERDIDAAAA despues: 0.00013778559514321387\n",
      "loss en el callback: 0.00014159032434690744, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.25576374]\n",
      "  [0.2569975 ]\n",
      "  [0.25737524]\n",
      "  [0.25885394]\n",
      "  [0.25987679]\n",
      "  [0.26190269]\n",
      "  [0.26293486]\n",
      "  [0.26393503]]]\n",
      "ejemplar: [0.25576374 0.2569975  0.25737524 0.25885394 0.25987679 0.26190269\n",
      " 0.26293486 0.26393503]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2645387]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.25576374 0.2569975  0.25737524 0.25885394 0.25987679 0.26190269\n",
      "  0.26293486 0.26393503]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00493018189445138\n",
      "Predicción post entrenamiento : [[0.26572797]]\n",
      "PERDIDAAAA despues: 0.004764587618410587\n",
      "loss en el callback: 0.0070961397141218185, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.2569975 ]\n",
      "  [0.25737524]\n",
      "  [0.25885394]\n",
      "  [0.25987679]\n",
      "  [0.26190269]\n",
      "  [0.26293486]\n",
      "  [0.26393503]\n",
      "  [0.26453871]]]\n",
      "ejemplar: [0.2569975  0.25737524 0.25885394 0.25987679 0.26190269 0.26293486\n",
      " 0.26393503 0.26453871]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.2664802]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.2569975  0.25737524 0.25885394 0.25987679 0.26190269 0.26293486\n",
      "  0.26393503 0.26453871]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007955904118716717\n",
      "Predicción post entrenamiento : [[0.2679335]]\n",
      "PERDIDAAAA despues: 0.007698763161897659\n",
      "loss en el callback: 0.010303696617484093, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.25737524]\n",
      "  [0.25885394]\n",
      "  [0.25987679]\n",
      "  [0.26190269]\n",
      "  [0.26293486]\n",
      "  [0.26393503]\n",
      "  [0.26453871]\n",
      "  [0.26648021]]]\n",
      "ejemplar: [0.25737524 0.25885394 0.25987679 0.26190269 0.26293486 0.26393503\n",
      " 0.26453871 0.26648021]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2686687]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.25737524 0.25885394 0.25987679 0.26190269 0.26293486 0.26393503\n",
      "  0.26453871 0.26648021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00462705921381712\n",
      "Predicción post entrenamiento : [[0.26972887]]\n",
      "PERDIDAAAA despues: 0.004483954049646854\n",
      "loss en el callback: 0.005254347342997789, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.25885394]\n",
      "  [0.25987679]\n",
      "  [0.26190269]\n",
      "  [0.26293486]\n",
      "  [0.26393503]\n",
      "  [0.26453871]\n",
      "  [0.26648021]\n",
      "  [0.26866871]]]\n",
      "ejemplar: [0.25885394 0.25987679 0.26190269 0.26293486 0.26393503 0.26453871\n",
      " 0.26648021 0.26866871]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.27065042]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.25885394 0.25987679 0.26190269 0.26293486 0.26393503 0.26453871\n",
      "  0.26648021 0.26866871]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003961597569286823\n",
      "Predicción post entrenamiento : [[0.27175874]]\n",
      "PERDIDAAAA despues: 0.003823308041319251\n",
      "loss en el callback: 0.007415919564664364, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.25987679]\n",
      "  [0.26190269]\n",
      "  [0.26293486]\n",
      "  [0.26393503]\n",
      "  [0.26453871]\n",
      "  [0.26648021]\n",
      "  [0.26866871]\n",
      "  [0.27065042]]]\n",
      "ejemplar: [0.25987679 0.26190269 0.26293486 0.26393503 0.26453871 0.26648021\n",
      " 0.26866871 0.27065042]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.2726516]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.25987679 0.26190269 0.26293486 0.26393503 0.26453871 0.26648021\n",
      "  0.26866871 0.27065042]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01256259623914957\n",
      "Predicción post entrenamiento : [[0.2743296]]\n",
      "PERDIDAAAA despues: 0.012189263477921486\n",
      "loss en el callback: 0.01617860607802868, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.26190269]\n",
      "  [0.26293486]\n",
      "  [0.26393503]\n",
      "  [0.26453871]\n",
      "  [0.26648021]\n",
      "  [0.26866871]\n",
      "  [0.27065042]\n",
      "  [0.27265161]]]\n",
      "ejemplar: [0.26190269 0.26293486 0.26393503 0.26453871 0.26648021 0.26866871\n",
      " 0.27065042 0.27265161]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27530697]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.26190269 0.26293486 0.26393503 0.26453871 0.26648021 0.26866871\n",
      "  0.27065042 0.27265161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08749143779277802\n",
      "Predicción post entrenamiento : [[0.27929372]]\n",
      "PERDIDAAAA despues: 0.08514885604381561\n",
      "loss en el callback: 0.07108993083238602, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.26293486]\n",
      "  [0.26393503]\n",
      "  [0.26453871]\n",
      "  [0.26648021]\n",
      "  [0.26866871]\n",
      "  [0.27065042]\n",
      "  [0.27265161]\n",
      "  [0.27530697]]]\n",
      "ejemplar: [0.26293486 0.26393503 0.26453871 0.26648021 0.26866871 0.27065042\n",
      " 0.27265161 0.27530697]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28015488]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.26293486 0.26393503 0.26453871 0.26648021 0.26866871 0.27065042\n",
      "  0.27265161 0.27530697]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09993541240692139\n",
      "Predicción post entrenamiento : [[0.28449866]]\n",
      "PERDIDAAAA despues: 0.0972079262137413\n",
      "loss en el callback: 0.08922749757766724, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.26393503]\n",
      "  [0.26453871]\n",
      "  [0.26648021]\n",
      "  [0.26866871]\n",
      "  [0.27065042]\n",
      "  [0.27265161]\n",
      "  [0.27530697]\n",
      "  [0.28015488]]]\n",
      "ejemplar: [0.26393503 0.26453871 0.26648021 0.26866871 0.27065042 0.27265161\n",
      " 0.27530697 0.28015488]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28549135]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.26393503 0.26453871 0.26648021 0.26866871 0.27065042 0.27265161\n",
      "  0.27530697 0.28015488]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08357425779104233\n",
      "Predicción post entrenamiento : [[0.28895208]]\n",
      "PERDIDAAAA despues: 0.08158528804779053\n",
      "loss en el callback: 0.056546900421381, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.26453871]\n",
      "  [0.26648021]\n",
      "  [0.26866871]\n",
      "  [0.27065042]\n",
      "  [0.27265161]\n",
      "  [0.27530697]\n",
      "  [0.28015488]\n",
      "  [0.28549135]]]\n",
      "ejemplar: [0.26453871 0.26648021 0.26866871 0.27065042 0.27265161 0.27530697\n",
      " 0.28015488 0.28549135]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29015988]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.26453871 0.26648021 0.26866871 0.27065042 0.27265161 0.27530697\n",
      "  0.28015488 0.28549135]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09997879713773727\n",
      "Predicción post entrenamiento : [[0.29414538]]\n",
      "PERDIDAAAA despues: 0.09747429937124252\n",
      "loss en el callback: 0.12938770651817322, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.26648021]\n",
      "  [0.26866871]\n",
      "  [0.27065042]\n",
      "  [0.27265161]\n",
      "  [0.27530697]\n",
      "  [0.28015488]\n",
      "  [0.28549135]\n",
      "  [0.29015988]]]\n",
      "ejemplar: [0.26648021 0.26866871 0.27065042 0.27265161 0.27530697 0.28015488\n",
      " 0.28549135 0.29015988]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.2957606]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.26648021 0.26866871 0.27065042 0.27265161 0.27530697 0.28015488\n",
      "  0.28549135 0.29015988]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0834612026810646\n",
      "Predicción post entrenamiento : [[0.2990863]]\n",
      "PERDIDAAAA despues: 0.0815507024526596\n",
      "loss en el callback: 0.0565396286547184, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.26866871]\n",
      "  [0.27065042]\n",
      "  [0.27265161]\n",
      "  [0.27530697]\n",
      "  [0.28015488]\n",
      "  [0.28549135]\n",
      "  [0.29015988]\n",
      "  [0.2957606 ]]]\n",
      "ejemplar: [0.26866871 0.27065042 0.27265161 0.27530697 0.28015488 0.28549135\n",
      " 0.29015988 0.2957606 ]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3009289]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.26866871 0.27065042 0.27265161 0.27530697 0.28015488 0.28549135\n",
      "  0.29015988 0.2957606 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0717398151755333\n",
      "Predicción post entrenamiento : [[0.3043446]]\n",
      "PERDIDAAAA despues: 0.06992173939943314\n",
      "loss en el callback: 0.09181682020425797, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27065042]\n",
      "  [0.27265161]\n",
      "  [0.27530697]\n",
      "  [0.28015488]\n",
      "  [0.28549135]\n",
      "  [0.29015988]\n",
      "  [0.2957606 ]\n",
      "  [0.30092889]]]\n",
      "ejemplar: [0.27065042 0.27265161 0.27530697 0.28015488 0.28549135 0.29015988\n",
      " 0.2957606  0.30092889]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30646035]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27065042 0.27265161 0.27530697 0.28015488 0.28549135 0.29015988\n",
      "  0.2957606  0.30092889]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11310694366693497\n",
      "Predicción post entrenamiento : [[0.310514]]\n",
      "PERDIDAAAA despues: 0.11039677262306213\n",
      "loss en el callback: 0.12106147408485413, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27265161]\n",
      "  [0.27530697]\n",
      "  [0.28015488]\n",
      "  [0.28549135]\n",
      "  [0.29015988]\n",
      "  [0.2957606 ]\n",
      "  [0.30092889]\n",
      "  [0.30646035]]]\n",
      "ejemplar: [0.27265161 0.27530697 0.28015488 0.28549135 0.29015988 0.2957606\n",
      " 0.30092889 0.30646035]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3130629]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27265161 0.27530697 0.28015488 0.28549135 0.29015988 0.2957606\n",
      "  0.30092889 0.30646035]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12158898264169693\n",
      "Predicción post entrenamiento : [[0.31705722]]\n",
      "PERDIDAAAA despues: 0.11881932616233826\n",
      "loss en el callback: 0.11684146523475647, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27530697]\n",
      "  [0.28015488]\n",
      "  [0.28549135]\n",
      "  [0.29015988]\n",
      "  [0.2957606 ]\n",
      "  [0.30092889]\n",
      "  [0.30646035]\n",
      "  [0.31306291]]]\n",
      "ejemplar: [0.27530697 0.28015488 0.28549135 0.29015988 0.2957606  0.30092889\n",
      " 0.30646035 0.31306291]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32016677]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27530697 0.28015488 0.28549135 0.29015988 0.2957606  0.30092889\n",
      "  0.30646035 0.31306291]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1244877427816391\n",
      "Predicción post entrenamiento : [[0.32411164]]\n",
      "PERDIDAAAA despues: 0.12171957641839981\n",
      "loss en el callback: 0.16656506061553955, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28015488]\n",
      "  [0.28549135]\n",
      "  [0.29015988]\n",
      "  [0.2957606 ]\n",
      "  [0.30092889]\n",
      "  [0.30646035]\n",
      "  [0.31306291]\n",
      "  [0.32016677]]]\n",
      "ejemplar: [0.28015488 0.28549135 0.29015988 0.2957606  0.30092889 0.30646035\n",
      " 0.31306291 0.32016677]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.32777053]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28015488 0.28549135 0.29015988 0.2957606  0.30092889 0.30646035\n",
      "  0.31306291 0.32016677]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.146541029214859\n",
      "Predicción post entrenamiento : [[0.33193004]]\n",
      "PERDIDAAAA despues: 0.1433737576007843\n",
      "loss en el callback: 0.11227598786354065, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28549135]\n",
      "  [0.29015988]\n",
      "  [0.2957606 ]\n",
      "  [0.30092889]\n",
      "  [0.30646035]\n",
      "  [0.31306291]\n",
      "  [0.32016677]\n",
      "  [0.32777053]]]\n",
      "ejemplar: [0.28549135 0.29015988 0.2957606  0.30092889 0.30646035 0.31306291\n",
      " 0.32016677 0.32777053]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33574843]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28549135 0.29015988 0.2957606  0.30092889 0.30646035 0.31306291\n",
      "  0.32016677 0.32777053]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13560236990451813\n",
      "Predicción post entrenamiento : [[0.339731]]\n",
      "PERDIDAAAA despues: 0.132685124874115\n",
      "loss en el callback: 0.10207106918096542, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29015988]\n",
      "  [0.2957606 ]\n",
      "  [0.30092889]\n",
      "  [0.30646035]\n",
      "  [0.31306291]\n",
      "  [0.32016677]\n",
      "  [0.32777053]\n",
      "  [0.33574843]]]\n",
      "ejemplar: [0.29015988 0.2957606  0.30092889 0.30646035 0.31306291 0.32016677\n",
      " 0.32777053 0.33574843]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3436623]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29015988 0.2957606  0.30092889 0.30646035 0.31306291 0.32016677\n",
      "  0.32777053 0.33574843]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14712995290756226\n",
      "Predicción post entrenamiento : [[0.3479571]]\n",
      "PERDIDAAAA despues: 0.14385363459587097\n",
      "loss en el callback: 0.15666912496089935, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.2957606 ]\n",
      "  [0.30092889]\n",
      "  [0.30646035]\n",
      "  [0.31306291]\n",
      "  [0.32016677]\n",
      "  [0.32777053]\n",
      "  [0.33574843]\n",
      "  [0.34366229]]]\n",
      "ejemplar: [0.2957606  0.30092889 0.30646035 0.31306291 0.32016677 0.32777053\n",
      " 0.33574843 0.34366229]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3522348]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.2957606  0.30092889 0.30646035 0.31306291 0.32016677 0.32777053\n",
      "  0.33574843 0.34366229]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13716156780719757\n",
      "Predicción post entrenamiento : [[0.356142]]\n",
      "PERDIDAAAA despues: 0.13428275287151337\n",
      "loss en el callback: 0.12963876128196716, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30092889]\n",
      "  [0.30646035]\n",
      "  [0.31306291]\n",
      "  [0.32016677]\n",
      "  [0.32777053]\n",
      "  [0.33574843]\n",
      "  [0.34366229]\n",
      "  [0.35223481]]]\n",
      "ejemplar: [0.30092889 0.30646035 0.31306291 0.32016677 0.32777053 0.33574843\n",
      " 0.34366229 0.35223481]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36065254]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30092889 0.30646035 0.31306291 0.32016677 0.32777053 0.33574843\n",
      "  0.34366229 0.35223481]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16903722286224365\n",
      "Predicción post entrenamiento : [[0.3650265]]\n",
      "PERDIDAAAA despues: 0.16545972228050232\n",
      "loss en el callback: 0.1433994323015213, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30646035]\n",
      "  [0.31306291]\n",
      "  [0.32016677]\n",
      "  [0.32777053]\n",
      "  [0.33574843]\n",
      "  [0.34366229]\n",
      "  [0.35223481]\n",
      "  [0.36065254]]]\n",
      "ejemplar: [0.30646035 0.31306291 0.32016677 0.32777053 0.33574843 0.34366229\n",
      " 0.35223481 0.36065254]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36996958]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30646035 0.31306291 0.32016677 0.32777053 0.33574843 0.34366229\n",
      "  0.35223481 0.36065254]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12570983171463013\n",
      "Predicción post entrenamiento : [[0.3736788]]\n",
      "PERDIDAAAA despues: 0.12309332937002182\n",
      "loss en el callback: 0.10914802551269531, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31306291]\n",
      "  [0.32016677]\n",
      "  [0.32777053]\n",
      "  [0.33574843]\n",
      "  [0.34366229]\n",
      "  [0.35223481]\n",
      "  [0.36065254]\n",
      "  [0.36996958]]]\n",
      "ejemplar: [0.31306291 0.32016677 0.32777053 0.33574843 0.34366229 0.35223481\n",
      " 0.36065254 0.36996958]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3790871]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31306291 0.32016677 0.32777053 0.33574843 0.34366229 0.35223481\n",
      "  0.36065254 0.36996958]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08524683862924576\n",
      "Predicción post entrenamiento : [[0.38233483]]\n",
      "PERDIDAAAA despues: 0.08336089551448822\n",
      "loss en el callback: 0.11555787175893784, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32016677]\n",
      "  [0.32777053]\n",
      "  [0.33574843]\n",
      "  [0.34366229]\n",
      "  [0.35223481]\n",
      "  [0.36065254]\n",
      "  [0.36996958]\n",
      "  [0.37908709]]]\n",
      "ejemplar: [0.32016677 0.32777053 0.33574843 0.34366229 0.35223481 0.36065254\n",
      " 0.36996958 0.37908709]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38806233]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32016677 0.32777053 0.33574843 0.34366229 0.35223481 0.36065254\n",
      "  0.36996958 0.37908709]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08162877708673477\n",
      "Predicción post entrenamiento : [[0.3909646]]\n",
      "PERDIDAAAA despues: 0.07997880131006241\n",
      "loss en el callback: 0.08043903857469559, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32777053]\n",
      "  [0.33574843]\n",
      "  [0.34366229]\n",
      "  [0.35223481]\n",
      "  [0.36065254]\n",
      "  [0.36996958]\n",
      "  [0.37908709]\n",
      "  [0.38806233]]]\n",
      "ejemplar: [0.32777053 0.33574843 0.34366229 0.35223481 0.36065254 0.36996958\n",
      " 0.37908709 0.38806233]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39697266]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32777053 0.33574843 0.34366229 0.35223481 0.36065254 0.36996958\n",
      "  0.37908709 0.38806233]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10079299658536911\n",
      "Predicción post entrenamiento : [[0.4002786]]\n",
      "PERDIDAAAA despues: 0.09870479255914688\n",
      "loss en el callback: 0.09393776953220367, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33574843]\n",
      "  [0.34366229]\n",
      "  [0.35223481]\n",
      "  [0.36065254]\n",
      "  [0.36996958]\n",
      "  [0.37908709]\n",
      "  [0.38806233]\n",
      "  [0.39697266]]]\n",
      "ejemplar: [0.33574843 0.34366229 0.35223481 0.36065254 0.36996958 0.37908709\n",
      " 0.38806233 0.39697266]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4065154]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33574843 0.34366229 0.35223481 0.36065254 0.36996958 0.37908709\n",
      "  0.38806233 0.39697266]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11382684856653214\n",
      "Predicción post entrenamiento : [[0.41000363]]\n",
      "PERDIDAAAA despues: 0.11148527264595032\n",
      "loss en el callback: 0.13098901510238647, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34366229]\n",
      "  [0.35223481]\n",
      "  [0.36065254]\n",
      "  [0.36996958]\n",
      "  [0.37908709]\n",
      "  [0.38806233]\n",
      "  [0.39697266]\n",
      "  [0.40651539]]]\n",
      "ejemplar: [0.34366229 0.35223481 0.36065254 0.36996958 0.37908709 0.38806233\n",
      " 0.39697266 0.40651539]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4164338]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34366229 0.35223481 0.36065254 0.36996958 0.37908709 0.38806233\n",
      "  0.39697266 0.40651539]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09373046457767487\n",
      "Predicción post entrenamiento : [[0.41970938]]\n",
      "PERDIDAAAA despues: 0.09173552691936493\n",
      "loss en el callback: 0.13150908052921295, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35223481]\n",
      "  [0.36065254]\n",
      "  [0.36996958]\n",
      "  [0.37908709]\n",
      "  [0.38806233]\n",
      "  [0.39697266]\n",
      "  [0.40651539]\n",
      "  [0.41643381]]]\n",
      "ejemplar: [0.35223481 0.36065254 0.36996958 0.37908709 0.38806233 0.39697266\n",
      " 0.40651539 0.41643381]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4264004]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35223481 0.36065254 0.36996958 0.37908709 0.38806233 0.39697266\n",
      "  0.40651539 0.41643381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07449676841497421\n",
      "Predicción post entrenamiento : [[0.42885163]]\n",
      "PERDIDAAAA despues: 0.0731646865606308\n",
      "loss en el callback: 0.0527266226708889, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36065254]\n",
      "  [0.36996958]\n",
      "  [0.37908709]\n",
      "  [0.38806233]\n",
      "  [0.39697266]\n",
      "  [0.40651539]\n",
      "  [0.41643381]\n",
      "  [0.42640039]]]\n",
      "ejemplar: [0.36065254 0.36996958 0.37908709 0.38806233 0.39697266 0.40651539\n",
      " 0.41643381 0.42640039]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4356947]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36065254 0.36996958 0.37908709 0.38806233 0.39697266 0.40651539\n",
      "  0.41643381 0.42640039]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09097246825695038\n",
      "Predicción post entrenamiento : [[0.438531]]\n",
      "PERDIDAAAA despues: 0.08926955610513687\n",
      "loss en el callback: 0.07532250881195068, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36996958]\n",
      "  [0.37908709]\n",
      "  [0.38806233]\n",
      "  [0.39697266]\n",
      "  [0.40651539]\n",
      "  [0.41643381]\n",
      "  [0.42640039]\n",
      "  [0.43569469]]]\n",
      "ejemplar: [0.36996958 0.37908709 0.38806233 0.39697266 0.40651539 0.41643381\n",
      " 0.42640039 0.43569469]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44560537]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36996958 0.37908709 0.38806233 0.39697266 0.40651539 0.41643381\n",
      "  0.42640039 0.43569469]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0760769248008728\n",
      "Predicción post entrenamiento : [[0.44841224]]\n",
      "PERDIDAAAA despues: 0.07453642040491104\n",
      "loss en el callback: 0.11744070053100586, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37908709]\n",
      "  [0.38806233]\n",
      "  [0.39697266]\n",
      "  [0.40651539]\n",
      "  [0.41643381]\n",
      "  [0.42640039]\n",
      "  [0.43569469]\n",
      "  [0.44560537]]]\n",
      "ejemplar: [0.37908709 0.38806233 0.39697266 0.40651539 0.41643381 0.42640039\n",
      " 0.43569469 0.44560537]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45553502]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37908709 0.38806233 0.39697266 0.40651539 0.41643381 0.42640039\n",
      "  0.43569469 0.44560537]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0692630186676979\n",
      "Predicción post entrenamiento : [[0.45791197]]\n",
      "PERDIDAAAA despues: 0.06801754236221313\n",
      "loss en el callback: 0.056231237947940826, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38806233]\n",
      "  [0.39697266]\n",
      "  [0.40651539]\n",
      "  [0.41643381]\n",
      "  [0.42640039]\n",
      "  [0.43569469]\n",
      "  [0.44560537]\n",
      "  [0.45553502]]]\n",
      "ejemplar: [0.38806233 0.39697266 0.40651539 0.41643381 0.42640039 0.43569469\n",
      " 0.44560537 0.45553502]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4651504]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38806233 0.39697266 0.40651539 0.41643381 0.42640039 0.43569469\n",
      "  0.44560537 0.45553502]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04368389770388603\n",
      "Predicción post entrenamiento : [[0.4672656]]\n",
      "PERDIDAAAA despues: 0.042804181575775146\n",
      "loss en el callback: 0.05280126631259918, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39697266]\n",
      "  [0.40651539]\n",
      "  [0.41643381]\n",
      "  [0.42640039]\n",
      "  [0.43569469]\n",
      "  [0.44560537]\n",
      "  [0.45553502]\n",
      "  [0.46515039]]]\n",
      "ejemplar: [0.39697266 0.40651539 0.41643381 0.42640039 0.43569469 0.44560537\n",
      " 0.45553502 0.46515039]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47468296]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39697266 0.40651539 0.41643381 0.42640039 0.43569469 0.44560537\n",
      "  0.45553502 0.46515039]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05012381076812744\n",
      "Predicción post entrenamiento : [[0.4766168]]\n",
      "PERDIDAAAA despues: 0.04926164075732231\n",
      "loss en el callback: 0.03794676810503006, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40651539]\n",
      "  [0.41643381]\n",
      "  [0.42640039]\n",
      "  [0.43569469]\n",
      "  [0.44560537]\n",
      "  [0.45553502]\n",
      "  [0.46515039]\n",
      "  [0.47468296]]]\n",
      "ejemplar: [0.40651539 0.41643381 0.42640039 0.43569469 0.44560537 0.45553502\n",
      " 0.46515039 0.47468296]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4842614]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40651539 0.41643381 0.42640039 0.43569469 0.44560537 0.45553502\n",
      "  0.46515039 0.47468296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.056063324213027954\n",
      "Predicción post entrenamiento : [[0.48650414]]\n",
      "PERDIDAAAA despues: 0.05500629171729088\n",
      "loss en el callback: 0.05471256002783775, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41643381]\n",
      "  [0.42640039]\n",
      "  [0.43569469]\n",
      "  [0.44560537]\n",
      "  [0.45553502]\n",
      "  [0.46515039]\n",
      "  [0.47468296]\n",
      "  [0.48426139]]]\n",
      "ejemplar: [0.41643381 0.42640039 0.43569469 0.44560537 0.45553502 0.46515039\n",
      " 0.47468296 0.48426139]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49424243]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41643381 0.42640039 0.43569469 0.44560537 0.45553502 0.46515039\n",
      "  0.47468296 0.48426139]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05214175581932068\n",
      "Predicción post entrenamiento : [[0.49657008]]\n",
      "PERDIDAAAA despues: 0.05108415335416794\n",
      "loss en el callback: 0.0661068856716156, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42640039]\n",
      "  [0.43569469]\n",
      "  [0.44560537]\n",
      "  [0.45553502]\n",
      "  [0.46515039]\n",
      "  [0.47468296]\n",
      "  [0.48426139]\n",
      "  [0.49424243]]]\n",
      "ejemplar: [0.42640039 0.43569469 0.44560537 0.45553502 0.46515039 0.47468296\n",
      " 0.48426139 0.49424243]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.50430906]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42640039 0.43569469 0.44560537 0.45553502 0.46515039 0.47468296\n",
      "  0.48426139 0.49424243]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06349743902683258\n",
      "Predicción post entrenamiento : [[0.50688773]]\n",
      "PERDIDAAAA despues: 0.062204502522945404\n",
      "loss en el callback: 0.10297661274671555, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43569469]\n",
      "  [0.44560537]\n",
      "  [0.45553502]\n",
      "  [0.46515039]\n",
      "  [0.47468296]\n",
      "  [0.48426139]\n",
      "  [0.49424243]\n",
      "  [0.50430906]]]\n",
      "ejemplar: [0.43569469 0.44560537 0.45553502 0.46515039 0.47468296 0.48426139\n",
      " 0.49424243 0.50430906]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5146085]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43569469 0.44560537 0.45553502 0.46515039 0.47468296 0.48426139\n",
      "  0.49424243 0.50430906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09795506298542023\n",
      "Predicción post entrenamiento : [[0.5174973]]\n",
      "PERDIDAAAA despues: 0.09615514427423477\n",
      "loss en el callback: 0.10189235955476761, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44560537]\n",
      "  [0.45553502]\n",
      "  [0.46515039]\n",
      "  [0.47468296]\n",
      "  [0.48426139]\n",
      "  [0.49424243]\n",
      "  [0.50430906]\n",
      "  [0.5146085 ]]]\n",
      "ejemplar: [0.44560537 0.45553502 0.46515039 0.47468296 0.48426139 0.49424243\n",
      " 0.50430906 0.5146085 ]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5253765]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44560537 0.45553502 0.46515039 0.47468296 0.48426139 0.49424243\n",
      "  0.50430906 0.5146085 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0982481986284256\n",
      "Predicción post entrenamiento : [[0.528325]]\n",
      "PERDIDAAAA despues: 0.09640848636627197\n",
      "loss en el callback: 0.096250981092453, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45553502]\n",
      "  [0.46515039]\n",
      "  [0.47468296]\n",
      "  [0.48426139]\n",
      "  [0.49424243]\n",
      "  [0.50430906]\n",
      "  [0.5146085 ]\n",
      "  [0.5253765 ]]]\n",
      "ejemplar: [0.45553502 0.46515039 0.47468296 0.48426139 0.49424243 0.50430906\n",
      " 0.5146085  0.5253765 ]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.53622806]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45553502 0.46515039 0.47468296 0.48426139 0.49424243 0.50430906\n",
      "  0.5146085  0.5253765 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06658347696065903\n",
      "Predicción post entrenamiento : [[0.537333]]\n",
      "PERDIDAAAA despues: 0.06601446121931076\n",
      "loss en el callback: 0.009743793867528439, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46515039]\n",
      "  [0.47468296]\n",
      "  [0.48426139]\n",
      "  [0.49424243]\n",
      "  [0.50430906]\n",
      "  [0.5146085 ]\n",
      "  [0.5253765 ]\n",
      "  [0.53622806]]]\n",
      "ejemplar: [0.46515039 0.47468296 0.48426139 0.49424243 0.50430906 0.5146085\n",
      " 0.5253765  0.53622806]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.54526293]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46515039 0.47468296 0.48426139 0.49424243 0.50430906 0.5146085\n",
      "  0.5253765  0.53622806]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05690218135714531\n",
      "Predicción post entrenamiento : [[0.5469973]]\n",
      "PERDIDAAAA despues: 0.0560777485370636\n",
      "loss en el callback: 0.027567896991968155, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47468296]\n",
      "  [0.48426139]\n",
      "  [0.49424243]\n",
      "  [0.50430906]\n",
      "  [0.5146085 ]\n",
      "  [0.5253765 ]\n",
      "  [0.53622806]\n",
      "  [0.54526293]]]\n",
      "ejemplar: [0.47468296 0.48426139 0.49424243 0.50430906 0.5146085  0.5253765\n",
      " 0.53622806 0.54526293]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5550553]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47468296 0.48426139 0.49424243 0.50430906 0.5146085  0.5253765\n",
      "  0.53622806 0.54526293]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04531112685799599\n",
      "Predicción post entrenamiento : [[0.55689824]]\n",
      "PERDIDAAAA despues: 0.04452994093298912\n",
      "loss en el callback: 0.038397956639528275, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48426139]\n",
      "  [0.49424243]\n",
      "  [0.50430906]\n",
      "  [0.5146085 ]\n",
      "  [0.5253765 ]\n",
      "  [0.53622806]\n",
      "  [0.54526293]\n",
      "  [0.55505532]]]\n",
      "ejemplar: [0.48426139 0.49424243 0.50430906 0.5146085  0.5253765  0.53622806\n",
      " 0.54526293 0.55505532]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5651316]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48426139 0.49424243 0.50430906 0.5146085  0.5253765  0.53622806\n",
      "  0.54526293 0.55505532]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04815743863582611\n",
      "Predicción post entrenamiento : [[0.5669242]]\n",
      "PERDIDAAAA despues: 0.04737388342618942\n",
      "loss en el callback: 0.03731543570756912, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49424243]\n",
      "  [0.50430906]\n",
      "  [0.5146085 ]\n",
      "  [0.5253765 ]\n",
      "  [0.53622806]\n",
      "  [0.54526293]\n",
      "  [0.55505532]\n",
      "  [0.5651316 ]]]\n",
      "ejemplar: [0.49424243 0.50430906 0.5146085  0.5253765  0.53622806 0.54526293\n",
      " 0.55505532 0.5651316 ]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5753444]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49424243 0.50430906 0.5146085  0.5253765  0.53622806 0.54526293\n",
      "  0.55505532 0.5651316 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09204232692718506\n",
      "Predicción post entrenamiento : [[0.57792115]]\n",
      "PERDIDAAAA despues: 0.09048546105623245\n",
      "loss en el callback: 0.06782802939414978, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50430906]\n",
      "  [0.5146085 ]\n",
      "  [0.5253765 ]\n",
      "  [0.53622806]\n",
      "  [0.54526293]\n",
      "  [0.55505532]\n",
      "  [0.5651316 ]\n",
      "  [0.57534438]]]\n",
      "ejemplar: [0.50430906 0.5146085  0.5253765  0.53622806 0.54526293 0.55505532\n",
      " 0.5651316  0.57534438]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5864399]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50430906 0.5146085  0.5253765  0.53622806 0.54526293 0.55505532\n",
      "  0.5651316  0.57534438]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08363068103790283\n",
      "Predicción post entrenamiento : [[0.58897257]]\n",
      "PERDIDAAAA despues: 0.08217225223779678\n",
      "loss en el callback: 0.08190258592367172, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.5146085 ]\n",
      "  [0.5253765 ]\n",
      "  [0.53622806]\n",
      "  [0.54526293]\n",
      "  [0.55505532]\n",
      "  [0.5651316 ]\n",
      "  [0.57534438]\n",
      "  [0.58643991]]]\n",
      "ejemplar: [0.5146085  0.5253765  0.53622806 0.54526293 0.55505532 0.5651316\n",
      " 0.57534438 0.58643991]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.597572]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.5146085  0.5253765  0.53622806 0.54526293 0.55505532 0.5651316\n",
      "  0.57534438 0.58643991]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0631636306643486\n",
      "Predicción post entrenamiento : [[0.60027736]]\n",
      "PERDIDAAAA despues: 0.06181111931800842\n",
      "loss en el callback: 0.14389783143997192, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.5253765 ]\n",
      "  [0.53622806]\n",
      "  [0.54526293]\n",
      "  [0.55505532]\n",
      "  [0.5651316 ]\n",
      "  [0.57534438]\n",
      "  [0.58643991]\n",
      "  [0.59757203]]]\n",
      "ejemplar: [0.5253765  0.53622806 0.54526293 0.55505532 0.5651316  0.57534438\n",
      " 0.58643991 0.59757203]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6089021]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.5253765  0.53622806 0.54526293 0.55505532 0.5651316  0.57534438\n",
      "  0.58643991 0.59757203]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043842244893312454\n",
      "Predicción post entrenamiento : [[0.6111589]]\n",
      "PERDIDAAAA despues: 0.042902249842882156\n",
      "loss en el callback: 0.08188512176275253, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53622806]\n",
      "  [0.54526293]\n",
      "  [0.55505532]\n",
      "  [0.5651316 ]\n",
      "  [0.57534438]\n",
      "  [0.58643991]\n",
      "  [0.59757203]\n",
      "  [0.6089021 ]]]\n",
      "ejemplar: [0.53622806 0.54526293 0.55505532 0.5651316  0.57534438 0.58643991\n",
      " 0.59757203 0.6089021 ]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6196878]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53622806 0.54526293 0.55505532 0.5651316  0.57534438 0.58643991\n",
      "  0.59757203 0.6089021 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04290015250444412\n",
      "Predicción post entrenamiento : [[0.62148094]]\n",
      "PERDIDAAAA despues: 0.04216056317090988\n",
      "loss en el callback: 0.04269622266292572, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54526293]\n",
      "  [0.55505532]\n",
      "  [0.5651316 ]\n",
      "  [0.57534438]\n",
      "  [0.58643991]\n",
      "  [0.59757203]\n",
      "  [0.6089021 ]\n",
      "  [0.6196878 ]]]\n",
      "ejemplar: [0.54526293 0.55505532 0.5651316  0.57534438 0.58643991 0.59757203\n",
      " 0.6089021  0.6196878 ]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.62989163]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54526293 0.55505532 0.5651316  0.57534438 0.58643991 0.59757203\n",
      "  0.6089021  0.6196878 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024168701842427254\n",
      "Predicción post entrenamiento : [[0.63160217]]\n",
      "PERDIDAAAA despues: 0.023639777675271034\n",
      "loss en el callback: 0.04045242816209793, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55505532]\n",
      "  [0.5651316 ]\n",
      "  [0.57534438]\n",
      "  [0.58643991]\n",
      "  [0.59757203]\n",
      "  [0.6089021 ]\n",
      "  [0.6196878 ]\n",
      "  [0.62989163]]]\n",
      "ejemplar: [0.55505532 0.5651316  0.57534438 0.58643991 0.59757203 0.6089021\n",
      " 0.6196878  0.62989163]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.64040947]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55505532 0.5651316  0.57534438 0.58643991 0.59757203 0.6089021\n",
      "  0.6196878  0.62989163]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022147245705127716\n",
      "Predicción post entrenamiento : [[0.6418036]]\n",
      "PERDIDAAAA despues: 0.02173423394560814\n",
      "loss en el callback: 0.028831670060753822, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.5651316 ]\n",
      "  [0.57534438]\n",
      "  [0.58643991]\n",
      "  [0.59757203]\n",
      "  [0.6089021 ]\n",
      "  [0.6196878 ]\n",
      "  [0.62989163]\n",
      "  [0.64040947]]]\n",
      "ejemplar: [0.5651316  0.57534438 0.58643991 0.59757203 0.6089021  0.6196878\n",
      " 0.62989163 0.64040947]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.650871]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.5651316  0.57534438 0.58643991 0.59757203 0.6089021  0.6196878\n",
      "  0.62989163 0.64040947]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033599551767110825\n",
      "Predicción post entrenamiento : [[0.6528682]]\n",
      "PERDIDAAAA despues: 0.032871346920728683\n",
      "loss en el callback: 0.05970818176865578, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57534438]\n",
      "  [0.58643991]\n",
      "  [0.59757203]\n",
      "  [0.6089021 ]\n",
      "  [0.6196878 ]\n",
      "  [0.62989163]\n",
      "  [0.64040947]\n",
      "  [0.65087098]]]\n",
      "ejemplar: [0.57534438 0.58643991 0.59757203 0.6089021  0.6196878  0.62989163\n",
      " 0.64040947 0.65087098]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.66215855]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57534438 0.58643991 0.59757203 0.6089021  0.6196878  0.62989163\n",
      "  0.64040947 0.65087098]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022595277056097984\n",
      "Predicción post entrenamiento : [[0.6639509]]\n",
      "PERDIDAAAA despues: 0.022059639915823936\n",
      "loss en el callback: 0.05236018821597099, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58643991]\n",
      "  [0.59757203]\n",
      "  [0.6089021 ]\n",
      "  [0.6196878 ]\n",
      "  [0.62989163]\n",
      "  [0.64040947]\n",
      "  [0.65087098]\n",
      "  [0.66215855]]]\n",
      "ejemplar: [0.58643991 0.59757203 0.6089021  0.6196878  0.62989163 0.64040947\n",
      " 0.65087098 0.66215855]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6734512]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58643991 0.59757203 0.6089021  0.6196878  0.62989163 0.64040947\n",
      "  0.65087098 0.66215855]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016329942271113396\n",
      "Predicción post entrenamiento : [[0.67523235]]\n",
      "PERDIDAAAA despues: 0.015877889469265938\n",
      "loss en el callback: 0.056779857724905014, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59757203]\n",
      "  [0.6089021 ]\n",
      "  [0.6196878 ]\n",
      "  [0.62989163]\n",
      "  [0.64040947]\n",
      "  [0.65087098]\n",
      "  [0.66215855]\n",
      "  [0.67345119]]]\n",
      "ejemplar: [0.59757203 0.6089021  0.6196878  0.62989163 0.64040947 0.65087098\n",
      " 0.66215855 0.67345119]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.68471146]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59757203 0.6089021  0.6196878  0.62989163 0.64040947 0.65087098\n",
      "  0.66215855 0.67345119]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014034098945558071\n",
      "Predicción post entrenamiento : [[0.6854944]]\n",
      "PERDIDAAAA despues: 0.013849202543497086\n",
      "loss en el callback: 0.007110155187547207, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.6089021 ]\n",
      "  [0.6196878 ]\n",
      "  [0.62989163]\n",
      "  [0.64040947]\n",
      "  [0.65087098]\n",
      "  [0.66215855]\n",
      "  [0.67345119]\n",
      "  [0.68471146]]]\n",
      "ejemplar: [0.6089021  0.6196878  0.62989163 0.64040947 0.65087098 0.66215855\n",
      " 0.67345119 0.68471146]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.69492584]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.6089021  0.6196878  0.62989163 0.64040947 0.65087098 0.66215855\n",
      "  0.67345119 0.68471146]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009715067222714424\n",
      "Predicción post entrenamiento : [[0.6952398]]\n",
      "PERDIDAAAA despues: 0.009653279557824135\n",
      "loss en el callback: 0.0011418401263654232, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.6196878 ]\n",
      "  [0.62989163]\n",
      "  [0.64040947]\n",
      "  [0.65087098]\n",
      "  [0.66215855]\n",
      "  [0.67345119]\n",
      "  [0.68471146]\n",
      "  [0.69492584]]]\n",
      "ejemplar: [0.6196878  0.62989163 0.64040947 0.65087098 0.66215855 0.67345119\n",
      " 0.68471146 0.69492584]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.70455295]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.6196878  0.62989163 0.64040947 0.65087098 0.66215855 0.67345119\n",
      "  0.68471146 0.69492584]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030933076050132513\n",
      "Predicción post entrenamiento : [[0.7053194]]\n",
      "PERDIDAAAA despues: 0.0030086382757872343\n",
      "loss en el callback: 0.009667432866990566, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62989163]\n",
      "  [0.64040947]\n",
      "  [0.65087098]\n",
      "  [0.66215855]\n",
      "  [0.67345119]\n",
      "  [0.68471146]\n",
      "  [0.69492584]\n",
      "  [0.70455295]]]\n",
      "ejemplar: [0.62989163 0.64040947 0.65087098 0.66215855 0.67345119 0.68471146\n",
      " 0.69492584 0.70455295]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.71464914]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62989163 0.64040947 0.65087098 0.66215855 0.67345119 0.68471146\n",
      "  0.69492584 0.70455295]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004295162216294557\n",
      "Predicción post entrenamiento : [[0.71528536]]\n",
      "PERDIDAAAA despues: 0.00040354998782277107\n",
      "loss en el callback: 0.007115654647350311, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.64040947]\n",
      "  [0.65087098]\n",
      "  [0.66215855]\n",
      "  [0.67345119]\n",
      "  [0.68471146]\n",
      "  [0.69492584]\n",
      "  [0.70455295]\n",
      "  [0.71464914]]]\n",
      "ejemplar: [0.64040947 0.65087098 0.66215855 0.67345119 0.68471146 0.69492584\n",
      " 0.70455295 0.71464914]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7247915]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.64040947 0.65087098 0.66215855 0.67345119 0.68471146 0.69492584\n",
      "  0.70455295 0.71464914]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021320985979400575\n",
      "Predicción post entrenamiento : [[0.72422135]]\n",
      "PERDIDAAAA despues: 0.0001968838187167421\n",
      "loss en el callback: 0.004072247538715601, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.65087098]\n",
      "  [0.66215855]\n",
      "  [0.67345119]\n",
      "  [0.68471146]\n",
      "  [0.69492584]\n",
      "  [0.70455295]\n",
      "  [0.71464914]\n",
      "  [0.72479153]]]\n",
      "ejemplar: [0.65087098 0.66215855 0.67345119 0.68471146 0.69492584 0.70455295\n",
      " 0.71464914 0.72479153]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7338137]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.65087098 0.66215855 0.67345119 0.68471146 0.69492584 0.70455295\n",
      "  0.71464914 0.72479153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004703091981355101\n",
      "Predicción post entrenamiento : [[0.733281]]\n",
      "PERDIDAAAA despues: 0.0004474886227399111\n",
      "loss en el callback: 0.003741759341210127, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.66215855]\n",
      "  [0.67345119]\n",
      "  [0.68471146]\n",
      "  [0.69492584]\n",
      "  [0.70455295]\n",
      "  [0.71464914]\n",
      "  [0.72479153]\n",
      "  [0.7338137 ]]]\n",
      "ejemplar: [0.66215855 0.67345119 0.68471146 0.69492584 0.70455295 0.71464914\n",
      " 0.72479153 0.7338137 ]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7429531]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.66215855 0.67345119 0.68471146 0.69492584 0.70455295 0.71464914\n",
      "  0.72479153 0.7338137 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1004455700458493e-05\n",
      "Predicción post entrenamiento : [[0.7427745]]\n",
      "PERDIDAAAA despues: 9.85119550023228e-06\n",
      "loss en el callback: 0.00043970535625703633, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.67345119]\n",
      "  [0.68471146]\n",
      "  [0.69492584]\n",
      "  [0.70455295]\n",
      "  [0.71464914]\n",
      "  [0.72479153]\n",
      "  [0.7338137 ]\n",
      "  [0.74295312]]]\n",
      "ejemplar: [0.67345119 0.68471146 0.69492584 0.70455295 0.71464914 0.72479153\n",
      " 0.7338137  0.74295312]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.75224817]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.67345119 0.68471146 0.69492584 0.70455295 0.71464914 0.72479153\n",
      "  0.7338137  0.74295312]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002591904776636511\n",
      "Predicción post entrenamiento : [[0.7505049]]\n",
      "PERDIDAAAA despues: 0.00020609864441212267\n",
      "loss en el callback: 0.031688615679740906, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.68471146]\n",
      "  [0.69492584]\n",
      "  [0.70455295]\n",
      "  [0.71464914]\n",
      "  [0.72479153]\n",
      "  [0.7338137 ]\n",
      "  [0.74295312]\n",
      "  [0.75224817]]]\n",
      "ejemplar: [0.68471146 0.69492584 0.70455295 0.71464914 0.72479153 0.7338137\n",
      " 0.74295312 0.75224817]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.75969005]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.68471146 0.69492584 0.70455295 0.71464914 0.72479153 0.7338137\n",
      "  0.74295312 0.75224817]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008485971949994564\n",
      "Predicción post entrenamiento : [[0.7588448]]\n",
      "PERDIDAAAA despues: 0.00833095796406269\n",
      "loss en el callback: 0.010713091120123863, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.69492584]\n",
      "  [0.70455295]\n",
      "  [0.71464914]\n",
      "  [0.72479153]\n",
      "  [0.7338137 ]\n",
      "  [0.74295312]\n",
      "  [0.75224817]\n",
      "  [0.75969005]]]\n",
      "ejemplar: [0.69492584 0.70455295 0.71464914 0.72479153 0.7338137  0.74295312\n",
      " 0.75224817 0.75969005]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7676558]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.69492584 0.70455295 0.71464914 0.72479153 0.7338137  0.74295312\n",
      "  0.75224817 0.75969005]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009557091630995274\n",
      "Predicción post entrenamiento : [[0.7663037]]\n",
      "PERDIDAAAA despues: 0.009294562041759491\n",
      "loss en el callback: 0.022222120314836502, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.70455295]\n",
      "  [0.71464914]\n",
      "  [0.72479153]\n",
      "  [0.7338137 ]\n",
      "  [0.74295312]\n",
      "  [0.75224817]\n",
      "  [0.75969005]\n",
      "  [0.76765579]]]\n",
      "ejemplar: [0.70455295 0.71464914 0.72479153 0.7338137  0.74295312 0.75224817\n",
      " 0.75969005 0.76765579]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7749379]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.70455295 0.71464914 0.72479153 0.7338137  0.74295312 0.75224817\n",
      "  0.75969005 0.76765579]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006132252514362335\n",
      "Predicción post entrenamiento : [[0.7744643]]\n",
      "PERDIDAAAA despues: 0.0060582999140024185\n",
      "loss en el callback: 0.0035787385422736406, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.71464914]\n",
      "  [0.72479153]\n",
      "  [0.7338137 ]\n",
      "  [0.74295312]\n",
      "  [0.75224817]\n",
      "  [0.75969005]\n",
      "  [0.76765579]\n",
      "  [0.77493793]]]\n",
      "ejemplar: [0.71464914 0.72479153 0.7338137  0.74295312 0.75224817 0.75969005\n",
      " 0.76765579 0.77493793]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7830134]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.71464914 0.72479153 0.7338137  0.74295312 0.75224817 0.75969005\n",
      "  0.76765579 0.77493793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01614578813314438\n",
      "Predicción post entrenamiento : [[0.7809232]]\n",
      "PERDIDAAAA despues: 0.015618965961039066\n",
      "loss en el callback: 0.05212936922907829, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.72479153]\n",
      "  [0.7338137 ]\n",
      "  [0.74295312]\n",
      "  [0.75224817]\n",
      "  [0.75969005]\n",
      "  [0.76765579]\n",
      "  [0.77493793]\n",
      "  [0.7830134 ]]]\n",
      "ejemplar: [0.72479153 0.7338137  0.74295312 0.75224817 0.75969005 0.76765579\n",
      " 0.77493793 0.7830134 ]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.78916776]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.72479153 0.7338137  0.74295312 0.75224817 0.75969005 0.76765579\n",
      "  0.77493793 0.7830134 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012179572135210037\n",
      "Predicción post entrenamiento : [[0.7870697]]\n",
      "PERDIDAAAA despues: 0.01172088086605072\n",
      "loss en el callback: 0.04995998367667198, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.7338137 ]\n",
      "  [0.74295312]\n",
      "  [0.75224817]\n",
      "  [0.75969005]\n",
      "  [0.76765579]\n",
      "  [0.77493793]\n",
      "  [0.7830134 ]\n",
      "  [0.78916776]]]\n",
      "ejemplar: [0.7338137  0.74295312 0.75224817 0.75969005 0.76765579 0.77493793\n",
      " 0.7830134  0.78916776]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.79488367]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.7338137  0.74295312 0.75224817 0.75969005 0.76765579 0.77493793\n",
      "  0.7830134  0.78916776]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014110858552157879\n",
      "Predicción post entrenamiento : [[0.7937267]]\n",
      "PERDIDAAAA despues: 0.01383732259273529\n",
      "loss en el callback: 0.0185503289103508, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.74295312]\n",
      "  [0.75224817]\n",
      "  [0.75969005]\n",
      "  [0.76765579]\n",
      "  [0.77493793]\n",
      "  [0.7830134 ]\n",
      "  [0.78916776]\n",
      "  [0.79488367]]]\n",
      "ejemplar: [0.74295312 0.75224817 0.75969005 0.76765579 0.77493793 0.7830134\n",
      " 0.78916776 0.79488367]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.8013129]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.74295312 0.75224817 0.75969005 0.76765579 0.77493793 0.7830134\n",
      "  0.78916776 0.79488367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0051481714472174644\n",
      "Predicción post entrenamiento : [[0.80136204]]\n",
      "PERDIDAAAA despues: 0.005155222024768591\n",
      "loss en el callback: 4.407874439493753e-05, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.75224817]\n",
      "  [0.75969005]\n",
      "  [0.76765579]\n",
      "  [0.77493793]\n",
      "  [0.7830134 ]\n",
      "  [0.78916776]\n",
      "  [0.79488367]\n",
      "  [0.80131292]]]\n",
      "ejemplar: [0.75224817 0.75969005 0.76765579 0.77493793 0.7830134  0.78916776\n",
      " 0.79488367 0.80131292]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.8085864]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.75224817 0.75969005 0.76765579 0.77493793 0.7830134  0.78916776\n",
      "  0.79488367 0.80131292]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011514974758028984\n",
      "Predicción post entrenamiento : [[0.80766726]]\n",
      "PERDIDAAAA despues: 0.011318553239107132\n",
      "loss en el callback: 0.012436416000127792, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.75969005]\n",
      "  [0.76765579]\n",
      "  [0.77493793]\n",
      "  [0.7830134 ]\n",
      "  [0.78916776]\n",
      "  [0.79488367]\n",
      "  [0.80131292]\n",
      "  [0.80858642]]]\n",
      "ejemplar: [0.75969005 0.76765579 0.77493793 0.7830134  0.78916776 0.79488367\n",
      " 0.80131292 0.80858642]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8143675]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.75969005 0.76765579 0.77493793 0.7830134  0.78916776 0.79488367\n",
      "  0.80131292 0.80858642]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002193562453612685\n",
      "Predicción post entrenamiento : [[0.81416774]]\n",
      "PERDIDAAAA despues: 0.0021748929284512997\n",
      "loss en el callback: 0.0006514117121696472, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.76765579]\n",
      "  [0.77493793]\n",
      "  [0.7830134 ]\n",
      "  [0.78916776]\n",
      "  [0.79488367]\n",
      "  [0.80131292]\n",
      "  [0.80858642]\n",
      "  [0.81436747]]]\n",
      "ejemplar: [0.76765579 0.77493793 0.7830134  0.78916776 0.79488367 0.80131292\n",
      " 0.80858642 0.81436747]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.8207755]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.76765579 0.77493793 0.7830134  0.78916776 0.79488367 0.80131292\n",
      "  0.80858642 0.81436747]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004308848641812801\n",
      "Predicción post entrenamiento : [[0.8204874]]\n",
      "PERDIDAAAA despues: 0.00427110493183136\n",
      "loss en el callback: 0.0013107886770740151, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.77493793]\n",
      "  [0.7830134 ]\n",
      "  [0.78916776]\n",
      "  [0.79488367]\n",
      "  [0.80131292]\n",
      "  [0.80858642]\n",
      "  [0.81436747]\n",
      "  [0.82077551]]]\n",
      "ejemplar: [0.77493793 0.7830134  0.78916776 0.79488367 0.80131292 0.80858642\n",
      " 0.81436747 0.82077551]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.82679385]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.77493793 0.7830134  0.78916776 0.79488367 0.80131292 0.80858642\n",
      "  0.81436747 0.82077551]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0066804178059101105\n",
      "Predicción post entrenamiento : [[0.82596093]]\n",
      "PERDIDAAAA despues: 0.006544956937432289\n",
      "loss en el callback: 0.01015602145344019, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.7830134 ]\n",
      "  [0.78916776]\n",
      "  [0.79488367]\n",
      "  [0.80131292]\n",
      "  [0.80858642]\n",
      "  [0.81436747]\n",
      "  [0.82077551]\n",
      "  [0.82679385]]]\n",
      "ejemplar: [0.7830134  0.78916776 0.79488367 0.80131292 0.80858642 0.81436747\n",
      " 0.82077551 0.82679385]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.83209294]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.7830134  0.78916776 0.79488367 0.80131292 0.80858642 0.81436747\n",
      "  0.82077551 0.82679385]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0064094229601323605\n",
      "Predicción post entrenamiento : [[0.832595]]\n",
      "PERDIDAAAA despues: 0.006490062456578016\n",
      "loss en el callback: 0.00564282201230526, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.78916776]\n",
      "  [0.79488367]\n",
      "  [0.80131292]\n",
      "  [0.80858642]\n",
      "  [0.81436747]\n",
      "  [0.82077551]\n",
      "  [0.82679385]\n",
      "  [0.83209294]]]\n",
      "ejemplar: [0.78916776 0.79488367 0.80131292 0.80858642 0.81436747 0.82077551\n",
      " 0.82679385 0.83209294]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8382638]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.78916776 0.79488367 0.80131292 0.80858642 0.81436747 0.82077551\n",
      "  0.82679385 0.83209294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01650233566761017\n",
      "Predicción post entrenamiento : [[0.83704877]]\n",
      "PERDIDAAAA despues: 0.016191640868782997\n",
      "loss en el callback: 0.021465390920639038, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.79488367]\n",
      "  [0.80131292]\n",
      "  [0.80858642]\n",
      "  [0.81436747]\n",
      "  [0.82077551]\n",
      "  [0.82679385]\n",
      "  [0.83209294]\n",
      "  [0.83826381]]]\n",
      "ejemplar: [0.79488367 0.80131292 0.80858642 0.81436747 0.82077551 0.82679385\n",
      " 0.83209294 0.83826381]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.842744]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.79488367 0.80131292 0.80858642 0.81436747 0.82077551 0.82679385\n",
      "  0.83209294 0.83826381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02319953776896\n",
      "Predicción post entrenamiento : [[0.84181726]]\n",
      "PERDIDAAAA despues: 0.022918088361620903\n",
      "loss en el callback: 0.014731954783201218, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.80131292]\n",
      "  [0.80858642]\n",
      "  [0.81436747]\n",
      "  [0.82077551]\n",
      "  [0.82679385]\n",
      "  [0.83209294]\n",
      "  [0.83826381]\n",
      "  [0.84274399]]]\n",
      "ejemplar: [0.80131292 0.80858642 0.81436747 0.82077551 0.82679385 0.83209294\n",
      " 0.83826381 0.84274399]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8476541]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.80131292 0.80858642 0.81436747 0.82077551 0.82679385 0.83209294\n",
      "  0.83826381 0.84274399]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008704019710421562\n",
      "Predicción post entrenamiento : [[0.84735453]]\n",
      "PERDIDAAAA despues: 0.008648212067782879\n",
      "loss en el callback: 0.0016033126739785075, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.80858642]\n",
      "  [0.81436747]\n",
      "  [0.82077551]\n",
      "  [0.82679385]\n",
      "  [0.83209294]\n",
      "  [0.83826381]\n",
      "  [0.84274399]\n",
      "  [0.8476541 ]]]\n",
      "ejemplar: [0.80858642 0.81436747 0.82077551 0.82679385 0.83209294 0.83826381\n",
      " 0.84274399 0.8476541 ]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.85310495]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.80858642 0.81436747 0.82077551 0.82679385 0.83209294 0.83826381\n",
      "  0.84274399 0.8476541 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017135923728346825\n",
      "Predicción post entrenamiento : [[0.8528231]]\n",
      "PERDIDAAAA despues: 0.01706220768392086\n",
      "loss en el callback: 0.0016446789959445596, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.81436747]\n",
      "  [0.82077551]\n",
      "  [0.82679385]\n",
      "  [0.83209294]\n",
      "  [0.83826381]\n",
      "  [0.84274399]\n",
      "  [0.8476541 ]\n",
      "  [0.85310495]]]\n",
      "ejemplar: [0.81436747 0.82077551 0.82679385 0.83209294 0.83826381 0.84274399\n",
      " 0.8476541  0.85310495]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.85817903]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.81436747 0.82077551 0.82679385 0.83209294 0.83826381 0.84274399\n",
      "  0.8476541  0.85310495]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.35219504754059e-05\n",
      "Predicción post entrenamiento : [[0.8571769]]\n",
      "PERDIDAAAA despues: 7.51436164136976e-05\n",
      "loss en el callback: 0.01604303903877735, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.82077551]\n",
      "  [0.82679385]\n",
      "  [0.83209294]\n",
      "  [0.83826381]\n",
      "  [0.84274399]\n",
      "  [0.8476541 ]\n",
      "  [0.85310495]\n",
      "  [0.85817903]]]\n",
      "ejemplar: [0.82077551 0.82679385 0.83209294 0.83826381 0.84274399 0.8476541\n",
      " 0.85310495 0.85817903]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8624954]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.82077551 0.82679385 0.83209294 0.83826381 0.84274399 0.8476541\n",
      "  0.85310495 0.85817903]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018462110310792923\n",
      "Predicción post entrenamiento : [[0.8639002]]\n",
      "PERDIDAAAA despues: 0.0017274660058319569\n",
      "loss en el callback: 0.05460774153470993, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.82679385]\n",
      "  [0.83209294]\n",
      "  [0.83826381]\n",
      "  [0.84274399]\n",
      "  [0.8476541 ]\n",
      "  [0.85310495]\n",
      "  [0.85817903]\n",
      "  [0.86249542]]]\n",
      "ejemplar: [0.82679385 0.83209294 0.83826381 0.84274399 0.8476541  0.85310495\n",
      " 0.85817903 0.86249542]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8689585]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.82679385 0.83209294 0.83826381 0.84274399 0.8476541  0.85310495\n",
      "  0.85817903 0.86249542]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017576772370375693\n",
      "Predicción post entrenamiento : [[0.86978114]]\n",
      "PERDIDAAAA despues: 0.0001546311832498759\n",
      "loss en el callback: 0.013888722285628319, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.83209294]\n",
      "  [0.83826381]\n",
      "  [0.84274399]\n",
      "  [0.8476541 ]\n",
      "  [0.85310495]\n",
      "  [0.85817903]\n",
      "  [0.86249542]\n",
      "  [0.86895847]]]\n",
      "ejemplar: [0.83209294 0.83826381 0.84274399 0.8476541  0.85310495 0.85817903\n",
      " 0.86249542 0.86895847]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.87463796]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.83209294 0.83826381 0.84274399 0.8476541  0.85310495 0.85817903\n",
      "  0.86249542 0.86895847]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001098903827369213\n",
      "Predicción post entrenamiento : [[0.87578607]]\n",
      "PERDIDAAAA despues: 0.0010241033742204309\n",
      "loss en el callback: 0.03416217491030693, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.83826381]\n",
      "  [0.84274399]\n",
      "  [0.8476541 ]\n",
      "  [0.85310495]\n",
      "  [0.85817903]\n",
      "  [0.86249542]\n",
      "  [0.86895847]\n",
      "  [0.87463796]]]\n",
      "ejemplar: [0.83826381 0.84274399 0.8476541  0.85310495 0.85817903 0.86249542\n",
      " 0.86895847 0.87463796]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8806271]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.83826381 0.84274399 0.8476541  0.85310495 0.85817903 0.86249542\n",
      "  0.86895847 0.87463796]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.011308091226965e-05\n",
      "Predicción post entrenamiento : [[0.8814564]]\n",
      "PERDIDAAAA despues: 6.59557044855319e-05\n",
      "loss en el callback: 0.015188375487923622, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.84274399]\n",
      "  [0.8476541 ]\n",
      "  [0.85310495]\n",
      "  [0.85817903]\n",
      "  [0.86249542]\n",
      "  [0.86895847]\n",
      "  [0.87463796]\n",
      "  [0.8806271 ]]]\n",
      "ejemplar: [0.84274399 0.8476541  0.85310495 0.85817903 0.86249542 0.86895847\n",
      " 0.87463796 0.8806271 ]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.88602144]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.84274399 0.8476541  0.85310495 0.85817903 0.86249542 0.86895847\n",
      "  0.87463796 0.8806271 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012469633657019585\n",
      "Predicción post entrenamiento : [[0.8864612]]\n",
      "PERDIDAAAA despues: 0.00013471118290908635\n",
      "loss en el callback: 0.004186893347650766, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.8476541 ]\n",
      "  [0.85310495]\n",
      "  [0.85817903]\n",
      "  [0.86249542]\n",
      "  [0.86895847]\n",
      "  [0.87463796]\n",
      "  [0.8806271 ]\n",
      "  [0.88602144]]]\n",
      "ejemplar: [0.8476541  0.85310495 0.85817903 0.86249542 0.86895847 0.87463796\n",
      " 0.8806271  0.88602144]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.89124346]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.8476541  0.85310495 0.85817903 0.86249542 0.86895847 0.87463796\n",
      "  0.8806271  0.88602144]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004826142976526171\n",
      "Predicción post entrenamiento : [[0.8915322]]\n",
      "PERDIDAAAA despues: 0.00047001196071505547\n",
      "loss en el callback: 0.0014642185997217894, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.85310495]\n",
      "  [0.85817903]\n",
      "  [0.86249542]\n",
      "  [0.86895847]\n",
      "  [0.87463796]\n",
      "  [0.8806271 ]\n",
      "  [0.88602144]\n",
      "  [0.89124346]]]\n",
      "ejemplar: [0.85310495 0.85817903 0.86249542 0.86895847 0.87463796 0.8806271\n",
      " 0.88602144 0.89124346]\n",
      "y: 1.0\n",
      "Predicción : [[0.896451]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.85310495 0.85817903 0.86249542 0.86895847 0.87463796 0.8806271\n",
      "  0.88602144 0.89124346]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010722395963966846\n",
      "Predicción post entrenamiento : [[0.89685273]]\n",
      "PERDIDAAAA despues: 0.01063935924321413\n",
      "loss en el callback: 0.002704351907595992, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.85817903]\n",
      "  [0.86249542]\n",
      "  [0.86895847]\n",
      "  [0.87463796]\n",
      "  [0.8806271 ]\n",
      "  [0.88602144]\n",
      "  [0.89124346]\n",
      "  [0.896451  ]]]\n",
      "ejemplar: [0.85817903 0.86249542 0.86895847 0.87463796 0.8806271  0.88602144\n",
      " 0.89124346 0.896451  ]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.90177333]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.85817903 0.86249542 0.86895847 0.87463796 0.8806271  0.88602144\n",
      "  0.89124346 0.896451  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004730787593871355\n",
      "Predicción post entrenamiento : [[0.9026467]]\n",
      "PERDIDAAAA despues: 0.00461140600964427\n",
      "loss en el callback: 0.014658327214419842, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.86249542]\n",
      "  [0.86895847]\n",
      "  [0.87463796]\n",
      "  [0.8806271 ]\n",
      "  [0.88602144]\n",
      "  [0.89124346]\n",
      "  [0.896451  ]\n",
      "  [0.90177333]]]\n",
      "ejemplar: [0.86249542 0.86895847 0.87463796 0.8806271  0.88602144 0.89124346\n",
      " 0.896451   0.90177333]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.9076903]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.86249542 0.86895847 0.87463796 0.8806271  0.88602144 0.89124346\n",
      "  0.896451   0.90177333]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035673839738592505\n",
      "Predicción post entrenamiento : [[0.9087234]]\n",
      "PERDIDAAAA despues: 0.0003968321834690869\n",
      "loss en el callback: 0.026335598900914192, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.86895847]\n",
      "  [0.87463796]\n",
      "  [0.8806271 ]\n",
      "  [0.88602144]\n",
      "  [0.89124346]\n",
      "  [0.896451  ]\n",
      "  [0.90177333]\n",
      "  [0.90769029]]]\n",
      "ejemplar: [0.86895847 0.87463796 0.8806271  0.88602144 0.89124346 0.896451\n",
      " 0.90177333 0.90769029]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.91413987]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.86895847 0.87463796 0.8806271  0.88602144 0.89124346 0.896451\n",
      "  0.90177333 0.90769029]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001309394952841103\n",
      "Predicción post entrenamiento : [[0.91277605]]\n",
      "PERDIDAAAA despues: 0.0012125541688874364\n",
      "loss en el callback: 0.02720809355378151, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.87463796]\n",
      "  [0.8806271 ]\n",
      "  [0.88602144]\n",
      "  [0.89124346]\n",
      "  [0.896451  ]\n",
      "  [0.90177333]\n",
      "  [0.90769029]\n",
      "  [0.91413987]]]\n",
      "ejemplar: [0.87463796 0.8806271  0.88602144 0.89124346 0.896451   0.90177333\n",
      " 0.90769029 0.91413987]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.91795325]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.87463796 0.8806271  0.88602144 0.89124346 0.896451   0.90177333\n",
      "  0.90769029 0.91413987]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047689336352050304\n",
      "Predicción post entrenamiento : [[0.9179606]]\n",
      "PERDIDAAAA despues: 0.0047699459828436375\n",
      "loss en el callback: 1.168667949968949e-06, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.8806271 ]\n",
      "  [0.88602144]\n",
      "  [0.89124346]\n",
      "  [0.896451  ]\n",
      "  [0.90177333]\n",
      "  [0.90769029]\n",
      "  [0.91413987]\n",
      "  [0.91795325]]]\n",
      "ejemplar: [0.8806271  0.88602144 0.89124346 0.896451   0.90177333 0.90769029\n",
      " 0.91413987 0.91795325]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.92309487]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.8806271  0.88602144 0.89124346 0.896451   0.90177333 0.90769029\n",
      "  0.91413987 0.91795325]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007907137274742126\n",
      "Predicción post entrenamiento : [[0.92309815]]\n",
      "PERDIDAAAA despues: 0.007907720282673836\n",
      "loss en el callback: 2.6398225827506394e-07, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.88602144]\n",
      "  [0.89124346]\n",
      "  [0.896451  ]\n",
      "  [0.90177333]\n",
      "  [0.90769029]\n",
      "  [0.91413987]\n",
      "  [0.91795325]\n",
      "  [0.92309487]]]\n",
      "ejemplar: [0.88602144 0.89124346 0.896451   0.90177333 0.90769029 0.91413987\n",
      " 0.91795325 0.92309487]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9280781]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.88602144 0.89124346 0.896451   0.90177333 0.90769029 0.91413987\n",
      "  0.91795325 0.92309487]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005326548125594854\n",
      "Predicción post entrenamiento : [[0.92903817]]\n",
      "PERDIDAAAA despues: 0.00546760531142354\n",
      "loss en el callback: 0.024713557213544846, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.89124346]\n",
      "  [0.896451  ]\n",
      "  [0.90177333]\n",
      "  [0.90769029]\n",
      "  [0.91413987]\n",
      "  [0.91795325]\n",
      "  [0.92309487]\n",
      "  [0.92807811]]]\n",
      "ejemplar: [0.89124346 0.896451   0.90177333 0.90769029 0.91413987 0.91795325\n",
      " 0.92309487 0.92807811]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9340151]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.89124346 0.896451   0.90177333 0.90769029 0.91413987 0.91795325\n",
      "  0.92309487 0.92807811]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00345425633713603\n",
      "Predicción post entrenamiento : [[0.93286806]]\n",
      "PERDIDAAAA despues: 0.0033207430969923735\n",
      "loss en el callback: 0.021201830357313156, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.896451  ]\n",
      "  [0.90177333]\n",
      "  [0.90769029]\n",
      "  [0.91413987]\n",
      "  [0.91795325]\n",
      "  [0.92309487]\n",
      "  [0.92807811]\n",
      "  [0.9340151 ]]]\n",
      "ejemplar: [0.896451   0.90177333 0.90769029 0.91413987 0.91795325 0.92309487\n",
      " 0.92807811 0.9340151 ]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.93788546]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.896451   0.90177333 0.90769029 0.91413987 0.91795325 0.92309487\n",
      "  0.92807811 0.9340151 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006537253502756357\n",
      "Predicción post entrenamiento : [[0.93720686]]\n",
      "PERDIDAAAA despues: 0.006427980028092861\n",
      "loss en el callback: 0.008651194162666798, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.90177333]\n",
      "  [0.90769029]\n",
      "  [0.91413987]\n",
      "  [0.91795325]\n",
      "  [0.92309487]\n",
      "  [0.92807811]\n",
      "  [0.9340151 ]\n",
      "  [0.93788546]]]\n",
      "ejemplar: [0.90177333 0.90769029 0.91413987 0.91795325 0.92309487 0.92807811\n",
      " 0.9340151  0.93788546]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9422611]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.90177333 0.90769029 0.91413987 0.91795325 0.92309487 0.92807811\n",
      "  0.9340151  0.93788546]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008501386269927025\n",
      "Predicción post entrenamiento : [[0.94256675]]\n",
      "PERDIDAAAA despues: 0.00855784397572279\n",
      "loss en el callback: 0.0022800564765930176, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.90769029]\n",
      "  [0.91413987]\n",
      "  [0.91795325]\n",
      "  [0.92309487]\n",
      "  [0.92807811]\n",
      "  [0.9340151 ]\n",
      "  [0.93788546]\n",
      "  [0.9422611 ]]]\n",
      "ejemplar: [0.90769029 0.91413987 0.91795325 0.92309487 0.92807811 0.9340151\n",
      " 0.93788546 0.9422611 ]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.94760525]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.90769029 0.91413987 0.91795325 0.92309487 0.92807811 0.9340151\n",
      "  0.93788546 0.9422611 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011005823500454426\n",
      "Predicción post entrenamiento : [[0.9463606]]\n",
      "PERDIDAAAA despues: 0.01074622105807066\n",
      "loss en el callback: 0.026402868330478668, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.91413987]\n",
      "  [0.91795325]\n",
      "  [0.92309487]\n",
      "  [0.92807811]\n",
      "  [0.9340151 ]\n",
      "  [0.93788546]\n",
      "  [0.9422611 ]\n",
      "  [0.94760525]]]\n",
      "ejemplar: [0.91413987 0.91795325 0.92309487 0.92807811 0.9340151  0.93788546\n",
      " 0.9422611  0.94760525]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.95116943]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.91413987 0.91795325 0.92309487 0.92807811 0.9340151  0.93788546\n",
      "  0.9422611  0.94760525]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01644359901547432\n",
      "Predicción post entrenamiento : [[0.9506728]]\n",
      "PERDIDAAAA despues: 0.016316479071974754\n",
      "loss en el callback: 0.005280657671391964, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.91795325]\n",
      "  [0.92309487]\n",
      "  [0.92807811]\n",
      "  [0.9340151 ]\n",
      "  [0.93788546]\n",
      "  [0.9422611 ]\n",
      "  [0.94760525]\n",
      "  [0.95116943]]]\n",
      "ejemplar: [0.91795325 0.92309487 0.92807811 0.9340151  0.93788546 0.9422611\n",
      " 0.94760525 0.95116943]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.95503074]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.91795325 0.92309487 0.92807811 0.9340151  0.93788546 0.9422611\n",
      "  0.94760525 0.95116943]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03258917108178139\n",
      "Predicción post entrenamiento : [[0.95422465]]\n",
      "PERDIDAAAA despues: 0.03229878097772598\n",
      "loss en el callback: 0.013628002256155014, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.92309487]\n",
      "  [0.92807811]\n",
      "  [0.9340151 ]\n",
      "  [0.93788546]\n",
      "  [0.9422611 ]\n",
      "  [0.94760525]\n",
      "  [0.95116943]\n",
      "  [0.95503074]]]\n",
      "ejemplar: [0.92309487 0.92807811 0.9340151  0.93788546 0.9422611  0.94760525\n",
      " 0.95116943 0.95503074]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9588598]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.92309487 0.92807811 0.9340151  0.93788546 0.9422611  0.94760525\n",
      "  0.95116943 0.95503074]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03050879016518593\n",
      "Predicción post entrenamiento : [[0.95819324]]\n",
      "PERDIDAAAA despues: 0.030276382341980934\n",
      "loss en el callback: 0.010597605258226395, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.92807811]\n",
      "  [0.9340151 ]\n",
      "  [0.93788546]\n",
      "  [0.9422611 ]\n",
      "  [0.94760525]\n",
      "  [0.95116943]\n",
      "  [0.95503074]\n",
      "  [0.9588598 ]]]\n",
      "ejemplar: [0.92807811 0.9340151  0.93788546 0.9422611  0.94760525 0.95116943\n",
      " 0.95503074 0.9588598 ]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9627093]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.92807811 0.9340151  0.93788546 0.9422611  0.94760525 0.95116943\n",
      "  0.95503074 0.9588598 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010601790621876717\n",
      "Predicción post entrenamiento : [[0.96106225]]\n",
      "PERDIDAAAA despues: 0.01026532519608736\n",
      "loss en el callback: 0.04548142850399017, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.9340151 ]\n",
      "  [0.93788546]\n",
      "  [0.9422611 ]\n",
      "  [0.94760525]\n",
      "  [0.95116943]\n",
      "  [0.95503074]\n",
      "  [0.9588598 ]\n",
      "  [0.96270931]]]\n",
      "ejemplar: [0.9340151  0.93788546 0.9422611  0.94760525 0.95116943 0.95503074\n",
      " 0.9588598  0.96270931]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9654537]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.9340151  0.93788546 0.9422611  0.94760525 0.95116943 0.95503074\n",
      "  0.9588598  0.96270931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012350684963166714\n",
      "Predicción post entrenamiento : [[0.96523327]]\n",
      "PERDIDAAAA despues: 0.012301742099225521\n",
      "loss en el callback: 0.0010956815676763654, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.93788546]\n",
      "  [0.9422611 ]\n",
      "  [0.94760525]\n",
      "  [0.95116943]\n",
      "  [0.95503074]\n",
      "  [0.9588598 ]\n",
      "  [0.96270931]\n",
      "  [0.96545368]]]\n",
      "ejemplar: [0.93788546 0.9422611  0.94760525 0.95116943 0.95503074 0.9588598\n",
      " 0.96270931 0.96545368]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9691499]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.93788546 0.9422611  0.94760525 0.95116943 0.95503074 0.9588598\n",
      "  0.96270931 0.96545368]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017494022846221924\n",
      "Predicción post entrenamiento : [[0.9668235]]\n",
      "PERDIDAAAA despues: 0.01688404008746147\n",
      "loss en el callback: 0.08340410143136978, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.9422611 ]\n",
      "  [0.94760525]\n",
      "  [0.95116943]\n",
      "  [0.95503074]\n",
      "  [0.9588598 ]\n",
      "  [0.96270931]\n",
      "  [0.96545368]\n",
      "  [0.96914989]]]\n",
      "ejemplar: [0.9422611  0.94760525 0.95116943 0.95503074 0.9588598  0.96270931\n",
      " 0.96545368 0.96914989]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9707998]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.9422611  0.94760525 0.95116943 0.95503074 0.9588598  0.96270931\n",
      "  0.96545368 0.96914989]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019849689677357674\n",
      "Predicción post entrenamiento : [[0.9692824]]\n",
      "PERDIDAAAA despues: 0.019424419850111008\n",
      "loss en el callback: 0.04440038278698921, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.94760525]\n",
      "  [0.95116943]\n",
      "  [0.95503074]\n",
      "  [0.9588598 ]\n",
      "  [0.96270931]\n",
      "  [0.96545368]\n",
      "  [0.96914989]\n",
      "  [0.9707998 ]]]\n",
      "ejemplar: [0.94760525 0.95116943 0.95503074 0.9588598  0.96270931 0.96545368\n",
      " 0.96914989 0.9707998 ]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.97313076]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.94760525 0.95116943 0.95503074 0.9588598  0.96270931 0.96545368\n",
      "  0.96914989 0.9707998 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007374992594122887\n",
      "Predicción post entrenamiento : [[0.9724096]]\n",
      "PERDIDAAAA despues: 0.007251649629324675\n",
      "loss en el callback: 0.010528700426220894, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.95116943]\n",
      "  [0.95503074]\n",
      "  [0.9588598 ]\n",
      "  [0.96270931]\n",
      "  [0.96545368]\n",
      "  [0.96914989]\n",
      "  [0.9707998 ]\n",
      "  [0.97313076]]]\n",
      "ejemplar: [0.95116943 0.95503074 0.9588598  0.96270931 0.96545368 0.96914989\n",
      " 0.9707998  0.97313076]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9757635]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.95116943 0.95503074 0.9588598  0.96270931 0.96545368 0.96914989\n",
      "  0.9707998  0.97313076]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013460452668368816\n",
      "Predicción post entrenamiento : [[0.97554225]]\n",
      "PERDIDAAAA despues: 0.013409161940217018\n",
      "loss en el callback: 0.0012397366808727384, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.95503074]\n",
      "  [0.9588598 ]\n",
      "  [0.96270931]\n",
      "  [0.96545368]\n",
      "  [0.96914989]\n",
      "  [0.9707998 ]\n",
      "  [0.97313076]\n",
      "  [0.9757635 ]]]\n",
      "ejemplar: [0.95503074 0.9588598  0.96270931 0.96545368 0.96914989 0.9707998\n",
      " 0.97313076 0.9757635 ]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.97883594]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.95503074 0.9588598  0.96270931 0.96545368 0.96914989 0.9707998\n",
      "  0.97313076 0.9757635 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019387468695640564\n",
      "Predicción post entrenamiento : [[0.97731215]]\n",
      "PERDIDAAAA despues: 0.018965449184179306\n",
      "loss en el callback: 0.0441056489944458, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.9588598 ]\n",
      "  [0.96270931]\n",
      "  [0.96545368]\n",
      "  [0.96914989]\n",
      "  [0.9707998 ]\n",
      "  [0.97313076]\n",
      "  [0.9757635 ]\n",
      "  [0.97883594]]]\n",
      "ejemplar: [0.9588598  0.96270931 0.96545368 0.96914989 0.9707998  0.97313076\n",
      " 0.9757635  0.97883594]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9804059]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.9588598  0.96270931 0.96545368 0.96914989 0.9707998  0.97313076\n",
      "  0.9757635  0.97883594]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03865203633904457\n",
      "Predicción post entrenamiento : [[0.9778819]]\n",
      "PERDIDAAAA despues: 0.037665955722332\n",
      "loss en el callback: 0.11873356252908707, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.96270931]\n",
      "  [0.96545368]\n",
      "  [0.96914989]\n",
      "  [0.9707998 ]\n",
      "  [0.97313076]\n",
      "  [0.9757635 ]\n",
      "  [0.97883594]\n",
      "  [0.98040593]]]\n",
      "ejemplar: [0.96270931 0.96545368 0.96914989 0.9707998  0.97313076 0.9757635\n",
      " 0.97883594 0.98040593]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9807167]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.96270931 0.96545368 0.96914989 0.9707998  0.97313076 0.9757635\n",
      "  0.97883594 0.98040593]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02638324908912182\n",
      "Predicción post entrenamiento : [[0.97872514]]\n",
      "PERDIDAAAA despues: 0.025740237906575203\n",
      "loss en el callback: 0.07258907705545425, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.96545368]\n",
      "  [0.96914989]\n",
      "  [0.9707998 ]\n",
      "  [0.97313076]\n",
      "  [0.9757635 ]\n",
      "  [0.97883594]\n",
      "  [0.98040593]\n",
      "  [0.98071671]]]\n",
      "ejemplar: [0.96545368 0.96914989 0.9707998  0.97313076 0.9757635  0.97883594\n",
      " 0.98040593 0.98071671]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.98121417]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.96545368 0.96914989 0.9707998  0.97313076 0.9757635  0.97883594\n",
      "  0.98040593 0.98071671]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03611823543906212\n",
      "Predicción post entrenamiento : [[0.98026556]]\n",
      "PERDIDAAAA despues: 0.035758573561906815\n",
      "loss en el callback: 0.022698717191815376, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.96914989]\n",
      "  [0.9707998 ]\n",
      "  [0.97313076]\n",
      "  [0.9757635 ]\n",
      "  [0.97883594]\n",
      "  [0.98040593]\n",
      "  [0.98071671]\n",
      "  [0.98121417]]]\n",
      "ejemplar: [0.96914989 0.9707998  0.97313076 0.9757635  0.97883594 0.98040593\n",
      " 0.98071671 0.98121417]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9826532]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.96914989 0.9707998  0.97313076 0.9757635  0.97883594 0.98040593\n",
      "  0.98071671 0.98121417]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049326300621032715\n",
      "Predicción post entrenamiento : [[0.98153555]]\n",
      "PERDIDAAAA despues: 0.04883110150694847\n",
      "loss en el callback: 0.029233194887638092, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.9707998 ]\n",
      "  [0.97313076]\n",
      "  [0.9757635 ]\n",
      "  [0.97883594]\n",
      "  [0.98040593]\n",
      "  [0.98071671]\n",
      "  [0.98121417]\n",
      "  [0.9826532 ]]]\n",
      "ejemplar: [0.9707998  0.97313076 0.9757635  0.97883594 0.98040593 0.98071671\n",
      " 0.98121417 0.9826532 ]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.98346496]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.9707998  0.97313076 0.9757635  0.97883594 0.98040593 0.98071671\n",
      "  0.98121417 0.9826532 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03682994097471237\n",
      "Predicción post entrenamiento : [[0.98276263]]\n",
      "PERDIDAAAA despues: 0.036560866981744766\n",
      "loss en el callback: 0.012887987308204174, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.97313076]\n",
      "  [0.9757635 ]\n",
      "  [0.97883594]\n",
      "  [0.98040593]\n",
      "  [0.98071671]\n",
      "  [0.98121417]\n",
      "  [0.9826532 ]\n",
      "  [0.98346496]]]\n",
      "ejemplar: [0.97313076 0.9757635  0.97883594 0.98040593 0.98071671 0.98121417\n",
      " 0.9826532  0.98346496]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.98475367]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.97313076 0.9757635  0.97883594 0.98040593 0.98071671 0.98121417\n",
      "  0.9826532  0.98346496]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04668165743350983\n",
      "Predicción post entrenamiento : [[0.98225856]]\n",
      "PERDIDAAAA despues: 0.04560970142483711\n",
      "loss en el callback: 0.1178535670042038, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.9757635 ]\n",
      "  [0.97883594]\n",
      "  [0.98040593]\n",
      "  [0.98071671]\n",
      "  [0.98121417]\n",
      "  [0.9826532 ]\n",
      "  [0.98346496]\n",
      "  [0.98475367]]]\n",
      "ejemplar: [0.9757635  0.97883594 0.98040593 0.98071671 0.98121417 0.9826532\n",
      " 0.98346496 0.98475367]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.98406345]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.9757635  0.97883594 0.98040593 0.98071671 0.98121417 0.9826532\n",
      "  0.98346496 0.98475367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046383876353502274\n",
      "Predicción post entrenamiento : [[0.98319507]]\n",
      "PERDIDAAAA despues: 0.046010587364435196\n",
      "loss en el callback: 0.018732311204075813, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.97883594]\n",
      "  [0.98040593]\n",
      "  [0.98071671]\n",
      "  [0.98121417]\n",
      "  [0.9826532 ]\n",
      "  [0.98346496]\n",
      "  [0.98475367]\n",
      "  [0.98406345]]]\n",
      "ejemplar: [0.97883594 0.98040593 0.98071671 0.98121417 0.9826532  0.98346496\n",
      " 0.98475367 0.98406345]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9846423]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.97883594 0.98040593 0.98071671 0.98121417 0.9826532  0.98346496\n",
      "  0.98475367 0.98406345]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034494586288928986\n",
      "Predicción post entrenamiento : [[0.9846329]]\n",
      "PERDIDAAAA despues: 0.03449108824133873\n",
      "loss en el callback: 3.0360365599335637e-06, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.98040593]\n",
      "  [0.98071671]\n",
      "  [0.98121417]\n",
      "  [0.9826532 ]\n",
      "  [0.98346496]\n",
      "  [0.98475367]\n",
      "  [0.98406345]\n",
      "  [0.98464233]]]\n",
      "ejemplar: [0.98040593 0.98071671 0.98121417 0.9826532  0.98346496 0.98475367\n",
      " 0.98406345 0.98464233]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9854905]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.98040593 0.98071671 0.98121417 0.9826532  0.98346496 0.98475367\n",
      "  0.98406345 0.98464233]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03821501135826111\n",
      "Predicción post entrenamiento : [[0.98407876]]\n",
      "PERDIDAAAA despues: 0.03766505420207977\n",
      "loss en el callback: 0.044505491852760315, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.98071671]\n",
      "  [0.98121417]\n",
      "  [0.9826532 ]\n",
      "  [0.98346496]\n",
      "  [0.98475367]\n",
      "  [0.98406345]\n",
      "  [0.98464233]\n",
      "  [0.9854905 ]]]\n",
      "ejemplar: [0.98071671 0.98121417 0.9826532  0.98346496 0.98475367 0.98406345\n",
      " 0.98464233 0.9854905 ]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.98470134]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.98071671 0.98121417 0.9826532  0.98346496 0.98475367 0.98406345\n",
      "  0.98464233 0.9854905 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05041411519050598\n",
      "Predicción post entrenamiento : [[0.9813764]]\n",
      "PERDIDAAAA despues: 0.04893207177519798\n",
      "loss en el callback: 0.19488514959812164, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.98121417]\n",
      "  [0.9826532 ]\n",
      "  [0.98346496]\n",
      "  [0.98475367]\n",
      "  [0.98406345]\n",
      "  [0.98464233]\n",
      "  [0.9854905 ]\n",
      "  [0.98470134]]]\n",
      "ejemplar: [0.98121417 0.9826532  0.98346496 0.98475367 0.98406345 0.98464233\n",
      " 0.9854905  0.98470134]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.982101]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.98121417 0.9826532  0.98346496 0.98475367 0.98406345 0.98464233\n",
      "  0.9854905  0.98470134]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08803548663854599\n",
      "Predicción post entrenamiento : [[0.981425]]\n",
      "PERDIDAAAA despues: 0.08763477206230164\n",
      "loss en el callback: 0.014634291641414165, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.9826532 ]\n",
      "  [0.98346496]\n",
      "  [0.98475367]\n",
      "  [0.98406345]\n",
      "  [0.98464233]\n",
      "  [0.9854905 ]\n",
      "  [0.98470134]\n",
      "  [0.98210102]]]\n",
      "ejemplar: [0.9826532  0.98346496 0.98475367 0.98406345 0.98464233 0.9854905\n",
      " 0.98470134 0.98210102]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.98217005]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.9826532  0.98346496 0.98475367 0.98406345 0.98464233 0.9854905\n",
      "  0.98470134 0.98210102]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1421126276254654\n",
      "Predicción post entrenamiento : [[0.9802658]]\n",
      "PERDIDAAAA despues: 0.14068052172660828\n",
      "loss en el callback: 0.10297885537147522, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.98346496]\n",
      "  [0.98475367]\n",
      "  [0.98406345]\n",
      "  [0.98464233]\n",
      "  [0.9854905 ]\n",
      "  [0.98470134]\n",
      "  [0.98210102]\n",
      "  [0.98217005]]]\n",
      "ejemplar: [0.98346496 0.98475367 0.98406345 0.98464233 0.9854905  0.98470134\n",
      " 0.98210102 0.98217005]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9806933]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.98346496 0.98475367 0.98406345 0.98464233 0.9854905  0.98470134\n",
      "  0.98210102 0.98217005]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0997515618801117\n",
      "Predicción post entrenamiento : [[0.97773737]]\n",
      "PERDIDAAAA despues: 0.0978931337594986\n",
      "loss en el callback: 0.19702646136283875, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.98475367]\n",
      "  [0.98406345]\n",
      "  [0.98464233]\n",
      "  [0.9854905 ]\n",
      "  [0.98470134]\n",
      "  [0.98210102]\n",
      "  [0.98217005]\n",
      "  [0.98069328]]]\n",
      "ejemplar: [0.98475367 0.98406345 0.98464233 0.9854905  0.98470134 0.98210102\n",
      " 0.98217005 0.98069328]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9779406]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.98475367 0.98406345 0.98464233 0.9854905  0.98470134 0.98210102\n",
      "  0.98217005 0.98069328]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07294074445962906\n",
      "Predicción post entrenamiento : [[0.97624385]]\n",
      "PERDIDAAAA despues: 0.07202710956335068\n",
      "loss en el callback: 0.07639318704605103, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.98406345]\n",
      "  [0.98464233]\n",
      "  [0.9854905 ]\n",
      "  [0.98470134]\n",
      "  [0.98210102]\n",
      "  [0.98217005]\n",
      "  [0.98069328]\n",
      "  [0.97794062]]]\n",
      "ejemplar: [0.98406345 0.98464233 0.9854905  0.98470134 0.98210102 0.98217005\n",
      " 0.98069328 0.97794062]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.97598344]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.98406345 0.98464233 0.9854905  0.98470134 0.98210102 0.98217005\n",
      "  0.98069328 0.97794062]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09679868072271347\n",
      "Predicción post entrenamiento : [[0.974391]]\n",
      "PERDIDAAAA despues: 0.09581030905246735\n",
      "loss en el callback: 0.07974565774202347, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.98464233]\n",
      "  [0.9854905 ]\n",
      "  [0.98470134]\n",
      "  [0.98210102]\n",
      "  [0.98217005]\n",
      "  [0.98069328]\n",
      "  [0.97794062]\n",
      "  [0.97598344]]]\n",
      "ejemplar: [0.98464233 0.9854905  0.98470134 0.98210102 0.98217005 0.98069328\n",
      " 0.97794062 0.97598344]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9741484]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.98464233 0.9854905  0.98470134 0.98210102 0.98217005 0.98069328\n",
      "  0.97794062 0.97598344]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06906185299158096\n",
      "Predicción post entrenamiento : [[0.973435]]\n",
      "PERDIDAAAA despues: 0.06868740171194077\n",
      "loss en el callback: 0.016454072669148445, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.9854905 ]\n",
      "  [0.98470134]\n",
      "  [0.98210102]\n",
      "  [0.98217005]\n",
      "  [0.98069328]\n",
      "  [0.97794062]\n",
      "  [0.97598344]\n",
      "  [0.97414839]]]\n",
      "ejemplar: [0.9854905  0.98470134 0.98210102 0.98217005 0.98069328 0.97794062\n",
      " 0.97598344 0.97414839]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.97276294]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.9854905  0.98470134 0.98210102 0.98217005 0.98069328 0.97794062\n",
      "  0.97598344 0.97414839]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08732382953166962\n",
      "Predicción post entrenamiento : [[0.97118556]]\n",
      "PERDIDAAAA despues: 0.08639407157897949\n",
      "loss en el callback: 0.06797253340482712, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.98470134]\n",
      "  [0.98210102]\n",
      "  [0.98217005]\n",
      "  [0.98069328]\n",
      "  [0.97794062]\n",
      "  [0.97598344]\n",
      "  [0.97414839]\n",
      "  [0.97276294]]]\n",
      "ejemplar: [0.98470134 0.98210102 0.98217005 0.98069328 0.97794062 0.97598344\n",
      " 0.97414839 0.97276294]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9698904]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.98470134 0.98210102 0.98217005 0.98069328 0.97794062 0.97598344\n",
      "  0.97414839 0.97276294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043173644691705704\n",
      "Predicción post entrenamiento : [[0.9690778]]\n",
      "PERDIDAAAA despues: 0.04283662140369415\n",
      "loss en el callback: 0.02223452739417553, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.98210102]\n",
      "  [0.98217005]\n",
      "  [0.98069328]\n",
      "  [0.97794062]\n",
      "  [0.97598344]\n",
      "  [0.97414839]\n",
      "  [0.97276294]\n",
      "  [0.96989042]]]\n",
      "ejemplar: [0.98210102 0.98217005 0.98069328 0.97794062 0.97598344 0.97414839\n",
      " 0.97276294 0.96989042]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9675389]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.98210102 0.98217005 0.98069328 0.97794062 0.97598344 0.97414839\n",
      "  0.97276294 0.96989042]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025756191462278366\n",
      "Predicción post entrenamiento : [[0.96696097]]\n",
      "PERDIDAAAA despues: 0.025571024045348167\n",
      "loss en el callback: 0.010286207310855389, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.98217005]\n",
      "  [0.98069328]\n",
      "  [0.97794062]\n",
      "  [0.97598344]\n",
      "  [0.97414839]\n",
      "  [0.97276294]\n",
      "  [0.96989042]\n",
      "  [0.96753889]]]\n",
      "ejemplar: [0.98217005 0.98069328 0.97794062 0.97598344 0.97414839 0.97276294\n",
      " 0.96989042 0.96753889]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9656749]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.98217005 0.98069328 0.97794062 0.97598344 0.97414839 0.97276294\n",
      "  0.96989042 0.96753889]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02264632098376751\n",
      "Predicción post entrenamiento : [[0.964967]]\n",
      "PERDIDAAAA despues: 0.022433772683143616\n",
      "loss en el callback: 0.016750657930970192, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.98069328]\n",
      "  [0.97794062]\n",
      "  [0.97598344]\n",
      "  [0.97414839]\n",
      "  [0.97276294]\n",
      "  [0.96989042]\n",
      "  [0.96753889]\n",
      "  [0.96567488]]]\n",
      "ejemplar: [0.98069328 0.97794062 0.97598344 0.97414839 0.97276294 0.96989042\n",
      " 0.96753889 0.96567488]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9631277]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.98069328 0.97794062 0.97598344 0.97414839 0.97276294 0.96989042\n",
      "  0.96753889 0.96567488]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032364462967962027\n",
      "Predicción post entrenamiento : [[0.96277386]]\n",
      "PERDIDAAAA despues: 0.003196314675733447\n",
      "loss en el callback: 0.0033327138517051935, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.97794062]\n",
      "  [0.97598344]\n",
      "  [0.97414839]\n",
      "  [0.97276294]\n",
      "  [0.96989042]\n",
      "  [0.96753889]\n",
      "  [0.96567488]\n",
      "  [0.96312767]]]\n",
      "ejemplar: [0.97794062 0.97598344 0.97414839 0.97276294 0.96989042 0.96753889\n",
      " 0.96567488 0.96312767]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9607581]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.97794062 0.97598344 0.97414839 0.97276294 0.96989042 0.96753889\n",
      "  0.96567488 0.96312767]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1078792567786877e-06\n",
      "Predicción post entrenamiento : [[0.960358]]\n",
      "PERDIDAAAA despues: 4.257458670053893e-07\n",
      "loss en el callback: 0.004361940082162619, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.97598344]\n",
      "  [0.97414839]\n",
      "  [0.97276294]\n",
      "  [0.96989042]\n",
      "  [0.96753889]\n",
      "  [0.96567488]\n",
      "  [0.96312767]\n",
      "  [0.96075809]]]\n",
      "ejemplar: [0.97598344 0.97414839 0.97276294 0.96989042 0.96753889 0.96567488\n",
      " 0.96312767 0.96075809]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9585245]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.97598344 0.97414839 0.97276294 0.96989042 0.96753889 0.96567488\n",
      "  0.96312767 0.96075809]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.399295383132994e-05\n",
      "Predicción post entrenamiento : [[0.9595924]]\n",
      "PERDIDAAAA despues: 2.2681128029944375e-05\n",
      "loss en el callback: 0.04889494925737381, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.97414839]\n",
      "  [0.97276294]\n",
      "  [0.96989042]\n",
      "  [0.96753889]\n",
      "  [0.96567488]\n",
      "  [0.96312767]\n",
      "  [0.96075809]\n",
      "  [0.95852453]]]\n",
      "ejemplar: [0.97414839 0.97276294 0.96989042 0.96753889 0.96567488 0.96312767\n",
      " 0.96075809 0.95852453]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.95771354]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.97414839 0.97276294 0.96989042 0.96753889 0.96567488 0.96312767\n",
      "  0.96075809 0.95852453]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004856088198721409\n",
      "Predicción post entrenamiento : [[0.95781726]]\n",
      "PERDIDAAAA despues: 0.0048705535009503365\n",
      "loss en el callback: 0.0003904698824044317, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.97276294]\n",
      "  [0.96989042]\n",
      "  [0.96753889]\n",
      "  [0.96567488]\n",
      "  [0.96312767]\n",
      "  [0.96075809]\n",
      "  [0.95852453]\n",
      "  [0.95771354]]]\n",
      "ejemplar: [0.97276294 0.96989042 0.96753889 0.96567488 0.96312767 0.96075809\n",
      " 0.95852453 0.95771354]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.95584697]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.97276294 0.96989042 0.96753889 0.96567488 0.96312767 0.96075809\n",
      "  0.95852453 0.95771354]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0039904131554067135\n",
      "Predicción post entrenamiento : [[0.9561444]]\n",
      "PERDIDAAAA despues: 0.004028078634291887\n",
      "loss en el callback: 0.0034564496017992496, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.96989042]\n",
      "  [0.96753889]\n",
      "  [0.96567488]\n",
      "  [0.96312767]\n",
      "  [0.96075809]\n",
      "  [0.95852453]\n",
      "  [0.95771354]\n",
      "  [0.95584697]]]\n",
      "ejemplar: [0.96989042 0.96753889 0.96567488 0.96312767 0.96075809 0.95852453\n",
      " 0.95771354 0.95584697]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9539383]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.96989042 0.96753889 0.96567488 0.96312767 0.96075809 0.95852453\n",
      "  0.95771354 0.95584697]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006193080917000771\n",
      "Predicción post entrenamiento : [[0.9534666]]\n",
      "PERDIDAAAA despues: 0.00611905986443162\n",
      "loss en el callback: 0.006288780830800533, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.96753889]\n",
      "  [0.96567488]\n",
      "  [0.96312767]\n",
      "  [0.96075809]\n",
      "  [0.95852453]\n",
      "  [0.95771354]\n",
      "  [0.95584697]\n",
      "  [0.95393831]]]\n",
      "ejemplar: [0.96753889 0.96567488 0.96312767 0.96075809 0.95852453 0.95771354\n",
      " 0.95584697 0.95393831]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9514639]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.96753889 0.96567488 0.96312767 0.96075809 0.95852453 0.95771354\n",
      "  0.95584697 0.95393831]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010126573964953423\n",
      "Predicción post entrenamiento : [[0.95091444]]\n",
      "PERDIDAAAA despues: 0.010016295127570629\n",
      "loss en el callback: 0.010196885094046593, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.96567488]\n",
      "  [0.96312767]\n",
      "  [0.96075809]\n",
      "  [0.95852453]\n",
      "  [0.95771354]\n",
      "  [0.95584697]\n",
      "  [0.95393831]\n",
      "  [0.95146388]]]\n",
      "ejemplar: [0.96567488 0.96312767 0.96075809 0.95852453 0.95771354 0.95584697\n",
      " 0.95393831 0.95146388]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9489997]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.96567488 0.96312767 0.96075809 0.95852453 0.95771354 0.95584697\n",
      "  0.95393831 0.95146388]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010020793415606022\n",
      "Predicción post entrenamiento : [[0.94851774]]\n",
      "PERDIDAAAA despues: 0.00992453284561634\n",
      "loss en el callback: 0.007519736420363188, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.96312767]\n",
      "  [0.96075809]\n",
      "  [0.95852453]\n",
      "  [0.95771354]\n",
      "  [0.95584697]\n",
      "  [0.95393831]\n",
      "  [0.95146388]\n",
      "  [0.9489997 ]]]\n",
      "ejemplar: [0.96312767 0.96075809 0.95852453 0.95771354 0.95584697 0.95393831\n",
      " 0.95146388 0.9489997 ]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.94656044]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.96312767 0.96075809 0.95852453 0.95771354 0.95584697 0.95393831\n",
      "  0.95146388 0.9489997 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025145141989924014\n",
      "Predicción post entrenamiento : [[0.946745]]\n",
      "PERDIDAAAA despues: 0.0002456330112181604\n",
      "loss en el callback: 0.0010892748832702637, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.96075809]\n",
      "  [0.95852453]\n",
      "  [0.95771354]\n",
      "  [0.95584697]\n",
      "  [0.95393831]\n",
      "  [0.95146388]\n",
      "  [0.9489997 ]\n",
      "  [0.94656044]]]\n",
      "ejemplar: [0.96075809 0.95852453 0.95771354 0.95584697 0.95393831 0.95146388\n",
      " 0.9489997  0.94656044]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9449467]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.96075809 0.95852453 0.95771354 0.95584697 0.95393831 0.95146388\n",
      "  0.9489997  0.94656044]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00052419095300138\n",
      "Predicción post entrenamiento : [[0.94493383]]\n",
      "PERDIDAAAA despues: 0.0005247806548140943\n",
      "loss en el callback: 5.310694177751429e-06, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.95852453]\n",
      "  [0.95771354]\n",
      "  [0.95584697]\n",
      "  [0.95393831]\n",
      "  [0.95146388]\n",
      "  [0.9489997 ]\n",
      "  [0.94656044]\n",
      "  [0.94494671]]]\n",
      "ejemplar: [0.95852453 0.95771354 0.95584697 0.95393831 0.95146388 0.9489997\n",
      " 0.94656044 0.94494671]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.943258]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.95852453 0.95771354 0.95584697 0.95393831 0.95146388 0.9489997\n",
      "  0.94656044 0.94494671]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.437942829506937e-06\n",
      "Predicción post entrenamiento : [[0.9415887]]\n",
      "PERDIDAAAA despues: 7.534629844485607e-07\n",
      "loss en el callback: 0.06413707137107849, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.95771354]\n",
      "  [0.95584697]\n",
      "  [0.95393831]\n",
      "  [0.95146388]\n",
      "  [0.9489997 ]\n",
      "  [0.94656044]\n",
      "  [0.94494671]\n",
      "  [0.94325799]]]\n",
      "ejemplar: [0.95771354 0.95584697 0.95393831 0.95146388 0.9489997  0.94656044\n",
      " 0.94494671 0.94325799]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9400027]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.95771354 0.95584697 0.95393831 0.95146388 0.9489997  0.94656044\n",
      "  0.94494671 0.94325799]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001055508153513074\n",
      "Predicción post entrenamiento : [[0.9399375]]\n",
      "PERDIDAAAA despues: 0.0010597493965178728\n",
      "loss en el callback: 0.00014072636258788407, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.95584697]\n",
      "  [0.95393831]\n",
      "  [0.95146388]\n",
      "  [0.9489997 ]\n",
      "  [0.94656044]\n",
      "  [0.94494671]\n",
      "  [0.94325799]\n",
      "  [0.94000268]]]\n",
      "ejemplar: [0.95584697 0.95393831 0.95146388 0.9489997  0.94656044 0.94494671\n",
      " 0.94325799 0.94000268]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9380004]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.95584697 0.95393831 0.95146388 0.9489997  0.94656044 0.94494671\n",
      "  0.94325799 0.94000268]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034692168701440096\n",
      "Predicción post entrenamiento : [[0.93897337]]\n",
      "PERDIDAAAA despues: 0.0033555456902831793\n",
      "loss en el callback: 0.043401703238487244, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.95393831]\n",
      "  [0.95146388]\n",
      "  [0.9489997 ]\n",
      "  [0.94656044]\n",
      "  [0.94494671]\n",
      "  [0.94325799]\n",
      "  [0.94000268]\n",
      "  [0.93800038]]]\n",
      "ejemplar: [0.95393831 0.95146388 0.9489997  0.94656044 0.94494671 0.94325799\n",
      " 0.94000268 0.93800038]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9369444]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.95393831 0.95146388 0.9489997  0.94656044 0.94494671 0.94325799\n",
      "  0.94000268 0.93800038]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020270027744118124\n",
      "Predicción post entrenamiento : [[0.9372306]]\n",
      "PERDIDAAAA despues: 0.00019463383068796247\n",
      "loss en el callback: 0.0030808488372713327, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.95146388]\n",
      "  [0.9489997 ]\n",
      "  [0.94656044]\n",
      "  [0.94494671]\n",
      "  [0.94325799]\n",
      "  [0.94000268]\n",
      "  [0.93800038]\n",
      "  [0.93694443]]]\n",
      "ejemplar: [0.95146388 0.9489997  0.94656044 0.94494671 0.94325799 0.94000268\n",
      " 0.93800038 0.93694443]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.93511486]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.95146388 0.9489997  0.94656044 0.94494671 0.94325799 0.94000268\n",
      "  0.93800038 0.93694443]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001547482330352068\n",
      "Predicción post entrenamiento : [[0.934934]]\n",
      "PERDIDAAAA despues: 0.0015332872280851007\n",
      "loss en el callback: 0.0013323745224624872, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.9489997 ]\n",
      "  [0.94656044]\n",
      "  [0.94494671]\n",
      "  [0.94325799]\n",
      "  [0.94000268]\n",
      "  [0.93800038]\n",
      "  [0.93694443]\n",
      "  [0.93511486]]]\n",
      "ejemplar: [0.9489997  0.94656044 0.94494671 0.94325799 0.94000268 0.93800038\n",
      " 0.93694443 0.93511486]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9329041]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.9489997  0.94656044 0.94494671 0.94325799 0.94000268 0.93800038\n",
      "  0.93694443 0.93511486]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026484227273613214\n",
      "Predicción post entrenamiento : [[0.9330706]]\n",
      "PERDIDAAAA despues: 0.0026655851397663355\n",
      "loss en el callback: 0.001211388036608696, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.94656044]\n",
      "  [0.94494671]\n",
      "  [0.94325799]\n",
      "  [0.94000268]\n",
      "  [0.93800038]\n",
      "  [0.93694443]\n",
      "  [0.93511486]\n",
      "  [0.93290412]]]\n",
      "ejemplar: [0.94656044 0.94494671 0.94325799 0.94000268 0.93800038 0.93694443\n",
      " 0.93511486 0.93290412]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9311477]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.94656044 0.94494671 0.94325799 0.94000268 0.93800038 0.93694443\n",
      "  0.93511486 0.93290412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001977193751372397\n",
      "Predicción post entrenamiento : [[0.93025786]]\n",
      "PERDIDAAAA despues: 0.00017348668188787997\n",
      "loss en el callback: 0.023693382740020752, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.94494671]\n",
      "  [0.94325799]\n",
      "  [0.94000268]\n",
      "  [0.93800038]\n",
      "  [0.93694443]\n",
      "  [0.93511486]\n",
      "  [0.93290412]\n",
      "  [0.93114769]]]\n",
      "ejemplar: [0.94494671 0.94325799 0.94000268 0.93800038 0.93694443 0.93511486\n",
      " 0.93290412 0.93114769]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9284597]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.94494671 0.94325799 0.94000268 0.93800038 0.93694443 0.93511486\n",
      "  0.93290412 0.93114769]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.501553773181513e-05\n",
      "Predicción post entrenamiento : [[0.92849445]]\n",
      "PERDIDAAAA despues: 7.561868551420048e-05\n",
      "loss en el callback: 4.5323660742724314e-05, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.94325799]\n",
      "  [0.94000268]\n",
      "  [0.93800038]\n",
      "  [0.93694443]\n",
      "  [0.93511486]\n",
      "  [0.93290412]\n",
      "  [0.93114769]\n",
      "  [0.9284597 ]]]\n",
      "ejemplar: [0.94325799 0.94000268 0.93800038 0.93694443 0.93511486 0.93290412\n",
      " 0.93114769 0.9284597 ]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9265885]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.94325799 0.94000268 0.93800038 0.93694443 0.93511486 0.93290412\n",
      "  0.93114769 0.9284597 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012288057478144765\n",
      "Predicción post entrenamiento : [[0.92698455]]\n",
      "PERDIDAAAA despues: 0.001201194478198886\n",
      "loss en el callback: 0.006597719620913267, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.94000268]\n",
      "  [0.93800038]\n",
      "  [0.93694443]\n",
      "  [0.93511486]\n",
      "  [0.93290412]\n",
      "  [0.93114769]\n",
      "  [0.9284597 ]\n",
      "  [0.92658848]]]\n",
      "ejemplar: [0.94000268 0.93800038 0.93694443 0.93511486 0.93290412 0.93114769\n",
      " 0.9284597  0.92658848]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9249802]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.94000268 0.93800038 0.93694443 0.93511486 0.93290412 0.93114769\n",
      "  0.9284597  0.92658848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018704872345551848\n",
      "Predicción post entrenamiento : [[0.92536795]]\n",
      "PERDIDAAAA despues: 0.0018370997859165072\n",
      "loss en el callback: 0.006164248567074537, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.93800038]\n",
      "  [0.93694443]\n",
      "  [0.93511486]\n",
      "  [0.93290412]\n",
      "  [0.93114769]\n",
      "  [0.9284597 ]\n",
      "  [0.92658848]\n",
      "  [0.92498022]]]\n",
      "ejemplar: [0.93800038 0.93694443 0.93511486 0.93290412 0.93114769 0.9284597\n",
      " 0.92658848 0.92498022]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9237325]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.93800038 0.93694443 0.93511486 0.93290412 0.93114769 0.9284597\n",
      "  0.92658848 0.92498022]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011584358289837837\n",
      "Predicción post entrenamiento : [[0.9233294]]\n",
      "PERDIDAAAA despues: 0.0011860383674502373\n",
      "loss en el callback: 0.005133726634085178, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n"
     ]
    }
   ],
   "source": [
    "\n",
    "red.compile(optimizer=SGD(learning_rate=0.01),loss='mean_squared_error')#SGD(learning_rate=1e-3)\n",
    "\n",
    "# Definir el callback con la función de la tasa de aprendizaje\n",
    "lr_callback = CustomLearningRateScheduler(initial_lr=0.01, decay_factor=0.5)#0.9\n",
    "lr_callback.reset()\n",
    "ts_cierre_s_pred = c_entrenamiento_n\n",
    "sub_epocas = 1\n",
    "t_lote = 1\n",
    "\n",
    "loss_m = []\n",
    "print(f\"y_entrenamiento: {y_entrenamiento}\")\n",
    "for epoca in range(10):  # Número de épocas\n",
    "    ts_cierre_s_pred = c_entrenamiento_n[:time_steps] #:8 se toman los primeros 8 elementos del conjunto de entrenamiendo predictivo \n",
    "    ts_cierre_s_pred_post_entreno = c_entrenamiento_n[:time_steps]\n",
    "    loss = []\n",
    "    n_ejemplar = 1\n",
    "    n_lote = 1\n",
    "    x_lote = []\n",
    "    # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "    for i in range(0,len(y_entrenamiento)):#time_steps+1\n",
    "        print(i)\n",
    "        # Obtener las características y la etiqueta actual\n",
    "        ejemplar = ts_cierre_s_pred[i:i+time_steps,0]\n",
    "        print(ejemplar.reshape(1,time_steps,1))\n",
    "\n",
    "        x_lote.append(ejemplar)\n",
    "\n",
    "        # Predicción del modelo \n",
    "        #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "        prediccion = red(ejemplar.reshape(1,time_steps,1))\n",
    "        \n",
    "        # Agregar la predicción a las características para el siguiente paso\n",
    "        # print(ts_cierre_s_pred)\n",
    "        print(f\"ejemplar: {ejemplar}\")\n",
    "        print(f\"y: {np.array( y_entrenamiento[i])}\")\n",
    "        print(f\"Predicción : { prediccion}\")\n",
    "        ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "        \n",
    "\n",
    "        if(n_ejemplar == t_lote):\n",
    "            \n",
    "            #print(f\"y: {np.array( y_entrenamiento[i-t_lote+1:i+1]).reshape(t_lote,1)}\")\n",
    "            \n",
    "            #print(f\"x_lote: {x_lote}\")\n",
    "            lr = float(red.optimizer.lr)\n",
    "            print(f\"Lr que voy a aplicar en el lote: {n_lote} es {lr}\")\n",
    "            print(f\"lote que voy a entrenar: {np.array(x_lote)}\")\n",
    "            print(f\"verdaderas salidas: {np.array( [y_entrenamiento[i-t_lote+1:i+1]]).shape}\")\n",
    "            print(f\"PERDIDAAAA antes: {red.test_on_batch(np.array(x_lote),np.array( [y_entrenamiento[i-t_lote+1:i+1]]))}\")\n",
    "            train = red.train_on_batch(np.array(x_lote), np.array( [y_entrenamiento[i-t_lote+1:i+1]]))\n",
    "            \n",
    "            # print(f\"train: {train}\")\n",
    "            loss.append(train)#np.array(y_entrenamiento[i:i+t_lote])\n",
    "            prediccion_post_entrenamiento = red(ejemplar.reshape(1,time_steps,1))\n",
    "            print(f\"Predicción post entrenamiento : { prediccion_post_entrenamiento}\")\n",
    "            print(f\"PERDIDAAAA despues: {red.test_on_batch(np.array(x_lote),np.array( [y_entrenamiento[i-t_lote+1:i+1]]))}\")\n",
    "            #ts_cierre_s_pred_post_entreno = np.concatenate([ts_cierre_s_pred_post_entreno, prediccion])\n",
    "            lr_callback.on_batch_begin(n_lote, logs={'loss': train, 'epoca': epoca+1})  # Llamada al callback en cada lote\n",
    "            #red.optimizer.lr =\n",
    "            x_lote = []\n",
    "            n_ejemplar = 0\n",
    "            \n",
    "            n_lote = n_lote + 1\n",
    "            \n",
    "        n_ejemplar = n_ejemplar+1\n",
    "        print(\">>>>>>>>>>>>>>>Fin lote \")\n",
    "\n",
    "        # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "        # for sub_epoca in range(sub_epocas):\n",
    "        #     red.train_on_batch(x_actual, y_actual)\n",
    "        #     if(sub_epoca == sub_epocas - 1):\n",
    "        #         loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "        \n",
    "\n",
    "        \n",
    "    #print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "    #loss_m.append(np.mean(np.array(loss)))\n",
    "    mse = np.mean(np.array(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0])))\n",
    "    loss_m.append(mse)\n",
    "    writer.add_scalar(f'Perdida de entrenamiento predictivo de la red: ', mse, epoca+1)\n",
    "    \n",
    "    \n",
    "    plot_buf = utls.gen_plot(c_entrenamiento_n,ts_cierre_s_pred,mse)\n",
    "\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = ToTensor()(image).unsqueeze(0)\n",
    "    writer.add_image(f'Comportamiento de la serie de tiempo para la red: {0} durante el entrenamiento predictivo', image, epoca+1,dataformats='NCHW')\n",
    "    lr_callback.reset()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1589248606556082, 0.15862695495753734, 0.15763485813638708, 0.1628810052503071, 0.16296689057695865, 0.16502582313176523, 0.16293438046390396, 0.1669420935764901, 0.17186400736105034, 0.17514912029899876]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss_m)\n",
    "plt.plot(range(len(loss_m)),loss_m)\n",
    "plt.show()\n",
    "# losses = history.history['loss']\n",
    "# print(losses)\n",
    "# plt.plot(range(len(losses)),losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "shape: (78, 1)\n",
      "[0.54539295 0.44850949 0.42344173 0.48577236 0.49051491 0.56368564\n",
      " 0.57520325 0.55691057]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "shape: (86,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for i in range(time_steps, N):\n",
    "#     X_entrenamiento.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "#     y_entrenamiento.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "\n",
    "# Ahora, el modelo ha sido entrenado de manera iterativa\n",
    "\n",
    "# print(X_entrenamiento.shape)\n",
    "# print(X_entrenamiento[0,:].shape)\n",
    "f_X_test_cierre = np.reshape(X_entrenamiento[0,:], (1, X_entrenamiento[0,:].shape[0], 1))\n",
    "# print(f_X_test_cierre)\n",
    "f_predicted_sp_cierre = red.predict(f_X_test_cierre)\n",
    "print(f\"shape: {precios_predichos.shape}\")\n",
    "f_predicted_sp_cierre = m_m_s.inverse_transform(f_predicted_sp_cierre)\n",
    "print(f_X_test_cierre.reshape(8))\n",
    "\n",
    "# Predice el conjunto de prueba usando la prediccion predictiva (ñps datos que va prediciendo)\n",
    "\n",
    "predicted_stock_price_cierre_pred = utls.genera_prediccion_predictiva(f_X_test_cierre.reshape(8),8,78,red)\n",
    "print(f\"shape: {predicted_stock_price_cierre_pred.shape}\")\n",
    "temp = predicted_stock_price_cierre_pred\n",
    "predicted_stock_price_cierre_pred = m_m_s.inverse_transform(predicted_stock_price_cierre_pred.reshape(86,1))\n",
    "# input_shape_primera_capa = red.layers[0].input_shape\n",
    "# print(input_shape_primera_capa[1:])\n",
    "\n",
    "# arreglo_una_dimension = np.random.rand(8)  # Completa con tus valores reales\n",
    "\n",
    "# # Utilizar input_shape_primera_capa en la función reshape\n",
    "# arreglo_reshape = arreglo_una_dimension.reshape(1, *input_shape_primera_capa[1:])\n",
    "# print(arreglo_reshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predice el conjunto de entrenamiento usando la prediccion predictiva (usando los datos que predice)\n",
    "\n",
    "#f_X_train_cierre = np.reshape(X_entrenamiento[0,:], (1, X_entrenamiento[0,:].shape[0], 1))\n",
    "f_X_train_cierre = c_entrenamiento_n[:time_steps].reshape(8)\n",
    "# # print(f_X_test_cierre)\n",
    "# f_predicted_t_sp_cierre = red.predict(f_X_train_cierre)\n",
    "# print(f\"shape: {precios_predichos.shape}\")\n",
    "# f_predicted_sp_cierre = m_m_s.inverse_transform(f_predicted_t_sp_cierre)\n",
    "# print(f_X_test_cierre.reshape(8))\n",
    "\n",
    "predicted_stock_price_cierre_pred_t = utls.genera_prediccion_predictiva(f_X_train_cierre,8,182,red)\n",
    "# print(f\"shape: {predicted_stock_price_cierre_pred_t.shape}\")\n",
    "# temp_t = predicted_stock_price_cierre_pred_t\n",
    "# predicted_stock_price_cierre_pred = m_m_s.inverse_transform(predicted_stock_price_cierre_pred.reshape(86,1))\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(c_entrenamiento_n, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(predicted_stock_price_cierre_pred_t, color = 'green', label = 'Predicted COMI closing Stock prices') #ts_cierre_s_pred[:,0]\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAClo0lEQVR4nOzdZ3RU1deA8WfSey+0QAKh9w4CAtIEpYmKoDQB/SOiiIoVsYMoiqICIoIVkCJdeuhVegktBBIgCYGEhPQy5/2Qd4YMKaRMMklm/9aaRWbunXt3AiQ7++xzjkYppRBCCCGEqCAsTB2AEEIIIYQxSXIjhBBCiApFkhshhBBCVCiS3AghhBCiQpHkRgghhBAViiQ3QgghhKhQJLkRQgghRIUiyY0QQgghKhRJboQQQghRoUhyI4QoUTt27ECj0bB8+XKT3H/RokVoNBquXLlikvubysiRI/H39zd4TaPR8OGHHxrtHl26dKFLly5Gu54QxiLJjRC5CAkJ4cUXX6RmzZrY2dnh4uJChw4d+Pbbb0lOTjY4Nz09ne+++47WrVvj7OyMk5MTrVu35rvvviM9PT3Htf39/dFoNHTv3j3Xe8+fPx+NRoNGo+G///7Tv/7hhx+i0Wi4devWA+M/deoUTz75JDVq1MDOzo6qVavSo0cPZs+ebXDe559/zqpVqwrwFTGNK1eu6L8WGo0GS0tLqlevzsCBAzl+/Lipw8tTeY07N2fPnuXDDz80u+RQlG9Wpg5AiLJm/fr1PPXUU9ja2jJ8+HAaNWpEWloae/bs4c033+TMmTP89NNPACQmJvLYY4+xc+dOHn/8cUaOHImFhQUbN27k1VdfZeXKlaxfvx5HR0eDe9jZ2REUFERkZCSVKlUyOPbnn39iZ2dHSkpKkeLft28fXbt2pXr16owdO5ZKlSoRHh7OgQMH+Pbbb5kwYYL+3M8//5wnn3ySAQMGFOlepWXIkCH06dOHzMxMgoODmTNnDv/++y8HDhygWbNm+b532LBhPPPMM9ja2pZOsNkUJ+6SkJycjJVV4b7tnz17lo8++oguXbrkqARt3rzZiNEJYTyS3AiRTWhoKM888ww1atRg+/btVK5cWX9s/PjxXLp0ifXr1+tfmzRpEjt37mT27Nm8/PLL+tfHjRvHDz/8wMsvv8wbb7zBnDlzDO7ToUMHDh8+zNKlS3n11Vf1r1+7do3du3czcOBAVqxYUaTP4bPPPsPV1ZXDhw/j5uZmcOzmzZtFuqaptWjRgueee07/vEOHDvTr1485c+Ywb968XN+TmJiIo6MjlpaWWFpallaoBooTd0mws7Mz6vVsbGyMej0hjEWGpYTIZsaMGSQkJLBgwQKDxEYnMDBQn4xcu3aNBQsW8MgjjxgkNjrjx4+na9eu/Pzzz1y7ds3gmJ2dHU888QR//fWXweuLFy/G3d2dXr16FflzCAkJoWHDhjkSGwAfHx/9xxqNhsTERH799Vf98MnIkSP1x48dO0bv3r1xcXHBycmJbt26ceDAgRzXvHPnDq+99hr+/v7Y2tpSrVo1hg8fnu/wWWpqKo8//jiurq7s27ev0J/jI488AmQlo3Cvr2bnzp289NJL+Pj4UK1aNYNj9w+r/Pvvv3Tu3BlnZ2dcXFxo3bp1jr+PgwcP8uijj+Lq6oqDgwOdO3dm7969hY63KHHrYuzUqROOjo44Ozvz2GOPcebMmRzXXbVqFY0aNcLOzo5GjRrxzz//5Hr/3Hpurl+/zujRo6lSpQq2trYEBAQwbtw40tLSWLRoEU899RQAXbt21f872bFjB5B7z83NmzcZPXo0vr6+2NnZ0bRpU3799VeDc3TDdl999RU//fQTtWrVwtbWltatW3P48OECfz2FyItUboTIZu3atdSsWZOHHnrogef++++/ZGZmMnz48DzPGT58OEFBQWzcuJExY8YYHBs6dCg9e/YkJCSEWrVqAfDXX3/x5JNPYm1tXeTPoUaNGuzfv5/Tp0/TqFGjPM/7/fffGTNmDG3atOGFF14A0Mdx5swZOnXqhIuLC5MnT8ba2pp58+bRpUsXdu7cSdu2bQFISEigU6dOBAcH8/zzz9OiRQtu3brFmjVruHbtGl5eXjnum5ycTP/+/fnvv//YunUrrVu3LvTnGBISAoCnp6fB6y+99BLe3t588MEHJCYm5vn+RYsW8fzzz9OwYUPeeecd3NzcOHbsGBs3bmTo0KEAbN++nd69e9OyZUumTp2KhYUFCxcu5JFHHmH37t20adOmROP+/fffGTFiBL169eKLL74gKSmJOXPm0LFjR44dO6YfItq8eTODBg2iQYMGTJs2jdu3bzNq1CiDJCkvN27coE2bNty5c4cXXniBevXqcf36dZYvX05SUhIPP/wwr7zyCt999x3vvvsu9evXB9D/eb/k5GS6dOnCpUuXePnllwkICGDZsmWMHDmSO3fuGFQpIevf+927d3nxxRfRaDTMmDGDJ554gsuXLxfr/4AQKCGEUkqpuLg4Baj+/fsX6PyJEycqQB07dizPc44ePaoANWnSJP1rNWrUUI899pjKyMhQlSpVUp988olSSqmzZ88qQO3cuVMtXLhQAerw4cP6902dOlUBKjo6Ot+4Nm/erCwtLZWlpaVq3769mjx5stq0aZNKS0vLca6jo6MaMWJEjtcHDBigbGxsVEhIiP61GzduKGdnZ/Xwww/rX/vggw8UoFauXJnjGlqtVimlVFBQkALUsmXL1N27d1Xnzp2Vl5dXvl83ndDQUAWojz76SEVHR6vIyEi1Y8cO1bx5cwWoFStWKKWU/uvVsWNHlZGRYXAN3bHQ0FCllFJ37txRzs7Oqm3btio5OTnXmLVarapdu7bq1auX/jWllEpKSlIBAQGqR48eJRr33bt3lZubmxo7dqzBdSMjI5Wrq6vB682aNVOVK1dWd+7c0b+2efNmBagaNWoYvB9QU6dO1T8fPny4srCwMPh3dv/XYtmyZQpQQUFBOc7p3Lmz6ty5s/75rFmzFKD++OMP/WtpaWmqffv2ysnJScXHxxt8fTw9PVVMTIz+3NWrVytArV27Nse9hCgMGZYS4v/Fx8cD4OzsXKDz7969+8Dzdcd0187O0tKSp59+msWLFwNZjcR+fn506tSpUHHfr0ePHuzfv59+/fpx4sQJZsyYQa9evahatSpr1qx54PszMzPZvHkzAwYMoGbNmvrXK1euzNChQ9mzZ4/+81mxYgVNmzZl4MCBOa6j0WgMnsfFxdGzZ0/OnTvHjh07CtVQO3XqVLy9valUqRJdunQhJCSEL774gieeeMLgvLFjxz6wv2bLli3cvXuXt99+O0cPii7m48ePc/HiRYYOHcrt27e5desWt27dIjExkW7durFr1y60Wm2Jxb1lyxbu3LnDkCFD9Pe+desWlpaWtG3blqCgIAAiIiI4fvw4I0aMwNXVVf/+Hj160KBBg3xj02q1rFq1ir59+9KqVascx+//+yuIDRs2UKlSJYYMGaJ/zdramldeeYWEhAR27txpcP7gwYNxd3fXP9f92798+XKh7y1EdjIsJcT/c3FxAe4lLQ+iS1zyO/9BCdDQoUP57rvvOHHiBH/99RfPPPNMkX6o3K9169asXLmStLQ0Tpw4wT///MM333zDk08+yfHjx/P9wRcdHU1SUhJ169bNcax+/fpotVrCw8Np2LAhISEhDBo0qEAxTZw4kZSUFI4dO0bDhg0L9fm88MILPPXUU1hYWODm5kbDhg1znf0UEBDwwGvphobyG7K7ePEiACNGjMjznLi4OIMfzMaMW3d/XY/O/XT/Vq9evQpA7dq1c5xTt25djh49mmds0dHRxMfH5/t1KKyrV69Su3ZtLCwMf2/WDWPp4tWpXr26wXPd1zM2NtZoMQnzJMmNEP/PxcWFKlWqcPr06QKdr/uGffLkyTyrECdPngTIM5lo27YttWrVYuLEiYSGhur7PYzFxsaG1q1b07p1a+rUqcOoUaNYtmwZU6dONep9CqJ///4sWbKE6dOn89tvv+X4AZif2rVr57kuUHb29vbFCVFPV5X58ssv8/y7dXJyeuB1ihq37v6///57jqUCgEJP5y6r8qqyKaVKORJR0VSM/yFCGMnjjz/OTz/9xP79+2nfvn2+5/bu3RtLS0t+//33PJuKf/vtN6ysrHj00UfzvM6QIUP49NNPqV+/fomufaIbeoiIiNC/lluVyNvbGwcHB86fP5/j2Llz57CwsMDPzw/IakAuaDI4YMAAevbsyciRI3F2ds4xPb606JqmT58+TWBgYL7nuLi4FCg5MTbd/X18fPK9f40aNYB7lZ7scvv7y87b2xsXF5cH/v0VppJYo0YNTp48iVarNUhez507ZxCvECVNem6EyGby5Mk4OjoyZswYoqKichwPCQnh22+/BcDPz49Ro0axdevWXH9Qz507l+3btzN69Oh8Z66MGTOGqVOnMnPmTKN8DkFBQbn+5rthwwYAg+EmR0dH7ty5Y3CepaUlPXv2ZPXq1QbTp6Oiovjrr7/o2LGjflhk0KBB+mGv++UWw/Dhw/nuu++YO3cub731VlE+vWLr2bMnzs7OTJs2LcdCibqYW7ZsSa1atfjqq69ISEjIcY3o6OgSjbFXr164uLjw+eef57rKte7+lStXplmzZvz666/ExcXpj2/ZsoWzZ8/mew8LCwsGDBjA2rVrDVbC1tF9LXRr7tz/7yQ3ffr0ITIykqVLl+pfy8jIYPbs2Tg5OdG5c+cHXkMIY5DKjRDZ1KpVi7/++ovBgwdTv359gxWK9+3bp5/WqvPNN99w7tw5XnrpJTZu3Kiv0GzatInVq1fTuXPnByYtNWrUMOp+PxMmTCApKYmBAwdSr149fexLly7F39+fUaNG6c9t2bIlW7du5euvv6ZKlSoEBATQtm1bPv30U7Zs2ULHjh156aWXsLKyYt68eaSmpjJjxgz9+998802WL1/OU089xfPPP0/Lli2JiYlhzZo1zJ07l6ZNm+aI7+WXXyY+Pp733nsPV1dX3n33XaN97gXh4uLCN998w5gxY2jdujVDhw7F3d2dEydOkJSUxK+//oqFhQU///wzvXv3pmHDhowaNYqqVaty/fp1goKCcHFxYe3atSUa45w5cxg2bBgtWrTgmWeewdvbm7CwMNavX0+HDh34/vvvAZg2bRqPPfYYHTt25PnnnycmJobZs2fTsGHDXBOz7D7//HM2b95M586deeGFF6hfvz4REREsW7aMPXv24ObmRrNmzbC0tOSLL74gLi4OW1tbHnnkEYM1k3ReeOEF5s2bx8iRIzly5Aj+/v4sX76cvXv3MmvWrAI36wtRbCadqyVEGXXhwgU1duxY5e/vr2xsbJSzs7Pq0KGDmj17tkpJSTE4NzU1VX3zzTeqZcuWytHRUTk4OKgWLVqoWbNm5Tr9WjcVPD/FmQr+77//queff17Vq1dPOTk5KRsbGxUYGKgmTJigoqKiDM49d+6cevjhh5W9vb0CDKaFHz16VPXq1Us5OTkpBwcH1bVrV7Vv374c97t9+7Z6+eWXVdWqVZWNjY2qVq2aGjFihLp165ZSynAqeHaTJ09WgPr+++/z/Fx0U4a//PLLfD/n3L5e9x/TTQXXWbNmjXrooYeUvb29cnFxUW3atFGLFy82OOfYsWPqiSeeUJ6ensrW1lbVqFFDPf3002rbtm35xmOMuJXK+tr16tVLubq6Kjs7O1WrVi01cuRI9d9//xmct2LFClW/fn1la2urGjRooFauXKlGjBjxwKngSil19epVNXz4cOXt7a1sbW1VzZo11fjx41Vqaqr+nPnz56uaNWsqS0tLg2nh908FV0qpqKgoNWrUKOXl5aVsbGxU48aN1cKFCwv89cktRiEKS6OUdG4JIYQQouKQnhshhBBCVCiS3AghhBCiQpHkRgghhBAViiQ3QgghhKhQJLkRQgghRIUiyY0QQgghKhSzW8RPq9Vy48YNnJ2djbJBoRBCCCFKnlKKu3fvUqVKlQfuTWd2yc2NGzf0++IIIYQQonwJDw/Pd0sbMMPkRrf8d3h4uH5/HCGEEEKUbfHx8fj5+RVoGw+zS250Q1EuLi6S3AghhBDlTEFaSqShWAghhBAViiQ3QgghhKhQJLkRQgghRIUiyY0QQgghKhRJboQQQghRoUhyI4QQQogKRZIbIYQQQlQoktwIIYQQokKR5EYIIYQQFYokN0IIIYSoUEya3OzatYu+fftSpUoVNBoNq1ateuB7duzYQYsWLbC1tSUwMJBFixaVeJxCCCGEKD9MmtwkJibStGlTfvjhhwKdHxoaymOPPUbXrl05fvw4EydOZMyYMWzatKmEIxVCCCFEeWHSjTN79+5N7969C3z+3LlzCQgIYObMmQDUr1+fPXv28M0339CrV6+SClMIUcLS09OxtLTEwkJGyoUQxVeuvpPs37+f7t27G7zWq1cv9u/fn+d7UlNTiY+PN3gIIcqO06dP4+zszKRJk0wdihCigihXyU1kZCS+vr4Gr/n6+hIfH09ycnKu75k2bRqurq76h5+fX2mEKoQooCVLlpCamsr8+fPz/H8shBCFUa6Sm6J45513iIuL0z/Cw8NNHZIQIpugoCAAkpKS2LJli4mjEUJUBOUqualUqRJRUVEGr0VFReHi4oK9vX2u77G1tcXFxcXgIYQoGxISEjh06JD++cqVK00YjRCioihXyU379u3Ztm2bwWtbtmyhffv2JopICFEce/bsISMjAxsbGwDWrFlDenq6iaMSQpR3Jk1uEhISOH78OMePHweypnofP36csLAwIGtIafjw4frz//e//3H58mUmT57MuXPn+PHHH/n777957bXXTBG+EKKYtm/fDsCQIUPw9vYmNjaWnTt3mjgqIUR5Z9Lk5r///qN58+Y0b94cgEmTJtG8eXM++OADACIiIvSJDkBAQADr169ny5YtNG3alJkzZ/Lzzz/LNHAhyildv02PHj3o378/AP/8848pQxJCVAAapZQydRClKT4+HldXV+Li4qT/RggTunPnDp6enmi1Wq5fv86JEyfo06cPlStX5tq1a7LmjRDCQGF+fst3DyGESezatQutVkvdunWpUqUKjzzyCC4uLkRERHDw4EFThyeEKMckuRFCmISu3+aRRx4BsmY2PvbYY4AMTQkhikeSGyGESeiSm65du+pfe+KJJ4CsKeG5jZjPmTOHDh06cOPGjdIJUghRLklyI4QoddHR0Zw6dQqALl266F9/9NFHsbOzIyQkRH9cZ8WKFbz00kvs27ePVatWlWK0QojyRpIbIUSp27FjBwCNGzfG29tb/7qTk5N+9mP2Bf2OHTtmsCxESEhI6QQqhCiXJLkRQpQ63RRwXb9NdgMHDgTu9d1ERETQr18/kpKS9DMkJLkRQuRHkhshRKnLrd9Gp2/fvlhaWnLy5ElOnz7NwIEDuXbtGvXq1eOnn34C4PLly6UarxCifLEydQBCCPNy48YNzp8/j4WFBZ07d85x3MPDg65du7J161Z69OhBZGQk7u7urF27Fq1WC2QlN0opNBpNaYcvhCgHpHIjhChVuiGpFi1a4Obmlus5ullTkZGRWFlZsXz5cgIDA/H398fCwoLExMQcm+gKIYSOJDdCiFKlS25yG5LSGTBggH6F4tmzZ+t7c2xsbPDz8wNkaEoIkTcZlhJClKr7F+/LTeXKlVm6dClJSUkGs6QAatasydWrVwkJCeGhhx4q0ViFEOWTJDdCiFJz5coVQkNDsbKyomPHjvme++STT+b6eq1atQgKCpIZU0KIPElyI4QwOq1Wy4QJE9i5cyfe3t74+Pjg4+PDzZs3AWjTpg1OTk5FunatWrUAGZYSQuRNkhshhNHNmDGDH3/8Mc/j+Q1JPUjNmjUBWetGCJE3SW6EEEa1bds23nvvPQA++ugjateuzc2bN/UPpRQTJkwo8vV1lRtJboQQeZHkRghhNNeuXWPIkCFotVpGjhzJlClTjL4WjS65iYqKIjExEUdHR6NeXwhR/slUcCGEUaSlpfHUU08RHR1Ns2bN+PHHH0tkkT03Nzfc3d0B6bsRQuROkhshhFFMmjSJAwcO4ObmxooVK7C3ty+xe8nQlBAiP5LcCCGK7c8//+SHH34A4Pfff9c3/ZYUSW6EEPmR5EYIUSwhISGMHTsWgPfff5/HH3+8xO8p08GFEPmR5EYIUSxvv/02ycnJdOnShQ8//LBU7inTwYUQ+ZHkRghRZPv27WP58uVYWFgwe/ZsLC0tS+W+MiwlhMiPJDdCiCJRSvH6668D8Pzzz9OoUaNSu7cuubly5QqZmZmldl8hRPkgyY0QpSgmJob27dsza9YsU4dSbMuXL+fAgQM4ODjw8ccfl+q9q1Spgo2NDRkZGYSHh5fqvYUQZZ8kN0KUovXr13PgwAE+/fRTtFqtqcMpstTUVN5++20AJk+eTOXKlUv1/paWlgQEBAAyNCWEyEmSGyFK0YULFwC4ffs2J06cMHE0Rffjjz9y+fJlKleuzBtvvGGSGGTGlBAiL5LcCFGKdMkNwNatW00YSdHFxMTwySefAPDJJ5+YbPsDmTElhMiLJDdClKKLFy/qP962bZsJIym6zz77jNjYWBo1asTIkSNNFofMmBJC5EWSGyFKiVLKoHKza9cuUlNTTRhR4V2+fJnZs2cD8NVXX5Xa1O/cyLCUECIvktwIUUoiIiJITEzE0tISHx8fkpOT2b9/v6nDKrC0tDSGDRtGeno6PXv2pFevXiaNJ/uwlFLKpLEIIcoWSW6EKCW6qk1AQAA9evQAylffzSuvvMK+fftwdXXl+++/N3U4+uQmLi6OmJgYE0cjhChLJLkRopTo+m1q165N9+7dgfKT3Pz000/MmzcPjUbDX3/9Re3atU0dEvb29lSpUgWQoSkhhCFJboQoJbrKTZ06dejWrRsAhw8fJi4uzpRhPdC+fft4+eWXAfj000/p06ePiSO6R5qKhRC5keRGiFKSPbnx8/Ojbt26aLVaduzYYdrA8nH9+nUGDRpEeno6Tz75JO+8846pQzIg08GFELmR5EaIUpI9uQH01ZuyOjSVkpLCE088QWRkJI0aNWLhwoVoNBpTh2VAKjdCiNxIciNEKcjMzNT/ANb1q5TVvpuEhAT++usvevXqxaFDh3Bzc2PVqlU4OTmZOrQcZDq4ECI3VqYOQAhzcPXqVdLT07G1tcXPzw+ALl26YGFhwblz57h+/TpVq1Y1WXzJycn8+++/LFmyhHXr1pGcnAyAlZUVS5Ys0ScRZY0MSwkhciOVGyFKgW5Iqnbt2lhYZP23c3d3p1WrVoBpVyuOjY2ladOmDBo0iGXLlpGcnExgYCBTpkzhzJkzJl/PJj+6pOv69eukpKSYOBohRFkhyY0QpeD+fhudsjA0tXTpUi5evIiHhwdvvvkmR44c4cKFC3z88cc54i1rvLy8cHZ2RinFlStXTB2OEKKMkORGiFKQvXKTXfamYlOtsvvXX38B8M477zBjxgxatGhR5hqH86LRaGRoSgiRgyQ3QpQC3QJ+91dCHnroIezs7IiIiCA4OLjU4woLC2P37t1oNBqeeeaZUr+/MciMKSHE/SS5EaIU5DUsZWdnR6dOnQDTDE0tXrwYgM6dO1OtWrVSv78xyIwpIcT9JLkRooSlpKRw9epVIGdyA/f6bkzRVKwbkho6dGip39tY/P39AfRfYyGEkORGiBKm27Xa1dUVb2/vHMd1fTdBQUFkZGSUWlynT5/m5MmTWFtb8+STT5bafY3N19cXgJs3b5o4EiFEWSHJjRAlLPuGmbk16jZr1gwnJyfu3r2rH74qDbqqTZ8+fXB3dy+1+xqbj48PANHR0SaORAhRVkhyIyqE27dv8++//5psxlF+8uq30bG0tKRevXoAnDt3rlRiUkpViCEpuJfcSOVGCKEjyY0o9zIzM+nZsyd9+vRh9erVpg4nhwclNwD169cHSi+52bdvH1evXsXJyYm+ffuWyj1Lim6oLy4ujrS0NBNHI4QoCyS5EeXeggULOHr0KADr1q0zcTQ5FSS50VVuSms6uK5q88QTT2Bvb18q9ywpbm5uWFll7SQjQ1NCCJDkRpRzsbGxvPfee/rnptzGIC/Ze27yUprDUunp6fz9999A+R+SArCwsMDLywuQoSkhRBZJbkS59tFHH3Hr1i3q1q2LlZUVV65cKVPrncTHxxMZGQnkn9xkH5Yq6b6hLVu2cOvWLXx8fPQztco7aSoWQmQnyY0ot86ePcv3338PwOzZs2nXrh1Qtqo3uqqNr68vrq6ueZ5Xq1YtLC0tSUhI4MaNGyUak25IavDgwfrhnPJOmoqFENlJciPKJaUUEydOJDMzk/79+9OjRw99FaIsJTcF6bcBsLGx0a+0W5J9N4mJiaxatQqoGENSOrqmYkluhBAgyY0op9asWcOWLVuwtbXl66+/Bu4thrd9+3a0Wq0pw9MrSL+NTmnMmFq3bh2JiYnUrFmTtm3blth9SpsMSwkhspPkRpQ7KSkpTJo0CYDXX39dvyt027ZtcXBwIDo6mtOnT5syRL2CVm6gdJqKdbPKevfuXW52/i4IqdwIIbKT5EaUO19//TWXL1+mSpUqvPPOO/rXbWxsePjhh4GyMzRVlOSmJIelrly5AtzbbLKikMqNECI7SW5EuRIXF8fnn38OwIwZM3BycjI4Xpb6bpRShUpuSmNYSre5ZI0aNUrsHqYgDcVCiOxMntz88MMP+Pv7Y2dnR9u2bTl06FC+58+aNYu6detib2+Pn58fr732GikpKaUUrTC1xYsXk5iYSIMGDXJtiNUlNzt37iQ9Pb20wzNw69Yt4uLi0Gg0BaqU1K1bF4AbN24QHx9fIjHpKje6nbQrChmWEkJkZ9LkZunSpUyaNImpU6dy9OhRmjZtSq9evfL8BvXXX3/x9ttvM3XqVIKDg1mwYAFLly7l3XffLeXIhaksWLAAgDFjxuTaM9K0aVM8PT1JSEjg8OHDpR2eAV3Vpnr16tjZ2T3wfDc3NypVqgSUTPUmOTmZqKgooOJWbmRYSggBJk5uvv76a8aOHcuoUaNo0KABc+fOxcHBgV9++SXX8/ft20eHDh0YOnQo/v7+9OzZkyFDhjyw2iMqhhMnTvDff/9hbW3NsGHDcj3HwsKCrl27AqYfmirMkJROSTYVh4WFAeDk5ISHh4fRr29KuspNQkICSUlJJo5GCGFqJktu0tLSOHLkCN27d78XjIUF3bt3Z//+/bm+56GHHuLIkSP6ZOby5cts2LCBPn365Hmf1NRU4uPjDR6ifNJVbQYMGKBfbj83ZaXvpijJTUn23WTvt6lIM6UAXFxcsLGxAaR6I4QwYXJz69YtMjMz8fX1NXjd19dXv1z9/YYOHcrHH39Mx44dsba2platWnTp0iXfYalp06bh6uqqf/j5+Rn18xClIyUlhT/++AOA0aNH53uuLrnZv3+/SX+L1yXpjRs3LvB7SnLGVEXttwHQaDQyNCWE0DN5Q3Fh7Nixg88//5wff/yRo0ePsnLlStavX88nn3yS53veeecd4uLi9I/w8PBSjFgYyz///ENsbCzVq1c3qPblJjAwED8/P9LS0tizZ08pRWgoISGBffv2ARRq/6aSHJbSVW4qYnID0lQshLjHZMmNl5cXlpaW+gZHnaioKH1T5f2mTJnCsGHDGDNmDI0bN2bgwIF8/vnnTJs2Lc8VaW1tbXFxcTF4iPJHNyQ1atQoLC0t8z1Xo9GYfGhq9+7dpKen4+/vX6g1ZXTDUpcuXTL6bC9d5aaiNRPrSOVGCKFjsuTGxsaGli1bGvzw0Wq1bNu2jfbt2+f6nqSkJCwsDEPW/aAr6Z2UhelcvnyZbdu2odFoGDVqVIHeY+rkZsuWLQB07969UP0tVatWxdHRkYyMDKPvbl7RKzey1o0QQsekw1KTJk1i/vz5/PrrrwQHBzNu3DgSExP1P8CGDx9usAJt3759mTNnDkuWLCE0NJQtW7YwZcoU+vbt+8Df5kX5tXDhQgB69OhR4KrDI488AmRtNxATE1NiseVFl9z06NGjUO+zsLDQr3dj7L6bil65kWEpIYSOlSlvPnjwYKKjo/nggw+IjIykWbNmbNy4Ud9kHBYWZlCpef/999FoNLz//vtcv34db29v+vbty2effWaqT0GUsMzMTH1y86BG4uyqVKlC/fr1CQ4OJigoiEGDBpVUiDlERkZy+vRpNBqNPskqjPr163P06FGj9t2kpaVx48YNoOJXbmRYSghh0uQG4OWXX+bll1/O9diOHTsMnltZWTF16lSmTp1aCpGJsmDTpk1cv34dT09P+vfvX6j3duvWjeDgYLZv316qyc3WrVsBaN68eb5T1vNSEk3F4eHhKKWwt7fXVzgqGqncCCF0ytVsKWF+fv75ZwCGDRuGra1tod7bpk0boGQ3osyNLrkp7JCUTklMB88+JFXR1rjRkcqNEEJHkhtRZkVFRbF27VqgcENSOjVr1gQwemNufpRSBs3ERZF9IT9jNcpX9GZikIZiIcQ9ktyIMmv79u1kZGTQokULGjVqVOj365Kb8PDwUttE89y5c9y4cQM7Ozs6duxYpGsEBgZiYWFBfHx8ngtaFlZFbyYGw2EpmT0phHmT5EaUWdevXwfuVTIKq1KlStjZ2aHVavX7KpU0XdWmY8eOBdosMze2trb6xMxYQ1PmVLlJSUkhMTHRxNEIIUxJkhtRZumqFnkt6vggGo2GgIAAAEJDQwv9ft2WDwkJCQV+T1GngN/P2E3F5lC5cXR0xN7eHpChKSHMnSQ3osyKiIgAoHLlykW+hi65KUrfzRtvvMGwYcPynM13v/T0dP0Mv6L22+gYewNNc6jcgPTdCCGySHIjyqziVm7gXt9NYSs3N27c0M/U+vPPPws0rHXw4EESEhLw8vKiWbNmhY41O2POmMrIyODatWtAxa7cgMyYEkJkkeRGlFmmrNx89dVXpKamAlnJwddff/3A9+imgHfr1i3HNiGFZcxhqWvXrpGZmYmNjU2xEsXyQNa6EUJAGVjET4i8mKpyEx0dzdy5cwF4/fXXmTlzJvPnz2fKlCl4enrm+b7iTgHPTpfcXLt2jbt37+Ls7Fzka+mGpGrUqFHspKusk8qNECUvPTOd2JRYYpNjDf68k3JH/3E1l2pMbDfRZDFKciPKpJSUFGJjY4HSr9x88803JCcn06pVK7788ku2b9/OsWPH+P777/NcHTsuLo6DBw8CxW8mBvDw8MDHx4ebN29y4cIFWrZsWeRrmUMzsY5UboQoGKUUcalxxCTHEJscS0xyjP4RmxJ77/WUGH3ConstMf3BsxHbVWsnyY0Q94uKigKypkW7ubkV+Tq65Ob27dvEx8fj4uKS7/kxMTF8//33wL29zN5++20GDx7M7NmzeeONN3B0dMzxvp07d5KZmUlgYKDRkoh69epx8+ZNtm/fXqzkxlyaiUEaioX5UUqRkJbA7eTb3E66rf8zJjmG28mGfxokMMmxZKrMYt3b1dYVd3t33O3ccbd3x83OLetjO3cCPQKN9BkWjSQ3okzKPiRVnO0CXFxc8PT05Pbt24SGhtK0adN8z589ezZ3796lSZMm9O3bF4BBgwZRq1YtQkJCWLBgAa+88kqO9xlrCnh2Tz/9NLt27eKDDz6gd+/eRVrIEMyrciPDUqI801VTbiXd0j9uJ92+93Hybf2f2ROZdG3RFym1t7LH08ETdzt3POw98LD30H+sS1xy+9jV1hVLC0sjfvbGJcmNKJN0zcTGaICtWbNmgZKb+Ph4vv32WwDee+89fX+KpaUlb7zxBuPGjWPmzJmMGzcOa2tr/fv+++8/li5dChin30Zn3LhxrFu3jo0bN/LMM89w+PBh/TouhWFOlRsZlhJlSWpGKtFJ0UQnRnMr6RbRSf//Z2K0/uP7H0Wtptha2uLp4Imnvaf+Tw97j3t/Ohg+1yUpdlZFW2y0rJPkRpRJxmgm1gkICODw4cMP7LuZM2cOsbGx1K1bN8cu4iNHjuTDDz8kLCyMpUuX8txzz6GU4qeffuKVV14hLS2NunXr0qtXr2LHq2NhYcGiRYto2rQpZ86c4fXXX+fHH38s9HXMsXIjyY0oCbpk5WbiTaITs/68mXjz3mv/n8joniekFXwB0OycbJzwtPfEy8FL/9AlLXl9bG9lX2E3xS0KSW5EmWSMaeA6BZkxlZiYyMyZM4Gsqo2lpWG51c7OjldffZV3332XL774goEDB/LSSy/x22+/AdCvXz9+/fXXXPtxisPX15fff/+dnj17MmfOHLp3784TTzxR4PdnZmYSHh4OmEflJvuwlFJKvtmLfCmluJNyh5uJN4lKjCIqIUr/sS5xyf6IS40r9D2sLKzwcvDC28E7609H73sfO3jj6eCpf+7l4IWng2eFraaUJkluRJlk7MoN5D9jav78+URHR1OzZk2GDBmS6znjxo1j2rRpnD59mnr16nHt2jUsLCz4/PPPefPNN0tsmnWPHj2YPHkyM2bMYPTo0bRq1Yrq1asX6L0RERGkp6djZWVFlSpVSiS+skQ3LJWenk5cXFyxmtFF+aSUIj41nsiESCITIolKjNJ/rHselRClT2DSMtMKdX0rCyu8HbzxcfTRJyo+jj54O3jj7Wj4sbeDN252bpJkm4AkN6JMKu3Kzfz58wF4++23sbLK/b+Fm5sb//vf//jyyy+5du0avr6+LFmyhC5duhQ7xgf59NNP2bFjB4cOHeLZZ58lKCgozziz0w1J+fn55ahGVUR2dnY4Oztz9+5doqOjJbmpQNIz0/WJSsTdiKw/EyL0SUv2j1MyUgp1bVdbV3wcffB18sXX0RcfR5+s59k+1iUz7nbukqyUA5LciDKpJCo3oaGhuQ5VxMTEcPbsWQAGDhyY77UmTZrE+vXr8fPz45dffim1aoi1tTV//fUXzZs3Z8+ePbz44ovMnj0bBweHfN9nTs3EOt7e3ty9e5ebN29Su3ZtU4cjHiAlI4WIuxHcuHuDiIQIIu5GEJFw77kumbmVdAuFKvB1nW2cqexcGV9HXyo5VcLX0Rdfp5wf+zj6yDBQBSTJjSiTjFm5qV69OhYWFqSkpBAZGZnjmrrF92rXro2Xl1e+16pUqRJnzpwpdkxFUatWLX766SeGDBnCL7/8wp49e/jtt99o27Ztnu8xp2ZiHR8fHy5fvixNxSaWqc0kKjGK6/HXuXH3BtfvXs/6OOEGN+7ee8QkxxT4mlYWVlRyqkQlp0pUdqqs//j+575OvjhY55/4i4pNkhtR5mi1Wv0ifsao3FhbW+Pn58fVq1e5fPlyjuRm//79ALRv377Y9yppzzzzDO7u7jz//PNcuHCBhx56iHfffZcpU6ZgY2OT43xzrNzIWjclLzUjlRt3b3At/prh4+41rsdf51r8NSITIgs8rdnOyo7KTpWp4lyFys6VqexU2eC5LnnxdPDEQlOxtxARxiHJjShzYmJiSE/PWpTK19fXKNesWbMmV69eJTQ0lA4dOhgc0yU37dq1M8q9SlqvXr04ffo0EyZM4M8//+TTTz9l/fr1/P777zRs2NDgXHOs3MhaN8WTkpHC9fjrhMeH65OW8Lhwrt29l8TcTCzY19ZCY0Elp0pUda5KVZeqWX86V6WKcxWDhzTdCmOT5EaUObp+G09Pz1yrEUUREBBAUFBQjhlTmZmZ+mGp8lC50XF3d+ePP/6gf//+jBs3jmPHjtGhQweOHTum7zECqdwIQ+mZ6dy4e4Pw+HDC4sIIjwsnPP7/H3FZyUx0UsG+bnZWdlR1rko1l2pUdalKNedq9z52qUZV56r4OvliZSE/ZkTpk391oswxZjOxTl4zpoKDg7l79y6Ojo5F3t7AlJ566ik6depE//79OXToEEOGDGH37t1YW1uj1WrNMrkx58rN3dS7XI27ytU7V7ly5wphcWGExYdl/RkXxo27N9Aq7QOvY29lTzWXavi5+uHn4kc1l2r6h+65h72HVFtEmSXJjShzjNlMrJPXWje6Iak2bdoUaGp1WVSpUiX+/vtvmjZtysGDB5k6dSqff/45N2/eJDU1FQsLC6pWrWrqMEtNRV6lOCEtgSt3rnDlzhVCY0OzPo67on+tIM251hbW+qRF/2e2jyVxERVB+fxuLiq00qzclKdm4vzUqFGDn3/+maeeeorp06fTrVs3/WrJ1apVM9gLq6Irz8NSqRmpXI27SmhsKKF3spKX0Duh+ue3km498Brudu7UcKtBDdesR3XX6tRwy/qzumt1fBx9pClXVHiS3IgypyQrN9euXSM1NRVbW1ug/DUT5+fJJ5/khRde4KeffuK5557j3XffBcyrmRjK9rBUpjaTa/HXciQtuo9v3L3xwLVc3OzcCHALIMA9AH9XfwLcA6jhWgN/N39quNXAxdallD4bIcouSW5EmVMSlRsfHx8cHBxISkoiLCyM2rVrExMTw7lz54CKkdwAfPPNN+zevZvg4GAmT54MmFe/Ddyr3Ny6dQutVlti22LkJTY5lpDYEC7HXuZy7GVCY0O5fCfrz6txV8nQZuT7fgdrB33yEuAWcC+RcfMnwC0AVzvXUvpMhCi/JLkRZU5JVG40Gg0BAQGcOXOGy5cvU7t2bQ4dOgRAYGCg/rf98s7BwYGlS5fSunVrUlKylqA3t8qNbiHGzMxMYmNj8fT0NOr1lVLcSrrFxZiLXLx9kYsxF7kUc4mQ2BBCYkKITYnN9/3WFtbUcKtBgNu9hEWfyLgH4O3gLf0uQhSTJDeizCmJyg1k9d2cOXNG33dTUfpt7te4cWO+/vprxo8fD5hf5cbGxgY3Nzfu3LnDzZs3i5zcJKcnczHmIudvnef87f9/3DrPhdsXHrg7dCWnStRyr0VN95r6pEX3cRXnKlhaVPx9voQwJUluRJmjq9wYO7m5f8ZURU1uIGsH84MHD7Jy5cpS2dizrPHx8eHOnTtER0dTv379PM9TSnH97vV7CUy2RObqnav59r/4ufhR27M2tT2yHoEegdR0r0lN95o42jiWxKclhCggSW5EmZKcnExcXNZvxcYclgLDGVNarVa/eF9F6bfJTqPR8Ouvv7JgwYJyO8W9OLy9vblw4YK+qfh20m39MNKF2xe4EHMh68/bF0hKT8rzOm52btT1rEtdr7pZf3rWpY5nHQI9ArG3ti+tT0cIUUjm911PlGm6ISlbW1tcXY3bOKlLbi5fvszZs2eJj4/H0dGRxo0bG/U+ZYk5JTZxKXH6BCamcQz4whvn3+CFL17Itw/GysKKALcA6nnVM0xkvOpK/4sQ5ZT5fOcT5YIuualcubLRf6johqVCQ0M5cOAAAK1btzarBKC80yotV+9cJfhWMOdunTN4GGwbUCnrcTXjKvz/5KSqzlX1w0i65KWOZx0C3AKwtjSfdYCEMAfyXV2UKSXVTAz3kpvY2Fj+/fdfoGL221QUNxNvcjLqJKeiTnH65mlO3TzFmegz+Q4j+Tr6UtuzNnev3OXE9hP0at2LGW/NoJZ7LemDEcKMSHIjypSSmAau4+joiI+PDzdv3mT9+vWAJDdlgVZpCY0N5VjkMY5HHtf/eePujVzPt7G0oY5nHep51aOeZ72s4aT/r8LoFrCbPXs2r+x5BedKzjTxbVKan44QogyQ5EaUKSVZuYGsvhvdnksAbdu2LZH7iNylZaYRHB3MschjHIs4xrHIY5yIOkF8anyOczVoqOVRi8Y+jWns05hGPo1o7NuYQI/AB+40rVu3qDxuwSCEKL5iJTcpKSnY2dkZKxYhSmwauE5AQIC+36ZWrVr61WyFcWVqM7kad5UzN89w6uaprEfUKc7fPp/rCr02ljY09mlM80rNaVapGc0rN6exT2OcbZ2LdP+KvHmmEOLBCp3caLVaPvvsM+bOnUtUVBQXLlygZs2aTJkyBX9/f0aPHl0ScQozkb2huCToZkyBDEkZQ2JaIhduX+D87fOcu3VO3+h74fYFUjJScn2Pi61LVgJTqXnWo3Jz6nvVN2pTb3nePFMIUXyFTm4+/fRTfv31V2bMmMHYsWP1rzdq1IhZs2ZJciOKpTQqNzqS3BRcbHIsp2+e5vTN05yJPsO5W+c4f/s81+Kv5fkeW0tb6nrVzTGs5OfiV+LTq3VbMNy+fdsk+0sJIUyr0MnNb7/9xk8//US3bt343//+p3+9adOm+k0IhSgqqdyYXlRCFAevH+TAtQMcizzGqahTXL97Pc/zPe09qetVl3qe9ajvXZ/6XvWp51UPfzd/k20z4O7uDmStQBwXF6d/LoQwD4VObq5fv05gYGCO17VaLenp6UYJSpgnrVZLVFQUUHKVm3r16mFtbY2Li0uFXryvoLRKy6moU+y4soP91/Zz4NoBrsZdzfVcPxc/Gvs2pqF3Q+p71dcvdufpYNyNKY3B1tYWe3t7kpOTiY2NleRGCDNT6OSmQYMG7N69O8dOw8uXL6d58+ZGC0yYn9u3b5ORkdVs6uvrWyL3qFy5Mlu2bMHNzc0sF+9TSnEm+gw7ruwg6EoQO6/s5HbybYNzNGho4N2AtlXb0rpqa5r4NqGhd0Nc7Yy7YnRJ8/Dw4Pr168TG5r9LtxCi4in0d/cPPviAESNGcP36dbRaLStXruT8+fP89ttvrFu3riRiFGZC12/j5eWFtXXJrRjbuXPnErt2WaOU4sLtCwRdCSLoShA7ruzgZqLhDCJHa0c6Vu9Ip+qdaFetHa2rttavF1Oeubu7S3IjhJkqdHLTv39/1q5dy8cff4yjoyMffPABLVq0YO3atfTo0aMkYhRmoqT7bcxBQloCRyOOcuj6IQ5dP8Te8L05FsOzt7KnQ/UOdPXvSlf/rrSq0qpCbj+gG4qS5EYI81OkunynTp3YsmWLsWMRZq6kZ0pVJIlpiVyKuaTf2fpCzAWORRzjTPQZtEprcK6NpQ3tq7XnkYBH6OrflTZV22BrZWuiyEuPLrmJiYkxcSRCiNJW6OTm8OHDaLXaHCu7Hjx4EEtLS1q1amW04IR5KenVicub5PRkLty+wKWYS/cesVl/5jcFu6pzVdpUbUObqm1oW7Ut7aq1w97avhQjLxukciOE+Sp0cjN+/HgmT56cI7m5fv06X3zxBQcPHjRacMK8mPOw1NU7Vzl843DWJpHRpzkVdYqQ2JAcVZjsPOw9qONZJ+vhUYeGPg1pXaU1VV2qlmLkZZeHhwcgyY0Q5qjQyc3Zs2dp0aJFjtebN2/O2bNnjRKUME/mNCyVkJbAjis72ByymU0hm7hw+0Ku5+kSmECPQGq519L/WcezTpmcgl2WSOVGCPNV6OTG1taWqKgog8XQIOsHkzlOrRXGU9ErN4lpiSw/u5zfT/7Orqu7SNfeWxfKUmNJ88rNaeLThMa+Wav5NvJphK+jb4mv5ltRSc+NEOar0NlIz549eeedd1i9ejWurlnrXty5c4d3331XZkuJYqmIlRulFHvD97Lw2EL+Pvs3CWkJ+mMBbgH0qtWLXoG96OrftdytI1PWSeVGCPNV6OTmq6++4uGHH6ZGjRr6RfuOHz+Or68vv//+u9EDFOajIlVursdf57cTv7HoxCKDIadAj0BGNh3J0w2fJtAjUKoyJUh6boQwX4VObqpWrcrJkyf5888/OXHiBPb29owaNYohQ4aU6MJromJLSkoiPj4eKL+Vm7TMNNaeX8svx39h46WN+mZgR2tHnm74NKOajaJj9Y6S0JQSqdwIYb6K1CTj6OjICy+8YOxYhBnTVW3s7e1xcSk/q+PGJMewPXQ7W0K2sCJ4hcFWBp2qd2JUs1E81fApnGycTBileZKeGyHMV4GSmzVr1tC7d2+sra1Zs2ZNvuf269fPKIEJ85K936YsVjaUUtxOvk3E3Qiu373OnrA9bLm8hf9u/GcwXbuKcxVGNB3ByGYjqeNZx4QRC11yEx8fT2ZmJpaWptmhXAhR+gqU3AwYMIDIyEh8fHwYMGBAnudpNBoyMzONFZuooFJTU0lPT8fJ6V41o7QX8FNKceXOFY5HHudE1AmORx4nPD4cyNo4UpdgaZWWm4k3iUqIMpjdlF0D7wb0qNmD3oG96VazG1YWMmuwLMi+E/idO3fw9JSp80KYiwJ9F9Zqtbl+LERhRUVF0blzZy5fvkz//v0ZPXo0PXr00FduSrKZODoxmpXBK1kRvIKD1w8Snxpf6Gt42ntSyakSTXyb0LNWT7rX7E41l2olEK0oLmtra5ycnEhISCA2NlaSGyHMSKF+xUxPT+fRRx9l7ty51K5d2ygB/PDDD3z55ZdERkbStGlTZs+eTZs2bfI8/86dO7z33nusXLmSmJgYatSowaxZs+jTp49R4hElJyEhgccee4zz588DsHz5cpYvX061atXw8fEBjF+5iU6M5p9z//D3mb/ZcWUHmepeZdHG0oaG3g1pVqkZTX2bEugRiIXGAoUCsqo7Go0GbwdvKjlVwtfJFxtLG6PGJ0qWu7s7CQkJ0ncjhJkpVHJjbW3NyZMnjXbzpUuXMmnSJObOnUvbtm2ZNWsWvXr14vz58/ofdtmlpaXRo0cPfHx8WL58OVWrVuXq1au4ubkZLSZRMtLS0hg0aBBHjhzBy8uLRYsWsXnzZv744w+uXbvGtWtZeyUZq3KTnJ7MRzs/Yub+mWRoM/Svt6jcgqcbPE3v2r2p71W/Qu6GLe5xd3cnPDxcZkwJYW5UIU2cOFG99dZbhX1brtq0aaPGjx+vf56ZmamqVKmipk2bluv5c+bMUTVr1lRpaWlFvmdcXJwCVFxcXJGvIQpHq9WqYcOGKUA5ODiogwcP6o8lJyerJUuWqB49eqjq1aurkydPFvt+W0O2qlrf1lJ8iOJDVPO5zdW03dPUpduXin1tUb506dJFAWrx4sWmDkUIUUyF+fld6M7HjIwMfvnlF7Zu3UrLli1xdHQ0OP71118X6DppaWkcOXKEd955R/+ahYUF3bt3Z//+/bm+Z82aNbRv357x48ezevVqvL29GTp0KG+99VaeMyFSU1NJTU3VP9etpSJKzzvvvMPvv/+OpaUly5cvNxh2tLOzY/DgwQwePLjY97mddJvXN7/Oryd+BbJ2x/6hzw/0r9e/2NcW5ZOsdSOEeSp0cnP69Gn9xpkXLhhu9leYKby3bt0iMzMTX19fg9d9fX05d+5cru+5fPky27dv59lnn2XDhg1cunSJl156ifT0dKZOnZrre6ZNm8ZHH31U4LiEcX333Xd88cUXAPz888/07t27RO6z7Mwyxm8YT3RSNBo0jG89ns+6fYaLbflZM0cYn6x1I4R5KnRyExQUVBJxFIhWq8XHx4effvoJS0tLWrZsyfXr1/nyyy/zTG7eeecdJk2apH8eHx+Pn59faYVs1s6cOcPEiRMB+Pzzzxk5cqTR73E39S6vbHyFRccXAdDQuyHz+86nvV97o99LlD9SuRHCPBUquVm6dClr1qwhLS2Nbt268b///a/IN/by8sLS0pKoqCiD16OiovKcMVO5cmWsra0NhqDq169PZGQkaWlp2NjknMlia2uLra1tkeMURbdhwwaUt6JNhza88vorRr/+oeuHGLpiKCGxIVhoLHin4zt80PkDmdEk9GR/KSHMk0VBT5wzZw5Dhgzhv//+4+LFi4wfP54333yzyDe2sbGhZcuWbNu2Tf+aVqtl27ZttG+f+2/dHTp04NKlSwZr7Vy4cIHKlSvnmtgI01FKMS9kHrwEh5oewmW6Cw1/bMhzK59j5r6ZHLh2AKVUka6dqc3ks12f8dCChwiJDaG6a3V2jNjBp498KomNMCCVGyHMU4GTm++//56pU6dy/vx5jh8/zq+//sqPP/5YrJtPmjSJ+fPn8+uvvxIcHMy4ceNITExk1KhRAAwfPtyg4XjcuHHExMTw6quvcuHCBdavX8/nn3/O+PHjixWHMK4MbQZj14wlpHIIAG42bmiVlrPRZ/nz1J+8seUN2i9oT/0f6jNj7wyiEqIecMUscSlx/Hz0Z9r+3Jb3g94nU2UyuOFgTvzvBJ1qdCrJT0mUU5LcCGGeCjwsdfnyZUaMGKF/PnToUEaPHk1ERESR1yYZPHgw0dHRfPDBB0RGRtKsWTM2btyobzIOCwvDwuJe/uXn58emTZt47bXXaNKkCVWrVuXVV1/lrbfeKtL9hfGlZKQwdMVQ/jn3D2jBdqstN3fcJDolmmMRxzgWeYyjEUfZFLKJ87fP89bWt3hv+3s8XudxhjUZRk33mnjYe+Bu546TjRNapSXoShCLji9iZfBKkjOSAXCyceL73t8zvOnwMrkXlSgbpKFYCPOkUQUcG7CwsCAqKgpvb2/9a87Ozpw4cYKaNWuWWIDGFh8fj6urK3FxceVq9+nyID41ngFLBhB0JQhLLMlcmklv/95s2LAh13OXnl7KgmMLOHj9YK7Xs7Kwws7KjoS0BP1rDbwbMLLpSIY1HUYlp9LZh0qUX4cPH6ZNmzb4+fkRFhZm6nCEEMVQmJ/fhWoonjJlCg4ODvrnaWlpfPbZZ7i6uupfK+g6N8K4klKSmLFiBiMeGUFA5YBSv//NxJv0/rM3RyOO4mzjTJOzTdgbvJfOIzrner6LrQtjW45lbMuxnLl5hgXHFrA5ZDO3k28TkxxDWmYaGdoMEtIScLdzZ0ijIYxsNpJWVVpJpUYUmAxLCWGeCly56dKlywN/qGg0GrZv326UwEpKRazc7Dq5iz4L+5DolohNnA0X3rpADd8apXb/U1Gn6Lu4L1fjruLt4M36oevp3bQ3t2/fZv/+/bRr165Q11NKkZyRTExyDPGp8dR0r4mdlV0JRS8qstu3b+Pl5QVk/TJmbS3bbQhRXhXm53eBk5uKoqIlN6/Of5XvQr+DbLPd3WPdCZsWhpO9U4nff92FdQxZMYSEtAQCPQJZP3Q9aRFpNG7cGAcHB+7cuSM/UITJZGZmYmWVVaCOiorKdc86IUT5UJif3wWeLSXKlpuxN6n7Zl2+u5GV2DjHOvN+zfchDWLdY2k+pbnBlHljU0rx9f6v6be4HwlpCXT178rBMQep41mHnTt3AvDQQw9JYiNMytLSUj9sLkNTQpgPSW7KoS1HtuD3iR8XnC6Ago7ajtyccZNPhn3CR40+Ai1ccr5Ez097lsj90zLTGLt2LK9vfh2F4oUWL7DpuU142GctmKZLbjp3zr3fRojSJH03QpgfSW7KoWF/DCPNNQ2LRAtmNp3J7o92Y2eT1ZPywZAPeMb1GQC2qW2Mn2vcNYCUUjy17CkWHFuAhcaCbx/9lrmPz8Xa0lp/XJIbUZZIciOE+ZHkppzRarXctLsJwE/dfmLSwEk5zlk8aTGt0loB8OP1H/l+7fdGu/+fp/5kzfk12FnZsW7IOl5p+4pBo/mFCxe4efMmdnZ2Brt/C2EqstaNEOan0MlNenp6nsdu3bpVrGDEg205ugVlpyAdBj88OM/z9n+8nypxVcAKXtn7CntO7in2vW8l3eK1Ta8BMLXzVHrXzrnDt65q065dO9nTS5QJsr+UEOan0MnNM888k+ueQFFRUXTp0sUYMYl8/HPoHwCcE5zznQ1lZWnFyQ9P4hDngLJX9Jrbi5jY4v3m+sbmN7iVdIvGPo15vf3ruZ6jS24efvjhYt1LCGORYSkhzE+hk5uwsDDGjBlj8FpkZCRdunShXr16RgtM5G7v1b0A1Hao/cBzPV082TR2E5p0DUm+SbR7ox0ZGRlFuu+2y9v49cSvaNAwv+98fY9NdtJvI8oiSW6EMD+FTm42bNjAvn37mDQpq9fjxo0bdO7cmcaNG/P3338bPcDyIjgsmNd+fo0J8yaU6H0up10GoGNAxwKd37F+Rz5o/QEAF6td5Nm3ny30PZPTk3lx3YsAjG89nrbV2uZ6XmhoKNevX8fa2rrQC/cJUVKk50YI81Po5Mbb25vNmzezYsUKJk2aRJcuXWjevDmLFy822OTS3Kw7vI5Z12cx78K8ErtHTHwMSc5JADzV/qkCv29qv6l0dO0IFvB3xt9899N3hbrvJ7s+ISQ2hKrOVfms22d5nqer2rRp08Zgmw4hTEl6boQwP0XKRvz8/NiyZQt//vknbdq0YfHixVhaWho7tnKlR7MeAKQ7pROfGF8i91i2ZxlYgkWSBQ81eKjA79NoNKz73zrccAN3mLh1Ijt27CjQe09FneLLfV8C8EOfH3CxzXtVSOm3EWWRDEsJYX4KlNy4u7vj4eFh8GjXrh1xcXGsXbsWT09P/evmqklAEzQpGrCALce2lMg9NpzM2l3bJ82n0FUyVztXNjy/AY3SoBoqHp/yuD4ZyUtqRipj144lQ5vBE/WfoH+9/vmeL/02oiyS5EYI81OgXcFnzZpVwmGUfxYWFjgmO5Jgl8Cu4F0M6jjI6Pc4dvMYuEJjj8ZFen97v/Z82PlDpu6aSuLDiXQZ3YVJ/Sfx2WefYWdnuDFlXEocA5cO5OD1g7jYuvDdo/kPZYWFhXHlyhUsLS156KGCV5WEKGnScyOE+SlQcjNixIiSjqNCqGJdhQtc4MT1EyVy/RsWNwDo0aBHka/xXuf32HFlB0FhQfAcfL3zaza03MAfv/1By5YtAbgef53ef/bm1M1TONs4s/LplVR1qZrvdXft2gVAy5YtcXZ2LnJ8Qhib9NwIYX6KNFtq06ZNOV7fvHkz//77r1GCKq/qeWZNhQ+JDzH6tU9ePkmmcyYoGPLwkCJfx9LCkvXPrWdsi7GgAbrAuZbnaPtIWz766CNO3DhB+wXtOXXzFJWcKrFr1C661ez2wOuuXr0aQNY6EmWOrnKTnJxMamqqiaMRQpSGQic3b7/9NpmZmTle12q1vP3220YJqrxq7d8agGiijX7tJXuWAGAbb0s172rFupa9tT0/9f2J3wb8hoOVA9SCzDGZfLj+Q9rOa0t4fDh1Peuyf/R+mlVq9sDrRUREsGrVKgCee+65YsUmhLG5uLjotwiR6o0Q5qHQyc3Fixdp0KBBjtfr1avHpUuXjBJUedW1cVcAUp1SSUlLMeq1d1zcAUB1y+pGu+awpsM4/MJh6nvVBxfgMUi1SKWJexP2Pr8Xfzf/Al1nwYIFZGRk0KFDBxo3Llo/kBAlxcLCAjc3N0CSGyHMRaGTG1dXVy5fvpzj9UuXLuHo6GiUoMqrtvXaQhpgCUEngox67XN3zwHQpqpxN6Ns4N2Aw2MPM6zJsKwXgsF2iS3udu4Fen9mZiY//fQTAP/73/+MGpsQxqLru5GmYiHMQ6GTm/79+zNx4kRCQu71lVy6dInXX3+dfv36GTW48sbK0gqHpKzF63ac2WG066alpxHrkPUbZ78Wxv8aO9o48tvA3zj+7HEc1ztyeP9hFi1aVKD3rl+/nvDwcDw9PXnyySeNHpsQxiDTwYUwL4VObmbMmIGjoyP16tUjICCAgIAA6tevj6enJ1999VVJxFiuVLKsBMDR8KNGu+b6Q+vBFkiDfu1KLoFsGtiUjz78CIC33nqrQD8I5s6dC8CoUaNyTCcXoqyQ5EYI81KgqeDZubq6sm/fPrZs2cKJEyewt7enSZMmsirt/6vtVpvLmZe5dMd4/Uerj2TNRHJNdMXOpmQTiFdeeYVffvmFs2fPMmXKFL7//vs8zw0NDWXjxo0AvPjiiyUalxDFIcmNEOalSNsvaDQaevbsyZtvvsnLL78siU02LWtkrRUTpY0y2jUPXjsIQF2nuka7Zl6sra2ZPXs2AHPmzOH48eN5njtv3jyUUvTs2ZPAwMASj02IopKeGyHMS5GSm507d9K3b18CAwMJDAykX79+7N6929ixlUuPNHoEgGTHZDIyM4xyzSvpVwDoXKt0tjV45JFHePrpp9FqtYwfPx6tVpvjnNTUVH755RdAGolF2SeVGyHMS6GTmz/++IPu3bvj4ODAK6+8wiuvvIK9vT3dunXjr7/+KokYy5VOjTpBBmAN+87sK/b1ImMiSXHJmlb+TMdnin29gpo5cyaOjo7s27ePX3/9NcfxlStXEh0dTdWqVenbt2+pxSVEUUhyI4R5KXRy89lnnzFjxgyWLl2qT26WLl3K9OnT+eSTT0oixnLFxtoGu4Ssvpjtp7YX+3pLdi0BC7BMsKRF7RbFvl5BVatWjSlTpgAwevRohg0bZrCO0Zw5cwAYO3YsVlaFbt0SolRJciOEeSl0cnP58uVcf1Pv168foaGhRgmqvPOx8AHg8NXDxb7WpjNZW11UyqxU7GsV1muvvcbQoUNRSvHHH39Qr149xowZw4YNG9i9ezeWlpaMGTOm1OMSorCk50YI81Lo5MbPz49t27bleH3r1q34+fkZJajyrpZLLQAuxFwo9rVO3MrahLOpV9NiX6uwbGxs+PPPPzly5AiPPfYYmZmZLFiwgMceewzISmirVs1/Q00hygKp3AhhXgo9nvD666/zyiuvcPz4cR566CEA9u7dy6JFi/j222+NHmB51Lxac4KuBRGRGVGk92dkZrBoyyIW7ltIhH3WNR5t9KgxQyyUFi1asG7dOvbv38+UKVP0ye348eNNFpMQhSHJjRDmpdDJzbhx46hUqRIzZ87k77//BqB+/fosXbqU/v37Gz3A8qhzw858fe1rEu0T0Wq1WFg8uECm1Wr5dOmn/HH0Dy5ZXEI5KLAELMEi0YIhnYu+E7ixtG/fnq1bt7J3717u3LlDt24P3i1ciLIge3KjlNJvpCmEqJg0Sill6iBKU3x8PK6ursTFxeHi4lIi90hITsB5mjNYwqFnDtG6busHvmfmypm8ceqNey+kgl+KH4/VfozJAyYTUDmgRGIVwhzo/t8DJCYm4uDgYOKIhBCFVZif34XuualZsya3b9/O8fqdO3eoWbNmYS9XITnZO2GTYAPAtpM5+5Nys+TIEgBcYl2Y0WgGd6fcJezrMOaMmyOJjRDF5OzsjKWlJSBDU0KYg0InN1euXCEzMzPH66mpqVy/ft0oQVUEXngBcCj0UIHOP5t0FoBn6z3Lm4PexMneqcRiE8LcaDQa6bsRwowUuOdmzZo1+o83bdqkL/ECZGZmsm3bNvz9/Y0aXHlW07kmN7hB8K3gB557NeoqSS5JAIzpJlOrhSgJ7u7u3Lp1S5IbIcxAgZObAQMGAFm/AY0YMcLgmLW1Nf7+/sycOdOowZVnTSo3YU/UHm6k3XjguT9t/gkswDreulQX6hPCnEjlRgjzUeBhKa1Wi1arpXr16ty8eVP/XKvVkpqayvnz53n88cdLMtZy5eH6WZuJ3rW7m+veTNn9e/ZfAGpZ1irxuIQwV7KQnxDmo9A9N6GhoXh5eZVELBVKj+Y9QIGyVwSH5T80dS7lXNZ7AnuURmhCmCWp3AhhPgqc3Ozfv59169YZvPbbb78REBCAj48PL7zwAqmpqUYPsLzycPHA6m7WqN+W41vyPC/kRgjJrskAjOku/TZClBRJboQwHwVObj7++GPOnDmjf37q1ClGjx5N9+7defvtt1m7di3Tpk0rkSDLKw9tVhn8YMjBPM/5afNPoAGbOBua1GxSWqEJYXYkuRHCfBQ4uTl+/LjBirRLliyhbdu2zJ8/n0mTJvHdd9/pVywWWfwd/QE4E30mz3M2ntsIQB3rOqURkhBmS3puhDAfBU5uYmNj8fX11T/fuXMnvXv31j9v3bo14eHhxo2unGtSOasScy3lWp7nnE87D0DPOj1LJSYhzJVUboQwHwVObnx9fQkNDQUgLS2No0eP0q5dO/3xu3fvYm1tbfwIy7GHamdtLBpnE5fr8eCwYFJds/qUxvSQfhshSpIkN0KYjwInN3369OHtt99m9+7dvPPOOzg4ONCpUyf98ZMnT1Krlkxlzq5Xy14AaB21hNwIyXH85y0/A2AbZ0v96vVLNTYhzI0kN0KYjwInN5988glWVlZ07tyZ+fPnM3/+fGxsbPTHf/nlF3r2lKGV7Kp4VsEmLutr9OyPz+Y4vvnCZgDq2tQt1biEMEfScyOE+SjwCsVeXl7s2rWLuLg4nJyc9JvQ6SxbtgwnJ9kP6X6Tm0/m08ufctDyIMt3L+fJTk/qj11IvwDAo/UeNVV4QpiN7JUbpRQajcbEEQkhSkqhF/FzdXXNkdhA1m9F2Ss5Issnwz6halxVsICRK0eSlp4GwMnLJ0lzTQMFL/R8wcRRClHx6ZKbjIwMEhMTTRyNEKIkFTq5EYW3ZtwaSIVEt0SenZU1PPXz1qx+G/s4e2pVkV4lIUqag4ODftKD9N0IUbFJclMKWtRuwWDPwQAsj13O4fOH2XppKwD17aWRWIjSoNFopO9GCDMhyU0p+WPiHzjFOoEt9J/bn0uZlwB4tL702whRWmTGlBDmQZKbUmJlacVvT/0GmRDhFkG6Szpopd9GiNLk6uoKQHx8vIkjEUKUpALPllqzZk2BzuvXr1+Rg6noBnYYSPuN7dnPfgAc4h2o4VvDxFEJYT6cnZ0BSW6EqOgKnNwMGDDggedoNBoyMzOLE0+Ft+7Ndfh+5EuGSwYNHBqYOhwhzIouubl7966JIxFClKQCD0tptdoHPiSxeTAPFw+WDFxCvcR6LBi9wNThCGFWXFxcAEluhKjoCly5EcYzqOMgBnUcZOowhDA7UrkRwjwUOLnZtWtXgc57+OGHixyMEEKUJOm5EcI8FDi56dKli365cqVUrucUtefmhx9+4MsvvyQyMpKmTZsye/Zs2rRp88D3LVmyhCFDhtC/f39WrVpV6PsKIcyLVG6EMA8F7rlxd3fHz8+PKVOmcPHiRWJjY3M8irIw1tKlS5k0aRJTp07l6NGjNG3alF69enHz5s1833flyhXeeOMNg53JhRAiP9JzI4R5KHByExERwRdffMH+/ftp3Lgxo0ePZt++fbi4uODq6qp/FNbXX3/N2LFjGTVqFA0aNGDu3Lk4ODjwyy+/5PmezMxMnn32WT766CNq1qxZ6HsKIcyTVG6EMA8FTm5sbGwYPHgwmzZt4ty5czRp0oSXX34ZPz8/3nvvPTIyMgp987S0NI4cOUL37t3vBWRhQffu3dm/f3+e7/v444/x8fFh9OjRhb6nEMJ8Sc+NEOahSCsUV69enQ8++ICtW7dSp04dpk+fXqRvFrdu3SIzMxNfX1+D1319fYmMjMz1PXv27GHBggXMnz+/QPdITU0lPj7e4CGEME9SuRHCPBQ6uUlNTeWvv/6ie/fuNGrUCC8vL9avX6/fkK4k3b17l2HDhjF//ny8vLwK9J5p06YZDJv5+fmVcJRCiLJKem6EMA8Fni116NAhFi5cyJIlS/D392fUqFH8/fffxUpqvLy8sLS0JCoqyuD1qKgoKlWqlOP8kJAQrly5Qt++ffWvabVaAKysrDh//jy1atUyeM8777zDpEmT9M/j4+MlwRHCTEnlRgjzUODkpl27dlSvXp1XXnmFli1bAllDRPcrzN5SNjY2tGzZkm3btum3d9BqtWzbto2XX345x/n16tXj1KlTBq+9//773L17l2+//TbXpMXW1hZbW9sCxySEqLiyJzdKKf3yFkKIiqVQKxSHhYXxySef5Hm8KOvcTJo0iREjRtCqVSvatGnDrFmzSExMZNSoUQAMHz6cqlWrMm3aNOzs7GjUqJHB+93c3AByvC6EEPfTJTfp6emkpqZiZ2dn4oiEECWhwMmNbvjH2AYPHkx0dDQffPABkZGRNGvWjI0bN+qbjMPCwrCwKFLfsxBCGHByctJ/fPfuXUluKqjp06fz999/8++//+aYsCLMg0bltdxwBRUfH4+rqytxcXH65kIhhPlwcnIiMTGRkJAQWSerAlJKUblyZaKiovjhhx946aWXTB2SMJLC/PwudElk2bJlPPHEEzRq1IhGjRrxxBNPsHz58iIHK4QQpUmaiiu269ev6yep5NYXKsxDgZMbrVbL4MGDGTx4MGfPniUwMJDAwEDOnDnD4MGDeeaZZ/Lcc0oIIcoKWcivYvvvv//0H+/du9ckMWzZsoU///xTfiaaUIF7br799lu2bt3KmjVrePzxxw2OrVmzhlGjRvHtt98yceJEY8cohBBGI5Wbiu3w4cP6j8PCwggLC6N69eqldv/ExET69+9PcnIymZmZDB8+vNTuLe4pcOVm4cKFfPnllzkSG8ia/j1jxox894MSQoiyQBbyq9iyV26g9Ks3u3btIjk5GYCXXnqJCxculOr9RZYCJzcXL1402APqft27d+fixYtGCUoIIUqKVG4qLqWUPrnp2LEjUPrJzebNm4GspVESExN55plnSE1NLdUYRCGSG3t7e+7cuZPn8fj4eJlWKYQo8yS5qbhCQ0OJiYnBxsaGcePGAaXfVKxLbr755hs8PT05duwY77zzTqnGIAqR3LRv3545c+bkefyHH36gffv2RglKCCFKijQU35OSksLgwYOpVatWnpsVlye6qk3Tpk3p2rUrACdPniQuLq5U7n/t2jXOnj2LhYUFw4YNY+HChUBWorNhw4ZSiUFkKXBy895777FgwQKefvppDh06RHx8PHFxcRw4cICnnnqKX375hffee68kYxVCiGKTnpssycnJDBgwgL///pvLly/rfxCXZ7rkplWrVlSuXJmaNWuilOLAgQOlcn9d1aZ169Z4eHjQt29fJkyYAMDIkSOJiIgolThEIZKbhx56iKVLlxIUFET79u1xd3fHw8ODDh06EBQUxOLFi+nQoUNJxiqEEMUmw1KQlJRE//792bRpk/6133//vdxPXdbNlGrVqhVwr++mtIamdMlNz5499a/NmDGDpk2bEh0dzbBhw0pstX9hqFCL+A0cOJCrV6+yfPlypk2bxrRp01ixYgVhYWEMGjSopGIUQgijMffkJjExkb59+7JlyxYcHR1Zu3YtdnZ2BAcHc/ToUVOHV2RarZYjR44AWZUTQP8Ld37JzfHjxwkNDS32/TMzM9myZQsAvXr10r9uZ2fHkiVLcHBwYNu2bfz666/Fvpd4sEKvUOzg4MDAgQOZPHkykydPZsCAATg4OJREbEIIYXTm3HOTkJDA448/zvbt23FycmLTpk08/vjj9O/fH8iq3pRXFy9e5O7du9jb21O/fn3gXuXm4MGDpKen53jPoUOHaNmyJXXq1OHNN98sVsJ77NgxYmJicHFxoU2bNgbH6tWrxwcffADAd999V+4rZOVBgZOb7du306BBg1y/IcTFxdGwYUN2795t1OCEEMLYzLVyk5mZyeOPP86OHTtwdnZm8+bN+srGsGHDAFi8eHGuSUB5oBuSat68OVZWWevT1qtXD3d3d5KTkzl27FiO93z++edotVoyMjL46quvqFevHkuXLi1S8qEbknrkkUewtrbOcXzs2LHY2dlx/PjxUusBMmcFTm5mzZrF2LFjc92sytXVlRdffJGvv/7aqMEJIYSxmWtDcVBQEDt37sTJyYktW7YYzG7t2bMn3t7e3Lx5U/9DurzRNRPrhqQALCws8hyaOn36NKtXr0aj0fDDDz9Qq1Ytbty4wTPPPEP37t0JDg4u1P1z67fJzsPDgyFDhgBZs4tFySpwcnPixAkeffTRPI/37NlTP94phBBllblWblavXg3A4MGDadu2rcExa2trhg4dCpTfoansM6Wyy2sxv+nTpwPwxBNP8NJLL3H69Gk+/vhj7Ozs2L59O82aNSvwqvt3797VXz+v5AbQ71C+bNkybt68WaBri6IpcHITFRWVa6lNx8rKiujoaKMEJYQQJcUce26UUqxZswZA319zP93Q1OrVq0ttXRhjycjI0DdD35/cZK/c6IabLl++zJIlSwD0C+zZ2dkxZcoUzp49S+/evUlLS2P06NG8+uqrZGRk5Hv/HTt2kJGRQa1atahVq1ae57Vq1Yo2bdqQlpbGggULivbJigIpcHJTtWpVTp8+nefxkydPUrlyZaMEJYQQJcUcKzcnTpwgLCwMe3t7unXrlus5LVq0oH79+qSkpLBixYpSjrB4goODSU5OxtnZmTp16hgca9WqFTY2Nty8eZNLly4B8OWXX5KZmUmvXr1o2bKlwfkBAQGsW7eODz/8EMhqAH700Ue5fft2nvd/0JBUdrrqzdy5c8nMzCzw5ygKp8DJTZ8+fZgyZQopKSk5jiUnJzN16tRcN9UUQoiyRNdzk5yc/MDfyCsKXdWmZ8+eec5u1Wg0+upNeRua0g1JtWzZEgsLwx9rdnZ2+j6cvXv3EhERoR9uymtbBAsLC6ZOncrKlStxdHRk27ZttGnThjNnzuR6fmGSm8GDB+Ph4UFYWBjr168v2CcoCq3Ayc37779PTEwMderUYcaMGaxevZrVq1fzxRdfULduXWJiYmSFYiFEmaer3EDW1GhzoOu36devX77nPfvss0DWMMvVq1dLPC5juX/xvvtlH5r65ptvSEtL46GHHuLhhx/O97oDBw5k//79BAQEcPnyZdq1a8cff/xhMJvqypUrXLhwAUtLS/2WD/mxs7Nj9OjRAPz4448F+vxEEahCuHLliurdu7eysLBQGo1GaTQaZWFhoXr37q0uX75cmEuZTFxcnAJUXFycqUMRQpiIjY2NAlRYWJipQylx4eHhClAajUZFRUU98PyuXbsqQH322WelEJ1xtG7dWgFq6dKluR5fs2aNAlT16tWVk5OTAtS6desKfP1bt26pRx55RAEKUIMGDVLR0dFKKaXmzZunANWhQ4cCX+/y5ctKo9EoQF24cKHA7zN3hfn5XahF/GrUqMGGDRu4desWBw8e5MCBA9y6dYsNGzYQEBBgzJxLCCFKjDk1Fa9duxbI2vzYx8fngednH5pS5WCxubS0NE6cOAHkXbl56KGHAAgLCyMhIYEmTZrQp0+fAt/D09OTTZs28cknn2BlZcWKFSto1KgRa9eu1Q9JZV+V+EECAgL09587d26B3ycKrtArFAO4u7vTunVr2rRpg7u7u7FjEkKIEmVOTcW6Iam8Zkndb9CgQdjZ2XHu3LlysbzHqVOnSEtLw8PDI89fsj09PfWrFgO8++67aDSaQt3HysqK999/n4MHD9KgQQOioqLo168fq1atAgrWb5OdrrH4l19+ISkpqVDvFQ9WpORGCCHKM3NZyC8+Pp7t27cDD+630XFxcWHAgAFA1nosZV329W3yS1h0690EBgby5JNPFvl+LVq04MiRI7z++utoNBoyMzNxc3PLs2qUl0cffZSAgADu3Lmjn5YujEeSGyGE2TGXys2mTZtIT0+nTp061KtXr8Dv0y3Yum/fvpIKzWjyWrzvfuPHj6d169b8+OOPWFpaFuuednZ2fPXVV+zYsYN27drx/vvvF/qaFhYWvPjiiwAsX768WPGInKxMHYAQQpQ2c+m50U0BL2jVRqddu3ZAVuKQnp6e7wKupvagmVI6TZs25dChQ0a998MPP8z+/fuL/P6mTZsCcOPGDWOFJP6fVG6EEGbHHCo36enp+nVUCtpvo1O7dm3c3d1JSUnRN+vmJSIiggsXLhQ5zuJITk7WLy6bfU+p8kLX4C2r+xufJDdCCLNjDj03e/fuJTY2Fi8vL4NNMgvCwsJCX73JbwdrpRRdunShWbNmREZGFiveojh48CCZmZlUqVKFqlWrlvr9i8vb2xuAmzdvlouZaeWJJDdCCLNjDpUb3Sypxx9/vEg9JgVJbk6fPs2FCxdITk7m5MmTRQu0GHbs2AFA586dCz37qSzQJTcZGRncuXPHtMFUMJLcCCHMTkVPbpRSBV6VOC+65Ca/npKtW7fqPw4JCSnSfYpj586dQFZyUx7Z2dnp/y3K0JRxSXIjhDA7Fb2h+MyZM4SGhmJra1vo9Vd02rRpA2TtoH3z5s1cz8me3Og2pSwtKSkp+sSrS5cupXpvY9L13eT1NRZFI8mNEMLsVPSeG92qud26dcPR0bFI13Bzc6NBgwZAVm/L/dLT0/WVEyj9ys2hQ4dITU3F19c3x07g5Yk0FZcMSW6EEGanog9LXbx4EYDmzZsX6zr59d0cPHiQxMRE/fPSrtzo+m26dOlSLvttdLI3FQvjkeRGCGF2Knpyo6ui1KpVq1jXya/vRjck1bJlSyBr+Eqr1RbrfoVR3vttdGRYqmRIciOEMDsVvefm8uXLANSsWbNY19ElN4cOHSIzM9PgmC65GT16NJaWliQnJxMREVGs+xVUamqqfvXk8txvA/cqNzIsZVyS3AghzI4xKzdKKUJDQ8vMOiUZGRlcvXoVKH7lpkGDBjg7O5OYmMiZM2f0r9+9e1ffh9O7d29q1KgBlF7fzeHDh0lJScHHx6dQ20qURVK5KRmS3AghzI4xG4pnzpxJzZo1+f3334t9LWMIDw8nIyMDW1tbqlSpUqxrWVpa6mdNZR+a2rVrFxkZGdSqVQt/f38CAwOB0uu7Ke/r22QnDcUlQ5IbIYTZyV65KW7FRbd4XXH2GDImXfUkICAAC4vif4vPralYNyTVrVs3AH1yU1qVm4rSbwPSUFxSJLkRQpgdXXKjlDKY8VMUur6dK1euFDcsozBWv42ObuuG3JKb7t27A/eGv0qjcpOWlsbevXuB8t9vAzIsVVJkV3AhhNlxcHDAwsICrVbL3bt3cXJyKvK14uLigLKT3BhrppRO27ZtATh37hwxMTGkpaVx+vRpNBoNXbt2BUq3cvPff/+RnJyMl5eXfh2e8kxXubl16xZardYo1TYhlRshhBnSaDRGayrOXrkpC03Fxq7ceHl56ZOXQ4cOsX37diBrDR0vLy/AsHJT0l8D3ZDUww8/XO77bQD911Cr1RITE2PiaCoOSW6EEGbJWMmNrnKTkpJCVFRUseMqLmNXbsCw7+b+ISm4l0jFxcWV+A/o7Iv3VQQ2Nja4u7sDMjRlTJLcCCHMkrGTGzD90JRSSp/cGKtyA/f6bvbv359rcmNvb0/VqlWBku27SU9P1/fbVIRmYh1Z68b4JLkRQpglYy3kl/39pk5uYmJi9PEEBAQY7bq6yk1QUBDh4eHY2NjQoUMHg3NKo+/myJEjJCYm4uHhQaNGjUrsPqWtOE3FFy9eJD093dghlXuS3AghzJIx1rpJSUkhLS1N/zw0NLTYcRWHrt+mcuXKODg4GO26jRs3xt7eXv9DtEOHDjmuXxozprL321SkxtuirnXz999/U6dOHT788MMSiKp8qzj/OoQQohCMMSx1f9XH1JWbkhiSArC2tqZVq1b659mHpHRKo3JT0fptdIq61s1vv/0GwNq1a40eU3knyY0QwiwZI7nJ3m8Dpk9udJUbYzYT6+j6biD35KakKzcZGRns2bMHqFj9NlC0YamkpCS2bdsGwJkzZ0hISCiR2MorSW6EEGbJGD03ZS25KanKDdzru3F1ddXvBJ5dSVdujhw5QkJCAu7u7jRp0qRE7mEqRWko3rZtGykpKUDWNPL//vuvRGIrryS5EUKYJWMOSzk6OgJZyY1Wqy1+cEVUkpWbxx57jDFjxvDdd99haWmZ47junlFRUUbZsyu7sLAwhg8fDkDXrl0rVL8NFK1yc/9QlG4jU5GlYv0LEUKIAjJGQ7GuctOgQQMsLCxIS0sjMjLSKPEVhbEX8MvOxsaG+fPn65OM+7m6uuoXpNPFYQwXL16kY8eOXLhwgRo1avDll18a7dplRWEbipVSrFu3Drg3RCjJjSFJboQQZsmYlRtPT0/8/PwA0w1NpaamEh4eDpRM5aYgjN13c/LkSTp16kR4eDh16tRh9+7dJZK4mVphG4qPHj1KREQEjo6OvPXWW0DWAotlYYXsskKSGyGEWTJmz42Liwv+/v5AySY34eHh3LhxI9djV69eRSmFo6OjvhJQ2ozZd3Pw4EG6dOlCVFQUTZs2Zffu3foEsqLR/X3dvn2bjIyMB56vq9r07NmThx56CEtLSyIiIrh27VqJxlmeSHIjhDBLxpwt5erqqk9uSmqtmxs3btC4cWNatmypbyTNLnszsan2XDJW5WbPnj10796d2NhY2rdvT1BQkMkSttLg6emp/zu7ffv2A8/X9ds8/vjjODg46BusZWjqHkluhBBmyRg9N7qqj6urq35F4MJWbiIiIvjzzz8fuMrs9OnTiYuLIzIyUr+YXXYl2W9TUMao3CilePHFF0lISKBbt25s3rxZv/dSRWVpaYmnpyfw4KGpGzducOTIESCryRvu7dwuyc09ktwIIcySMSs3xRmWmjx5Ms899xzvvPNOnudcu3aNefPm6Z+vX78+xzklsWFmYRmjcrN582bOnj2Ls7MzK1aswMnJyVjhlWkFnTGl+7tv06YNvr6+gOHGpiKLJDdCCLNkzIbi7MNShU1udL+Fz5o1i5MnT+Z6zrRp00hLS9NXMNavX5+jebQsVW7Cw8NJTU0t0jVmzZoFwOjRo3F1dTVWaGVeQde60fXb9O3bV/+arnJz5MgR2Wfq/0lyI4QwSyXVUHz16lUyMzML9P709HQuXrwIQGZmJuPGjcuxTk5YWBjz588H4Pfff8fGxobLly9z4cIFg/PKQuXG29sbJycnlFJF6j0KDg5m48aNaDQaJkyYUAIRll0FqdwkJyezZcsWIKvfRqdOnTq4urqSnJzM6dOnSzbQckKSGyGEWdIlN+np6UWuMmSv3FStWhUrKyvS09OJiIgo0PtDQkLIyMjA3t4eR0dH9u3bx8KFCw3O+eyzz0hPT+eRRx7hscce0289kH1oSilVJio3Go2mWH03uqrNgAEDKuSU7/wUpHITFBREcnIy1apVo2nTpvrXLSwsaNOmDSB9NzplIrn54Ycf8Pf3x87OjrZt23Lo0KE8z50/fz6dOnXC3d0dd3d3unfvnu/5QgiRG11yA0Ufmso+W8rKyqrQa90EBwcDWYsAfvTRR0BWD86tW7eArJlXv/zyC4D+eJ8+fQDYsGGD/jpRUVEkJSWh0Wj0FSRTKWrfze3bt/UbQU6cONHYYZV5BancZJ8ldf+MOF3fjSQ3WUye3CxdupRJkyYxdepUjh49StOmTenVq1eef8E7duxgyJAhBAUFsX//fvz8/OjZsyfXr18v5ciFEOWZpaUlDg4OQPGTG93Mq8L23eiSm/r16/PKK6/QuHFjYmJi9AuzffbZZ2RkZNCjRw86duwI3Jshs2vXLn3cuqqNn58fNjY2RfpcjKWolZt58+aRkpJCixYt6NSpU0mEVqY9KLnJvipx9n4bHV3fjTQVZzF5cvP1118zduxYRo0aRYMGDZg7dy4ODg7631bu9+eff/LSSy/RrFkz6tWrx88//4xWq9XvjiqEEAVV3L6b7MNSQKHXusme3FhbWzNnzhwAfvnlF3777TcWLVoE3KvaANSuXZvAwEDS09PZunUrUDb6bXSKUrlJS0vjhx9+ALKqNqZap8eUHjQsdeLECa5du4aDgwOPPPJIjuO6Yalz585x586dEouzvDBpcpOWlsaRI0f0e2NA1thh9+7d2b9/f4GukZSURHp6Oh4eHiUVphCigirOjCmtVqt/n65yU9i1brInNwAdOnRg9OjRAIwYMYLMzEx69+5N+/btDd6nq97o+m7KQr+NTlEqN8uWLePGjRtUrlyZwYMHl1RoZdqDKjfZ95Kys7PLcdzb21v/93/48OESirL8MGlyc+vWLTIzM/Vz9XV8fX0LvPncW2+9RZUqVQwSpOxSU1OJj483eAghBBRvIb+EhAT9dOz7KzcFSW6UUpw7dw64l9wAfPHFF/oF3QA+/PDDHO/VJTcbNmxAKVUmKzehoaEFmjWmlOKbb74BYPz48SYfVjOVB1VuNm3aBBjOkrqf9N3cY/JhqeKYPn06S5Ys4Z9//sk1k4Ws9SFcXV31j4q6N4kQovCKU7nR9dvY2Njov/8UJrm5du0aiYmJWFlZGSQlnp6efP311wA88cQT+uGG7B5++GEcHR2JiIjg+PHjZapyU61aNWxtbUlPT9dv5AlZlfqTJ08SEhJisBbL3r17OXLkCHZ2drz44oumCLlM0FVu7ty5Q1pamsGx9PR0/vvvPyDr7z4vslLxPVamvLmXlxeWlpZERUUZvB4VFUWlSpXyfe9XX33F9OnT2bp1q35fjdy88847TJo0Sf88Pj5eEhwhBGCc5EZX/YF7w1JhYWFkZmZiaWmZ5/t1Q1KBgYFYW1sbHBs+fDitW7fOc+aTra0t3bt3Z/Xq1axfv75MVW4sLCyoWbMmwcHBzJs3j+TkZA4ePMixY8f0U+4tLCyoVq0aAQEB+u//w4YNw8vLy5Shm5S7uzuWlpZkZmYSHR1N1apV9cdOnz5NSkoKrq6u1K5dO89rZG8qVkqZZe+SjkkrNzY2NrRs2dKgGVjXHHz/GHN2M2bM4JNPPmHjxo20atUq33vY2tri4uJi8BBCCCheQ/H9zcQAlStXxtramoyMjAfO4Ly/3+Z+9evXx97ePs/366aEL1u2TD+MXxYqN3AvyZo+fTrffvstBw4cIDU1FVdXV+zs7NBqtYSFhbFz50790Nyrr75qypBNzsLCQp/c3T80pavEtGnTBguLvH9sN2vWDBsbG27dulViG7iWFyat3ABMmjSJESNG0KpVK9q0acOsWbNITExk1KhRQNZvMFWrVmXatGlA1nj0Bx98wF9//YW/v7/+P7WTk5PZ7EEihDCO4vTc5Fa5sbS0pHr16oSEhHDlyhWqV6+e5/sflNw8iC650W3Z4ObmVmYmVgwdOpQDBw4QEBBA27Zt9Q9ds3FUVBShoaH6R7169WjYsKGJozY9Hx8foqKicjQV65IbXWUmL7a2tjRr1oxDhw5x8ODBMpPsmoLJk5vBgwcTHR3NBx98QGRkJM2aNWPjxo36JuOwsDCDTHXOnDmkpaXx5JNPGlxn6tSpuTbeCSFEXoozLJVb5Qay+m50yU1+/RHFTW6qVatGkyZN9MlNWfpBNmTIEIYMGZLn8UqVKlGpUqV8K/TmSNdUXNTkBrKainXJje7vQKvVEhsbS1JSEg4ODjg4OGBnZ1ehh61MntwAvPzyy7z88su5HtuxY4fB88JuSieEEHkxds8N3Ou7edCwQHGTG8iaNaVLbspCv40oHl1TcfZhqbi4OP3QXW7N5ffTJUC//fYbQUFB3Lx5k+jo6Bwz1ywsLHBwcMDZ2Rk/Pz8CAgIMHg899BCOjo7G+tRKXZlIboQQwhTy67lZtmwZAQEBefb1Zd96IbuCzJi6ffu2/gdY3bp1Cxu2Xp8+ffRD9mWpciOKJre1bv777z+UUvj7++uP56djx45YWloSGxtLbGyswTEbGxv9TCytVktCQgIJCQlERETk2MaoU6dO7Nq1q7ifkslIciOEMFt5VW727NnD008/TZ06dTh//nyu781vWAryT250v4n7+fkVq1ewXbt2uLu7ExsbK5WbCiC3tW4KMyQFUL16dXbs2MGVK1fw8fHRP7y8vLCxsSEjI4OkpCQSExNJTEwkLi6OsLAwgx6oDRs2sHv3bq5fv24wa6s8keRGCGG28mooXrlyJZA1tJTXlNq8hqUKktwYY0gKwMrKismTJ/Pzzz/Tu3fvYl1LmF5ulRtdRaWgyQ1kVW90e5Hdz8rKKsfM4ZYtWxqc0759ew4cOMCGDRsYO3Zsge9blpTrRfyEEKI4cqvcKKVYtWoVkLV42v2lfZ28Kje6npvw8HAyMjJyfa+xkhuAt99+m0uXLlGtWrViX0uY1v0NxUopg2ngpUW3CrJuy4fySJIbIYTZyq3n5vTp0wbNwHnt9ZNX5aZSpUrY2NiQmZnJtWvXcn2vMZMbUXHc31AcHh5OZGQkVlZWtGjRotTi0G3vsXXrVlJSUkrtvsYkyY0QwmzlVrnRVW107l9BXSevhmILCwtq1KgB5D00JcmNyM39w1K6qk2TJk3yXdDR2Jo2bUrVqlVJSkrKMWO5vJDkRghhtnLruSlocpPXsBTkvzt4UlISV69eBSS5EYZ0w1IJCQkkJyfr+21Kc0gKQKPRlPuhKUluhBBmS1e5SUpKIjMzk/DwcI4ePYpGo6Fz587Agys3uW3pkl9T8YULF1BK4eHhYdZ7KYmcXF1d9fuMRUdHF3qmlDHphqbWr1+PUqrU719cktwIIcyWLrmBrN+WV69eDUCHDh1o1KgRULTKjS65yW0hv+xDUhV5hVhReBqNRj80dePGDY4cOQKYJrnp1q0bdnZ2XLlyhbNnz5b6/YtLkhshhNmytbXV/6YcHx+vH5Lq37+/fguY4lRuzpw5k+O3Xum3EfnRDU0FBQWRlJSEi4tLsRZ6LCoHBwe6du0KZFVvyhtJboQQZk2XnISHh7Nz507AMLnJbbZUamoqqampQO6Vmw4dOmBjY8ORI0f01SAdSW5EfnSVG12vS+vWrfPdCbwklee+G0luhBBmTTc0tXTpUjIyMmjQoAG1a9fW/5DJrXKTfep49qEtnerVq/P6668DMHHiRJKSkvTHJLkR+dFVbvbv3w+YZkhKR9d3s2/fPmJiYkwWR1FIciOEMGu65GTx4sUADBgwACDfYSndkJSTkxOWlpa5Xve9997Dz8+Pq1evMn36dAAyMjK4cOECIMmNyJ0uqdYNZ5oyualRowaNGjUiMzOTTZs2mSyOopDkRghh1nTJjW7htP79+wOGyc39fTP5NRPrODo68vXXXwMwY8YMQkJCCA0NJT09HXt7e6pXr27cT0RUCPdvjlna08Dvp6velLehKUluhBBmLfuwUpUqVfS7gOuSm+TkZBISEgzek18zcXaDBg2ie/fupKam8uqrr+qHpOrWrWuyPgpRtumGpSBreLNSpUomjOZe383GjRvz3E6kLJL/XUIIs5Y9Qenfv78+6XB0dMTR0RHIOTRVkMoNZE3tnT17NtbW1qxfv15fyZEhKZGX7JUbUw5J6eh2no+JieHAgQOmDqfAJLkRQpi17JUb3ZCUTl59NwWt3ADUq1eP1157DUA/G0uSG5GX7JWbspDcWFlZ6XecL09TwiW5EUKYNV1y4+Liol/XQyev6eB57SuVlylTplC1alX9c0luRF7KWuUGymffjSQ3Qgizpvth0qdPH2xsbHI9VtRhKR0nJydmzpypfy7JjchL5cqVcXR0xNnZuVR3As/Po48+ioWFBadPnyYkJMTU4RSIlakDEEIIU3rxxRdJSUlh3LhxOY4ZY1hK5+mnn+bAgQPEx8dLciPyZG9vz65du7C0tMTBwcHU4QDg4eFB9+7d2bx5MwsWLODzzz83dUgPJJUbIYRZ8/T05OOPP6Zy5co5juWV3BS2cgNZzcXffPMNCxYskJlSIl8tWrSgadOmpg7DwAsvvADAL7/8Qnp6uomjeTD5HyaEEHkwZuVGiPKsX79+VKpUiaioqBxbipRFktwIIUQeHpTcFKZyI0R5Zm1tzfPPPw/AvHnzTBzNg0lyI4QQechrtlRRhqWEKO/Gjh2LRqNh69atZb6xWBqK85CZmVkuxhWFECXHy8uLGjVqYGNjQ0pKiv51BwcHatSogZubm8HrpcHa2jrP/ayEKEn+/v706tWLjRs3Mn/+fP2eaWWRRt2/aUoFFx8fj6urK3FxcbmOlyuliIyM5M6dO6UfnBCiTNFqtYSHhwNZS+FrNBoArl27RmZmJpUqVcLW1rbU43Jzc6NSpUr6eIQoLatWrWLgwIH4+PgQHh6eY/mEkvSgn9/ZSeXmPrrExsfHBwcHB/nmIYQZU0qRkpKCUopq1arpv5EnJyej1WoJCAgo1eRGKUVSUpJ+mCy3GV5ClKTHHnuMypUrExERwapVq3j66adNHVKuJLnJJjMzU5/YeHp6mjocIUQZYG1tTVpaGpaWltjZ2aGUQqvVAlnDU9bW1qUaj729PZDVB+Tj4yNDVKJUWVtbM3r0aD799FPmzZtXZpMbaSjORtdjU1YWThJCmJ6VVdbvgLrvD7rEBjDZejW671HSFyhMYcyYMWg0GrZv387FixdNHU6uJLnJhQxFCSF0dJUZXSKRmZkJZH2fMFVyI9+jhCnVqFFDv5nm/PnzTRxN7iS5EWXehx9+SLNmzQr1ni5dujBx4kSTx1Fa/P39mTVrVqncqyS+tmWZLrnJyMgA7iU3lpaWkmQIs/Xiiy8CsHDhQlJTU00cTU6S3FQgkZGRTJgwgZo1a2Jra4ufnx99+/Zl27ZtBuft27ePPn364O7ujp2dHY0bN+brr7/Wf9PW0Wg0aDQaDhw4YPB6amoqnp6eaDQaduzYYXD+qlWrjP55vfHGGzk+hwdZuXIln3zyidFjeZB//vmHdu3a4erqirOzMw0bNjRIBMpyglRQpvramsr9w1LZkxshzFWfPn2oWrUqt27d4q+//jJ1ODlIclNBXLlyhZYtW7J9+3a+/PJLTp06xcaNG+natSvjx4/Xn/fPP//QuXNnqlWrRlBQEOfOnePVV1/l008/5ZlnnuH+lQH8/PxYuHChwWv//PMPTk5OJf45KaXIyMjAycmp0A3eHh4eODs7l1Bkudu2bRuDBw9m0KBBHDp0iCNHjvDZZ59VmL6ItLQ0wDRfW1PKa1hKkhthzqysrJgwYQIAkyZN0i+ZUGYoMxMXF6cAFRcXl+NYcnKyOnv2rEpOTjZBZMXTu3dvVbVqVZWQkJDjWGxsrFJKqYSEBOXp6ameeOKJHOesWbNGAWrJkiX61wD1/vvvKxcXF5WUlKR/vUePHmrKlCkKUEFBQQbn//PPP3nGmJKSoiZMmKC8vb2Vra2t6tChgzp06JD+eFBQkALUhg0bVIsWLZS1tbUKCgpSU6dOVU2bNtWfl56eriZMmKBcXV2Vh4eHmjx5sho+fLjq37+//pzOnTurV199Vf+8Ro0a6rPPPlOjRo1STk5Oys/PT82bN88gvsmTJ6vatWsre3t7FRAQoN5//32VlpamP35/HPd79dVXVZcuXfI8vnDhQgUYPBYuXKiUUurq1auqX79+ytHRUTk7O6unnnpKRUZGGrx/zZo1qlWrVsrW1lZ5enqqAQMGGHx+33zzjf75/Pnzlaurq9q6dWuesbi6uqp//vlHBQYGKltbW9WzZ08VFhaW4/OdP3++8vf3VxqNRimV82ubkpKiJk+erKpVq6ZsbGxUrVq11M8//6w/furUKfXoo48qR0dH5ePjo5577jkVHR2tP75s2TLVqFEjZWdnpzw8PFS3bt1y/XdsKrdu3VKHDx9W586dU0opdfv2bXX48GEVHBxsspjK8/cqUXGkpaWpNm3aKEB16dJFZWZmluj98vv5fT+p3DyAUorExESTPFQB11eMiYlh48aNjB8/HkdHxxzH3dzcANi8eTO3b9/mjTfeyHFO3759qVOnDosXLzZ4vWXLlvj7+7NixQoAwsLC2LVrF8OGDSvkVxImT57MihUr+PXXXzl69CiBgYH06tWLmJgYg/Pefvttpk+fTnBwME2aNMlxnS+++II///yThQsXsnfvXuLj4ws0HDZz5kxatWrFsWPHeOmllxg3bhznz5/XH3d2dmbRokWcPXuWb7/9lvnz5/PNN98U+POrVKkSZ86c4fTp07keHzx4MK+//joNGzYkIiKCiIgIBg8ejFarpX///sTExLBz5062bNnC5cuXGTx4sP6969evZ+DAgfTp04djx46xbds22rRpk+t9ZsyYwdtvv83mzZvp1q1bnvEmJSXx2Wef8dtvv7F3717u3LnDM888Y3DOpUuXWLFiBStXruT48eO5Xmf48OEsXryY7777juDgYObNm6ev7N25c4dHHnmE5s2b899//7Fx40aioqL000cjIiIYMmQIzz//PMHBwezYsYMnnniiwP/2S4NUboTInbW1NX/++SeOjo7s2LGDmTNnmjqke0o0zSqDClu5SUhIyPHbdmk9Cvrb68GDBxWgVq5cme9506dPV4C+knO/fv36qfr16+uf8/+VmFmzZqmuXbsqpZT66KOP1MCBA1VsbGyhKjcJCQnK2tpa/fnnn/rX0tLSVJUqVdSMGTOUUvcqN6tWrTJ47/0VE19fX/Xll1/qn2dkZKjq1as/sHLz3HPP6Z9rtVrl4+Oj5syZk2u8Sin15ZdfqpYtW+YZR26fY58+fRSgatSooQYPHqwWLFigUlJS8r3G5s2blaWlpUHV5MyZMwrQV7bat2+vnn322TzvravcTJ48WVWuXFmdPn06z3OVuldFOnDggP614OBgBaiDBw/qY7W2tlY3b940eG/2r+358+cVoLZs2ZLrfT755BPVs2dPg9fCw8MVoM6fP6+OHDmiAHXlypV84zWlpKQkdfjwYXXs2DGllFIRERHq8OHDKiQkxGQxSeVGlCU///yzApS1tbU6evRoid1HKjdmRhXyt9zCnv/cc8+xf/9+Ll++zKJFi/Q7wxZGSEgI6enpdOjQQf+atbU1bdq0ITg42ODcVq1a5XmduLg4oqKiDKoWlpaWtGzZ8oExZK8CaTQaKlWqZLAh4tKlS+nQoQOVKlXCycmJ999/n7CwsAJ9fgCOjo6sX7+eS5cu8f777+Pk5MTrr79OmzZtSEpKyvN9wcHB+Pn54efnp3+tQYMGuLm56b82x48fz7cKA1mVqfnz57Nnzx4aNmz4wHitrKxo3bq1/nm9evUM7glZUz69vb3zvMbx48extLSkc+fOuR4/ceIEQUFBODk56R/16tUDsv5NNG3alG7dutG4cWOeeuop5s+fT2xs7ANjL026huKMjAy0Wq1UboS4z/PPP8+AAQNIT0/n2Wefzff7XWmR5OYBHBwcSEhIMMmjoIsJ1q5dG41Gw7lz5/I9r06dOgA5kgmd4OBg/TnZeXp68vjjjzN69GhSUlL06xuUlNyG1ozh/pVkNRqNfkG2/fv38+yzz9KnTx/WrVvHsWPHeO+99/RNtIVRq1YtxowZw88//8zRo0c5e/YsS5cuLVbsulVp89OpUycyMzP5+++/i3Wv7B70d/GguBISEujbty/Hjx83eFy8eJGHH34YS0tLtmzZwr///kuDBg2YPXs2devWJTQ01GifQ3HpkhvISnAkuRHCkEajYf78+VSuXJng4GAmT55s6pAkuXkQjUaDo6OjSR4FXUPDw8ODXr168cMPP5CYmJjjuG4T0J49e+Lh4ZHruOiaNWu4ePEiQ4YMyfUezz//PDt27GD48OFF+qZeq1YtbGxs2Lt3r/619PR0Dh8+TIMGDQp8HVdXV3x9fTl8+LD+tczMTI4ePVromLLbt28fNWrU4L333qNVq1bUrl2bq1evFuuakLX+jIODg/7vxcbGJseU+/r16xMeHm4w2+Ds2bPcuXNH/7Vp0qTJA6fDt2nThn///ZfPP/+cr7766oGxZWRk8N9//+mfnz9/njt37lC/fv0Cf36NGzdGq9Wyc+fOXI+3aNGCM2fO4O/vT2BgoMFDlzhpNBo6dOjARx99xLFjx7CxseGff/4pcAwlTaPRGKx1I8mNEDl5eXnpZ9b+8MMPbNiwwaTxSHJTQfzwww9kZmbSpk0bVqxYwcWLFwkODua7776jffv2QNZv4fPmzWP16tW88MILnDx5kitXrrBgwQJGjhzJk08+mec+IY8++ijR0dF8/PHHRYrP0dGRcePG8eabb7Jx40bOnj3L2LFjSUpKYvTo0YW61oQJE5g2bRqrV6/m/PnzvPrqq8TGxhZrQbXatWsTFhbGkiVLCAkJ4bvvviv0D9gPP/yQyZMns2PHDkJDQzl27BjPP/886enp9OjRA8hKdkJDQzl+/Di3bt0iNTWV7t2707hxY5599lmOHj3KoUOHGD58OJ07d9YP0U2dOpXFixczdepUgoODOXXqFF988UWOGB566CE2bNjARx999MBF/aytrZkwYQIHDx7kyJEjjBw5knbt2uXZqJwbf39/RowYwfPPP8+qVasIDQ1lx44d+urR+PHjiYmJYciQIRw+fJiQkBA2bdrEqFGjyMzM5ODBg3z++ef8999/hIWFsXLlSqKjowuVYJWG7GvdSHIjRO569erFK6+8AsDo0aNNOjwlyU0FUbNmTY4ePUrXrl15/fXXadSoET169GDbtm3MmTNHf96TTz5JUFAQYWFhdOrUibp16/LNN9/w3nvvsWTJkjwTBI1Gg5eXV7G2t58+fTqDBg1i2LBhtGjRgkuXLrFp0ybc3d0LdZ233nqLIUOGMHz4cNq3b4+TkxO9evXCzs6uyLH169eP1157jZdffplmzZqxb98+pkyZUqhrdO7cmcuXLzN8+HDq1atH7969iYyMZPPmzdStWxeAQYMG8eijj9K1a1e8vb1ZvHgxGo2G1atX4+7uzsMPP0z37t2pWbOmwVBWly5dWLZsGWvWrKFZs2Y88sgjHDp0KNc4OnbsyPr163n//feZPXt2nvE6ODjw1ltvMXToUDp06ICTk1ORhs/mzJnDk08+yUsvvUS9evUYO3asvlJVpUoV9u7dS2ZmJj179qRx48ZMnDgRNzc3LCwscHFxYdeuXfTp04c6derw/vvvM3PmzBIf+iys7DOmJLkRIm/Tp0+nV69e/PHHHybdp1GjCttdWs7Fx8fj6upKXFwcLi4uBsdSUlIIDQ0lICCgWD8oRenSarXUr1+fp59+2qxWzi2ORYsWMXHiRP2QpchfaGgot2/fplq1asTExJCUlERgYKB+mYXSJt+rhDnK7+f3/azyPSpEGXT16lU2b95M586dSU1N5fvvvyc0NJShQ4eaOjRRQWUfltI1oUvlRoiyS4alRLljYWHBokWLaN26NR06dODUqVNs3bq1zPVpiIpDhqWEKF+kciPKHT8/P4NZV6LwRo4cyciRI00dRrmRfbaUbndwSW6EKLukciOEEA+gG5ZKS0vTL4IpyY0QZZckN0II8QC6yk1qaqr+NUluhCi7JLkRQogH0FVudFUbCwuLYq2rJIQoWZLcCCHEA9y/dYdUbYQo2yS5EUKIB9BoNAZ7TElyI0TZJsmNEEIUQPbqjSQ3QpRtktyIQhs5ciQDBgzQP+/SpQsTJ04s9Th27NiBRqOp0KvsLlq0yKir4Pr7+z9wz6ny7P5/m8Z0f+Xmww8/pFmzZiVyLyFE8UhyU0GMHDkSjUaDRqPBxsaGwMBAPv74Y/2aHCVp5cqVBd72wBQJybFjx3jqqafw9fXFzs6O2rVrM3bsWC5cuGBw3q+//krr1q1xcHDA2dmZzp07s27dulzjd3d3JyUlxeDY4cOH9X8H959fVhKww4cP88ILL5T4fU6cOEG/fv3w8fHBzs4Of39/Bg8ezM2bN4Gy93UpiPsrN2+88cYDd2oXQpiGJDcVyKOPPkpERAQXL17k9ddf58MPP+TLL7/M9dy0tDSj3dfDwwNnZ2ejXc+Y1q1bR7t27UhNTeXPP/8kODiYP/74A1dXV4ONMd944w1efPFFBg8ezMmTJzl06BAdO3akf//+fP/99zmu6+zsnGPX8AULFlC9evUS/5yKw9vbu8Q3s4uOjqZbt254eHiwadMmgoODWbhwIVWqVNFvqFkeZZ8xpZTCyckJT09PE0clhMiVMjNxcXEKUHFxcTmOJScnq7Nnz6rk5GQTRFY8I0aMUP379zd4rUePHqpdu3YGxz/99FNVuXJl5e/vr5RSKiwsTD311FPK1dVVubu7q379+qnQ0FD9NTIyMtRrr72mXF1dlYeHh3rzzTfV8OHDDe7VuXNn9eqrr+qfp6SkqMmTJ6tq1aopGxsbVatWLfXzzz+r0NBQBRg8RowYoZRSKjMzU33++efK399f2dnZqSZNmqhly5YZfD7r169XtWvXVnZ2dqpLly5q4cKFClCxsbG5fk0SExOVl5eXGjBgQK7Hde/bv3+/AtR3332X45xJkyYpa2trFRYWppRSKigoSAHq/fffV927d9efl5SUpFxdXdWUKVNU9v9WuvPzilEXxwsvvKB8fHyUra2tatiwoVq7dq1SSqmFCxcqV1dXg/N//PFHVbNmTWVtba3q1KmjfvvtN/0xrVarpk6dqvz8/JSNjY2qXLmymjBhgv54jRo11DfffKN/Dqj58+erAQMGKHt7exUYGKhWr15tcL/Vq1erwMBAZWtrq7p06aIWLVqU7+f0zz//KCsrK5Wenp7r8fz+HaSkpKgJEyYob29vZWtrqzp06KAOHTpk8P7Tp0+rxx57TDk7OysnJyfVsWNHdenSJaVUzv8Hhw4dUl5eXmr69On5xrJ48WLVvn17/dd/x44d+nN0f4d//PGHqlevnrKyslJLly5VU6dOVU2bNjW43oIFC1SDBg2UjY2NqlSpkho/frz+WGxsrBo9erTy8vJSzs7OqmvXrur48eP648ePH1ddunRRTk5OytnZWbVo0UIdPnw417jL8/cqIYoqv5/f95PKzQMopUhMSzTJQxVzw3Z7e3uDCs22bds4f/48W7ZsYd26daSnp9OrVy+cnZ3ZvXs3e/fuxcnJiUcffVT/vpkzZ7Jo0SJ++eUX9uzZQ0xMTI6Kxf2GDx/O4sWL+e677wgODmbevHk4OTnh5+fHihUrADh//jwRERF8++23AEybNo3ffvuNuXPncubMGV577TWee+45du7cCUB4eDhPPPEEffv25fjx44wZM4a333473zg2bdrErVu3mDx5cq7Hdb0sixcvxsnJiRdffDHHOa+//jrp6en6uHWGDRvG7t27CQsLA2DFihX4+/vTokWLfGO6n1arpXfv3uzdu5c//viDs2fPMn369DwbVv/55x9effVVXn/9dU6fPs2LL77IqFGjCAoK0sfxzTffMG/ePC5evMiqVato3LhxvjF89NFHPP3005w8eZI+ffrw7LPPEhMTA2Tthv3kk08yYMAATpw4wf+1d+dRTV7pH8C/LElYwlKhbAqCIAKKM6BC0bFORypax0r14DLUWnWwKliQEfeqHQ/iRit2LLSdIoyFoXoqjsWqRRGPC5WtUG0lIuJgZbM6GlMQkDy/Pzy8P2MCSl0CyfM5J+eQe2/ePG/uS3i4773v+84772D16tVdbs/BwQH37t1Ddna2xmO4q+Ng2bJl+Oqrr5Ceno7S0lJ4eHggJCREiOfatWt4+eWXIZFIkJeXh5KSEsydO1fj6de8vDy8+uqriI+Px/Lly7uMOS4uDn/729/w/fffIygoCJMmTcKNGzdU2iQkJCAqKgp79+7F4MGD1baRnJyMyMhIzJ8/H+fOncOBAwfg4eEh1IeFhaGxsRGHDh1CSUkJ/P39MXbsWGHfwsPD0a9fPxQVFaGkpAQrVqxQW4LOGHtMzzrT6mm6O3KjaFEQ1kMrD0WL4rH368H/WJVKJeXm5pJEIqGlS5cK9fb29tTS0iK8Zvfu3TRo0CBSKpVCWUtLC5mamtKRI0eIiMjR0ZG2bNki1Le1tVG/fv06HbmRyWQEgHJzczXGqWkk4+7du2RmZkZnzpxRaTtv3jyaOXMmERGtXLmSfHx8VOqXL1/e5QjC5s2bCQDdvHlTY32H8ePHq/0H/iBLS0tauHChWvyhoaH0/vvvExHRK6+8QklJSZSdnd2tkZsjR46QoaEhyWQyjfUPj9yMHDmSIiIiVNqEhYXRa6+9RkREiYmJ5OnpSa2trRq3p2nkZs2aNcJzhUJBAOjQoUNEdP8zHjJkiMo2Vq9e/cjRqFWrVpGxsTH16dOHxo8fT1u2bKH6+nqhXtPnolAoSCQSUUZGhlDW2tpKTk5OwjG4cuVKcnNz63T/On4P9u3bR1KplLKysjqNkej/R24eHNnpOMY3b96sEmtGRgYVFRVRUVER1dfXq43cODk50erVqzW+z8mTJ8nS0pLu3r2rUu7u7k6ffPIJERFZWFhQWlpal/F24JEbpo963cjNzp074erqChMTEwQGBqKwsLDL9nv37oWXlxdMTEzg6+uLb7755jlF2rPl5ORAKpXCxMQEEyZMwPTp07F+/Xqh3tfXF2KxWHheXl6OS5cuwcLCAlKpFFKpFH369MHdu3dRVVWF27dvo66uDoGBgcJrjI2NMXz48E5jKCsrg5GREcaMGfPYcV+6dAlNTU149dVXhTikUin+9a9/oaqqCgBw4cIFlTgAICgoqMvtUjdGvrrTtsPcuXORlpaGy5cvo6CgAOHh4d3eRllZGfr16wdPT8/Han/hwgWMGjVKpWzUqFG4cOECgPujA83NzRgwYAAiIiKQnZ39yEnlQ4cOFX42NzeHpaWlMPFXJpNhxIgRKu0DAgIeGWd8fDzq6+uRkpKCwYMHIyUlBV5eXjh37lynr6mqqkJbW5vK/olEIgQEBAj7V1ZWhtGjR3c5onH27FmEhYVh9+7dmD59+iNjBVSPpY5jvOM9Ozz4ORgaqn51NjY2ora2FmPHjtW4/fLycigUCtjY2Kgc49XV1cIxHhsbi7/+9a8IDg7Gpk2bhHLGWPdp/a7gX375JWJjY5GSkoLAwEBs374dISEhkMlksLOzU2t/5swZzJw5EwkJCfjzn/+MzMxMhIaGorS0FEOGDHnq8ZmJzKBYqXjq233c9+6OV155BcnJyRCLxXByclJZugrc/8P1IIVCgWHDhiEjI0NtWy+++GL3A8b9U2HdpVDc/3wPHjyIvn37qtRJJJLfFAcAIWGoqKjoMhHy9PTEqVOn0NraqpL8AUBtbS3kcrnG5GPChAmYP38+5s2bh0mTJv2myaW/5fPqirOzM2QyGY4ePYrc3FwsWrQIW7duxYkTJzpNCB4uNzAwgFKpfOJYbGxsEBYWhrCwMGzcuBF+fn7Ytm0b0tPTf/M2H+fzcnd3h42NDVJTUzFx4sSndmrHysoKt2/fBqB+nZtHxaVQKODo6Ij8/Hy1uo7To+vXr8df/vIXHDx4EIcOHcK6deuQlZWFN95446nEz5g+0frIzQcffICIiAjMmTMHPj4+SElJgZmZGVJTUzW2T0pKwvjx4xEXFwdvb29s2LAB/v7+Gle0PA0GBgYwF5tr5dHde9eYm5vDw8MDLi4uaomNJv7+/qisrISdnR08PDxUHlZWVrCysoKjoyPOnj0rvObevXsoKSnpdJu+vr5QKpXCXJmHdSQP7e3tQpmPjw8kEglqamrU4nB2dgYAeHt7q43offfdd13u37hx42Bra4stW7ZorO9YhjxjxgwoFAp88sknam22bdsGkUiEqVOnqtUZGxvjrbfeQn5+PubOndtlLJ0ZOnQofv75Z7Vl6Z3x9vbG6dOnVcpOnz4NHx8f4bmpqSkmTZqEHTt2ID8/HwUFBV2OmHRl0KBBKC4uVikrKirq9nbEYjHc3d2F1VKajgN3d3eIxWKV/Wtra0NRUZGwf0OHDsXJkyfR1tbW6XvZ2toiLy8Ply5dwrRp07ps2+HBY6njGPf29lZp8+Dv1MO/XxYWFnB1de10abi/vz/q6+thbGysdozb2toK7Tw9PbFkyRJ8++23mDJlCnbt2vXI2Blj6rSa3LS2tqKkpATBwcFCmaGhIYKDg1FQUKDxNQUFBSrtASAkJKTT9i0tLZDL5SoPdl94eDhsbW0xefJknDx5EtXV1cjPz8e7776Ln3/+GQAQHR2NTZs2Yf/+/aioqMCiRYu6vDaJq6srZs+ejblz52L//v3CNvfs2QMA6N+/PwwMDJCTk4Pr169DoVDAwsICS5cuxZIlS5Ceno6qqiqUlpbio48+Ev7LX7BgASorKxEXFweZTIbMzEykpaV1uX/m5ub45z//iYMHD+L111/H0aNHceXKFRQXF2PZsmVYsGABgPunJKKjoxEXF4fExERUVVWhoqICa9asQVJSEhITE4Uk62EbNmzA9evXERIS0s1P/74xY8bg5ZdfxtSpU5Gbm4vq6mocOnQIhw8f1tg+Li4OaWlpSE5ORmVlJT744APs27cPS5cuBXD/on+ff/45zp8/j8uXL+OLL76Aqakp+vfv/5vie+edd1BRUYHly5fj4sWL2LNnj/C5d5Z85+Tk4M0330ROTg4uXrwImUyGbdu24ZtvvsHkyZMBaD4OzM3NsXDhQsTFxeHw4cP46aefEBERgaamJsybNw8AEBUVBblcjhkzZqC4uBiVlZXYvXs3ZDKZSgx2dnbIy8tDRUUFZs6c+chTczt37kR2djYqKioQGRmJ//3vf2oJq6GhoTBi8/BpKeD+yEtiYiJ27NiByspK4RgGgODgYAQFBSE0NBTffvstrly5gjNnzmD16tUoLi5Gc3MzoqKikJ+fj//+9784ffo0ioqK1BIsxthjeuYzgLpw7do1AqA2kTQuLo4CAgI0vkYkElFmZqZK2c6dO8nOzk5j+3Xr1qktO4WeLAV/nPq6ujp66623yNbWliQSCQ0YMIAiIiKEz6etrY2io6PJ0tKSrK2tKTY29pFLwZubm2nJkiXk6OhIYrGYPDw8KDU1Vaj/+9//Tg4ODmRgYCAsAVYqlbR9+3YaNGgQiUQievHFFykkJIROnDghvO7rr78WliSPHj2aUlNTHzmxlYioqKiIpkyZIiwv9vDwoPnz51NlZaVKu88//5yGDRtGJiYmZG5uTqNHj6YDBw6otHnUBOHuTigmIrpx4wbNmTOHbGxsyMTEhIYMGUI5OTlE1P2l4NnZ2RQYGEiWlpZkbm5OL730Eh09elSo1zShODs7W2X7VlZWtGvXLuH5w0vBk5OTCUCnvydVVVUUERFBnp6eZGpqStbW1jRixAiVbRJpPg6am5tp8eLFwvGoaSl4eXk5jRs3jszMzMjCwoJGjx5NVVVVRKR+nNfW1pKnpydNmzaN7t27pxZrx4TizMxMCggIILFYTD4+PpSXlye0ebAPa2pq6Mcff6T29naNS8FTUlKEY/jhZfhyuZwWL15MTk5OJBKJyNnZmcLDw6mmpoZaWlpoxowZwhJ+JycnioqK6vQz7s3fVYz9Vt2ZUGxA9ITrjZ9AbW0t+vbtizNnzqjMiVi2bBlOnDihcjqkg1gsRnp6OmbOnCmUffzxx3j//ffR0NCg1r6lpQUtLS3Cc7lcDmdnZ9y+fRuWlpYqbe/evYvq6mq4ubnBxMTkaewiYzonPj4eKSkpuHr1qrZDeWJXrlyBm5sbvv/++151KwX+rmL6SC6XC3PfHv77/TCtTii2tbWFkZGRWlLS0NAABwcHja9xcHDoVnuJRPJEk1IZ03cff/wxRowYARsbG5w+fRpbt25FVFSUtsNijLFOaXXOjVgsxrBhw1Qm4SmVShw7dqzT1S1BQUFqk/Zyc3MfuSyYMfbbVFZWYvLkyfDx8cGGDRuEW3swxlhPpfWl4LGxsZg9ezaGDx+OgIAAbN++Hb/++ivmzJkD4P7Vbvv27YuEhAQA9ye4jhkzBomJiZg4cSKysrJQXFyMTz/9VJu7wZjO+vDDD/Hhhx9qO4xnwtXV9YmvBM4Y63m0ntxMnz4d169fx9q1a1FfX4/f//73OHz4MOzt7QEANTU1KisTRo4ciczMTKxZswarVq3CwIEDsX///mdyjRvGGGOM9T5anVCsDV1NSOJJeoyx3oC/q5g+6s6EYq1fxK8n0rN8jzHWy/B3FGNd4+TmAR2XaW9qatJyJIwx1rmO7yi+azhjmml9zk1PYmRkBGtra+GmgWZmZt2+BQJjjD0rRISmpiY0NjbC2tpa7R5XjLH7OLl5SMf1cjoSHMYY62msra07vbYXY4yTGzUGBgZwdHSEnZ3dY91wjzHGnieRSMQjNow9Aic3nTAyMuIvEMYYY6wX4gnFjDHGGNMpnNwwxhhjTKdwcsMYY4wxnaJ3c246Ln4ll8u1HAljjDHGHlfH3+3HuYil3iU3d+7cAQA4OztrORLGGGOMddedO3dgZWXVZRu9u7eUUqlEbW0tLCwsnvoF+uRyOZydnXH16tVH3veCaQ/3U+/A/dQ7cD/1DrrQT0SEO3fuwMnJSeWG2pro3ciNoaEh+vXr90zfw9LSstcePPqE+6l34H7qHbifeofe3k+PGrHpwBOKGWOMMaZTOLlhjDHGmE7h5OYpkkgkWLduHSQSibZDYV3gfuoduJ96B+6n3kHf+knvJhQzxhhjTLfxyA1jjDHGdAonN4wxxhjTKZzcMMYYY0yncHLDGGOMMZ3Cyc1TsnPnTri6usLExASBgYEoLCzUdkh6LSEhASNGjICFhQXs7OwQGhoKmUym0ubu3buIjIyEjY0NpFIppk6dioaGBi1FzABg06ZNMDAwQExMjFDG/dQzXLt2DW+++SZsbGxgamoKX19fFBcXC/VEhLVr18LR0RGmpqYIDg5GZWWlFiPWP+3t7Xjvvffg5uYGU1NTuLu7Y8OGDSr3YtKbfiL2xLKyskgsFlNqair9+OOPFBERQdbW1tTQ0KDt0PRWSEgI7dq1i86fP09lZWX02muvkYuLCykUCqHNggULyNnZmY4dO0bFxcX00ksv0ciRI7UYtX4rLCwkV1dXGjp0KEVHRwvl3E/ad/PmTerfvz+9/fbbdPbsWbp8+TIdOXKELl26JLTZtGkTWVlZ0f79+6m8vJxef/11cnNzo+bmZi1Grl/i4+PJxsaGcnJyqLq6mvbu3UtSqZSSkpKENvrST5zcPAUBAQEUGRkpPG9vbycnJydKSEjQYlTsQY2NjQSATpw4QUREt27dIpFIRHv37hXaXLhwgQBQQUGBtsLUW3fu3KGBAwdSbm4ujRkzRkhuuJ96huXLl9Mf/vCHTuuVSiU5ODjQ1q1bhbJbt26RRCKhf//7388jREZEEydOpLlz56qUTZkyhcLDw4lIv/qJT0s9odbWVpSUlCA4OFgoMzQ0RHBwMAoKCrQYGXvQ7du3AQB9+vQBAJSUlKCtrU2l37y8vODi4sL9pgWRkZGYOHGiSn8A3E89xYEDBzB8+HCEhYXBzs4Ofn5++Oyzz4T66upq1NfXq/STlZUVAgMDuZ+eo5EjR+LYsWO4ePEiAKC8vBynTp3ChAkTAOhXP+ndjTOftl9++QXt7e2wt7dXKbe3t0dFRYWWomIPUiqViImJwahRozBkyBAAQH19PcRiMaytrVXa2tvbo76+XgtR6q+srCyUlpaiqKhIrY77qWe4fPkykpOTERsbi1WrVqGoqAjvvvsuxGIxZs+eLfSFpu9B7qfnZ8WKFZDL5fDy8oKRkRHa29sRHx+P8PBwANCrfuLkhum8yMhInD9/HqdOndJ2KOwhV69eRXR0NHJzc2FiYqLtcFgnlEolhg8fjo0bNwIA/Pz8cP78eaSkpGD27Nlajo512LNnDzIyMpCZmYnBgwejrKwMMTExcHJy0rt+4tNST8jW1hZGRkZqqzcaGhrg4OCgpahYh6ioKOTk5OD48ePo16+fUO7g4IDW1lbcunVLpT332/NVUlKCxsZG+Pv7w9jYGMbGxjhx4gR27NgBY2Nj2Nvbcz/1AI6OjvDx8VEp8/b2Rk1NDQAIfcHfg9oVFxeHFStWYMaMGfD19cWsWbOwZMkSJCQkANCvfuLk5gmJxWIMGzYMx44dE8qUSiWOHTuGoKAgLUam34gIUVFRyM7ORl5eHtzc3FTqhw0bBpFIpNJvMpkMNTU13G/P0dixY3Hu3DmUlZUJj+HDhyM8PFz4mftJ+0aNGqV2KYWLFy+if//+AAA3Nzc4ODio9JNcLsfZs2e5n56jpqYmGBqq/lk3MjKCUqkEoGf9pO0ZzbogKyuLJBIJpaWl0U8//UTz588na2trqq+v13ZoemvhwoVkZWVF+fn5VFdXJzyampqENgsWLCAXFxfKy8uj4uJiCgoKoqCgIC1GzYhIZbUUEfdTT1BYWEjGxsYUHx9PlZWVlJGRQWZmZvTFF18IbTZt2kTW1tb0n//8h3744QeaPHmyTi4x7slmz55Nffv2FZaC79u3j2xtbWnZsmVCG33pJ05unpKPPvqIXFxcSCwWU0BAAH333XfaDkmvAdD42LVrl9CmubmZFi1aRC+88AKZmZnRG2+8QXV1ddoLmhGRenLD/dQzfP311zRkyBCSSCTk5eVFn376qUq9Uqmk9957j+zt7UkikdDYsWNJJpNpKVr9JJfLKTo6mlxcXMjExIQGDBhAq1evppaWFqGNvvSTAdEDly5kjDHGGOvleM4NY4wxxnQKJzeMMcYY0ymc3DDGGGNMp3BywxhjjDGdwskNY4wxxnQKJzeMMcYY0ymc3DDGGGNMp3BywxjrVd5++22EhoZqOwzGWA/GdwVnjPUYBgYGXdavW7cOSUlJ4GuPMsa6wskNY6zHqKurE37+8ssvsXbtWpUbNkqlUkilUm2ExhjrRfi0FGOsx3BwcBAeVlZWMDAwUCmTSqVqp6X++Mc/YvHixYiJicELL7wAe3t7fPbZZ/j1118xZ84cWFhYwMPDA4cOHVJ5r/Pnz2PChAmQSqWwt7fHrFmz8MsvvzznPWaMPQuc3DDGer309HTY2tqisLAQixcvxsKFCxEWFoaRI0eitLQU48aNw6xZs9DU1AQAuHXrFv70pz/Bz88PxcXFOHz4MBoaGjBt2jQt7wlj7Gng5IYx1uv97ne/w5o1azBw4ECsXLkSJiYmsLW1RUREBAYOHIi1a9fixo0b+OGHHwAA//jHP+Dn54eNGzfCy8sLfn5+SE1NxfHjx3Hx4kUt7w1j7EnxnBvGWK83dOhQ4WcjIyPY2NjA19dXKLO3twcANDY2AgDKy8tx/PhxjfN3qqqq4Onp+YwjZow9S5zcMMZ6PZFIpPLcwMBApaxjFZZSqQQAKBQKTJo0CZs3b1bblqOj4zOMlDH2PHBywxjTO/7+/vjqq6/g6uoKY2P+GmRM1/CcG8aY3omMjMTNmzcxc+ZMFBUVoaqqCkeOHMGcOXPQ3t6u7fAYY0+IkxvGmN5xcnLC6dOn0d7ejnHjxsHX1xcxMTGwtraGoSF/LTLW2xkQX+qTMcYYYzqE/0VhjDHGmE7h5IYxxhhjOoWTG8YYY4zpFE5uGGOMMaZTOLlhjDHGmE7h5IYxxhhjOoWTG8YYY4zpFE5uGGOMMaZTOLlhjDHGmE7h5IYxxhhjOoWTG8YYY4zpFE5uGGOMMaZT/g9QmowRXVCz+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sin normalizar\n",
    "plt.plot(inputs_cierre, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(temp, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sin normalizar\n",
    "# plt.plot(inputs_cierre, color = 'black', label = 'COMI original Stock prices')\n",
    "# plt.plot(temp, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "# plt.title('COMI Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('COMI Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "# plt.plot(predicted_stock_price_cierre_pred, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "# plt.title('COMI Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('COMI Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.9232, dtype=torch.float64)\n",
      "tensor(76.5941, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()\n",
    "perdida = criterion(torch.tensor(precios_reales),torch.tensor(precios_predichos))\n",
    "print(perdida)\n",
    "perdida = criterion(torch.tensor(precios_reales),torch.tensor(predicted_stock_price_cierre_pred[:78]))\n",
    "print(perdida)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
