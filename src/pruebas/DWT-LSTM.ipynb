{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import src.utilerias.reader as rd\n",
    "import src.utilerias.utilerias as utls\n",
    "# Llamamos a la función antes de ejecutar el script\n",
    "utls.eliminar_archivos_registro(\"logs/lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOS = 'datos/Datos históricos COMI 3ene16-31dic2020 semanal.csv'\n",
    "cierre = rd.leer_archivo(DATOS).astype(float)\n",
    "c_entrenamiento = np.array(cierre[:int(len(cierre) * 0.7)])\n",
    "\n",
    "#Se convierte en un arreglo bidimensional\n",
    "c_entrenamiento = np.reshape(c_entrenamiento, (c_entrenamiento.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "m_m_s = MinMaxScaler(feature_range=(0,1))\n",
    "c_entrenamiento_n = m_m_s.fit_transform(c_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crean los conjuntos de entradas y salidas para la red, que funcionaran para predecir y comparar con las salidas esperadas a la hora de realizar el entrenamiento\n",
    "time_steps = 8\n",
    "N = len(c_entrenamiento_n) #182\n",
    "X_entrenamiento_n = []\n",
    "y_entrenamiento_n = []\n",
    "for i in range(time_steps, N):\n",
    "    X_entrenamiento_n.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "    y_entrenamiento_n.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "X_entrenamiento_n, y_entrenamiento_n = np.array(X_entrenamiento_n), np.array(y_entrenamiento_n)\n",
    "\n",
    "#Se le da una tercera dimension al conjunto de entradas de entrenamiento\n",
    "X_entrenamiento_n = np.reshape(X_entrenamiento_n, (X_entrenamiento_n.shape[0], X_entrenamiento_n.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "#red = load_model('redes/DWT_LSTM/auto_predictiva/LSTM_prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.6379\n",
      "Epoch 2/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.6233\n",
      "Epoch 3/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.6073\n",
      "Epoch 4/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.5929\n",
      "Epoch 5/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5778\n",
      "Epoch 6/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5623\n",
      "Epoch 7/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.5480\n",
      "Epoch 8/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.5330\n",
      "Epoch 9/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.5189\n",
      "Epoch 10/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5040\n",
      "Epoch 11/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.4897\n",
      "Epoch 12/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4755\n",
      "Epoch 13/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.4615\n",
      "Epoch 14/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4475\n",
      "Epoch 15/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.4336\n",
      "Epoch 16/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4204\n",
      "Epoch 17/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.4063\n",
      "Epoch 18/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3944\n",
      "Epoch 19/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3798\n",
      "Epoch 20/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3665\n",
      "Epoch 21/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3535\n",
      "Epoch 22/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.3394\n",
      "Epoch 23/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3267\n",
      "Epoch 24/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3141\n",
      "Epoch 25/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.3011\n",
      "Epoch 26/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.2889\n",
      "Epoch 27/60\n",
      "6/6 [==============================] - 0s 998us/step - loss: 1.2758\n",
      "Epoch 28/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.2632\n",
      "Epoch 29/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.2526\n",
      "Epoch 30/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.2385\n",
      "Epoch 31/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.2270\n",
      "Epoch 32/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.2149\n",
      "Epoch 33/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.2025\n",
      "Epoch 34/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1908\n",
      "Epoch 35/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.1798\n",
      "Epoch 36/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.1669\n",
      "Epoch 37/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1558\n",
      "Epoch 38/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1442\n",
      "Epoch 39/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.1328\n",
      "Epoch 40/60\n",
      "6/6 [==============================] - 0s 998us/step - loss: 1.1219\n",
      "Epoch 41/60\n",
      "6/6 [==============================] - 0s 798us/step - loss: 1.1101\n",
      "Epoch 42/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0987\n",
      "Epoch 43/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0873\n",
      "Epoch 44/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0765\n",
      "Epoch 45/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0661\n",
      "Epoch 46/60\n",
      "6/6 [==============================] - 0s 798us/step - loss: 1.0545\n",
      "Epoch 47/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0441\n",
      "Epoch 48/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0340\n",
      "Epoch 49/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0226\n",
      "Epoch 50/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0121\n",
      "Epoch 51/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.0019\n",
      "Epoch 52/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.9915\n",
      "Epoch 53/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9811\n",
      "Epoch 54/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.9711\n",
      "Epoch 55/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9609\n",
      "Epoch 56/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.9512\n",
      "Epoch 57/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9409\n",
      "Epoch 58/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.9308\n",
      "Epoch 59/60\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.9214\n",
      "Epoch 60/60\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.9112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.modelos.LSTM.LSTM import red_LSTM\n",
    "from src.modelos.GRU.GRU import red_GRU\n",
    "from src.modelos.NARNN.NARNN import NARNN\n",
    "#red = red_GRU(input_dim = X_entrenamiento_n.shape[1],output_dim= 1)\n",
    "red = red_LSTM(input_dim = X_entrenamiento_n.shape[1],output_dim= 1)\n",
    "#red = NARNN(input_dim = X_entrenamiento_n.shape[1],output_dim= 1)\n",
    "red.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\n",
    "history = red.fit(X_entrenamiento_n,y_entrenamiento_n,epochs=60,batch_size=32)#batch_size=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"losses = history.history['loss']\\nprint(losses)\\nplt.plot(range(len(losses)),losses)\\nplt.show()\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener la pérdida durante el entrenamiento\n",
    "\"\"\"losses = history.history['loss']\n",
    "print(losses)\n",
    "plt.plot(range(len(losses)),losses)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_reales = cierre[int(len(cierre) * 0.7):] #verdaderos valores del conjunto de prueba\n",
    "precios_reales = np.reshape(precios_reales, (precios_reales.shape[0], 1)) #se le da una dimension mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m s_normalizar \u001b[38;5;241m=\u001b[39m precios_predichos\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#Se desnormalizan los datos\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m precios_predichos \u001b[38;5;241m=\u001b[39m \u001b[43mm_m_s_prueba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecios_predichos\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:544\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Undo the scaling of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m    Transformed data.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 544\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    549\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:951\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m     )\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    957\u001b[0m     _assert_all_finite(\n\u001b[0;32m    958\u001b[0m         array,\n\u001b[0;32m    959\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    960\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    961\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    962\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "#toma los ultimos 86 elementos, los ultimos 8 de entrenamiento y todos los de prueba  \n",
    "c_prueba = cierre[len(cierre) - len(precios_reales) - time_steps:]\n",
    "\n",
    "c_prueba = np.array(c_prueba).reshape(-1,1)\n",
    "\n",
    "m_m_s_prueba = MinMaxScaler(feature_range=(0,1))\n",
    "# se normalizan los datos usandlo los parametros que se le dieron a m_m_s\n",
    "c_prueba_n = m_m_s_prueba.fit_transform(c_prueba)\n",
    "\n",
    "X_prueba_n = []\n",
    "for i in range(time_steps, len(c_prueba_n)):\n",
    "    X_prueba_n.append(c_prueba_n[i-time_steps:i, 0]) # se toman en paquetes de 8 \n",
    "X_prueba_n = np.array(X_prueba_n)\n",
    "X_prueba_n = np.reshape(X_prueba_n, (X_prueba_n.shape[0], X_prueba_n.shape[1], 1))#(78, 8, 1)\n",
    "\n",
    "precios_predichos = red.predict(X_prueba_n)\n",
    "s_normalizar = precios_predichos\n",
    "\n",
    "#Se desnormalizan los datos\n",
    "precios_predichos = m_m_s_prueba.inverse_transform(precios_predichos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La normalización funciona correctamente\n",
    "plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "# red.save('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_entrenamiento_n.size)\n",
    "# plt.plot(y_entrenamiento_n)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cierre_s_pred = c_entrenamiento_n\n",
    "\n",
    "# loss_m = []\n",
    "# for epoch in range(100):  # Número de épocas\n",
    "#     ts_cierre_s_pred = c_entrenamiento_n[:time_steps]#se obtienen los primeros time_steps(8) elementos del trainig set\n",
    "#     loss = []\n",
    "#     X_train_c_pred = []\n",
    "#     # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "#     for i in range(time_steps, N):\n",
    "#         # Obtener las características y la etiqueta actual\n",
    "#         x_actual = ts_cierre_s_pred[i-time_steps:i,0]\n",
    "#         X_train_c_pred.append(x_actual)\n",
    "#         x_actual = x_actual.reshape(1,time_steps,1)\n",
    "\n",
    "#         y_actual = np.array([y_entrenamiento_n[i-time_steps]])\n",
    "\n",
    "#         print(f\"x_actual: {x_actual}\")\n",
    "#         print(f\"y_actual: {y_actual}\")\n",
    "        \n",
    "#         # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "#         #loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "\n",
    "#         # Predicción del modelo\n",
    "#         #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "#         prediccion = red(x_actual)\n",
    "        \n",
    "#         # Agregar la predicción a las características para el siguiente paso\n",
    "#         # print(ts_cierre_s_pred)\n",
    "#         print(f\"prediccion: {prediccion}\")\n",
    "#         ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "\n",
    "\n",
    "\n",
    "#     # print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "#     # loss_m.append(np.mean(np.array(loss)))\n",
    "#     X_train_c_pred = np.array(X_train_c_pred)\n",
    "#     X_train_c_pred = np.reshape(X_train_c_pred, (X_train_c_pred.shape[0], X_train_c_pred.shape[1], 1))\n",
    "#     history = red.fit(X_train_c_pred, y_entrenamiento_n, epochs=1, batch_size=32)\n",
    "#     loss = history.history['loss']\n",
    "#     loss_m.append(loss)\n",
    "#     loss_m.append(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_entrenamiento: [0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23895779]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03719175234436989\n",
      "Predicción post entrenamiento : [[0.21194479]]\n",
      "PERDIDAAAA despues: 0.027502451092004776\n",
      "loss en el callback: 0.033078938722610474, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23895779]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.19687349]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23895779]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008584081195294857\n",
      "Predicción post entrenamiento : [[0.18620159]]\n",
      "PERDIDAAAA despues: 0.006720460951328278\n",
      "loss en el callback: 0.00593525730073452, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23895779]\n",
      " [0.19687349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.18997572]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23895779]\n",
      "  [0.19687349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012796303490176797\n",
      "Predicción post entrenamiento : [[0.18611084]]\n",
      "PERDIDAAAA despues: 0.0010180589742958546\n",
      "loss en el callback: 0.001503486535511911, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23895779]\n",
      " [0.19687349]\n",
      " [0.18997572]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.19700408]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23895779]\n",
      "  [0.19687349]\n",
      "  [0.18997572]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017016035271808505\n",
      "Predicción post entrenamiento : [[0.19514626]]\n",
      "PERDIDAAAA despues: 0.0015517831780016422\n",
      "loss en el callback: 0.0007364634657278657, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23895779]\n",
      " [0.19687349]\n",
      " [0.18997572]\n",
      " [0.19700408]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.2072835]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23895779]\n",
      "  [0.19687349]\n",
      "  [0.18997572]\n",
      "  [0.19700408]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00668318523094058\n",
      "Predicción post entrenamiento : [[0.20221637]]\n",
      "PERDIDAAAA despues: 0.005880378652364016\n",
      "loss en el callback: 0.006838084664195776, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23895779]\n",
      " [0.19687349]\n",
      " [0.18997572]\n",
      " [0.19700408]\n",
      " [0.2072835 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.21189082]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23895779]\n",
      "  [0.19687349]\n",
      "  [0.18997572]\n",
      "  [0.19700408]\n",
      "  [0.2072835 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004383876919746399\n",
      "Predicción post entrenamiento : [[0.2080432]]\n",
      "PERDIDAAAA despues: 0.0038891732692718506\n",
      "loss en el callback: 0.005536316893994808, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23895779]\n",
      " [0.19687349]\n",
      " [0.18997572]\n",
      " [0.19700408]\n",
      " [0.2072835 ]\n",
      " [0.21189082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.22855246]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23895779]\n",
      "  [0.19687349]\n",
      "  [0.18997572]\n",
      "  [0.19700408]\n",
      "  [0.2072835 ]\n",
      "  [0.21189082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006740016862750053\n",
      "Predicción post entrenamiento : [[0.22558443]]\n",
      "PERDIDAAAA despues: 0.006261489819735289\n",
      "loss en el callback: 0.0050033084116876125, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.23895779]\n",
      " [0.19687349]\n",
      " [0.18997572]\n",
      " [0.19700408]\n",
      " [0.2072835 ]\n",
      " [0.21189082]\n",
      " [0.22855246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.25074428]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.23895779]\n",
      "  [0.19687349]\n",
      "  [0.18997572]\n",
      "  [0.19700408]\n",
      "  [0.2072835 ]\n",
      "  [0.21189082]\n",
      "  [0.22855246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029916793573647738\n",
      "Predicción post entrenamiento : [[0.2504394]]\n",
      "PERDIDAAAA despues: 0.002958421129733324\n",
      "loss en el callback: 7.769932562950999e-05, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.23895779]\n",
      " [0.19687349]\n",
      " [0.18997572]\n",
      " [0.19700408]\n",
      " [0.2072835 ]\n",
      " [0.21189082]\n",
      " [0.22855246]\n",
      " [0.25074428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.28072414]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.23895779]\n",
      "  [0.19687349]\n",
      "  [0.18997572]\n",
      "  [0.19700408]\n",
      "  [0.2072835 ]\n",
      "  [0.21189082]\n",
      "  [0.22855246]\n",
      "  [0.25074428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025193714536726475\n",
      "Predicción post entrenamiento : [[0.27890816]]\n",
      "PERDIDAAAA despues: 0.0023403693921864033\n",
      "loss en el callback: 0.0023945376742631197, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.19687349]\n",
      " [0.18997572]\n",
      " [0.19700408]\n",
      " [0.2072835 ]\n",
      " [0.21189082]\n",
      " [0.22855246]\n",
      " [0.25074428]\n",
      " [0.28072414]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.27303764]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.19687349]\n",
      "  [0.18997572]\n",
      "  [0.19700408]\n",
      "  [0.2072835 ]\n",
      "  [0.21189082]\n",
      "  [0.22855246]\n",
      "  [0.25074428]\n",
      "  [0.28072414]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004172036424279213\n",
      "Predicción post entrenamiento : [[0.26909375]]\n",
      "PERDIDAAAA despues: 0.003678108798339963\n",
      "loss en el callback: 0.011120454408228397, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.18997572]\n",
      " [0.19700408]\n",
      " [0.2072835 ]\n",
      " [0.21189082]\n",
      " [0.22855246]\n",
      " [0.25074428]\n",
      " [0.28072414]\n",
      " [0.27303764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.27247345]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.18997572]\n",
      "  [0.19700408]\n",
      "  [0.2072835 ]\n",
      "  [0.21189082]\n",
      "  [0.22855246]\n",
      "  [0.25074428]\n",
      "  [0.28072414]\n",
      "  [0.27303764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036651031114161015\n",
      "Predicción post entrenamiento : [[0.2699104]]\n",
      "PERDIDAAAA despues: 0.0033613366540521383\n",
      "loss en el callback: 0.006271509453654289, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.19700408]\n",
      " [0.2072835 ]\n",
      " [0.21189082]\n",
      " [0.22855246]\n",
      " [0.25074428]\n",
      " [0.28072414]\n",
      " [0.27303764]\n",
      " [0.27247345]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.27674425]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.19700408]\n",
      "  [0.2072835 ]\n",
      "  [0.21189082]\n",
      "  [0.22855246]\n",
      "  [0.25074428]\n",
      "  [0.28072414]\n",
      "  [0.27303764]\n",
      "  [0.27247345]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004824725445359945\n",
      "Predicción post entrenamiento : [[0.2746609]]\n",
      "PERDIDAAAA despues: 0.004539644345641136\n",
      "loss en el callback: 0.005679695401340723, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.2072835 ]\n",
      " [0.21189082]\n",
      " [0.22855246]\n",
      " [0.25074428]\n",
      " [0.28072414]\n",
      " [0.27303764]\n",
      " [0.27247345]\n",
      " [0.27674425]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.28252164]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.2072835 ]\n",
      "  [0.21189082]\n",
      "  [0.22855246]\n",
      "  [0.25074428]\n",
      "  [0.28072414]\n",
      "  [0.27303764]\n",
      "  [0.27247345]\n",
      "  [0.27674425]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00802335049957037\n",
      "Predicción post entrenamiento : [[0.28079993]]\n",
      "PERDIDAAAA despues: 0.00771787716075778\n",
      "loss en el callback: 0.004807019606232643, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.21189082]\n",
      " [0.22855246]\n",
      " [0.25074428]\n",
      " [0.28072414]\n",
      " [0.27303764]\n",
      " [0.27247345]\n",
      " [0.27674425]\n",
      " [0.28252164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.28901058]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.21189082]\n",
      "  [0.22855246]\n",
      "  [0.25074428]\n",
      "  [0.28072414]\n",
      "  [0.27303764]\n",
      "  [0.27247345]\n",
      "  [0.27674425]\n",
      "  [0.28252164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008498561568558216\n",
      "Predicción post entrenamiento : [[0.28574473]]\n",
      "PERDIDAAAA despues: 0.007907084189355373\n",
      "loss en el callback: 0.015304475091397762, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.22855246]\n",
      " [0.25074428]\n",
      " [0.28072414]\n",
      " [0.27303764]\n",
      " [0.27247345]\n",
      " [0.27674425]\n",
      " [0.28252164]\n",
      " [0.28901058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.29539698]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.22855246]\n",
      "  [0.25074428]\n",
      "  [0.28072414]\n",
      "  [0.27303764]\n",
      "  [0.27247345]\n",
      "  [0.27674425]\n",
      "  [0.28252164]\n",
      "  [0.28901058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006583527196198702\n",
      "Predicción post entrenamiento : [[0.29218358]]\n",
      "PERDIDAAAA despues: 0.006072388496249914\n",
      "loss en el callback: 0.015673302114009857, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.25074428]\n",
      " [0.28072414]\n",
      " [0.27303764]\n",
      " [0.27247345]\n",
      " [0.27674425]\n",
      " [0.28252164]\n",
      " [0.28901058]\n",
      " [0.29539698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.30059376]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.25074428]\n",
      "  [0.28072414]\n",
      "  [0.27303764]\n",
      "  [0.27247345]\n",
      "  [0.27674425]\n",
      "  [0.28252164]\n",
      "  [0.28901058]\n",
      "  [0.29539698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014225022867321968\n",
      "Predicción post entrenamiento : [[0.2987867]]\n",
      "PERDIDAAAA despues: 0.013797235675156116\n",
      "loss en el callback: 0.008166028186678886, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.28072414]\n",
      " [0.27303764]\n",
      " [0.27247345]\n",
      " [0.27674425]\n",
      " [0.28252164]\n",
      " [0.28901058]\n",
      " [0.29539698]\n",
      " [0.30059376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.3042561]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.28072414]\n",
      "  [0.27303764]\n",
      "  [0.27247345]\n",
      "  [0.27674425]\n",
      "  [0.28252164]\n",
      "  [0.28901058]\n",
      "  [0.29539698]\n",
      "  [0.30059376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016674604266881943\n",
      "Predicción post entrenamiento : [[0.30190626]]\n",
      "PERDIDAAAA despues: 0.016073253005743027\n",
      "loss en el callback: 0.014667753130197525, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.27303764]\n",
      " [0.27247345]\n",
      " [0.27674425]\n",
      " [0.28252164]\n",
      " [0.28901058]\n",
      " [0.29539698]\n",
      " [0.30059376]\n",
      " [0.30425611]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.3020565]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.27303764]\n",
      "  [0.27247345]\n",
      "  [0.27674425]\n",
      "  [0.28252164]\n",
      "  [0.28901058]\n",
      "  [0.29539698]\n",
      "  [0.30059376]\n",
      "  [0.30425611]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02373196929693222\n",
      "Predicción post entrenamiento : [[0.3000142]]\n",
      "PERDIDAAAA despues: 0.023106902837753296\n",
      "loss en el callback: 0.013981937430799007, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.27247345]\n",
      " [0.27674425]\n",
      " [0.28252164]\n",
      " [0.28901058]\n",
      " [0.29539698]\n",
      " [0.30059376]\n",
      " [0.30425611]\n",
      " [0.30205649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.30242187]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.27247345]\n",
      "  [0.27674425]\n",
      "  [0.28252164]\n",
      "  [0.28901058]\n",
      "  [0.29539698]\n",
      "  [0.30059376]\n",
      "  [0.30425611]\n",
      "  [0.30205649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020611973479390144\n",
      "Predicción post entrenamiento : [[0.29918516]]\n",
      "PERDIDAAAA despues: 0.01969306915998459\n",
      "loss en el callback: 0.027705704793334007, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.27674425]\n",
      " [0.28252164]\n",
      " [0.28901058]\n",
      " [0.29539698]\n",
      " [0.30059376]\n",
      " [0.30425611]\n",
      " [0.30205649]\n",
      " [0.30242187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.30262932]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.27674425]\n",
      "  [0.28252164]\n",
      "  [0.28901058]\n",
      "  [0.29539698]\n",
      "  [0.30059376]\n",
      "  [0.30425611]\n",
      "  [0.30205649]\n",
      "  [0.30242187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012200472876429558\n",
      "Predicción post entrenamiento : [[0.30057353]]\n",
      "PERDIDAAAA despues: 0.01175055094063282\n",
      "loss en el callback: 0.013278116472065449, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.28252164]\n",
      " [0.28901058]\n",
      " [0.29539698]\n",
      " [0.30059376]\n",
      " [0.30425611]\n",
      " [0.30205649]\n",
      " [0.30242187]\n",
      " [0.30262932]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.3040619]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.28252164]\n",
      "  [0.28901058]\n",
      "  [0.29539698]\n",
      "  [0.30059376]\n",
      "  [0.30425611]\n",
      "  [0.30205649]\n",
      "  [0.30242187]\n",
      "  [0.30262932]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013944647274911404\n",
      "Predicción post entrenamiento : [[0.30181134]]\n",
      "PERDIDAAAA despues: 0.013418188318610191\n",
      "loss en el callback: 0.01733807474374771, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.28901058]\n",
      " [0.29539698]\n",
      " [0.30059376]\n",
      " [0.30425611]\n",
      " [0.30205649]\n",
      " [0.30242187]\n",
      " [0.30262932]\n",
      " [0.30406189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.3048956]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.28901058]\n",
      "  [0.29539698]\n",
      "  [0.30059376]\n",
      "  [0.30425611]\n",
      "  [0.30205649]\n",
      "  [0.30242187]\n",
      "  [0.30262932]\n",
      "  [0.30406189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014398096827790141\n",
      "Predicción post entrenamiento : [[0.3040457]]\n",
      "PERDIDAAAA despues: 0.0013760331785306334\n",
      "loss en el callback: 0.002625515917316079, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.29539698]\n",
      " [0.30059376]\n",
      " [0.30425611]\n",
      " [0.30205649]\n",
      " [0.30242187]\n",
      " [0.30262932]\n",
      " [0.30406189]\n",
      " [0.30489561]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.30638748]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.29539698]\n",
      "  [0.30059376]\n",
      "  [0.30425611]\n",
      "  [0.30205649]\n",
      "  [0.30242187]\n",
      "  [0.30262932]\n",
      "  [0.30406189]\n",
      "  [0.30489561]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019224383868277073\n",
      "Predicción post entrenamiento : [[0.30523938]]\n",
      "PERDIDAAAA despues: 0.00016172458708751947\n",
      "loss en el callback: 0.004461746197193861, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.30059376]\n",
      " [0.30425611]\n",
      " [0.30205649]\n",
      " [0.30242187]\n",
      " [0.30262932]\n",
      " [0.30406189]\n",
      " [0.30489561]\n",
      " [0.30638748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.3066529]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.30059376]\n",
      "  [0.30425611]\n",
      "  [0.30205649]\n",
      "  [0.30242187]\n",
      "  [0.30262932]\n",
      "  [0.30406189]\n",
      "  [0.30489561]\n",
      "  [0.30638748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000122177938465029\n",
      "Predicción post entrenamiento : [[0.30657077]]\n",
      "PERDIDAAAA despues: 0.0001240004348801449\n",
      "loss en el callback: 2.847529685823247e-05, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.30425611]\n",
      " [0.30205649]\n",
      " [0.30242187]\n",
      " [0.30262932]\n",
      " [0.30406189]\n",
      " [0.30489561]\n",
      " [0.30638748]\n",
      " [0.3066529 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.30712548]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.30425611]\n",
      "  [0.30205649]\n",
      "  [0.30242187]\n",
      "  [0.30262932]\n",
      "  [0.30406189]\n",
      "  [0.30489561]\n",
      "  [0.30638748]\n",
      "  [0.3066529 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.0736340704606846e-05\n",
      "Predicción post entrenamiento : [[0.30700442]]\n",
      "PERDIDAAAA despues: 3.209328497177921e-05\n",
      "loss en el callback: 6.7700537329074e-05, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.30205649]\n",
      " [0.30242187]\n",
      " [0.30262932]\n",
      " [0.30406189]\n",
      " [0.30489561]\n",
      " [0.30638748]\n",
      " [0.3066529 ]\n",
      " [0.30712548]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.30689624]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.30205649]\n",
      "  [0.30242187]\n",
      "  [0.30262932]\n",
      "  [0.30406189]\n",
      "  [0.30489561]\n",
      "  [0.30638748]\n",
      "  [0.3066529 ]\n",
      "  [0.30712548]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003190145653206855\n",
      "Predicción post entrenamiento : [[0.30611494]]\n",
      "PERDIDAAAA despues: 0.00029171552159823477\n",
      "loss en el callback: 0.0026064105331897736, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.30242187]\n",
      " [0.30262932]\n",
      " [0.30406189]\n",
      " [0.30489561]\n",
      " [0.30638748]\n",
      " [0.3066529 ]\n",
      " [0.30712548]\n",
      " [0.30689624]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.3065674]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.30242187]\n",
      "  [0.30262932]\n",
      "  [0.30406189]\n",
      "  [0.30489561]\n",
      "  [0.30638748]\n",
      "  [0.3066529 ]\n",
      "  [0.30712548]\n",
      "  [0.30689624]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005631741951219738\n",
      "Predicción post entrenamiento : [[0.3065177]]\n",
      "PERDIDAAAA despues: 0.0005608173087239265\n",
      "loss en el callback: 1.7236876374226995e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.30262932]\n",
      " [0.30406189]\n",
      " [0.30489561]\n",
      " [0.30638748]\n",
      " [0.3066529 ]\n",
      " [0.30712548]\n",
      " [0.30689624]\n",
      " [0.3065674 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30704203]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.30262932]\n",
      "  [0.30406189]\n",
      "  [0.30489561]\n",
      "  [0.30638748]\n",
      "  [0.3066529 ]\n",
      "  [0.30712548]\n",
      "  [0.30689624]\n",
      "  [0.3065674 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.693773346138187e-05\n",
      "Predicción post entrenamiento : [[0.30705914]]\n",
      "PERDIDAAAA despues: 5.7196186389774084e-05\n",
      "loss en el callback: 1.9017592194359167e-06, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.30406189]\n",
      " [0.30489561]\n",
      " [0.30638748]\n",
      " [0.3066529 ]\n",
      " [0.30712548]\n",
      " [0.30689624]\n",
      " [0.3065674 ]\n",
      " [0.30704203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30768728]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.30406189]\n",
      "  [0.30489561]\n",
      "  [0.30638748]\n",
      "  [0.3066529 ]\n",
      "  [0.30712548]\n",
      "  [0.30689624]\n",
      "  [0.3065674 ]\n",
      "  [0.30704203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010128442663699389\n",
      "Predicción post entrenamiento : [[0.3077568]]\n",
      "PERDIDAAAA despues: 0.0010172746842727065\n",
      "loss en el callback: 4.502840238274075e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.30489561]\n",
      " [0.30638748]\n",
      " [0.3066529 ]\n",
      " [0.30712548]\n",
      " [0.30689624]\n",
      " [0.3065674 ]\n",
      " [0.30704203]\n",
      " [0.30768728]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.3082114]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.30489561]\n",
      "  [0.30638748]\n",
      "  [0.3066529 ]\n",
      "  [0.30712548]\n",
      "  [0.30689624]\n",
      "  [0.3065674 ]\n",
      "  [0.30704203]\n",
      "  [0.30768728]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011230319505557418\n",
      "Predicción post entrenamiento : [[0.3074824]]\n",
      "PERDIDAAAA despues: 0.0010747037595137954\n",
      "loss en el callback: 0.0034813324455171824, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.30638748]\n",
      " [0.3066529 ]\n",
      " [0.30712548]\n",
      " [0.30689624]\n",
      " [0.3065674 ]\n",
      " [0.30704203]\n",
      " [0.30768728]\n",
      " [0.30821139]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30785686]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.30638748]\n",
      "  [0.3066529 ]\n",
      "  [0.30712548]\n",
      "  [0.30689624]\n",
      "  [0.3065674 ]\n",
      "  [0.30704203]\n",
      "  [0.30768728]\n",
      "  [0.30821139]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010486100800335407\n",
      "Predicción post entrenamiento : [[0.30770144]]\n",
      "PERDIDAAAA despues: 0.0010385686764493585\n",
      "loss en el callback: 0.00020138030231464654, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.3066529 ]\n",
      " [0.30712548]\n",
      " [0.30689624]\n",
      " [0.3065674 ]\n",
      " [0.30704203]\n",
      " [0.30768728]\n",
      " [0.30821139]\n",
      " [0.30785686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3078254]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.3066529 ]\n",
      "  [0.30712548]\n",
      "  [0.30689624]\n",
      "  [0.3065674 ]\n",
      "  [0.30704203]\n",
      "  [0.30768728]\n",
      "  [0.30821139]\n",
      "  [0.30785686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007251480710692704\n",
      "Predicción post entrenamiento : [[0.30781874]]\n",
      "PERDIDAAAA despues: 0.0007255060481838882\n",
      "loss en el callback: 3.032236861599813e-07, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.30712548]\n",
      " [0.30689624]\n",
      " [0.3065674 ]\n",
      " [0.30704203]\n",
      " [0.30768728]\n",
      " [0.30821139]\n",
      " [0.30785686]\n",
      " [0.30782539]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.30792475]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.30712548]\n",
      "  [0.30689624]\n",
      "  [0.3065674 ]\n",
      "  [0.30704203]\n",
      "  [0.30768728]\n",
      "  [0.30821139]\n",
      "  [0.30785686]\n",
      "  [0.30782539]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002280190121382475\n",
      "Predicción post entrenamiento : [[0.30842084]]\n",
      "PERDIDAAAA despues: 0.0022330584470182657\n",
      "loss en el callback: 0.0021677855402231216, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.30689624]\n",
      " [0.3065674 ]\n",
      " [0.30704203]\n",
      " [0.30768728]\n",
      " [0.30821139]\n",
      " [0.30785686]\n",
      " [0.30782539]\n",
      " [0.30792475]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30845878]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.30689624]\n",
      "  [0.3065674 ]\n",
      "  [0.30704203]\n",
      "  [0.30768728]\n",
      "  [0.30821139]\n",
      "  [0.30785686]\n",
      "  [0.30782539]\n",
      "  [0.30792475]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007970698643475771\n",
      "Predicción post entrenamiento : [[0.3087791]]\n",
      "PERDIDAAAA despues: 0.0007790859090164304\n",
      "loss en el callback: 0.0008926622685976326, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.3065674 ]\n",
      " [0.30704203]\n",
      " [0.30768728]\n",
      " [0.30821139]\n",
      " [0.30785686]\n",
      " [0.30782539]\n",
      " [0.30792475]\n",
      " [0.30845878]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.308898]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.3065674 ]\n",
      "  [0.30704203]\n",
      "  [0.30768728]\n",
      "  [0.30821139]\n",
      "  [0.30785686]\n",
      "  [0.30782539]\n",
      "  [0.30792475]\n",
      "  [0.30845878]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000609775772318244\n",
      "Predicción post entrenamiento : [[0.30915684]]\n",
      "PERDIDAAAA despues: 0.000597059668507427\n",
      "loss en el callback: 0.0006372654461301863, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30704203]\n",
      " [0.30768728]\n",
      " [0.30821139]\n",
      " [0.30785686]\n",
      " [0.30782539]\n",
      " [0.30792475]\n",
      " [0.30845878]\n",
      " [0.308898  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.30939397]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30704203]\n",
      "  [0.30768728]\n",
      "  [0.30821139]\n",
      "  [0.30785686]\n",
      "  [0.30782539]\n",
      "  [0.30792475]\n",
      "  [0.30845878]\n",
      "  [0.308898  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005676210392266512\n",
      "Predicción post entrenamiento : [[0.31023493]]\n",
      "PERDIDAAAA despues: 0.005550200119614601\n",
      "loss en el callback: 0.007445373106747866, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30768728]\n",
      " [0.30821139]\n",
      " [0.30785686]\n",
      " [0.30782539]\n",
      " [0.30792475]\n",
      " [0.30845878]\n",
      " [0.308898  ]\n",
      " [0.30939397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.3104282]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30768728]\n",
      "  [0.30821139]\n",
      "  [0.30785686]\n",
      "  [0.30782539]\n",
      "  [0.30792475]\n",
      "  [0.30845878]\n",
      "  [0.308898  ]\n",
      "  [0.30939397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06794795393943787\n",
      "Predicción post entrenamiento : [[0.31289002]]\n",
      "PERDIDAAAA despues: 0.06667057424783707\n",
      "loss en el callback: 0.0569995753467083, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30821139]\n",
      " [0.30785686]\n",
      " [0.30782539]\n",
      " [0.30792475]\n",
      " [0.30845878]\n",
      " [0.308898  ]\n",
      " [0.30939397]\n",
      " [0.3104282 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.3129983]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30821139]\n",
      "  [0.30785686]\n",
      "  [0.30782539]\n",
      "  [0.30792475]\n",
      "  [0.30845878]\n",
      "  [0.308898  ]\n",
      "  [0.30939397]\n",
      "  [0.3104282 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08024881780147552\n",
      "Predicción post entrenamiento : [[0.31565022]]\n",
      "PERDIDAAAA despues: 0.07875335961580276\n",
      "loss en el callback: 0.07259945571422577, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30785686]\n",
      " [0.30782539]\n",
      " [0.30792475]\n",
      " [0.30845878]\n",
      " [0.308898  ]\n",
      " [0.30939397]\n",
      " [0.3104282 ]\n",
      " [0.31299829]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3157063]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30785686]\n",
      "  [0.30782539]\n",
      "  [0.30792475]\n",
      "  [0.30845878]\n",
      "  [0.308898  ]\n",
      "  [0.30939397]\n",
      "  [0.3104282 ]\n",
      "  [0.31299829]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06701738387346268\n",
      "Predicción post entrenamiento : [[0.31809512]]\n",
      "PERDIDAAAA despues: 0.06578627228736877\n",
      "loss en el callback: 0.06470291316509247, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30782539]\n",
      " [0.30792475]\n",
      " [0.30845878]\n",
      " [0.308898  ]\n",
      " [0.30939397]\n",
      " [0.3104282 ]\n",
      " [0.31299829]\n",
      " [0.31570631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.31832543]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30782539]\n",
      "  [0.30792475]\n",
      "  [0.30845878]\n",
      "  [0.308898  ]\n",
      "  [0.30939397]\n",
      "  [0.3104282 ]\n",
      "  [0.31299829]\n",
      "  [0.31570631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08296052366495132\n",
      "Predicción post entrenamiento : [[0.3208271]]\n",
      "PERDIDAAAA despues: 0.08152567595243454\n",
      "loss en el callback: 0.07547188550233841, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30792475]\n",
      " [0.30845878]\n",
      " [0.308898  ]\n",
      " [0.30939397]\n",
      " [0.3104282 ]\n",
      " [0.31299829]\n",
      " [0.31570631]\n",
      " [0.31832543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3212309]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30792475]\n",
      "  [0.30845878]\n",
      "  [0.308898  ]\n",
      "  [0.30939397]\n",
      "  [0.3104282 ]\n",
      "  [0.31299829]\n",
      "  [0.31570631]\n",
      "  [0.31832543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06939338892698288\n",
      "Predicción post entrenamiento : [[0.32325375]]\n",
      "PERDIDAAAA despues: 0.06833172589540482\n",
      "loss en el callback: 0.039223361760377884, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30845878]\n",
      " [0.308898  ]\n",
      " [0.30939397]\n",
      " [0.3104282 ]\n",
      " [0.31299829]\n",
      " [0.31570631]\n",
      " [0.31832543]\n",
      " [0.32123089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3238779]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30845878]\n",
      "  [0.308898  ]\n",
      "  [0.30939397]\n",
      "  [0.3104282 ]\n",
      "  [0.31299829]\n",
      "  [0.31570631]\n",
      "  [0.31832543]\n",
      "  [0.32123089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059973012655973434\n",
      "Predicción post entrenamiento : [[0.32607475]]\n",
      "PERDIDAAAA despues: 0.05890185013413429\n",
      "loss en el callback: 0.06702548265457153, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.308898  ]\n",
      " [0.30939397]\n",
      " [0.3104282 ]\n",
      " [0.31299829]\n",
      " [0.31570631]\n",
      " [0.31832543]\n",
      " [0.32123089]\n",
      " [0.3238779 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32690373]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.308898  ]\n",
      "  [0.30939397]\n",
      "  [0.3104282 ]\n",
      "  [0.31299829]\n",
      "  [0.31570631]\n",
      "  [0.31832543]\n",
      "  [0.32123089]\n",
      "  [0.3238779 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09977409243583679\n",
      "Predicción post entrenamiento : [[0.3292027]]\n",
      "PERDIDAAAA despues: 0.09832701832056046\n",
      "loss en el callback: 0.049422863870859146, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.30939397]\n",
      " [0.3104282 ]\n",
      " [0.31299829]\n",
      " [0.31570631]\n",
      " [0.31832543]\n",
      " [0.32123089]\n",
      " [0.3238779 ]\n",
      " [0.32690373]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3303362]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.30939397]\n",
      "  [0.3104282 ]\n",
      "  [0.31299829]\n",
      "  [0.31570631]\n",
      "  [0.31832543]\n",
      "  [0.32123089]\n",
      "  [0.3238779 ]\n",
      "  [0.32690373]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10984107851982117\n",
      "Predicción post entrenamiento : [[0.33289906]]\n",
      "PERDIDAAAA despues: 0.10814887285232544\n",
      "loss en el callback: 0.06729107350111008, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.3104282 ]\n",
      " [0.31299829]\n",
      " [0.31570631]\n",
      " [0.31832543]\n",
      " [0.32123089]\n",
      " [0.3238779 ]\n",
      " [0.32690373]\n",
      " [0.33033621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33441278]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.3104282 ]\n",
      "  [0.31299829]\n",
      "  [0.31570631]\n",
      "  [0.31832543]\n",
      "  [0.32123089]\n",
      "  [0.3238779 ]\n",
      "  [0.32690373]\n",
      "  [0.33033621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11463789641857147\n",
      "Predicción post entrenamiento : [[0.33711806]]\n",
      "PERDIDAAAA despues: 0.112813301384449\n",
      "loss en el callback: 0.10228482633829117, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.31299829]\n",
      " [0.31570631]\n",
      " [0.31832543]\n",
      " [0.32123089]\n",
      " [0.3238779 ]\n",
      " [0.32690373]\n",
      " [0.33033621]\n",
      " [0.33441278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.33898258]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.31299829]\n",
      "  [0.31570631]\n",
      "  [0.31832543]\n",
      "  [0.32123089]\n",
      "  [0.3238779 ]\n",
      "  [0.32690373]\n",
      "  [0.33033621]\n",
      "  [0.33441278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13808263838291168\n",
      "Predicción post entrenamiento : [[0.34188366]]\n",
      "PERDIDAAAA despues: 0.1359350085258484\n",
      "loss en el callback: 0.11942354589700699, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31570631]\n",
      " [0.31832543]\n",
      " [0.32123089]\n",
      " [0.3238779 ]\n",
      " [0.32690373]\n",
      " [0.33033621]\n",
      " [0.33441278]\n",
      " [0.33898258]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34382975]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31570631]\n",
      "  [0.31832543]\n",
      "  [0.32123089]\n",
      "  [0.3238779 ]\n",
      "  [0.32690373]\n",
      "  [0.33033621]\n",
      "  [0.33441278]\n",
      "  [0.33898258]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1297159045934677\n",
      "Predicción post entrenamiento : [[0.3465502]]\n",
      "PERDIDAAAA despues: 0.12776371836662292\n",
      "loss en el callback: 0.1003054827451706, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31832543]\n",
      " [0.32123089]\n",
      " [0.3238779 ]\n",
      " [0.32690373]\n",
      " [0.33033621]\n",
      " [0.33441278]\n",
      " [0.33898258]\n",
      " [0.34382975]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34859046]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31832543]\n",
      "  [0.32123089]\n",
      "  [0.3238779 ]\n",
      "  [0.32690373]\n",
      "  [0.33033621]\n",
      "  [0.33441278]\n",
      "  [0.33898258]\n",
      "  [0.34382975]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14337359368801117\n",
      "Predicción post entrenamiento : [[0.35149458]]\n",
      "PERDIDAAAA despues: 0.1411827653646469\n",
      "loss en el callback: 0.12850134074687958, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32123089]\n",
      " [0.3238779 ]\n",
      " [0.32690373]\n",
      " [0.33033621]\n",
      " [0.33441278]\n",
      " [0.33898258]\n",
      " [0.34382975]\n",
      " [0.34859046]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3537031]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32123089]\n",
      "  [0.3238779 ]\n",
      "  [0.32690373]\n",
      "  [0.33033621]\n",
      "  [0.33441278]\n",
      "  [0.33898258]\n",
      "  [0.34382975]\n",
      "  [0.34859046]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1360761523246765\n",
      "Predicción post entrenamiento : [[0.35641435]]\n",
      "PERDIDAAAA despues: 0.13408322632312775\n",
      "loss en el callback: 0.1769055873155594, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.3238779 ]\n",
      " [0.32690373]\n",
      " [0.33033621]\n",
      " [0.33441278]\n",
      " [0.33898258]\n",
      " [0.34382975]\n",
      " [0.34859046]\n",
      " [0.35370311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.358793]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.3238779 ]\n",
      "  [0.32690373]\n",
      "  [0.33033621]\n",
      "  [0.33441278]\n",
      "  [0.33898258]\n",
      "  [0.34382975]\n",
      "  [0.34859046]\n",
      "  [0.35370311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1705697476863861\n",
      "Predicción post entrenamiento : [[0.3618898]]\n",
      "PERDIDAAAA despues: 0.16802136600017548\n",
      "loss en el callback: 0.17332172393798828, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32690373]\n",
      " [0.33033621]\n",
      " [0.33441278]\n",
      " [0.33898258]\n",
      " [0.34382975]\n",
      " [0.34859046]\n",
      " [0.35370311]\n",
      " [0.35879299]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36456907]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32690373]\n",
      "  [0.33033621]\n",
      "  [0.33441278]\n",
      "  [0.33898258]\n",
      "  [0.34382975]\n",
      "  [0.34859046]\n",
      "  [0.35370311]\n",
      "  [0.35879299]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12956856191158295\n",
      "Predicción post entrenamiento : [[0.3671761]]\n",
      "PERDIDAAAA despues: 0.12769852578639984\n",
      "loss en el callback: 0.11475013196468353, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33033621]\n",
      " [0.33441278]\n",
      " [0.33898258]\n",
      " [0.34382975]\n",
      " [0.34859046]\n",
      " [0.35370311]\n",
      " [0.35879299]\n",
      " [0.36456907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37015402]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33033621]\n",
      "  [0.33441278]\n",
      "  [0.33898258]\n",
      "  [0.34382975]\n",
      "  [0.34859046]\n",
      "  [0.35370311]\n",
      "  [0.35879299]\n",
      "  [0.36456907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09054302424192429\n",
      "Predicción post entrenamiento : [[0.37236068]]\n",
      "PERDIDAAAA despues: 0.08921991288661957\n",
      "loss en el callback: 0.10292398184537888, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33441278]\n",
      " [0.33898258]\n",
      " [0.34382975]\n",
      " [0.34859046]\n",
      " [0.35370311]\n",
      " [0.35879299]\n",
      " [0.36456907]\n",
      " [0.37015402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.37562203]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33441278]\n",
      "  [0.33898258]\n",
      "  [0.34382975]\n",
      "  [0.34859046]\n",
      "  [0.35370311]\n",
      "  [0.35879299]\n",
      "  [0.36456907]\n",
      "  [0.37015402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08889210969209671\n",
      "Predicción post entrenamiento : [[0.3777173]]\n",
      "PERDIDAAAA despues: 0.08764711022377014\n",
      "loss en el callback: 0.07366856187582016, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33898258]\n",
      " [0.34382975]\n",
      " [0.34859046]\n",
      " [0.35370311]\n",
      " [0.35879299]\n",
      " [0.36456907]\n",
      " [0.37015402]\n",
      " [0.37562203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3811805]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33898258]\n",
      "  [0.34382975]\n",
      "  [0.34859046]\n",
      "  [0.35370311]\n",
      "  [0.35879299]\n",
      "  [0.36456907]\n",
      "  [0.37015402]\n",
      "  [0.37562203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11106975376605988\n",
      "Predicción post entrenamiento : [[0.38350117]]\n",
      "PERDIDAAAA despues: 0.1095283105969429\n",
      "loss en el callback: 0.11855948716402054, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34382975]\n",
      " [0.34859046]\n",
      " [0.35370311]\n",
      " [0.35879299]\n",
      " [0.36456907]\n",
      " [0.37015402]\n",
      " [0.37562203]\n",
      " [0.3811805 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.38710073]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34382975]\n",
      "  [0.34859046]\n",
      "  [0.35370311]\n",
      "  [0.35879299]\n",
      "  [0.36456907]\n",
      "  [0.37015402]\n",
      "  [0.37562203]\n",
      "  [0.3811805 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1273041069507599\n",
      "Predicción post entrenamiento : [[0.3896256]]\n",
      "PERDIDAAAA despues: 0.12550874054431915\n",
      "loss en el callback: 0.11472208797931671, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.34859046]\n",
      " [0.35370311]\n",
      " [0.35879299]\n",
      " [0.36456907]\n",
      " [0.37015402]\n",
      " [0.37562203]\n",
      " [0.3811805 ]\n",
      " [0.38710073]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.39333344]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.34859046]\n",
      "  [0.35370311]\n",
      "  [0.35879299]\n",
      "  [0.36456907]\n",
      "  [0.37015402]\n",
      "  [0.37562203]\n",
      "  [0.3811805 ]\n",
      "  [0.38710073]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10840865224599838\n",
      "Predicción post entrenamiento : [[0.39539006]]\n",
      "PERDIDAAAA despues: 0.1070585697889328\n",
      "loss en el callback: 0.07143865525722504, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35370311]\n",
      " [0.35879299]\n",
      " [0.36456907]\n",
      " [0.37015402]\n",
      " [0.37562203]\n",
      " [0.3811805 ]\n",
      " [0.38710073]\n",
      " [0.39333344]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.39925924]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35370311]\n",
      "  [0.35879299]\n",
      "  [0.36456907]\n",
      "  [0.37015402]\n",
      "  [0.37562203]\n",
      "  [0.3811805 ]\n",
      "  [0.38710073]\n",
      "  [0.39333344]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09004927426576614\n",
      "Predicción post entrenamiento : [[0.4013123]]\n",
      "PERDIDAAAA despues: 0.08882132172584534\n",
      "loss en el callback: 0.09449134767055511, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.35879299]\n",
      " [0.36456907]\n",
      " [0.37015402]\n",
      " [0.37562203]\n",
      " [0.3811805 ]\n",
      " [0.38710073]\n",
      " [0.39333344]\n",
      " [0.39925924]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.40529773]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.35879299]\n",
      "  [0.36456907]\n",
      "  [0.37015402]\n",
      "  [0.37562203]\n",
      "  [0.3811805 ]\n",
      "  [0.38710073]\n",
      "  [0.39333344]\n",
      "  [0.39925924]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1102328971028328\n",
      "Predicción post entrenamiento : [[0.4075986]]\n",
      "PERDIDAAAA despues: 0.10871034115552902\n",
      "loss en el callback: 0.12537328898906708, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.36456907]\n",
      " [0.37015402]\n",
      " [0.37562203]\n",
      " [0.3811805 ]\n",
      " [0.38710073]\n",
      " [0.39333344]\n",
      " [0.39925924]\n",
      " [0.40529773]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.41173628]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.36456907]\n",
      "  [0.37015402]\n",
      "  [0.37562203]\n",
      "  [0.3811805 ]\n",
      "  [0.38710073]\n",
      "  [0.39333344]\n",
      "  [0.39925924]\n",
      "  [0.40529773]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09590762108564377\n",
      "Predicción post entrenamiento : [[0.41378462]]\n",
      "PERDIDAAAA despues: 0.09464311599731445\n",
      "loss en el callback: 0.09924281388521194, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37015402]\n",
      " [0.37562203]\n",
      " [0.3811805 ]\n",
      " [0.38710073]\n",
      " [0.39333344]\n",
      " [0.39925924]\n",
      " [0.40529773]\n",
      " [0.41173628]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4179422]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37015402]\n",
      "  [0.37562203]\n",
      "  [0.3811805 ]\n",
      "  [0.38710073]\n",
      "  [0.39333344]\n",
      "  [0.39925924]\n",
      "  [0.40529773]\n",
      "  [0.41173628]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09046349674463272\n",
      "Predicción post entrenamiento : [[0.41985646]]\n",
      "PERDIDAAAA despues: 0.08931565284729004\n",
      "loss en el callback: 0.07039348781108856, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.37562203]\n",
      " [0.3811805 ]\n",
      " [0.38710073]\n",
      " [0.39333344]\n",
      " [0.39925924]\n",
      " [0.40529773]\n",
      " [0.41173628]\n",
      " [0.4179422 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.42409357]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.37562203]\n",
      "  [0.3811805 ]\n",
      "  [0.38710073]\n",
      "  [0.39333344]\n",
      "  [0.39925924]\n",
      "  [0.40529773]\n",
      "  [0.41173628]\n",
      "  [0.4179422 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06253188103437424\n",
      "Predicción post entrenamiento : [[0.42591947]]\n",
      "PERDIDAAAA despues: 0.06162203103303909\n",
      "loss en el callback: 0.09664279967546463, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.3811805 ]\n",
      " [0.38710073]\n",
      " [0.39333344]\n",
      " [0.39925924]\n",
      " [0.40529773]\n",
      " [0.41173628]\n",
      " [0.4179422 ]\n",
      " [0.42409357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.43028796]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.3811805 ]\n",
      "  [0.38710073]\n",
      "  [0.39333344]\n",
      "  [0.39925924]\n",
      "  [0.40529773]\n",
      "  [0.41173628]\n",
      "  [0.4179422 ]\n",
      "  [0.42409357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07197334617376328\n",
      "Predicción post entrenamiento : [[0.43218192]]\n",
      "PERDIDAAAA despues: 0.07096070796251297\n",
      "loss en el callback: 0.12431001663208008, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.38710073]\n",
      " [0.39333344]\n",
      " [0.39925924]\n",
      " [0.40529773]\n",
      " [0.41173628]\n",
      " [0.4179422 ]\n",
      " [0.42409357]\n",
      " [0.43028796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.43668798]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.38710073]\n",
      "  [0.39333344]\n",
      "  [0.39925924]\n",
      "  [0.40529773]\n",
      "  [0.41173628]\n",
      "  [0.4179422 ]\n",
      "  [0.42409357]\n",
      "  [0.43028796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08085513114929199\n",
      "Predicción post entrenamiento : [[0.43797195]]\n",
      "PERDIDAAAA despues: 0.08012658357620239\n",
      "loss en el callback: 0.027139119803905487, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.39333344]\n",
      " [0.39925924]\n",
      " [0.40529773]\n",
      " [0.41173628]\n",
      " [0.4179422 ]\n",
      " [0.42409357]\n",
      " [0.43028796]\n",
      " [0.43668798]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4425502]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.39333344]\n",
      "  [0.39925924]\n",
      "  [0.40529773]\n",
      "  [0.41173628]\n",
      "  [0.4179422 ]\n",
      "  [0.42409357]\n",
      "  [0.43028796]\n",
      "  [0.43668798]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0784212276339531\n",
      "Predicción post entrenamiento : [[0.4443581]]\n",
      "PERDIDAAAA despues: 0.0774119421839714\n",
      "loss en el callback: 0.07230085134506226, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.39925924]\n",
      " [0.40529773]\n",
      " [0.41173628]\n",
      " [0.4179422 ]\n",
      " [0.42409357]\n",
      " [0.43028796]\n",
      " [0.43668798]\n",
      " [0.44255021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.44894284]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.39925924]\n",
      "  [0.40529773]\n",
      "  [0.41173628]\n",
      "  [0.4179422 ]\n",
      "  [0.42409357]\n",
      "  [0.43028796]\n",
      "  [0.43668798]\n",
      "  [0.44255021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09446598589420319\n",
      "Predicción post entrenamiento : [[0.45090222]]\n",
      "PERDIDAAAA despues: 0.09326538443565369\n",
      "loss en el callback: 0.10371065884828568, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.40529773]\n",
      " [0.41173628]\n",
      " [0.4179422 ]\n",
      " [0.42409357]\n",
      " [0.43028796]\n",
      " [0.43668798]\n",
      " [0.44255021]\n",
      " [0.44894284]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.45557064]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.40529773]\n",
      "  [0.41173628]\n",
      "  [0.4179422 ]\n",
      "  [0.42409357]\n",
      "  [0.43028796]\n",
      "  [0.43668798]\n",
      "  [0.44255021]\n",
      "  [0.44894284]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13839560747146606\n",
      "Predicción post entrenamiento : [[0.45796734]]\n",
      "PERDIDAAAA despues: 0.13661812245845795\n",
      "loss en el callback: 0.15320411324501038, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.41173628]\n",
      " [0.4179422 ]\n",
      " [0.42409357]\n",
      " [0.43028796]\n",
      " [0.43668798]\n",
      " [0.44255021]\n",
      " [0.44894284]\n",
      " [0.45557064]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.4627048]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.41173628]\n",
      "  [0.4179422 ]\n",
      "  [0.42409357]\n",
      "  [0.43028796]\n",
      "  [0.43668798]\n",
      "  [0.44255021]\n",
      "  [0.44894284]\n",
      "  [0.45557064]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14146427810192108\n",
      "Predicción post entrenamiento : [[0.46513727]]\n",
      "PERDIDAAAA despues: 0.1396404206752777\n",
      "loss en el callback: 0.1877322793006897, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.4179422 ]\n",
      " [0.42409357]\n",
      " [0.43028796]\n",
      " [0.43668798]\n",
      " [0.44255021]\n",
      " [0.44894284]\n",
      " [0.45557064]\n",
      " [0.46270481]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.46985668]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.4179422 ]\n",
      "  [0.42409357]\n",
      "  [0.43028796]\n",
      "  [0.43668798]\n",
      "  [0.44255021]\n",
      "  [0.44894284]\n",
      "  [0.45557064]\n",
      "  [0.46270481]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10524128377437592\n",
      "Predicción post entrenamiento : [[0.47202054]]\n",
      "PERDIDAAAA despues: 0.10384201258420944\n",
      "loss en el callback: 0.13227546215057373, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.42409357]\n",
      " [0.43028796]\n",
      " [0.43668798]\n",
      " [0.44255021]\n",
      " [0.44894284]\n",
      " [0.45557064]\n",
      " [0.46270481]\n",
      " [0.46985668]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.47678635]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.42409357]\n",
      "  [0.43028796]\n",
      "  [0.43668798]\n",
      "  [0.44255021]\n",
      "  [0.44894284]\n",
      "  [0.45557064]\n",
      "  [0.46270481]\n",
      "  [0.46985668]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09426028281450272\n",
      "Predicción post entrenamiento : [[0.47870654]]\n",
      "PERDIDAAAA despues: 0.0930848941206932\n",
      "loss en el callback: 0.09890343248844147, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.43028796]\n",
      " [0.43668798]\n",
      " [0.44255021]\n",
      " [0.44894284]\n",
      " [0.45557064]\n",
      " [0.46270481]\n",
      " [0.46985668]\n",
      " [0.47678635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.48355407]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.43028796]\n",
      "  [0.43668798]\n",
      "  [0.44255021]\n",
      "  [0.44894284]\n",
      "  [0.45557064]\n",
      "  [0.46270481]\n",
      "  [0.46985668]\n",
      "  [0.47678635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08086365461349487\n",
      "Predicción post entrenamiento : [[0.48528457]]\n",
      "PERDIDAAAA despues: 0.07988245785236359\n",
      "loss en el callback: 0.07908163219690323, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.43668798]\n",
      " [0.44255021]\n",
      " [0.44894284]\n",
      " [0.45557064]\n",
      " [0.46270481]\n",
      " [0.46985668]\n",
      " [0.47678635]\n",
      " [0.48355407]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.4902308]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.43668798]\n",
      "  [0.44255021]\n",
      "  [0.44894284]\n",
      "  [0.45557064]\n",
      "  [0.46270481]\n",
      "  [0.46985668]\n",
      "  [0.47678635]\n",
      "  [0.48355407]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08664123713970184\n",
      "Predicción post entrenamiento : [[0.49214786]]\n",
      "PERDIDAAAA despues: 0.08551634103059769\n",
      "loss en el callback: 0.10562968254089355, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.44255021]\n",
      " [0.44894284]\n",
      " [0.45557064]\n",
      " [0.46270481]\n",
      " [0.46985668]\n",
      " [0.47678635]\n",
      " [0.48355407]\n",
      " [0.4902308 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.497169]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.44255021]\n",
      "  [0.44894284]\n",
      "  [0.45557064]\n",
      "  [0.46270481]\n",
      "  [0.46985668]\n",
      "  [0.47678635]\n",
      "  [0.48355407]\n",
      "  [0.4902308 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14558817446231842\n",
      "Predicción post entrenamiento : [[0.49956393]]\n",
      "PERDIDAAAA despues: 0.14376626908779144\n",
      "loss en el callback: 0.159461110830307, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.44894284]\n",
      " [0.45557064]\n",
      " [0.46270481]\n",
      " [0.46985668]\n",
      " [0.47678635]\n",
      " [0.48355407]\n",
      " [0.4902308 ]\n",
      " [0.49716899]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.50482243]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.44894284]\n",
      "  [0.45557064]\n",
      "  [0.46270481]\n",
      "  [0.46985668]\n",
      "  [0.47678635]\n",
      "  [0.48355407]\n",
      "  [0.4902308 ]\n",
      "  [0.49716899]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13749796152114868\n",
      "Predicción post entrenamiento : [[0.50704074]]\n",
      "PERDIDAAAA despues: 0.1358577460050583\n",
      "loss en el callback: 0.1434774547815323, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.45557064]\n",
      " [0.46270481]\n",
      " [0.46985668]\n",
      " [0.47678635]\n",
      " [0.48355407]\n",
      " [0.4902308 ]\n",
      " [0.49716899]\n",
      " [0.50482243]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.51244366]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.45557064]\n",
      "  [0.46270481]\n",
      "  [0.46985668]\n",
      "  [0.47678635]\n",
      "  [0.48355407]\n",
      "  [0.4902308 ]\n",
      "  [0.49716899]\n",
      "  [0.50482243]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11320003122091293\n",
      "Predicción post entrenamiento : [[0.5145711]]\n",
      "PERDIDAAAA despues: 0.11177301406860352\n",
      "loss en el callback: 0.14684869349002838, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.46270481]\n",
      " [0.46985668]\n",
      " [0.47678635]\n",
      " [0.48355407]\n",
      " [0.4902308 ]\n",
      " [0.49716899]\n",
      " [0.50482243]\n",
      " [0.51244366]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5200851]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.46270481]\n",
      "  [0.46985668]\n",
      "  [0.47678635]\n",
      "  [0.48355407]\n",
      "  [0.4902308 ]\n",
      "  [0.49716899]\n",
      "  [0.50482243]\n",
      "  [0.51244366]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08892466872930527\n",
      "Predicción post entrenamiento : [[0.5220077]]\n",
      "PERDIDAAAA despues: 0.08778171241283417\n",
      "loss en el callback: 0.11621982604265213, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.46985668]\n",
      " [0.47678635]\n",
      " [0.48355407]\n",
      " [0.4902308 ]\n",
      " [0.49716899]\n",
      " [0.50482243]\n",
      " [0.51244366]\n",
      " [0.5200851 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.52752405]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.46985668]\n",
      "  [0.47678635]\n",
      "  [0.48355407]\n",
      "  [0.4902308 ]\n",
      "  [0.49716899]\n",
      "  [0.50482243]\n",
      "  [0.51244366]\n",
      "  [0.5200851 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08957286179065704\n",
      "Predicción post entrenamiento : [[0.5295156]]\n",
      "PERDIDAAAA despues: 0.0883847251534462\n",
      "loss en el callback: 0.1640053540468216, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.47678635]\n",
      " [0.48355407]\n",
      " [0.4902308 ]\n",
      " [0.49716899]\n",
      " [0.50482243]\n",
      " [0.51244366]\n",
      " [0.5200851 ]\n",
      " [0.52752405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.53503954]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.47678635]\n",
      "  [0.48355407]\n",
      "  [0.4902308 ]\n",
      "  [0.49716899]\n",
      "  [0.50482243]\n",
      "  [0.51244366]\n",
      "  [0.5200851 ]\n",
      "  [0.52752405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06265757232904434\n",
      "Predicción post entrenamiento : [[0.5363957]]\n",
      "PERDIDAAAA despues: 0.0619804672896862\n",
      "loss en el callback: 0.04442143440246582, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.48355407]\n",
      " [0.4902308 ]\n",
      " [0.49716899]\n",
      " [0.50482243]\n",
      " [0.51244366]\n",
      " [0.5200851 ]\n",
      " [0.52752405]\n",
      " [0.53503954]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5419984]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.48355407]\n",
      "  [0.4902308 ]\n",
      "  [0.49716899]\n",
      "  [0.50482243]\n",
      "  [0.51244366]\n",
      "  [0.5200851 ]\n",
      "  [0.52752405]\n",
      "  [0.53503954]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061122965067625046\n",
      "Predicción post entrenamiento : [[0.54353714]]\n",
      "PERDIDAAAA despues: 0.06036447733640671\n",
      "loss en el callback: 0.08477313071489334, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.4902308 ]\n",
      " [0.49716899]\n",
      " [0.50482243]\n",
      " [0.51244366]\n",
      " [0.5200851 ]\n",
      " [0.52752405]\n",
      " [0.53503954]\n",
      " [0.54199839]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5492855]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.4902308 ]\n",
      "  [0.49716899]\n",
      "  [0.50482243]\n",
      "  [0.51244366]\n",
      "  [0.5200851 ]\n",
      "  [0.52752405]\n",
      "  [0.53503954]\n",
      "  [0.54199839]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0811607837677002\n",
      "Predicción post entrenamiento : [[0.5509991]]\n",
      "PERDIDAAAA despues: 0.08018733561038971\n",
      "loss en el callback: 0.0923055112361908, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.49716899]\n",
      " [0.50482243]\n",
      " [0.51244366]\n",
      " [0.5200851 ]\n",
      " [0.52752405]\n",
      " [0.53503954]\n",
      " [0.54199839]\n",
      " [0.54928547]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.55694556]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.49716899]\n",
      "  [0.50482243]\n",
      "  [0.51244366]\n",
      "  [0.5200851 ]\n",
      "  [0.52752405]\n",
      "  [0.53503954]\n",
      "  [0.54199839]\n",
      "  [0.54928547]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06529570370912552\n",
      "Predicción post entrenamiento : [[0.55836546]]\n",
      "PERDIDAAAA despues: 0.06457206606864929\n",
      "loss en el callback: 0.06314260512590408, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.50482243]\n",
      " [0.51244366]\n",
      " [0.5200851 ]\n",
      " [0.52752405]\n",
      " [0.53503954]\n",
      " [0.54199839]\n",
      " [0.54928547]\n",
      " [0.55694556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.56446844]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.50482243]\n",
      "  [0.51244366]\n",
      "  [0.5200851 ]\n",
      "  [0.52752405]\n",
      "  [0.53503954]\n",
      "  [0.54199839]\n",
      "  [0.54928547]\n",
      "  [0.55694556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05606069788336754\n",
      "Predicción post entrenamiento : [[0.5655118]]\n",
      "PERDIDAAAA despues: 0.055567700415849686\n",
      "loss en el callback: 0.025477437302470207, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.51244366]\n",
      " [0.5200851 ]\n",
      " [0.52752405]\n",
      " [0.53503954]\n",
      " [0.54199839]\n",
      " [0.54928547]\n",
      " [0.55694556]\n",
      " [0.56446844]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.57159513]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.51244366]\n",
      "  [0.5200851 ]\n",
      "  [0.52752405]\n",
      "  [0.53503954]\n",
      "  [0.54199839]\n",
      "  [0.54928547]\n",
      "  [0.55694556]\n",
      "  [0.56446844]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05363018810749054\n",
      "Predicción post entrenamiento : [[0.57290226]]\n",
      "PERDIDAAAA despues: 0.053026482462882996\n",
      "loss en el callback: 0.05219503864645958, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.5200851 ]\n",
      " [0.52752405]\n",
      " [0.53503954]\n",
      " [0.54199839]\n",
      " [0.54928547]\n",
      " [0.55694556]\n",
      " [0.56446844]\n",
      " [0.57159513]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.5789627]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.5200851 ]\n",
      "  [0.52752405]\n",
      "  [0.53503954]\n",
      "  [0.54199839]\n",
      "  [0.54928547]\n",
      "  [0.55694556]\n",
      "  [0.56446844]\n",
      "  [0.57159513]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04602234810590744\n",
      "Predicción post entrenamiento : [[0.5797301]]\n",
      "PERDIDAAAA despues: 0.04569367691874504\n",
      "loss en el callback: 0.014510691165924072, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.52752405]\n",
      " [0.53503954]\n",
      " [0.54199839]\n",
      " [0.54928547]\n",
      " [0.55694556]\n",
      " [0.56446844]\n",
      " [0.57159513]\n",
      " [0.57896268]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.5857485]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.52752405]\n",
      "  [0.53503954]\n",
      "  [0.54199839]\n",
      "  [0.54928547]\n",
      "  [0.55694556]\n",
      "  [0.56446844]\n",
      "  [0.57159513]\n",
      "  [0.57896268]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03042302280664444\n",
      "Predicción post entrenamiento : [[0.5869313]]\n",
      "PERDIDAAAA despues: 0.03001181036233902\n",
      "loss en el callback: 0.048956334590911865, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.53503954]\n",
      " [0.54199839]\n",
      " [0.54928547]\n",
      " [0.55694556]\n",
      " [0.56446844]\n",
      " [0.57159513]\n",
      " [0.57896268]\n",
      " [0.58574849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.59294957]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.53503954]\n",
      "  [0.54199839]\n",
      "  [0.54928547]\n",
      "  [0.55694556]\n",
      "  [0.56446844]\n",
      "  [0.57159513]\n",
      "  [0.57896268]\n",
      "  [0.58574849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02028469368815422\n",
      "Predicción post entrenamiento : [[0.5933752]]\n",
      "PERDIDAAAA despues: 0.020163632929325104\n",
      "loss en el callback: 0.004513029474765062, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.54199839]\n",
      " [0.54928547]\n",
      " [0.55694556]\n",
      " [0.56446844]\n",
      " [0.57159513]\n",
      " [0.57896268]\n",
      " [0.58574849]\n",
      " [0.59294957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.5993611]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.54199839]\n",
      "  [0.54928547]\n",
      "  [0.55694556]\n",
      "  [0.56446844]\n",
      "  [0.57159513]\n",
      "  [0.57896268]\n",
      "  [0.58574849]\n",
      "  [0.59294957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01228300016373396\n",
      "Predicción post entrenamiento : [[0.6002325]]\n",
      "PERDIDAAAA despues: 0.012090615928173065\n",
      "loss en el callback: 0.030195726081728935, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.54928547]\n",
      " [0.55694556]\n",
      " [0.56446844]\n",
      " [0.57159513]\n",
      " [0.57896268]\n",
      " [0.58574849]\n",
      " [0.59294957]\n",
      " [0.59936112]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.60632205]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.54928547]\n",
      "  [0.55694556]\n",
      "  [0.56446844]\n",
      "  [0.57159513]\n",
      "  [0.57896268]\n",
      "  [0.58574849]\n",
      "  [0.59294957]\n",
      "  [0.59936112]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011194705963134766\n",
      "Predicción post entrenamiento : [[0.60696733]]\n",
      "PERDIDAAAA despues: 0.011058575473725796\n",
      "loss en el callback: 0.013377651572227478, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.55694556]\n",
      " [0.56446844]\n",
      " [0.57159513]\n",
      " [0.57896268]\n",
      " [0.58574849]\n",
      " [0.59294957]\n",
      " [0.59936112]\n",
      " [0.60632205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.613069]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.55694556]\n",
      "  [0.56446844]\n",
      "  [0.57159513]\n",
      "  [0.57896268]\n",
      "  [0.58574849]\n",
      "  [0.59294957]\n",
      "  [0.59936112]\n",
      "  [0.60632205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01601916179060936\n",
      "Predicción post entrenamiento : [[0.61297727]]\n",
      "PERDIDAAAA despues: 0.01604239083826542\n",
      "loss en el callback: 0.00019416511349845678, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.56446844]\n",
      " [0.57159513]\n",
      " [0.57896268]\n",
      " [0.58574849]\n",
      " [0.59294957]\n",
      " [0.59936112]\n",
      " [0.60632205]\n",
      " [0.613069  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.61896646]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.56446844]\n",
      "  [0.57159513]\n",
      "  [0.57896268]\n",
      "  [0.58574849]\n",
      "  [0.59294957]\n",
      "  [0.59936112]\n",
      "  [0.60632205]\n",
      "  [0.613069  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013731694780290127\n",
      "Predicción post entrenamiento : [[0.6196053]]\n",
      "PERDIDAAAA despues: 0.0135823804885149\n",
      "loss en el callback: 0.013975482434034348, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.57159513]\n",
      " [0.57896268]\n",
      " [0.58574849]\n",
      " [0.59294957]\n",
      " [0.59936112]\n",
      " [0.60632205]\n",
      " [0.613069  ]\n",
      " [0.61896646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6254813]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.57159513]\n",
      "  [0.57896268]\n",
      "  [0.58574849]\n",
      "  [0.59294957]\n",
      "  [0.59936112]\n",
      "  [0.60632205]\n",
      "  [0.613069  ]\n",
      "  [0.61896646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017715177964419127\n",
      "Predicción post entrenamiento : [[0.62603354]]\n",
      "PERDIDAAAA despues: 0.001725336187519133\n",
      "loss en el callback: 0.011165878735482693, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.57896268]\n",
      " [0.58574849]\n",
      " [0.59294957]\n",
      " [0.59936112]\n",
      " [0.60632205]\n",
      " [0.613069  ]\n",
      " [0.61896646]\n",
      " [0.62548131]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6318653]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.57896268]\n",
      "  [0.58574849]\n",
      "  [0.59294957]\n",
      "  [0.59936112]\n",
      "  [0.60632205]\n",
      "  [0.613069  ]\n",
      "  [0.61896646]\n",
      "  [0.62548131]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001446287613362074\n",
      "Predicción post entrenamiento : [[0.6320841]]\n",
      "PERDIDAAAA despues: 0.0014296973822638392\n",
      "loss en el callback: 0.0015506916679441929, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.58574849]\n",
      " [0.59294957]\n",
      " [0.59936112]\n",
      " [0.60632205]\n",
      " [0.613069  ]\n",
      " [0.61896646]\n",
      " [0.62548131]\n",
      " [0.63186532]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.6377751]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.58574849]\n",
      "  [0.59294957]\n",
      "  [0.59936112]\n",
      "  [0.60632205]\n",
      "  [0.613069  ]\n",
      "  [0.61896646]\n",
      "  [0.62548131]\n",
      "  [0.63186532]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034638054203242064\n",
      "Predicción post entrenamiento : [[0.63755035]]\n",
      "PERDIDAAAA despues: 0.0034903131891041994\n",
      "loss en el callback: 0.0013258467661216855, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.59294957]\n",
      " [0.59936112]\n",
      " [0.60632205]\n",
      " [0.613069  ]\n",
      " [0.61896646]\n",
      " [0.62548131]\n",
      " [0.63186532]\n",
      " [0.63777512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6432188]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.59294957]\n",
      "  [0.59936112]\n",
      "  [0.60632205]\n",
      "  [0.613069  ]\n",
      "  [0.61896646]\n",
      "  [0.62548131]\n",
      "  [0.63186532]\n",
      "  [0.63777512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016201502876356244\n",
      "Predicción post entrenamiento : [[0.6434499]]\n",
      "PERDIDAAAA despues: 0.00015618563338648528\n",
      "loss en el callback: 0.0020306219812482595, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.59936112]\n",
      " [0.60632205]\n",
      " [0.613069  ]\n",
      " [0.61896646]\n",
      " [0.62548131]\n",
      " [0.63186532]\n",
      " [0.63777512]\n",
      " [0.64321882]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.64895284]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.59936112]\n",
      "  [0.60632205]\n",
      "  [0.613069  ]\n",
      "  [0.61896646]\n",
      "  [0.62548131]\n",
      "  [0.63186532]\n",
      "  [0.63777512]\n",
      "  [0.64321882]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008912506164051592\n",
      "Predicción post entrenamiento : [[0.64901614]]\n",
      "PERDIDAAAA despues: 0.000887475092895329\n",
      "loss en el callback: 0.00013222396955825388, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.60632205]\n",
      " [0.613069  ]\n",
      " [0.61896646]\n",
      " [0.62548131]\n",
      " [0.63186532]\n",
      " [0.63777512]\n",
      " [0.64321882]\n",
      " [0.64895284]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.65452313]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.60632205]\n",
      "  [0.613069  ]\n",
      "  [0.61896646]\n",
      "  [0.62548131]\n",
      "  [0.63186532]\n",
      "  [0.63777512]\n",
      "  [0.64321882]\n",
      "  [0.64895284]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004653251962736249\n",
      "Predicción post entrenamiento : [[0.65488034]]\n",
      "PERDIDAAAA despues: 0.0004500417271628976\n",
      "loss en el callback: 0.0048149055801332, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.613069  ]\n",
      " [0.61896646]\n",
      " [0.62548131]\n",
      " [0.63186532]\n",
      " [0.63777512]\n",
      " [0.64321882]\n",
      " [0.64895284]\n",
      " [0.65452313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.6602118]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.613069  ]\n",
      "  [0.61896646]\n",
      "  [0.62548131]\n",
      "  [0.63186532]\n",
      "  [0.63777512]\n",
      "  [0.64321882]\n",
      "  [0.64895284]\n",
      "  [0.65452313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00480947270989418\n",
      "Predicción post entrenamiento : [[0.660174]]\n",
      "PERDIDAAAA despues: 0.004814715590327978\n",
      "loss en el callback: 4.270614226697944e-05, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.61896646]\n",
      " [0.62548131]\n",
      " [0.63186532]\n",
      " [0.63777512]\n",
      " [0.64321882]\n",
      " [0.64895284]\n",
      " [0.65452313]\n",
      " [0.6602118 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.665337]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.61896646]\n",
      "  [0.62548131]\n",
      "  [0.63186532]\n",
      "  [0.63777512]\n",
      "  [0.64321882]\n",
      "  [0.64895284]\n",
      "  [0.65452313]\n",
      "  [0.6602118 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012917943531647325\n",
      "Predicción post entrenamiento : [[0.6652015]]\n",
      "PERDIDAAAA despues: 0.0013015558943152428\n",
      "loss en el callback: 0.0005342857330106199, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.62548131]\n",
      " [0.63186532]\n",
      " [0.63777512]\n",
      " [0.64321882]\n",
      " [0.64895284]\n",
      " [0.65452313]\n",
      " [0.6602118 ]\n",
      " [0.66533703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.67038625]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.62548131]\n",
      "  [0.63186532]\n",
      "  [0.63777512]\n",
      "  [0.64321882]\n",
      "  [0.64895284]\n",
      "  [0.65452313]\n",
      "  [0.6602118 ]\n",
      "  [0.66533703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009437293745577335\n",
      "Predicción post entrenamiento : [[0.6712629]]\n",
      "PERDIDAAAA despues: 0.009267734363675117\n",
      "loss en el callback: 0.03154522180557251, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.63186532]\n",
      " [0.63777512]\n",
      " [0.64321882]\n",
      " [0.64895284]\n",
      " [0.65452313]\n",
      " [0.6602118 ]\n",
      " [0.66533703]\n",
      " [0.67038625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.67627585]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.63186532]\n",
      "  [0.63777512]\n",
      "  [0.64321882]\n",
      "  [0.64895284]\n",
      "  [0.65452313]\n",
      "  [0.6602118 ]\n",
      "  [0.66533703]\n",
      "  [0.67038625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006218558643013239\n",
      "Predicción post entrenamiento : [[0.67678905]]\n",
      "PERDIDAAAA despues: 0.00613788329064846\n",
      "loss en el callback: 0.00945332832634449, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.63777512]\n",
      " [0.64321882]\n",
      " [0.64895284]\n",
      " [0.65452313]\n",
      " [0.6602118 ]\n",
      " [0.66533703]\n",
      " [0.67038625]\n",
      " [0.67627585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.6816192]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.63777512]\n",
      "  [0.64321882]\n",
      "  [0.64895284]\n",
      "  [0.65452313]\n",
      "  [0.6602118 ]\n",
      "  [0.66533703]\n",
      "  [0.67038625]\n",
      "  [0.67627585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004024735186249018\n",
      "Predicción post entrenamiento : [[0.6815117]]\n",
      "PERDIDAAAA despues: 0.0040383897721767426\n",
      "loss en el callback: 0.00031548249535262585, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.64321882]\n",
      " [0.64895284]\n",
      " [0.65452313]\n",
      " [0.6602118 ]\n",
      " [0.66533703]\n",
      " [0.67038625]\n",
      " [0.67627585]\n",
      " [0.68161923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.68625164]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.64321882]\n",
      "  [0.64895284]\n",
      "  [0.65452313]\n",
      "  [0.6602118 ]\n",
      "  [0.66533703]\n",
      "  [0.67038625]\n",
      "  [0.67627585]\n",
      "  [0.68161923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004327327944338322\n",
      "Predicción post entrenamiento : [[0.6862538]]\n",
      "PERDIDAAAA despues: 0.004327045287936926\n",
      "loss en el callback: 1.4343483201173512e-07, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.64895284]\n",
      " [0.65452313]\n",
      " [0.6602118 ]\n",
      " [0.66533703]\n",
      " [0.67038625]\n",
      " [0.67627585]\n",
      " [0.68161923]\n",
      " [0.68625164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.69101024]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.64895284]\n",
      "  [0.65452313]\n",
      "  [0.6602118 ]\n",
      "  [0.66533703]\n",
      "  [0.67038625]\n",
      "  [0.67627585]\n",
      "  [0.68161923]\n",
      "  [0.68625164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035314500564709306\n",
      "Predicción post entrenamiento : [[0.6911743]]\n",
      "PERDIDAAAA despues: 0.0003470046503935009\n",
      "loss en el callback: 0.001084417337551713, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.65452313]\n",
      " [0.6602118 ]\n",
      " [0.66533703]\n",
      " [0.67038625]\n",
      " [0.67627585]\n",
      " [0.68161923]\n",
      " [0.68625164]\n",
      " [0.69101024]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.69585294]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.65452313]\n",
      "  [0.6602118 ]\n",
      "  [0.66533703]\n",
      "  [0.67038625]\n",
      "  [0.67627585]\n",
      "  [0.68161923]\n",
      "  [0.68625164]\n",
      "  [0.69101024]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.9407738111331128e-05\n",
      "Predicción post entrenamiento : [[0.69612813]]\n",
      "PERDIDAAAA despues: 3.24681714118924e-05\n",
      "loss en el callback: 0.0028928034007549286, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.6602118 ]\n",
      " [0.66533703]\n",
      " [0.67038625]\n",
      " [0.67627585]\n",
      " [0.68161923]\n",
      " [0.68625164]\n",
      " [0.69101024]\n",
      " [0.69585294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7007458]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.6602118 ]\n",
      "  [0.66533703]\n",
      "  [0.67038625]\n",
      "  [0.67627585]\n",
      "  [0.68161923]\n",
      "  [0.68625164]\n",
      "  [0.69101024]\n",
      "  [0.69585294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028743480797857046\n",
      "Predicción post entrenamiento : [[0.70134324]]\n",
      "PERDIDAAAA despues: 0.0028106465470045805\n",
      "loss en el callback: 0.013932040892541409, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.66533703]\n",
      " [0.67038625]\n",
      " [0.67627585]\n",
      " [0.68161923]\n",
      " [0.68625164]\n",
      " [0.69101024]\n",
      " [0.69585294]\n",
      " [0.70074582]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.70584035]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.66533703]\n",
      "  [0.67038625]\n",
      "  [0.67627585]\n",
      "  [0.68161923]\n",
      "  [0.68625164]\n",
      "  [0.69101024]\n",
      "  [0.69585294]\n",
      "  [0.70074582]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026766079827211797\n",
      "Predicción post entrenamiento : [[0.70565873]]\n",
      "PERDIDAAAA despues: 0.0002736363676376641\n",
      "loss en el callback: 0.0011148592457175255, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.67038625]\n",
      " [0.67627585]\n",
      " [0.68161923]\n",
      " [0.68625164]\n",
      " [0.69101024]\n",
      " [0.69585294]\n",
      " [0.70074582]\n",
      " [0.70584035]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.71016216]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.67038625]\n",
      "  [0.67627585]\n",
      "  [0.68161923]\n",
      "  [0.68625164]\n",
      "  [0.69101024]\n",
      "  [0.69585294]\n",
      "  [0.70074582]\n",
      "  [0.70584035]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019139669835567474\n",
      "Predicción post entrenamiento : [[0.7111809]]\n",
      "PERDIDAAAA despues: 0.01885882392525673\n",
      "loss en el callback: 0.045863088220357895, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.67627585]\n",
      " [0.68161923]\n",
      " [0.68625164]\n",
      " [0.69101024]\n",
      " [0.69585294]\n",
      " [0.70074582]\n",
      " [0.70584035]\n",
      " [0.71016216]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7157002]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.67627585]\n",
      "  [0.68161923]\n",
      "  [0.68625164]\n",
      "  [0.69101024]\n",
      "  [0.69585294]\n",
      "  [0.70074582]\n",
      "  [0.70584035]\n",
      "  [0.71016216]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036009907722473145\n",
      "Predicción post entrenamiento : [[0.7167702]]\n",
      "PERDIDAAAA despues: 0.03560497611761093\n",
      "loss en el callback: 0.047125693410634995, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.68161923]\n",
      " [0.68625164]\n",
      " [0.69101024]\n",
      " [0.69585294]\n",
      " [0.70074582]\n",
      " [0.70584035]\n",
      " [0.71016216]\n",
      " [0.71570021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.721053]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.68161923]\n",
      "  [0.68625164]\n",
      "  [0.69101024]\n",
      "  [0.69585294]\n",
      "  [0.70074582]\n",
      "  [0.70584035]\n",
      "  [0.71016216]\n",
      "  [0.71570021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02597358077764511\n",
      "Predicción post entrenamiento : [[0.7219161]]\n",
      "PERDIDAAAA despues: 0.025696134194731712\n",
      "loss en el callback: 0.028977593407034874, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.68625164]\n",
      " [0.69101024]\n",
      " [0.69585294]\n",
      " [0.70074582]\n",
      " [0.70584035]\n",
      " [0.71016216]\n",
      " [0.71570021]\n",
      " [0.721053  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.7260807]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.68625164]\n",
      "  [0.69101024]\n",
      "  [0.69585294]\n",
      "  [0.70074582]\n",
      "  [0.70584035]\n",
      "  [0.71016216]\n",
      "  [0.71570021]\n",
      "  [0.721053  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033017419278621674\n",
      "Predicción post entrenamiento : [[0.72630453]]\n",
      "PERDIDAAAA despues: 0.032936133444309235\n",
      "loss en el callback: 0.0014174992684274912, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.69101024]\n",
      " [0.69585294]\n",
      " [0.70074582]\n",
      " [0.70584035]\n",
      " [0.71016216]\n",
      " [0.71570021]\n",
      " [0.721053  ]\n",
      " [0.72608072]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.7305437]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.69101024]\n",
      "  [0.69585294]\n",
      "  [0.70074582]\n",
      "  [0.70584035]\n",
      "  [0.71016216]\n",
      "  [0.71570021]\n",
      "  [0.721053  ]\n",
      "  [0.72608072]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025291817262768745\n",
      "Predicción post entrenamiento : [[0.7310423]]\n",
      "PERDIDAAAA despues: 0.025133460760116577\n",
      "loss en el callback: 0.007875008508563042, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.69585294]\n",
      " [0.70074582]\n",
      " [0.70584035]\n",
      " [0.71016216]\n",
      " [0.71570021]\n",
      " [0.721053  ]\n",
      " [0.72608072]\n",
      " [0.73054367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.73533714]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.69585294]\n",
      "  [0.70074582]\n",
      "  [0.70584035]\n",
      "  [0.71016216]\n",
      "  [0.71570021]\n",
      "  [0.721053  ]\n",
      "  [0.72608072]\n",
      "  [0.73054367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019465144723653793\n",
      "Predicción post entrenamiento : [[0.7362995]]\n",
      "PERDIDAAAA despues: 0.019197534769773483\n",
      "loss en el callback: 0.044777438044548035, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.70074582]\n",
      " [0.70584035]\n",
      " [0.71016216]\n",
      " [0.71570021]\n",
      " [0.721053  ]\n",
      " [0.72608072]\n",
      " [0.73054367]\n",
      " [0.73533714]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.7406355]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.70074582]\n",
      "  [0.70584035]\n",
      "  [0.71016216]\n",
      "  [0.71570021]\n",
      "  [0.721053  ]\n",
      "  [0.72608072]\n",
      "  [0.73054367]\n",
      "  [0.73533714]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029782623052597046\n",
      "Predicción post entrenamiento : [[0.74182904]]\n",
      "PERDIDAAAA despues: 0.02937209978699684\n",
      "loss en el callback: 0.06918038427829742, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.70584035]\n",
      " [0.71016216]\n",
      " [0.71570021]\n",
      " [0.721053  ]\n",
      " [0.72608072]\n",
      " [0.73054367]\n",
      " [0.73533714]\n",
      " [0.74063551]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.7461984]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.70584035]\n",
      "  [0.71016216]\n",
      "  [0.71570021]\n",
      "  [0.721053  ]\n",
      "  [0.72608072]\n",
      "  [0.73054367]\n",
      "  [0.73533714]\n",
      "  [0.74063551]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06441524624824524\n",
      "Predicción post entrenamiento : [[0.7471799]]\n",
      "PERDIDAAAA despues: 0.06391798704862595\n",
      "loss en el callback: 0.03242770954966545, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.71016216]\n",
      " [0.71570021]\n",
      " [0.721053  ]\n",
      " [0.72608072]\n",
      " [0.73054367]\n",
      " [0.73533714]\n",
      " [0.74063551]\n",
      " [0.74619842]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.75153047]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.71016216]\n",
      "  [0.71570021]\n",
      "  [0.721053  ]\n",
      "  [0.72608072]\n",
      "  [0.73054367]\n",
      "  [0.73533714]\n",
      "  [0.74063551]\n",
      "  [0.74619842]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04797133058309555\n",
      "Predicción post entrenamiento : [[0.75266635]]\n",
      "PERDIDAAAA despues: 0.04747505113482475\n",
      "loss en el callback: 0.0518026165664196, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.71570021]\n",
      " [0.721053  ]\n",
      " [0.72608072]\n",
      " [0.73054367]\n",
      " [0.73533714]\n",
      " [0.74063551]\n",
      " [0.74619842]\n",
      " [0.75153047]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.7572249]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.71570021]\n",
      "  [0.721053  ]\n",
      "  [0.72608072]\n",
      "  [0.73054367]\n",
      "  [0.73533714]\n",
      "  [0.74063551]\n",
      "  [0.74619842]\n",
      "  [0.75153047]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017312729731202126\n",
      "Predicción post entrenamiento : [[0.75754386]]\n",
      "PERDIDAAAA despues: 0.017228899523615837\n",
      "loss en el callback: 0.003563088132068515, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.721053  ]\n",
      " [0.72608072]\n",
      " [0.73054367]\n",
      " [0.73533714]\n",
      " [0.74063551]\n",
      " [0.74619842]\n",
      " [0.75153047]\n",
      " [0.75722492]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.76199055]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.721053  ]\n",
      "  [0.72608072]\n",
      "  [0.73054367]\n",
      "  [0.73533714]\n",
      "  [0.74063551]\n",
      "  [0.74619842]\n",
      "  [0.75153047]\n",
      "  [0.75722492]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013447592966258526\n",
      "Predicción post entrenamiento : [[0.7628999]]\n",
      "PERDIDAAAA despues: 0.01323752198368311\n",
      "loss en el callback: 0.03994334489107132, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.72608072]\n",
      " [0.73054367]\n",
      " [0.73533714]\n",
      " [0.74063551]\n",
      " [0.74619842]\n",
      " [0.75153047]\n",
      " [0.75722492]\n",
      " [0.76199055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.7672792]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.72608072]\n",
      "  [0.73054367]\n",
      "  [0.73533714]\n",
      "  [0.74063551]\n",
      "  [0.74619842]\n",
      "  [0.75153047]\n",
      "  [0.75722492]\n",
      "  [0.76199055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006661266088485718\n",
      "Predicción post entrenamiento : [[0.76703733]]\n",
      "PERDIDAAAA despues: 0.00670080678537488\n",
      "loss en el callback: 0.0017784435767680407, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.73054367]\n",
      " [0.73533714]\n",
      " [0.74063551]\n",
      " [0.74619842]\n",
      " [0.75153047]\n",
      " [0.75722492]\n",
      " [0.76199055]\n",
      " [0.76727921]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.77144307]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.73054367]\n",
      "  [0.73533714]\n",
      "  [0.74063551]\n",
      "  [0.74619842]\n",
      "  [0.75153047]\n",
      "  [0.75722492]\n",
      "  [0.76199055]\n",
      "  [0.76727921]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00393501715734601\n",
      "Predicción post entrenamiento : [[0.7716849]]\n",
      "PERDIDAAAA despues: 0.003904737764969468\n",
      "loss en el callback: 0.0022200674284249544, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.73533714]\n",
      " [0.74063551]\n",
      " [0.74619842]\n",
      " [0.75153047]\n",
      " [0.75722492]\n",
      " [0.76199055]\n",
      " [0.76727921]\n",
      " [0.77144307]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.77629113]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.73533714]\n",
      "  [0.74063551]\n",
      "  [0.74619842]\n",
      "  [0.75153047]\n",
      "  [0.75722492]\n",
      "  [0.76199055]\n",
      "  [0.76727921]\n",
      "  [0.77144307]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006210035178810358\n",
      "Predicción post entrenamiento : [[0.7768935]]\n",
      "PERDIDAAAA despues: 0.0061154612340033054\n",
      "loss en el callback: 0.018786273896694183, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.74063551]\n",
      " [0.74619842]\n",
      " [0.75153047]\n",
      " [0.75722492]\n",
      " [0.76199055]\n",
      " [0.76727921]\n",
      " [0.77144307]\n",
      " [0.77629113]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.78162724]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.74063551]\n",
      "  [0.74619842]\n",
      "  [0.75153047]\n",
      "  [0.75722492]\n",
      "  [0.76199055]\n",
      "  [0.76727921]\n",
      "  [0.77144307]\n",
      "  [0.77629113]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008763756603002548\n",
      "Predicción post entrenamiento : [[0.7816004]]\n",
      "PERDIDAAAA despues: 0.00876877922564745\n",
      "loss en el callback: 2.6768848329083994e-05, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.74619842]\n",
      " [0.75153047]\n",
      " [0.75722492]\n",
      " [0.76199055]\n",
      " [0.76727921]\n",
      " [0.77144307]\n",
      " [0.77629113]\n",
      " [0.78162724]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.78631616]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.74619842]\n",
      "  [0.75153047]\n",
      "  [0.75722492]\n",
      "  [0.76199055]\n",
      "  [0.76727921]\n",
      "  [0.77144307]\n",
      "  [0.77629113]\n",
      "  [0.78162724]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005000756122171879\n",
      "Predicción post entrenamiento : [[0.786377]]\n",
      "PERDIDAAAA despues: 0.004992152564227581\n",
      "loss en el callback: 0.00014449740410782397, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.75153047]\n",
      " [0.75722492]\n",
      " [0.76199055]\n",
      " [0.76727921]\n",
      " [0.77144307]\n",
      " [0.77629113]\n",
      " [0.78162724]\n",
      " [0.78631616]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.7909764]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.75153047]\n",
      "  [0.75722492]\n",
      "  [0.76199055]\n",
      "  [0.76727921]\n",
      "  [0.77144307]\n",
      "  [0.77629113]\n",
      "  [0.78162724]\n",
      "  [0.78631616]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003490651259198785\n",
      "Predicción post entrenamiento : [[0.79143983]]\n",
      "PERDIDAAAA despues: 0.003436106024309993\n",
      "loss en el callback: 0.00998715776950121, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.75722492]\n",
      " [0.76199055]\n",
      " [0.76727921]\n",
      " [0.77144307]\n",
      " [0.77629113]\n",
      " [0.78162724]\n",
      " [0.78631616]\n",
      " [0.79097641]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.79595697]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.75722492]\n",
      "  [0.76199055]\n",
      "  [0.76727921]\n",
      "  [0.77144307]\n",
      "  [0.77629113]\n",
      "  [0.78162724]\n",
      "  [0.78631616]\n",
      "  [0.79097641]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002184593817219138\n",
      "Predicción post entrenamiento : [[0.7960784]]\n",
      "PERDIDAAAA despues: 0.002173258690163493\n",
      "loss en el callback: 0.0006004959577694535, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.76199055]\n",
      " [0.76727921]\n",
      " [0.77144307]\n",
      " [0.77629113]\n",
      " [0.78162724]\n",
      " [0.78631616]\n",
      " [0.79097641]\n",
      " [0.79595697]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8003822]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.76199055]\n",
      "  [0.76727921]\n",
      "  [0.77144307]\n",
      "  [0.77629113]\n",
      "  [0.78162724]\n",
      "  [0.78631616]\n",
      "  [0.79097641]\n",
      "  [0.79595697]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005087116151116788\n",
      "Predicción post entrenamiento : [[0.800098]]\n",
      "PERDIDAAAA despues: 0.0005216121789999306\n",
      "loss en el callback: 0.002865235088393092, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.76727921]\n",
      " [0.77144307]\n",
      " [0.77629113]\n",
      " [0.78162724]\n",
      " [0.78631616]\n",
      " [0.79097641]\n",
      " [0.79595697]\n",
      " [0.8003822 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8044236]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.76727921]\n",
      "  [0.77144307]\n",
      "  [0.77629113]\n",
      "  [0.78162724]\n",
      "  [0.78631616]\n",
      "  [0.79097641]\n",
      "  [0.79595697]\n",
      "  [0.8003822 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008950590854510665\n",
      "Predicción post entrenamiento : [[0.8045382]]\n",
      "PERDIDAAAA despues: 0.0009019304998219013\n",
      "loss en el callback: 0.0006257828790694475, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.77144307]\n",
      " [0.77629113]\n",
      " [0.78162724]\n",
      " [0.78631616]\n",
      " [0.79097641]\n",
      " [0.79595697]\n",
      " [0.8003822 ]\n",
      " [0.80442357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.80872726]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.77144307]\n",
      "  [0.77629113]\n",
      "  [0.78162724]\n",
      "  [0.78631616]\n",
      "  [0.79097641]\n",
      "  [0.79595697]\n",
      "  [0.8003822 ]\n",
      "  [0.80442357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006019721040502191\n",
      "Predicción post entrenamiento : [[0.8090531]]\n",
      "PERDIDAAAA despues: 0.0006180682103149593\n",
      "loss en el callback: 0.0055160257034003735, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.77629113]\n",
      " [0.78162724]\n",
      " [0.78631616]\n",
      " [0.79097641]\n",
      " [0.79595697]\n",
      " [0.8003822 ]\n",
      " [0.80442357]\n",
      " [0.80872726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8134085]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.77629113]\n",
      "  [0.78162724]\n",
      "  [0.78631616]\n",
      "  [0.79097641]\n",
      "  [0.79595697]\n",
      "  [0.8003822 ]\n",
      "  [0.80442357]\n",
      "  [0.80872726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002147007966414094\n",
      "Predicción post entrenamiento : [[0.8135896]]\n",
      "PERDIDAAAA despues: 0.00213025975972414\n",
      "loss en el callback: 0.001415000413544476, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.78162724]\n",
      " [0.78631616]\n",
      " [0.79097641]\n",
      " [0.79595697]\n",
      " [0.8003822 ]\n",
      " [0.80442357]\n",
      " [0.80872726]\n",
      " [0.81340849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.81791896]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.78162724]\n",
      "  [0.78631616]\n",
      "  [0.79097641]\n",
      "  [0.79595697]\n",
      "  [0.8003822 ]\n",
      "  [0.80442357]\n",
      "  [0.80872726]\n",
      "  [0.81340849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013250395422801375\n",
      "Predicción post entrenamiento : [[0.81866884]]\n",
      "PERDIDAAAA despues: 0.001271008513867855\n",
      "loss en el callback: 0.034679193049669266, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.78631616]\n",
      " [0.79097641]\n",
      " [0.79595697]\n",
      " [0.8003822 ]\n",
      " [0.80442357]\n",
      " [0.80872726]\n",
      " [0.81340849]\n",
      " [0.81791896]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8228078]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.78631616]\n",
      "  [0.79097641]\n",
      "  [0.79595697]\n",
      "  [0.8003822 ]\n",
      "  [0.80442357]\n",
      "  [0.80872726]\n",
      "  [0.81340849]\n",
      "  [0.81791896]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019816550775431097\n",
      "Predicción post entrenamiento : [[0.8226744]]\n",
      "PERDIDAAAA despues: 0.00020193893578834832\n",
      "loss en el callback: 0.0007009389228187501, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.79097641]\n",
      " [0.79595697]\n",
      " [0.8003822 ]\n",
      " [0.80442357]\n",
      " [0.80872726]\n",
      " [0.81340849]\n",
      " [0.81791896]\n",
      " [0.82280779]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8267765]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.79097641]\n",
      "  [0.79595697]\n",
      "  [0.8003822 ]\n",
      "  [0.80442357]\n",
      "  [0.80872726]\n",
      "  [0.81340849]\n",
      "  [0.81791896]\n",
      "  [0.82280779]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.8242744570598e-06\n",
      "Predicción post entrenamiento : [[0.82664794]]\n",
      "PERDIDAAAA despues: 1.0646758710208815e-05\n",
      "loss en el callback: 0.000677769014146179, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.79595697]\n",
      " [0.8003822 ]\n",
      " [0.80442357]\n",
      " [0.80872726]\n",
      " [0.81340849]\n",
      " [0.81791896]\n",
      " [0.82280779]\n",
      " [0.8267765 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.83070993]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.79595697]\n",
      "  [0.8003822 ]\n",
      "  [0.80442357]\n",
      "  [0.80872726]\n",
      "  [0.81340849]\n",
      "  [0.81791896]\n",
      "  [0.82280779]\n",
      "  [0.8267765 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031971167773008347\n",
      "Predicción post entrenamiento : [[0.83104396]]\n",
      "PERDIDAAAA despues: 0.0031594547908753157\n",
      "loss en el callback: 0.005185720510780811, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.8003822 ]\n",
      " [0.80442357]\n",
      " [0.80872726]\n",
      " [0.81340849]\n",
      " [0.81791896]\n",
      " [0.82280779]\n",
      " [0.8267765 ]\n",
      " [0.83070993]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8349586]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.8003822 ]\n",
      "  [0.80442357]\n",
      "  [0.80872726]\n",
      "  [0.81340849]\n",
      "  [0.81791896]\n",
      "  [0.82280779]\n",
      "  [0.8267765 ]\n",
      "  [0.83070993]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006143308128230274\n",
      "Predicción post entrenamiento : [[0.8343077]]\n",
      "PERDIDAAAA despues: 0.0006470226217061281\n",
      "loss en el callback: 0.014710446819663048, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.80442357]\n",
      " [0.80872726]\n",
      " [0.81340849]\n",
      " [0.81791896]\n",
      " [0.82280779]\n",
      " [0.8267765 ]\n",
      " [0.83070993]\n",
      " [0.83495861]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8382128]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.80442357]\n",
      "  [0.80872726]\n",
      "  [0.81340849]\n",
      "  [0.81791896]\n",
      "  [0.82280779]\n",
      "  [0.8267765 ]\n",
      "  [0.83070993]\n",
      "  [0.83495861]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.916170958793373e-06\n",
      "Predicción post entrenamiento : [[0.83897877]]\n",
      "PERDIDAAAA despues: 3.82268893872606e-07\n",
      "loss en el callback: 0.03571987897157669, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.80872726]\n",
      " [0.81340849]\n",
      " [0.81791896]\n",
      " [0.82280779]\n",
      " [0.8267765 ]\n",
      " [0.83070993]\n",
      " [0.83495861]\n",
      " [0.83821279]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.84297943]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.80872726]\n",
      "  [0.81340849]\n",
      "  [0.81791896]\n",
      "  [0.82280779]\n",
      "  [0.8267765 ]\n",
      "  [0.83070993]\n",
      "  [0.83495861]\n",
      "  [0.83821279]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003501647152006626\n",
      "Predicción post entrenamiento : [[0.84232086]]\n",
      "PERDIDAAAA despues: 0.003424139227718115\n",
      "loss en el callback: 0.017756229266524315, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.81340849]\n",
      " [0.81791896]\n",
      " [0.82280779]\n",
      " [0.8267765 ]\n",
      " [0.83070993]\n",
      " [0.83495861]\n",
      " [0.83821279]\n",
      " [0.84297943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8463375]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.81340849]\n",
      "  [0.81791896]\n",
      "  [0.82280779]\n",
      "  [0.8267765 ]\n",
      "  [0.83070993]\n",
      "  [0.83495861]\n",
      "  [0.83821279]\n",
      "  [0.84297943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007868027896620333\n",
      "Predicción post entrenamiento : [[0.84627205]]\n",
      "PERDIDAAAA despues: 0.000783135590609163\n",
      "loss en el callback: 0.0002104408195009455, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.81791896]\n",
      " [0.82280779]\n",
      " [0.8267765 ]\n",
      " [0.83070993]\n",
      " [0.83495861]\n",
      " [0.83821279]\n",
      " [0.84297943]\n",
      " [0.8463375 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.85017484]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.81791896]\n",
      "  [0.82280779]\n",
      "  [0.8267765 ]\n",
      "  [0.83070993]\n",
      "  [0.83495861]\n",
      "  [0.83821279]\n",
      "  [0.84297943]\n",
      "  [0.8463375 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003482021624222398\n",
      "Predicción post entrenamiento : [[0.8503145]]\n",
      "PERDIDAAAA despues: 0.003498522797599435\n",
      "loss en el callback: 0.0010769246146082878, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.82280779]\n",
      " [0.8267765 ]\n",
      " [0.83070993]\n",
      " [0.83495861]\n",
      " [0.83821279]\n",
      " [0.84297943]\n",
      " [0.8463375 ]\n",
      " [0.85017484]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.85411817]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.82280779]\n",
      "  [0.8267765 ]\n",
      "  [0.83070993]\n",
      "  [0.83495861]\n",
      "  [0.83821279]\n",
      "  [0.84297943]\n",
      "  [0.8463375 ]\n",
      "  [0.85017484]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008753514848649502\n",
      "Predicción post entrenamiento : [[0.8535053]]\n",
      "PERDIDAAAA despues: 0.00863921269774437\n",
      "loss en el callback: 0.016048582270741463, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.8267765 ]\n",
      " [0.83070993]\n",
      " [0.83495861]\n",
      " [0.83821279]\n",
      " [0.84297943]\n",
      " [0.8463375 ]\n",
      " [0.85017484]\n",
      " [0.85411817]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8570655]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.8267765 ]\n",
      "  [0.83070993]\n",
      "  [0.83495861]\n",
      "  [0.83821279]\n",
      "  [0.84297943]\n",
      "  [0.8463375 ]\n",
      "  [0.85017484]\n",
      "  [0.85411817]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004291798919439316\n",
      "Predicción post entrenamiento : [[0.8565797]]\n",
      "PERDIDAAAA despues: 0.00422838656231761\n",
      "loss en el callback: 0.01009857002645731, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.83070993]\n",
      " [0.83495861]\n",
      " [0.83821279]\n",
      " [0.84297943]\n",
      " [0.8463375 ]\n",
      " [0.85017484]\n",
      " [0.85411817]\n",
      " [0.8570655 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8601226]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.83070993]\n",
      "  [0.83495861]\n",
      "  [0.83821279]\n",
      "  [0.84297943]\n",
      "  [0.8463375 ]\n",
      "  [0.85017484]\n",
      "  [0.85411817]\n",
      "  [0.8570655 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008359141647815704\n",
      "Predicción post entrenamiento : [[0.85977155]]\n",
      "PERDIDAAAA despues: 0.008295068517327309\n",
      "loss en el callback: 0.006082495208829641, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.83495861]\n",
      " [0.83821279]\n",
      " [0.84297943]\n",
      " [0.8463375 ]\n",
      " [0.85017484]\n",
      " [0.85411817]\n",
      " [0.8570655 ]\n",
      " [0.86012262]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.86329037]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.83495861]\n",
      "  [0.83821279]\n",
      "  [0.84297943]\n",
      "  [0.8463375 ]\n",
      "  [0.85017484]\n",
      "  [0.85411817]\n",
      "  [0.8570655 ]\n",
      "  [0.86012262]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00894842017441988\n",
      "Predicción post entrenamiento : [[0.86302775]]\n",
      "PERDIDAAAA despues: 0.00889880396425724\n",
      "loss en el callback: 0.003574012080207467, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.83821279]\n",
      " [0.84297943]\n",
      " [0.8463375 ]\n",
      " [0.85017484]\n",
      " [0.85411817]\n",
      " [0.8570655 ]\n",
      " [0.86012262]\n",
      " [0.86329037]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.86640465]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.83821279]\n",
      "  [0.84297943]\n",
      "  [0.8463375 ]\n",
      "  [0.85017484]\n",
      "  [0.85411817]\n",
      "  [0.8570655 ]\n",
      "  [0.86012262]\n",
      "  [0.86329037]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00455483328551054\n",
      "Predicción post entrenamiento : [[0.86665434]]\n",
      "PERDIDAAAA despues: 0.00458859745413065\n",
      "loss en el callback: 0.004113323055207729, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.84297943]\n",
      " [0.8463375 ]\n",
      " [0.85017484]\n",
      " [0.85411817]\n",
      " [0.8570655 ]\n",
      " [0.86012262]\n",
      " [0.86329037]\n",
      " [0.86640465]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.8701455]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.84297943]\n",
      "  [0.8463375 ]\n",
      "  [0.85017484]\n",
      "  [0.85411817]\n",
      "  [0.8570655 ]\n",
      "  [0.86012262]\n",
      "  [0.86329037]\n",
      "  [0.86640465]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006422676611691713\n",
      "Predicción post entrenamiento : [[0.86967266]]\n",
      "PERDIDAAAA despues: 0.00634711142629385\n",
      "loss en el callback: 0.010467324405908585, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.8463375 ]\n",
      " [0.85017484]\n",
      " [0.85411817]\n",
      " [0.8570655 ]\n",
      " [0.86012262]\n",
      " [0.86329037]\n",
      " [0.86640465]\n",
      " [0.8701455 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.8728185]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.8463375 ]\n",
      "  [0.85017484]\n",
      "  [0.85411817]\n",
      "  [0.8570655 ]\n",
      "  [0.86012262]\n",
      "  [0.86329037]\n",
      "  [0.86640465]\n",
      "  [0.8701455 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012689587660133839\n",
      "Predicción post entrenamiento : [[0.87271327]]\n",
      "PERDIDAAAA despues: 0.012665883637964725\n",
      "loss en el callback: 0.0006637708283960819, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.85017484]\n",
      " [0.85411817]\n",
      " [0.8570655 ]\n",
      " [0.86012262]\n",
      " [0.86329037]\n",
      " [0.86640465]\n",
      " [0.8701455 ]\n",
      " [0.87281853]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.87586796]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.85017484]\n",
      "  [0.85411817]\n",
      "  [0.8570655 ]\n",
      "  [0.86012262]\n",
      "  [0.86329037]\n",
      "  [0.86640465]\n",
      "  [0.8701455 ]\n",
      "  [0.87281853]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03628060594201088\n",
      "Predicción post entrenamiento : [[0.8751111]]\n",
      "PERDIDAAAA despues: 0.035992853343486786\n",
      "loss en el callback: 0.030257530510425568, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.85411817]\n",
      " [0.8570655 ]\n",
      " [0.86012262]\n",
      " [0.86329037]\n",
      " [0.86640465]\n",
      " [0.8701455 ]\n",
      " [0.87281853]\n",
      " [0.87586796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.87811714]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.85411817]\n",
      "  [0.8570655 ]\n",
      "  [0.86012262]\n",
      "  [0.86329037]\n",
      "  [0.86640465]\n",
      "  [0.8701455 ]\n",
      "  [0.87281853]\n",
      "  [0.87586796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07448825985193253\n",
      "Predicción post entrenamiento : [[0.8769211]]\n",
      "PERDIDAAAA despues: 0.07383684068918228\n",
      "loss en el callback: 0.08031197637319565, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.8570655 ]\n",
      " [0.86012262]\n",
      " [0.86329037]\n",
      " [0.86640465]\n",
      " [0.8701455 ]\n",
      " [0.87281853]\n",
      " [0.87586796]\n",
      " [0.87811714]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8797087]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.8570655 ]\n",
      "  [0.86012262]\n",
      "  [0.86329037]\n",
      "  [0.86640465]\n",
      "  [0.8701455 ]\n",
      "  [0.87281853]\n",
      "  [0.87586796]\n",
      "  [0.87811714]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04616057872772217\n",
      "Predicción post entrenamiento : [[0.8784276]]\n",
      "PERDIDAAAA despues: 0.04561173543334007\n",
      "loss en el callback: 0.07411318272352219, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.86012262]\n",
      " [0.86329037]\n",
      " [0.86640465]\n",
      " [0.8701455 ]\n",
      " [0.87281853]\n",
      " [0.87586796]\n",
      " [0.87811714]\n",
      " [0.87970871]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.88124615]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.86012262]\n",
      "  [0.86329037]\n",
      "  [0.86640465]\n",
      "  [0.8701455 ]\n",
      "  [0.87281853]\n",
      "  [0.87586796]\n",
      "  [0.87811714]\n",
      "  [0.87970871]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030060961842536926\n",
      "Predicción post entrenamiento : [[0.88016456]]\n",
      "PERDIDAAAA despues: 0.029687078669667244\n",
      "loss en el callback: 0.05698968470096588, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.86329037]\n",
      " [0.86640465]\n",
      " [0.8701455 ]\n",
      " [0.87281853]\n",
      " [0.87586796]\n",
      " [0.87811714]\n",
      " [0.87970871]\n",
      " [0.88124615]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.88295674]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.86329037]\n",
      "  [0.86640465]\n",
      "  [0.8701455 ]\n",
      "  [0.87281853]\n",
      "  [0.87586796]\n",
      "  [0.87811714]\n",
      "  [0.87970871]\n",
      "  [0.88124615]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04756680876016617\n",
      "Predicción post entrenamiento : [[0.8810995]]\n",
      "PERDIDAAAA despues: 0.04676014557480812\n",
      "loss en el callback: 0.14327983558177948, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.86640465]\n",
      " [0.8701455 ]\n",
      " [0.87281853]\n",
      " [0.87586796]\n",
      " [0.87811714]\n",
      " [0.87970871]\n",
      " [0.88124615]\n",
      " [0.88295674]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.8837873]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.86640465]\n",
      "  [0.8701455 ]\n",
      "  [0.87281853]\n",
      "  [0.87586796]\n",
      "  [0.87811714]\n",
      "  [0.87970871]\n",
      "  [0.88124615]\n",
      "  [0.88295674]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029733864590525627\n",
      "Predicción post entrenamiento : [[0.8829051]]\n",
      "PERDIDAAAA despues: 0.029430417343974113\n",
      "loss en el callback: 0.04112633317708969, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.8701455 ]\n",
      " [0.87281853]\n",
      " [0.87586796]\n",
      " [0.87811714]\n",
      " [0.87970871]\n",
      " [0.88124615]\n",
      " [0.88295674]\n",
      " [0.88378727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.88543975]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.8701455 ]\n",
      "  [0.87281853]\n",
      "  [0.87586796]\n",
      "  [0.87811714]\n",
      "  [0.87970871]\n",
      "  [0.88124615]\n",
      "  [0.88295674]\n",
      "  [0.88378727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043340109288692474\n",
      "Predicción post entrenamiento : [[0.8840668]]\n",
      "PERDIDAAAA despues: 0.042770352214574814\n",
      "loss en el callback: 0.08340784907341003, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.87281853]\n",
      " [0.87586796]\n",
      " [0.87811714]\n",
      " [0.87970871]\n",
      " [0.88124615]\n",
      " [0.88295674]\n",
      " [0.88378727]\n",
      " [0.88543975]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.88618594]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.87281853]\n",
      "  [0.87586796]\n",
      "  [0.87811714]\n",
      "  [0.87970871]\n",
      "  [0.88124615]\n",
      "  [0.88295674]\n",
      "  [0.88378727]\n",
      "  [0.88543975]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015395402908325195\n",
      "Predicción post entrenamiento : [[0.88555413]]\n",
      "PERDIDAAAA despues: 0.015239015221595764\n",
      "loss en el callback: 0.02124175615608692, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.87586796]\n",
      " [0.87811714]\n",
      " [0.87970871]\n",
      " [0.88124615]\n",
      " [0.88295674]\n",
      " [0.88378727]\n",
      " [0.88543975]\n",
      " [0.88618594]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.8874713]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.87586796]\n",
      "  [0.87811714]\n",
      "  [0.87970871]\n",
      "  [0.88124615]\n",
      "  [0.88295674]\n",
      "  [0.88378727]\n",
      "  [0.88543975]\n",
      "  [0.88618594]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0064673409797251225\n",
      "Predicción post entrenamiento : [[0.8878837]]\n",
      "PERDIDAAAA despues: 0.006533842068165541\n",
      "loss en el callback: 0.014904523268342018, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.87811714]\n",
      " [0.87970871]\n",
      " [0.88124615]\n",
      " [0.88295674]\n",
      " [0.88378727]\n",
      " [0.88543975]\n",
      " [0.88618594]\n",
      " [0.88747132]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.8894199]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.87811714]\n",
      "  [0.87970871]\n",
      "  [0.88124615]\n",
      "  [0.88295674]\n",
      "  [0.88378727]\n",
      "  [0.88543975]\n",
      "  [0.88618594]\n",
      "  [0.88747132]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005510387010872364\n",
      "Predicción post entrenamiento : [[0.8888024]]\n",
      "PERDIDAAAA despues: 0.005419091321527958\n",
      "loss en el callback: 0.01797240972518921, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.87970871]\n",
      " [0.88124615]\n",
      " [0.88295674]\n",
      " [0.88378727]\n",
      " [0.88543975]\n",
      " [0.88618594]\n",
      " [0.88747132]\n",
      " [0.88941991]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.89011943]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.87970871]\n",
      "  [0.88124615]\n",
      "  [0.88295674]\n",
      "  [0.88378727]\n",
      "  [0.88543975]\n",
      "  [0.88618594]\n",
      "  [0.88747132]\n",
      "  [0.88941991]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002598049759399146\n",
      "Predicción post entrenamiento : [[0.8905972]]\n",
      "PERDIDAAAA despues: 0.0002446307335048914\n",
      "loss en el callback: 0.016342543065547943, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.88124615]\n",
      " [0.88295674]\n",
      " [0.88378727]\n",
      " [0.88543975]\n",
      " [0.88618594]\n",
      " [0.88747132]\n",
      " [0.88941991]\n",
      " [0.89011943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.89184934]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.88124615]\n",
      "  [0.88295674]\n",
      "  [0.88378727]\n",
      "  [0.88543975]\n",
      "  [0.88618594]\n",
      "  [0.88747132]\n",
      "  [0.88941991]\n",
      "  [0.89011943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0046044629998505116\n",
      "Predicción post entrenamiento : [[0.8916017]]\n",
      "PERDIDAAAA despues: 0.004638134501874447\n",
      "loss en el callback: 0.0027740097139030695, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.88295674]\n",
      " [0.88378727]\n",
      " [0.88543975]\n",
      " [0.88618594]\n",
      " [0.88747132]\n",
      " [0.88941991]\n",
      " [0.89011943]\n",
      " [0.89184934]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.89279157]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.88295674]\n",
      "  [0.88378727]\n",
      "  [0.88543975]\n",
      "  [0.88618594]\n",
      "  [0.88747132]\n",
      "  [0.88941991]\n",
      "  [0.89011943]\n",
      "  [0.89184934]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005121306516230106\n",
      "Predicción post entrenamiento : [[0.8926345]]\n",
      "PERDIDAAAA despues: 0.00514381006360054\n",
      "loss en el callback: 0.0011430408339947462, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.88378727]\n",
      " [0.88543975]\n",
      " [0.88618594]\n",
      " [0.88747132]\n",
      " [0.88941991]\n",
      " [0.89011943]\n",
      " [0.89184934]\n",
      " [0.89279157]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.89369863]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.88378727]\n",
      "  [0.88543975]\n",
      "  [0.88618594]\n",
      "  [0.88747132]\n",
      "  [0.88941991]\n",
      "  [0.89011943]\n",
      "  [0.89184934]\n",
      "  [0.89279157]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.215713513782248e-05\n",
      "Predicción post entrenamiento : [[0.8937009]]\n",
      "PERDIDAAAA despues: 3.218283018213697e-05\n",
      "loss en el callback: 3.517275217745919e-07, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.88543975]\n",
      " [0.88618594]\n",
      " [0.88747132]\n",
      " [0.88941991]\n",
      " [0.89011943]\n",
      " [0.89184934]\n",
      " [0.89279157]\n",
      " [0.89369863]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.8948851]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.88543975]\n",
      "  [0.88618594]\n",
      "  [0.88747132]\n",
      "  [0.88941991]\n",
      "  [0.89011943]\n",
      "  [0.89184934]\n",
      "  [0.89279157]\n",
      "  [0.89369863]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.874713340541348e-06\n",
      "Predicción post entrenamiento : [[0.8945847]]\n",
      "PERDIDAAAA despues: 3.6384335544425994e-06\n",
      "loss en el callback: 0.0051063112914562225, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.88618594]\n",
      " [0.88747132]\n",
      " [0.88941991]\n",
      " [0.89011943]\n",
      " [0.89184934]\n",
      " [0.89279157]\n",
      " [0.89369863]\n",
      " [0.89488512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.89565647]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.88618594]\n",
      "  [0.88747132]\n",
      "  [0.88941991]\n",
      "  [0.89011943]\n",
      "  [0.89184934]\n",
      "  [0.89279157]\n",
      "  [0.89369863]\n",
      "  [0.89488512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041674336534924805\n",
      "Predicción post entrenamiento : [[0.89587617]]\n",
      "PERDIDAAAA despues: 0.0004257617692928761\n",
      "loss en el callback: 0.0034317190293222666, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.88747132]\n",
      " [0.88941991]\n",
      " [0.89011943]\n",
      " [0.89184934]\n",
      " [0.89279157]\n",
      " [0.89369863]\n",
      " [0.89488512]\n",
      " [0.89565647]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.89708585]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.88747132]\n",
      "  [0.88941991]\n",
      "  [0.89011943]\n",
      "  [0.89184934]\n",
      "  [0.89279157]\n",
      "  [0.89369863]\n",
      "  [0.89488512]\n",
      "  [0.89565647]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021393257193267345\n",
      "Predicción post entrenamiento : [[0.897359]]\n",
      "PERDIDAAAA despues: 0.002164670033380389\n",
      "loss en el callback: 0.005756371188908815, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.88941991]\n",
      " [0.89011943]\n",
      " [0.89184934]\n",
      " [0.89279157]\n",
      " [0.89369863]\n",
      " [0.89488512]\n",
      " [0.89565647]\n",
      " [0.89708585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8985563]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.88941991]\n",
      "  [0.89011943]\n",
      "  [0.89184934]\n",
      "  [0.89279157]\n",
      "  [0.89369863]\n",
      "  [0.89488512]\n",
      "  [0.89565647]\n",
      "  [0.89708585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002466165693476796\n",
      "Predicción post entrenamiento : [[0.89910054]]\n",
      "PERDIDAAAA despues: 0.002520517213270068\n",
      "loss en el callback: 0.02799943834543228, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.89011943]\n",
      " [0.89184934]\n",
      " [0.89279157]\n",
      " [0.89369863]\n",
      " [0.89488512]\n",
      " [0.89565647]\n",
      " [0.89708585]\n",
      " [0.89855629]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.90007704]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.89011943]\n",
      "  [0.89184934]\n",
      "  [0.89279157]\n",
      "  [0.89369863]\n",
      "  [0.89488512]\n",
      "  [0.89565647]\n",
      "  [0.89708585]\n",
      "  [0.89855629]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003886352526023984\n",
      "Predicción post entrenamiento : [[0.8999899]]\n",
      "PERDIDAAAA despues: 0.0038972250185906887\n",
      "loss en el callback: 0.0004007744719274342, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.89184934]\n",
      " [0.89279157]\n",
      " [0.89369863]\n",
      " [0.89488512]\n",
      " [0.89565647]\n",
      " [0.89708585]\n",
      " [0.89855629]\n",
      " [0.90007704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.90109074]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.89184934]\n",
      "  [0.89279157]\n",
      "  [0.89369863]\n",
      "  [0.89488512]\n",
      "  [0.89565647]\n",
      "  [0.89708585]\n",
      "  [0.89855629]\n",
      "  [0.90007704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004455720540136099\n",
      "Predicción post entrenamiento : [[0.90154785]]\n",
      "PERDIDAAAA despues: 0.0043949042446911335\n",
      "loss en el callback: 0.013884282670915127, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.89279157]\n",
      " [0.89369863]\n",
      " [0.89488512]\n",
      " [0.89565647]\n",
      " [0.89708585]\n",
      " [0.89855629]\n",
      " [0.90007704]\n",
      " [0.90109074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.90248513]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.89279157]\n",
      "  [0.89369863]\n",
      "  [0.89488512]\n",
      "  [0.89565647]\n",
      "  [0.89708585]\n",
      "  [0.89855629]\n",
      "  [0.90007704]\n",
      "  [0.90109074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014619568828493357\n",
      "Predicción post entrenamiento : [[0.9026711]]\n",
      "PERDIDAAAA despues: 0.0014477703953161836\n",
      "loss en el callback: 0.002221258357167244, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.89369863]\n",
      " [0.89488512]\n",
      " [0.89565647]\n",
      " [0.89708585]\n",
      " [0.89855629]\n",
      " [0.90007704]\n",
      " [0.90109074]\n",
      " [0.90248513]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9036659]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.89369863]\n",
      "  [0.89488512]\n",
      "  [0.89565647]\n",
      "  [0.89708585]\n",
      "  [0.89855629]\n",
      "  [0.90007704]\n",
      "  [0.90109074]\n",
      "  [0.90248513]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004736930597573519\n",
      "Predicción post entrenamiento : [[0.9038584]]\n",
      "PERDIDAAAA despues: 0.00471046706661582\n",
      "loss en el callback: 0.002224956639111042, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.89488512]\n",
      " [0.89565647]\n",
      " [0.89708585]\n",
      " [0.89855629]\n",
      " [0.90007704]\n",
      " [0.90109074]\n",
      " [0.90248513]\n",
      " [0.9036659 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9049387]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.89488512]\n",
      "  [0.89565647]\n",
      "  [0.89708585]\n",
      "  [0.89855629]\n",
      "  [0.90007704]\n",
      "  [0.90109074]\n",
      "  [0.90248513]\n",
      "  [0.9036659 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008456962183117867\n",
      "Predicción post entrenamiento : [[0.9052144]]\n",
      "PERDIDAAAA despues: 0.008406324312090874\n",
      "loss en el callback: 0.004484692122787237, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.89565647]\n",
      " [0.89708585]\n",
      " [0.89855629]\n",
      " [0.90007704]\n",
      " [0.90109074]\n",
      " [0.90248513]\n",
      " [0.9036659 ]\n",
      " [0.9049387 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.90631443]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.89565647]\n",
      "  [0.89708585]\n",
      "  [0.89855629]\n",
      "  [0.90007704]\n",
      "  [0.90109074]\n",
      "  [0.90248513]\n",
      "  [0.9036659 ]\n",
      "  [0.9049387 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020130726043134928\n",
      "Predicción post entrenamiento : [[0.905701]]\n",
      "PERDIDAAAA despues: 0.0020684965420514345\n",
      "loss en el callback: 0.017555616796016693, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.89708585]\n",
      " [0.89855629]\n",
      " [0.90007704]\n",
      " [0.90109074]\n",
      " [0.90248513]\n",
      " [0.9036659 ]\n",
      " [0.9049387 ]\n",
      " [0.90631443]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9069508]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.89708585]\n",
      "  [0.89855629]\n",
      "  [0.90007704]\n",
      "  [0.90109074]\n",
      "  [0.90248513]\n",
      "  [0.9036659 ]\n",
      "  [0.9049387 ]\n",
      "  [0.90631443]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012485745537560433\n",
      "Predicción post entrenamiento : [[0.9069071]]\n",
      "PERDIDAAAA despues: 0.00012388298637233675\n",
      "loss en el callback: 0.00013062912330497056, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.89855629]\n",
      " [0.90007704]\n",
      " [0.90109074]\n",
      " [0.90248513]\n",
      " [0.9036659 ]\n",
      " [0.9049387 ]\n",
      " [0.90631443]\n",
      " [0.90695077]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9081252]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.89855629]\n",
      "  [0.90007704]\n",
      "  [0.90109074]\n",
      "  [0.90248513]\n",
      "  [0.9036659 ]\n",
      "  [0.9049387 ]\n",
      "  [0.90631443]\n",
      "  [0.90695077]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000712031964212656\n",
      "Predicción post entrenamiento : [[0.90831196]]\n",
      "PERDIDAAAA despues: 0.0007220327970571816\n",
      "loss en el callback: 0.002948931185528636, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.90007704]\n",
      " [0.90109074]\n",
      " [0.90248513]\n",
      " [0.9036659 ]\n",
      " [0.9049387 ]\n",
      " [0.90631443]\n",
      " [0.90695077]\n",
      " [0.90812522]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9094723]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.90007704]\n",
      "  [0.90109074]\n",
      "  [0.90248513]\n",
      "  [0.9036659 ]\n",
      "  [0.9049387 ]\n",
      "  [0.90631443]\n",
      "  [0.90695077]\n",
      "  [0.90812522]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.797506310045719e-05\n",
      "Predicción post entrenamiento : [[0.90996414]]\n",
      "PERDIDAAAA despues: 5.072684871265665e-05\n",
      "loss en el callback: 0.01836254820227623, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.90109074]\n",
      " [0.90248513]\n",
      " [0.9036659 ]\n",
      " [0.9049387 ]\n",
      " [0.90631443]\n",
      " [0.90695077]\n",
      " [0.90812522]\n",
      " [0.90947229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.91103745]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.90109074]\n",
      "  [0.90248513]\n",
      "  [0.9036659 ]\n",
      "  [0.9049387 ]\n",
      "  [0.90631443]\n",
      "  [0.90695077]\n",
      "  [0.90812522]\n",
      "  [0.90947229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.675700908293948e-05\n",
      "Predicción post entrenamiento : [[0.9114864]]\n",
      "PERDIDAAAA despues: 6.909210060257465e-05\n",
      "loss en el callback: 0.017066070809960365, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.90248513]\n",
      " [0.9036659 ]\n",
      " [0.9049387 ]\n",
      " [0.90631443]\n",
      " [0.90695077]\n",
      " [0.90812522]\n",
      " [0.90947229]\n",
      " [0.91103745]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.912612]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.90248513]\n",
      "  [0.9036659 ]\n",
      "  [0.9049387 ]\n",
      "  [0.90631443]\n",
      "  [0.90695077]\n",
      "  [0.90812522]\n",
      "  [0.90947229]\n",
      "  [0.91103745]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002404017373919487\n",
      "Predicción post entrenamiento : [[0.9125282]]\n",
      "PERDIDAAAA despues: 0.0024122423492372036\n",
      "loss en el callback: 0.0004444676451385021, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.9036659 ]\n",
      " [0.9049387 ]\n",
      " [0.90631443]\n",
      " [0.90695077]\n",
      " [0.90812522]\n",
      " [0.90947229]\n",
      " [0.91103745]\n",
      " [0.91261202]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9136009]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.9036659 ]\n",
      "  [0.9049387 ]\n",
      "  [0.90631443]\n",
      "  [0.90695077]\n",
      "  [0.90812522]\n",
      "  [0.90947229]\n",
      "  [0.91103745]\n",
      "  [0.91261202]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029842655640095472\n",
      "Predicción post entrenamiento : [[0.9137864]]\n",
      "PERDIDAAAA despues: 0.002964033978059888\n",
      "loss en el callback: 0.0023430779110640287, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.9049387 ]\n",
      " [0.90631443]\n",
      " [0.90695077]\n",
      " [0.90812522]\n",
      " [0.90947229]\n",
      " [0.91103745]\n",
      " [0.91261202]\n",
      " [0.91360092]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9148666]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.9049387 ]\n",
      "  [0.90631443]\n",
      "  [0.90695077]\n",
      "  [0.90812522]\n",
      "  [0.90947229]\n",
      "  [0.91103745]\n",
      "  [0.91261202]\n",
      "  [0.91360092]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001840555458329618\n",
      "Predicción post entrenamiento : [[0.9148189]]\n",
      "PERDIDAAAA despues: 0.0018446542089805007\n",
      "loss en el callback: 0.0001533058239147067, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24348162]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03895707428455353\n",
      "Predicción post entrenamiento : [[0.2159488]]\n",
      "PERDIDAAAA despues: 0.02884652465581894\n",
      "loss en el callback: 0.03434528410434723, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24348162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.20059742]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24348162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009287996217608452\n",
      "Predicción post entrenamiento : [[0.18812038]]\n",
      "PERDIDAAAA despues: 0.007038741838186979\n",
      "loss en el callback: 0.007351895794272423, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24348162]\n",
      " [0.20059742]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.19202064]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24348162]\n",
      "  [0.20059742]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001430113217793405\n",
      "Predicción post entrenamiento : [[0.18758011]]\n",
      "PERDIDAAAA despues: 0.0011139778653159738\n",
      "loss en el callback: 0.0019261541310697794, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24348162]\n",
      " [0.20059742]\n",
      " [0.19202064]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.19878645]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24348162]\n",
      "  [0.20059742]\n",
      "  [0.19202064]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018518278375267982\n",
      "Predicción post entrenamiento : [[0.19779254]]\n",
      "PERDIDAAAA despues: 0.001767274341545999\n",
      "loss en el callback: 0.00023406281252391636, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24348162]\n",
      " [0.20059742]\n",
      " [0.19202064]\n",
      " [0.19878645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.21034789]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24348162]\n",
      "  [0.20059742]\n",
      "  [0.19202064]\n",
      "  [0.19878645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007193608675152063\n",
      "Predicción post entrenamiento : [[0.20509434]]\n",
      "PERDIDAAAA despues: 0.0063300468027591705\n",
      "loss en el callback: 0.007380252704024315, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24348162]\n",
      " [0.20059742]\n",
      " [0.19202064]\n",
      " [0.19878645]\n",
      " [0.21034789]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.21522684]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24348162]\n",
      "  [0.20059742]\n",
      "  [0.19202064]\n",
      "  [0.19878645]\n",
      "  [0.21034789]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004836768377572298\n",
      "Predicción post entrenamiento : [[0.21162765]]\n",
      "PERDIDAAAA despues: 0.004349096678197384\n",
      "loss en el callback: 0.00489529175683856, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.24348162]\n",
      " [0.20059742]\n",
      " [0.19202064]\n",
      " [0.19878645]\n",
      " [0.21034789]\n",
      " [0.21522684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.23291679]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24348162]\n",
      "  [0.20059742]\n",
      "  [0.19202064]\n",
      "  [0.19878645]\n",
      "  [0.21034789]\n",
      "  [0.21522684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007475665770471096\n",
      "Predicción post entrenamiento : [[0.23152378]]\n",
      "PERDIDAAAA despues: 0.007236722391098738\n",
      "loss en el callback: 0.0012724199332296848, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.24348162]\n",
      " [0.20059742]\n",
      " [0.19202064]\n",
      " [0.19878645]\n",
      " [0.21034789]\n",
      " [0.21522684]\n",
      " [0.23291679]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.25771308]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.24348162]\n",
      "  [0.20059742]\n",
      "  [0.19202064]\n",
      "  [0.19878645]\n",
      "  [0.21034789]\n",
      "  [0.21522684]\n",
      "  [0.23291679]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038025774993002415\n",
      "Predicción post entrenamiento : [[0.253724]]\n",
      "PERDIDAAAA despues: 0.0033265177626162767\n",
      "loss en el callback: 0.008024653419852257, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.24348162]\n",
      " [0.20059742]\n",
      " [0.19202064]\n",
      " [0.19878645]\n",
      " [0.21034789]\n",
      " [0.21522684]\n",
      " [0.23291679]\n",
      " [0.25771308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.28522778]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.24348162]\n",
      "  [0.20059742]\n",
      "  [0.19202064]\n",
      "  [0.19878645]\n",
      "  [0.21034789]\n",
      "  [0.21522684]\n",
      "  [0.23291679]\n",
      "  [0.25771308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002991759218275547\n",
      "Predicción post entrenamiento : [[0.28071937]]\n",
      "PERDIDAAAA despues: 0.002518892753869295\n",
      "loss en el callback: 0.010693179443478584, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.20059742]\n",
      " [0.19202064]\n",
      " [0.19878645]\n",
      " [0.21034789]\n",
      " [0.21522684]\n",
      " [0.23291679]\n",
      " [0.25771308]\n",
      " [0.28522778]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2744886]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.20059742]\n",
      "  [0.19202064]\n",
      "  [0.19878645]\n",
      "  [0.21034789]\n",
      "  [0.21522684]\n",
      "  [0.23291679]\n",
      "  [0.25771308]\n",
      "  [0.28522778]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00436158012598753\n",
      "Predicción post entrenamiento : [[0.27190447]]\n",
      "PERDIDAAAA despues: 0.004026934038847685\n",
      "loss en el callback: 0.0056524998508393764, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.19202064]\n",
      " [0.19878645]\n",
      " [0.21034789]\n",
      " [0.21522684]\n",
      " [0.23291679]\n",
      " [0.25771308]\n",
      " [0.28522778]\n",
      " [0.2744886 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.27526504]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.19202064]\n",
      "  [0.19878645]\n",
      "  [0.21034789]\n",
      "  [0.21522684]\n",
      "  [0.23291679]\n",
      "  [0.25771308]\n",
      "  [0.28522778]\n",
      "  [0.2744886 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004010901320725679\n",
      "Predicción post entrenamiento : [[0.27277642]]\n",
      "PERDIDAAAA despues: 0.00370187871158123\n",
      "loss en el callback: 0.005971604026854038, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.19878645]\n",
      " [0.21034789]\n",
      " [0.21522684]\n",
      " [0.23291679]\n",
      " [0.25771308]\n",
      " [0.28522778]\n",
      " [0.2744886 ]\n",
      " [0.27526504]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.28004116]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.19878645]\n",
      "  [0.21034789]\n",
      "  [0.21522684]\n",
      "  [0.23291679]\n",
      "  [0.25771308]\n",
      "  [0.28522778]\n",
      "  [0.2744886 ]\n",
      "  [0.27526504]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005293603520840406\n",
      "Predicción post entrenamiento : [[0.27671283]]\n",
      "PERDIDAAAA despues: 0.004820362664759159\n",
      "loss en el callback: 0.011576645076274872, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.21034789]\n",
      " [0.21522684]\n",
      " [0.23291679]\n",
      " [0.25771308]\n",
      " [0.28522778]\n",
      " [0.2744886 ]\n",
      " [0.27526504]\n",
      " [0.28004116]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.28513977]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.21034789]\n",
      "  [0.21522684]\n",
      "  [0.23291679]\n",
      "  [0.25771308]\n",
      "  [0.28522778]\n",
      "  [0.2744886 ]\n",
      "  [0.27526504]\n",
      "  [0.28004116]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008499234914779663\n",
      "Predicción post entrenamiento : [[0.2843891]]\n",
      "PERDIDAAAA despues: 0.008361388929188251\n",
      "loss en el callback: 0.0011989582562819123, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.21522684]\n",
      " [0.23291679]\n",
      " [0.25771308]\n",
      " [0.28522778]\n",
      " [0.2744886 ]\n",
      " [0.27526504]\n",
      " [0.28004116]\n",
      " [0.28513977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.29295123]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.21522684]\n",
      "  [0.23291679]\n",
      "  [0.25771308]\n",
      "  [0.28522778]\n",
      "  [0.2744886 ]\n",
      "  [0.27526504]\n",
      "  [0.28004116]\n",
      "  [0.28513977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009240646846592426\n",
      "Predicción post entrenamiento : [[0.28985783]]\n",
      "PERDIDAAAA despues: 0.008655491285026073\n",
      "loss en el callback: 0.013231288641691208, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.23291679]\n",
      " [0.25771308]\n",
      " [0.28522778]\n",
      " [0.2744886 ]\n",
      " [0.27526504]\n",
      " [0.28004116]\n",
      " [0.28513977]\n",
      " [0.29295123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.29983667]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.23291679]\n",
      "  [0.25771308]\n",
      "  [0.28522778]\n",
      "  [0.2744886 ]\n",
      "  [0.27526504]\n",
      "  [0.28004116]\n",
      "  [0.28513977]\n",
      "  [0.29295123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0073237004689872265\n",
      "Predicción post entrenamiento : [[0.29687285]]\n",
      "PERDIDAAAA despues: 0.0068252068012952805\n",
      "loss en el callback: 0.014997394755482674, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.25771308]\n",
      " [0.28522778]\n",
      " [0.2744886 ]\n",
      " [0.27526504]\n",
      " [0.28004116]\n",
      " [0.28513977]\n",
      " [0.29295123]\n",
      " [0.29983667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.30534598]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.25771308]\n",
      "  [0.28522778]\n",
      "  [0.2744886 ]\n",
      "  [0.27526504]\n",
      "  [0.28004116]\n",
      "  [0.28513977]\n",
      "  [0.29295123]\n",
      "  [0.29983667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01538118813186884\n",
      "Predicción post entrenamiento : [[0.30307615]]\n",
      "PERDIDAAAA despues: 0.014823326840996742\n",
      "loss en el callback: 0.011178627610206604, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.28522778]\n",
      " [0.2744886 ]\n",
      " [0.27526504]\n",
      " [0.28004116]\n",
      " [0.28513977]\n",
      " [0.29295123]\n",
      " [0.29983667]\n",
      " [0.30534598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.30791768]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.28522778]\n",
      "  [0.2744886 ]\n",
      "  [0.27526504]\n",
      "  [0.28004116]\n",
      "  [0.28513977]\n",
      "  [0.29295123]\n",
      "  [0.29983667]\n",
      "  [0.30534598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017633650451898575\n",
      "Predicción post entrenamiento : [[0.305975]]\n",
      "PERDIDAAAA despues: 0.01712147705256939\n",
      "loss en el callback: 0.010364561341702938, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.2744886 ]\n",
      " [0.27526504]\n",
      " [0.28004116]\n",
      " [0.28513977]\n",
      " [0.29295123]\n",
      " [0.29983667]\n",
      " [0.30534598]\n",
      " [0.30791768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.30584547]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.2744886 ]\n",
      "  [0.27526504]\n",
      "  [0.28004116]\n",
      "  [0.28513977]\n",
      "  [0.29295123]\n",
      "  [0.29983667]\n",
      "  [0.30534598]\n",
      "  [0.30791768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0249137245118618\n",
      "Predicción post entrenamiento : [[0.3022528]]\n",
      "PERDIDAAAA despues: 0.023792490363121033\n",
      "loss en el callback: 0.030498744919896126, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.27526504]\n",
      " [0.28004116]\n",
      " [0.28513977]\n",
      " [0.29295123]\n",
      " [0.29983667]\n",
      " [0.30534598]\n",
      " [0.30791768]\n",
      " [0.30584547]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.30510387]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.27526504]\n",
      "  [0.28004116]\n",
      "  [0.28513977]\n",
      "  [0.29295123]\n",
      "  [0.29983667]\n",
      "  [0.30534598]\n",
      "  [0.30791768]\n",
      "  [0.30584547]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021389270201325417\n",
      "Predicción post entrenamiento : [[0.3031835]]\n",
      "PERDIDAAAA despues: 0.020831245929002762\n",
      "loss en el callback: 0.013865484856069088, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.28004116]\n",
      " [0.28513977]\n",
      " [0.29295123]\n",
      " [0.29983667]\n",
      " [0.30534598]\n",
      " [0.30791768]\n",
      " [0.30584547]\n",
      " [0.30510387]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.30687362]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.28004116]\n",
      "  [0.28513977]\n",
      "  [0.29295123]\n",
      "  [0.29983667]\n",
      "  [0.30534598]\n",
      "  [0.30791768]\n",
      "  [0.30584547]\n",
      "  [0.30510387]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013156101107597351\n",
      "Predicción post entrenamiento : [[0.3044714]]\n",
      "PERDIDAAAA despues: 0.012610803358256817\n",
      "loss en el callback: 0.01736885868012905, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.28513977]\n",
      " [0.29295123]\n",
      " [0.29983667]\n",
      " [0.30534598]\n",
      " [0.30791768]\n",
      " [0.30584547]\n",
      " [0.30510387]\n",
      " [0.30687362]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.3081277]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.28513977]\n",
      "  [0.29295123]\n",
      "  [0.29983667]\n",
      "  [0.30534598]\n",
      "  [0.30791768]\n",
      "  [0.30584547]\n",
      "  [0.30510387]\n",
      "  [0.30687362]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014921420253813267\n",
      "Predicción post entrenamiento : [[0.30574936]]\n",
      "PERDIDAAAA despues: 0.014346032403409481\n",
      "loss en el callback: 0.017458150163292885, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.29295123]\n",
      " [0.29983667]\n",
      " [0.30534598]\n",
      " [0.30791768]\n",
      " [0.30584547]\n",
      " [0.30510387]\n",
      " [0.30687362]\n",
      " [0.3081277 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.30916753]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.29295123]\n",
      "  [0.29983667]\n",
      "  [0.30534598]\n",
      "  [0.30791768]\n",
      "  [0.30584547]\n",
      "  [0.30510387]\n",
      "  [0.30687362]\n",
      "  [0.3081277 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017822538502514362\n",
      "Predicción post entrenamiento : [[0.30840415]]\n",
      "PERDIDAAAA despues: 0.0017183811869472265\n",
      "loss en el callback: 0.0021185593213886023, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.29983667]\n",
      " [0.30534598]\n",
      " [0.30791768]\n",
      " [0.30584547]\n",
      " [0.30510387]\n",
      " [0.30687362]\n",
      " [0.3081277 ]\n",
      " [0.30916753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.31080288]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.29983667]\n",
      "  [0.30534598]\n",
      "  [0.30791768]\n",
      "  [0.30584547]\n",
      "  [0.30510387]\n",
      "  [0.30687362]\n",
      "  [0.3081277 ]\n",
      "  [0.30916753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033418016391806304\n",
      "Predicción post entrenamiento : [[0.31068596]]\n",
      "PERDIDAAAA despues: 0.0003299193049315363\n",
      "loss en el callback: 5.900801988900639e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.30534598]\n",
      " [0.30791768]\n",
      " [0.30584547]\n",
      " [0.30510387]\n",
      " [0.30687362]\n",
      " [0.3081277 ]\n",
      " [0.30916753]\n",
      " [0.31080288]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.3120224]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.30534598]\n",
      "  [0.30791768]\n",
      "  [0.30584547]\n",
      "  [0.30510387]\n",
      "  [0.30687362]\n",
      "  [0.3081277 ]\n",
      "  [0.30916753]\n",
      "  [0.31080288]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.230704533052631e-05\n",
      "Predicción post entrenamiento : [[0.31240273]]\n",
      "PERDIDAAAA despues: 2.8128082703915425e-05\n",
      "loss en el callback: 0.0007404358475469053, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.30791768]\n",
      " [0.30584547]\n",
      " [0.30510387]\n",
      " [0.30687362]\n",
      " [0.3081277 ]\n",
      " [0.30916753]\n",
      " [0.31080288]\n",
      " [0.31202239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.31278205]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.30791768]\n",
      "  [0.30584547]\n",
      "  [0.30510387]\n",
      "  [0.30687362]\n",
      "  [0.3081277 ]\n",
      "  [0.30916753]\n",
      "  [0.31080288]\n",
      "  [0.31202239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2663804227486253e-08\n",
      "Predicción post entrenamiento : [[0.31214494]]\n",
      "PERDIDAAAA despues: 2.751846750470577e-07\n",
      "loss en el callback: 0.0016802333993837237, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.30584547]\n",
      " [0.30510387]\n",
      " [0.30687362]\n",
      " [0.3081277 ]\n",
      " [0.30916753]\n",
      " [0.31080288]\n",
      " [0.31202239]\n",
      " [0.31278205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.3120937]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.30584547]\n",
      "  [0.30510387]\n",
      "  [0.30687362]\n",
      "  [0.3081277 ]\n",
      "  [0.30916753]\n",
      "  [0.31080288]\n",
      "  [0.31202239]\n",
      "  [0.31278205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000531691825017333\n",
      "Predicción post entrenamiento : [[0.31182805]]\n",
      "PERDIDAAAA despues: 0.0005195111152715981\n",
      "loss en el callback: 0.0003665999392978847, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.30510387]\n",
      " [0.30687362]\n",
      " [0.3081277 ]\n",
      " [0.30916753]\n",
      " [0.31080288]\n",
      " [0.31202239]\n",
      " [0.31278205]\n",
      " [0.3120937 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.31236392]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.30510387]\n",
      "  [0.30687362]\n",
      "  [0.3081277 ]\n",
      "  [0.30916753]\n",
      "  [0.31080288]\n",
      "  [0.31202239]\n",
      "  [0.31278205]\n",
      "  [0.3120937 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008718917379155755\n",
      "Predicción post entrenamiento : [[0.31198165]]\n",
      "PERDIDAAAA despues: 0.0008494624053128064\n",
      "loss en el callback: 0.0008567115874029696, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.30687362]\n",
      " [0.3081277 ]\n",
      " [0.30916753]\n",
      " [0.31080288]\n",
      " [0.31202239]\n",
      " [0.31278205]\n",
      " [0.3120937 ]\n",
      " [0.31236392]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.31289503]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.30687362]\n",
      "  [0.3081277 ]\n",
      "  [0.30916753]\n",
      "  [0.31080288]\n",
      "  [0.31202239]\n",
      "  [0.31278205]\n",
      "  [0.3120937 ]\n",
      "  [0.31236392]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017952534835785627\n",
      "Predicción post entrenamiento : [[0.31292835]]\n",
      "PERDIDAAAA despues: 0.00018041931616608053\n",
      "loss en el callback: 6.991063855821267e-06, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.3081277 ]\n",
      " [0.30916753]\n",
      " [0.31080288]\n",
      " [0.31202239]\n",
      " [0.31278205]\n",
      " [0.3120937 ]\n",
      " [0.31236392]\n",
      " [0.31289503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.31368312]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.3081277 ]\n",
      "  [0.30916753]\n",
      "  [0.31080288]\n",
      "  [0.31202239]\n",
      "  [0.31278205]\n",
      "  [0.3120937 ]\n",
      "  [0.31236392]\n",
      "  [0.31289503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014304321957752109\n",
      "Predicción post entrenamiento : [[0.313577]]\n",
      "PERDIDAAAA despues: 0.0014224158367142081\n",
      "loss en el callback: 8.422935206908733e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.30916753]\n",
      " [0.31080288]\n",
      " [0.31202239]\n",
      " [0.31278205]\n",
      " [0.3120937 ]\n",
      " [0.31236392]\n",
      " [0.31289503]\n",
      " [0.31368312]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.31424448]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.30916753]\n",
      "  [0.31080288]\n",
      "  [0.31202239]\n",
      "  [0.31278205]\n",
      "  [0.3120937 ]\n",
      "  [0.31236392]\n",
      "  [0.31289503]\n",
      "  [0.31368312]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015637881588190794\n",
      "Predicción post entrenamiento : [[0.3141124]]\n",
      "PERDIDAAAA despues: 0.0015533590922132134\n",
      "loss en el callback: 0.00014269535313360393, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.31080288]\n",
      " [0.31202239]\n",
      " [0.31278205]\n",
      " [0.3120937 ]\n",
      " [0.31236392]\n",
      " [0.31289503]\n",
      " [0.31368312]\n",
      " [0.31424448]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.31471112]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.31080288]\n",
      "  [0.31202239]\n",
      "  [0.31278205]\n",
      "  [0.3120937 ]\n",
      "  [0.31236392]\n",
      "  [0.31289503]\n",
      "  [0.31368312]\n",
      "  [0.31424448]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015395041555166245\n",
      "Predicción post entrenamiento : [[0.3141692]]\n",
      "PERDIDAAAA despues: 0.0014972713543102145\n",
      "loss en el callback: 0.0019781412556767464, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.31202239]\n",
      " [0.31278205]\n",
      " [0.3120937 ]\n",
      " [0.31236392]\n",
      " [0.31289503]\n",
      " [0.31368312]\n",
      " [0.31424448]\n",
      " [0.31471112]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3145387]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.31202239]\n",
      "  [0.31278205]\n",
      "  [0.3120937 ]\n",
      "  [0.31236392]\n",
      "  [0.31289503]\n",
      "  [0.31368312]\n",
      "  [0.31424448]\n",
      "  [0.31471112]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00040865724440664053\n",
      "Predicción post entrenamiento : [[0.31488633]]\n",
      "PERDIDAAAA despues: 0.0003947226796299219\n",
      "loss en el callback: 0.001057891291566193, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.31278205]\n",
      " [0.3120937 ]\n",
      " [0.31236392]\n",
      " [0.31289503]\n",
      " [0.31368312]\n",
      " [0.31424448]\n",
      " [0.31471112]\n",
      " [0.31453869]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.3150792]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.31278205]\n",
      "  [0.3120937 ]\n",
      "  [0.31236392]\n",
      "  [0.31289503]\n",
      "  [0.31368312]\n",
      "  [0.31424448]\n",
      "  [0.31471112]\n",
      "  [0.31453869]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016481060301885009\n",
      "Predicción post entrenamiento : [[0.31548473]]\n",
      "PERDIDAAAA despues: 0.0016153447795659304\n",
      "loss en el callback: 0.0013759535504505038, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.3120937 ]\n",
      " [0.31236392]\n",
      " [0.31289503]\n",
      " [0.31368312]\n",
      " [0.31424448]\n",
      " [0.31471112]\n",
      " [0.31453869]\n",
      " [0.31507921]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.31557983]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.3120937 ]\n",
      "  [0.31236392]\n",
      "  [0.31289503]\n",
      "  [0.31368312]\n",
      "  [0.31424448]\n",
      "  [0.31471112]\n",
      "  [0.31453869]\n",
      "  [0.31507921]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00044568991870619357\n",
      "Predicción post entrenamiento : [[0.31602028]]\n",
      "PERDIDAAAA despues: 0.00042728695552796125\n",
      "loss en el callback: 0.0019286322640255094, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.31236392]\n",
      " [0.31289503]\n",
      " [0.31368312]\n",
      " [0.31424448]\n",
      " [0.31471112]\n",
      " [0.31453869]\n",
      " [0.31507921]\n",
      " [0.31557983]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.31634086]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.31236392]\n",
      "  [0.31289503]\n",
      "  [0.31368312]\n",
      "  [0.31424448]\n",
      "  [0.31471112]\n",
      "  [0.31453869]\n",
      "  [0.31507921]\n",
      "  [0.31557983]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002975892857648432\n",
      "Predicción post entrenamiento : [[0.3167273]]\n",
      "PERDIDAAAA despues: 0.00028440559981390834\n",
      "loss en el callback: 0.001587532926350832, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.31289503]\n",
      " [0.31368312]\n",
      " [0.31424448]\n",
      " [0.31471112]\n",
      " [0.31453869]\n",
      " [0.31507921]\n",
      " [0.31557983]\n",
      " [0.31634086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.31709066]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.31289503]\n",
      "  [0.31368312]\n",
      "  [0.31424448]\n",
      "  [0.31471112]\n",
      "  [0.31453869]\n",
      "  [0.31507921]\n",
      "  [0.31557983]\n",
      "  [0.31634086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004575702827423811\n",
      "Predicción post entrenamiento : [[0.3178799]]\n",
      "PERDIDAAAA despues: 0.004469553008675575\n",
      "loss en el callback: 0.006250623147934675, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.31368312]\n",
      " [0.31424448]\n",
      " [0.31471112]\n",
      " [0.31453869]\n",
      " [0.31507921]\n",
      " [0.31557983]\n",
      " [0.31634086]\n",
      " [0.31709066]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.31823304]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.31368312]\n",
      "  [0.31424448]\n",
      "  [0.31471112]\n",
      "  [0.31453869]\n",
      "  [0.31507921]\n",
      "  [0.31557983]\n",
      "  [0.31634086]\n",
      "  [0.31709066]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06393991410732269\n",
      "Predicción post entrenamiento : [[0.3205776]]\n",
      "PERDIDAAAA despues: 0.06275971233844757\n",
      "loss en el callback: 0.05339062213897705, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.31424448]\n",
      " [0.31471112]\n",
      " [0.31453869]\n",
      " [0.31507921]\n",
      " [0.31557983]\n",
      " [0.31634086]\n",
      " [0.31709066]\n",
      " [0.31823304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.32086432]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.31424448]\n",
      "  [0.31471112]\n",
      "  [0.31453869]\n",
      "  [0.31507921]\n",
      "  [0.31557983]\n",
      "  [0.31634086]\n",
      "  [0.31709066]\n",
      "  [0.31823304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07585407793521881\n",
      "Predicción post entrenamiento : [[0.323502]]\n",
      "PERDIDAAAA despues: 0.07440811395645142\n",
      "loss en el callback: 0.10126782953739166, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.31471112]\n",
      " [0.31453869]\n",
      " [0.31507921]\n",
      " [0.31557983]\n",
      " [0.31634086]\n",
      " [0.31709066]\n",
      " [0.31823304]\n",
      " [0.32086432]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.32378134]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.31471112]\n",
      "  [0.31453869]\n",
      "  [0.31507921]\n",
      "  [0.31557983]\n",
      "  [0.31634086]\n",
      "  [0.31709066]\n",
      "  [0.31823304]\n",
      "  [0.32086432]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06290170550346375\n",
      "Predicción post entrenamiento : [[0.32612714]]\n",
      "PERDIDAAAA despues: 0.06173054873943329\n",
      "loss en el callback: 0.06081819161772728, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31453869]\n",
      " [0.31507921]\n",
      " [0.31557983]\n",
      " [0.31634086]\n",
      " [0.31709066]\n",
      " [0.31823304]\n",
      " [0.32086432]\n",
      " [0.32378134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.32645273]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31453869]\n",
      "  [0.31507921]\n",
      "  [0.31557983]\n",
      "  [0.31634086]\n",
      "  [0.31709066]\n",
      "  [0.31823304]\n",
      "  [0.32086432]\n",
      "  [0.32378134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07834478467702866\n",
      "Predicción post entrenamiento : [[0.32871765]]\n",
      "PERDIDAAAA despues: 0.07708200812339783\n",
      "loss en el callback: 0.04652179777622223, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31507921]\n",
      " [0.31557983]\n",
      " [0.31634086]\n",
      " [0.31709066]\n",
      " [0.31823304]\n",
      " [0.32086432]\n",
      " [0.32378134]\n",
      " [0.32645273]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3292892]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31507921]\n",
      "  [0.31557983]\n",
      "  [0.31634086]\n",
      "  [0.31709066]\n",
      "  [0.31823304]\n",
      "  [0.32086432]\n",
      "  [0.32378134]\n",
      "  [0.32645273]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06521277874708176\n",
      "Predicción post entrenamiento : [[0.3311562]]\n",
      "PERDIDAAAA despues: 0.06426272541284561\n",
      "loss en el callback: 0.03215130418539047, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.31557983]\n",
      " [0.31634086]\n",
      " [0.31709066]\n",
      " [0.31823304]\n",
      " [0.32086432]\n",
      " [0.32378134]\n",
      " [0.32645273]\n",
      " [0.3292892 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.33189464]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.31557983]\n",
      "  [0.31634086]\n",
      "  [0.31709066]\n",
      "  [0.31823304]\n",
      "  [0.32086432]\n",
      "  [0.32378134]\n",
      "  [0.32645273]\n",
      "  [0.3292892 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05611078068614006\n",
      "Predicción post entrenamiento : [[0.33408156]]\n",
      "PERDIDAAAA despues: 0.05507949739694595\n",
      "loss en el callback: 0.06241689249873161, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.31634086]\n",
      " [0.31709066]\n",
      " [0.31823304]\n",
      " [0.32086432]\n",
      " [0.32378134]\n",
      " [0.32645273]\n",
      " [0.3292892 ]\n",
      " [0.33189464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3350684]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.31634086]\n",
      "  [0.31709066]\n",
      "  [0.31823304]\n",
      "  [0.32086432]\n",
      "  [0.32378134]\n",
      "  [0.32645273]\n",
      "  [0.3292892 ]\n",
      "  [0.33189464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09468279778957367\n",
      "Predicción post entrenamiento : [[0.33772534]]\n",
      "PERDIDAAAA despues: 0.09305474907159805\n",
      "loss en el callback: 0.11524050682783127, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31709066]\n",
      " [0.31823304]\n",
      " [0.32086432]\n",
      " [0.32378134]\n",
      " [0.32645273]\n",
      " [0.3292892 ]\n",
      " [0.33189464]\n",
      " [0.3350684 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3389825]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31709066]\n",
      "  [0.31823304]\n",
      "  [0.32086432]\n",
      "  [0.32378134]\n",
      "  [0.32645273]\n",
      "  [0.3292892 ]\n",
      "  [0.33189464]\n",
      "  [0.3350684 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10418468713760376\n",
      "Predicción post entrenamiento : [[0.34169453]]\n",
      "PERDIDAAAA despues: 0.10244127362966537\n",
      "loss en el callback: 0.11089807003736496, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.31823304]\n",
      " [0.32086432]\n",
      " [0.32378134]\n",
      " [0.32645273]\n",
      " [0.3292892 ]\n",
      " [0.33189464]\n",
      " [0.3350684 ]\n",
      " [0.33898249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34330726]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.31823304]\n",
      "  [0.32086432]\n",
      "  [0.32378134]\n",
      "  [0.32645273]\n",
      "  [0.3292892 ]\n",
      "  [0.33189464]\n",
      "  [0.3350684 ]\n",
      "  [0.33898249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10869398713111877\n",
      "Predicción post entrenamiento : [[0.3460738]]\n",
      "PERDIDAAAA despues: 0.10687744617462158\n",
      "loss en el callback: 0.14954110980033875, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.32086432]\n",
      " [0.32378134]\n",
      " [0.32645273]\n",
      " [0.3292892 ]\n",
      " [0.33189464]\n",
      " [0.3350684 ]\n",
      " [0.33898249]\n",
      " [0.34330726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34804225]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.32086432]\n",
      "  [0.32378134]\n",
      "  [0.32645273]\n",
      "  [0.3292892 ]\n",
      "  [0.33189464]\n",
      "  [0.3350684 ]\n",
      "  [0.33898249]\n",
      "  [0.34330726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1314316689968109\n",
      "Predicción post entrenamiento : [[0.35091645]]\n",
      "PERDIDAAAA despues: 0.12935593724250793\n",
      "loss en el callback: 0.1399640589952469, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.32378134]\n",
      " [0.32645273]\n",
      " [0.3292892 ]\n",
      " [0.33189464]\n",
      " [0.3350684 ]\n",
      " [0.33898249]\n",
      " [0.34330726]\n",
      " [0.34804225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3529788]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.32378134]\n",
      "  [0.32645273]\n",
      "  [0.3292892 ]\n",
      "  [0.33189464]\n",
      "  [0.3350684 ]\n",
      "  [0.33898249]\n",
      "  [0.34330726]\n",
      "  [0.34804225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12320935726165771\n",
      "Predicción post entrenamiento : [[0.35559997]]\n",
      "PERDIDAAAA despues: 0.12137609720230103\n",
      "loss en el callback: 0.08047191798686981, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32645273]\n",
      " [0.3292892 ]\n",
      " [0.33189464]\n",
      " [0.3350684 ]\n",
      " [0.33898249]\n",
      " [0.34330726]\n",
      " [0.34804225]\n",
      " [0.3529788 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.357739]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32645273]\n",
      "  [0.3292892 ]\n",
      "  [0.33189464]\n",
      "  [0.3350684 ]\n",
      "  [0.33898249]\n",
      "  [0.34330726]\n",
      "  [0.34804225]\n",
      "  [0.3529788 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13652916252613068\n",
      "Predicción post entrenamiento : [[0.36061645]]\n",
      "PERDIDAAAA despues: 0.1344110071659088\n",
      "loss en el callback: 0.15525276958942413, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.3292892 ]\n",
      " [0.33189464]\n",
      " [0.3350684 ]\n",
      " [0.33898249]\n",
      " [0.34330726]\n",
      " [0.34804225]\n",
      " [0.3529788 ]\n",
      " [0.357739  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3629445]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.3292892 ]\n",
      "  [0.33189464]\n",
      "  [0.3350684 ]\n",
      "  [0.33898249]\n",
      "  [0.34330726]\n",
      "  [0.34804225]\n",
      "  [0.3529788 ]\n",
      "  [0.357739  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12934352457523346\n",
      "Predicción post entrenamiento : [[0.3657543]]\n",
      "PERDIDAAAA despues: 0.12733037769794464\n",
      "loss en el callback: 0.11827640980482101, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.33189464]\n",
      " [0.3350684 ]\n",
      " [0.33898249]\n",
      " [0.34330726]\n",
      " [0.34804225]\n",
      " [0.3529788 ]\n",
      " [0.357739  ]\n",
      " [0.36294451]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36830696]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.33189464]\n",
      "  [0.3350684 ]\n",
      "  [0.33898249]\n",
      "  [0.34330726]\n",
      "  [0.34804225]\n",
      "  [0.3529788 ]\n",
      "  [0.357739  ]\n",
      "  [0.36294451]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16280171275138855\n",
      "Predicción post entrenamiento : [[0.37135157]]\n",
      "PERDIDAAAA despues: 0.16035406291484833\n",
      "loss en el callback: 0.1587180346250534, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.3350684 ]\n",
      " [0.33898249]\n",
      " [0.34330726]\n",
      " [0.34804225]\n",
      " [0.3529788 ]\n",
      " [0.357739  ]\n",
      " [0.36294451]\n",
      " [0.36830696]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37426388]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.3350684 ]\n",
      "  [0.33898249]\n",
      "  [0.34330726]\n",
      "  [0.34804225]\n",
      "  [0.3529788 ]\n",
      "  [0.357739  ]\n",
      "  [0.36294451]\n",
      "  [0.36830696]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12268312275409698\n",
      "Predicción post entrenamiento : [[0.37688315]]\n",
      "PERDIDAAAA despues: 0.12085513025522232\n",
      "loss en el callback: 0.12057499587535858, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33898249]\n",
      " [0.34330726]\n",
      " [0.34804225]\n",
      " [0.3529788 ]\n",
      " [0.357739  ]\n",
      " [0.36294451]\n",
      " [0.36830696]\n",
      " [0.37426388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38011402]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33898249]\n",
      "  [0.34330726]\n",
      "  [0.34804225]\n",
      "  [0.3529788 ]\n",
      "  [0.357739  ]\n",
      "  [0.36294451]\n",
      "  [0.36830696]\n",
      "  [0.37426388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08464822918176651\n",
      "Predicción post entrenamiento : [[0.38221425]]\n",
      "PERDIDAAAA despues: 0.08343054354190826\n",
      "loss en el callback: 0.06405545026063919, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34330726]\n",
      " [0.34804225]\n",
      " [0.3529788 ]\n",
      " [0.357739  ]\n",
      " [0.36294451]\n",
      " [0.36830696]\n",
      " [0.37426388]\n",
      " [0.38011402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3856666]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34330726]\n",
      "  [0.34804225]\n",
      "  [0.3529788 ]\n",
      "  [0.357739  ]\n",
      "  [0.36294451]\n",
      "  [0.36830696]\n",
      "  [0.37426388]\n",
      "  [0.38011402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.083003468811512\n",
      "Predicción post entrenamiento : [[0.38755304]]\n",
      "PERDIDAAAA despues: 0.08192005753517151\n",
      "loss en el callback: 0.05822589993476868, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34804225]\n",
      " [0.3529788 ]\n",
      " [0.357739  ]\n",
      " [0.36294451]\n",
      " [0.36830696]\n",
      " [0.37426388]\n",
      " [0.38011402]\n",
      " [0.38566661]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39118794]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34804225]\n",
      "  [0.3529788 ]\n",
      "  [0.357739  ]\n",
      "  [0.36294451]\n",
      "  [0.36830696]\n",
      "  [0.37426388]\n",
      "  [0.38011402]\n",
      "  [0.38566661]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10449951887130737\n",
      "Predicción post entrenamiento : [[0.39348418]]\n",
      "PERDIDAAAA despues: 0.10302020609378815\n",
      "loss en el callback: 0.09004505723714828, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.3529788 ]\n",
      " [0.357739  ]\n",
      " [0.36294451]\n",
      " [0.36830696]\n",
      " [0.37426388]\n",
      " [0.38011402]\n",
      " [0.38566661]\n",
      " [0.39118794]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39725134]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.3529788 ]\n",
      "  [0.357739  ]\n",
      "  [0.36294451]\n",
      "  [0.36830696]\n",
      "  [0.37426388]\n",
      "  [0.38011402]\n",
      "  [0.38566661]\n",
      "  [0.39118794]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12016372382640839\n",
      "Predicción post entrenamiento : [[0.39976916]]\n",
      "PERDIDAAAA despues: 0.11842447519302368\n",
      "loss en el callback: 0.17989398539066315, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.357739  ]\n",
      " [0.36294451]\n",
      " [0.36830696]\n",
      " [0.37426388]\n",
      " [0.38011402]\n",
      " [0.38566661]\n",
      " [0.39118794]\n",
      " [0.39725134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40365756]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.357739  ]\n",
      "  [0.36294451]\n",
      "  [0.36830696]\n",
      "  [0.37426388]\n",
      "  [0.38011402]\n",
      "  [0.38566661]\n",
      "  [0.39118794]\n",
      "  [0.39725134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10171670466661453\n",
      "Predicción post entrenamiento : [[0.40562573]]\n",
      "PERDIDAAAA despues: 0.10046515613794327\n",
      "loss en el callback: 0.058230429887771606, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36294451]\n",
      " [0.36830696]\n",
      " [0.37426388]\n",
      " [0.38011402]\n",
      " [0.38566661]\n",
      " [0.39118794]\n",
      " [0.39725134]\n",
      " [0.40365756]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.40971333]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36294451]\n",
      "  [0.36830696]\n",
      "  [0.37426388]\n",
      "  [0.38011402]\n",
      "  [0.38566661]\n",
      "  [0.39118794]\n",
      "  [0.39725134]\n",
      "  [0.40365756]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08388439565896988\n",
      "Predicción post entrenamiento : [[0.41161475]]\n",
      "PERDIDAAAA despues: 0.08278660476207733\n",
      "loss en el callback: 0.062428731471300125, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36830696]\n",
      " [0.37426388]\n",
      " [0.38011402]\n",
      " [0.38566661]\n",
      " [0.39118794]\n",
      " [0.39725134]\n",
      " [0.40365756]\n",
      " [0.40971333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.41583672]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36830696]\n",
      "  [0.37426388]\n",
      "  [0.38011402]\n",
      "  [0.38566661]\n",
      "  [0.39118794]\n",
      "  [0.39725134]\n",
      "  [0.40365756]\n",
      "  [0.40971333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10334578901529312\n",
      "Predicción post entrenamiento : [[0.41804183]]\n",
      "PERDIDAAAA despues: 0.10193288326263428\n",
      "loss en el callback: 0.08960872143507004, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37426388]\n",
      " [0.38011402]\n",
      " [0.38566661]\n",
      " [0.39118794]\n",
      " [0.39725134]\n",
      " [0.40365756]\n",
      " [0.40971333]\n",
      " [0.41583672]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4223915]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37426388]\n",
      "  [0.38011402]\n",
      "  [0.38566661]\n",
      "  [0.39118794]\n",
      "  [0.39725134]\n",
      "  [0.40365756]\n",
      "  [0.40971333]\n",
      "  [0.41583672]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08942152559757233\n",
      "Predicción post entrenamiento : [[0.42453945]]\n",
      "PERDIDAAAA despues: 0.08814152330160141\n",
      "loss en el callback: 0.14608870446681976, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38011402]\n",
      " [0.38566661]\n",
      " [0.39118794]\n",
      " [0.39725134]\n",
      " [0.40365756]\n",
      " [0.40971333]\n",
      " [0.41583672]\n",
      " [0.4223915 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.42889735]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38011402]\n",
      "  [0.38566661]\n",
      "  [0.39118794]\n",
      "  [0.39725134]\n",
      "  [0.40365756]\n",
      "  [0.40971333]\n",
      "  [0.41583672]\n",
      "  [0.4223915 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08399351686239243\n",
      "Predicción post entrenamiento : [[0.43088418]]\n",
      "PERDIDAAAA despues: 0.08284582942724228\n",
      "loss en el callback: 0.08051764965057373, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38566661]\n",
      " [0.39118794]\n",
      " [0.39725134]\n",
      " [0.40365756]\n",
      " [0.40971333]\n",
      " [0.41583672]\n",
      " [0.4223915 ]\n",
      " [0.42889735]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.43528876]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38566661]\n",
      "  [0.39118794]\n",
      "  [0.39725134]\n",
      "  [0.40365756]\n",
      "  [0.40971333]\n",
      "  [0.41583672]\n",
      "  [0.4223915 ]\n",
      "  [0.42889735]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057058192789554596\n",
      "Predicción post entrenamiento : [[0.4369941]]\n",
      "PERDIDAAAA despues: 0.05624639242887497\n",
      "loss en el callback: 0.06861931085586548, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39118794]\n",
      " [0.39725134]\n",
      " [0.40365756]\n",
      " [0.40971333]\n",
      " [0.41583672]\n",
      " [0.4223915 ]\n",
      " [0.42889735]\n",
      " [0.43528876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44153985]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39118794]\n",
      "  [0.39725134]\n",
      "  [0.40365756]\n",
      "  [0.40971333]\n",
      "  [0.41583672]\n",
      "  [0.4223915 ]\n",
      "  [0.42889735]\n",
      "  [0.43528876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06606266647577286\n",
      "Predicción post entrenamiento : [[0.44330075]]\n",
      "PERDIDAAAA despues: 0.06516057252883911\n",
      "loss en el callback: 0.07261259108781815, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39725134]\n",
      " [0.40365756]\n",
      " [0.40971333]\n",
      " [0.41583672]\n",
      " [0.4223915 ]\n",
      " [0.42889735]\n",
      " [0.43528876]\n",
      " [0.44153985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.44802836]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39725134]\n",
      "  [0.40365756]\n",
      "  [0.40971333]\n",
      "  [0.41583672]\n",
      "  [0.4223915 ]\n",
      "  [0.42889735]\n",
      "  [0.43528876]\n",
      "  [0.44153985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07453445345163345\n",
      "Predicción post entrenamiento : [[0.4500101]]\n",
      "PERDIDAAAA despues: 0.073456309735775\n",
      "loss en el callback: 0.10817823559045792, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40365756]\n",
      " [0.40971333]\n",
      " [0.41583672]\n",
      " [0.4223915 ]\n",
      " [0.42889735]\n",
      " [0.43528876]\n",
      " [0.44153985]\n",
      " [0.44802836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4548168]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40365756]\n",
      "  [0.40971333]\n",
      "  [0.41583672]\n",
      "  [0.4223915 ]\n",
      "  [0.42889735]\n",
      "  [0.43528876]\n",
      "  [0.44153985]\n",
      "  [0.44802836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07170148938894272\n",
      "Predicción post entrenamiento : [[0.456811]]\n",
      "PERDIDAAAA despues: 0.07063747197389603\n",
      "loss en el callback: 0.10079407691955566, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.40971333]\n",
      " [0.41583672]\n",
      " [0.4223915 ]\n",
      " [0.42889735]\n",
      " [0.43528876]\n",
      " [0.44153985]\n",
      " [0.44802836]\n",
      " [0.45481679]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.46162447]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.40971333]\n",
      "  [0.41583672]\n",
      "  [0.4223915 ]\n",
      "  [0.42889735]\n",
      "  [0.43528876]\n",
      "  [0.44153985]\n",
      "  [0.44802836]\n",
      "  [0.45481679]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08683133125305176\n",
      "Predicción post entrenamiento : [[0.4636067]]\n",
      "PERDIDAAAA despues: 0.08566705882549286\n",
      "loss en el callback: 0.08827857673168182, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41583672]\n",
      " [0.4223915 ]\n",
      " [0.42889735]\n",
      " [0.43528876]\n",
      " [0.44153985]\n",
      " [0.44802836]\n",
      " [0.45481679]\n",
      " [0.46162447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.46852282]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41583672]\n",
      "  [0.4223915 ]\n",
      "  [0.42889735]\n",
      "  [0.43528876]\n",
      "  [0.44153985]\n",
      "  [0.44802836]\n",
      "  [0.45481679]\n",
      "  [0.46162447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12892653048038483\n",
      "Predicción post entrenamiento : [[0.47086862]]\n",
      "PERDIDAAAA despues: 0.12724745273590088\n",
      "loss en el callback: 0.15236599743366241, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.4223915 ]\n",
      " [0.42889735]\n",
      " [0.43528876]\n",
      " [0.44153985]\n",
      " [0.44802836]\n",
      " [0.45481679]\n",
      " [0.46162447]\n",
      " [0.46852282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.47589415]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.4223915 ]\n",
      "  [0.42889735]\n",
      "  [0.43528876]\n",
      "  [0.44153985]\n",
      "  [0.44802836]\n",
      "  [0.45481679]\n",
      "  [0.46162447]\n",
      "  [0.46852282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1317167580127716\n",
      "Predicción post entrenamiento : [[0.4780022]]\n",
      "PERDIDAAAA despues: 0.13019107282161713\n",
      "loss en el callback: 0.08422081172466278, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.42889735]\n",
      " [0.43528876]\n",
      " [0.44153985]\n",
      " [0.44802836]\n",
      " [0.45481679]\n",
      " [0.46162447]\n",
      " [0.46852282]\n",
      " [0.47589415]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.48305082]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.42889735]\n",
      "  [0.43528876]\n",
      "  [0.44153985]\n",
      "  [0.44802836]\n",
      "  [0.45481679]\n",
      "  [0.46162447]\n",
      "  [0.46852282]\n",
      "  [0.47589415]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09685476869344711\n",
      "Predicción post entrenamiento : [[0.48496073]]\n",
      "PERDIDAAAA despues: 0.09566962718963623\n",
      "loss en el callback: 0.08585859835147858, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.43528876]\n",
      " [0.44153985]\n",
      " [0.44802836]\n",
      " [0.45481679]\n",
      " [0.46162447]\n",
      " [0.46852282]\n",
      " [0.47589415]\n",
      " [0.48305082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.49005935]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.43528876]\n",
      "  [0.44153985]\n",
      "  [0.44802836]\n",
      "  [0.45481679]\n",
      "  [0.46162447]\n",
      "  [0.46852282]\n",
      "  [0.47589415]\n",
      "  [0.48305082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08628634363412857\n",
      "Predicción post entrenamiento : [[0.49204028]]\n",
      "PERDIDAAAA despues: 0.08512648940086365\n",
      "loss en el callback: 0.10845860093832016, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44153985]\n",
      " [0.44802836]\n",
      " [0.45481679]\n",
      " [0.46162447]\n",
      " [0.46852282]\n",
      " [0.47589415]\n",
      " [0.48305082]\n",
      " [0.49005935]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.4972408]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44153985]\n",
      "  [0.44802836]\n",
      "  [0.45481679]\n",
      "  [0.46162447]\n",
      "  [0.46852282]\n",
      "  [0.47589415]\n",
      "  [0.48305082]\n",
      "  [0.49005935]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0732669085264206\n",
      "Predicción post entrenamiento : [[0.49859774]]\n",
      "PERDIDAAAA despues: 0.07253416627645493\n",
      "loss en el callback: 0.035133231431245804, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.44802836]\n",
      " [0.45481679]\n",
      " [0.46162447]\n",
      " [0.46852282]\n",
      " [0.47589415]\n",
      " [0.48305082]\n",
      " [0.49005935]\n",
      " [0.49724081]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5039647]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.44802836]\n",
      "  [0.45481679]\n",
      "  [0.46162447]\n",
      "  [0.46852282]\n",
      "  [0.47589415]\n",
      "  [0.48305082]\n",
      "  [0.49005935]\n",
      "  [0.49724081]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07874473184347153\n",
      "Predicción post entrenamiento : [[0.50570744]]\n",
      "PERDIDAAAA despues: 0.0777696967124939\n",
      "loss en el callback: 0.07520823925733566, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.45481679]\n",
      " [0.46162447]\n",
      " [0.46852282]\n",
      " [0.47589415]\n",
      " [0.48305082]\n",
      " [0.49005935]\n",
      " [0.49724081]\n",
      " [0.50396472]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5112138]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.45481679]\n",
      "  [0.46162447]\n",
      "  [0.46852282]\n",
      "  [0.47589415]\n",
      "  [0.48305082]\n",
      "  [0.49005935]\n",
      "  [0.49724081]\n",
      "  [0.50396472]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13506755232810974\n",
      "Predicción post entrenamiento : [[0.5135028]]\n",
      "PERDIDAAAA despues: 0.13339030742645264\n",
      "loss en el callback: 0.11412951350212097, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.46162447]\n",
      " [0.46852282]\n",
      " [0.47589415]\n",
      " [0.48305082]\n",
      " [0.49005935]\n",
      " [0.49724081]\n",
      " [0.50396472]\n",
      " [0.51121378]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.51909494]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.46162447]\n",
      "  [0.46852282]\n",
      "  [0.47589415]\n",
      "  [0.48305082]\n",
      "  [0.49005935]\n",
      "  [0.49724081]\n",
      "  [0.50396472]\n",
      "  [0.51121378]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12711696326732635\n",
      "Predicción post entrenamiento : [[0.5214385]]\n",
      "PERDIDAAAA despues: 0.12545135617256165\n",
      "loss en el callback: 0.18534782528877258, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.46852282]\n",
      " [0.47589415]\n",
      " [0.48305082]\n",
      " [0.49005935]\n",
      " [0.49724081]\n",
      " [0.50396472]\n",
      " [0.51121378]\n",
      " [0.51909494]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5271278]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.46852282]\n",
      "  [0.47589415]\n",
      "  [0.48305082]\n",
      "  [0.49005935]\n",
      "  [0.49724081]\n",
      "  [0.50396472]\n",
      "  [0.51121378]\n",
      "  [0.51909494]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10353463888168335\n",
      "Predicción post entrenamiento : [[0.5287726]]\n",
      "PERDIDAAAA despues: 0.10247886180877686\n",
      "loss en el callback: 0.051930543035268784, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.47589415]\n",
      " [0.48305082]\n",
      " [0.49005935]\n",
      " [0.49724081]\n",
      " [0.50396472]\n",
      " [0.51121378]\n",
      " [0.51909494]\n",
      " [0.5271278 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5345544]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.47589415]\n",
      "  [0.48305082]\n",
      "  [0.49005935]\n",
      "  [0.49724081]\n",
      "  [0.50396472]\n",
      "  [0.51121378]\n",
      "  [0.51909494]\n",
      "  [0.5271278 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08050445467233658\n",
      "Predicción post entrenamiento : [[0.53631204]]\n",
      "PERDIDAAAA despues: 0.0795101523399353\n",
      "loss en el callback: 0.07778292894363403, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.48305082]\n",
      " [0.49005935]\n",
      " [0.49724081]\n",
      " [0.50396472]\n",
      " [0.51121378]\n",
      " [0.51909494]\n",
      " [0.5271278 ]\n",
      " [0.53455442]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.542082]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.48305082]\n",
      "  [0.49005935]\n",
      "  [0.49724081]\n",
      "  [0.50396472]\n",
      "  [0.51121378]\n",
      "  [0.51909494]\n",
      "  [0.5271278 ]\n",
      "  [0.53455442]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08107077330350876\n",
      "Predicción post entrenamiento : [[0.54380924]]\n",
      "PERDIDAAAA despues: 0.08009018003940582\n",
      "loss en el callback: 0.08525460213422775, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.49005935]\n",
      " [0.49724081]\n",
      " [0.50396472]\n",
      " [0.51121378]\n",
      " [0.51909494]\n",
      " [0.5271278 ]\n",
      " [0.53455442]\n",
      " [0.54208201]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.54963297]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.49005935]\n",
      "  [0.49724081]\n",
      "  [0.50396472]\n",
      "  [0.51121378]\n",
      "  [0.51909494]\n",
      "  [0.5271278 ]\n",
      "  [0.53455442]\n",
      "  [0.54208201]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05556463822722435\n",
      "Predicción post entrenamiento : [[0.5511398]]\n",
      "PERDIDAAAA despues: 0.05485653504729271\n",
      "loss en el callback: 0.07495874911546707, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.49724081]\n",
      " [0.50396472]\n",
      " [0.51121378]\n",
      " [0.51909494]\n",
      " [0.5271278 ]\n",
      " [0.53455442]\n",
      " [0.54208201]\n",
      " [0.54963297]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5570764]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.49724081]\n",
      "  [0.50396472]\n",
      "  [0.51121378]\n",
      "  [0.51909494]\n",
      "  [0.5271278 ]\n",
      "  [0.53455442]\n",
      "  [0.54208201]\n",
      "  [0.54963297]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05389482155442238\n",
      "Predicción post entrenamiento : [[0.5583685]]\n",
      "PERDIDAAAA despues: 0.05329655855894089\n",
      "loss en el callback: 0.04747169837355614, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.50396472]\n",
      " [0.51121378]\n",
      " [0.51909494]\n",
      " [0.5271278 ]\n",
      " [0.53455442]\n",
      " [0.54208201]\n",
      " [0.54963297]\n",
      " [0.55707639]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.56439626]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.50396472]\n",
      "  [0.51121378]\n",
      "  [0.51909494]\n",
      "  [0.5271278 ]\n",
      "  [0.53455442]\n",
      "  [0.54208201]\n",
      "  [0.54963297]\n",
      "  [0.55707639]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07277937233448029\n",
      "Predicción post entrenamiento : [[0.56633395]]\n",
      "PERDIDAAAA despues: 0.07173763960599899\n",
      "loss en el callback: 0.13812533020973206, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.51121378]\n",
      " [0.51909494]\n",
      " [0.5271278 ]\n",
      " [0.53455442]\n",
      " [0.54208201]\n",
      " [0.54963297]\n",
      " [0.55707639]\n",
      " [0.56439626]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5725959]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.51121378]\n",
      "  [0.51909494]\n",
      "  [0.5271278 ]\n",
      "  [0.53455442]\n",
      "  [0.54208201]\n",
      "  [0.54963297]\n",
      "  [0.55707639]\n",
      "  [0.56439626]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05754236876964569\n",
      "Predicción post entrenamiento : [[0.574113]]\n",
      "PERDIDAAAA despues: 0.05681682005524635\n",
      "loss en el callback: 0.07096729427576065, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.51909494]\n",
      " [0.5271278 ]\n",
      " [0.53455442]\n",
      " [0.54208201]\n",
      " [0.54963297]\n",
      " [0.55707639]\n",
      " [0.56439626]\n",
      " [0.57259589]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.58049995]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.51909494]\n",
      "  [0.5271278 ]\n",
      "  [0.53455442]\n",
      "  [0.54208201]\n",
      "  [0.54963297]\n",
      "  [0.55707639]\n",
      "  [0.56439626]\n",
      "  [0.57259589]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04872610419988632\n",
      "Predicción post entrenamiento : [[0.58180124]]\n",
      "PERDIDAAAA despues: 0.04815330356359482\n",
      "loss en el callback: 0.04925010725855827, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.5271278 ]\n",
      " [0.53455442]\n",
      " [0.54208201]\n",
      " [0.54963297]\n",
      " [0.55707639]\n",
      " [0.56439626]\n",
      " [0.57259589]\n",
      " [0.58049995]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.5881533]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.5271278 ]\n",
      "  [0.53455442]\n",
      "  [0.54208201]\n",
      "  [0.54963297]\n",
      "  [0.55707639]\n",
      "  [0.56439626]\n",
      "  [0.57259589]\n",
      "  [0.58049995]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04623521491885185\n",
      "Predicción post entrenamiento : [[0.58959574]]\n",
      "PERDIDAAAA despues: 0.04561698064208031\n",
      "loss en el callback: 0.07197785377502441, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.53455442]\n",
      " [0.54208201]\n",
      " [0.54963297]\n",
      " [0.55707639]\n",
      " [0.56439626]\n",
      " [0.57259589]\n",
      " [0.58049995]\n",
      " [0.5881533 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.59586316]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.53455442]\n",
      "  [0.54208201]\n",
      "  [0.54963297]\n",
      "  [0.55707639]\n",
      "  [0.56439626]\n",
      "  [0.57259589]\n",
      "  [0.58049995]\n",
      "  [0.5881533 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03905671834945679\n",
      "Predicción post entrenamiento : [[0.59686816]]\n",
      "PERDIDAAAA despues: 0.03866049647331238\n",
      "loss en el callback: 0.025714807212352753, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.54208201]\n",
      " [0.54963297]\n",
      " [0.55707639]\n",
      " [0.56439626]\n",
      " [0.57259589]\n",
      " [0.58049995]\n",
      " [0.5881533 ]\n",
      " [0.59586316]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6032056]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.54208201]\n",
      "  [0.54963297]\n",
      "  [0.55707639]\n",
      "  [0.56439626]\n",
      "  [0.57259589]\n",
      "  [0.58049995]\n",
      "  [0.5881533 ]\n",
      "  [0.59586316]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024637959897518158\n",
      "Predicción post entrenamiento : [[0.60377854]]\n",
      "PERDIDAAAA despues: 0.02445843257009983\n",
      "loss en el callback: 0.007781853433698416, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.54963297]\n",
      " [0.55707639]\n",
      " [0.56439626]\n",
      " [0.57259589]\n",
      " [0.58049995]\n",
      " [0.5881533 ]\n",
      " [0.59586316]\n",
      " [0.60320562]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.61016876]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.54963297]\n",
      "  [0.55707639]\n",
      "  [0.56439626]\n",
      "  [0.57259589]\n",
      "  [0.58049995]\n",
      "  [0.5881533 ]\n",
      "  [0.59586316]\n",
      "  [0.60320562]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015676332637667656\n",
      "Predicción post entrenamiento : [[0.6109882]]\n",
      "PERDIDAAAA despues: 0.015471805818378925\n",
      "loss en el callback: 0.019872689619660378, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.55707639]\n",
      " [0.56439626]\n",
      " [0.57259589]\n",
      " [0.58049995]\n",
      " [0.5881533 ]\n",
      " [0.59586316]\n",
      " [0.60320562]\n",
      " [0.61016876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.61742866]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.55707639]\n",
      "  [0.56439626]\n",
      "  [0.57259589]\n",
      "  [0.58049995]\n",
      "  [0.5881533 ]\n",
      "  [0.59586316]\n",
      "  [0.60320562]\n",
      "  [0.61016876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008604632690548897\n",
      "Predicción post entrenamiento : [[0.61782306]]\n",
      "PERDIDAAAA despues: 0.008531617000699043\n",
      "loss en el callback: 0.004042936488986015, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.56439626]\n",
      " [0.57259589]\n",
      " [0.58049995]\n",
      " [0.5881533 ]\n",
      " [0.59586316]\n",
      " [0.60320562]\n",
      " [0.61016876]\n",
      " [0.61742866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.62433916]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.56439626]\n",
      "  [0.57259589]\n",
      "  [0.58049995]\n",
      "  [0.5881533 ]\n",
      "  [0.59586316]\n",
      "  [0.60320562]\n",
      "  [0.61016876]\n",
      "  [0.61742866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007706719916313887\n",
      "Predicción post entrenamiento : [[0.6246293]]\n",
      "PERDIDAAAA despues: 0.007655859924852848\n",
      "loss en el callback: 0.002229750156402588, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.57259589]\n",
      " [0.58049995]\n",
      " [0.5881533 ]\n",
      " [0.59586316]\n",
      " [0.60320562]\n",
      " [0.61016876]\n",
      " [0.61742866]\n",
      " [0.62433916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6312482]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.57259589]\n",
      "  [0.58049995]\n",
      "  [0.5881533 ]\n",
      "  [0.59586316]\n",
      "  [0.60320562]\n",
      "  [0.61016876]\n",
      "  [0.61742866]\n",
      "  [0.62433916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011747882701456547\n",
      "Predicción post entrenamiento : [[0.6322602]]\n",
      "PERDIDAAAA despues: 0.011529523879289627\n",
      "loss en el callback: 0.037857163697481155, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.58049995]\n",
      " [0.5881533 ]\n",
      " [0.59586316]\n",
      " [0.60320562]\n",
      " [0.61016876]\n",
      " [0.61742866]\n",
      " [0.62433916]\n",
      " [0.63124818]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6387264]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.58049995]\n",
      "  [0.5881533 ]\n",
      "  [0.59586316]\n",
      "  [0.60320562]\n",
      "  [0.61016876]\n",
      "  [0.61742866]\n",
      "  [0.62433916]\n",
      "  [0.63124818]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009491116739809513\n",
      "Predicción post entrenamiento : [[0.63929033]]\n",
      "PERDIDAAAA despues: 0.009381557814776897\n",
      "loss en el callback: 0.00896825548261404, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.5881533 ]\n",
      " [0.59586316]\n",
      " [0.60320562]\n",
      " [0.61016876]\n",
      " [0.61742866]\n",
      " [0.62433916]\n",
      " [0.63124818]\n",
      " [0.63872641]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6456385]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.5881533 ]\n",
      "  [0.59586316]\n",
      "  [0.60320562]\n",
      "  [0.61016876]\n",
      "  [0.61742866]\n",
      "  [0.62433916]\n",
      "  [0.63124818]\n",
      "  [0.63872641]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00048102071741595864\n",
      "Predicción post entrenamiento : [[0.645405]]\n",
      "PERDIDAAAA despues: 0.0004913189332000911\n",
      "loss en el callback: 0.0014406850095838308, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.59586316]\n",
      " [0.60320562]\n",
      " [0.61016876]\n",
      " [0.61742866]\n",
      " [0.62433916]\n",
      " [0.63124818]\n",
      " [0.63872641]\n",
      " [0.64563853]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6516664]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.59586316]\n",
      "  [0.60320562]\n",
      "  [0.61016876]\n",
      "  [0.61742866]\n",
      "  [0.62433916]\n",
      "  [0.63124818]\n",
      "  [0.63872641]\n",
      "  [0.64563853]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003322967095300555\n",
      "Predicción post entrenamiento : [[0.651483]]\n",
      "PERDIDAAAA despues: 0.00033901690039783716\n",
      "loss en el callback: 0.0008698917808942497, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.60320562]\n",
      " [0.61016876]\n",
      " [0.61742866]\n",
      " [0.62433916]\n",
      " [0.63124818]\n",
      " [0.63872641]\n",
      " [0.64563853]\n",
      " [0.6516664 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.65760946]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.60320562]\n",
      "  [0.61016876]\n",
      "  [0.61742866]\n",
      "  [0.62433916]\n",
      "  [0.63124818]\n",
      "  [0.63872641]\n",
      "  [0.64563853]\n",
      "  [0.6516664 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015225419774651527\n",
      "Predicción post entrenamiento : [[0.65783525]]\n",
      "PERDIDAAAA despues: 0.0015049729263409972\n",
      "loss en el callback: 0.001554609159938991, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.61016876]\n",
      " [0.61742866]\n",
      " [0.62433916]\n",
      " [0.63124818]\n",
      " [0.63872641]\n",
      " [0.64563853]\n",
      " [0.6516664 ]\n",
      " [0.65760946]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.66389036]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.61016876]\n",
      "  [0.61742866]\n",
      "  [0.62433916]\n",
      "  [0.63124818]\n",
      "  [0.63872641]\n",
      "  [0.64563853]\n",
      "  [0.6516664 ]\n",
      "  [0.65760946]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.309179298114032e-05\n",
      "Predicción post entrenamiento : [[0.6638791]]\n",
      "PERDIDAAAA despues: 6.29129572189413e-05\n",
      "loss en el callback: 3.597845079639228e-06, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.61742866]\n",
      " [0.62433916]\n",
      " [0.63124818]\n",
      " [0.63872641]\n",
      " [0.64563853]\n",
      " [0.6516664 ]\n",
      " [0.65760946]\n",
      " [0.66389036]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.6699361]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.61742866]\n",
      "  [0.62433916]\n",
      "  [0.63124818]\n",
      "  [0.63872641]\n",
      "  [0.64563853]\n",
      "  [0.6516664 ]\n",
      "  [0.65760946]\n",
      "  [0.66389036]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.868651300668716e-05\n",
      "Predicción post entrenamiento : [[0.67034656]]\n",
      "PERDIDAAAA despues: 7.157336949603632e-05\n",
      "loss en el callback: 0.006396602839231491, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.62433916]\n",
      " [0.63124818]\n",
      " [0.63872641]\n",
      " [0.64563853]\n",
      " [0.6516664 ]\n",
      " [0.65760946]\n",
      " [0.66389036]\n",
      " [0.66993612]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.6762938]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.62433916]\n",
      "  [0.63124818]\n",
      "  [0.63872641]\n",
      "  [0.64563853]\n",
      "  [0.6516664 ]\n",
      "  [0.65760946]\n",
      "  [0.66389036]\n",
      "  [0.66993612]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.970388107177314e-08\n",
      "Predicción post entrenamiento : [[0.6758787]]\n",
      "PERDIDAAAA despues: 4.658190633222148e-08\n",
      "loss en el callback: 0.004610992968082428, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.63124818]\n",
      " [0.63872641]\n",
      " [0.64563853]\n",
      " [0.6516664 ]\n",
      " [0.65760946]\n",
      " [0.66389036]\n",
      " [0.66993612]\n",
      " [0.67629379]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.6817684]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.63124818]\n",
      "  [0.63872641]\n",
      "  [0.64563853]\n",
      "  [0.6516664 ]\n",
      "  [0.65760946]\n",
      "  [0.66389036]\n",
      "  [0.66993612]\n",
      "  [0.67629379]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002284242073073983\n",
      "Predicción post entrenamiento : [[0.68147933]]\n",
      "PERDIDAAAA despues: 0.0023119584657251835\n",
      "loss en el callback: 0.0022338724229484797, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.63872641]\n",
      " [0.64563853]\n",
      " [0.6516664 ]\n",
      " [0.65760946]\n",
      " [0.66389036]\n",
      " [0.66993612]\n",
      " [0.67629379]\n",
      " [0.68176842]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.6872731]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.63872641]\n",
      "  [0.64563853]\n",
      "  [0.6516664 ]\n",
      "  [0.65760946]\n",
      "  [0.66389036]\n",
      "  [0.66993612]\n",
      "  [0.67629379]\n",
      "  [0.68176842]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001961535308510065\n",
      "Predicción post entrenamiento : [[0.68806744]]\n",
      "PERDIDAAAA despues: 0.00017453398322686553\n",
      "loss en el callback: 0.03130112960934639, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.64563853]\n",
      " [0.6516664 ]\n",
      " [0.65760946]\n",
      " [0.66389036]\n",
      " [0.66993612]\n",
      " [0.67629379]\n",
      " [0.68176842]\n",
      " [0.68727309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.6935587]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.64563853]\n",
      "  [0.6516664 ]\n",
      "  [0.65760946]\n",
      "  [0.66389036]\n",
      "  [0.66993612]\n",
      "  [0.67629379]\n",
      "  [0.68176842]\n",
      "  [0.68727309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0054720486514270306\n",
      "Predicción post entrenamiento : [[0.69396037]]\n",
      "PERDIDAAAA despues: 0.005412783473730087\n",
      "loss en el callback: 0.005062866024672985, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.6516664 ]\n",
      " [0.65760946]\n",
      " [0.66389036]\n",
      " [0.66993612]\n",
      " [0.67629379]\n",
      " [0.68176842]\n",
      " [0.68727309]\n",
      " [0.69355869]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.6992441]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.6516664 ]\n",
      "  [0.65760946]\n",
      "  [0.66389036]\n",
      "  [0.66993612]\n",
      "  [0.67629379]\n",
      "  [0.68176842]\n",
      "  [0.68727309]\n",
      "  [0.69355869]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031236479990184307\n",
      "Predicción post entrenamiento : [[0.69984174]]\n",
      "PERDIDAAAA despues: 0.003057199763134122\n",
      "loss en el callback: 0.01269534882158041, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.65760946]\n",
      " [0.66389036]\n",
      " [0.66993612]\n",
      " [0.67629379]\n",
      " [0.68176842]\n",
      " [0.68727309]\n",
      " [0.69355869]\n",
      " [0.69924408]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7051301]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.65760946]\n",
      "  [0.66389036]\n",
      "  [0.66993612]\n",
      "  [0.67629379]\n",
      "  [0.68176842]\n",
      "  [0.68727309]\n",
      "  [0.69355869]\n",
      "  [0.69924408]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015943989856168628\n",
      "Predicción post entrenamiento : [[0.7057671]]\n",
      "PERDIDAAAA despues: 0.0015439344570040703\n",
      "loss en el callback: 0.016582908108830452, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.66389036]\n",
      " [0.66993612]\n",
      " [0.67629379]\n",
      " [0.68176842]\n",
      " [0.68727309]\n",
      " [0.69355869]\n",
      " [0.69924408]\n",
      " [0.7051301 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7110763]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.66389036]\n",
      "  [0.66993612]\n",
      "  [0.67629379]\n",
      "  [0.68176842]\n",
      "  [0.68727309]\n",
      "  [0.69355869]\n",
      "  [0.69924408]\n",
      "  [0.7051301 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001677537220530212\n",
      "Predicción post entrenamiento : [[0.71088713]]\n",
      "PERDIDAAAA despues: 0.0016930701676756144\n",
      "loss en el callback: 0.0009722161921672523, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.66993612]\n",
      " [0.67629379]\n",
      " [0.68176842]\n",
      " [0.68727309]\n",
      " [0.69355869]\n",
      " [0.69924408]\n",
      " [0.7051301 ]\n",
      " [0.71107632]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.71611077]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.66993612]\n",
      "  [0.67629379]\n",
      "  [0.68176842]\n",
      "  [0.68727309]\n",
      "  [0.69355869]\n",
      "  [0.69924408]\n",
      "  [0.7051301 ]\n",
      "  [0.71107632]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.9795617340132594e-05\n",
      "Predicción post entrenamiento : [[0.716124]]\n",
      "PERDIDAAAA despues: 3.996273881057277e-05\n",
      "loss en el callback: 5.737043466069736e-06, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.67629379]\n",
      " [0.68176842]\n",
      " [0.68727309]\n",
      " [0.69355869]\n",
      " [0.69924408]\n",
      " [0.7051301 ]\n",
      " [0.71107632]\n",
      " [0.71611077]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7213069]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.67629379]\n",
      "  [0.68176842]\n",
      "  [0.68727309]\n",
      "  [0.69355869]\n",
      "  [0.69924408]\n",
      "  [0.7051301 ]\n",
      "  [0.71107632]\n",
      "  [0.71611077]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009533814154565334\n",
      "Predicción post entrenamiento : [[0.72090214]]\n",
      "PERDIDAAAA despues: 0.00092854886315763\n",
      "loss en el callback: 0.005087672732770443, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.68176842]\n",
      " [0.68727309]\n",
      " [0.69355869]\n",
      " [0.69924408]\n",
      " [0.7051301 ]\n",
      " [0.71107632]\n",
      " [0.71611077]\n",
      " [0.72130692]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7259339]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.68176842]\n",
      "  [0.68727309]\n",
      "  [0.69355869]\n",
      "  [0.69924408]\n",
      "  [0.7051301 ]\n",
      "  [0.71107632]\n",
      "  [0.71611077]\n",
      "  [0.72130692]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008079726248979568\n",
      "Predicción post entrenamiento : [[0.7250052]]\n",
      "PERDIDAAAA despues: 0.0008616314153186977\n",
      "loss en el callback: 0.020151125267148018, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.68727309]\n",
      " [0.69355869]\n",
      " [0.69924408]\n",
      " [0.7051301 ]\n",
      " [0.71107632]\n",
      " [0.71611077]\n",
      " [0.72130692]\n",
      " [0.72593391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.73010343]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.68727309]\n",
      "  [0.69355869]\n",
      "  [0.69924408]\n",
      "  [0.7051301 ]\n",
      "  [0.71107632]\n",
      "  [0.71611077]\n",
      "  [0.72130692]\n",
      "  [0.72593391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.24533204245381e-05\n",
      "Predicción post entrenamiento : [[0.73007]]\n",
      "PERDIDAAAA despues: 6.192592991283163e-05\n",
      "loss en el callback: 4.1069797589443624e-05, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.69355869]\n",
      " [0.69924408]\n",
      " [0.7051301 ]\n",
      " [0.71107632]\n",
      " [0.71611077]\n",
      " [0.72130692]\n",
      " [0.72593391]\n",
      " [0.73010343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7352106]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.69355869]\n",
      "  [0.69924408]\n",
      "  [0.7051301 ]\n",
      "  [0.71107632]\n",
      "  [0.71611077]\n",
      "  [0.72130692]\n",
      "  [0.72593391]\n",
      "  [0.73010343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01283638272434473\n",
      "Predicción post entrenamiento : [[0.73535496]]\n",
      "PERDIDAAAA despues: 0.012803691439330578\n",
      "loss en el callback: 0.0005818564677610993, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.69924408]\n",
      " [0.7051301 ]\n",
      " [0.71107632]\n",
      " [0.71611077]\n",
      " [0.72130692]\n",
      " [0.72593391]\n",
      " [0.73010343]\n",
      " [0.7352106 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.74028146]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.69924408]\n",
      "  [0.7051301 ]\n",
      "  [0.71107632]\n",
      "  [0.71611077]\n",
      "  [0.72130692]\n",
      "  [0.72593391]\n",
      "  [0.73010343]\n",
      "  [0.7352106 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027284933254122734\n",
      "Predicción post entrenamiento : [[0.74138653]]\n",
      "PERDIDAAAA despues: 0.02692108042538166\n",
      "loss en el callback: 0.053446099162101746, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.7051301 ]\n",
      " [0.71107632]\n",
      " [0.71611077]\n",
      " [0.72130692]\n",
      " [0.72593391]\n",
      " [0.73010343]\n",
      " [0.7352106 ]\n",
      " [0.74028146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.74621254]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.7051301 ]\n",
      "  [0.71107632]\n",
      "  [0.71611077]\n",
      "  [0.72130692]\n",
      "  [0.72593391]\n",
      "  [0.73010343]\n",
      "  [0.7352106 ]\n",
      "  [0.74028146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018496999517083168\n",
      "Predicción post entrenamiento : [[0.74714106]]\n",
      "PERDIDAAAA despues: 0.01824529655277729\n",
      "loss en el callback: 0.03272896260023117, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.71107632]\n",
      " [0.71611077]\n",
      " [0.72130692]\n",
      " [0.72593391]\n",
      " [0.73010343]\n",
      " [0.7352106 ]\n",
      " [0.74028146]\n",
      " [0.74621254]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.7517711]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.71107632]\n",
      "  [0.71611077]\n",
      "  [0.72130692]\n",
      "  [0.72593391]\n",
      "  [0.73010343]\n",
      "  [0.7352106 ]\n",
      "  [0.74028146]\n",
      "  [0.74621254]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024341175332665443\n",
      "Predicción post entrenamiento : [[0.7520403]]\n",
      "PERDIDAAAA despues: 0.02425723895430565\n",
      "loss en el callback: 0.002082203747704625, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.71611077]\n",
      " [0.72130692]\n",
      " [0.72593391]\n",
      " [0.73010343]\n",
      " [0.7352106 ]\n",
      " [0.74028146]\n",
      " [0.74621254]\n",
      " [0.75177109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.75641924]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.71611077]\n",
      "  [0.72130692]\n",
      "  [0.72593391]\n",
      "  [0.73010343]\n",
      "  [0.7352106 ]\n",
      "  [0.74028146]\n",
      "  [0.74621254]\n",
      "  [0.75177109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01773117110133171\n",
      "Predicción post entrenamiento : [[0.756007]]\n",
      "PERDIDAAAA despues: 0.017841124907135963\n",
      "loss en el callback: 0.0041055819019675255, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.72130692]\n",
      " [0.72593391]\n",
      " [0.73010343]\n",
      " [0.7352106 ]\n",
      " [0.74028146]\n",
      " [0.74621254]\n",
      " [0.75177109]\n",
      " [0.75641924]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.7603704]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.72130692]\n",
      "  [0.72593391]\n",
      "  [0.73010343]\n",
      "  [0.7352106 ]\n",
      "  [0.74028146]\n",
      "  [0.74621254]\n",
      "  [0.75177109]\n",
      "  [0.75641924]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013106657192111015\n",
      "Predicción post entrenamiento : [[0.7611915]]\n",
      "PERDIDAAAA despues: 0.012919322587549686\n",
      "loss en el callback: 0.028511028736829758, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.72593391]\n",
      " [0.73010343]\n",
      " [0.7352106 ]\n",
      " [0.74028146]\n",
      " [0.74621254]\n",
      " [0.75177109]\n",
      " [0.75641924]\n",
      " [0.76037037]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.76549715]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.72593391]\n",
      "  [0.73010343]\n",
      "  [0.7352106 ]\n",
      "  [0.74028146]\n",
      "  [0.74621254]\n",
      "  [0.75177109]\n",
      "  [0.75641924]\n",
      "  [0.76037037]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02181966044008732\n",
      "Predicción post entrenamiento : [[0.7654486]]\n",
      "PERDIDAAAA despues: 0.021834013983607292\n",
      "loss en el callback: 6.366405432345346e-05, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.73010343]\n",
      " [0.7352106 ]\n",
      " [0.74028146]\n",
      " [0.74621254]\n",
      " [0.75177109]\n",
      " [0.75641924]\n",
      " [0.76037037]\n",
      " [0.76549715]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.76985884]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.73010343]\n",
      "  [0.7352106 ]\n",
      "  [0.74028146]\n",
      "  [0.74621254]\n",
      "  [0.75177109]\n",
      "  [0.75641924]\n",
      "  [0.76037037]\n",
      "  [0.76549715]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0529649555683136\n",
      "Predicción post entrenamiento : [[0.7701598]]\n",
      "PERDIDAAAA despues: 0.05282652750611305\n",
      "loss en el callback: 0.002304535824805498, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.7352106 ]\n",
      " [0.74028146]\n",
      " [0.74621254]\n",
      " [0.75177109]\n",
      " [0.75641924]\n",
      " [0.76037037]\n",
      " [0.76549715]\n",
      " [0.76985884]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.774822]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.7352106 ]\n",
      "  [0.74028146]\n",
      "  [0.74621254]\n",
      "  [0.75177109]\n",
      "  [0.75641924]\n",
      "  [0.76037037]\n",
      "  [0.76549715]\n",
      "  [0.76985884]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03831103816628456\n",
      "Predicción post entrenamiento : [[0.7756547]]\n",
      "PERDIDAAAA despues: 0.03798576816916466\n",
      "loss en el callback: 0.02297426573932171, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.74028146]\n",
      " [0.74621254]\n",
      " [0.75177109]\n",
      " [0.75641924]\n",
      " [0.76037037]\n",
      " [0.76549715]\n",
      " [0.76985884]\n",
      " [0.774822  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.78031385]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.74028146]\n",
      "  [0.74621254]\n",
      "  [0.75177109]\n",
      "  [0.75641924]\n",
      "  [0.76037037]\n",
      "  [0.76549715]\n",
      "  [0.76985884]\n",
      "  [0.774822  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011769845150411129\n",
      "Predicción post entrenamiento : [[0.78113186]]\n",
      "PERDIDAAAA despues: 0.01159302331507206\n",
      "loss en el callback: 0.028083298355340958, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.74621254]\n",
      " [0.75177109]\n",
      " [0.75641924]\n",
      " [0.76037037]\n",
      " [0.76549715]\n",
      " [0.76985884]\n",
      " [0.774822  ]\n",
      " [0.78031385]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.785781]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.74621254]\n",
      "  [0.75177109]\n",
      "  [0.75641924]\n",
      "  [0.76037037]\n",
      "  [0.76549715]\n",
      "  [0.76985884]\n",
      "  [0.774822  ]\n",
      "  [0.78031385]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00849591288715601\n",
      "Predicción post entrenamiento : [[0.78654146]]\n",
      "PERDIDAAAA despues: 0.00835630763322115\n",
      "loss en el callback: 0.023466486483812332, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.75177109]\n",
      " [0.75641924]\n",
      " [0.76037037]\n",
      " [0.76549715]\n",
      " [0.76985884]\n",
      " [0.774822  ]\n",
      " [0.78031385]\n",
      " [0.78578103]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.7909124]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.75177109]\n",
      "  [0.75641924]\n",
      "  [0.76037037]\n",
      "  [0.76549715]\n",
      "  [0.76985884]\n",
      "  [0.774822  ]\n",
      "  [0.78031385]\n",
      "  [0.78578103]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033620744943618774\n",
      "Predicción post entrenamiento : [[0.7910487]]\n",
      "PERDIDAAAA despues: 0.0033462848514318466\n",
      "loss en el callback: 0.0006228370475582778, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.75641924]\n",
      " [0.76037037]\n",
      " [0.76549715]\n",
      " [0.76985884]\n",
      " [0.774822  ]\n",
      " [0.78031385]\n",
      " [0.78578103]\n",
      " [0.79091239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.7952133]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.75641924]\n",
      "  [0.76037037]\n",
      "  [0.76549715]\n",
      "  [0.76985884]\n",
      "  [0.774822  ]\n",
      "  [0.78031385]\n",
      "  [0.78578103]\n",
      "  [0.79091239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015178428729996085\n",
      "Predicción post entrenamiento : [[0.79559785]]\n",
      "PERDIDAAAA despues: 0.0014880255330353975\n",
      "loss en el callback: 0.006063107401132584, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.76037037]\n",
      " [0.76549715]\n",
      " [0.76985884]\n",
      " [0.774822  ]\n",
      " [0.78031385]\n",
      " [0.78578103]\n",
      " [0.79091239]\n",
      " [0.79521328]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.79981107]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.76037037]\n",
      "  [0.76549715]\n",
      "  [0.76985884]\n",
      "  [0.774822  ]\n",
      "  [0.78031385]\n",
      "  [0.78578103]\n",
      "  [0.79091239]\n",
      "  [0.79521328]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030563033651560545\n",
      "Predicción post entrenamiento : [[0.7998938]]\n",
      "PERDIDAAAA despues: 0.003047162899747491\n",
      "loss en el callback: 0.0002440493699396029, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.76549715]\n",
      " [0.76985884]\n",
      " [0.774822  ]\n",
      " [0.78031385]\n",
      " [0.78578103]\n",
      " [0.79091239]\n",
      " [0.79521328]\n",
      " [0.79981107]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8043816]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.76549715]\n",
      "  [0.76985884]\n",
      "  [0.774822  ]\n",
      "  [0.78031385]\n",
      "  [0.78578103]\n",
      "  [0.79091239]\n",
      "  [0.79521328]\n",
      "  [0.79981107]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005021219607442617\n",
      "Predicción post entrenamiento : [[0.8051444]]\n",
      "PERDIDAAAA despues: 0.004913693759590387\n",
      "loss en el callback: 0.028049267828464508, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.76985884]\n",
      " [0.774822  ]\n",
      " [0.78031385]\n",
      " [0.78578103]\n",
      " [0.79091239]\n",
      " [0.79521328]\n",
      " [0.79981107]\n",
      " [0.80438161]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.80959564]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.76985884]\n",
      "  [0.774822  ]\n",
      "  [0.78031385]\n",
      "  [0.78578103]\n",
      "  [0.79091239]\n",
      "  [0.79521328]\n",
      "  [0.79981107]\n",
      "  [0.80438161]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002250224817544222\n",
      "Predicción post entrenamiento : [[0.81013423]]\n",
      "PERDIDAAAA despues: 0.002199417445808649\n",
      "loss en el callback: 0.012508961372077465, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.774822  ]\n",
      " [0.78031385]\n",
      " [0.78578103]\n",
      " [0.79091239]\n",
      " [0.79521328]\n",
      " [0.79981107]\n",
      " [0.80438161]\n",
      " [0.80959564]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8147662]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.774822  ]\n",
      "  [0.78031385]\n",
      "  [0.78578103]\n",
      "  [0.79091239]\n",
      "  [0.79521328]\n",
      "  [0.79981107]\n",
      "  [0.80438161]\n",
      "  [0.80959564]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012455189134925604\n",
      "Predicción post entrenamiento : [[0.814789]]\n",
      "PERDIDAAAA despues: 0.0012439122656360269\n",
      "loss en el callback: 2.023902015935164e-05, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.78031385]\n",
      " [0.78578103]\n",
      " [0.79091239]\n",
      " [0.79521328]\n",
      " [0.79981107]\n",
      " [0.80438161]\n",
      " [0.80959564]\n",
      " [0.81476623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8194377]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.78031385]\n",
      "  [0.78578103]\n",
      "  [0.79091239]\n",
      "  [0.79521328]\n",
      "  [0.79981107]\n",
      "  [0.80438161]\n",
      "  [0.80959564]\n",
      "  [0.81476623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005409775767475367\n",
      "Predicción post entrenamiento : [[0.81876]]\n",
      "PERDIDAAAA despues: 0.0005729622207581997\n",
      "loss en el callback: 0.013299272395670414, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.78578103]\n",
      " [0.79091239]\n",
      " [0.79521328]\n",
      " [0.79981107]\n",
      " [0.80438161]\n",
      " [0.80959564]\n",
      " [0.81476623]\n",
      " [0.81943768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.82325405]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.78578103]\n",
      "  [0.79091239]\n",
      "  [0.79521328]\n",
      "  [0.79981107]\n",
      "  [0.80438161]\n",
      "  [0.80959564]\n",
      "  [0.81476623]\n",
      "  [0.81943768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0062593958082289e-07\n",
      "Predicción post entrenamiento : [[0.82314956]]\n",
      "PERDIDAAAA despues: 4.525361774199155e-08\n",
      "loss en el callback: 0.0004139761149417609, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.79091239]\n",
      " [0.79521328]\n",
      " [0.79981107]\n",
      " [0.80438161]\n",
      " [0.80959564]\n",
      " [0.81476623]\n",
      " [0.81943768]\n",
      " [0.82325405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8274622]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.79091239]\n",
      "  [0.79521328]\n",
      "  [0.79981107]\n",
      "  [0.80438161]\n",
      "  [0.80959564]\n",
      "  [0.81476623]\n",
      "  [0.81943768]\n",
      "  [0.82325405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028043552301824093\n",
      "Predicción post entrenamiento : [[0.8279765]]\n",
      "PERDIDAAAA despues: 0.0028590934816747904\n",
      "loss en el callback: 0.017603175714612007, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.79521328]\n",
      " [0.79981107]\n",
      " [0.80438161]\n",
      " [0.80959564]\n",
      " [0.81476623]\n",
      " [0.81943768]\n",
      " [0.82325405]\n",
      " [0.8274622 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.83217335]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.79521328]\n",
      "  [0.79981107]\n",
      "  [0.80438161]\n",
      "  [0.80959564]\n",
      "  [0.81476623]\n",
      "  [0.81943768]\n",
      "  [0.82325405]\n",
      "  [0.8274622 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023021958768367767\n",
      "Predicción post entrenamiento : [[0.8323923]]\n",
      "PERDIDAAAA despues: 0.0023232526145875454\n",
      "loss en el callback: 0.002528591314330697, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.79981107]\n",
      " [0.80438161]\n",
      " [0.80959564]\n",
      " [0.81476623]\n",
      " [0.81943768]\n",
      " [0.82325405]\n",
      " [0.8274622 ]\n",
      " [0.83217335]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.83669966]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.79981107]\n",
      "  [0.80438161]\n",
      "  [0.80959564]\n",
      "  [0.81476623]\n",
      "  [0.81943768]\n",
      "  [0.82325405]\n",
      "  [0.8274622 ]\n",
      "  [0.83217335]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005310556734912097\n",
      "Predicción post entrenamiento : [[0.8372295]]\n",
      "PERDIDAAAA despues: 0.0005069171311333776\n",
      "loss en el callback: 0.014919312670826912, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.80438161]\n",
      " [0.80959564]\n",
      " [0.81476623]\n",
      " [0.81943768]\n",
      " [0.82325405]\n",
      " [0.8274622 ]\n",
      " [0.83217335]\n",
      " [0.83669966]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8415646]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.80438161]\n",
      "  [0.80959564]\n",
      "  [0.81476623]\n",
      "  [0.81943768]\n",
      "  [0.82325405]\n",
      "  [0.8274622 ]\n",
      "  [0.83217335]\n",
      "  [0.83669966]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016270160267595202\n",
      "Predicción post entrenamiento : [[0.8418741]]\n",
      "PERDIDAAAA despues: 0.00015490109217353165\n",
      "loss en el callback: 0.0043595945462584496, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.80959564]\n",
      " [0.81476623]\n",
      " [0.81943768]\n",
      " [0.82325405]\n",
      " [0.8274622 ]\n",
      " [0.83217335]\n",
      " [0.83669966]\n",
      " [0.8415646 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.84623736]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.80959564]\n",
      "  [0.81476623]\n",
      "  [0.81943768]\n",
      "  [0.82325405]\n",
      "  [0.8274622 ]\n",
      "  [0.83217335]\n",
      "  [0.83669966]\n",
      "  [0.8415646 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.746823732508346e-05\n",
      "Predicción post entrenamiento : [[0.84650874]]\n",
      "PERDIDAAAA despues: 9.261801460525021e-05\n",
      "loss en el callback: 0.0034054003190249205, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.81476623]\n",
      " [0.81943768]\n",
      " [0.82325405]\n",
      " [0.8274622 ]\n",
      " [0.83217335]\n",
      " [0.83669966]\n",
      " [0.8415646 ]\n",
      " [0.84623736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.85069895]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.81476623]\n",
      "  [0.81943768]\n",
      "  [0.82325405]\n",
      "  [0.8274622 ]\n",
      "  [0.83217335]\n",
      "  [0.83669966]\n",
      "  [0.8415646 ]\n",
      "  [0.84623736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043214400648139417\n",
      "Predicción post entrenamiento : [[0.8507636]]\n",
      "PERDIDAAAA despues: 0.0004348369548097253\n",
      "loss en el callback: 0.00019779146532528102, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.81943768]\n",
      " [0.82325405]\n",
      " [0.8274622 ]\n",
      " [0.83217335]\n",
      " [0.83669966]\n",
      " [0.8415646 ]\n",
      " [0.84623736]\n",
      " [0.85069895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.8547641]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.81943768]\n",
      "  [0.82325405]\n",
      "  [0.8274622 ]\n",
      "  [0.83217335]\n",
      "  [0.83669966]\n",
      "  [0.8415646 ]\n",
      "  [0.84623736]\n",
      "  [0.85069895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010555274784564972\n",
      "Predicción post entrenamiento : [[0.85458744]]\n",
      "PERDIDAAAA despues: 0.0010670381598174572\n",
      "loss en el callback: 0.0012085061753168702, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.82325405]\n",
      " [0.8274622 ]\n",
      " [0.83217335]\n",
      " [0.83669966]\n",
      " [0.8415646 ]\n",
      " [0.84623736]\n",
      " [0.85069895]\n",
      " [0.8547641 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.85852444]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.82325405]\n",
      "  [0.8274622 ]\n",
      "  [0.83217335]\n",
      "  [0.83669966]\n",
      "  [0.8415646 ]\n",
      "  [0.84623736]\n",
      "  [0.85069895]\n",
      "  [0.8547641 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4880795333738206e-06\n",
      "Predicción post entrenamiento : [[0.85871357]]\n",
      "PERDIDAAAA despues: 1.0624313517837436e-06\n",
      "loss en el callback: 0.0017552735516801476, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.8274622 ]\n",
      " [0.83217335]\n",
      " [0.83669966]\n",
      " [0.8415646 ]\n",
      " [0.84623736]\n",
      " [0.85069895]\n",
      " [0.8547641 ]\n",
      " [0.85852444]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.86283886]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.8274622 ]\n",
      "  [0.83217335]\n",
      "  [0.83669966]\n",
      "  [0.8415646 ]\n",
      "  [0.84623736]\n",
      "  [0.85069895]\n",
      "  [0.8547641 ]\n",
      "  [0.85852444]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005401821108534932\n",
      "Predicción post entrenamiento : [[0.86194646]]\n",
      "PERDIDAAAA despues: 0.0004994964692741632\n",
      "loss en el callback: 0.026683354750275612, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.83217335]\n",
      " [0.83669966]\n",
      " [0.8415646 ]\n",
      " [0.84623736]\n",
      " [0.85069895]\n",
      " [0.8547641 ]\n",
      " [0.85852444]\n",
      " [0.86283886]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.86616087]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.83217335]\n",
      "  [0.83669966]\n",
      "  [0.8415646 ]\n",
      "  [0.84623736]\n",
      "  [0.85069895]\n",
      "  [0.8547641 ]\n",
      "  [0.85852444]\n",
      "  [0.86283886]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006782536394894123\n",
      "Predicción post entrenamiento : [[0.86572814]]\n",
      "PERDIDAAAA despues: 0.006711447611451149\n",
      "loss en el callback: 0.008662530221045017, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.83669966]\n",
      " [0.8415646 ]\n",
      " [0.84623736]\n",
      " [0.85069895]\n",
      " [0.8547641 ]\n",
      " [0.85852444]\n",
      " [0.86283886]\n",
      " [0.86616087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8698719]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.83669966]\n",
      "  [0.8415646 ]\n",
      "  [0.84623736]\n",
      "  [0.85069895]\n",
      "  [0.8547641 ]\n",
      "  [0.85852444]\n",
      "  [0.86283886]\n",
      "  [0.86616087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002660952741280198\n",
      "Predicción post entrenamiento : [[0.87056303]]\n",
      "PERDIDAAAA despues: 0.002732731867581606\n",
      "loss en el callback: 0.03751680999994278, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.8415646 ]\n",
      " [0.84623736]\n",
      " [0.85069895]\n",
      " [0.8547641 ]\n",
      " [0.85852444]\n",
      " [0.86283886]\n",
      " [0.86616087]\n",
      " [0.86987191]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.87465775]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.8415646 ]\n",
      "  [0.84623736]\n",
      "  [0.85069895]\n",
      "  [0.8547641 ]\n",
      "  [0.85852444]\n",
      "  [0.86283886]\n",
      "  [0.86616087]\n",
      "  [0.86987191]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006970841437578201\n",
      "Predicción post entrenamiento : [[0.8746035]]\n",
      "PERDIDAAAA despues: 0.00696178711950779\n",
      "loss en el callback: 0.0001411736011505127, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.84623736]\n",
      " [0.85069895]\n",
      " [0.8547641 ]\n",
      " [0.85852444]\n",
      " [0.86283886]\n",
      " [0.86616087]\n",
      " [0.86987191]\n",
      " [0.87465775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.878515]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.84623736]\n",
      "  [0.85069895]\n",
      "  [0.8547641 ]\n",
      "  [0.85852444]\n",
      "  [0.86283886]\n",
      "  [0.86616087]\n",
      "  [0.86987191]\n",
      "  [0.87465775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013913867063820362\n",
      "Predicción post entrenamiento : [[0.8765331]]\n",
      "PERDIDAAAA despues: 0.01345023326575756\n",
      "loss en el callback: 0.11823418736457825, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.85069895]\n",
      " [0.8547641 ]\n",
      " [0.85852444]\n",
      " [0.86283886]\n",
      " [0.86616087]\n",
      " [0.86987191]\n",
      " [0.87465775]\n",
      " [0.87851501]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8802741]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.85069895]\n",
      "  [0.8547641 ]\n",
      "  [0.85852444]\n",
      "  [0.86283886]\n",
      "  [0.86616087]\n",
      "  [0.86987191]\n",
      "  [0.87465775]\n",
      "  [0.87851501]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007871316745877266\n",
      "Predicción post entrenamiento : [[0.87975556]]\n",
      "PERDIDAAAA despues: 0.007779571693390608\n",
      "loss en el callback: 0.011825625784695148, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.8547641 ]\n",
      " [0.85852444]\n",
      " [0.86283886]\n",
      " [0.86616087]\n",
      " [0.86987191]\n",
      " [0.87465775]\n",
      " [0.87851501]\n",
      " [0.88027412]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.88334835]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.8547641 ]\n",
      "  [0.85852444]\n",
      "  [0.86283886]\n",
      "  [0.86616087]\n",
      "  [0.86987191]\n",
      "  [0.87465775]\n",
      "  [0.87851501]\n",
      "  [0.88027412]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013145554810762405\n",
      "Predicción post entrenamiento : [[0.882466]]\n",
      "PERDIDAAAA despues: 0.012944008223712444\n",
      "loss en el callback: 0.031562287360429764, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.85852444]\n",
      " [0.86283886]\n",
      " [0.86616087]\n",
      " [0.86987191]\n",
      " [0.87465775]\n",
      " [0.87851501]\n",
      " [0.88027412]\n",
      " [0.88334835]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8859876]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.85852444]\n",
      "  [0.86283886]\n",
      "  [0.86616087]\n",
      "  [0.86987191]\n",
      "  [0.87465775]\n",
      "  [0.87851501]\n",
      "  [0.88027412]\n",
      "  [0.88334835]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013757717795670033\n",
      "Predicción post entrenamiento : [[0.88543475]]\n",
      "PERDIDAAAA despues: 0.013628336600959301\n",
      "loss en el callback: 0.01487963180989027, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.86283886]\n",
      " [0.86616087]\n",
      " [0.86987191]\n",
      " [0.87465775]\n",
      " [0.87851501]\n",
      " [0.88027412]\n",
      " [0.88334835]\n",
      " [0.88598758]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.8889399]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.86283886]\n",
      "  [0.86616087]\n",
      "  [0.86987191]\n",
      "  [0.87465775]\n",
      "  [0.87851501]\n",
      "  [0.88027412]\n",
      "  [0.88334835]\n",
      "  [0.88598758]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008104459382593632\n",
      "Predicción post entrenamiento : [[0.8891027]]\n",
      "PERDIDAAAA despues: 0.00813379418104887\n",
      "loss en el callback: 0.0017160741845145822, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.86616087]\n",
      " [0.86987191]\n",
      " [0.87465775]\n",
      " [0.87851501]\n",
      " [0.88027412]\n",
      " [0.88334835]\n",
      " [0.88598758]\n",
      " [0.88893992]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.89238816]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.86616087]\n",
      "  [0.86987191]\n",
      "  [0.87465775]\n",
      "  [0.87851501]\n",
      "  [0.88027412]\n",
      "  [0.88334835]\n",
      "  [0.88598758]\n",
      "  [0.88893992]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010482538491487503\n",
      "Predicción post entrenamiento : [[0.89287406]]\n",
      "PERDIDAAAA despues: 0.01058227103203535\n",
      "loss en el callback: 0.01657402142882347, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.86987191]\n",
      " [0.87465775]\n",
      " [0.87851501]\n",
      " [0.88027412]\n",
      " [0.88334835]\n",
      " [0.88598758]\n",
      " [0.88893992]\n",
      " [0.89238816]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.8961814]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.86987191]\n",
      "  [0.87465775]\n",
      "  [0.87851501]\n",
      "  [0.88027412]\n",
      "  [0.88334835]\n",
      "  [0.88598758]\n",
      "  [0.88893992]\n",
      "  [0.89238816]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01849897764623165\n",
      "Predicción post entrenamiento : [[0.89486986]]\n",
      "PERDIDAAAA despues: 0.018143929541110992\n",
      "loss en el callback: 0.06357159465551376, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.87465775]\n",
      " [0.87851501]\n",
      " [0.88027412]\n",
      " [0.88334835]\n",
      " [0.88598758]\n",
      " [0.88893992]\n",
      " [0.89238816]\n",
      " [0.8961814 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.8980571]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.87465775]\n",
      "  [0.87851501]\n",
      "  [0.88027412]\n",
      "  [0.88334835]\n",
      "  [0.88598758]\n",
      "  [0.88893992]\n",
      "  [0.89238816]\n",
      "  [0.8961814 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.045225903391838074\n",
      "Predicción post entrenamiento : [[0.897914]]\n",
      "PERDIDAAAA despues: 0.045165054500103\n",
      "loss en el callback: 0.001382423797622323, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.87851501]\n",
      " [0.88027412]\n",
      " [0.88334835]\n",
      " [0.88598758]\n",
      " [0.88893992]\n",
      " [0.89238816]\n",
      " [0.8961814 ]\n",
      " [0.8980571 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.90061504]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.87851501]\n",
      "  [0.88027412]\n",
      "  [0.88334835]\n",
      "  [0.88598758]\n",
      "  [0.88893992]\n",
      "  [0.89238816]\n",
      "  [0.8961814 ]\n",
      "  [0.8980571 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08727490901947021\n",
      "Predicción post entrenamiento : [[0.8995467]]\n",
      "PERDIDAAAA despues: 0.08664481341838837\n",
      "loss en el callback: 0.06091006472706795, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.88027412]\n",
      " [0.88334835]\n",
      " [0.88598758]\n",
      " [0.88893992]\n",
      " [0.89238816]\n",
      " [0.8961814 ]\n",
      " [0.8980571 ]\n",
      " [0.90061504]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9019642]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.88027412]\n",
      "  [0.88334835]\n",
      "  [0.88598758]\n",
      "  [0.88893992]\n",
      "  [0.89238816]\n",
      "  [0.8961814 ]\n",
      "  [0.8980571 ]\n",
      "  [0.90061504]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05621907114982605\n",
      "Predicción post entrenamiento : [[0.9017403]]\n",
      "PERDIDAAAA despues: 0.05611295625567436\n",
      "loss en el callback: 0.0034394818358123302, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.88334835]\n",
      " [0.88598758]\n",
      " [0.88893992]\n",
      " [0.89238816]\n",
      " [0.8961814 ]\n",
      " [0.8980571 ]\n",
      " [0.90061504]\n",
      " [0.90196419]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.90446997]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.88334835]\n",
      "  [0.88598758]\n",
      "  [0.88893992]\n",
      "  [0.89238816]\n",
      "  [0.8961814 ]\n",
      "  [0.8980571 ]\n",
      "  [0.90061504]\n",
      "  [0.90196419]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03865344449877739\n",
      "Predicción post entrenamiento : [[0.90356815]]\n",
      "PERDIDAAAA despues: 0.03829965367913246\n",
      "loss en el callback: 0.04002183675765991, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.88598758]\n",
      " [0.88893992]\n",
      " [0.89238816]\n",
      " [0.8961814 ]\n",
      " [0.8980571 ]\n",
      " [0.90061504]\n",
      " [0.90196419]\n",
      " [0.90446997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9062378]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.88598758]\n",
      "  [0.88893992]\n",
      "  [0.89238816]\n",
      "  [0.8961814 ]\n",
      "  [0.8980571 ]\n",
      "  [0.90061504]\n",
      "  [0.90196419]\n",
      "  [0.90446997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05826392024755478\n",
      "Predicción post entrenamiento : [[0.9057895]]\n",
      "PERDIDAAAA despues: 0.05804770439863205\n",
      "loss en el callback: 0.012849000282585621, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.88893992]\n",
      " [0.89238816]\n",
      " [0.8961814 ]\n",
      " [0.8980571 ]\n",
      " [0.90061504]\n",
      " [0.90196419]\n",
      " [0.90446997]\n",
      " [0.90623778]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9084948]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.88893992]\n",
      "  [0.89238816]\n",
      "  [0.8961814 ]\n",
      "  [0.8980571 ]\n",
      "  [0.90061504]\n",
      "  [0.90196419]\n",
      "  [0.90446997]\n",
      "  [0.90623778]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03886520490050316\n",
      "Predicción post entrenamiento : [[0.90791965]]\n",
      "PERDIDAAAA despues: 0.038638774305582047\n",
      "loss en el callback: 0.017252754420042038, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.89238816]\n",
      " [0.8961814 ]\n",
      " [0.8980571 ]\n",
      " [0.90061504]\n",
      " [0.90196419]\n",
      " [0.90446997]\n",
      " [0.90623778]\n",
      " [0.90849477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9105357]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.89238816]\n",
      "  [0.8961814 ]\n",
      "  [0.8980571 ]\n",
      "  [0.90061504]\n",
      "  [0.90196419]\n",
      "  [0.90446997]\n",
      "  [0.90623778]\n",
      "  [0.90849477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054419003427028656\n",
      "Predicción post entrenamiento : [[0.909718]]\n",
      "PERDIDAAAA despues: 0.0540381595492363\n",
      "loss en el callback: 0.03764233738183975, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.8961814 ]\n",
      " [0.8980571 ]\n",
      " [0.90061504]\n",
      " [0.90196419]\n",
      " [0.90446997]\n",
      " [0.90623778]\n",
      " [0.90849477]\n",
      " [0.91053569]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9120451]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.8961814 ]\n",
      "  [0.8980571 ]\n",
      "  [0.90061504]\n",
      "  [0.90196419]\n",
      "  [0.90446997]\n",
      "  [0.90623778]\n",
      "  [0.90849477]\n",
      "  [0.91053569]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022481221705675125\n",
      "Predicción post entrenamiento : [[0.91147786]]\n",
      "PERDIDAAAA despues: 0.022311436012387276\n",
      "loss en el callback: 0.01725444570183754, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.8980571 ]\n",
      " [0.90061504]\n",
      " [0.90196419]\n",
      " [0.90446997]\n",
      " [0.90623778]\n",
      " [0.90849477]\n",
      " [0.91053569]\n",
      " [0.91204512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.91334146]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.8980571 ]\n",
      "  [0.90061504]\n",
      "  [0.90196419]\n",
      "  [0.90446997]\n",
      "  [0.90623778]\n",
      "  [0.90849477]\n",
      "  [0.91053569]\n",
      "  [0.91204512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011297548189759254\n",
      "Predicción post entrenamiento : [[0.9121638]]\n",
      "PERDIDAAAA despues: 0.01104858610779047\n",
      "loss en el callback: 0.06167595833539963, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.90061504]\n",
      " [0.90196419]\n",
      " [0.90446997]\n",
      " [0.90623778]\n",
      " [0.90849477]\n",
      " [0.91053569]\n",
      " [0.91204512]\n",
      " [0.91334146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9140662]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.90061504]\n",
      "  [0.90196419]\n",
      "  [0.90446997]\n",
      "  [0.90623778]\n",
      "  [0.90849477]\n",
      "  [0.91053569]\n",
      "  [0.91204512]\n",
      "  [0.91334146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00977691076695919\n",
      "Predicción post entrenamiento : [[0.91356677]]\n",
      "PERDIDAAAA despues: 0.009678395465016365\n",
      "loss en el callback: 0.012863368727266788, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.90196419]\n",
      " [0.90446997]\n",
      " [0.90623778]\n",
      " [0.90849477]\n",
      " [0.91053569]\n",
      " [0.91204512]\n",
      " [0.91334146]\n",
      " [0.9140662 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.91528845]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.90196419]\n",
      "  [0.90446997]\n",
      "  [0.90623778]\n",
      "  [0.90849477]\n",
      "  [0.91053569]\n",
      "  [0.91204512]\n",
      "  [0.91334146]\n",
      "  [0.9140662 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.19124179542996e-05\n",
      "Predicción post entrenamiento : [[0.9153096]]\n",
      "PERDIDAAAA despues: 8.229588274843991e-05\n",
      "loss en el callback: 2.459805727994535e-05, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.90446997]\n",
      " [0.90623778]\n",
      " [0.90849477]\n",
      " [0.91053569]\n",
      " [0.91204512]\n",
      " [0.91334146]\n",
      " [0.9140662 ]\n",
      " [0.91528845]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9171725]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.90446997]\n",
      "  [0.90623778]\n",
      "  [0.90849477]\n",
      "  [0.91053569]\n",
      "  [0.91204512]\n",
      "  [0.91334146]\n",
      "  [0.9140662 ]\n",
      "  [0.91528845]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018090595258399844\n",
      "Predicción post entrenamiento : [[0.91767675]]\n",
      "PERDIDAAAA despues: 0.001766418805345893\n",
      "loss en el callback: 0.015642976388335228, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.90623778]\n",
      " [0.90849477]\n",
      " [0.91053569]\n",
      " [0.91204512]\n",
      " [0.91334146]\n",
      " [0.9140662 ]\n",
      " [0.91528845]\n",
      " [0.91717249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9193237]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.90623778]\n",
      "  [0.90849477]\n",
      "  [0.91053569]\n",
      "  [0.91204512]\n",
      "  [0.91334146]\n",
      "  [0.9140662 ]\n",
      "  [0.91528845]\n",
      "  [0.91717249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002027807990089059\n",
      "Predicción post entrenamiento : [[0.9193219]]\n",
      "PERDIDAAAA despues: 0.0020279691088944674\n",
      "loss en el callback: 1.3780260132989497e-07, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.90849477]\n",
      " [0.91053569]\n",
      " [0.91204512]\n",
      " [0.91334146]\n",
      " [0.9140662 ]\n",
      " [0.91528845]\n",
      " [0.91717249]\n",
      " [0.91932368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.92092866]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.90849477]\n",
      "  [0.91053569]\n",
      "  [0.91204512]\n",
      "  [0.91334146]\n",
      "  [0.9140662 ]\n",
      "  [0.91528845]\n",
      "  [0.91717249]\n",
      "  [0.91932368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010824593482539058\n",
      "Predicción post entrenamiento : [[0.9208477]]\n",
      "PERDIDAAAA despues: 0.001077139750123024\n",
      "loss en el callback: 0.0003571055131033063, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.91053569]\n",
      " [0.91204512]\n",
      " [0.91334146]\n",
      " [0.9140662 ]\n",
      " [0.91528845]\n",
      " [0.91717249]\n",
      " [0.91932368]\n",
      " [0.92092866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9222486]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.91053569]\n",
      "  [0.91204512]\n",
      "  [0.91334146]\n",
      "  [0.9140662 ]\n",
      "  [0.91528845]\n",
      "  [0.91717249]\n",
      "  [0.91932368]\n",
      "  [0.92092866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008744649821892381\n",
      "Predicción post entrenamiento : [[0.92223895]]\n",
      "PERDIDAAAA despues: 0.0008738940232433379\n",
      "loss en el callback: 5.714508915843908e-06, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.91204512]\n",
      " [0.91334146]\n",
      " [0.9140662 ]\n",
      " [0.91528845]\n",
      " [0.91717249]\n",
      " [0.91932368]\n",
      " [0.92092866]\n",
      " [0.9222486 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.92346925]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.91204512]\n",
      "  [0.91334146]\n",
      "  [0.9140662 ]\n",
      "  [0.91528845]\n",
      "  [0.91717249]\n",
      "  [0.91932368]\n",
      "  [0.92092866]\n",
      "  [0.9222486 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023258505389094353\n",
      "Predicción post entrenamiento : [[0.92231053]]\n",
      "PERDIDAAAA despues: 0.002215430373325944\n",
      "loss en el callback: 0.05307653546333313, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.91334146]\n",
      " [0.9140662 ]\n",
      " [0.91528845]\n",
      " [0.91717249]\n",
      " [0.91932368]\n",
      " [0.92092866]\n",
      " [0.9222486 ]\n",
      " [0.92346925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.92351377]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.91334146]\n",
      "  [0.9140662 ]\n",
      "  [0.91528845]\n",
      "  [0.91717249]\n",
      "  [0.91932368]\n",
      "  [0.92092866]\n",
      "  [0.9222486 ]\n",
      "  [0.92346925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005282494705170393\n",
      "Predicción post entrenamiento : [[0.92270285]]\n",
      "PERDIDAAAA despues: 0.005165275186300278\n",
      "loss en el callback: 0.032245561480522156, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.9140662 ]\n",
      " [0.91528845]\n",
      " [0.91717249]\n",
      " [0.91932368]\n",
      " [0.92092866]\n",
      " [0.9222486 ]\n",
      " [0.92346925]\n",
      " [0.92351377]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9239417]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.9140662 ]\n",
      "  [0.91528845]\n",
      "  [0.91717249]\n",
      "  [0.91932368]\n",
      "  [0.92092866]\n",
      "  [0.9222486 ]\n",
      "  [0.92346925]\n",
      "  [0.92351377]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0056318845599889755\n",
      "Predicción post entrenamiento : [[0.9238032]]\n",
      "PERDIDAAAA despues: 0.005611121654510498\n",
      "loss en el callback: 0.0011939710238948464, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.91528845]\n",
      " [0.91717249]\n",
      " [0.91932368]\n",
      " [0.92092866]\n",
      " [0.9222486 ]\n",
      " [0.92346925]\n",
      " [0.92351377]\n",
      " [0.92394167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9252464]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.91528845]\n",
      "  [0.91717249]\n",
      "  [0.91932368]\n",
      "  [0.92092866]\n",
      "  [0.9222486 ]\n",
      "  [0.92346925]\n",
      "  [0.92351377]\n",
      "  [0.92394167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001381701440550387\n",
      "Predicción post entrenamiento : [[0.9252297]]\n",
      "PERDIDAAAA despues: 0.001382942427881062\n",
      "loss en el callback: 1.5280682418961078e-05, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.91717249]\n",
      " [0.91932368]\n",
      " [0.92092866]\n",
      " [0.9222486 ]\n",
      " [0.92346925]\n",
      " [0.92351377]\n",
      " [0.92394167]\n",
      " [0.92524642]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9267324]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.91717249]\n",
      "  [0.91932368]\n",
      "  [0.92092866]\n",
      "  [0.9222486 ]\n",
      "  [0.92346925]\n",
      "  [0.92351377]\n",
      "  [0.92394167]\n",
      "  [0.92524642]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016899912152439356\n",
      "Predicción post entrenamiento : [[0.9272992]]\n",
      "PERDIDAAAA despues: 0.0016437122831121087\n",
      "loss en el callback: 0.02250220999121666, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.91932368]\n",
      " [0.92092866]\n",
      " [0.9222486 ]\n",
      " [0.92346925]\n",
      " [0.92351377]\n",
      " [0.92394167]\n",
      " [0.92524642]\n",
      " [0.92673242]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9286389]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.91932368]\n",
      "  [0.92092866]\n",
      "  [0.9222486 ]\n",
      "  [0.92346925]\n",
      "  [0.92351377]\n",
      "  [0.92394167]\n",
      "  [0.92524642]\n",
      "  [0.92673242]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014596994151361287\n",
      "Predicción post entrenamiento : [[0.9287332]]\n",
      "PERDIDAAAA despues: 0.0001436988968634978\n",
      "loss en el callback: 0.0005400380468927324, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.92092866]\n",
      " [0.9222486 ]\n",
      " [0.92346925]\n",
      " [0.92351377]\n",
      " [0.92394167]\n",
      " [0.92524642]\n",
      " [0.92673242]\n",
      " [0.92863888]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.92978454]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.92092866]\n",
      "  [0.9222486 ]\n",
      "  [0.92346925]\n",
      "  [0.92351377]\n",
      "  [0.92394167]\n",
      "  [0.92524642]\n",
      "  [0.92673242]\n",
      "  [0.92863888]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018238646443933249\n",
      "Predicción post entrenamiento : [[0.93001074]]\n",
      "PERDIDAAAA despues: 0.001804595347493887\n",
      "loss en el callback: 0.0031923733185976744, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.9222486 ]\n",
      " [0.92346925]\n",
      " [0.92351377]\n",
      " [0.92394167]\n",
      " [0.92524642]\n",
      " [0.92673242]\n",
      " [0.92863888]\n",
      " [0.92978454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.93089557]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.9222486 ]\n",
      "  [0.92346925]\n",
      "  [0.92351377]\n",
      "  [0.92394167]\n",
      "  [0.92524642]\n",
      "  [0.92673242]\n",
      "  [0.92863888]\n",
      "  [0.92978454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004356643185019493\n",
      "Predicción post entrenamiento : [[0.9313896]]\n",
      "PERDIDAAAA despues: 0.004291674122214317\n",
      "loss en el callback: 0.017621906474232674, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.92346925]\n",
      " [0.92351377]\n",
      " [0.92394167]\n",
      " [0.92524642]\n",
      " [0.92673242]\n",
      " [0.92863888]\n",
      " [0.92978454]\n",
      " [0.93089557]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9321807]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.92346925]\n",
      "  [0.92351377]\n",
      "  [0.92394167]\n",
      "  [0.92524642]\n",
      "  [0.92673242]\n",
      "  [0.92863888]\n",
      "  [0.92978454]\n",
      "  [0.93089557]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003610382555052638\n",
      "Predicción post entrenamiento : [[0.9322412]]\n",
      "PERDIDAAAA despues: 0.0003587428655009717\n",
      "loss en el callback: 0.00021452433429658413, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.92351377]\n",
      " [0.92394167]\n",
      " [0.92524642]\n",
      " [0.92673242]\n",
      " [0.92863888]\n",
      " [0.92978454]\n",
      " [0.93089557]\n",
      " [0.9321807 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.93297374]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.92351377]\n",
      "  [0.92394167]\n",
      "  [0.92524642]\n",
      "  [0.92673242]\n",
      "  [0.92863888]\n",
      "  [0.92978454]\n",
      "  [0.93089557]\n",
      "  [0.9321807 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013836119323968887\n",
      "Predicción post entrenamiento : [[0.9332972]]\n",
      "PERDIDAAAA despues: 0.0014077810337767005\n",
      "loss en el callback: 0.00838950090110302, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.92394167]\n",
      " [0.92524642]\n",
      " [0.92673242]\n",
      " [0.92863888]\n",
      " [0.92978454]\n",
      " [0.93089557]\n",
      " [0.9321807 ]\n",
      " [0.93297374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.934341]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.92394167]\n",
      "  [0.92524642]\n",
      "  [0.92673242]\n",
      "  [0.92863888]\n",
      "  [0.92978454]\n",
      "  [0.93089557]\n",
      "  [0.9321807 ]\n",
      "  [0.93297374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00279838009737432\n",
      "Predicción post entrenamiento : [[0.9341588]]\n",
      "PERDIDAAAA despues: 0.0027791354805231094\n",
      "loss en el callback: 0.002049758331850171, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.92524642]\n",
      " [0.92673242]\n",
      " [0.92863888]\n",
      " [0.92978454]\n",
      " [0.93089557]\n",
      " [0.9321807 ]\n",
      " [0.93297374]\n",
      " [0.93434101]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.93545073]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.92524642]\n",
      "  [0.92673242]\n",
      "  [0.92863888]\n",
      "  [0.92978454]\n",
      "  [0.93089557]\n",
      "  [0.9321807 ]\n",
      "  [0.93297374]\n",
      "  [0.93434101]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003372478822711855\n",
      "Predicción post entrenamiento : [[0.93539953]]\n",
      "PERDIDAAAA despues: 0.00033536998671479523\n",
      "loss en el callback: 0.00016970615251921117, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.92673242]\n",
      " [0.92863888]\n",
      " [0.92978454]\n",
      " [0.93089557]\n",
      " [0.9321807 ]\n",
      " [0.93297374]\n",
      " [0.93434101]\n",
      " [0.93545073]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9367004]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.92673242]\n",
      "  [0.92863888]\n",
      "  [0.92978454]\n",
      "  [0.93089557]\n",
      "  [0.9321807 ]\n",
      "  [0.93297374]\n",
      "  [0.93434101]\n",
      "  [0.93545073]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028567254776135087\n",
      "Predicción post entrenamiento : [[0.9360355]]\n",
      "PERDIDAAAA despues: 0.0002636389108374715\n",
      "loss en el callback: 0.021537426859140396, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.92863888]\n",
      " [0.92978454]\n",
      " [0.93089557]\n",
      " [0.9321807 ]\n",
      " [0.93297374]\n",
      " [0.93434101]\n",
      " [0.93545073]\n",
      " [0.9367004 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9372798]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.92863888]\n",
      "  [0.92978454]\n",
      "  [0.93089557]\n",
      "  [0.9321807 ]\n",
      "  [0.93297374]\n",
      "  [0.93434101]\n",
      "  [0.93545073]\n",
      "  [0.9367004 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005935548688285053\n",
      "Predicción post entrenamiento : [[0.93728524]]\n",
      "PERDIDAAAA despues: 0.0005932906060479581\n",
      "loss en el callback: 1.8266476899952977e-06, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.92978454]\n",
      " [0.93089557]\n",
      " [0.9321807 ]\n",
      " [0.93297374]\n",
      " [0.93434101]\n",
      " [0.93545073]\n",
      " [0.9367004 ]\n",
      " [0.93727982]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9383243]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.92978454]\n",
      "  [0.93089557]\n",
      "  [0.9321807 ]\n",
      "  [0.93297374]\n",
      "  [0.93434101]\n",
      "  [0.93545073]\n",
      "  [0.9367004 ]\n",
      "  [0.93727982]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008943138527683914\n",
      "Predicción post entrenamiento : [[0.9387594]]\n",
      "PERDIDAAAA despues: 0.000868478964548558\n",
      "loss en el callback: 0.013334502466022968, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.93089557]\n",
      " [0.9321807 ]\n",
      " [0.93297374]\n",
      " [0.93434101]\n",
      " [0.93545073]\n",
      " [0.9367004 ]\n",
      " [0.93727982]\n",
      " [0.93832427]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9397888]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.93089557]\n",
      "  [0.9321807 ]\n",
      "  [0.93297374]\n",
      "  [0.93434101]\n",
      "  [0.93545073]\n",
      "  [0.9367004 ]\n",
      "  [0.93727982]\n",
      "  [0.93832427]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032326250220648944\n",
      "Predicción post entrenamiento : [[0.93948793]]\n",
      "PERDIDAAAA despues: 0.0003341725387144834\n",
      "loss en el callback: 0.0052045551128685474, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23649806]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0362490750849247\n",
      "Predicción post entrenamiento : [[0.19987734]]\n",
      "PERDIDAAAA despues: 0.02364557422697544\n",
      "loss en el callback: 0.0470082126557827, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23649806]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.1844525]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23649806]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006436746101826429\n",
      "Predicción post entrenamiento : [[0.16837749]]\n",
      "PERDIDAAAA despues: 0.004115776624530554\n",
      "loss en el callback: 0.009950853884220123, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23649806]\n",
      " [0.1844525 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17214897]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23649806]\n",
      "  [0.1844525 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000322029140079394\n",
      "Predicción post entrenamiento : [[0.17103888]]\n",
      "PERDIDAAAA despues: 0.0002834198821801692\n",
      "loss en el callback: 0.00013889044930692762, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23649806]\n",
      " [0.1844525 ]\n",
      " [0.17214897]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.18193096]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23649806]\n",
      "  [0.1844525 ]\n",
      "  [0.17214897]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006852550432085991\n",
      "Predicción post entrenamiento : [[0.17924789]]\n",
      "PERDIDAAAA despues: 0.0005519822589121759\n",
      "loss en el callback: 0.0011979142436757684, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23649806]\n",
      " [0.1844525 ]\n",
      " [0.17214897]\n",
      " [0.18193096]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19114247]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23649806]\n",
      "  [0.1844525 ]\n",
      "  [0.17214897]\n",
      "  [0.18193096]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004304635804146528\n",
      "Predicción post entrenamiento : [[0.18687452]]\n",
      "PERDIDAAAA despues: 0.003762813750654459\n",
      "loss en el callback: 0.004863361828029156, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23649806]\n",
      " [0.1844525 ]\n",
      " [0.17214897]\n",
      " [0.18193096]\n",
      " [0.19114247]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19589575]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23649806]\n",
      "  [0.1844525 ]\n",
      "  [0.17214897]\n",
      "  [0.18193096]\n",
      "  [0.19114247]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002521624555811286\n",
      "Predicción post entrenamiento : [[0.193605]]\n",
      "PERDIDAAAA despues: 0.002296809572726488\n",
      "loss en el callback: 0.0020398262422531843, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23649806]\n",
      " [0.1844525 ]\n",
      " [0.17214897]\n",
      " [0.18193096]\n",
      " [0.19114247]\n",
      " [0.19589575]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.21323219]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23649806]\n",
      "  [0.1844525 ]\n",
      "  [0.17214897]\n",
      "  [0.18193096]\n",
      "  [0.19114247]\n",
      "  [0.19589575]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004459212068468332\n",
      "Predicción post entrenamiento : [[0.2094013]]\n",
      "PERDIDAAAA despues: 0.003962254151701927\n",
      "loss en el callback: 0.006684951484203339, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.23649806]\n",
      " [0.1844525 ]\n",
      " [0.17214897]\n",
      " [0.18193096]\n",
      " [0.19114247]\n",
      " [0.19589575]\n",
      " [0.21323219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.23320557]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.23649806]\n",
      "  [0.1844525 ]\n",
      "  [0.17214897]\n",
      "  [0.18193096]\n",
      "  [0.19114247]\n",
      "  [0.19589575]\n",
      "  [0.21323219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013806824572384357\n",
      "Predicción post entrenamiento : [[0.2307637]]\n",
      "PERDIDAAAA despues: 0.0012051775120198727\n",
      "loss en el callback: 0.0032605817541480064, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.23649806]\n",
      " [0.1844525 ]\n",
      " [0.17214897]\n",
      " [0.18193096]\n",
      " [0.19114247]\n",
      " [0.19589575]\n",
      " [0.21323219]\n",
      " [0.23320557]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2591158]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.23649806]\n",
      "  [0.1844525 ]\n",
      "  [0.17214897]\n",
      "  [0.18193096]\n",
      "  [0.19114247]\n",
      "  [0.19589575]\n",
      "  [0.21323219]\n",
      "  [0.23320557]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008171014487743378\n",
      "Predicción post entrenamiento : [[0.25961784]]\n",
      "PERDIDAAAA despues: 0.0008460556855425239\n",
      "loss en el callback: 0.00026468225405551493, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.1844525 ]\n",
      " [0.17214897]\n",
      " [0.18193096]\n",
      " [0.19114247]\n",
      " [0.19589575]\n",
      " [0.21323219]\n",
      " [0.23320557]\n",
      " [0.25911579]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2511865]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.1844525 ]\n",
      "  [0.17214897]\n",
      "  [0.18193096]\n",
      "  [0.19114247]\n",
      "  [0.19589575]\n",
      "  [0.21323219]\n",
      "  [0.23320557]\n",
      "  [0.25911579]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018267205450683832\n",
      "Predicción post entrenamiento : [[0.24945801]]\n",
      "PERDIDAAAA despues: 0.0016819576267153025\n",
      "loss en el callback: 0.0025085185188800097, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.17214897]\n",
      " [0.18193096]\n",
      " [0.19114247]\n",
      " [0.19589575]\n",
      " [0.21323219]\n",
      " [0.23320557]\n",
      " [0.25911579]\n",
      " [0.25118649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25208133]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.17214897]\n",
      "  [0.18193096]\n",
      "  [0.19114247]\n",
      "  [0.19589575]\n",
      "  [0.21323219]\n",
      "  [0.23320557]\n",
      "  [0.25911579]\n",
      "  [0.25118649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001611859886907041\n",
      "Predicción post entrenamiento : [[0.24937777]]\n",
      "PERDIDAAAA despues: 0.0014020840171724558\n",
      "loss en el callback: 0.006412073969841003, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.18193096]\n",
      " [0.19114247]\n",
      " [0.19589575]\n",
      " [0.21323219]\n",
      " [0.23320557]\n",
      " [0.25911579]\n",
      " [0.25118649]\n",
      " [0.25208133]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25646666]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.18193096]\n",
      "  [0.19114247]\n",
      "  [0.19589575]\n",
      "  [0.21323219]\n",
      "  [0.23320557]\n",
      "  [0.25911579]\n",
      "  [0.25118649]\n",
      "  [0.25208133]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024189334362745285\n",
      "Predicción post entrenamiento : [[0.25463924]]\n",
      "PERDIDAAAA despues: 0.0022425183560699224\n",
      "loss en el callback: 0.004131294321268797, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.19114247]\n",
      " [0.19589575]\n",
      " [0.21323219]\n",
      " [0.23320557]\n",
      " [0.25911579]\n",
      " [0.25118649]\n",
      " [0.25208133]\n",
      " [0.25646666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2620947]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.19114247]\n",
      "  [0.19589575]\n",
      "  [0.21323219]\n",
      "  [0.23320557]\n",
      "  [0.25911579]\n",
      "  [0.25118649]\n",
      "  [0.25208133]\n",
      "  [0.25646666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047812010161578655\n",
      "Predicción post entrenamiento : [[0.25960866]]\n",
      "PERDIDAAAA despues: 0.0044435798190534115\n",
      "loss en el callback: 0.008107171393930912, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.19589575]\n",
      " [0.21323219]\n",
      " [0.23320557]\n",
      " [0.25911579]\n",
      " [0.25118649]\n",
      " [0.25208133]\n",
      " [0.25646666]\n",
      " [0.26209471]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2674658]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.19589575]\n",
      "  [0.21323219]\n",
      "  [0.23320557]\n",
      "  [0.25911579]\n",
      "  [0.25118649]\n",
      "  [0.25208133]\n",
      "  [0.25646666]\n",
      "  [0.26209471]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004990413319319487\n",
      "Predicción post entrenamiento : [[0.26716053]]\n",
      "PERDIDAAAA despues: 0.004947376903146505\n",
      "loss en el callback: 0.0002485120785422623, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.21323219]\n",
      " [0.23320557]\n",
      " [0.25911579]\n",
      " [0.25118649]\n",
      " [0.25208133]\n",
      " [0.25646666]\n",
      " [0.26209471]\n",
      " [0.2674658 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27630097]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.21323219]\n",
      "  [0.23320557]\n",
      "  [0.25911579]\n",
      "  [0.25118649]\n",
      "  [0.25208133]\n",
      "  [0.25646666]\n",
      "  [0.26209471]\n",
      "  [0.2674658 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003849324071779847\n",
      "Predicción post entrenamiento : [[0.27628133]]\n",
      "PERDIDAAAA despues: 0.0038468874990940094\n",
      "loss en el callback: 1.021125058286998e-06, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.23320557]\n",
      " [0.25911579]\n",
      " [0.25118649]\n",
      " [0.25208133]\n",
      " [0.25646666]\n",
      " [0.26209471]\n",
      " [0.2674658 ]\n",
      " [0.27630097]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.28385738]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.23320557]\n",
      "  [0.25911579]\n",
      "  [0.25118649]\n",
      "  [0.25208133]\n",
      "  [0.25646666]\n",
      "  [0.26209471]\n",
      "  [0.2674658 ]\n",
      "  [0.27630097]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010512875393033028\n",
      "Predicción post entrenamiento : [[0.2800597]]\n",
      "PERDIDAAAA despues: 0.009748527780175209\n",
      "loss en el callback: 0.023296840488910675, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25911579]\n",
      " [0.25118649]\n",
      " [0.25208133]\n",
      " [0.25646666]\n",
      " [0.26209471]\n",
      " [0.2674658 ]\n",
      " [0.27630097]\n",
      " [0.28385738]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28497493]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25911579]\n",
      "  [0.25118649]\n",
      "  [0.25208133]\n",
      "  [0.25646666]\n",
      "  [0.26209471]\n",
      "  [0.2674658 ]\n",
      "  [0.27630097]\n",
      "  [0.28385738]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012066803872585297\n",
      "Predicción post entrenamiento : [[0.2835409]]\n",
      "PERDIDAAAA despues: 0.01175380777567625\n",
      "loss en el callback: 0.0058891139924526215, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.25118649]\n",
      " [0.25208133]\n",
      " [0.25646666]\n",
      " [0.26209471]\n",
      " [0.2674658 ]\n",
      " [0.27630097]\n",
      " [0.28385738]\n",
      " [0.28497493]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2839149]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.25118649]\n",
      "  [0.25208133]\n",
      "  [0.25646666]\n",
      "  [0.26209471]\n",
      "  [0.2674658 ]\n",
      "  [0.27630097]\n",
      "  [0.28385738]\n",
      "  [0.28497493]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018471594899892807\n",
      "Predicción post entrenamiento : [[0.28110266]]\n",
      "PERDIDAAAA despues: 0.017715079709887505\n",
      "loss en el callback: 0.020703747868537903, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.25208133]\n",
      " [0.25646666]\n",
      " [0.26209471]\n",
      " [0.2674658 ]\n",
      " [0.27630097]\n",
      " [0.28385738]\n",
      " [0.28497493]\n",
      " [0.28391489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.28391135]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.25208133]\n",
      "  [0.25646666]\n",
      "  [0.26209471]\n",
      "  [0.2674658 ]\n",
      "  [0.27630097]\n",
      "  [0.28385738]\n",
      "  [0.28497493]\n",
      "  [0.28391489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015639550983905792\n",
      "Predicción post entrenamiento : [[0.28074172]]\n",
      "PERDIDAAAA despues: 0.014856821857392788\n",
      "loss en el callback: 0.0253352839499712, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25646666]\n",
      " [0.26209471]\n",
      " [0.2674658 ]\n",
      " [0.27630097]\n",
      " [0.28385738]\n",
      " [0.28497493]\n",
      " [0.28391489]\n",
      " [0.28391135]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2843814]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25646666]\n",
      "  [0.26209471]\n",
      "  [0.2674658 ]\n",
      "  [0.27630097]\n",
      "  [0.28385738]\n",
      "  [0.28497493]\n",
      "  [0.28391489]\n",
      "  [0.28391135]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008502282202243805\n",
      "Predicción post entrenamiento : [[0.2835893]]\n",
      "PERDIDAAAA despues: 0.008356836624443531\n",
      "loss en el callback: 0.0025318984407931566, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.26209471]\n",
      " [0.2674658 ]\n",
      " [0.27630097]\n",
      " [0.28385738]\n",
      " [0.28497493]\n",
      " [0.28391489]\n",
      " [0.28391135]\n",
      " [0.28438139]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2873215]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.26209471]\n",
      "  [0.2674658 ]\n",
      "  [0.27630097]\n",
      "  [0.28385738]\n",
      "  [0.28497493]\n",
      "  [0.28391489]\n",
      "  [0.28391135]\n",
      "  [0.28438139]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010271229781210423\n",
      "Predicción post entrenamiento : [[0.28636506]]\n",
      "PERDIDAAAA despues: 0.010078278370201588\n",
      "loss en el callback: 0.004009622149169445, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.2674658 ]\n",
      " [0.27630097]\n",
      " [0.28385738]\n",
      " [0.28497493]\n",
      " [0.28391489]\n",
      " [0.28391135]\n",
      " [0.28438139]\n",
      " [0.28732151]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.28980342]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.2674658 ]\n",
      "  [0.27630097]\n",
      "  [0.28385738]\n",
      "  [0.28497493]\n",
      "  [0.28391489]\n",
      "  [0.28391135]\n",
      "  [0.28438139]\n",
      "  [0.28732151]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005222426843829453\n",
      "Predicción post entrenamiento : [[0.28932673]]\n",
      "PERDIDAAAA despues: 0.0005006827414035797\n",
      "loss en el callback: 0.0008331406279467046, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27630097]\n",
      " [0.28385738]\n",
      " [0.28497493]\n",
      " [0.28391489]\n",
      " [0.28391135]\n",
      " [0.28438139]\n",
      " [0.28732151]\n",
      " [0.28980342]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2923699]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27630097]\n",
      "  [0.28385738]\n",
      "  [0.28497493]\n",
      "  [0.28391489]\n",
      "  [0.28391135]\n",
      "  [0.28438139]\n",
      "  [0.28732151]\n",
      "  [0.28980342]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.3219442368827004e-08\n",
      "Predicción post entrenamiento : [[0.29209122]]\n",
      "PERDIDAAAA despues: 1.8581340555101633e-07\n",
      "loss en el callback: 0.0003111757105216384, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.28385738]\n",
      " [0.28497493]\n",
      " [0.28391489]\n",
      " [0.28391135]\n",
      " [0.28438139]\n",
      " [0.28732151]\n",
      " [0.28980342]\n",
      " [0.2923699 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.29379192]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.28385738]\n",
      "  [0.28497493]\n",
      "  [0.28391489]\n",
      "  [0.28391135]\n",
      "  [0.28438139]\n",
      "  [0.28732151]\n",
      "  [0.28980342]\n",
      "  [0.2923699 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005718983593396842\n",
      "Predicción post entrenamiento : [[0.29375607]]\n",
      "PERDIDAAAA despues: 0.0005736144375987351\n",
      "loss en el callback: 5.532881914405152e-06, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28497493]\n",
      " [0.28391489]\n",
      " [0.28391135]\n",
      " [0.28438139]\n",
      " [0.28732151]\n",
      " [0.28980342]\n",
      " [0.2923699 ]\n",
      " [0.29379192]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.2941513]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28497493]\n",
      "  [0.28391489]\n",
      "  [0.28391135]\n",
      "  [0.28438139]\n",
      "  [0.28732151]\n",
      "  [0.28980342]\n",
      "  [0.2923699 ]\n",
      "  [0.29379192]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00034292408963665366\n",
      "Predicción post entrenamiento : [[0.29384306]]\n",
      "PERDIDAAAA despues: 0.0003544354112818837\n",
      "loss en el callback: 0.0003863619640469551, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28391489]\n",
      " [0.28391135]\n",
      " [0.28438139]\n",
      " [0.28732151]\n",
      " [0.28980342]\n",
      " [0.2923699 ]\n",
      " [0.29379192]\n",
      " [0.29415131]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.29421544]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28391489]\n",
      "  [0.28391135]\n",
      "  [0.28438139]\n",
      "  [0.28732151]\n",
      "  [0.28980342]\n",
      "  [0.2923699 ]\n",
      "  [0.29379192]\n",
      "  [0.29415131]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.6834266463993117e-05\n",
      "Predicción post entrenamiento : [[0.29402617]]\n",
      "PERDIDAAAA despues: 2.4909137209760956e-05\n",
      "loss en el callback: 0.00018811100744642317, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28391135]\n",
      " [0.28438139]\n",
      " [0.28732151]\n",
      " [0.28980342]\n",
      " [0.2923699 ]\n",
      " [0.29379192]\n",
      " [0.29415131]\n",
      " [0.29421544]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.2948952]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28391135]\n",
      "  [0.28438139]\n",
      "  [0.28732151]\n",
      "  [0.28980342]\n",
      "  [0.2923699 ]\n",
      "  [0.29379192]\n",
      "  [0.29415131]\n",
      "  [0.29421544]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014542171265929937\n",
      "Predicción post entrenamiento : [[0.29514894]]\n",
      "PERDIDAAAA despues: 0.0001516057673143223\n",
      "loss en el callback: 0.0005154691752977669, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28438139]\n",
      " [0.28732151]\n",
      " [0.28980342]\n",
      " [0.2923699 ]\n",
      " [0.29379192]\n",
      " [0.29415131]\n",
      " [0.29421544]\n",
      " [0.2948952 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2963528]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28438139]\n",
      "  [0.28732151]\n",
      "  [0.28980342]\n",
      "  [0.2923699 ]\n",
      "  [0.29379192]\n",
      "  [0.29415131]\n",
      "  [0.29421544]\n",
      "  [0.2948952 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.881712685455568e-06\n",
      "Predicción post entrenamiento : [[0.29660335]]\n",
      "PERDIDAAAA despues: 8.369281204068102e-06\n",
      "loss en el callback: 0.00045660531031899154, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.28732151]\n",
      " [0.28980342]\n",
      " [0.2923699 ]\n",
      " [0.29379192]\n",
      " [0.29415131]\n",
      " [0.29421544]\n",
      " [0.2948952 ]\n",
      " [0.2963528 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.29806736]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.28732151]\n",
      "  [0.28980342]\n",
      "  [0.2923699 ]\n",
      "  [0.29379192]\n",
      "  [0.29415131]\n",
      "  [0.29421544]\n",
      "  [0.2948952 ]\n",
      "  [0.2963528 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004930750583298504\n",
      "Predicción post entrenamiento : [[0.29767466]]\n",
      "PERDIDAAAA despues: 0.00047578898374922574\n",
      "loss en el callback: 0.0009193523437716067, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28980342]\n",
      " [0.2923699 ]\n",
      " [0.29379192]\n",
      " [0.29415131]\n",
      " [0.29421544]\n",
      " [0.2948952 ]\n",
      " [0.2963528 ]\n",
      " [0.29806736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.29884198]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28980342]\n",
      "  [0.2923699 ]\n",
      "  [0.29379192]\n",
      "  [0.29415131]\n",
      "  [0.29421544]\n",
      "  [0.2948952 ]\n",
      "  [0.2963528 ]\n",
      "  [0.29806736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005828489665873349\n",
      "Predicción post entrenamiento : [[0.29871428]]\n",
      "PERDIDAAAA despues: 0.0005766992107965052\n",
      "loss en el callback: 0.00011974589142482728, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.2923699 ]\n",
      " [0.29379192]\n",
      " [0.29415131]\n",
      " [0.29421544]\n",
      " [0.2948952 ]\n",
      " [0.2963528 ]\n",
      " [0.29806736]\n",
      " [0.29884198]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.29961893]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.2923699 ]\n",
      "  [0.29379192]\n",
      "  [0.29415131]\n",
      "  [0.29421544]\n",
      "  [0.2948952 ]\n",
      "  [0.2963528 ]\n",
      "  [0.29806736]\n",
      "  [0.29884198]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005829482688568532\n",
      "Predicción post entrenamiento : [[0.2991291]]\n",
      "PERDIDAAAA despues: 0.0005595349357463419\n",
      "loss en el callback: 0.001623922842554748, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.29379192]\n",
      " [0.29415131]\n",
      " [0.29421544]\n",
      " [0.2948952 ]\n",
      " [0.2963528 ]\n",
      " [0.29806736]\n",
      " [0.29884198]\n",
      " [0.29961893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.29969713]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.29379192]\n",
      "  [0.29415131]\n",
      "  [0.29421544]\n",
      "  [0.2948952 ]\n",
      "  [0.2963528 ]\n",
      "  [0.29806736]\n",
      "  [0.29884198]\n",
      "  [0.29961893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012289813021197915\n",
      "Predicción post entrenamiento : [[0.29966378]]\n",
      "PERDIDAAAA despues: 0.001231320551596582\n",
      "loss en el callback: 7.366325462498935e-06, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.29415131]\n",
      " [0.29421544]\n",
      " [0.2948952 ]\n",
      " [0.2963528 ]\n",
      " [0.29806736]\n",
      " [0.29884198]\n",
      " [0.29961893]\n",
      " [0.29969713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.30010274]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.29415131]\n",
      "  [0.29421544]\n",
      "  [0.2948952 ]\n",
      "  [0.2963528 ]\n",
      "  [0.29806736]\n",
      "  [0.29884198]\n",
      "  [0.29961893]\n",
      "  [0.29969713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030883965082466602\n",
      "Predicción post entrenamiento : [[0.30088428]]\n",
      "PERDIDAAAA despues: 0.0030021423008292913\n",
      "loss en el callback: 0.00598430261015892, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.29421544]\n",
      " [0.2948952 ]\n",
      " [0.2963528 ]\n",
      " [0.29806736]\n",
      " [0.29884198]\n",
      " [0.29961893]\n",
      " [0.29969713]\n",
      " [0.30010274]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30141985]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.29421544]\n",
      "  [0.2948952 ]\n",
      "  [0.2963528 ]\n",
      "  [0.29806736]\n",
      "  [0.29884198]\n",
      "  [0.29961893]\n",
      "  [0.29969713]\n",
      "  [0.30010274]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012440679129213095\n",
      "Predicción post entrenamiento : [[0.3020485]]\n",
      "PERDIDAAAA despues: 0.0012001163559034467\n",
      "loss en el callback: 0.004740590695291758, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.2948952 ]\n",
      " [0.2963528 ]\n",
      " [0.29806736]\n",
      " [0.29884198]\n",
      " [0.29961893]\n",
      " [0.29969713]\n",
      " [0.30010274]\n",
      " [0.30141985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3027641]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.2948952 ]\n",
      "  [0.2963528 ]\n",
      "  [0.29806736]\n",
      "  [0.29884198]\n",
      "  [0.29961893]\n",
      "  [0.29969713]\n",
      "  [0.30010274]\n",
      "  [0.30141985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009503379696980119\n",
      "Predicción post entrenamiento : [[0.30335683]]\n",
      "PERDIDAAAA despues: 0.0009141439804807305\n",
      "loss en el callback: 0.003930229227989912, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.2963528 ]\n",
      " [0.29806736]\n",
      " [0.29884198]\n",
      " [0.29961893]\n",
      " [0.29969713]\n",
      " [0.30010274]\n",
      " [0.30141985]\n",
      " [0.30276409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.30413458]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.2963528 ]\n",
      "  [0.29806736]\n",
      "  [0.29884198]\n",
      "  [0.29961893]\n",
      "  [0.29969713]\n",
      "  [0.30010274]\n",
      "  [0.30141985]\n",
      "  [0.30276409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006496363785117865\n",
      "Predicción post entrenamiento : [[0.305014]]\n",
      "PERDIDAAAA despues: 0.006355371791869402\n",
      "loss en el callback: 0.00890603568404913, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.29806736]\n",
      " [0.29884198]\n",
      " [0.29961893]\n",
      " [0.29969713]\n",
      " [0.30010274]\n",
      " [0.30141985]\n",
      " [0.30276409]\n",
      " [0.30413458]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.30567974]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.29806736]\n",
      "  [0.29884198]\n",
      "  [0.29961893]\n",
      "  [0.29969713]\n",
      "  [0.30010274]\n",
      "  [0.30141985]\n",
      "  [0.30276409]\n",
      "  [0.30413458]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07044604420661926\n",
      "Predicción post entrenamiento : [[0.3082143]]\n",
      "PERDIDAAAA despues: 0.06910703331232071\n",
      "loss en el callback: 0.061704233288764954, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.29884198]\n",
      " [0.29961893]\n",
      " [0.29969713]\n",
      " [0.30010274]\n",
      " [0.30141985]\n",
      " [0.30276409]\n",
      " [0.30413458]\n",
      " [0.30567974]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.30869454]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.29884198]\n",
      "  [0.29961893]\n",
      "  [0.29969713]\n",
      "  [0.30010274]\n",
      "  [0.30141985]\n",
      "  [0.30276409]\n",
      "  [0.30413458]\n",
      "  [0.30567974]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08270569145679474\n",
      "Predicción post entrenamiento : [[0.31128186]]\n",
      "PERDIDAAAA despues: 0.0812242329120636\n",
      "loss en el callback: 0.06627035140991211, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.29961893]\n",
      " [0.29969713]\n",
      " [0.30010274]\n",
      " [0.30141985]\n",
      " [0.30276409]\n",
      " [0.30413458]\n",
      " [0.30567974]\n",
      " [0.30869454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3117867]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.29961893]\n",
      "  [0.29969713]\n",
      "  [0.30010274]\n",
      "  [0.30141985]\n",
      "  [0.30276409]\n",
      "  [0.30413458]\n",
      "  [0.30567974]\n",
      "  [0.30869454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06906213611364365\n",
      "Predicción post entrenamiento : [[0.31424233]]\n",
      "PERDIDAAAA despues: 0.06777750700712204\n",
      "loss en el callback: 0.07308705151081085, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29969713]\n",
      " [0.30010274]\n",
      " [0.30141985]\n",
      " [0.30276409]\n",
      " [0.30413458]\n",
      " [0.30567974]\n",
      " [0.30869454]\n",
      " [0.31178671]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.31481165]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29969713]\n",
      "  [0.30010274]\n",
      "  [0.30141985]\n",
      "  [0.30276409]\n",
      "  [0.30413458]\n",
      "  [0.30567974]\n",
      "  [0.30869454]\n",
      "  [0.31178671]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0849970132112503\n",
      "Predicción post entrenamiento : [[0.31733]]\n",
      "PERDIDAAAA despues: 0.08353494107723236\n",
      "loss en el callback: 0.0606415756046772, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30010274]\n",
      " [0.30141985]\n",
      " [0.30276409]\n",
      " [0.30413458]\n",
      " [0.30567974]\n",
      " [0.30869454]\n",
      " [0.31178671]\n",
      " [0.31481165]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.31818333]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30010274]\n",
      "  [0.30141985]\n",
      "  [0.30276409]\n",
      "  [0.30413458]\n",
      "  [0.30567974]\n",
      "  [0.30869454]\n",
      "  [0.31178671]\n",
      "  [0.31481165]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07100828737020493\n",
      "Predicción post entrenamiento : [[0.32056484]]\n",
      "PERDIDAAAA despues: 0.06974474340677261\n",
      "loss en el callback: 0.08141973614692688, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30141985]\n",
      " [0.30276409]\n",
      " [0.30413458]\n",
      " [0.30567974]\n",
      " [0.30869454]\n",
      " [0.31178671]\n",
      " [0.31481165]\n",
      " [0.31818333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32171872]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30141985]\n",
      "  [0.30276409]\n",
      "  [0.30413458]\n",
      "  [0.30567974]\n",
      "  [0.30869454]\n",
      "  [0.31178671]\n",
      "  [0.31481165]\n",
      "  [0.31818333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06103521212935448\n",
      "Predicción post entrenamiento : [[0.3237913]]\n",
      "PERDIDAAAA despues: 0.06001543626189232\n",
      "loss en el callback: 0.05179620161652565, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.30276409]\n",
      " [0.30413458]\n",
      " [0.30567974]\n",
      " [0.30869454]\n",
      " [0.31178671]\n",
      " [0.31481165]\n",
      " [0.31818333]\n",
      " [0.32171872]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32512456]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.30276409]\n",
      "  [0.30413458]\n",
      "  [0.30567974]\n",
      "  [0.30869454]\n",
      "  [0.31178671]\n",
      "  [0.31481165]\n",
      "  [0.31818333]\n",
      "  [0.32171872]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10090123116970062\n",
      "Predicción post entrenamiento : [[0.32791725]]\n",
      "PERDIDAAAA despues: 0.09913484007120132\n",
      "loss en el callback: 0.13821348547935486, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.30413458]\n",
      " [0.30567974]\n",
      " [0.30869454]\n",
      " [0.31178671]\n",
      " [0.31481165]\n",
      " [0.31818333]\n",
      " [0.32171872]\n",
      " [0.32512456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3294941]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.30413458]\n",
      "  [0.30567974]\n",
      "  [0.30869454]\n",
      "  [0.31178671]\n",
      "  [0.31481165]\n",
      "  [0.31818333]\n",
      "  [0.32171872]\n",
      "  [0.32512456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11039998382329941\n",
      "Predicción post entrenamiento : [[0.33226663]]\n",
      "PERDIDAAAA despues: 0.10856523364782333\n",
      "loss en el callback: 0.10407532006502151, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30567974]\n",
      " [0.30869454]\n",
      " [0.31178671]\n",
      " [0.31481165]\n",
      " [0.31818333]\n",
      " [0.32171872]\n",
      " [0.32512456]\n",
      " [0.32949409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3341603]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30567974]\n",
      "  [0.30869454]\n",
      "  [0.31178671]\n",
      "  [0.31481165]\n",
      "  [0.31818333]\n",
      "  [0.32171872]\n",
      "  [0.32512456]\n",
      "  [0.32949409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11480893939733505\n",
      "Predicción post entrenamiento : [[0.33690754]]\n",
      "PERDIDAAAA despues: 0.1129547655582428\n",
      "loss en el callback: 0.11494898051023483, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30869454]\n",
      " [0.31178671]\n",
      " [0.31481165]\n",
      " [0.31818333]\n",
      " [0.32171872]\n",
      " [0.32512456]\n",
      " [0.32949409]\n",
      " [0.3341603 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.33916524]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30869454]\n",
      "  [0.31178671]\n",
      "  [0.31481165]\n",
      "  [0.31818333]\n",
      "  [0.32171872]\n",
      "  [0.32512456]\n",
      "  [0.32949409]\n",
      "  [0.3341603 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13794691860675812\n",
      "Predicción post entrenamiento : [[0.34208602]]\n",
      "PERDIDAAAA despues: 0.13578583300113678\n",
      "loss en el callback: 0.16335906088352203, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31178671]\n",
      " [0.31481165]\n",
      " [0.31818333]\n",
      " [0.32171872]\n",
      " [0.32512456]\n",
      " [0.32949409]\n",
      " [0.3341603 ]\n",
      " [0.33916524]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34445062]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31178671]\n",
      "  [0.31481165]\n",
      "  [0.31818333]\n",
      "  [0.32171872]\n",
      "  [0.32512456]\n",
      "  [0.32949409]\n",
      "  [0.3341603 ]\n",
      "  [0.33916524]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1292690634727478\n",
      "Predicción post entrenamiento : [[0.34724686]]\n",
      "PERDIDAAAA despues: 0.12726616859436035\n",
      "loss en el callback: 0.12078765034675598, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31481165]\n",
      " [0.31818333]\n",
      " [0.32171872]\n",
      " [0.32512456]\n",
      " [0.32949409]\n",
      " [0.3341603 ]\n",
      " [0.33916524]\n",
      " [0.34445062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34975216]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31481165]\n",
      "  [0.31818333]\n",
      "  [0.32171872]\n",
      "  [0.32512456]\n",
      "  [0.32949409]\n",
      "  [0.3341603 ]\n",
      "  [0.33916524]\n",
      "  [0.34445062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14249520003795624\n",
      "Predicción post entrenamiento : [[0.3527175]]\n",
      "PERDIDAAAA despues: 0.14026525616645813\n",
      "loss en el callback: 0.14853136241436005, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31818333]\n",
      " [0.32171872]\n",
      " [0.32512456]\n",
      " [0.32949409]\n",
      " [0.3341603 ]\n",
      " [0.33916524]\n",
      " [0.34445062]\n",
      " [0.34975216]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.355442]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31818333]\n",
      "  [0.32171872]\n",
      "  [0.32512456]\n",
      "  [0.32949409]\n",
      "  [0.3341603 ]\n",
      "  [0.33916524]\n",
      "  [0.34445062]\n",
      "  [0.34975216]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13479627668857574\n",
      "Predicción post entrenamiento : [[0.35804844]]\n",
      "PERDIDAAAA despues: 0.13288918137550354\n",
      "loss en el callback: 0.08307404071092606, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32171872]\n",
      " [0.32512456]\n",
      " [0.32949409]\n",
      " [0.3341603 ]\n",
      " [0.33916524]\n",
      " [0.34445062]\n",
      " [0.34975216]\n",
      " [0.35544199]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3609849]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32171872]\n",
      "  [0.32512456]\n",
      "  [0.32949409]\n",
      "  [0.3341603 ]\n",
      "  [0.33916524]\n",
      "  [0.34445062]\n",
      "  [0.34975216]\n",
      "  [0.35544199]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16876403987407684\n",
      "Predicción post entrenamiento : [[0.36405268]]\n",
      "PERDIDAAAA despues: 0.16625289618968964\n",
      "loss en el callback: 0.23057737946510315, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32512456]\n",
      " [0.32949409]\n",
      " [0.3341603 ]\n",
      " [0.33916524]\n",
      " [0.34445062]\n",
      " [0.34975216]\n",
      " [0.35544199]\n",
      " [0.36098489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36723536]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32512456]\n",
      "  [0.32949409]\n",
      "  [0.3341603 ]\n",
      "  [0.33916524]\n",
      "  [0.34445062]\n",
      "  [0.34975216]\n",
      "  [0.35544199]\n",
      "  [0.36098489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12765616178512573\n",
      "Predicción post entrenamiento : [[0.36977252]]\n",
      "PERDIDAAAA despues: 0.12584960460662842\n",
      "loss en el callback: 0.09271757304668427, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32949409]\n",
      " [0.3341603 ]\n",
      " [0.33916524]\n",
      " [0.34445062]\n",
      " [0.34975216]\n",
      " [0.35544199]\n",
      " [0.36098489]\n",
      " [0.36723536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37330908]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32949409]\n",
      "  [0.3341603 ]\n",
      "  [0.33916524]\n",
      "  [0.34445062]\n",
      "  [0.34975216]\n",
      "  [0.35544199]\n",
      "  [0.36098489]\n",
      "  [0.36723536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08865424245595932\n",
      "Predicción post entrenamiento : [[0.37539378]]\n",
      "PERDIDAAAA despues: 0.08741715550422668\n",
      "loss en el callback: 0.06355497986078262, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.3341603 ]\n",
      " [0.33916524]\n",
      " [0.34445062]\n",
      " [0.34975216]\n",
      " [0.35544199]\n",
      " [0.36098489]\n",
      " [0.36723536]\n",
      " [0.37330908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.37913615]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.3341603 ]\n",
      "  [0.33916524]\n",
      "  [0.34445062]\n",
      "  [0.34975216]\n",
      "  [0.35544199]\n",
      "  [0.36098489]\n",
      "  [0.36723536]\n",
      "  [0.37330908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08680900931358337\n",
      "Predicción post entrenamiento : [[0.38125262]]\n",
      "PERDIDAAAA despues: 0.08556631952524185\n",
      "loss en el callback: 0.07950048893690109, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33916524]\n",
      " [0.34445062]\n",
      " [0.34975216]\n",
      " [0.35544199]\n",
      " [0.36098489]\n",
      " [0.36723536]\n",
      " [0.37330908]\n",
      " [0.37913615]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3851845]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33916524]\n",
      "  [0.34445062]\n",
      "  [0.34975216]\n",
      "  [0.35544199]\n",
      "  [0.36098489]\n",
      "  [0.36723536]\n",
      "  [0.37330908]\n",
      "  [0.37913615]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10841695219278336\n",
      "Predicción post entrenamiento : [[0.38759097]]\n",
      "PERDIDAAAA despues: 0.10683799535036087\n",
      "loss en el callback: 0.12491422146558762, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34445062]\n",
      " [0.34975216]\n",
      " [0.35544199]\n",
      " [0.36098489]\n",
      " [0.36723536]\n",
      " [0.37330908]\n",
      " [0.37913615]\n",
      " [0.3851845 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.3916786]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34445062]\n",
      "  [0.34975216]\n",
      "  [0.35544199]\n",
      "  [0.36098489]\n",
      "  [0.36723536]\n",
      "  [0.37330908]\n",
      "  [0.37913615]\n",
      "  [0.3851845 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1240583211183548\n",
      "Predicción post entrenamiento : [[0.3942036]]\n",
      "PERDIDAAAA despues: 0.12228598445653915\n",
      "loss en el callback: 0.11807376146316528, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.34975216]\n",
      " [0.35544199]\n",
      " [0.36098489]\n",
      " [0.36723536]\n",
      " [0.37330908]\n",
      " [0.37913615]\n",
      " [0.3851845 ]\n",
      " [0.3916786 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.39841852]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.34975216]\n",
      "  [0.35544199]\n",
      "  [0.36098489]\n",
      "  [0.36723536]\n",
      "  [0.37330908]\n",
      "  [0.37913615]\n",
      "  [0.3851845 ]\n",
      "  [0.3916786 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10508593171834946\n",
      "Predicción post entrenamiento : [[0.40030333]]\n",
      "PERDIDAAAA despues: 0.10386748611927032\n",
      "loss en el callback: 0.049908917397260666, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35544199]\n",
      " [0.36098489]\n",
      " [0.36723536]\n",
      " [0.37330908]\n",
      " [0.37913615]\n",
      " [0.3851845 ]\n",
      " [0.3916786 ]\n",
      " [0.39841852]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.404676]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35544199]\n",
      "  [0.36098489]\n",
      "  [0.36723536]\n",
      "  [0.37330908]\n",
      "  [0.37913615]\n",
      "  [0.3851845 ]\n",
      "  [0.3916786 ]\n",
      "  [0.39841852]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08682768046855927\n",
      "Predicción post entrenamiento : [[0.40677145]]\n",
      "PERDIDAAAA despues: 0.08559715002775192\n",
      "loss en el callback: 0.10113902390003204, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36098489]\n",
      " [0.36723536]\n",
      " [0.37330908]\n",
      " [0.37913615]\n",
      " [0.3851845 ]\n",
      " [0.3916786 ]\n",
      " [0.39841852]\n",
      " [0.40467599]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.41124374]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36098489]\n",
      "  [0.36723536]\n",
      "  [0.37330908]\n",
      "  [0.37913615]\n",
      "  [0.3851845 ]\n",
      "  [0.3916786 ]\n",
      "  [0.39841852]\n",
      "  [0.40467599]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10631994158029556\n",
      "Predicción post entrenamiento : [[0.41364557]]\n",
      "PERDIDAAAA despues: 0.10475939512252808\n",
      "loss en el callback: 0.1432061642408371, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.36723536]\n",
      " [0.37330908]\n",
      " [0.37913615]\n",
      " [0.3851845 ]\n",
      " [0.3916786 ]\n",
      " [0.39841852]\n",
      " [0.40467599]\n",
      " [0.41124374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.41828203]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.36723536]\n",
      "  [0.37330908]\n",
      "  [0.37913615]\n",
      "  [0.3851845 ]\n",
      "  [0.3916786 ]\n",
      "  [0.39841852]\n",
      "  [0.40467599]\n",
      "  [0.41124374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0918961614370346\n",
      "Predicción post entrenamiento : [[0.42034256]]\n",
      "PERDIDAAAA despues: 0.09065113216638565\n",
      "loss en el callback: 0.0908716470003128, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37330908]\n",
      " [0.37913615]\n",
      " [0.3851845 ]\n",
      " [0.3916786 ]\n",
      " [0.39841852]\n",
      " [0.40467599]\n",
      " [0.41124374]\n",
      " [0.41828203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4250018]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37330908]\n",
      "  [0.37913615]\n",
      "  [0.3851845 ]\n",
      "  [0.3916786 ]\n",
      "  [0.39841852]\n",
      "  [0.40467599]\n",
      "  [0.41124374]\n",
      "  [0.41828203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08626668155193329\n",
      "Predicción post entrenamiento : [[0.42698246]]\n",
      "PERDIDAAAA despues: 0.08510711789131165\n",
      "loss en el callback: 0.09149395674467087, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.37913615]\n",
      " [0.3851845 ]\n",
      " [0.3916786 ]\n",
      " [0.39841852]\n",
      " [0.40467599]\n",
      " [0.41124374]\n",
      " [0.41828203]\n",
      " [0.4250018 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.43172434]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.37913615]\n",
      "  [0.3851845 ]\n",
      "  [0.3916786 ]\n",
      "  [0.39841852]\n",
      "  [0.40467599]\n",
      "  [0.41124374]\n",
      "  [0.41828203]\n",
      "  [0.4250018 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05877375230193138\n",
      "Predicción post entrenamiento : [[0.43360224]]\n",
      "PERDIDAAAA despues: 0.057866744697093964\n",
      "loss en el callback: 0.11313679069280624, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.3851845 ]\n",
      " [0.3916786 ]\n",
      " [0.39841852]\n",
      " [0.40467599]\n",
      " [0.41124374]\n",
      " [0.41828203]\n",
      " [0.4250018 ]\n",
      " [0.43172434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.43851435]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.3851845 ]\n",
      "  [0.3916786 ]\n",
      "  [0.39841852]\n",
      "  [0.40467599]\n",
      "  [0.41124374]\n",
      "  [0.41828203]\n",
      "  [0.4250018 ]\n",
      "  [0.43172434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06762708723545074\n",
      "Predicción post entrenamiento : [[0.44033346]]\n",
      "PERDIDAAAA despues: 0.06668427586555481\n",
      "loss en el callback: 0.08271786570549011, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.3916786 ]\n",
      " [0.39841852]\n",
      " [0.40467599]\n",
      " [0.41124374]\n",
      " [0.41828203]\n",
      " [0.4250018 ]\n",
      " [0.43172434]\n",
      " [0.43851435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.44539565]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.3916786 ]\n",
      "  [0.39841852]\n",
      "  [0.40467599]\n",
      "  [0.41124374]\n",
      "  [0.41828203]\n",
      "  [0.4250018 ]\n",
      "  [0.43172434]\n",
      "  [0.43851435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07597889751195908\n",
      "Predicción post entrenamiento : [[0.44713622]]\n",
      "PERDIDAAAA despues: 0.0750223696231842\n",
      "loss en el callback: 0.060397110879421234, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.39841852]\n",
      " [0.40467599]\n",
      " [0.41124374]\n",
      " [0.41828203]\n",
      " [0.4250018 ]\n",
      " [0.43172434]\n",
      " [0.43851435]\n",
      " [0.44539565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.45226273]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.39841852]\n",
      "  [0.40467599]\n",
      "  [0.41124374]\n",
      "  [0.41828203]\n",
      "  [0.4250018 ]\n",
      "  [0.43172434]\n",
      "  [0.43851435]\n",
      "  [0.44539565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07307581603527069\n",
      "Predicción post entrenamiento : [[0.45409366]]\n",
      "PERDIDAAAA despues: 0.07208926975727081\n",
      "loss en el callback: 0.0913202241063118, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.40467599]\n",
      " [0.41124374]\n",
      " [0.41828203]\n",
      " [0.4250018 ]\n",
      " [0.43172434]\n",
      " [0.43851435]\n",
      " [0.44539565]\n",
      " [0.45226273]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.459234]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.40467599]\n",
      "  [0.41124374]\n",
      "  [0.41828203]\n",
      "  [0.4250018 ]\n",
      "  [0.43172434]\n",
      "  [0.43851435]\n",
      "  [0.44539565]\n",
      "  [0.45226273]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08824585378170013\n",
      "Predicción post entrenamiento : [[0.46082267]]\n",
      "PERDIDAAAA despues: 0.0873045101761818\n",
      "loss en el callback: 0.041093047708272934, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41124374]\n",
      " [0.41828203]\n",
      " [0.4250018 ]\n",
      " [0.43172434]\n",
      " [0.43851435]\n",
      " [0.44539565]\n",
      " [0.45226273]\n",
      " [0.459234  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.46610668]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41124374]\n",
      "  [0.41828203]\n",
      "  [0.4250018 ]\n",
      "  [0.43172434]\n",
      "  [0.43851435]\n",
      "  [0.44539565]\n",
      "  [0.45226273]\n",
      "  [0.459234  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13066746294498444\n",
      "Predicción post entrenamiento : [[0.46849513]]\n",
      "PERDIDAAAA despues: 0.1289464235305786\n",
      "loss en el callback: 0.14851902425289154, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.41828203]\n",
      " [0.4250018 ]\n",
      " [0.43172434]\n",
      " [0.43851435]\n",
      " [0.44539565]\n",
      " [0.45226273]\n",
      " [0.459234  ]\n",
      " [0.46610668]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.4738686]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.41828203]\n",
      "  [0.4250018 ]\n",
      "  [0.43172434]\n",
      "  [0.43851435]\n",
      "  [0.44539565]\n",
      "  [0.45226273]\n",
      "  [0.459234  ]\n",
      "  [0.46610668]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13319110870361328\n",
      "Predicción post entrenamiento : [[0.4761016]]\n",
      "PERDIDAAAA despues: 0.13156621158123016\n",
      "loss en el callback: 0.10844668745994568, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.4250018 ]\n",
      " [0.43172434]\n",
      " [0.43851435]\n",
      " [0.44539565]\n",
      " [0.45226273]\n",
      " [0.459234  ]\n",
      " [0.46610668]\n",
      " [0.47386861]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.4814575]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.4250018 ]\n",
      "  [0.43172434]\n",
      "  [0.43851435]\n",
      "  [0.44539565]\n",
      "  [0.45226273]\n",
      "  [0.459234  ]\n",
      "  [0.46610668]\n",
      "  [0.47386861]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0978490337729454\n",
      "Predicción post entrenamiento : [[0.4833801]]\n",
      "PERDIDAAAA despues: 0.09664991497993469\n",
      "loss en el callback: 0.08135784417390823, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.43172434]\n",
      " [0.43851435]\n",
      " [0.44539565]\n",
      " [0.45226273]\n",
      " [0.459234  ]\n",
      " [0.46610668]\n",
      " [0.47386861]\n",
      " [0.4814575 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.4888062]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.43172434]\n",
      "  [0.43851435]\n",
      "  [0.44539565]\n",
      "  [0.45226273]\n",
      "  [0.459234  ]\n",
      "  [0.46610668]\n",
      "  [0.47386861]\n",
      "  [0.4814575 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08702412992715836\n",
      "Predicción post entrenamiento : [[0.49081713]]\n",
      "PERDIDAAAA despues: 0.08584172278642654\n",
      "loss en el callback: 0.16488637030124664, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.43851435]\n",
      " [0.44539565]\n",
      " [0.45226273]\n",
      " [0.459234  ]\n",
      " [0.46610668]\n",
      " [0.47386861]\n",
      " [0.4814575 ]\n",
      " [0.48880619]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.49633566]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.43851435]\n",
      "  [0.44539565]\n",
      "  [0.45226273]\n",
      "  [0.459234  ]\n",
      "  [0.46610668]\n",
      "  [0.47386861]\n",
      "  [0.4814575 ]\n",
      "  [0.48880619]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07375774532556534\n",
      "Predicción post entrenamiento : [[0.49807385]]\n",
      "PERDIDAAAA despues: 0.0728166326880455\n",
      "loss en el callback: 0.07127382606267929, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.44539565]\n",
      " [0.45226273]\n",
      " [0.459234  ]\n",
      " [0.46610668]\n",
      " [0.47386861]\n",
      " [0.4814575 ]\n",
      " [0.48880619]\n",
      " [0.49633566]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5036936]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.44539565]\n",
      "  [0.45226273]\n",
      "  [0.459234  ]\n",
      "  [0.46610668]\n",
      "  [0.47386861]\n",
      "  [0.4814575 ]\n",
      "  [0.48880619]\n",
      "  [0.49633566]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07889697700738907\n",
      "Predicción post entrenamiento : [[0.5051324]]\n",
      "PERDIDAAAA despues: 0.07809077203273773\n",
      "loss en el callback: 0.039576996117830276, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.45226273]\n",
      " [0.459234  ]\n",
      " [0.46610668]\n",
      " [0.47386861]\n",
      " [0.4814575 ]\n",
      " [0.48880619]\n",
      " [0.49633566]\n",
      " [0.50369358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.51085544]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.45226273]\n",
      "  [0.459234  ]\n",
      "  [0.46610668]\n",
      "  [0.47386861]\n",
      "  [0.4814575 ]\n",
      "  [0.48880619]\n",
      "  [0.49633566]\n",
      "  [0.50369358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13533107936382294\n",
      "Predicción post entrenamiento : [[0.5129796]]\n",
      "PERDIDAAAA despues: 0.13377273082733154\n",
      "loss en el callback: 0.12443853914737701, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.459234  ]\n",
      " [0.46610668]\n",
      " [0.47386861]\n",
      " [0.4814575 ]\n",
      " [0.48880619]\n",
      " [0.49633566]\n",
      " [0.50369358]\n",
      " [0.51085544]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5188361]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.459234  ]\n",
      "  [0.46610668]\n",
      "  [0.47386861]\n",
      "  [0.4814575 ]\n",
      "  [0.48880619]\n",
      "  [0.49633566]\n",
      "  [0.50369358]\n",
      "  [0.51085544]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12730161845684052\n",
      "Predicción post entrenamiento : [[0.5210629]]\n",
      "PERDIDAAAA despues: 0.12571753561496735\n",
      "loss en el callback: 0.1565970778465271, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.46610668]\n",
      " [0.47386861]\n",
      " [0.4814575 ]\n",
      " [0.48880619]\n",
      " [0.49633566]\n",
      " [0.50369358]\n",
      " [0.51085544]\n",
      " [0.51883608]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5270511]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.46610668]\n",
      "  [0.47386861]\n",
      "  [0.4814575 ]\n",
      "  [0.48880619]\n",
      "  [0.49633566]\n",
      "  [0.50369358]\n",
      "  [0.51085544]\n",
      "  [0.51883608]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10358400642871857\n",
      "Predicción post entrenamiento : [[0.52871567]]\n",
      "PERDIDAAAA despues: 0.102515310049057\n",
      "loss en el callback: 0.055702388286590576, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.47386861]\n",
      " [0.4814575 ]\n",
      " [0.48880619]\n",
      " [0.49633566]\n",
      " [0.50369358]\n",
      " [0.51085544]\n",
      " [0.51883608]\n",
      " [0.52705109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5348864]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.47386861]\n",
      "  [0.4814575 ]\n",
      "  [0.48880619]\n",
      "  [0.49633566]\n",
      "  [0.50369358]\n",
      "  [0.51085544]\n",
      "  [0.51883608]\n",
      "  [0.52705109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08031617105007172\n",
      "Predicción post entrenamiento : [[0.53656554]]\n",
      "PERDIDAAAA despues: 0.0793672576546669\n",
      "loss en el callback: 0.06901609152555466, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.4814575 ]\n",
      " [0.48880619]\n",
      " [0.49633566]\n",
      " [0.50369358]\n",
      " [0.51085544]\n",
      " [0.51883608]\n",
      " [0.52705109]\n",
      " [0.53488642]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5427095]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.4814575 ]\n",
      "  [0.48880619]\n",
      "  [0.49633566]\n",
      "  [0.50369358]\n",
      "  [0.51085544]\n",
      "  [0.51883608]\n",
      "  [0.52705109]\n",
      "  [0.53488642]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08071382343769073\n",
      "Predicción post entrenamiento : [[0.54466426]]\n",
      "PERDIDAAAA despues: 0.07960695773363113\n",
      "loss en el callback: 0.1283126324415207, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.48880619]\n",
      " [0.49633566]\n",
      " [0.50369358]\n",
      " [0.51085544]\n",
      " [0.51883608]\n",
      " [0.52705109]\n",
      " [0.53488642]\n",
      " [0.54270953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5508307]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.48880619]\n",
      "  [0.49633566]\n",
      "  [0.50369358]\n",
      "  [0.51085544]\n",
      "  [0.51883608]\n",
      "  [0.52705109]\n",
      "  [0.53488642]\n",
      "  [0.54270953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055001400411129\n",
      "Predicción post entrenamiento : [[0.55215716]]\n",
      "PERDIDAAAA despues: 0.05438099429011345\n",
      "loss en el callback: 0.04376380145549774, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.49633566]\n",
      " [0.50369358]\n",
      " [0.51085544]\n",
      " [0.51883608]\n",
      " [0.52705109]\n",
      " [0.53488642]\n",
      " [0.54270953]\n",
      " [0.55083072]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5584226]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.49633566]\n",
      "  [0.50369358]\n",
      "  [0.51085544]\n",
      "  [0.51883608]\n",
      "  [0.52705109]\n",
      "  [0.53488642]\n",
      "  [0.54270953]\n",
      "  [0.55083072]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0532715730369091\n",
      "Predicción post entrenamiento : [[0.5596405]]\n",
      "PERDIDAAAA despues: 0.05271085724234581\n",
      "loss en el callback: 0.036141641438007355, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.50369358]\n",
      " [0.51085544]\n",
      " [0.51883608]\n",
      " [0.52705109]\n",
      " [0.53488642]\n",
      " [0.54270953]\n",
      " [0.55083072]\n",
      " [0.55842263]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.56597924]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.50369358]\n",
      "  [0.51085544]\n",
      "  [0.51883608]\n",
      "  [0.52705109]\n",
      "  [0.53488642]\n",
      "  [0.54270953]\n",
      "  [0.55083072]\n",
      "  [0.55842263]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07192777842283249\n",
      "Predicción post entrenamiento : [[0.56767964]]\n",
      "PERDIDAAAA despues: 0.07101859152317047\n",
      "loss en el callback: 0.0848165899515152, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.51085544]\n",
      " [0.51883608]\n",
      " [0.52705109]\n",
      " [0.53488642]\n",
      " [0.54270953]\n",
      " [0.55083072]\n",
      " [0.55842263]\n",
      " [0.56597924]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.574156]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.51085544]\n",
      "  [0.51883608]\n",
      "  [0.52705109]\n",
      "  [0.53488642]\n",
      "  [0.54270953]\n",
      "  [0.55083072]\n",
      "  [0.55842263]\n",
      "  [0.56597924]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05679633468389511\n",
      "Predicción post entrenamiento : [[0.5755693]]\n",
      "PERDIDAAAA despues: 0.05612470209598541\n",
      "loss en el callback: 0.04996022209525108, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.51883608]\n",
      " [0.52705109]\n",
      " [0.53488642]\n",
      " [0.54270953]\n",
      " [0.55083072]\n",
      " [0.55842263]\n",
      " [0.56597924]\n",
      " [0.57415599]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.58225864]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.51883608]\n",
      "  [0.52705109]\n",
      "  [0.53488642]\n",
      "  [0.54270953]\n",
      "  [0.55083072]\n",
      "  [0.55842263]\n",
      "  [0.56597924]\n",
      "  [0.57415599]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047952767461538315\n",
      "Predicción post entrenamiento : [[0.5839687]]\n",
      "PERDIDAAAA despues: 0.04720675200223923\n",
      "loss en el callback: 0.1320377141237259, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.52705109]\n",
      " [0.53488642]\n",
      " [0.54270953]\n",
      " [0.55083072]\n",
      " [0.55842263]\n",
      " [0.56597924]\n",
      " [0.57415599]\n",
      " [0.58225864]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.590672]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.52705109]\n",
      "  [0.53488642]\n",
      "  [0.54270953]\n",
      "  [0.55083072]\n",
      "  [0.55842263]\n",
      "  [0.56597924]\n",
      "  [0.57415599]\n",
      "  [0.58225864]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04515839368104935\n",
      "Predicción post entrenamiento : [[0.591983]]\n",
      "PERDIDAAAA despues: 0.04460292309522629\n",
      "loss en el callback: 0.05015086382627487, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.53488642]\n",
      " [0.54270953]\n",
      " [0.55083072]\n",
      " [0.55842263]\n",
      " [0.56597924]\n",
      " [0.57415599]\n",
      " [0.58225864]\n",
      " [0.59067202]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.59863204]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.53488642]\n",
      "  [0.54270953]\n",
      "  [0.55083072]\n",
      "  [0.55842263]\n",
      "  [0.56597924]\n",
      "  [0.57415599]\n",
      "  [0.58225864]\n",
      "  [0.59067202]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03796996921300888\n",
      "Predicción post entrenamiento : [[0.59970474]]\n",
      "PERDIDAAAA despues: 0.03755306825041771\n",
      "loss en el callback: 0.03016039729118347, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.54270953]\n",
      " [0.55083072]\n",
      " [0.55842263]\n",
      " [0.56597924]\n",
      " [0.57415599]\n",
      " [0.58225864]\n",
      " [0.59067202]\n",
      " [0.59863204]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6063973]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.54270953]\n",
      "  [0.55083072]\n",
      "  [0.55842263]\n",
      "  [0.56597924]\n",
      "  [0.57415599]\n",
      "  [0.58225864]\n",
      "  [0.59067202]\n",
      "  [0.59863204]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023646192625164986\n",
      "Predicción post entrenamiento : [[0.6078663]]\n",
      "PERDIDAAAA despues: 0.023196561262011528\n",
      "loss en el callback: 0.11506091803312302, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.55083072]\n",
      " [0.55842263]\n",
      " [0.56597924]\n",
      " [0.57415599]\n",
      " [0.58225864]\n",
      " [0.59067202]\n",
      " [0.59863204]\n",
      " [0.60639727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6146153]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.55083072]\n",
      "  [0.55842263]\n",
      "  [0.56597924]\n",
      "  [0.57415599]\n",
      "  [0.58225864]\n",
      "  [0.59067202]\n",
      "  [0.59863204]\n",
      "  [0.60639727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014582637697458267\n",
      "Predicción post entrenamiento : [[0.6152074]]\n",
      "PERDIDAAAA despues: 0.014439997263252735\n",
      "loss en el callback: 0.009624055586755276, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.55842263]\n",
      " [0.56597924]\n",
      " [0.57415599]\n",
      " [0.58225864]\n",
      " [0.59067202]\n",
      " [0.59863204]\n",
      " [0.60639727]\n",
      " [0.61461532]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.62193596]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.55842263]\n",
      "  [0.56597924]\n",
      "  [0.57415599]\n",
      "  [0.58225864]\n",
      "  [0.59067202]\n",
      "  [0.59863204]\n",
      "  [0.60639727]\n",
      "  [0.61461532]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007788742892444134\n",
      "Predicción post entrenamiento : [[0.62279546]]\n",
      "PERDIDAAAA despues: 0.0076377736404538155\n",
      "loss en el callback: 0.026107585057616234, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.56597924]\n",
      " [0.57415599]\n",
      " [0.58225864]\n",
      " [0.59067202]\n",
      " [0.59863204]\n",
      " [0.60639727]\n",
      " [0.61461532]\n",
      " [0.62193596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6296505]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.56597924]\n",
      "  [0.57415599]\n",
      "  [0.58225864]\n",
      "  [0.59067202]\n",
      "  [0.59863204]\n",
      "  [0.60639727]\n",
      "  [0.61461532]\n",
      "  [0.62193596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006802392192184925\n",
      "Predicción post entrenamiento : [[0.63035023]]\n",
      "PERDIDAAAA despues: 0.006687454413622618\n",
      "loss en el callback: 0.01517364289611578, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.57415599]\n",
      " [0.58225864]\n",
      " [0.59067202]\n",
      " [0.59863204]\n",
      " [0.60639727]\n",
      " [0.61461532]\n",
      " [0.62193596]\n",
      " [0.62965047]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.63735336]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.57415599]\n",
      "  [0.58225864]\n",
      "  [0.59067202]\n",
      "  [0.59863204]\n",
      "  [0.60639727]\n",
      "  [0.61461532]\n",
      "  [0.62193596]\n",
      "  [0.62965047]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010461702942848206\n",
      "Predicción post entrenamiento : [[0.63699985]]\n",
      "PERDIDAAAA despues: 0.010534144006669521\n",
      "loss en el callback: 0.002481813309714198, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.58225864]\n",
      " [0.59067202]\n",
      " [0.59863204]\n",
      " [0.60639727]\n",
      " [0.61461532]\n",
      " [0.62193596]\n",
      " [0.62965047]\n",
      " [0.63735336]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6439778]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.58225864]\n",
      "  [0.59067202]\n",
      "  [0.59863204]\n",
      "  [0.60639727]\n",
      "  [0.61461532]\n",
      "  [0.62193596]\n",
      "  [0.62965047]\n",
      "  [0.63735336]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008495484478771687\n",
      "Predicción post entrenamiento : [[0.64447606]]\n",
      "PERDIDAAAA despues: 0.008403887040913105\n",
      "loss en el callback: 0.006968372967094183, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.59067202]\n",
      " [0.59863204]\n",
      " [0.60639727]\n",
      " [0.61461532]\n",
      " [0.62193596]\n",
      " [0.62965047]\n",
      " [0.63735336]\n",
      " [0.64397782]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.651426]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.59067202]\n",
      "  [0.59863204]\n",
      "  [0.60639727]\n",
      "  [0.61461532]\n",
      "  [0.62193596]\n",
      "  [0.62965047]\n",
      "  [0.63735336]\n",
      "  [0.64397782]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002606511116027832\n",
      "Predicción post entrenamiento : [[0.65180117]]\n",
      "PERDIDAAAA despues: 0.000248678436037153\n",
      "loss en el callback: 0.0047841751947999, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.59863204]\n",
      " [0.60639727]\n",
      " [0.61461532]\n",
      " [0.62193596]\n",
      " [0.62965047]\n",
      " [0.63735336]\n",
      " [0.64397782]\n",
      " [0.65142602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6586023]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.59863204]\n",
      "  [0.60639727]\n",
      "  [0.61461532]\n",
      "  [0.62193596]\n",
      "  [0.62965047]\n",
      "  [0.63735336]\n",
      "  [0.64397782]\n",
      "  [0.65142602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012753441114909947\n",
      "Predicción post entrenamiento : [[0.6584727]]\n",
      "PERDIDAAAA despues: 0.00013047792890574783\n",
      "loss en el callback: 0.0004535968182608485, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.60639727]\n",
      " [0.61461532]\n",
      " [0.62193596]\n",
      " [0.62965047]\n",
      " [0.63735336]\n",
      " [0.64397782]\n",
      " [0.65142602]\n",
      " [0.6586023 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.66520673]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.60639727]\n",
      "  [0.61461532]\n",
      "  [0.62193596]\n",
      "  [0.62965047]\n",
      "  [0.63735336]\n",
      "  [0.64397782]\n",
      "  [0.65142602]\n",
      "  [0.6586023 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009873732924461365\n",
      "Predicción post entrenamiento : [[0.6650657]]\n",
      "PERDIDAAAA despues: 0.0009962557815015316\n",
      "loss en el callback: 0.0005569423083215952, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.61461532]\n",
      " [0.62193596]\n",
      " [0.62965047]\n",
      " [0.63735336]\n",
      " [0.64397782]\n",
      " [0.65142602]\n",
      " [0.6586023 ]\n",
      " [0.66520673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6717529]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.61461532]\n",
      "  [0.62193596]\n",
      "  [0.62965047]\n",
      "  [0.63735336]\n",
      "  [0.64397782]\n",
      "  [0.65142602]\n",
      "  [0.6586023 ]\n",
      "  [0.66520673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002498170651961118\n",
      "Predicción post entrenamiento : [[0.671528]]\n",
      "PERDIDAAAA despues: 0.000242756781517528\n",
      "loss en el callback: 0.001517290249466896, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.62193596]\n",
      " [0.62965047]\n",
      " [0.63735336]\n",
      " [0.64397782]\n",
      " [0.65142602]\n",
      " [0.6586023 ]\n",
      " [0.66520673]\n",
      " [0.67175293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.6780012]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.62193596]\n",
      "  [0.62965047]\n",
      "  [0.63735336]\n",
      "  [0.64397782]\n",
      "  [0.65142602]\n",
      "  [0.6586023 ]\n",
      "  [0.66520673]\n",
      "  [0.67175293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.487296673185483e-07\n",
      "Predicción post entrenamiento : [[0.6779048]]\n",
      "PERDIDAAAA despues: 8.133837354762363e-07\n",
      "loss en el callback: 0.00027048838092014194, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.62965047]\n",
      " [0.63735336]\n",
      " [0.64397782]\n",
      " [0.65142602]\n",
      " [0.6586023 ]\n",
      " [0.66520673]\n",
      " [0.67175293]\n",
      " [0.67800122]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.68436414]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.62965047]\n",
      "  [0.63735336]\n",
      "  [0.64397782]\n",
      "  [0.65142602]\n",
      "  [0.6586023 ]\n",
      "  [0.66520673]\n",
      "  [0.67175293]\n",
      "  [0.67800122]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.838642002549022e-05\n",
      "Predicción post entrenamiento : [[0.6843354]]\n",
      "PERDIDAAAA despues: 6.791207852074876e-05\n",
      "loss en el callback: 2.3471362510463223e-05, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.63735336]\n",
      " [0.64397782]\n",
      " [0.65142602]\n",
      " [0.6586023 ]\n",
      " [0.66520673]\n",
      " [0.67175293]\n",
      " [0.67800122]\n",
      " [0.68436414]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.6906336]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.63735336]\n",
      "  [0.64397782]\n",
      "  [0.65142602]\n",
      "  [0.6586023 ]\n",
      "  [0.66520673]\n",
      "  [0.67175293]\n",
      "  [0.67800122]\n",
      "  [0.68436414]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015154334250837564\n",
      "Predicción post entrenamiento : [[0.6911837]]\n",
      "PERDIDAAAA despues: 0.0014729074900969863\n",
      "loss en el callback: 0.011167478747665882, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.64397782]\n",
      " [0.65142602]\n",
      " [0.6586023 ]\n",
      " [0.66520673]\n",
      " [0.67175293]\n",
      " [0.67800122]\n",
      " [0.68436414]\n",
      " [0.69063359]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.6972714]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.64397782]\n",
      "  [0.65142602]\n",
      "  [0.6586023 ]\n",
      "  [0.66520673]\n",
      "  [0.67175293]\n",
      "  [0.67800122]\n",
      "  [0.68436414]\n",
      "  [0.69063359]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.6057336324593052e-05\n",
      "Predicción post entrenamiento : [[0.6974409]]\n",
      "PERDIDAAAA despues: 1.4727519555890467e-05\n",
      "loss en el callback: 0.0010094838216900826, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.65142602]\n",
      " [0.6586023 ]\n",
      " [0.66520673]\n",
      " [0.67175293]\n",
      " [0.67800122]\n",
      " [0.68436414]\n",
      " [0.69063359]\n",
      " [0.69727141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.70357686]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.65142602]\n",
      "  [0.6586023 ]\n",
      "  [0.66520673]\n",
      "  [0.67175293]\n",
      "  [0.67800122]\n",
      "  [0.68436414]\n",
      "  [0.69063359]\n",
      "  [0.69727141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00409025838598609\n",
      "Predicción post entrenamiento : [[0.70362073]]\n",
      "PERDIDAAAA despues: 0.004084649030119181\n",
      "loss en el callback: 5.393619721871801e-05, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.6586023 ]\n",
      " [0.66520673]\n",
      " [0.67175293]\n",
      " [0.67800122]\n",
      " [0.68436414]\n",
      " [0.69063359]\n",
      " [0.69727141]\n",
      " [0.70357686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.70954806]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.6586023 ]\n",
      "  [0.66520673]\n",
      "  [0.67175293]\n",
      "  [0.67800122]\n",
      "  [0.68436414]\n",
      "  [0.69063359]\n",
      "  [0.69727141]\n",
      "  [0.70357686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020780498161911964\n",
      "Predicción post entrenamiento : [[0.7093988]]\n",
      "PERDIDAAAA despues: 0.0020916794892400503\n",
      "loss en el callback: 0.0005940312403254211, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.66520673]\n",
      " [0.67175293]\n",
      " [0.67800122]\n",
      " [0.68436414]\n",
      " [0.69063359]\n",
      " [0.69727141]\n",
      " [0.70357686]\n",
      " [0.70954806]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7151462]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.66520673]\n",
      "  [0.67175293]\n",
      "  [0.67800122]\n",
      "  [0.68436414]\n",
      "  [0.69063359]\n",
      "  [0.69727141]\n",
      "  [0.70357686]\n",
      "  [0.70954806]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008948380127549171\n",
      "Predicción post entrenamiento : [[0.71508944]]\n",
      "PERDIDAAAA despues: 0.0008982360595837235\n",
      "loss en el callback: 9.336983930552378e-05, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.67175293]\n",
      " [0.67800122]\n",
      " [0.68436414]\n",
      " [0.69063359]\n",
      " [0.69727141]\n",
      " [0.70357686]\n",
      " [0.70954806]\n",
      " [0.71514618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.720783]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.67175293]\n",
      "  [0.67800122]\n",
      "  [0.68436414]\n",
      "  [0.69063359]\n",
      "  [0.69727141]\n",
      "  [0.70357686]\n",
      "  [0.70954806]\n",
      "  [0.71514618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009766295552253723\n",
      "Predicción post entrenamiento : [[0.7212132]]\n",
      "PERDIDAAAA despues: 0.0009499245788902044\n",
      "loss en el callback: 0.006550329737365246, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.67800122]\n",
      " [0.68436414]\n",
      " [0.69063359]\n",
      " [0.69727141]\n",
      " [0.70357686]\n",
      " [0.70954806]\n",
      " [0.71514618]\n",
      " [0.720783  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7268472]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.67800122]\n",
      "  [0.68436414]\n",
      "  [0.69063359]\n",
      "  [0.69727141]\n",
      "  [0.70357686]\n",
      "  [0.70954806]\n",
      "  [0.71514618]\n",
      "  [0.720783  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002905246219597757\n",
      "Predicción post entrenamiento : [[0.72702795]]\n",
      "PERDIDAAAA despues: 0.00029672004166059196\n",
      "loss en el callback: 0.0012005335884168744, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.68436414]\n",
      " [0.69063359]\n",
      " [0.69727141]\n",
      " [0.70357686]\n",
      " [0.70954806]\n",
      " [0.71514618]\n",
      " [0.720783  ]\n",
      " [0.72684717]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.73266405]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.68436414]\n",
      "  [0.69063359]\n",
      "  [0.69727141]\n",
      "  [0.70357686]\n",
      "  [0.70954806]\n",
      "  [0.71514618]\n",
      "  [0.720783  ]\n",
      "  [0.72684717]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001783711020834744\n",
      "Predicción post entrenamiento : [[0.7324632]]\n",
      "PERDIDAAAA despues: 0.0017667844658717513\n",
      "loss en el callback: 0.001337348367087543, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.69063359]\n",
      " [0.69727141]\n",
      " [0.70357686]\n",
      " [0.70954806]\n",
      " [0.71514618]\n",
      " [0.720783  ]\n",
      " [0.72684717]\n",
      " [0.73266405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.73804826]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.69063359]\n",
      "  [0.69727141]\n",
      "  [0.70357686]\n",
      "  [0.70954806]\n",
      "  [0.71514618]\n",
      "  [0.720783  ]\n",
      "  [0.72684717]\n",
      "  [0.73266405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002660328464116901\n",
      "Predicción post entrenamiento : [[0.7384782]]\n",
      "PERDIDAAAA despues: 0.00025219295639544725\n",
      "loss en el callback: 0.007512553595006466, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.69727141]\n",
      " [0.70357686]\n",
      " [0.70954806]\n",
      " [0.71514618]\n",
      " [0.720783  ]\n",
      " [0.72684717]\n",
      " [0.73266405]\n",
      " [0.73804826]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.74401367]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.69727141]\n",
      "  [0.70357686]\n",
      "  [0.70954806]\n",
      "  [0.71514618]\n",
      "  [0.720783  ]\n",
      "  [0.72684717]\n",
      "  [0.73266405]\n",
      "  [0.73804826]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004758058930747211\n",
      "Predicción post entrenamiento : [[0.7442237]]\n",
      "PERDIDAAAA despues: 0.0004850135010201484\n",
      "loss en el callback: 0.0016288890037685633, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.70357686]\n",
      " [0.70954806]\n",
      " [0.71514618]\n",
      " [0.720783  ]\n",
      " [0.72684717]\n",
      " [0.73266405]\n",
      " [0.73804826]\n",
      " [0.74401367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.74957293]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.70357686]\n",
      "  [0.70954806]\n",
      "  [0.71514618]\n",
      "  [0.720783  ]\n",
      "  [0.72684717]\n",
      "  [0.73266405]\n",
      "  [0.73804826]\n",
      "  [0.74401367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009788217954337597\n",
      "Predicción post entrenamiento : [[0.7496588]]\n",
      "PERDIDAAAA despues: 0.00977123063057661\n",
      "loss en el callback: 0.00021820487745571882, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.70954806]\n",
      " [0.71514618]\n",
      " [0.720783  ]\n",
      " [0.72684717]\n",
      " [0.73266405]\n",
      " [0.73804826]\n",
      " [0.74401367]\n",
      " [0.74957293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.75487983]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.70954806]\n",
      "  [0.71514618]\n",
      "  [0.720783  ]\n",
      "  [0.72684717]\n",
      "  [0.73266405]\n",
      "  [0.73804826]\n",
      "  [0.74401367]\n",
      "  [0.74957293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02267528511583805\n",
      "Predicción post entrenamiento : [[0.75618684]]\n",
      "PERDIDAAAA despues: 0.022283365949988365\n",
      "loss en el callback: 0.0858093872666359, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.71514618]\n",
      " [0.720783  ]\n",
      " [0.72684717]\n",
      " [0.73266405]\n",
      " [0.73804826]\n",
      " [0.74401367]\n",
      " [0.74957293]\n",
      " [0.75487983]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7613545]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.71514618]\n",
      "  [0.720783  ]\n",
      "  [0.72684717]\n",
      "  [0.73266405]\n",
      "  [0.73804826]\n",
      "  [0.74401367]\n",
      "  [0.74957293]\n",
      "  [0.75487983]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01460755243897438\n",
      "Predicción post entrenamiento : [[0.76242703]]\n",
      "PERDIDAAAA despues: 0.01434944849461317\n",
      "loss en el callback: 0.051702819764614105, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.720783  ]\n",
      " [0.72684717]\n",
      " [0.73266405]\n",
      " [0.73804826]\n",
      " [0.74401367]\n",
      " [0.74957293]\n",
      " [0.75487983]\n",
      " [0.76135451]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.7676422]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.720783  ]\n",
      "  [0.72684717]\n",
      "  [0.73266405]\n",
      "  [0.73804826]\n",
      "  [0.74401367]\n",
      "  [0.74957293]\n",
      "  [0.75487983]\n",
      "  [0.76135451]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019640754908323288\n",
      "Predicción post entrenamiento : [[0.7679892]]\n",
      "PERDIDAAAA despues: 0.019543610513210297\n",
      "loss en el callback: 0.0036648197565227747, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.72684717]\n",
      " [0.73266405]\n",
      " [0.73804826]\n",
      " [0.74401367]\n",
      " [0.74957293]\n",
      " [0.75487983]\n",
      " [0.76135451]\n",
      " [0.7676422 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.7732484]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.72684717]\n",
      "  [0.73266405]\n",
      "  [0.73804826]\n",
      "  [0.74401367]\n",
      "  [0.74957293]\n",
      "  [0.75487983]\n",
      "  [0.76135451]\n",
      "  [0.7676422 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013532509095966816\n",
      "Predicción post entrenamiento : [[0.7735522]]\n",
      "PERDIDAAAA despues: 0.013461918570101261\n",
      "loss en el callback: 0.002701829420402646, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.73266405]\n",
      " [0.73804826]\n",
      " [0.74401367]\n",
      " [0.74957293]\n",
      " [0.75487983]\n",
      " [0.76135451]\n",
      " [0.7676422 ]\n",
      " [0.77324837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.77873516]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.73266405]\n",
      "  [0.73804826]\n",
      "  [0.74401367]\n",
      "  [0.74957293]\n",
      "  [0.75487983]\n",
      "  [0.76135451]\n",
      "  [0.7676422 ]\n",
      "  [0.77324837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009238963015377522\n",
      "Predicción post entrenamiento : [[0.7791814]]\n",
      "PERDIDAAAA despues: 0.009153373539447784\n",
      "loss en el callback: 0.006411341484636068, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.73804826]\n",
      " [0.74401367]\n",
      " [0.74957293]\n",
      " [0.75487983]\n",
      " [0.76135451]\n",
      " [0.7676422 ]\n",
      " [0.77324837]\n",
      " [0.77873516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.78435504]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.73804826]\n",
      "  [0.74401367]\n",
      "  [0.74957293]\n",
      "  [0.75487983]\n",
      "  [0.76135451]\n",
      "  [0.7676422 ]\n",
      "  [0.77324837]\n",
      "  [0.77873516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016604099422693253\n",
      "Predicción post entrenamiento : [[0.78542644]]\n",
      "PERDIDAAAA despues: 0.01632913574576378\n",
      "loss en el callback: 0.05446559190750122, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.74401367]\n",
      " [0.74957293]\n",
      " [0.75487983]\n",
      " [0.76135451]\n",
      " [0.7676422 ]\n",
      " [0.77324837]\n",
      " [0.77873516]\n",
      " [0.78435504]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.79072493]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.74401367]\n",
      "  [0.74957293]\n",
      "  [0.75487983]\n",
      "  [0.76135451]\n",
      "  [0.7676422 ]\n",
      "  [0.77324837]\n",
      "  [0.77873516]\n",
      "  [0.78435504]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043796055018901825\n",
      "Predicción post entrenamiento : [[0.79205304]]\n",
      "PERDIDAAAA despues: 0.04324193671345711\n",
      "loss en el callback: 0.0713307112455368, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.74957293]\n",
      " [0.75487983]\n",
      " [0.76135451]\n",
      " [0.7676422 ]\n",
      " [0.77324837]\n",
      " [0.77873516]\n",
      " [0.78435504]\n",
      " [0.79072493]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.79732174]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.74957293]\n",
      "  [0.75487983]\n",
      "  [0.76135451]\n",
      "  [0.7676422 ]\n",
      "  [0.77324837]\n",
      "  [0.77873516]\n",
      "  [0.78435504]\n",
      "  [0.79072493]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03000943548977375\n",
      "Predicción post entrenamiento : [[0.79804116]]\n",
      "PERDIDAAAA despues: 0.0297606959939003\n",
      "loss en el callback: 0.01789933815598488, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.75487983]\n",
      " [0.76135451]\n",
      " [0.7676422 ]\n",
      " [0.77324837]\n",
      " [0.77873516]\n",
      " [0.78435504]\n",
      " [0.79072493]\n",
      " [0.79732174]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8034033]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.75487983]\n",
      "  [0.76135451]\n",
      "  [0.7676422 ]\n",
      "  [0.77324837]\n",
      "  [0.77873516]\n",
      "  [0.78435504]\n",
      "  [0.79072493]\n",
      "  [0.79732174]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007293066009879112\n",
      "Predicción post entrenamiento : [[0.8030812]]\n",
      "PERDIDAAAA despues: 0.00734818447381258\n",
      "loss en el callback: 0.0028902264311909676, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.76135451]\n",
      " [0.7676422 ]\n",
      " [0.77324837]\n",
      " [0.77873516]\n",
      " [0.78435504]\n",
      " [0.79072493]\n",
      " [0.79732174]\n",
      " [0.80340332]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8086317]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.76135451]\n",
      "  [0.7676422 ]\n",
      "  [0.77324837]\n",
      "  [0.77873516]\n",
      "  [0.78435504]\n",
      "  [0.79072493]\n",
      "  [0.79732174]\n",
      "  [0.80340332]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004805620759725571\n",
      "Predicción post entrenamiento : [[0.80918586]]\n",
      "PERDIDAAAA despues: 0.00472909864038229\n",
      "loss en el callback: 0.011661691591143608, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.7676422 ]\n",
      " [0.77324837]\n",
      " [0.77873516]\n",
      " [0.78435504]\n",
      " [0.79072493]\n",
      " [0.79732174]\n",
      " [0.80340332]\n",
      " [0.80863172]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8145984]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.7676422 ]\n",
      "  [0.77324837]\n",
      "  [0.77873516]\n",
      "  [0.78435504]\n",
      "  [0.79072493]\n",
      "  [0.79732174]\n",
      "  [0.80340332]\n",
      "  [0.80863172]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011763121001422405\n",
      "Predicción post entrenamiento : [[0.81426793]]\n",
      "PERDIDAAAA despues: 0.001199088292196393\n",
      "loss en el callback: 0.0032520631793886423, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.77324837]\n",
      " [0.77873516]\n",
      " [0.78435504]\n",
      " [0.79072493]\n",
      " [0.79732174]\n",
      " [0.80340332]\n",
      " [0.80863172]\n",
      " [0.81459838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8195756]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.77324837]\n",
      "  [0.77873516]\n",
      "  [0.78435504]\n",
      "  [0.79072493]\n",
      "  [0.79732174]\n",
      "  [0.80340332]\n",
      "  [0.80863172]\n",
      "  [0.81459838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021307759743649513\n",
      "Predicción post entrenamiento : [[0.8193712]]\n",
      "PERDIDAAAA despues: 0.00021908622875344008\n",
      "loss en el callback: 0.0013306301552802324, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.77873516]\n",
      " [0.78435504]\n",
      " [0.79072493]\n",
      " [0.79732174]\n",
      " [0.80340332]\n",
      " [0.80863172]\n",
      " [0.81459838]\n",
      " [0.81957561]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.82476485]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.77873516]\n",
      "  [0.78435504]\n",
      "  [0.79072493]\n",
      "  [0.79732174]\n",
      "  [0.80340332]\n",
      "  [0.80863172]\n",
      "  [0.81459838]\n",
      "  [0.81957561]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009199126507155597\n",
      "Predicción post entrenamiento : [[0.825382]]\n",
      "PERDIDAAAA despues: 0.0008828573627397418\n",
      "loss en el callback: 0.017646728083491325, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.78435504]\n",
      " [0.79072493]\n",
      " [0.79732174]\n",
      " [0.80340332]\n",
      " [0.80863172]\n",
      " [0.81459838]\n",
      " [0.81957561]\n",
      " [0.82476485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8309025]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.78435504]\n",
      "  [0.79072493]\n",
      "  [0.79732174]\n",
      "  [0.80340332]\n",
      "  [0.80863172]\n",
      "  [0.81459838]\n",
      "  [0.81957561]\n",
      "  [0.82476485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001966005191206932\n",
      "Predicción post entrenamiento : [[0.8317487]]\n",
      "PERDIDAAAA despues: 0.001891680178232491\n",
      "loss en el callback: 0.03614504262804985, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.79072493]\n",
      " [0.79732174]\n",
      " [0.80340332]\n",
      " [0.80863172]\n",
      " [0.81459838]\n",
      " [0.81957561]\n",
      " [0.82476485]\n",
      " [0.83090252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8373576]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.79072493]\n",
      "  [0.79732174]\n",
      "  [0.80340332]\n",
      "  [0.80863172]\n",
      "  [0.81459838]\n",
      "  [0.81957561]\n",
      "  [0.82476485]\n",
      "  [0.83090252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000387089850846678\n",
      "Predicción post entrenamiento : [[0.83762634]]\n",
      "PERDIDAAAA despues: 0.0003765866858884692\n",
      "loss en el callback: 0.0028593421448022127, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.79732174]\n",
      " [0.80340332]\n",
      " [0.80863172]\n",
      " [0.81459838]\n",
      " [0.81957561]\n",
      " [0.82476485]\n",
      " [0.83090252]\n",
      " [0.83735758]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.84308827]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.79732174]\n",
      "  [0.80340332]\n",
      "  [0.80863172]\n",
      "  [0.81459838]\n",
      "  [0.81957561]\n",
      "  [0.82476485]\n",
      "  [0.83090252]\n",
      "  [0.83735758]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.857907697441988e-05\n",
      "Predicción post entrenamiento : [[0.84311026]]\n",
      "PERDIDAAAA despues: 4.827296652365476e-05\n",
      "loss en el callback: 1.853768844739534e-05, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.80340332]\n",
      " [0.80863172]\n",
      " [0.81459838]\n",
      " [0.81957561]\n",
      " [0.82476485]\n",
      " [0.83090252]\n",
      " [0.83735758]\n",
      " [0.84308827]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8483223]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.80340332]\n",
      "  [0.80863172]\n",
      "  [0.81459838]\n",
      "  [0.81957561]\n",
      "  [0.82476485]\n",
      "  [0.83090252]\n",
      "  [0.83735758]\n",
      "  [0.84308827]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.1648109143134207e-05\n",
      "Predicción post entrenamiento : [[0.8479793]]\n",
      "PERDIDAAAA despues: 2.7906919058295898e-05\n",
      "loss en el callback: 0.003883610712364316, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.80863172]\n",
      " [0.81459838]\n",
      " [0.81957561]\n",
      " [0.82476485]\n",
      " [0.83090252]\n",
      " [0.83735758]\n",
      " [0.84308827]\n",
      " [0.84832227]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.853061]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.80863172]\n",
      "  [0.81459838]\n",
      "  [0.81957561]\n",
      "  [0.82476485]\n",
      "  [0.83090252]\n",
      "  [0.83735758]\n",
      "  [0.84308827]\n",
      "  [0.84832227]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009074666886590421\n",
      "Predicción post entrenamiento : [[0.8521795]]\n",
      "PERDIDAAAA despues: 0.0008551351493224502\n",
      "loss en el callback: 0.02354176715016365, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.81459838]\n",
      " [0.81957561]\n",
      " [0.82476485]\n",
      " [0.83090252]\n",
      " [0.83735758]\n",
      " [0.84308827]\n",
      " [0.84832227]\n",
      " [0.85306102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.85737306]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.81459838]\n",
      "  [0.81957561]\n",
      "  [0.82476485]\n",
      "  [0.83090252]\n",
      "  [0.83735758]\n",
      "  [0.84308827]\n",
      "  [0.84832227]\n",
      "  [0.85306102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006866944022476673\n",
      "Predicción post entrenamiento : [[0.8563142]]\n",
      "PERDIDAAAA despues: 0.006692573428153992\n",
      "loss en el callback: 0.034736983478069305, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.81957561]\n",
      " [0.82476485]\n",
      " [0.83090252]\n",
      " [0.83735758]\n",
      " [0.84308827]\n",
      " [0.84832227]\n",
      " [0.85306102]\n",
      " [0.85737306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.86139995]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.81957561]\n",
      "  [0.82476485]\n",
      "  [0.83090252]\n",
      "  [0.83735758]\n",
      "  [0.84308827]\n",
      "  [0.84832227]\n",
      "  [0.85306102]\n",
      "  [0.85737306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005961045157164335\n",
      "Predicción post entrenamiento : [[0.8601909]]\n",
      "PERDIDAAAA despues: 0.00577581487596035\n",
      "loss en el callback: 0.04532472789287567, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.82476485]\n",
      " [0.83090252]\n",
      " [0.83735758]\n",
      " [0.84308827]\n",
      " [0.84832227]\n",
      " [0.85306102]\n",
      " [0.85737306]\n",
      " [0.86139995]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.86543375]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.82476485]\n",
      "  [0.83090252]\n",
      "  [0.83735758]\n",
      "  [0.84308827]\n",
      "  [0.84832227]\n",
      "  [0.85306102]\n",
      "  [0.85737306]\n",
      "  [0.86139995]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.236975317122415e-05\n",
      "Predicción post entrenamiento : [[0.86566323]]\n",
      "PERDIDAAAA despues: 3.503361585899256e-05\n",
      "loss en el callback: 0.0021433085203170776, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.83090252]\n",
      " [0.83735758]\n",
      " [0.84308827]\n",
      " [0.84832227]\n",
      " [0.85306102]\n",
      " [0.85737306]\n",
      " [0.86139995]\n",
      " [0.86543375]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8709835]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.83090252]\n",
      "  [0.83735758]\n",
      "  [0.84308827]\n",
      "  [0.84832227]\n",
      "  [0.85306102]\n",
      "  [0.85737306]\n",
      "  [0.86139995]\n",
      "  [0.86543375]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027766998391598463\n",
      "Predicción post entrenamiento : [[0.87146604]]\n",
      "PERDIDAAAA despues: 0.0002939850091934204\n",
      "loss en el callback: 0.011233069933950901, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.83735758]\n",
      " [0.84308827]\n",
      " [0.84832227]\n",
      " [0.85306102]\n",
      " [0.85737306]\n",
      " [0.86139995]\n",
      " [0.86543375]\n",
      " [0.87098348]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8765357]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.83735758]\n",
      "  [0.84308827]\n",
      "  [0.84832227]\n",
      "  [0.85306102]\n",
      "  [0.85737306]\n",
      "  [0.86139995]\n",
      "  [0.86543375]\n",
      "  [0.87098348]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015721857780590653\n",
      "Predicción post entrenamiento : [[0.8752871]]\n",
      "PERDIDAAAA despues: 0.0014747289242222905\n",
      "loss en el callback: 0.04581689089536667, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.84308827]\n",
      " [0.84832227]\n",
      " [0.85306102]\n",
      " [0.85737306]\n",
      " [0.86139995]\n",
      " [0.86543375]\n",
      " [0.87098348]\n",
      " [0.87653571]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8799304]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.84308827]\n",
      "  [0.84832227]\n",
      "  [0.85306102]\n",
      "  [0.85737306]\n",
      "  [0.86139995]\n",
      "  [0.86543375]\n",
      "  [0.87098348]\n",
      "  [0.87653571]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025019505992531776\n",
      "Predicción post entrenamiento : [[0.8800427]]\n",
      "PERDIDAAAA despues: 0.002513197250664234\n",
      "loss en el callback: 0.0006022002198733389, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.84832227]\n",
      " [0.85306102]\n",
      " [0.85737306]\n",
      " [0.86139995]\n",
      " [0.86543375]\n",
      " [0.87098348]\n",
      " [0.87653571]\n",
      " [0.87993038]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.884398]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.84832227]\n",
      "  [0.85306102]\n",
      "  [0.85737306]\n",
      "  [0.86139995]\n",
      "  [0.86543375]\n",
      "  [0.87098348]\n",
      "  [0.87653571]\n",
      "  [0.87993038]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.151041583914775e-06\n",
      "Predicción post entrenamiento : [[0.88481927]]\n",
      "PERDIDAAAA despues: 5.922979653405491e-06\n",
      "loss en el callback: 0.008128580637276173, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.85306102]\n",
      " [0.85737306]\n",
      " [0.86139995]\n",
      " [0.86543375]\n",
      " [0.87098348]\n",
      " [0.87653571]\n",
      " [0.87993038]\n",
      " [0.88439798]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8889872]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.85306102]\n",
      "  [0.85737306]\n",
      "  [0.86139995]\n",
      "  [0.86543375]\n",
      "  [0.87098348]\n",
      "  [0.87653571]\n",
      "  [0.87993038]\n",
      "  [0.88439798]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008551456267014146\n",
      "Predicción post entrenamiento : [[0.88870573]]\n",
      "PERDIDAAAA despues: 0.0008387638372369111\n",
      "loss en el callback: 0.0029532702174037695, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.85737306]\n",
      " [0.86139995]\n",
      " [0.86543375]\n",
      " [0.87098348]\n",
      " [0.87653571]\n",
      " [0.87993038]\n",
      " [0.88439798]\n",
      " [0.88898718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8928114]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.85737306]\n",
      "  [0.86139995]\n",
      "  [0.86543375]\n",
      "  [0.87098348]\n",
      "  [0.87653571]\n",
      "  [0.87993038]\n",
      "  [0.88439798]\n",
      "  [0.88898718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002831769408658147\n",
      "Predicción post entrenamiento : [[0.89258665]]\n",
      "PERDIDAAAA despues: 0.0028078979812562466\n",
      "loss en el callback: 0.0020210070069879293, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.86139995]\n",
      " [0.86543375]\n",
      " [0.87098348]\n",
      " [0.87653571]\n",
      " [0.87993038]\n",
      " [0.88439798]\n",
      " [0.88898718]\n",
      " [0.89281142]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.8967514]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.86139995]\n",
      "  [0.86543375]\n",
      "  [0.87098348]\n",
      "  [0.87653571]\n",
      "  [0.87993038]\n",
      "  [0.88439798]\n",
      "  [0.88898718]\n",
      "  [0.89281142]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01275695487856865\n",
      "Predicción post entrenamiento : [[0.8959225]]\n",
      "PERDIDAAAA despues: 0.012570394203066826\n",
      "loss en el callback: 0.02540598064661026, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.86543375]\n",
      " [0.87098348]\n",
      " [0.87653571]\n",
      " [0.87993038]\n",
      " [0.88439798]\n",
      " [0.88898718]\n",
      " [0.89281142]\n",
      " [0.8967514 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9002343]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.86543375]\n",
      "  [0.87098348]\n",
      "  [0.87653571]\n",
      "  [0.87993038]\n",
      "  [0.88439798]\n",
      "  [0.88898718]\n",
      "  [0.89281142]\n",
      "  [0.8967514 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006715276278555393\n",
      "Predicción post entrenamiento : [[0.89973927]]\n",
      "PERDIDAAAA despues: 0.006634391378611326\n",
      "loss en el callback: 0.010385002940893173, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.87098348]\n",
      " [0.87653571]\n",
      " [0.87993038]\n",
      " [0.88439798]\n",
      " [0.88898718]\n",
      " [0.89281142]\n",
      " [0.8967514 ]\n",
      " [0.90023428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.90419614]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.87098348]\n",
      "  [0.87653571]\n",
      "  [0.87993038]\n",
      "  [0.88439798]\n",
      "  [0.88898718]\n",
      "  [0.89281142]\n",
      "  [0.8967514 ]\n",
      "  [0.90023428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01277577131986618\n",
      "Predicción post entrenamiento : [[0.9040658]]\n",
      "PERDIDAAAA despues: 0.012746320106089115\n",
      "loss en el callback: 0.0007986777345649898, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.87653571]\n",
      " [0.87993038]\n",
      " [0.88439798]\n",
      " [0.88898718]\n",
      " [0.89281142]\n",
      " [0.8967514 ]\n",
      " [0.90023428]\n",
      " [0.90419614]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.90818703]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.87653571]\n",
      "  [0.87993038]\n",
      "  [0.88439798]\n",
      "  [0.88898718]\n",
      "  [0.89281142]\n",
      "  [0.8967514 ]\n",
      "  [0.90023428]\n",
      "  [0.90419614]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02179434522986412\n",
      "Predicción post entrenamiento : [[0.90687066]]\n",
      "PERDIDAAAA despues: 0.021407410502433777\n",
      "loss en el callback: 0.06552249938249588, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.87993038]\n",
      " [0.88439798]\n",
      " [0.88898718]\n",
      " [0.89281142]\n",
      " [0.8967514 ]\n",
      " [0.90023428]\n",
      " [0.90419614]\n",
      " [0.90818703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9105775]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.87993038]\n",
      "  [0.88439798]\n",
      "  [0.88898718]\n",
      "  [0.89281142]\n",
      "  [0.8967514 ]\n",
      "  [0.90023428]\n",
      "  [0.90419614]\n",
      "  [0.90818703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014166665263473988\n",
      "Predicción post entrenamiento : [[0.90949947]]\n",
      "PERDIDAAAA despues: 0.01391120906919241\n",
      "loss en el callback: 0.040635619312524796, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.88439798]\n",
      " [0.88898718]\n",
      " [0.89281142]\n",
      " [0.8967514 ]\n",
      " [0.90023428]\n",
      " [0.90419614]\n",
      " [0.90818703]\n",
      " [0.91057748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9133791]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.88439798]\n",
      "  [0.88898718]\n",
      "  [0.89281142]\n",
      "  [0.8967514 ]\n",
      "  [0.90023428]\n",
      "  [0.90419614]\n",
      "  [0.90818703]\n",
      "  [0.91057748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020933689549565315\n",
      "Predicción post entrenamiento : [[0.9132923]]\n",
      "PERDIDAAAA despues: 0.02090858295559883\n",
      "loss en el callback: 0.00042299902997910976, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.88898718]\n",
      " [0.89281142]\n",
      " [0.8967514 ]\n",
      " [0.90023428]\n",
      " [0.90419614]\n",
      " [0.90818703]\n",
      " [0.91057748]\n",
      " [0.91337907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9170104]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.88898718]\n",
      "  [0.89281142]\n",
      "  [0.8967514 ]\n",
      "  [0.90023428]\n",
      "  [0.90419614]\n",
      "  [0.90818703]\n",
      "  [0.91057748]\n",
      "  [0.91337907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02199767902493477\n",
      "Predicción post entrenamiento : [[0.91517925]]\n",
      "PERDIDAAAA despues: 0.021457847207784653\n",
      "loss en el callback: 0.1030220091342926, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.89281142]\n",
      " [0.8967514 ]\n",
      " [0.90023428]\n",
      " [0.90419614]\n",
      " [0.90818703]\n",
      " [0.91057748]\n",
      " [0.91337907]\n",
      " [0.91701043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.91864187]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.89281142]\n",
      "  [0.8967514 ]\n",
      "  [0.90023428]\n",
      "  [0.90419614]\n",
      "  [0.90818703]\n",
      "  [0.91057748]\n",
      "  [0.91337907]\n",
      "  [0.91701043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014334486797451973\n",
      "Predicción post entrenamiento : [[0.9185397]]\n",
      "PERDIDAAAA despues: 0.014310033991932869\n",
      "loss en el callback: 0.0005208555958233774, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.8967514 ]\n",
      " [0.90023428]\n",
      " [0.90419614]\n",
      " [0.90818703]\n",
      " [0.91057748]\n",
      " [0.91337907]\n",
      " [0.91701043]\n",
      " [0.91864187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9219152]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.8967514 ]\n",
      "  [0.90023428]\n",
      "  [0.90419614]\n",
      "  [0.90818703]\n",
      "  [0.91057748]\n",
      "  [0.91337907]\n",
      "  [0.91701043]\n",
      "  [0.91864187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017400585114955902\n",
      "Predicción post entrenamiento : [[0.9210798]]\n",
      "PERDIDAAAA despues: 0.017180897295475006\n",
      "loss en el callback: 0.02807203307747841, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.90023428]\n",
      " [0.90419614]\n",
      " [0.90818703]\n",
      " [0.91057748]\n",
      " [0.91337907]\n",
      " [0.91701043]\n",
      " [0.91864187]\n",
      " [0.92191517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9242867]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.90023428]\n",
      "  [0.90419614]\n",
      "  [0.90818703]\n",
      "  [0.91057748]\n",
      "  [0.91337907]\n",
      "  [0.91701043]\n",
      "  [0.91864187]\n",
      "  [0.92191517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026934148743748665\n",
      "Predicción post entrenamiento : [[0.92299646]]\n",
      "PERDIDAAAA despues: 0.026512306183576584\n",
      "loss en el callback: 0.06542748212814331, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.90419614]\n",
      " [0.90818703]\n",
      " [0.91057748]\n",
      " [0.91337907]\n",
      " [0.91701043]\n",
      " [0.91864187]\n",
      " [0.92191517]\n",
      " [0.92428672]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9261192]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.90419614]\n",
      "  [0.90818703]\n",
      "  [0.91057748]\n",
      "  [0.91337907]\n",
      "  [0.91701043]\n",
      "  [0.91864187]\n",
      "  [0.92191517]\n",
      "  [0.92428672]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05794897675514221\n",
      "Predicción post entrenamiento : [[0.92516804]]\n",
      "PERDIDAAAA despues: 0.057491935789585114\n",
      "loss en el callback: 0.04149332642555237, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.90818703]\n",
      " [0.91057748]\n",
      " [0.91337907]\n",
      " [0.91701043]\n",
      " [0.91864187]\n",
      " [0.92191517]\n",
      " [0.92428672]\n",
      " [0.92611921]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9280118]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.90818703]\n",
      "  [0.91057748]\n",
      "  [0.91337907]\n",
      "  [0.91701043]\n",
      "  [0.91864187]\n",
      "  [0.92191517]\n",
      "  [0.92428672]\n",
      "  [0.92611921]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10421276092529297\n",
      "Predicción post entrenamiento : [[0.9268507]]\n",
      "PERDIDAAAA despues: 0.10346445441246033\n",
      "loss en el callback: 0.06504670530557632, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.91057748]\n",
      " [0.91337907]\n",
      " [0.91701043]\n",
      " [0.91864187]\n",
      " [0.92191517]\n",
      " [0.92428672]\n",
      " [0.92611921]\n",
      " [0.92801178]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9293329]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.91057748]\n",
      "  [0.91337907]\n",
      "  [0.91701043]\n",
      "  [0.91864187]\n",
      "  [0.92191517]\n",
      "  [0.92428672]\n",
      "  [0.92611921]\n",
      "  [0.92801178]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06994666904211044\n",
      "Predicción post entrenamiento : [[0.92863786]]\n",
      "PERDIDAAAA despues: 0.06957951188087463\n",
      "loss en el callback: 0.027975864708423615, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.91337907]\n",
      " [0.91701043]\n",
      " [0.91864187]\n",
      " [0.92191517]\n",
      " [0.92428672]\n",
      " [0.92611921]\n",
      " [0.92801178]\n",
      " [0.92933291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9311741]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.91337907]\n",
      "  [0.91701043]\n",
      "  [0.91864187]\n",
      "  [0.92191517]\n",
      "  [0.92428672]\n",
      "  [0.92611921]\n",
      "  [0.92801178]\n",
      "  [0.92933291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049866873770952225\n",
      "Predicción post entrenamiento : [[0.9302737]]\n",
      "PERDIDAAAA despues: 0.04946555569767952\n",
      "loss en el callback: 0.03957192227244377, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.91701043]\n",
      " [0.91864187]\n",
      " [0.92191517]\n",
      " [0.92428672]\n",
      " [0.92611921]\n",
      " [0.92801178]\n",
      " [0.92933291]\n",
      " [0.9311741 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9327123]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.91701043]\n",
      "  [0.91864187]\n",
      "  [0.92191517]\n",
      "  [0.92428672]\n",
      "  [0.92611921]\n",
      "  [0.92801178]\n",
      "  [0.92933291]\n",
      "  [0.9311741 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0717456266283989\n",
      "Predicción post entrenamiento : [[0.93027294]]\n",
      "PERDIDAAAA despues: 0.07044477760791779\n",
      "loss en el callback: 0.20630794763565063, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.91864187]\n",
      " [0.92191517]\n",
      " [0.92428672]\n",
      " [0.92611921]\n",
      " [0.92801178]\n",
      " [0.92933291]\n",
      " [0.9311741 ]\n",
      " [0.93271232]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.93230605]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.91864187]\n",
      "  [0.92191517]\n",
      "  [0.92428672]\n",
      "  [0.92611921]\n",
      "  [0.92801178]\n",
      "  [0.92933291]\n",
      "  [0.9311741 ]\n",
      "  [0.93271232]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0488206185400486\n",
      "Predicción post entrenamiento : [[0.93196154]]\n",
      "PERDIDAAAA despues: 0.04866849258542061\n",
      "loss en el callback: 0.007412139326334, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.92191517]\n",
      " [0.92428672]\n",
      " [0.92611921]\n",
      " [0.92801178]\n",
      " [0.92933291]\n",
      " [0.9311741 ]\n",
      " [0.93271232]\n",
      " [0.93230605]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9341107]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.92191517]\n",
      "  [0.92428672]\n",
      "  [0.92611921]\n",
      "  [0.92801178]\n",
      "  [0.92933291]\n",
      "  [0.9311741 ]\n",
      "  [0.93271232]\n",
      "  [0.93230605]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06597388535737991\n",
      "Predicción post entrenamiento : [[0.9323343]]\n",
      "PERDIDAAAA despues: 0.06506448984146118\n",
      "loss en el callback: 0.13307185471057892, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.92428672]\n",
      " [0.92611921]\n",
      " [0.92801178]\n",
      " [0.92933291]\n",
      " [0.9311741 ]\n",
      " [0.93271232]\n",
      " [0.93230605]\n",
      " [0.9341107 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9340658]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.92428672]\n",
      "  [0.92611921]\n",
      "  [0.92801178]\n",
      "  [0.92933291]\n",
      "  [0.9311741 ]\n",
      "  [0.93271232]\n",
      "  [0.93230605]\n",
      "  [0.9341107 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029569584876298904\n",
      "Predicción post entrenamiento : [[0.93360204]]\n",
      "PERDIDAAAA despues: 0.02941029705107212\n",
      "loss en el callback: 0.012263638898730278, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.92611921]\n",
      " [0.92801178]\n",
      " [0.92933291]\n",
      " [0.9311741 ]\n",
      " [0.93271232]\n",
      " [0.93230605]\n",
      " [0.9341107 ]\n",
      " [0.93406582]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.93509215]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.92611921]\n",
      "  [0.92801178]\n",
      "  [0.92933291]\n",
      "  [0.9311741 ]\n",
      "  [0.93271232]\n",
      "  [0.93230605]\n",
      "  [0.9341107 ]\n",
      "  [0.93406582]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016394399106502533\n",
      "Predicción post entrenamiento : [[0.9342543]]\n",
      "PERDIDAAAA despues: 0.01618053950369358\n",
      "loss en el callback: 0.03314914554357529, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.92801178]\n",
      " [0.92933291]\n",
      " [0.9311741 ]\n",
      " [0.93271232]\n",
      " [0.93230605]\n",
      " [0.9341107 ]\n",
      " [0.93406582]\n",
      " [0.93509215]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.93559986]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.92801178]\n",
      "  [0.92933291]\n",
      "  [0.9311741 ]\n",
      "  [0.93271232]\n",
      "  [0.93230605]\n",
      "  [0.9341107 ]\n",
      "  [0.93406582]\n",
      "  [0.93509215]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01449903380125761\n",
      "Predicción post entrenamiento : [[0.93482596]]\n",
      "PERDIDAAAA despues: 0.014313257299363613\n",
      "loss en el callback: 0.028633704409003258, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.92933291]\n",
      " [0.9311741 ]\n",
      " [0.93271232]\n",
      " [0.93230605]\n",
      " [0.9341107 ]\n",
      " [0.93406582]\n",
      " [0.93509215]\n",
      " [0.93559986]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9359565]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.92933291]\n",
      "  [0.9311741 ]\n",
      "  [0.93271232]\n",
      "  [0.93230605]\n",
      "  [0.9341107 ]\n",
      "  [0.93406582]\n",
      "  [0.93509215]\n",
      "  [0.93559986]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008831938612274826\n",
      "Predicción post entrenamiento : [[0.9357673]]\n",
      "PERDIDAAAA despues: 0.0008719850447960198\n",
      "loss en el callback: 0.0018412459176033735, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.9311741 ]\n",
      " [0.93271232]\n",
      " [0.93230605]\n",
      " [0.9341107 ]\n",
      " [0.93406582]\n",
      " [0.93509215]\n",
      " [0.93559986]\n",
      " [0.93595648]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9367999]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.9311741 ]\n",
      "  [0.93271232]\n",
      "  [0.93230605]\n",
      "  [0.9341107 ]\n",
      "  [0.93406582]\n",
      "  [0.93509215]\n",
      "  [0.93559986]\n",
      "  [0.93595648]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005246687214821577\n",
      "Predicción post entrenamiento : [[0.93755466]]\n",
      "PERDIDAAAA despues: 0.0004906612448394299\n",
      "loss en el callback: 0.04141900688409805, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.93271232]\n",
      " [0.93230605]\n",
      " [0.9341107 ]\n",
      " [0.93406582]\n",
      " [0.93509215]\n",
      " [0.93559986]\n",
      " [0.93595648]\n",
      " [0.93679988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.938292]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.93271232]\n",
      "  [0.93230605]\n",
      "  [0.9341107 ]\n",
      "  [0.93406582]\n",
      "  [0.93509215]\n",
      "  [0.93559986]\n",
      "  [0.93595648]\n",
      "  [0.93679988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006792719359509647\n",
      "Predicción post entrenamiento : [[0.938368]]\n",
      "PERDIDAAAA despues: 0.0006753163761459291\n",
      "loss en el callback: 0.00029533557244576514, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.93230605]\n",
      " [0.9341107 ]\n",
      " [0.93406582]\n",
      " [0.93509215]\n",
      " [0.93559986]\n",
      " [0.93595648]\n",
      " [0.93679988]\n",
      " [0.93829203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9388545]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.93230605]\n",
      "  [0.9341107 ]\n",
      "  [0.93406582]\n",
      "  [0.93509215]\n",
      "  [0.93559986]\n",
      "  [0.93595648]\n",
      "  [0.93679988]\n",
      "  [0.93829203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025833442341536283\n",
      "Predicción post entrenamiento : [[0.9387514]]\n",
      "PERDIDAAAA despues: 0.0025728726759552956\n",
      "loss en el callback: 0.0005808361456729472, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.9341107 ]\n",
      " [0.93406582]\n",
      " [0.93509215]\n",
      " [0.93559986]\n",
      " [0.93595648]\n",
      " [0.93679988]\n",
      " [0.93829203]\n",
      " [0.93885452]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9395577]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.9341107 ]\n",
      "  [0.93406582]\n",
      "  [0.93509215]\n",
      "  [0.93559986]\n",
      "  [0.93595648]\n",
      "  [0.93679988]\n",
      "  [0.93829203]\n",
      "  [0.93885452]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00219777412712574\n",
      "Predicción post entrenamiento : [[0.9392705]]\n",
      "PERDIDAAAA despues: 0.0021709308493882418\n",
      "loss en el callback: 0.004081579390913248, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.93406582]\n",
      " [0.93509215]\n",
      " [0.93559986]\n",
      " [0.93595648]\n",
      " [0.93679988]\n",
      " [0.93829203]\n",
      " [0.93885452]\n",
      " [0.93955767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9397617]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.93406582]\n",
      "  [0.93509215]\n",
      "  [0.93559986]\n",
      "  [0.93595648]\n",
      "  [0.93679988]\n",
      "  [0.93829203]\n",
      "  [0.93885452]\n",
      "  [0.93955767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004162768833339214\n",
      "Predicción post entrenamiento : [[0.94029164]]\n",
      "PERDIDAAAA despues: 0.004231433384120464\n",
      "loss en el callback: 0.024487225338816643, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.93509215]\n",
      " [0.93559986]\n",
      " [0.93595648]\n",
      " [0.93679988]\n",
      " [0.93829203]\n",
      " [0.93885452]\n",
      " [0.93955767]\n",
      " [0.9397617 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.94099814]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.93509215]\n",
      "  [0.93559986]\n",
      "  [0.93595648]\n",
      "  [0.93679988]\n",
      "  [0.93829203]\n",
      "  [0.93885452]\n",
      "  [0.93955767]\n",
      "  [0.9397617 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008129752241075039\n",
      "Predicción post entrenamiento : [[0.94080895]]\n",
      "PERDIDAAAA despues: 0.008095672354102135\n",
      "loss en el callback: 0.002012436045333743, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.93559986]\n",
      " [0.93595648]\n",
      " [0.93679988]\n",
      " [0.93829203]\n",
      " [0.93885452]\n",
      " [0.93955767]\n",
      " [0.9397617 ]\n",
      " [0.94099814]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9414341]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.93559986]\n",
      "  [0.93595648]\n",
      "  [0.93679988]\n",
      "  [0.93829203]\n",
      "  [0.93885452]\n",
      "  [0.93955767]\n",
      "  [0.9397617 ]\n",
      "  [0.94099814]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008563335984945297\n",
      "Predicción post entrenamiento : [[0.94181854]]\n",
      "PERDIDAAAA despues: 0.008634637109935284\n",
      "loss en el callback: 0.01284120511263609, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.93595648]\n",
      " [0.93679988]\n",
      " [0.93829203]\n",
      " [0.93885452]\n",
      " [0.93955767]\n",
      " [0.9397617 ]\n",
      " [0.94099814]\n",
      " [0.94143409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.94251215]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.93595648]\n",
      "  [0.93679988]\n",
      "  [0.93829203]\n",
      "  [0.93885452]\n",
      "  [0.93955767]\n",
      "  [0.9397617 ]\n",
      "  [0.94099814]\n",
      "  [0.94143409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039622923941351473\n",
      "Predicción post entrenamiento : [[0.9418129]]\n",
      "PERDIDAAAA despues: 0.00042455733637325466\n",
      "loss en el callback: 0.019981633871793747, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.93679988]\n",
      " [0.93829203]\n",
      " [0.93885452]\n",
      " [0.93955767]\n",
      " [0.9397617 ]\n",
      " [0.94099814]\n",
      " [0.94143409]\n",
      " [0.94251215]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9426321]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.93679988]\n",
      "  [0.93829203]\n",
      "  [0.93885452]\n",
      "  [0.93955767]\n",
      "  [0.9397617 ]\n",
      "  [0.94099814]\n",
      "  [0.94143409]\n",
      "  [0.94251215]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000635536212939769\n",
      "Predicción post entrenamiento : [[0.94326943]]\n",
      "PERDIDAAAA despues: 0.0006038073333911598\n",
      "loss en el callback: 0.033493220806121826, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.93829203]\n",
      " [0.93885452]\n",
      " [0.93955767]\n",
      " [0.9397617 ]\n",
      " [0.94099814]\n",
      " [0.94143409]\n",
      " [0.94251215]\n",
      " [0.94263208]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9440744]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.93829203]\n",
      "  [0.93885452]\n",
      "  [0.93955767]\n",
      "  [0.9397617 ]\n",
      "  [0.94099814]\n",
      "  [0.94143409]\n",
      "  [0.94251215]\n",
      "  [0.94263208]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1247403563174885e-05\n",
      "Predicción post entrenamiento : [[0.94478476]]\n",
      "PERDIDAAAA despues: 1.6516771211172454e-05\n",
      "loss en el callback: 0.040325094014406204, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.93885452]\n",
      " [0.93955767]\n",
      " [0.9397617 ]\n",
      " [0.94099814]\n",
      " [0.94143409]\n",
      " [0.94251215]\n",
      " [0.94263208]\n",
      " [0.94407439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.94536763]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.93885452]\n",
      "  [0.93955767]\n",
      "  [0.9397617 ]\n",
      "  [0.94099814]\n",
      "  [0.94143409]\n",
      "  [0.94251215]\n",
      "  [0.94263208]\n",
      "  [0.94407439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007356912828981876\n",
      "Predicción post entrenamiento : [[0.9452269]]\n",
      "PERDIDAAAA despues: 0.0007433451246470213\n",
      "loss en el callback: 0.001010188483633101, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.93955767]\n",
      " [0.9397617 ]\n",
      " [0.94099814]\n",
      " [0.94143409]\n",
      " [0.94251215]\n",
      " [0.94263208]\n",
      " [0.94407439]\n",
      " [0.94536763]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9458498]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.93955767]\n",
      "  [0.9397617 ]\n",
      "  [0.94099814]\n",
      "  [0.94143409]\n",
      "  [0.94251215]\n",
      "  [0.94263208]\n",
      "  [0.94407439]\n",
      "  [0.94536763]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026061702519655228\n",
      "Predicción post entrenamiento : [[0.9462878]]\n",
      "PERDIDAAAA despues: 0.002561638131737709\n",
      "loss en el callback: 0.011612232774496078, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.9397617 ]\n",
      " [0.94099814]\n",
      " [0.94143409]\n",
      " [0.94251215]\n",
      " [0.94263208]\n",
      " [0.94407439]\n",
      " [0.94536763]\n",
      " [0.94584978]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9469216]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.9397617 ]\n",
      "  [0.94099814]\n",
      "  [0.94143409]\n",
      "  [0.94251215]\n",
      "  [0.94263208]\n",
      "  [0.94407439]\n",
      "  [0.94536763]\n",
      "  [0.94584978]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.814864663174376e-05\n",
      "Predicción post entrenamiento : [[0.94739306]]\n",
      "PERDIDAAAA despues: 1.435386911907699e-05\n",
      "loss en el callback: 0.016820698976516724, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.94099814]\n",
      " [0.94143409]\n",
      " [0.94251215]\n",
      " [0.94263208]\n",
      " [0.94407439]\n",
      " [0.94536763]\n",
      " [0.94584978]\n",
      " [0.94692159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9482043]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.94099814]\n",
      "  [0.94143409]\n",
      "  [0.94251215]\n",
      "  [0.94263208]\n",
      "  [0.94407439]\n",
      "  [0.94536763]\n",
      "  [0.94584978]\n",
      "  [0.94692159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002748639788478613\n",
      "Predicción post entrenamiento : [[0.94737023]]\n",
      "PERDIDAAAA despues: 0.0026618812698870897\n",
      "loss en el callback: 0.03505683317780495, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.94143409]\n",
      " [0.94251215]\n",
      " [0.94263208]\n",
      " [0.94407439]\n",
      " [0.94536763]\n",
      " [0.94584978]\n",
      " [0.94692159]\n",
      " [0.94820428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9480719]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.94143409]\n",
      "  [0.94251215]\n",
      "  [0.94263208]\n",
      "  [0.94407439]\n",
      "  [0.94536763]\n",
      "  [0.94584978]\n",
      "  [0.94692159]\n",
      "  [0.94820428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004439637064933777\n",
      "Predicción post entrenamiento : [[0.9484032]]\n",
      "PERDIDAAAA despues: 0.004483893979340792\n",
      "loss en el callback: 0.008662551641464233, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.94251215]\n",
      " [0.94263208]\n",
      " [0.94407439]\n",
      " [0.94536763]\n",
      " [0.94584978]\n",
      " [0.94692159]\n",
      " [0.94820428]\n",
      " [0.9480719 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9492303]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.94251215]\n",
      "  [0.94263208]\n",
      "  [0.94407439]\n",
      "  [0.94536763]\n",
      "  [0.94584978]\n",
      "  [0.94692159]\n",
      "  [0.94820428]\n",
      "  [0.9480719 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010332297533750534\n",
      "Predicción post entrenamiento : [[0.9489661]]\n",
      "PERDIDAAAA despues: 0.0010163129772990942\n",
      "loss en el callback: 0.003777465783059597, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.94263208]\n",
      " [0.94407439]\n",
      " [0.94536763]\n",
      " [0.94584978]\n",
      " [0.94692159]\n",
      " [0.94820428]\n",
      " [0.9480719 ]\n",
      " [0.94923031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9497384]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.94263208]\n",
      "  [0.94407439]\n",
      "  [0.94536763]\n",
      "  [0.94584978]\n",
      "  [0.94692159]\n",
      "  [0.94820428]\n",
      "  [0.9480719 ]\n",
      "  [0.94923031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008963934378698468\n",
      "Predicción post entrenamiento : [[0.9497888]]\n",
      "PERDIDAAAA despues: 0.0008994154632091522\n",
      "loss en el callback: 0.00016748960479162633, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.94407439]\n",
      " [0.94536763]\n",
      " [0.94584978]\n",
      " [0.94692159]\n",
      " [0.94820428]\n",
      " [0.9480719 ]\n",
      " [0.94923031]\n",
      " [0.94973838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.95079154]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.94407439]\n",
      "  [0.94536763]\n",
      "  [0.94584978]\n",
      "  [0.94692159]\n",
      "  [0.94820428]\n",
      "  [0.9480719 ]\n",
      "  [0.94923031]\n",
      "  [0.94973838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011774992890423164\n",
      "Predicción post entrenamiento : [[0.95089364]]\n",
      "PERDIDAAAA despues: 0.00011554446973605081\n",
      "loss en el callback: 0.0006467012572102249, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.94536763]\n",
      " [0.94584978]\n",
      " [0.94692159]\n",
      " [0.94820428]\n",
      " [0.9480719 ]\n",
      " [0.94923031]\n",
      " [0.94973838]\n",
      " [0.95079154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9517403]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.94536763]\n",
      "  [0.94584978]\n",
      "  [0.94692159]\n",
      "  [0.94820428]\n",
      "  [0.9480719 ]\n",
      "  [0.94923031]\n",
      "  [0.94973838]\n",
      "  [0.95079154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027188807143829763\n",
      "Predicción post entrenamiento : [[0.95161223]]\n",
      "PERDIDAAAA despues: 0.000276128645054996\n",
      "loss en el callback: 0.0009968202793970704, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.94584978]\n",
      " [0.94692159]\n",
      " [0.94820428]\n",
      " [0.9480719 ]\n",
      " [0.94923031]\n",
      " [0.94973838]\n",
      " [0.95079154]\n",
      " [0.95174032]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.95231867]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.94584978]\n",
      "  [0.94692159]\n",
      "  [0.94820428]\n",
      "  [0.9480719 ]\n",
      "  [0.94923031]\n",
      "  [0.94973838]\n",
      "  [0.95079154]\n",
      "  [0.95174032]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.9698714570258744e-05\n",
      "Predicción post entrenamiento : [[0.95215744]]\n",
      "PERDIDAAAA despues: 3.148200994473882e-05\n",
      "loss en el callback: 0.00159381830599159, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22886316]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033400122076272964\n",
      "Predicción post entrenamiento : [[0.21069594]]\n",
      "PERDIDAAAA despues: 0.027089795097708702\n",
      "loss en el callback: 0.020094584673643112, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22886316]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.19492473]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22886316]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008226772770285606\n",
      "Predicción post entrenamiento : [[0.17831883]]\n",
      "PERDIDAAAA despues: 0.0054901666007936\n",
      "loss en el callback: 0.010764182545244694, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22886316]\n",
      " [0.19492473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.18213804]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22886316]\n",
      "  [0.19492473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007803216576576233\n",
      "Predicción post entrenamiento : [[0.17826733]]\n",
      "PERDIDAAAA despues: 0.0005790533614344895\n",
      "loss en el callback: 0.0013818898005411029, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22886316]\n",
      " [0.19492473]\n",
      " [0.18213804]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.18938163]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22886316]\n",
      "  [0.19492473]\n",
      "  [0.18213804]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001130845514126122\n",
      "Predicción post entrenamiento : [[0.18649594]]\n",
      "PERDIDAAAA despues: 0.0009450928191654384\n",
      "loss en el callback: 0.0013436792651191354, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22886316]\n",
      " [0.19492473]\n",
      " [0.18213804]\n",
      " [0.18938163]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19874027]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22886316]\n",
      "  [0.19492473]\n",
      "  [0.18213804]\n",
      "  [0.18938163]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005359341856092215\n",
      "Predicción post entrenamiento : [[0.1945603]]\n",
      "PERDIDAAAA despues: 0.004764803685247898\n",
      "loss en el callback: 0.004823409020900726, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22886316]\n",
      " [0.19492473]\n",
      " [0.18213804]\n",
      " [0.18938163]\n",
      " [0.19874027]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.20404907]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22886316]\n",
      "  [0.19492473]\n",
      "  [0.18213804]\n",
      "  [0.18938163]\n",
      "  [0.19874027]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00340695190243423\n",
      "Predicción post entrenamiento : [[0.20071444]]\n",
      "PERDIDAAAA despues: 0.0030287932604551315\n",
      "loss en el callback: 0.003975922707468271, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.22886316]\n",
      " [0.19492473]\n",
      " [0.18213804]\n",
      " [0.18938163]\n",
      " [0.19874027]\n",
      " [0.20404907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.22122881]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22886316]\n",
      "  [0.19492473]\n",
      "  [0.18213804]\n",
      "  [0.18938163]\n",
      "  [0.19874027]\n",
      "  [0.20404907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005591143853962421\n",
      "Predicción post entrenamiento : [[0.21710204]]\n",
      "PERDIDAAAA despues: 0.004991024266928434\n",
      "loss en el callback: 0.007369828410446644, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.22886316]\n",
      " [0.19492473]\n",
      " [0.18213804]\n",
      " [0.18938163]\n",
      " [0.19874027]\n",
      " [0.20404907]\n",
      " [0.22122881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.24215682]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.22886316]\n",
      "  [0.19492473]\n",
      "  [0.18213804]\n",
      "  [0.18938163]\n",
      "  [0.19874027]\n",
      "  [0.20404907]\n",
      "  [0.22122881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002126019913703203\n",
      "Predicción post entrenamiento : [[0.2397026]]\n",
      "PERDIDAAAA despues: 0.0019057206809520721\n",
      "loss en el callback: 0.003460997948423028, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.22886316]\n",
      " [0.19492473]\n",
      " [0.18213804]\n",
      " [0.18938163]\n",
      " [0.19874027]\n",
      " [0.20404907]\n",
      " [0.22122881]\n",
      " [0.24215682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.26972762]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.22886316]\n",
      "  [0.19492473]\n",
      "  [0.18213804]\n",
      "  [0.18938163]\n",
      "  [0.19874027]\n",
      "  [0.20404907]\n",
      "  [0.22122881]\n",
      "  [0.24215682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001536390627734363\n",
      "Predicción post entrenamiento : [[0.26799816]]\n",
      "PERDIDAAAA despues: 0.0014038031222298741\n",
      "loss en el callback: 0.001983401831239462, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.19492473]\n",
      " [0.18213804]\n",
      " [0.18938163]\n",
      " [0.19874027]\n",
      " [0.20404907]\n",
      " [0.22122881]\n",
      " [0.24215682]\n",
      " [0.26972762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.26252213]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.19492473]\n",
      "  [0.18213804]\n",
      "  [0.18938163]\n",
      "  [0.19874027]\n",
      "  [0.20404907]\n",
      "  [0.22122881]\n",
      "  [0.24215682]\n",
      "  [0.26972762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029241912998259068\n",
      "Predicción post entrenamiento : [[0.25987622]]\n",
      "PERDIDAAAA despues: 0.002645032713189721\n",
      "loss en el callback: 0.0054804314859211445, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.18213804]\n",
      " [0.18938163]\n",
      " [0.19874027]\n",
      " [0.20404907]\n",
      " [0.22122881]\n",
      " [0.24215682]\n",
      " [0.26972762]\n",
      " [0.26252213]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.26219383]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.18213804]\n",
      "  [0.18938163]\n",
      "  [0.19874027]\n",
      "  [0.20404907]\n",
      "  [0.22122881]\n",
      "  [0.24215682]\n",
      "  [0.26972762]\n",
      "  [0.26252213]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002526114694774151\n",
      "Predicción post entrenamiento : [[0.2591024]]\n",
      "PERDIDAAAA despues: 0.0022249186877161264\n",
      "loss en el callback: 0.007997680455446243, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.18938163]\n",
      " [0.19874027]\n",
      " [0.20404907]\n",
      " [0.22122881]\n",
      " [0.24215682]\n",
      " [0.26972762]\n",
      " [0.26252213]\n",
      " [0.26219383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2660572]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.18938163]\n",
      "  [0.19874027]\n",
      "  [0.20404907]\n",
      "  [0.22122881]\n",
      "  [0.24215682]\n",
      "  [0.26972762]\n",
      "  [0.26252213]\n",
      "  [0.26219383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034542877692729235\n",
      "Predicción post entrenamiento : [[0.26534352]]\n",
      "PERDIDAAAA despues: 0.0033709071576595306\n",
      "loss en el callback: 0.00083298230310902, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.19874027]\n",
      " [0.20404907]\n",
      " [0.22122881]\n",
      " [0.24215682]\n",
      " [0.26972762]\n",
      " [0.26252213]\n",
      " [0.26219383]\n",
      " [0.26605719]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.27324963]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.19874027]\n",
      "  [0.20404907]\n",
      "  [0.22122881]\n",
      "  [0.24215682]\n",
      "  [0.26972762]\n",
      "  [0.26252213]\n",
      "  [0.26219383]\n",
      "  [0.26605719]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006448274943977594\n",
      "Predicción post entrenamiento : [[0.27090284]]\n",
      "PERDIDAAAA despues: 0.006076883524656296\n",
      "loss en el callback: 0.007767834234982729, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.20404907]\n",
      " [0.22122881]\n",
      " [0.24215682]\n",
      " [0.26972762]\n",
      " [0.26252213]\n",
      " [0.26219383]\n",
      " [0.26605719]\n",
      " [0.27324963]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2792897]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.20404907]\n",
      "  [0.22122881]\n",
      "  [0.24215682]\n",
      "  [0.26972762]\n",
      "  [0.26252213]\n",
      "  [0.26219383]\n",
      "  [0.26605719]\n",
      "  [0.27324963]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006800765171647072\n",
      "Predicción post entrenamiento : [[0.2766782]]\n",
      "PERDIDAAAA despues: 0.006376862991601229\n",
      "loss en el callback: 0.010433519259095192, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.22122881]\n",
      " [0.24215682]\n",
      " [0.26972762]\n",
      " [0.26252213]\n",
      " [0.26219383]\n",
      " [0.26605719]\n",
      " [0.27324963]\n",
      " [0.27928969]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2863456]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.22122881]\n",
      "  [0.24215682]\n",
      "  [0.26972762]\n",
      "  [0.26252213]\n",
      "  [0.26219383]\n",
      "  [0.26605719]\n",
      "  [0.27324963]\n",
      "  [0.27928969]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0051966155879199505\n",
      "Predicción post entrenamiento : [[0.28479433]]\n",
      "PERDIDAAAA despues: 0.0049753678031265736\n",
      "loss en el callback: 0.004547173157334328, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.24215682]\n",
      " [0.26972762]\n",
      " [0.26252213]\n",
      " [0.26219383]\n",
      " [0.26605719]\n",
      " [0.27324963]\n",
      " [0.27928969]\n",
      " [0.2863456 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.29298687]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.24215682]\n",
      "  [0.26972762]\n",
      "  [0.26252213]\n",
      "  [0.26219383]\n",
      "  [0.26605719]\n",
      "  [0.27324963]\n",
      "  [0.27928969]\n",
      "  [0.2863456 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012468359433114529\n",
      "Predicción post entrenamiento : [[0.2900993]]\n",
      "PERDIDAAAA despues: 0.01183183304965496\n",
      "loss en el callback: 0.016625016927719116, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.26972762]\n",
      " [0.26252213]\n",
      " [0.26219383]\n",
      " [0.26605719]\n",
      " [0.27324963]\n",
      " [0.27928969]\n",
      " [0.2863456 ]\n",
      " [0.29298687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2954498]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.26972762]\n",
      "  [0.26252213]\n",
      "  [0.26219383]\n",
      "  [0.26605719]\n",
      "  [0.27324963]\n",
      "  [0.27928969]\n",
      "  [0.2863456 ]\n",
      "  [0.29298687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014477833174169064\n",
      "Predicción post entrenamiento : [[0.2917213]]\n",
      "PERDIDAAAA despues: 0.013594483956694603\n",
      "loss en el callback: 0.026270676404237747, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.26252213]\n",
      " [0.26219383]\n",
      " [0.26605719]\n",
      " [0.27324963]\n",
      " [0.27928969]\n",
      " [0.2863456 ]\n",
      " [0.29298687]\n",
      " [0.29544979]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.29209733]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.26252213]\n",
      "  [0.26219383]\n",
      "  [0.26605719]\n",
      "  [0.27324963]\n",
      "  [0.27928969]\n",
      "  [0.2863456 ]\n",
      "  [0.29298687]\n",
      "  [0.29544979]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020762700587511063\n",
      "Predicción post entrenamiento : [[0.28921798]]\n",
      "PERDIDAAAA despues: 0.01994120329618454\n",
      "loss en el callback: 0.020765749737620354, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.26219383]\n",
      " [0.26605719]\n",
      " [0.27324963]\n",
      " [0.27928969]\n",
      " [0.2863456 ]\n",
      " [0.29298687]\n",
      " [0.29544979]\n",
      " [0.29209733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.29188997]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.26219383]\n",
      "  [0.26605719]\n",
      "  [0.27324963]\n",
      "  [0.27928969]\n",
      "  [0.2863456 ]\n",
      "  [0.29298687]\n",
      "  [0.29544979]\n",
      "  [0.29209733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01769879274070263\n",
      "Predicción post entrenamiento : [[0.29002172]]\n",
      "PERDIDAAAA despues: 0.017205191776156425\n",
      "loss en el callback: 0.011098220944404602, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.26605719]\n",
      " [0.27324963]\n",
      " [0.27928969]\n",
      " [0.2863456 ]\n",
      " [0.29298687]\n",
      " [0.29544979]\n",
      " [0.29209733]\n",
      " [0.29188997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.29376626]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.26605719]\n",
      "  [0.27324963]\n",
      "  [0.27928969]\n",
      "  [0.2863456 ]\n",
      "  [0.29298687]\n",
      "  [0.29544979]\n",
      "  [0.29209733]\n",
      "  [0.29188997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010321074165403843\n",
      "Predicción post entrenamiento : [[0.29249328]]\n",
      "PERDIDAAAA despues: 0.01006404496729374\n",
      "loss en el callback: 0.006072049494832754, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.27324963]\n",
      " [0.27928969]\n",
      " [0.2863456 ]\n",
      " [0.29298687]\n",
      " [0.29544979]\n",
      " [0.29209733]\n",
      " [0.29188997]\n",
      " [0.29376626]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.29642016]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.27324963]\n",
      "  [0.27928969]\n",
      "  [0.2863456 ]\n",
      "  [0.29298687]\n",
      "  [0.29544979]\n",
      "  [0.29209733]\n",
      "  [0.29188997]\n",
      "  [0.29376626]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012198257260024548\n",
      "Predicción post entrenamiento : [[0.29398888]]\n",
      "PERDIDAAAA despues: 0.011667121201753616\n",
      "loss en el callback: 0.017371423542499542, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.27928969]\n",
      " [0.2863456 ]\n",
      " [0.29298687]\n",
      " [0.29544979]\n",
      " [0.29209733]\n",
      " [0.29188997]\n",
      " [0.29376626]\n",
      " [0.29642016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29722336]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.27928969]\n",
      "  [0.2863456 ]\n",
      "  [0.29298687]\n",
      "  [0.29544979]\n",
      "  [0.29209733]\n",
      "  [0.29188997]\n",
      "  [0.29376626]\n",
      "  [0.29642016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000916428689379245\n",
      "Predicción post entrenamiento : [[0.29667336]]\n",
      "PERDIDAAAA despues: 0.0008834312320686877\n",
      "loss en el callback: 0.0011069346219301224, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.2863456 ]\n",
      " [0.29298687]\n",
      " [0.29544979]\n",
      " [0.29209733]\n",
      " [0.29188997]\n",
      " [0.29376626]\n",
      " [0.29642016]\n",
      " [0.29722336]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29925752]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.2863456 ]\n",
      "  [0.29298687]\n",
      "  [0.29544979]\n",
      "  [0.29209733]\n",
      "  [0.29188997]\n",
      "  [0.29376626]\n",
      "  [0.29642016]\n",
      "  [0.29722336]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.536339838523418e-05\n",
      "Predicción post entrenamiento : [[0.29966345]]\n",
      "PERDIDAAAA despues: 5.0996350182686e-05\n",
      "loss en el callback: 0.0008549434714950621, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.29298687]\n",
      " [0.29544979]\n",
      " [0.29209733]\n",
      " [0.29188997]\n",
      " [0.29376626]\n",
      " [0.29642016]\n",
      " [0.29722336]\n",
      " [0.29925752]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.30117115]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.29298687]\n",
      "  [0.29544979]\n",
      "  [0.29209733]\n",
      "  [0.29188997]\n",
      "  [0.29376626]\n",
      "  [0.29642016]\n",
      "  [0.29722336]\n",
      "  [0.29925752]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002734115987550467\n",
      "Predicción post entrenamiento : [[0.30183157]]\n",
      "PERDIDAAAA despues: 0.0002520074776839465\n",
      "loss en el callback: 0.002082527382299304, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.29544979]\n",
      " [0.29209733]\n",
      " [0.29188997]\n",
      " [0.29376626]\n",
      " [0.29642016]\n",
      " [0.29722336]\n",
      " [0.29925752]\n",
      " [0.30117115]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.30215016]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.29544979]\n",
      "  [0.29209733]\n",
      "  [0.29188997]\n",
      "  [0.29376626]\n",
      "  [0.29642016]\n",
      "  [0.29722336]\n",
      "  [0.29925752]\n",
      "  [0.30117115]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011065683793276548\n",
      "Predicción post entrenamiento : [[0.30236122]]\n",
      "PERDIDAAAA despues: 0.00010626095900079235\n",
      "loss en el callback: 0.00020568897889461368, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.29209733]\n",
      " [0.29188997]\n",
      " [0.29376626]\n",
      " [0.29642016]\n",
      " [0.29722336]\n",
      " [0.29925752]\n",
      " [0.30117115]\n",
      " [0.30215016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.30229372]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.29209733]\n",
      "  [0.29188997]\n",
      "  [0.29376626]\n",
      "  [0.29642016]\n",
      "  [0.29722336]\n",
      "  [0.29925752]\n",
      "  [0.30117115]\n",
      "  [0.30215016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001757866848492995\n",
      "Predicción post entrenamiento : [[0.30256858]]\n",
      "PERDIDAAAA despues: 0.00018315085617359728\n",
      "loss en el callback: 0.0005077871028333902, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.29188997]\n",
      " [0.29376626]\n",
      " [0.29642016]\n",
      " [0.29722336]\n",
      " [0.29925752]\n",
      " [0.30117115]\n",
      " [0.30215016]\n",
      " [0.30229372]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.30344924]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.29188997]\n",
      "  [0.29376626]\n",
      "  [0.29642016]\n",
      "  [0.29722336]\n",
      "  [0.29925752]\n",
      "  [0.30117115]\n",
      "  [0.30215016]\n",
      "  [0.30229372]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00042490128544159234\n",
      "Predicción post entrenamiento : [[0.30330637]]\n",
      "PERDIDAAAA despues: 0.0004190315958112478\n",
      "loss en el callback: 0.00011952944623772055, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.29376626]\n",
      " [0.29642016]\n",
      " [0.29722336]\n",
      " [0.29925752]\n",
      " [0.30117115]\n",
      " [0.30215016]\n",
      " [0.30229372]\n",
      " [0.30344924]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30456087]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.29376626]\n",
      "  [0.29642016]\n",
      "  [0.29722336]\n",
      "  [0.29925752]\n",
      "  [0.30117115]\n",
      "  [0.30215016]\n",
      "  [0.30229372]\n",
      "  [0.30344924]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.5649636882008053e-05\n",
      "Predicción post entrenamiento : [[0.30442324]]\n",
      "PERDIDAAAA despues: 2.4274540919577703e-05\n",
      "loss en el callback: 0.00010789355292217806, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29642016]\n",
      " [0.29722336]\n",
      " [0.29925752]\n",
      " [0.30117115]\n",
      " [0.30215016]\n",
      " [0.30229372]\n",
      " [0.30344924]\n",
      " [0.30456087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30560735]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29642016]\n",
      "  [0.29722336]\n",
      "  [0.29925752]\n",
      "  [0.30117115]\n",
      "  [0.30215016]\n",
      "  [0.30229372]\n",
      "  [0.30344924]\n",
      "  [0.30456087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000884781708009541\n",
      "Predicción post entrenamiento : [[0.3051319]]\n",
      "PERDIDAAAA despues: 0.0008567238110117614\n",
      "loss en el callback: 0.0013815552229061723, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29722336]\n",
      " [0.29925752]\n",
      " [0.30117115]\n",
      " [0.30215016]\n",
      " [0.30229372]\n",
      " [0.30344924]\n",
      " [0.30456087]\n",
      " [0.30560735]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30603057]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29722336]\n",
      "  [0.29925752]\n",
      "  [0.30117115]\n",
      "  [0.30215016]\n",
      "  [0.30229372]\n",
      "  [0.30344924]\n",
      "  [0.30456087]\n",
      "  [0.30560735]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000981622375547886\n",
      "Predicción post entrenamiento : [[0.3060654]]\n",
      "PERDIDAAAA despues: 0.0009838066762313247\n",
      "loss en el callback: 9.992192644858733e-06, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29925752]\n",
      " [0.30117115]\n",
      " [0.30215016]\n",
      " [0.30229372]\n",
      " [0.30344924]\n",
      " [0.30456087]\n",
      " [0.30560735]\n",
      " [0.30603057]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30705172]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29925752]\n",
      "  [0.30117115]\n",
      "  [0.30215016]\n",
      "  [0.30229372]\n",
      "  [0.30344924]\n",
      "  [0.30456087]\n",
      "  [0.30560735]\n",
      "  [0.30603057]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000997113878838718\n",
      "Predicción post entrenamiento : [[0.30665293]]\n",
      "PERDIDAAAA despues: 0.0009720879606902599\n",
      "loss en el callback: 0.0011384871322661638, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.30117115]\n",
      " [0.30215016]\n",
      " [0.30229372]\n",
      " [0.30344924]\n",
      " [0.30456087]\n",
      " [0.30560735]\n",
      " [0.30603057]\n",
      " [0.30705172]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3074371]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.30117115]\n",
      "  [0.30215016]\n",
      "  [0.30229372]\n",
      "  [0.30344924]\n",
      "  [0.30456087]\n",
      "  [0.30560735]\n",
      "  [0.30603057]\n",
      "  [0.30705172]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007462112698704004\n",
      "Predicción post entrenamiento : [[0.30777422]]\n",
      "PERDIDAAAA despues: 0.0007279065903276205\n",
      "loss en el callback: 0.0008607358322478831, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.30215016]\n",
      " [0.30229372]\n",
      " [0.30344924]\n",
      " [0.30456087]\n",
      " [0.30560735]\n",
      " [0.30603057]\n",
      " [0.30705172]\n",
      " [0.30743709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.30834025]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.30215016]\n",
      "  [0.30229372]\n",
      "  [0.30344924]\n",
      "  [0.30456087]\n",
      "  [0.30560735]\n",
      "  [0.30603057]\n",
      "  [0.30705172]\n",
      "  [0.30743709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022406810894608498\n",
      "Predicción post entrenamiento : [[0.30919072]]\n",
      "PERDIDAAAA despues: 0.002160889096558094\n",
      "loss en el callback: 0.0071702818386256695, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.30229372]\n",
      " [0.30344924]\n",
      " [0.30456087]\n",
      " [0.30560735]\n",
      " [0.30603057]\n",
      " [0.30705172]\n",
      " [0.30743709]\n",
      " [0.30834025]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30971965]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.30229372]\n",
      "  [0.30344924]\n",
      "  [0.30456087]\n",
      "  [0.30560735]\n",
      "  [0.30603057]\n",
      "  [0.30705172]\n",
      "  [0.30743709]\n",
      "  [0.30834025]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007274644449353218\n",
      "Predicción post entrenamiento : [[0.30972672]]\n",
      "PERDIDAAAA despues: 0.0007270834757946432\n",
      "loss en el callback: 4.242304498802696e-07, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.30344924]\n",
      " [0.30456087]\n",
      " [0.30560735]\n",
      " [0.30603057]\n",
      " [0.30705172]\n",
      " [0.30743709]\n",
      " [0.30834025]\n",
      " [0.30971965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3104108]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.30344924]\n",
      "  [0.30456087]\n",
      "  [0.30560735]\n",
      "  [0.30603057]\n",
      "  [0.30705172]\n",
      "  [0.30743709]\n",
      "  [0.30834025]\n",
      "  [0.30971965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005373514723032713\n",
      "Predicción post entrenamiento : [[0.31107932]]\n",
      "PERDIDAAAA despues: 0.0005068043828941882\n",
      "loss en el callback: 0.005723338108509779, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30456087]\n",
      " [0.30560735]\n",
      " [0.30603057]\n",
      " [0.30705172]\n",
      " [0.30743709]\n",
      " [0.30834025]\n",
      " [0.30971965]\n",
      " [0.3104108 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.31170404]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30456087]\n",
      "  [0.30560735]\n",
      "  [0.30603057]\n",
      "  [0.30705172]\n",
      "  [0.30743709]\n",
      "  [0.30834025]\n",
      "  [0.30971965]\n",
      "  [0.3104108 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005333462730050087\n",
      "Predicción post entrenamiento : [[0.3127577]]\n",
      "PERDIDAAAA despues: 0.005180674139410257\n",
      "loss en el callback: 0.014802814461290836, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30560735]\n",
      " [0.30603057]\n",
      " [0.30705172]\n",
      " [0.30743709]\n",
      " [0.30834025]\n",
      " [0.30971965]\n",
      " [0.3104108 ]\n",
      " [0.31170404]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.31332508]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30560735]\n",
      "  [0.30603057]\n",
      "  [0.30705172]\n",
      "  [0.30743709]\n",
      "  [0.30834025]\n",
      "  [0.30971965]\n",
      "  [0.3104108 ]\n",
      "  [0.31170404]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06644609570503235\n",
      "Predicción post entrenamiento : [[0.31592754]]\n",
      "PERDIDAAAA despues: 0.0651111900806427\n",
      "loss en el callback: 0.07449880242347717, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30603057]\n",
      " [0.30705172]\n",
      " [0.30743709]\n",
      " [0.30834025]\n",
      " [0.30971965]\n",
      " [0.3104108 ]\n",
      " [0.31170404]\n",
      " [0.31332508]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.31645197]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30603057]\n",
      "  [0.30705172]\n",
      "  [0.30743709]\n",
      "  [0.30834025]\n",
      "  [0.30971965]\n",
      "  [0.3104108 ]\n",
      "  [0.31170404]\n",
      "  [0.31332508]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07830401510000229\n",
      "Predicción post entrenamiento : [[0.31926057]]\n",
      "PERDIDAAAA despues: 0.07674004882574081\n",
      "loss en el callback: 0.11055798083543777, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30705172]\n",
      " [0.30743709]\n",
      " [0.30834025]\n",
      " [0.30971965]\n",
      " [0.3104108 ]\n",
      " [0.31170404]\n",
      " [0.31332508]\n",
      " [0.31645197]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.31990418]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30705172]\n",
      "  [0.30743709]\n",
      "  [0.30834025]\n",
      "  [0.30971965]\n",
      "  [0.3104108 ]\n",
      "  [0.31170404]\n",
      "  [0.31332508]\n",
      "  [0.31645197]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06486154347658157\n",
      "Predicción post entrenamiento : [[0.32219076]]\n",
      "PERDIDAAAA despues: 0.06370207667350769\n",
      "loss en el callback: 0.04974852129817009, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30743709]\n",
      " [0.30834025]\n",
      " [0.30971965]\n",
      " [0.3104108 ]\n",
      " [0.31170404]\n",
      " [0.31332508]\n",
      " [0.31645197]\n",
      " [0.31990418]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3228647]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30743709]\n",
      "  [0.30834025]\n",
      "  [0.30971965]\n",
      "  [0.3104108 ]\n",
      "  [0.31170404]\n",
      "  [0.31332508]\n",
      "  [0.31645197]\n",
      "  [0.31990418]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08036624640226364\n",
      "Predicción post entrenamiento : [[0.32555336]]\n",
      "PERDIDAAAA despues: 0.07884906977415085\n",
      "loss en el callback: 0.10787806659936905, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30834025]\n",
      " [0.30971965]\n",
      " [0.3104108 ]\n",
      " [0.31170404]\n",
      " [0.31332508]\n",
      " [0.31645197]\n",
      " [0.31990418]\n",
      " [0.32286471]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.32645732]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30834025]\n",
      "  [0.30971965]\n",
      "  [0.3104108 ]\n",
      "  [0.31170404]\n",
      "  [0.31332508]\n",
      "  [0.31645197]\n",
      "  [0.31990418]\n",
      "  [0.32286471]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06666713953018188\n",
      "Predicción post entrenamiento : [[0.32851043]]\n",
      "PERDIDAAAA despues: 0.06561113148927689\n",
      "loss en el callback: 0.04184712842106819, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30971965]\n",
      " [0.3104108 ]\n",
      " [0.31170404]\n",
      " [0.31332508]\n",
      " [0.31645197]\n",
      " [0.31990418]\n",
      " [0.32286471]\n",
      " [0.32645732]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32960704]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30971965]\n",
      "  [0.3104108 ]\n",
      "  [0.31170404]\n",
      "  [0.31332508]\n",
      "  [0.31645197]\n",
      "  [0.31990418]\n",
      "  [0.32286471]\n",
      "  [0.32645732]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05719977244734764\n",
      "Predicción post entrenamiento : [[0.3318524]]\n",
      "PERDIDAAAA despues: 0.0561307892203331\n",
      "loss en el callback: 0.07787548750638962, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.3104108 ]\n",
      " [0.31170404]\n",
      " [0.31332508]\n",
      " [0.31645197]\n",
      " [0.31990418]\n",
      " [0.32286471]\n",
      " [0.32645732]\n",
      " [0.32960704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.33310726]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.3104108 ]\n",
      "  [0.31170404]\n",
      "  [0.31332508]\n",
      "  [0.31645197]\n",
      "  [0.31990418]\n",
      "  [0.32286471]\n",
      "  [0.32645732]\n",
      "  [0.32960704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09589355438947678\n",
      "Predicción post entrenamiento : [[0.3356536]]\n",
      "PERDIDAAAA despues: 0.09432300180196762\n",
      "loss en el callback: 0.07030504941940308, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31170404]\n",
      " [0.31332508]\n",
      " [0.31645197]\n",
      " [0.31990418]\n",
      " [0.32286471]\n",
      " [0.32645732]\n",
      " [0.32960704]\n",
      " [0.33310726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3373039]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31170404]\n",
      "  [0.31332508]\n",
      "  [0.31645197]\n",
      "  [0.31990418]\n",
      "  [0.32286471]\n",
      "  [0.32645732]\n",
      "  [0.32960704]\n",
      "  [0.33310726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1052711233496666\n",
      "Predicción post entrenamiento : [[0.34013775]]\n",
      "PERDIDAAAA despues: 0.10344024002552032\n",
      "loss en el callback: 0.14170363545417786, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.31332508]\n",
      " [0.31645197]\n",
      " [0.31990418]\n",
      " [0.32286471]\n",
      " [0.32645732]\n",
      " [0.32960704]\n",
      " [0.33310726]\n",
      " [0.33730391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34214363]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.31332508]\n",
      "  [0.31645197]\n",
      "  [0.31990418]\n",
      "  [0.32286471]\n",
      "  [0.32645732]\n",
      "  [0.32960704]\n",
      "  [0.33310726]\n",
      "  [0.33730391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10946261137723923\n",
      "Predicción post entrenamiento : [[0.3448238]]\n",
      "PERDIDAAAA despues: 0.10769630968570709\n",
      "loss en el callback: 0.10959812998771667, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.31645197]\n",
      " [0.31990418]\n",
      " [0.32286471]\n",
      " [0.32645732]\n",
      " [0.32960704]\n",
      " [0.33310726]\n",
      " [0.33730391]\n",
      " [0.34214363]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34719825]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.31645197]\n",
      "  [0.31990418]\n",
      "  [0.32286471]\n",
      "  [0.32645732]\n",
      "  [0.32960704]\n",
      "  [0.33310726]\n",
      "  [0.33730391]\n",
      "  [0.34214363]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13204434514045715\n",
      "Predicción post entrenamiento : [[0.35030112]]\n",
      "PERDIDAAAA despues: 0.12979893386363983\n",
      "loss en el callback: 0.14116640388965607, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31990418]\n",
      " [0.32286471]\n",
      " [0.32645732]\n",
      " [0.32960704]\n",
      " [0.33310726]\n",
      " [0.33730391]\n",
      " [0.34214363]\n",
      " [0.34719825]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3527698]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31990418]\n",
      "  [0.32286471]\n",
      "  [0.32645732]\n",
      "  [0.32960704]\n",
      "  [0.33310726]\n",
      "  [0.33730391]\n",
      "  [0.34214363]\n",
      "  [0.34719825]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12335612624883652\n",
      "Predicción post entrenamiento : [[0.3557172]]\n",
      "PERDIDAAAA despues: 0.12129442393779755\n",
      "loss en el callback: 0.14223699271678925, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32286471]\n",
      " [0.32645732]\n",
      " [0.32960704]\n",
      " [0.33310726]\n",
      " [0.33730391]\n",
      " [0.34214363]\n",
      " [0.34719825]\n",
      " [0.35276979]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35825044]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32286471]\n",
      "  [0.32645732]\n",
      "  [0.32960704]\n",
      "  [0.33310726]\n",
      "  [0.33730391]\n",
      "  [0.34214363]\n",
      "  [0.34719825]\n",
      "  [0.35276979]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13615146279335022\n",
      "Predicción post entrenamiento : [[0.36112738]]\n",
      "PERDIDAAAA despues: 0.13403664529323578\n",
      "loss en el callback: 0.13578125834465027, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32645732]\n",
      " [0.32960704]\n",
      " [0.33310726]\n",
      " [0.33730391]\n",
      " [0.34214363]\n",
      " [0.34719825]\n",
      " [0.35276979]\n",
      " [0.35825044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3638985]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32645732]\n",
      "  [0.32960704]\n",
      "  [0.33310726]\n",
      "  [0.33730391]\n",
      "  [0.34214363]\n",
      "  [0.34719825]\n",
      "  [0.35276979]\n",
      "  [0.35825044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1286582499742508\n",
      "Predicción post entrenamiento : [[0.36665902]]\n",
      "PERDIDAAAA despues: 0.12668552994728088\n",
      "loss en el callback: 0.12298456579446793, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32960704]\n",
      " [0.33310726]\n",
      " [0.33730391]\n",
      " [0.34214363]\n",
      " [0.34719825]\n",
      " [0.35276979]\n",
      " [0.35825044]\n",
      " [0.36389849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36959755]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32960704]\n",
      "  [0.33310726]\n",
      "  [0.33730391]\n",
      "  [0.34214363]\n",
      "  [0.34719825]\n",
      "  [0.35276979]\n",
      "  [0.35825044]\n",
      "  [0.36389849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16176189482212067\n",
      "Predicción post entrenamiento : [[0.3726275]]\n",
      "PERDIDAAAA despues: 0.15933382511138916\n",
      "loss en el callback: 0.1296876221895218, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33310726]\n",
      " [0.33730391]\n",
      " [0.34214363]\n",
      " [0.34719825]\n",
      " [0.35276979]\n",
      " [0.35825044]\n",
      " [0.36389849]\n",
      " [0.36959755]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37591448]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33310726]\n",
      "  [0.33730391]\n",
      "  [0.34214363]\n",
      "  [0.34719825]\n",
      "  [0.35276979]\n",
      "  [0.35825044]\n",
      "  [0.36389849]\n",
      "  [0.36959755]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12152956426143646\n",
      "Predicción post entrenamiento : [[0.37870052]]\n",
      "PERDIDAAAA despues: 0.11959484219551086\n",
      "loss en el callback: 0.15880855917930603, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33730391]\n",
      " [0.34214363]\n",
      " [0.34719825]\n",
      " [0.35276979]\n",
      " [0.35825044]\n",
      " [0.36389849]\n",
      " [0.36959755]\n",
      " [0.37591448]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38234645]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33730391]\n",
      "  [0.34214363]\n",
      "  [0.34719825]\n",
      "  [0.35276979]\n",
      "  [0.35825044]\n",
      "  [0.36389849]\n",
      "  [0.36959755]\n",
      "  [0.37591448]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08335418254137039\n",
      "Predicción post entrenamiento : [[0.38432488]]\n",
      "PERDIDAAAA despues: 0.08221571147441864\n",
      "loss en el callback: 0.05398635193705559, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34214363]\n",
      " [0.34719825]\n",
      " [0.35276979]\n",
      " [0.35825044]\n",
      " [0.36389849]\n",
      " [0.36959755]\n",
      " [0.37591448]\n",
      " [0.38234645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38824695]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34214363]\n",
      "  [0.34719825]\n",
      "  [0.35276979]\n",
      "  [0.35825044]\n",
      "  [0.36389849]\n",
      "  [0.36959755]\n",
      "  [0.37591448]\n",
      "  [0.38234645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08152331411838531\n",
      "Predicción post entrenamiento : [[0.39049354]]\n",
      "PERDIDAAAA despues: 0.08024545758962631\n",
      "loss en el callback: 0.14405997097492218, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34719825]\n",
      " [0.35276979]\n",
      " [0.35825044]\n",
      " [0.36389849]\n",
      " [0.36959755]\n",
      " [0.37591448]\n",
      " [0.38234645]\n",
      " [0.38824695]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39460126]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34719825]\n",
      "  [0.35276979]\n",
      "  [0.35825044]\n",
      "  [0.36389849]\n",
      "  [0.36959755]\n",
      "  [0.37591448]\n",
      "  [0.38234645]\n",
      "  [0.38824695]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1023043617606163\n",
      "Predicción post entrenamiento : [[0.39698887]]\n",
      "PERDIDAAAA despues: 0.10078270733356476\n",
      "loss en el callback: 0.11400870978832245, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35276979]\n",
      " [0.35825044]\n",
      " [0.36389849]\n",
      " [0.36959755]\n",
      " [0.37591448]\n",
      " [0.38234645]\n",
      " [0.38824695]\n",
      " [0.39460126]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40127835]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35276979]\n",
      "  [0.35825044]\n",
      "  [0.36389849]\n",
      "  [0.36959755]\n",
      "  [0.37591448]\n",
      "  [0.38234645]\n",
      "  [0.38824695]\n",
      "  [0.39460126]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1173880472779274\n",
      "Predicción post entrenamiento : [[0.40372667]]\n",
      "PERDIDAAAA despues: 0.115716353058815\n",
      "loss en el callback: 0.11812908947467804, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35825044]\n",
      " [0.36389849]\n",
      " [0.36959755]\n",
      " [0.37591448]\n",
      " [0.38234645]\n",
      " [0.38824695]\n",
      " [0.39460126]\n",
      " [0.40127835]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4081144]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35825044]\n",
      "  [0.36389849]\n",
      "  [0.36959755]\n",
      "  [0.37591448]\n",
      "  [0.38234645]\n",
      "  [0.38824695]\n",
      "  [0.39460126]\n",
      "  [0.40127835]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09889371693134308\n",
      "Predicción post entrenamiento : [[0.41036925]]\n",
      "PERDIDAAAA despues: 0.09748062491416931\n",
      "loss en el callback: 0.08375654369592667, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36389849]\n",
      " [0.36959755]\n",
      " [0.37591448]\n",
      " [0.38234645]\n",
      " [0.38824695]\n",
      " [0.39460126]\n",
      " [0.40127835]\n",
      " [0.4081144 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4149106]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36389849]\n",
      "  [0.36959755]\n",
      "  [0.37591448]\n",
      "  [0.38234645]\n",
      "  [0.38824695]\n",
      "  [0.39460126]\n",
      "  [0.40127835]\n",
      "  [0.4081144 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08090084791183472\n",
      "Predicción post entrenamiento : [[0.41700643]]\n",
      "PERDIDAAAA despues: 0.07971300929784775\n",
      "loss en el callback: 0.10388293117284775, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36959755]\n",
      " [0.37591448]\n",
      " [0.38234645]\n",
      " [0.38824695]\n",
      " [0.39460126]\n",
      " [0.40127835]\n",
      " [0.4081144 ]\n",
      " [0.41491061]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42170006]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36959755]\n",
      "  [0.37591448]\n",
      "  [0.38234645]\n",
      "  [0.38824695]\n",
      "  [0.39460126]\n",
      "  [0.40127835]\n",
      "  [0.4081144 ]\n",
      "  [0.41491061]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0996103435754776\n",
      "Predicción post entrenamiento : [[0.42386934]]\n",
      "PERDIDAAAA despues: 0.09824575483798981\n",
      "loss en el callback: 0.1020178347826004, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37591448]\n",
      " [0.38234645]\n",
      " [0.38824695]\n",
      " [0.39460126]\n",
      " [0.40127835]\n",
      " [0.4081144 ]\n",
      " [0.41491061]\n",
      " [0.42170006]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4287423]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37591448]\n",
      "  [0.38234645]\n",
      "  [0.38824695]\n",
      "  [0.39460126]\n",
      "  [0.40127835]\n",
      "  [0.4081144 ]\n",
      "  [0.41491061]\n",
      "  [0.42170006]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08566365391016006\n",
      "Predicción post entrenamiento : [[0.43083856]]\n",
      "PERDIDAAAA despues: 0.08444096148014069\n",
      "loss en el callback: 0.12900999188423157, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38234645]\n",
      " [0.38824695]\n",
      " [0.39460126]\n",
      " [0.40127835]\n",
      " [0.4081144 ]\n",
      " [0.41491061]\n",
      " [0.42170006]\n",
      " [0.42874229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4357735]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38234645]\n",
      "  [0.38824695]\n",
      "  [0.39460126]\n",
      "  [0.40127835]\n",
      "  [0.4081144 ]\n",
      "  [0.41491061]\n",
      "  [0.42170006]\n",
      "  [0.42874229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08005516231060028\n",
      "Predicción post entrenamiento : [[0.437736]]\n",
      "PERDIDAAAA despues: 0.07894846796989441\n",
      "loss en el callback: 0.07583863288164139, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38824695]\n",
      " [0.39460126]\n",
      " [0.40127835]\n",
      " [0.4081144 ]\n",
      " [0.41491061]\n",
      " [0.42170006]\n",
      " [0.42874229]\n",
      " [0.43577349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.44272447]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38824695]\n",
      "  [0.39460126]\n",
      "  [0.40127835]\n",
      "  [0.4081144 ]\n",
      "  [0.41491061]\n",
      "  [0.42170006]\n",
      "  [0.42874229]\n",
      "  [0.43577349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05356116592884064\n",
      "Predicción post entrenamiento : [[0.4442283]]\n",
      "PERDIDAAAA despues: 0.05286736041307449\n",
      "loss en el callback: 0.046366240829229355, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39460126]\n",
      " [0.40127835]\n",
      " [0.4081144 ]\n",
      " [0.41491061]\n",
      " [0.42170006]\n",
      " [0.42874229]\n",
      " [0.43577349]\n",
      " [0.44272447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44942796]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39460126]\n",
      "  [0.40127835]\n",
      "  [0.4081144 ]\n",
      "  [0.41491061]\n",
      "  [0.42170006]\n",
      "  [0.42874229]\n",
      "  [0.43577349]\n",
      "  [0.44272447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.062069978564977646\n",
      "Predicción post entrenamiento : [[0.45131052]]\n",
      "PERDIDAAAA despues: 0.061135489493608475\n",
      "loss en el callback: 0.0928749218583107, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.40127835]\n",
      " [0.4081144 ]\n",
      " [0.41491061]\n",
      " [0.42170006]\n",
      " [0.42874229]\n",
      " [0.43577349]\n",
      " [0.44272447]\n",
      " [0.44942796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.45664564]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.40127835]\n",
      "  [0.4081144 ]\n",
      "  [0.41491061]\n",
      "  [0.42170006]\n",
      "  [0.42874229]\n",
      "  [0.43577349]\n",
      "  [0.44272447]\n",
      "  [0.44942796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06990350037813187\n",
      "Predicción post entrenamiento : [[0.4586148]]\n",
      "PERDIDAAAA despues: 0.06886611878871918\n",
      "loss en el callback: 0.09941960871219635, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.4081144 ]\n",
      " [0.41491061]\n",
      " [0.42170006]\n",
      " [0.42874229]\n",
      " [0.43577349]\n",
      " [0.44272447]\n",
      " [0.44942796]\n",
      " [0.45664564]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.46402547]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.4081144 ]\n",
      "  [0.41491061]\n",
      "  [0.42170006]\n",
      "  [0.42874229]\n",
      "  [0.43577349]\n",
      "  [0.44272447]\n",
      "  [0.44942796]\n",
      "  [0.45664564]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06685464829206467\n",
      "Predicción post entrenamiento : [[0.46561787]]\n",
      "PERDIDAAAA despues: 0.06603371351957321\n",
      "loss en el callback: 0.04958774894475937, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.41491061]\n",
      " [0.42170006]\n",
      " [0.42874229]\n",
      " [0.43577349]\n",
      " [0.44272447]\n",
      " [0.44942796]\n",
      " [0.45664564]\n",
      " [0.46402547]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.47107515]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.41491061]\n",
      "  [0.42170006]\n",
      "  [0.42874229]\n",
      "  [0.43577349]\n",
      "  [0.44272447]\n",
      "  [0.44942796]\n",
      "  [0.45664564]\n",
      "  [0.46402547]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08135095983743668\n",
      "Predicción post entrenamiento : [[0.4730915]]\n",
      "PERDIDAAAA despues: 0.0802047997713089\n",
      "loss en el callback: 0.11054543405771255, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.42170006]\n",
      " [0.42874229]\n",
      " [0.43577349]\n",
      " [0.44272447]\n",
      " [0.44942796]\n",
      " [0.45664564]\n",
      " [0.46402547]\n",
      " [0.47107515]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.47861737]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.42170006]\n",
      "  [0.42874229]\n",
      "  [0.43577349]\n",
      "  [0.44272447]\n",
      "  [0.44942796]\n",
      "  [0.45664564]\n",
      "  [0.46402547]\n",
      "  [0.47107515]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12177927047014236\n",
      "Predicción post entrenamiento : [[0.48084775]]\n",
      "PERDIDAAAA despues: 0.12022757530212402\n",
      "loss en el callback: 0.09803805500268936, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.42874229]\n",
      " [0.43577349]\n",
      " [0.44272447]\n",
      " [0.44942796]\n",
      " [0.45664564]\n",
      " [0.46402547]\n",
      " [0.47107515]\n",
      " [0.47861737]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.48645937]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.42874229]\n",
      "  [0.43577349]\n",
      "  [0.44272447]\n",
      "  [0.44942796]\n",
      "  [0.45664564]\n",
      "  [0.46402547]\n",
      "  [0.47107515]\n",
      "  [0.47861737]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1241595521569252\n",
      "Predicción post entrenamiento : [[0.4887418]]\n",
      "PERDIDAAAA despues: 0.12255628407001495\n",
      "loss en el callback: 0.11360151320695877, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.43577349]\n",
      " [0.44272447]\n",
      " [0.44942796]\n",
      " [0.45664564]\n",
      " [0.46402547]\n",
      " [0.47107515]\n",
      " [0.47861737]\n",
      " [0.48645937]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.4943927]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.43577349]\n",
      "  [0.44272447]\n",
      "  [0.44942796]\n",
      "  [0.45664564]\n",
      "  [0.46402547]\n",
      "  [0.47107515]\n",
      "  [0.47861737]\n",
      "  [0.48645937]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08992388099431992\n",
      "Predicción post entrenamiento : [[0.49649227]]\n",
      "PERDIDAAAA despues: 0.08866908401250839\n",
      "loss en el callback: 0.10765036940574646, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.44272447]\n",
      " [0.44942796]\n",
      " [0.45664564]\n",
      " [0.46402547]\n",
      " [0.47107515]\n",
      " [0.47861737]\n",
      " [0.48645937]\n",
      " [0.49439269]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5022025]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.44272447]\n",
      "  [0.44942796]\n",
      "  [0.45664564]\n",
      "  [0.46402547]\n",
      "  [0.47107515]\n",
      "  [0.47861737]\n",
      "  [0.48645937]\n",
      "  [0.49439269]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07929980009794235\n",
      "Predicción post entrenamiento : [[0.50388044]]\n",
      "PERDIDAAAA despues: 0.07835759967565536\n",
      "loss en el callback: 0.0627332404255867, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44942796]\n",
      " [0.45664564]\n",
      " [0.46402547]\n",
      " [0.47107515]\n",
      " [0.47861737]\n",
      " [0.48645937]\n",
      " [0.49439269]\n",
      " [0.50220251]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5096957]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44942796]\n",
      "  [0.45664564]\n",
      "  [0.46402547]\n",
      "  [0.47107515]\n",
      "  [0.47861737]\n",
      "  [0.48645937]\n",
      "  [0.49439269]\n",
      "  [0.50220251]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06667948514223099\n",
      "Predicción post entrenamiento : [[0.5110812]]\n",
      "PERDIDAAAA despues: 0.06596586108207703\n",
      "loss en el callback: 0.04164455458521843, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.45664564]\n",
      " [0.46402547]\n",
      " [0.47107515]\n",
      " [0.47861737]\n",
      " [0.48645937]\n",
      " [0.49439269]\n",
      " [0.50220251]\n",
      " [0.50969571]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.51709914]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.45664564]\n",
      "  [0.46402547]\n",
      "  [0.47107515]\n",
      "  [0.47861737]\n",
      "  [0.48645937]\n",
      "  [0.49439269]\n",
      "  [0.50220251]\n",
      "  [0.50969571]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07154581695795059\n",
      "Predicción post entrenamiento : [[0.51839924]]\n",
      "PERDIDAAAA despues: 0.07085200399160385\n",
      "loss en el callback: 0.031009893864393234, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.46402547]\n",
      " [0.47107515]\n",
      " [0.47861737]\n",
      " [0.48645937]\n",
      " [0.49439269]\n",
      " [0.50220251]\n",
      " [0.50969571]\n",
      " [0.51709914]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5245206]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.46402547]\n",
      "  [0.47107515]\n",
      "  [0.47861737]\n",
      "  [0.48645937]\n",
      "  [0.49439269]\n",
      "  [0.50220251]\n",
      "  [0.50969571]\n",
      "  [0.51709914]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12546372413635254\n",
      "Predicción post entrenamiento : [[0.52686703]]\n",
      "PERDIDAAAA despues: 0.12380696088075638\n",
      "loss en el callback: 0.14786839485168457, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.47107515]\n",
      " [0.47861737]\n",
      " [0.48645937]\n",
      " [0.49439269]\n",
      " [0.50220251]\n",
      " [0.50969571]\n",
      " [0.51709914]\n",
      " [0.52452058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5330697]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.47107515]\n",
      "  [0.47861737]\n",
      "  [0.48645937]\n",
      "  [0.49439269]\n",
      "  [0.50220251]\n",
      "  [0.50969571]\n",
      "  [0.51709914]\n",
      "  [0.52452058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11734730750322342\n",
      "Predicción post entrenamiento : [[0.5353977]]\n",
      "PERDIDAAAA despues: 0.11575774103403091\n",
      "loss en el callback: 0.19344332814216614, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.47861737]\n",
      " [0.48645937]\n",
      " [0.49439269]\n",
      " [0.50220251]\n",
      " [0.50969571]\n",
      " [0.51709914]\n",
      " [0.52452058]\n",
      " [0.53306967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.54178685]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.47861737]\n",
      "  [0.48645937]\n",
      "  [0.49439269]\n",
      "  [0.50220251]\n",
      "  [0.50969571]\n",
      "  [0.51709914]\n",
      "  [0.52452058]\n",
      "  [0.53306967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09431590139865875\n",
      "Predicción post entrenamiento : [[0.543798]]\n",
      "PERDIDAAAA despues: 0.09308464080095291\n",
      "loss en el callback: 0.11439111828804016, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.48645937]\n",
      " [0.49439269]\n",
      " [0.50220251]\n",
      " [0.50969571]\n",
      " [0.51709914]\n",
      " [0.52452058]\n",
      " [0.53306967]\n",
      " [0.54178685]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5502712]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.48645937]\n",
      "  [0.49439269]\n",
      "  [0.50220251]\n",
      "  [0.50969571]\n",
      "  [0.51709914]\n",
      "  [0.52452058]\n",
      "  [0.53306967]\n",
      "  [0.54178685]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07183272391557693\n",
      "Predicción post entrenamiento : [[0.5519193]]\n",
      "PERDIDAAAA despues: 0.07095202058553696\n",
      "loss en el callback: 0.06522730737924576, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.49439269]\n",
      " [0.50220251]\n",
      " [0.50969571]\n",
      " [0.51709914]\n",
      " [0.52452058]\n",
      " [0.53306967]\n",
      " [0.54178685]\n",
      " [0.55027121]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5584133]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.49439269]\n",
      "  [0.50220251]\n",
      "  [0.50969571]\n",
      "  [0.51709914]\n",
      "  [0.52452058]\n",
      "  [0.53306967]\n",
      "  [0.54178685]\n",
      "  [0.55027121]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0720374807715416\n",
      "Predicción post entrenamiento : [[0.5600327]]\n",
      "PERDIDAAAA despues: 0.07117081433534622\n",
      "loss en el callback: 0.06647580116987228, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.50220251]\n",
      " [0.50969571]\n",
      " [0.51709914]\n",
      " [0.52452058]\n",
      " [0.53306967]\n",
      " [0.54178685]\n",
      " [0.55027121]\n",
      " [0.55841333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.56653666]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.50220251]\n",
      "  [0.50969571]\n",
      "  [0.51709914]\n",
      "  [0.52452058]\n",
      "  [0.53306967]\n",
      "  [0.54178685]\n",
      "  [0.55027121]\n",
      "  [0.55841333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047881241887807846\n",
      "Predicción post entrenamiento : [[0.5677039]]\n",
      "PERDIDAAAA despues: 0.04737177863717079\n",
      "loss en el callback: 0.031302351504564285, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.50969571]\n",
      " [0.51709914]\n",
      " [0.52452058]\n",
      " [0.53306967]\n",
      " [0.54178685]\n",
      " [0.55027121]\n",
      " [0.55841333]\n",
      " [0.56653666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.57426673]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.50969571]\n",
      "  [0.51709914]\n",
      "  [0.52452058]\n",
      "  [0.53306967]\n",
      "  [0.54178685]\n",
      "  [0.55027121]\n",
      "  [0.55841333]\n",
      "  [0.56653666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04620876535773277\n",
      "Predicción post entrenamiento : [[0.575759]]\n",
      "PERDIDAAAA despues: 0.04556943476200104\n",
      "loss en el callback: 0.05583757162094116, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.51709914]\n",
      " [0.52452058]\n",
      " [0.53306967]\n",
      " [0.54178685]\n",
      " [0.55027121]\n",
      " [0.55841333]\n",
      " [0.56653666]\n",
      " [0.57426673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5824916]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.51709914]\n",
      "  [0.52452058]\n",
      "  [0.53306967]\n",
      "  [0.54178685]\n",
      "  [0.55027121]\n",
      "  [0.55841333]\n",
      "  [0.56653666]\n",
      "  [0.57426673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06334342807531357\n",
      "Predicción post entrenamiento : [[0.5841528]]\n",
      "PERDIDAAAA despues: 0.06250998377799988\n",
      "loss en el callback: 0.06515556573867798, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.52452058]\n",
      " [0.53306967]\n",
      " [0.54178685]\n",
      " [0.55027121]\n",
      " [0.55841333]\n",
      " [0.56653666]\n",
      " [0.57426673]\n",
      " [0.58249158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5911142]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.52452058]\n",
      "  [0.53306967]\n",
      "  [0.54178685]\n",
      "  [0.55027121]\n",
      "  [0.55841333]\n",
      "  [0.56653666]\n",
      "  [0.57426673]\n",
      "  [0.58249158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049000948667526245\n",
      "Predicción post entrenamiento : [[0.5923863]]\n",
      "PERDIDAAAA despues: 0.0484393872320652\n",
      "loss en el callback: 0.040821708738803864, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.53306967]\n",
      " [0.54178685]\n",
      " [0.55027121]\n",
      " [0.55841333]\n",
      " [0.56653666]\n",
      " [0.57426673]\n",
      " [0.58249158]\n",
      " [0.59111422]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5996049]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.53306967]\n",
      "  [0.54178685]\n",
      "  [0.55027121]\n",
      "  [0.55841333]\n",
      "  [0.56653666]\n",
      "  [0.57426673]\n",
      "  [0.58249158]\n",
      "  [0.59111422]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04065664857625961\n",
      "Predicción post entrenamiento : [[0.600914]]\n",
      "PERDIDAAAA despues: 0.04013044387102127\n",
      "loss en el callback: 0.04838401451706886, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.54178685]\n",
      " [0.55027121]\n",
      " [0.55841333]\n",
      " [0.56653666]\n",
      " [0.57426673]\n",
      " [0.58249158]\n",
      " [0.59111422]\n",
      " [0.5996049 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.60810167]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.54178685]\n",
      "  [0.55027121]\n",
      "  [0.55841333]\n",
      "  [0.56653666]\n",
      "  [0.57426673]\n",
      "  [0.58249158]\n",
      "  [0.59111422]\n",
      "  [0.5996049 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03805441036820412\n",
      "Predicción post entrenamiento : [[0.60925686]]\n",
      "PERDIDAAAA despues: 0.03760504350066185\n",
      "loss en el callback: 0.03494351729750633, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.55027121]\n",
      " [0.55841333]\n",
      " [0.56653666]\n",
      " [0.57426673]\n",
      " [0.58249158]\n",
      " [0.59111422]\n",
      " [0.5996049 ]\n",
      " [0.60810167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.61635256]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.55027121]\n",
      "  [0.55841333]\n",
      "  [0.56653666]\n",
      "  [0.57426673]\n",
      "  [0.58249158]\n",
      "  [0.59111422]\n",
      "  [0.5996049 ]\n",
      "  [0.60810167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03137798607349396\n",
      "Predicción post entrenamiento : [[0.61777717]]\n",
      "PERDIDAAAA despues: 0.0308753103017807\n",
      "loss en el callback: 0.06622237712144852, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.55841333]\n",
      " [0.56653666]\n",
      " [0.57426673]\n",
      " [0.58249158]\n",
      " [0.59111422]\n",
      " [0.5996049 ]\n",
      " [0.60810167]\n",
      " [0.61635256]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6248316]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.55841333]\n",
      "  [0.56653666]\n",
      "  [0.57426673]\n",
      "  [0.58249158]\n",
      "  [0.59111422]\n",
      "  [0.5996049 ]\n",
      "  [0.60810167]\n",
      "  [0.61635256]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01831660233438015\n",
      "Predicción post entrenamiento : [[0.62585837]]\n",
      "PERDIDAAAA despues: 0.01803973875939846\n",
      "loss en el callback: 0.032786399126052856, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.56653666]\n",
      " [0.57426673]\n",
      " [0.58249158]\n",
      " [0.59111422]\n",
      " [0.5996049 ]\n",
      " [0.60810167]\n",
      " [0.61635256]\n",
      " [0.62483162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.63296646]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.56653666]\n",
      "  [0.57426673]\n",
      "  [0.58249158]\n",
      "  [0.59111422]\n",
      "  [0.5996049 ]\n",
      "  [0.60810167]\n",
      "  [0.61635256]\n",
      "  [0.62483162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010487287305295467\n",
      "Predicción post entrenamiento : [[0.63414466]]\n",
      "PERDIDAAAA despues: 0.010247360914945602\n",
      "loss en el callback: 0.05544721335172653, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.57426673]\n",
      " [0.58249158]\n",
      " [0.59111422]\n",
      " [0.5996049 ]\n",
      " [0.60810167]\n",
      " [0.61635256]\n",
      " [0.62483162]\n",
      " [0.63296646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.64132434]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.57426673]\n",
      "  [0.58249158]\n",
      "  [0.59111422]\n",
      "  [0.5996049 ]\n",
      "  [0.60810167]\n",
      "  [0.61635256]\n",
      "  [0.62483162]\n",
      "  [0.63296646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004742454271763563\n",
      "Predicción post entrenamiento : [[0.64175904]]\n",
      "PERDIDAAAA despues: 0.004682771861553192\n",
      "loss en el callback: 0.004824787378311157, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.58249158]\n",
      " [0.59111422]\n",
      " [0.5996049 ]\n",
      " [0.60810167]\n",
      " [0.61635256]\n",
      " [0.62483162]\n",
      " [0.63296646]\n",
      " [0.64132434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.64913356]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.58249158]\n",
      "  [0.59111422]\n",
      "  [0.5996049 ]\n",
      "  [0.60810167]\n",
      "  [0.61635256]\n",
      "  [0.62483162]\n",
      "  [0.63296646]\n",
      "  [0.64132434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003968184348195791\n",
      "Predicción post entrenamiento : [[0.64974463]]\n",
      "PERDIDAAAA despues: 0.003891571192070842\n",
      "loss en el callback: 0.01055152527987957, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.59111422]\n",
      " [0.5996049 ]\n",
      " [0.60810167]\n",
      " [0.61635256]\n",
      " [0.62483162]\n",
      " [0.63296646]\n",
      " [0.64132434]\n",
      " [0.64913356]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6571932]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.59111422]\n",
      "  [0.5996049 ]\n",
      "  [0.60810167]\n",
      "  [0.61635256]\n",
      "  [0.62483162]\n",
      "  [0.63296646]\n",
      "  [0.64132434]\n",
      "  [0.64913356]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006796788889914751\n",
      "Predicción post entrenamiento : [[0.6577079]]\n",
      "PERDIDAAAA despues: 0.006712180096656084\n",
      "loss en el callback: 0.007058001589030027, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.5996049 ]\n",
      " [0.60810167]\n",
      " [0.61635256]\n",
      " [0.62483162]\n",
      " [0.63296646]\n",
      " [0.64132434]\n",
      " [0.64913356]\n",
      " [0.65719318]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.66511106]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.5996049 ]\n",
      "  [0.60810167]\n",
      "  [0.61635256]\n",
      "  [0.62483162]\n",
      "  [0.63296646]\n",
      "  [0.64132434]\n",
      "  [0.64913356]\n",
      "  [0.65719318]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005046356003731489\n",
      "Predicción post entrenamiento : [[0.664835]]\n",
      "PERDIDAAAA despues: 0.005085657816380262\n",
      "loss en el callback: 0.0016692520584911108, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.60810167]\n",
      " [0.61635256]\n",
      " [0.62483162]\n",
      " [0.63296646]\n",
      " [0.64132434]\n",
      " [0.64913356]\n",
      " [0.65719318]\n",
      " [0.66511106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6722035]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.60810167]\n",
      "  [0.61635256]\n",
      "  [0.62483162]\n",
      "  [0.63296646]\n",
      "  [0.64132434]\n",
      "  [0.64913356]\n",
      "  [0.65719318]\n",
      "  [0.66511106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.1462567019625567e-05\n",
      "Predicción post entrenamiento : [[0.6723433]]\n",
      "PERDIDAAAA despues: 2.2777743652113713e-05\n",
      "loss en el callback: 0.0005760795902460814, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.61635256]\n",
      " [0.62483162]\n",
      " [0.63296646]\n",
      " [0.64132434]\n",
      " [0.64913356]\n",
      " [0.65719318]\n",
      " [0.66511106]\n",
      " [0.67220348]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6796508]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.61635256]\n",
      "  [0.62483162]\n",
      "  [0.63296646]\n",
      "  [0.64132434]\n",
      "  [0.64913356]\n",
      "  [0.65719318]\n",
      "  [0.66511106]\n",
      "  [0.67220348]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.516729915048927e-05\n",
      "Predicción post entrenamiento : [[0.67948055]]\n",
      "PERDIDAAAA despues: 9.187495015794411e-05\n",
      "loss en el callback: 0.0007650202023796737, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.62483162]\n",
      " [0.63296646]\n",
      " [0.64132434]\n",
      " [0.64913356]\n",
      " [0.65719318]\n",
      " [0.66511106]\n",
      " [0.67220348]\n",
      " [0.67965078]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.68676424]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.62483162]\n",
      "  [0.63296646]\n",
      "  [0.64132434]\n",
      "  [0.64913356]\n",
      "  [0.65719318]\n",
      "  [0.66511106]\n",
      "  [0.67220348]\n",
      "  [0.67965078]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.731794852996245e-05\n",
      "Predicción post entrenamiento : [[0.68666214]]\n",
      "PERDIDAAAA despues: 9.934285480994731e-05\n",
      "loss en el callback: 0.000273348530754447, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.63296646]\n",
      " [0.64132434]\n",
      " [0.64913356]\n",
      " [0.65719318]\n",
      " [0.66511106]\n",
      " [0.67220348]\n",
      " [0.67965078]\n",
      " [0.68676424]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.693822]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.63296646]\n",
      "  [0.64132434]\n",
      "  [0.64913356]\n",
      "  [0.65719318]\n",
      "  [0.66511106]\n",
      "  [0.67220348]\n",
      "  [0.67965078]\n",
      "  [0.68676424]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014344927622005343\n",
      "Predicción post entrenamiento : [[0.6934937]]\n",
      "PERDIDAAAA despues: 0.0014097319217398763\n",
      "loss en el callback: 0.0028462130576372147, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.64132434]\n",
      " [0.64913356]\n",
      " [0.65719318]\n",
      " [0.66511106]\n",
      " [0.67220348]\n",
      " [0.67965078]\n",
      " [0.68676424]\n",
      " [0.69382203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.70058167]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.64132434]\n",
      "  [0.64913356]\n",
      "  [0.65719318]\n",
      "  [0.66511106]\n",
      "  [0.67220348]\n",
      "  [0.67965078]\n",
      "  [0.68676424]\n",
      "  [0.69382203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004741509328596294\n",
      "Predicción post entrenamiento : [[0.7001209]]\n",
      "PERDIDAAAA despues: 0.0004542978131212294\n",
      "loss en el callback: 0.005724767688661814, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.64913356]\n",
      " [0.65719318]\n",
      " [0.66511106]\n",
      " [0.67220348]\n",
      " [0.67965078]\n",
      " [0.68676424]\n",
      " [0.69382203]\n",
      " [0.70058167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7070266]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.64913356]\n",
      "  [0.65719318]\n",
      "  [0.66511106]\n",
      "  [0.67220348]\n",
      "  [0.67965078]\n",
      "  [0.68676424]\n",
      "  [0.69382203]\n",
      "  [0.70058167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009567929082550108\n",
      "Predicción post entrenamiento : [[0.7063216]]\n",
      "PERDIDAAAA despues: 0.000913675467018038\n",
      "loss en el callback: 0.011843561194837093, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.65719318]\n",
      " [0.66511106]\n",
      " [0.67220348]\n",
      " [0.67965078]\n",
      " [0.68676424]\n",
      " [0.69382203]\n",
      " [0.70058167]\n",
      " [0.7070266 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7131459]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.65719318]\n",
      "  [0.66511106]\n",
      "  [0.67220348]\n",
      "  [0.67965078]\n",
      "  [0.68676424]\n",
      "  [0.69382203]\n",
      "  [0.70058167]\n",
      "  [0.7070266 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002694933209568262\n",
      "Predicción post entrenamiento : [[0.7136377]]\n",
      "PERDIDAAAA despues: 0.0002535882231313735\n",
      "loss en el callback: 0.008256645873188972, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.66511106]\n",
      " [0.67220348]\n",
      " [0.67965078]\n",
      " [0.68676424]\n",
      " [0.69382203]\n",
      " [0.70058167]\n",
      " [0.7070266 ]\n",
      " [0.71314591]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.72026086]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.66511106]\n",
      "  [0.67220348]\n",
      "  [0.67965078]\n",
      "  [0.68676424]\n",
      "  [0.69382203]\n",
      "  [0.70058167]\n",
      "  [0.7070266 ]\n",
      "  [0.71314591]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003603273944463581\n",
      "Predicción post entrenamiento : [[0.7205776]]\n",
      "PERDIDAAAA despues: 0.00037245257408358157\n",
      "loss en el callback: 0.0035156565718352795, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.67220348]\n",
      " [0.67965078]\n",
      " [0.68676424]\n",
      " [0.69382203]\n",
      " [0.70058167]\n",
      " [0.7070266 ]\n",
      " [0.71314591]\n",
      " [0.72026086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.72697914]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.67220348]\n",
      "  [0.67965078]\n",
      "  [0.68676424]\n",
      "  [0.69382203]\n",
      "  [0.70058167]\n",
      "  [0.7070266 ]\n",
      "  [0.71314591]\n",
      "  [0.72026086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001644534058868885\n",
      "Predicción post entrenamiento : [[0.72680783]]\n",
      "PERDIDAAAA despues: 0.0016584570985287428\n",
      "loss en el callback: 0.0007047408143989742, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.67965078]\n",
      " [0.68676424]\n",
      " [0.69382203]\n",
      " [0.70058167]\n",
      " [0.7070266 ]\n",
      " [0.71314591]\n",
      " [0.72026086]\n",
      " [0.72697914]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7331765]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.67965078]\n",
      "  [0.68676424]\n",
      "  [0.69382203]\n",
      "  [0.70058167]\n",
      "  [0.7070266 ]\n",
      "  [0.71314591]\n",
      "  [0.72026086]\n",
      "  [0.72697914]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00048211682587862015\n",
      "Predicción post entrenamiento : [[0.73314583]]\n",
      "PERDIDAAAA despues: 0.00048346578842028975\n",
      "loss en el callback: 2.8053844289388508e-05, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.68676424]\n",
      " [0.69382203]\n",
      " [0.70058167]\n",
      " [0.7070266 ]\n",
      " [0.71314591]\n",
      " [0.72026086]\n",
      " [0.72697914]\n",
      " [0.73317653]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7393499]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.68676424]\n",
      "  [0.69382203]\n",
      "  [0.70058167]\n",
      "  [0.7070266 ]\n",
      "  [0.71314591]\n",
      "  [0.72026086]\n",
      "  [0.72697914]\n",
      "  [0.73317653]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.2605526939732954e-05\n",
      "Predicción post entrenamiento : [[0.7385466]]\n",
      "PERDIDAAAA despues: 4.242459908709861e-05\n",
      "loss en el callback: 0.015332885086536407, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.69382203]\n",
      " [0.70058167]\n",
      " [0.7070266 ]\n",
      " [0.71314591]\n",
      " [0.72026086]\n",
      " [0.72697914]\n",
      " [0.73317653]\n",
      " [0.7393499 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.74464035]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.69382203]\n",
      "  [0.70058167]\n",
      "  [0.7070266 ]\n",
      "  [0.71314591]\n",
      "  [0.72026086]\n",
      "  [0.72697914]\n",
      "  [0.73317653]\n",
      "  [0.7393499 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.4667063523083925e-05\n",
      "Predicción post entrenamiento : [[0.74531066]]\n",
      "PERDIDAAAA despues: 4.5204160414868966e-05\n",
      "loss en el callback: 0.018269650638103485, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.70058167]\n",
      " [0.7070266 ]\n",
      " [0.71314591]\n",
      " [0.72026086]\n",
      " [0.72697914]\n",
      " [0.73317653]\n",
      " [0.7393499 ]\n",
      " [0.74464035]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7512774]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.70058167]\n",
      "  [0.7070266 ]\n",
      "  [0.71314591]\n",
      "  [0.72026086]\n",
      "  [0.72697914]\n",
      "  [0.73317653]\n",
      "  [0.7393499 ]\n",
      "  [0.74464035]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001720175496302545\n",
      "Predicción post entrenamiento : [[0.7510242]]\n",
      "PERDIDAAAA despues: 0.0016992365708574653\n",
      "loss en el callback: 0.0019636538345366716, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.7070266 ]\n",
      " [0.71314591]\n",
      " [0.72026086]\n",
      " [0.72697914]\n",
      " [0.73317653]\n",
      " [0.7393499 ]\n",
      " [0.74464035]\n",
      " [0.75127739]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.75691456]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.7070266 ]\n",
      "  [0.71314591]\n",
      "  [0.72026086]\n",
      "  [0.72697914]\n",
      "  [0.73317653]\n",
      "  [0.7393499 ]\n",
      "  [0.74464035]\n",
      "  [0.75127739]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004420190118253231\n",
      "Predicción post entrenamiento : [[0.75668126]]\n",
      "PERDIDAAAA despues: 0.004389224108308554\n",
      "loss en el callback: 0.0017650662921369076, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.71314591]\n",
      " [0.72026086]\n",
      " [0.72697914]\n",
      " [0.73317653]\n",
      " [0.7393499 ]\n",
      " [0.74464035]\n",
      " [0.75127739]\n",
      " [0.75691456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.76256096]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.71314591]\n",
      "  [0.72026086]\n",
      "  [0.72697914]\n",
      "  [0.73317653]\n",
      "  [0.7393499 ]\n",
      "  [0.74464035]\n",
      "  [0.75127739]\n",
      "  [0.75691456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.727600703015924e-05\n",
      "Predicción post entrenamiento : [[0.7624396]]\n",
      "PERDIDAAAA despues: 6.529997335746884e-05\n",
      "loss en el callback: 0.00047279949649237096, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.72026086]\n",
      " [0.72697914]\n",
      " [0.73317653]\n",
      " [0.7393499 ]\n",
      " [0.74464035]\n",
      " [0.75127739]\n",
      " [0.75691456]\n",
      " [0.76256096]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.768383]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.72026086]\n",
      "  [0.72697914]\n",
      "  [0.73317653]\n",
      "  [0.7393499 ]\n",
      "  [0.74464035]\n",
      "  [0.75127739]\n",
      "  [0.75691456]\n",
      "  [0.76256096]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021328080911189318\n",
      "Predicción post entrenamiento : [[0.76834464]]\n",
      "PERDIDAAAA despues: 0.0021292639430612326\n",
      "loss en el callback: 4.852674464927986e-05, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.72697914]\n",
      " [0.73317653]\n",
      " [0.7393499 ]\n",
      " [0.74464035]\n",
      " [0.75127739]\n",
      " [0.75691456]\n",
      " [0.76256096]\n",
      " [0.76838303]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7740337]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.72697914]\n",
      "  [0.73317653]\n",
      "  [0.7393499 ]\n",
      "  [0.74464035]\n",
      "  [0.75127739]\n",
      "  [0.75691456]\n",
      "  [0.76256096]\n",
      "  [0.76838303]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005546471104025841\n",
      "Predicción post entrenamiento : [[0.7748269]]\n",
      "PERDIDAAAA despues: 0.0054289596155285835\n",
      "loss en el callback: 0.02469124272465706, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.73317653]\n",
      " [0.7393499 ]\n",
      " [0.74464035]\n",
      " [0.75127739]\n",
      " [0.75691456]\n",
      " [0.76256096]\n",
      " [0.76838303]\n",
      " [0.77403373]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7803242]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.73317653]\n",
      "  [0.7393499 ]\n",
      "  [0.74464035]\n",
      "  [0.75127739]\n",
      "  [0.75691456]\n",
      "  [0.76256096]\n",
      "  [0.76838303]\n",
      "  [0.77403373]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01565970852971077\n",
      "Predicción post entrenamiento : [[0.7810702]]\n",
      "PERDIDAAAA despues: 0.015473570674657822\n",
      "loss en el callback: 0.018167460337281227, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.7393499 ]\n",
      " [0.74464035]\n",
      " [0.75127739]\n",
      " [0.75691456]\n",
      " [0.76256096]\n",
      " [0.76838303]\n",
      " [0.77403373]\n",
      " [0.78032422]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7864937]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.7393499 ]\n",
      "  [0.74464035]\n",
      "  [0.75127739]\n",
      "  [0.75691456]\n",
      "  [0.76256096]\n",
      "  [0.76838303]\n",
      "  [0.77403373]\n",
      "  [0.78032422]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009162796661257744\n",
      "Predicción post entrenamiento : [[0.78763336]]\n",
      "PERDIDAAAA despues: 0.008945916779339314\n",
      "loss en el callback: 0.05261204391717911, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.74464035]\n",
      " [0.75127739]\n",
      " [0.75691456]\n",
      " [0.76256096]\n",
      " [0.76838303]\n",
      " [0.77403373]\n",
      " [0.78032422]\n",
      " [0.78649372]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.79297775]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.74464035]\n",
      "  [0.75127739]\n",
      "  [0.75691456]\n",
      "  [0.76256096]\n",
      "  [0.76838303]\n",
      "  [0.77403373]\n",
      "  [0.78032422]\n",
      "  [0.78649372]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013181320391595364\n",
      "Predicción post entrenamiento : [[0.7936229]]\n",
      "PERDIDAAAA despues: 0.013033594936132431\n",
      "loss en el callback: 0.013009408488869667, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.75127739]\n",
      " [0.75691456]\n",
      " [0.76256096]\n",
      " [0.76838303]\n",
      " [0.77403373]\n",
      " [0.78032422]\n",
      " [0.78649372]\n",
      " [0.79297775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.79915106]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.75127739]\n",
      "  [0.75691456]\n",
      "  [0.76256096]\n",
      "  [0.76838303]\n",
      "  [0.77403373]\n",
      "  [0.78032422]\n",
      "  [0.78649372]\n",
      "  [0.79297775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008176974020898342\n",
      "Predicción post entrenamiento : [[0.79994875]]\n",
      "PERDIDAAAA despues: 0.008033346384763718\n",
      "loss en el callback: 0.02336222119629383, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.75691456]\n",
      " [0.76256096]\n",
      " [0.76838303]\n",
      " [0.77403373]\n",
      " [0.78032422]\n",
      " [0.78649372]\n",
      " [0.79297775]\n",
      " [0.79915106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8052832]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.75691456]\n",
      "  [0.76256096]\n",
      "  [0.76838303]\n",
      "  [0.77403373]\n",
      "  [0.78032422]\n",
      "  [0.78649372]\n",
      "  [0.79297775]\n",
      "  [0.79915106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004840192850679159\n",
      "Predicción post entrenamiento : [[0.8053231]]\n",
      "PERDIDAAAA despues: 0.004834637977182865\n",
      "loss en el callback: 4.39877767348662e-05, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.76256096]\n",
      " [0.76838303]\n",
      " [0.77403373]\n",
      " [0.78032422]\n",
      " [0.78649372]\n",
      " [0.79297775]\n",
      " [0.79915106]\n",
      " [0.80528319]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8107513]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.76256096]\n",
      "  [0.76838303]\n",
      "  [0.77403373]\n",
      "  [0.78032422]\n",
      "  [0.78649372]\n",
      "  [0.79297775]\n",
      "  [0.79915106]\n",
      "  [0.80528319]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010498179122805595\n",
      "Predicción post entrenamiento : [[0.8112265]]\n",
      "PERDIDAAAA despues: 0.010401032865047455\n",
      "loss en el callback: 0.0073358966037631035, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.76838303]\n",
      " [0.77403373]\n",
      " [0.78032422]\n",
      " [0.78649372]\n",
      " [0.79297775]\n",
      " [0.79915106]\n",
      " [0.80528319]\n",
      " [0.81075132]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8167705]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.76838303]\n",
      "  [0.77403373]\n",
      "  [0.78032422]\n",
      "  [0.78649372]\n",
      "  [0.79297775]\n",
      "  [0.79915106]\n",
      "  [0.80528319]\n",
      "  [0.81075132]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033573050051927567\n",
      "Predicción post entrenamiento : [[0.81799424]]\n",
      "PERDIDAAAA despues: 0.0331260971724987\n",
      "loss en el callback: 0.05418238416314125, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.77403373]\n",
      " [0.78032422]\n",
      " [0.78649372]\n",
      " [0.79297775]\n",
      " [0.79915106]\n",
      " [0.80528319]\n",
      " [0.81075132]\n",
      " [0.81677049]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8236224]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.77403373]\n",
      "  [0.78032422]\n",
      "  [0.78649372]\n",
      "  [0.79297775]\n",
      "  [0.79915106]\n",
      "  [0.80528319]\n",
      "  [0.81075132]\n",
      "  [0.81677049]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02158890850841999\n",
      "Predicción post entrenamiento : [[0.8243561]]\n",
      "PERDIDAAAA despues: 0.021373847499489784\n",
      "loss en el callback: 0.016666600480675697, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.78032422]\n",
      " [0.78649372]\n",
      " [0.79297775]\n",
      " [0.79915106]\n",
      " [0.80528319]\n",
      " [0.81075132]\n",
      " [0.81677049]\n",
      " [0.82362241]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8301339]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.78032422]\n",
      "  [0.78649372]\n",
      "  [0.79297775]\n",
      "  [0.79915106]\n",
      "  [0.80528319]\n",
      "  [0.81075132]\n",
      "  [0.81677049]\n",
      "  [0.82362241]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003442034125328064\n",
      "Predicción post entrenamiento : [[0.83053994]]\n",
      "PERDIDAAAA despues: 0.003394556697458029\n",
      "loss en el callback: 0.0061699403449893, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.78649372]\n",
      " [0.79297775]\n",
      " [0.79915106]\n",
      " [0.80528319]\n",
      " [0.81075132]\n",
      " [0.81677049]\n",
      " [0.82362241]\n",
      " [0.83013391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.83629185]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.78649372]\n",
      "  [0.79297775]\n",
      "  [0.79915106]\n",
      "  [0.80528319]\n",
      "  [0.81075132]\n",
      "  [0.81677049]\n",
      "  [0.82362241]\n",
      "  [0.83013391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017357601318508387\n",
      "Predicción post entrenamiento : [[0.8371025]]\n",
      "PERDIDAAAA despues: 0.0016688720788806677\n",
      "loss en el callback: 0.027029646560549736, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.79297775]\n",
      " [0.79915106]\n",
      " [0.80528319]\n",
      " [0.81075132]\n",
      " [0.81677049]\n",
      " [0.82362241]\n",
      " [0.83013391]\n",
      " [0.83629185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8428625]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.79297775]\n",
      "  [0.79915106]\n",
      "  [0.80528319]\n",
      "  [0.81075132]\n",
      "  [0.81677049]\n",
      "  [0.82362241]\n",
      "  [0.83013391]\n",
      "  [0.83629185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.640072463895194e-05\n",
      "Predicción post entrenamiento : [[0.8432096]]\n",
      "PERDIDAAAA despues: 3.233246025047265e-05\n",
      "loss en el callback: 0.004401647951453924, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.79915106]\n",
      " [0.80528319]\n",
      " [0.81075132]\n",
      " [0.81677049]\n",
      " [0.82362241]\n",
      " [0.83013391]\n",
      " [0.83629185]\n",
      " [0.84286249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8488853]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.79915106]\n",
      "  [0.80528319]\n",
      "  [0.81075132]\n",
      "  [0.81677049]\n",
      "  [0.82362241]\n",
      "  [0.83013391]\n",
      "  [0.83629185]\n",
      "  [0.84286249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021645802189595997\n",
      "Predicción post entrenamiento : [[0.8483148]]\n",
      "PERDIDAAAA despues: 0.00019999720097985119\n",
      "loss en el callback: 0.009021880105137825, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.80528319]\n",
      " [0.81075132]\n",
      " [0.81677049]\n",
      " [0.82362241]\n",
      " [0.83013391]\n",
      " [0.83629185]\n",
      " [0.84286249]\n",
      " [0.8488853 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.85399514]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.80528319]\n",
      "  [0.81075132]\n",
      "  [0.81677049]\n",
      "  [0.82362241]\n",
      "  [0.83013391]\n",
      "  [0.83629185]\n",
      "  [0.84286249]\n",
      "  [0.8488853 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2094836847609258e-06\n",
      "Predicción post entrenamiento : [[0.8544241]]\n",
      "PERDIDAAAA despues: 4.499601118368446e-07\n",
      "loss en el callback: 0.007433769758790731, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.81075132]\n",
      " [0.81677049]\n",
      " [0.82362241]\n",
      " [0.83013391]\n",
      " [0.83629185]\n",
      " [0.84286249]\n",
      " [0.8488853 ]\n",
      " [0.85399514]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.860128]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.81075132]\n",
      "  [0.81677049]\n",
      "  [0.82362241]\n",
      "  [0.83013391]\n",
      "  [0.83629185]\n",
      "  [0.84286249]\n",
      "  [0.8488853 ]\n",
      "  [0.85399514]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022843868646305054\n",
      "Predicción post entrenamiento : [[0.8604742]]\n",
      "PERDIDAAAA despues: 0.00021809218742419034\n",
      "loss en el callback: 0.0050244806334376335, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.81677049]\n",
      " [0.82362241]\n",
      " [0.83013391]\n",
      " [0.83629185]\n",
      " [0.84286249]\n",
      " [0.8488853 ]\n",
      " [0.85399514]\n",
      " [0.86012799]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.86640793]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.81677049]\n",
      "  [0.82362241]\n",
      "  [0.83013391]\n",
      "  [0.83629185]\n",
      "  [0.84286249]\n",
      "  [0.8488853 ]\n",
      "  [0.85399514]\n",
      "  [0.86012799]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.79047074704431e-05\n",
      "Predicción post entrenamiento : [[0.8656905]]\n",
      "PERDIDAAAA despues: 7.496701437048614e-05\n",
      "loss en el callback: 0.014687379822134972, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.82362241]\n",
      " [0.83013391]\n",
      " [0.83629185]\n",
      " [0.84286249]\n",
      " [0.8488853 ]\n",
      " [0.85399514]\n",
      " [0.86012799]\n",
      " [0.86640793]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.87170273]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.82362241]\n",
      "  [0.83013391]\n",
      "  [0.83629185]\n",
      "  [0.84286249]\n",
      "  [0.8488853 ]\n",
      "  [0.85399514]\n",
      "  [0.86012799]\n",
      "  [0.86640793]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00046848837519064546\n",
      "Predicción post entrenamiento : [[0.8717496]]\n",
      "PERDIDAAAA despues: 0.00047051862929947674\n",
      "loss en el callback: 7.604638085467741e-05, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.83013391]\n",
      " [0.83629185]\n",
      " [0.84286249]\n",
      " [0.8488853 ]\n",
      " [0.85399514]\n",
      " [0.86012799]\n",
      " [0.86640793]\n",
      " [0.87170273]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8775715]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.83013391]\n",
      "  [0.83629185]\n",
      "  [0.84286249]\n",
      "  [0.8488853 ]\n",
      "  [0.85399514]\n",
      "  [0.86012799]\n",
      "  [0.86640793]\n",
      "  [0.87170273]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012162597849965096\n",
      "Predicción post entrenamiento : [[0.87793195]]\n",
      "PERDIDAAAA despues: 0.001241529593244195\n",
      "loss en el callback: 0.00538563821464777, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.83629185]\n",
      " [0.84286249]\n",
      " [0.8488853 ]\n",
      " [0.85399514]\n",
      " [0.86012799]\n",
      " [0.86640793]\n",
      " [0.87170273]\n",
      " [0.87757152]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.88362134]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.83629185]\n",
      "  [0.84286249]\n",
      "  [0.8488853 ]\n",
      "  [0.85399514]\n",
      "  [0.86012799]\n",
      "  [0.86640793]\n",
      "  [0.87170273]\n",
      "  [0.87757152]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036826087161898613\n",
      "Predicción post entrenamiento : [[0.88352364]]\n",
      "PERDIDAAAA despues: 0.0036707615945488214\n",
      "loss en el callback: 0.00035816733725368977, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.84286249]\n",
      " [0.8488853 ]\n",
      " [0.85399514]\n",
      " [0.86012799]\n",
      " [0.86640793]\n",
      " [0.87170273]\n",
      " [0.87757152]\n",
      " [0.88362134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.88915616]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.84286249]\n",
      "  [0.8488853 ]\n",
      "  [0.85399514]\n",
      "  [0.86012799]\n",
      "  [0.86640793]\n",
      "  [0.87170273]\n",
      "  [0.87757152]\n",
      "  [0.88362134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013144652359187603\n",
      "Predicción post entrenamiento : [[0.8890069]]\n",
      "PERDIDAAAA despues: 0.013110451400279999\n",
      "loss en el callback: 0.0009503986220806837, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.8488853 ]\n",
      " [0.85399514]\n",
      " [0.86012799]\n",
      " [0.86640793]\n",
      " [0.87170273]\n",
      " [0.87757152]\n",
      " [0.88362134]\n",
      " [0.88915616]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.89443463]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.8488853 ]\n",
      "  [0.85399514]\n",
      "  [0.86012799]\n",
      "  [0.86640793]\n",
      "  [0.87170273]\n",
      "  [0.87757152]\n",
      "  [0.88362134]\n",
      "  [0.88915616]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01215340569615364\n",
      "Predicción post entrenamiento : [[0.8944263]]\n",
      "PERDIDAAAA despues: 0.012151566334068775\n",
      "loss en el callback: 3.1985082387109287e-06, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.85399514]\n",
      " [0.86012799]\n",
      " [0.86640793]\n",
      " [0.87170273]\n",
      " [0.87757152]\n",
      " [0.88362134]\n",
      " [0.88915616]\n",
      " [0.89443463]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8997841]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.85399514]\n",
      "  [0.86012799]\n",
      "  [0.86640793]\n",
      "  [0.87170273]\n",
      "  [0.87757152]\n",
      "  [0.88362134]\n",
      "  [0.88915616]\n",
      "  [0.89443463]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001603183802217245\n",
      "Predicción post entrenamiento : [[0.89939743]]\n",
      "PERDIDAAAA despues: 0.0015723700635135174\n",
      "loss en el callback: 0.004946429748088121, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.86012799]\n",
      " [0.86640793]\n",
      " [0.87170273]\n",
      " [0.87757152]\n",
      " [0.88362134]\n",
      " [0.88915616]\n",
      " [0.89443463]\n",
      " [0.89978409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9049535]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.86012799]\n",
      "  [0.86640793]\n",
      "  [0.87170273]\n",
      "  [0.87757152]\n",
      "  [0.88362134]\n",
      "  [0.88915616]\n",
      "  [0.89443463]\n",
      "  [0.89978409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002563744317740202\n",
      "Predicción post entrenamiento : [[0.904943]]\n",
      "PERDIDAAAA despues: 0.002562682144343853\n",
      "loss en el callback: 4.630188414012082e-06, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.86640793]\n",
      " [0.87170273]\n",
      " [0.87757152]\n",
      " [0.88362134]\n",
      " [0.88915616]\n",
      " [0.89443463]\n",
      " [0.89978409]\n",
      " [0.90495348]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9103914]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.86640793]\n",
      "  [0.87170273]\n",
      "  [0.87757152]\n",
      "  [0.88362134]\n",
      "  [0.88915616]\n",
      "  [0.89443463]\n",
      "  [0.89978409]\n",
      "  [0.90495348]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005403201561421156\n",
      "Predicción post entrenamiento : [[0.9092843]]\n",
      "PERDIDAAAA despues: 0.005241669714450836\n",
      "loss en el callback: 0.03716806694865227, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.87170273]\n",
      " [0.87757152]\n",
      " [0.88362134]\n",
      " [0.88915616]\n",
      " [0.89443463]\n",
      " [0.89978409]\n",
      " [0.90495348]\n",
      " [0.91039139]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.914543]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.87170273]\n",
      "  [0.87757152]\n",
      "  [0.88362134]\n",
      "  [0.88915616]\n",
      "  [0.89443463]\n",
      "  [0.89978409]\n",
      "  [0.90495348]\n",
      "  [0.91039139]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0071625919081270695\n",
      "Predicción post entrenamiento : [[0.9132191]]\n",
      "PERDIDAAAA despues: 0.006940259598195553\n",
      "loss en el callback: 0.0552353709936142, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.87757152]\n",
      " [0.88362134]\n",
      " [0.88915616]\n",
      " [0.89443463]\n",
      " [0.89978409]\n",
      " [0.90495348]\n",
      " [0.91039139]\n",
      " [0.91454297]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.91854733]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.87757152]\n",
      "  [0.88362134]\n",
      "  [0.88915616]\n",
      "  [0.89443463]\n",
      "  [0.89978409]\n",
      "  [0.90495348]\n",
      "  [0.91039139]\n",
      "  [0.91454297]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009793360950425267\n",
      "Predicción post entrenamiento : [[0.91867244]]\n",
      "PERDIDAAAA despues: 0.0009871822549030185\n",
      "loss en el callback: 0.0006283799884840846, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.88362134]\n",
      " [0.88915616]\n",
      " [0.89443463]\n",
      " [0.89978409]\n",
      " [0.90495348]\n",
      " [0.91039139]\n",
      " [0.91454297]\n",
      " [0.91854733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9238729]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.88362134]\n",
      "  [0.88915616]\n",
      "  [0.89443463]\n",
      "  [0.89978409]\n",
      "  [0.90495348]\n",
      "  [0.91039139]\n",
      "  [0.91454297]\n",
      "  [0.91854733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004112474620342255\n",
      "Predicción post entrenamiento : [[0.9227048]]\n",
      "PERDIDAAAA despues: 0.0039640250615775585\n",
      "loss en el callback: 0.04184490814805031, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.88915616]\n",
      " [0.89443463]\n",
      " [0.89978409]\n",
      " [0.90495348]\n",
      " [0.91039139]\n",
      " [0.91454297]\n",
      " [0.91854733]\n",
      " [0.92387289]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.92766684]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.88915616]\n",
      "  [0.89443463]\n",
      "  [0.89978409]\n",
      "  [0.90495348]\n",
      "  [0.91039139]\n",
      "  [0.91454297]\n",
      "  [0.91854733]\n",
      "  [0.92387289]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007756289094686508\n",
      "Predicción post entrenamiento : [[0.9262198]]\n",
      "PERDIDAAAA despues: 0.007503504864871502\n",
      "loss en el callback: 0.06150439754128456, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.89443463]\n",
      " [0.89978409]\n",
      " [0.90495348]\n",
      " [0.91039139]\n",
      " [0.91454297]\n",
      " [0.91854733]\n",
      " [0.92387289]\n",
      " [0.92766684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.93103784]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.89443463]\n",
      "  [0.89978409]\n",
      "  [0.90495348]\n",
      "  [0.91039139]\n",
      "  [0.91454297]\n",
      "  [0.91854733]\n",
      "  [0.92387289]\n",
      "  [0.92766684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021677594631910324\n",
      "Predicción post entrenamiento : [[0.9302125]]\n",
      "PERDIDAAAA despues: 0.021435238420963287\n",
      "loss en el callback: 0.024064641445875168, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.89978409]\n",
      " [0.90495348]\n",
      " [0.91039139]\n",
      " [0.91454297]\n",
      " [0.91854733]\n",
      " [0.92387289]\n",
      " [0.92766684]\n",
      " [0.93103784]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9349117]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.89978409]\n",
      "  [0.90495348]\n",
      "  [0.91039139]\n",
      "  [0.91454297]\n",
      "  [0.91854733]\n",
      "  [0.92387289]\n",
      "  [0.92766684]\n",
      "  [0.93103784]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0136012127622962\n",
      "Predicción post entrenamiento : [[0.93411326]]\n",
      "PERDIDAAAA despues: 0.013415609486401081\n",
      "loss en el callback: 0.023408398032188416, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.90495348]\n",
      " [0.91039139]\n",
      " [0.91454297]\n",
      " [0.91854733]\n",
      " [0.92387289]\n",
      " [0.92766684]\n",
      " [0.93103784]\n",
      " [0.93491173]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.938615]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.90495348]\n",
      "  [0.91039139]\n",
      "  [0.91454297]\n",
      "  [0.91854733]\n",
      "  [0.92387289]\n",
      "  [0.92766684]\n",
      "  [0.93103784]\n",
      "  [0.93491173]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02174115926027298\n",
      "Predicción post entrenamiento : [[0.93702835]]\n",
      "PERDIDAAAA despues: 0.021275769919157028\n",
      "loss en el callback: 0.07770485430955887, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.91039139]\n",
      " [0.91454297]\n",
      " [0.91854733]\n",
      " [0.92387289]\n",
      " [0.92766684]\n",
      " [0.93103784]\n",
      " [0.93491173]\n",
      " [0.93861502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9413203]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.91039139]\n",
      "  [0.91454297]\n",
      "  [0.91854733]\n",
      "  [0.92387289]\n",
      "  [0.92766684]\n",
      "  [0.93103784]\n",
      "  [0.93491173]\n",
      "  [0.93861502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03267502784729004\n",
      "Predicción post entrenamiento : [[0.940457]]\n",
      "PERDIDAAAA despues: 0.032363664358854294\n",
      "loss en el callback: 0.03208057954907417, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.91454297]\n",
      " [0.91854733]\n",
      " [0.92387289]\n",
      " [0.92766684]\n",
      " [0.93103784]\n",
      " [0.93491173]\n",
      " [0.93861502]\n",
      " [0.9413203 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9443864]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.91454297]\n",
      "  [0.91854733]\n",
      "  [0.92387289]\n",
      "  [0.92766684]\n",
      "  [0.93103784]\n",
      "  [0.93491173]\n",
      "  [0.93861502]\n",
      "  [0.9413203 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023357847705483437\n",
      "Predicción post entrenamiento : [[0.94323033]]\n",
      "PERDIDAAAA despues: 0.023005807772278786\n",
      "loss en el callback: 0.0457540899515152, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.91854733]\n",
      " [0.92387289]\n",
      " [0.92766684]\n",
      " [0.93103784]\n",
      " [0.93491173]\n",
      " [0.93861502]\n",
      " [0.9413203 ]\n",
      " [0.94438642]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9471115]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.91854733]\n",
      "  [0.92387289]\n",
      "  [0.92766684]\n",
      "  [0.93103784]\n",
      "  [0.93491173]\n",
      "  [0.93861502]\n",
      "  [0.9413203 ]\n",
      "  [0.94438642]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03183269873261452\n",
      "Predicción post entrenamiento : [[0.9458132]]\n",
      "PERDIDAAAA despues: 0.0313711054623127\n",
      "loss en el callback: 0.05786392092704773, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.92387289]\n",
      " [0.92766684]\n",
      " [0.93103784]\n",
      " [0.93491173]\n",
      " [0.93861502]\n",
      " [0.9413203 ]\n",
      " [0.94438642]\n",
      " [0.94711149]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.94964606]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.92387289]\n",
      "  [0.92766684]\n",
      "  [0.93103784]\n",
      "  [0.93491173]\n",
      "  [0.93861502]\n",
      "  [0.9413203 ]\n",
      "  [0.94438642]\n",
      "  [0.94711149]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03274354338645935\n",
      "Predicción post entrenamiento : [[0.94938844]]\n",
      "PERDIDAAAA despues: 0.032650381326675415\n",
      "loss en el callback: 0.003413370344787836, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.92766684]\n",
      " [0.93103784]\n",
      " [0.93491173]\n",
      " [0.93861502]\n",
      " [0.9413203 ]\n",
      " [0.94438642]\n",
      " [0.94711149]\n",
      " [0.94964606]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.95270777]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.92766684]\n",
      "  [0.93103784]\n",
      "  [0.93491173]\n",
      "  [0.93861502]\n",
      "  [0.9413203 ]\n",
      "  [0.94438642]\n",
      "  [0.94711149]\n",
      "  [0.94964606]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023652169853448868\n",
      "Predicción post entrenamiento : [[0.9506462]]\n",
      "PERDIDAAAA despues: 0.02302231825888157\n",
      "loss en el callback: 0.12863022089004517, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93103784]\n",
      " [0.93491173]\n",
      " [0.93861502]\n",
      " [0.9413203 ]\n",
      " [0.94438642]\n",
      " [0.94711149]\n",
      " [0.94964606]\n",
      " [0.95270777]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.95382166]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93103784]\n",
      "  [0.93491173]\n",
      "  [0.93861502]\n",
      "  [0.9413203 ]\n",
      "  [0.94438642]\n",
      "  [0.94711149]\n",
      "  [0.94964606]\n",
      "  [0.95270777]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02683625929057598\n",
      "Predicción post entrenamiento : [[0.9526052]]\n",
      "PERDIDAAAA despues: 0.026439180597662926\n",
      "loss en el callback: 0.05277456343173981, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93491173]\n",
      " [0.93861502]\n",
      " [0.9413203 ]\n",
      " [0.94438642]\n",
      " [0.94711149]\n",
      " [0.94964606]\n",
      " [0.95270777]\n",
      " [0.95382166]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9557142]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93491173]\n",
      "  [0.93861502]\n",
      "  [0.9413203 ]\n",
      "  [0.94438642]\n",
      "  [0.94711149]\n",
      "  [0.94964606]\n",
      "  [0.95270777]\n",
      "  [0.95382166]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03823736310005188\n",
      "Predicción post entrenamiento : [[0.9532998]]\n",
      "PERDIDAAAA despues: 0.03729895129799843\n",
      "loss en el callback: 0.17994871735572815, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.93861502]\n",
      " [0.9413203 ]\n",
      " [0.94438642]\n",
      " [0.94711149]\n",
      " [0.94964606]\n",
      " [0.95270777]\n",
      " [0.95382166]\n",
      " [0.95571423]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9561323]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.93861502]\n",
      "  [0.9413203 ]\n",
      "  [0.94438642]\n",
      "  [0.94711149]\n",
      "  [0.94964606]\n",
      "  [0.95270777]\n",
      "  [0.95382166]\n",
      "  [0.95571423]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07329961657524109\n",
      "Predicción post entrenamiento : [[0.9549613]]\n",
      "PERDIDAAAA despues: 0.07266692072153091\n",
      "loss en el callback: 0.05947215110063553, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.9413203 ]\n",
      " [0.94438642]\n",
      " [0.94711149]\n",
      " [0.94964606]\n",
      " [0.95270777]\n",
      " [0.95382166]\n",
      " [0.95571423]\n",
      " [0.95613229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9574831]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.9413203 ]\n",
      "  [0.94438642]\n",
      "  [0.94711149]\n",
      "  [0.94964606]\n",
      "  [0.95270777]\n",
      "  [0.95382166]\n",
      "  [0.95571423]\n",
      "  [0.95613229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1241091936826706\n",
      "Predicción post entrenamiento : [[0.9564697]]\n",
      "PERDIDAAAA despues: 0.12339619547128677\n",
      "loss en el callback: 0.05512308329343796, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94438642]\n",
      " [0.94711149]\n",
      " [0.94964606]\n",
      " [0.95270777]\n",
      " [0.95382166]\n",
      " [0.95571423]\n",
      " [0.95613229]\n",
      " [0.95748311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9588998]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94438642]\n",
      "  [0.94711149]\n",
      "  [0.94964606]\n",
      "  [0.95270777]\n",
      "  [0.95382166]\n",
      "  [0.95571423]\n",
      "  [0.95613229]\n",
      "  [0.95748311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08646024018526077\n",
      "Predicción post entrenamiento : [[0.95824426]]\n",
      "PERDIDAAAA despues: 0.08607515692710876\n",
      "loss en el callback: 0.023389961570501328, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.94711149]\n",
      " [0.94964606]\n",
      " [0.95270777]\n",
      " [0.95382166]\n",
      " [0.95571423]\n",
      " [0.95613229]\n",
      " [0.95748311]\n",
      " [0.9588998 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.96040624]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.94711149]\n",
      "  [0.94964606]\n",
      "  [0.95270777]\n",
      "  [0.95382166]\n",
      "  [0.95571423]\n",
      "  [0.95613229]\n",
      "  [0.95748311]\n",
      "  [0.9588998 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06377699226140976\n",
      "Predicción post entrenamiento : [[0.9590497]]\n",
      "PERDIDAAAA despues: 0.06309366226196289\n",
      "loss en el callback: 0.07809353619813919, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.94964606]\n",
      " [0.95270777]\n",
      " [0.95382166]\n",
      " [0.95571423]\n",
      " [0.95613229]\n",
      " [0.95748311]\n",
      " [0.9588998 ]\n",
      " [0.96040624]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.96096516]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.94964606]\n",
      "  [0.95270777]\n",
      "  [0.95382166]\n",
      "  [0.95571423]\n",
      "  [0.95613229]\n",
      "  [0.95748311]\n",
      "  [0.9588998 ]\n",
      "  [0.96040624]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08767910301685333\n",
      "Predicción post entrenamiento : [[0.95858854]]\n",
      "PERDIDAAAA despues: 0.08627729117870331\n",
      "loss en el callback: 0.19987648725509644, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.95270777]\n",
      " [0.95382166]\n",
      " [0.95571423]\n",
      " [0.95613229]\n",
      " [0.95748311]\n",
      " [0.9588998 ]\n",
      " [0.96040624]\n",
      " [0.96096516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9602396]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.95270777]\n",
      "  [0.95382166]\n",
      "  [0.95571423]\n",
      "  [0.95613229]\n",
      "  [0.95748311]\n",
      "  [0.9588998 ]\n",
      "  [0.96040624]\n",
      "  [0.96096516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06194494664669037\n",
      "Predicción post entrenamiento : [[0.95900494]]\n",
      "PERDIDAAAA despues: 0.061331894248723984\n",
      "loss en el callback: 0.06846582144498825, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.95382166]\n",
      " [0.95571423]\n",
      " [0.95613229]\n",
      " [0.95748311]\n",
      " [0.9588998 ]\n",
      " [0.96040624]\n",
      " [0.96096516]\n",
      " [0.96023959]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.96014726]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.95382166]\n",
      "  [0.95571423]\n",
      "  [0.95613229]\n",
      "  [0.95748311]\n",
      "  [0.9588998 ]\n",
      "  [0.96040624]\n",
      "  [0.96096516]\n",
      "  [0.96023959]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08002696931362152\n",
      "Predicción post entrenamiento : [[0.9591123]]\n",
      "PERDIDAAAA despues: 0.07944247126579285\n",
      "loss en el callback: 0.053239110857248306, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.95571423]\n",
      " [0.95613229]\n",
      " [0.95748311]\n",
      " [0.9588998 ]\n",
      " [0.96040624]\n",
      " [0.96096516]\n",
      " [0.96023959]\n",
      " [0.96014726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9602472]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.95571423]\n",
      "  [0.95613229]\n",
      "  [0.95748311]\n",
      "  [0.9588998 ]\n",
      "  [0.96040624]\n",
      "  [0.96096516]\n",
      "  [0.96023959]\n",
      "  [0.96014726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03925925865769386\n",
      "Predicción post entrenamiento : [[0.9602303]]\n",
      "PERDIDAAAA despues: 0.03925254940986633\n",
      "loss en el callback: 1.8122247638530098e-05, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.95613229]\n",
      " [0.95748311]\n",
      " [0.9588998 ]\n",
      " [0.96040624]\n",
      " [0.96096516]\n",
      " [0.96023959]\n",
      " [0.96014726]\n",
      " [0.96024722]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.96107775]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.95613229]\n",
      "  [0.95748311]\n",
      "  [0.9588998 ]\n",
      "  [0.96040624]\n",
      "  [0.96096516]\n",
      "  [0.96023959]\n",
      "  [0.96014726]\n",
      "  [0.96024722]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02372407354414463\n",
      "Predicción post entrenamiento : [[0.96022356]]\n",
      "PERDIDAAAA despues: 0.023461665958166122\n",
      "loss en el callback: 0.03269147127866745, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.95748311]\n",
      " [0.9588998 ]\n",
      " [0.96040624]\n",
      " [0.96096516]\n",
      " [0.96023959]\n",
      " [0.96014726]\n",
      " [0.96024722]\n",
      " [0.96107775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9611709]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.95748311]\n",
      "  [0.9588998 ]\n",
      "  [0.96040624]\n",
      "  [0.96096516]\n",
      "  [0.96023959]\n",
      "  [0.96014726]\n",
      "  [0.96024722]\n",
      "  [0.96107775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02131102979183197\n",
      "Predicción post entrenamiento : [[0.9602435]]\n",
      "PERDIDAAAA despues: 0.021041125059127808\n",
      "loss en el callback: 0.03821391612291336, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.9588998 ]\n",
      " [0.96040624]\n",
      " [0.96096516]\n",
      " [0.96023959]\n",
      " [0.96014726]\n",
      " [0.96024722]\n",
      " [0.96107775]\n",
      " [0.96117091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9609789]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.9588998 ]\n",
      "  [0.96040624]\n",
      "  [0.96096516]\n",
      "  [0.96023959]\n",
      "  [0.96014726]\n",
      "  [0.96024722]\n",
      "  [0.96107775]\n",
      "  [0.96117091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029965797439217567\n",
      "Predicción post entrenamiento : [[0.96109605]]\n",
      "PERDIDAAAA despues: 0.0030094163957983255\n",
      "loss en el callback: 0.0007455015438608825, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.96040624]\n",
      " [0.96096516]\n",
      " [0.96023959]\n",
      " [0.96014726]\n",
      " [0.96024722]\n",
      " [0.96107775]\n",
      " [0.96117091]\n",
      " [0.96097893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.96153575]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.96040624]\n",
      "  [0.96096516]\n",
      "  [0.96023959]\n",
      "  [0.96014726]\n",
      "  [0.96024722]\n",
      "  [0.96107775]\n",
      "  [0.96117091]\n",
      "  [0.96097893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.349706048538792e-06\n",
      "Predicción post entrenamiento : [[0.9618723]]\n",
      "PERDIDAAAA despues: 4.694797098636627e-06\n",
      "loss en el callback: 0.006825063843280077, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.96096516]\n",
      " [0.96023959]\n",
      " [0.96014726]\n",
      " [0.96024722]\n",
      " [0.96107775]\n",
      " [0.96117091]\n",
      " [0.96097893]\n",
      " [0.96153575]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9619282]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.96096516]\n",
      "  [0.96023959]\n",
      "  [0.96014726]\n",
      "  [0.96024722]\n",
      "  [0.96107775]\n",
      "  [0.96117091]\n",
      "  [0.96097893]\n",
      "  [0.96153575]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.888794930797303e-06\n",
      "Predicción post entrenamiento : [[0.9622204]]\n",
      "PERDIDAAAA despues: 4.556098701868905e-06\n",
      "loss en el callback: 0.00505975354462862, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.96023959]\n",
      " [0.96014726]\n",
      " [0.96024722]\n",
      " [0.96107775]\n",
      " [0.96117091]\n",
      " [0.96097893]\n",
      " [0.96153575]\n",
      " [0.96192819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9621358]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.96023959]\n",
      "  [0.96014726]\n",
      "  [0.96024722]\n",
      "  [0.96107775]\n",
      "  [0.96117091]\n",
      "  [0.96097893]\n",
      "  [0.96153575]\n",
      "  [0.96192819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0054919784888625145\n",
      "Predicción post entrenamiento : [[0.9624022]]\n",
      "PERDIDAAAA despues: 0.005531539209187031\n",
      "loss en el callback: 0.004420245531946421, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.96014726]\n",
      " [0.96024722]\n",
      " [0.96107775]\n",
      " [0.96117091]\n",
      " [0.96097893]\n",
      " [0.96153575]\n",
      " [0.96192819]\n",
      " [0.96213579]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.96257144]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.96014726]\n",
      "  [0.96024722]\n",
      "  [0.96107775]\n",
      "  [0.96117091]\n",
      "  [0.96097893]\n",
      "  [0.96153575]\n",
      "  [0.96192819]\n",
      "  [0.96213579]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004885198548436165\n",
      "Predicción post entrenamiento : [[0.962232]]\n",
      "PERDIDAAAA despues: 0.004837862681597471\n",
      "loss en el callback: 0.005773133598268032, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.96024722]\n",
      " [0.96107775]\n",
      " [0.96117091]\n",
      " [0.96097893]\n",
      " [0.96153575]\n",
      " [0.96192819]\n",
      " [0.96213579]\n",
      " [0.96257144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9625033]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.96024722]\n",
      "  [0.96107775]\n",
      "  [0.96117091]\n",
      "  [0.96097893]\n",
      "  [0.96153575]\n",
      "  [0.96192819]\n",
      "  [0.96213579]\n",
      "  [0.96257144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007614506408572197\n",
      "Predicción post entrenamiento : [[0.9613562]]\n",
      "PERDIDAAAA despues: 0.007415629457682371\n",
      "loss en el callback: 0.053337212651968, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.96107775]\n",
      " [0.96117091]\n",
      " [0.96097893]\n",
      " [0.96153575]\n",
      " [0.96192819]\n",
      " [0.96213579]\n",
      " [0.96257144]\n",
      " [0.96250331]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9616844]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.96107775]\n",
      "  [0.96117091]\n",
      "  [0.96097893]\n",
      "  [0.96153575]\n",
      "  [0.96192819]\n",
      "  [0.96213579]\n",
      "  [0.96257144]\n",
      "  [0.96250331]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01228803489357233\n",
      "Predicción post entrenamiento : [[0.96127295]]\n",
      "PERDIDAAAA despues: 0.012196984142065048\n",
      "loss en el callback: 0.009217376820743084, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.96117091]\n",
      " [0.96097893]\n",
      " [0.96153575]\n",
      " [0.96192819]\n",
      " [0.96213579]\n",
      " [0.96257144]\n",
      " [0.96250331]\n",
      " [0.96168441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9614282]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.96117091]\n",
      "  [0.96097893]\n",
      "  [0.96153575]\n",
      "  [0.96192819]\n",
      "  [0.96213579]\n",
      "  [0.96257144]\n",
      "  [0.96250331]\n",
      "  [0.96168441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012663549743592739\n",
      "Predicción post entrenamiento : [[0.9612043]]\n",
      "PERDIDAAAA despues: 0.012613199651241302\n",
      "loss en el callback: 0.0028593740426003933, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.96097893]\n",
      " [0.96153575]\n",
      " [0.96192819]\n",
      " [0.96213579]\n",
      " [0.96257144]\n",
      " [0.96250331]\n",
      " [0.96168441]\n",
      " [0.96142823]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9613814]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.96097893]\n",
      "  [0.96153575]\n",
      "  [0.96192819]\n",
      "  [0.96213579]\n",
      "  [0.96257144]\n",
      "  [0.96250331]\n",
      "  [0.96168441]\n",
      "  [0.96142823]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0738893934103544e-06\n",
      "Predicción post entrenamiento : [[0.9619238]]\n",
      "PERDIDAAAA despues: 2.439214767946396e-07\n",
      "loss en el callback: 0.021938329562544823, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.96153575]\n",
      " [0.96192819]\n",
      " [0.96213579]\n",
      " [0.96257144]\n",
      " [0.96250331]\n",
      " [0.96168441]\n",
      " [0.96142823]\n",
      " [0.96138138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9622008]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.96153575]\n",
      "  [0.96192819]\n",
      "  [0.96213579]\n",
      "  [0.96257144]\n",
      "  [0.96250331]\n",
      "  [0.96168441]\n",
      "  [0.96142823]\n",
      "  [0.96138138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.182204090990126e-05\n",
      "Predicción post entrenamiento : [[0.9624062]]\n",
      "PERDIDAAAA despues: 2.9546890800702386e-05\n",
      "loss en el callback: 0.0026977660600095987, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.96192819]\n",
      " [0.96213579]\n",
      " [0.96257144]\n",
      " [0.96250331]\n",
      " [0.96168441]\n",
      " [0.96142823]\n",
      " [0.96138138]\n",
      " [0.96220082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.96255124]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.96192819]\n",
      "  [0.96213579]\n",
      "  [0.96257144]\n",
      "  [0.96250331]\n",
      "  [0.96168441]\n",
      "  [0.96142823]\n",
      "  [0.96138138]\n",
      "  [0.96220082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00047657330287620425\n",
      "Predicción post entrenamiento : [[0.96288836]]\n",
      "PERDIDAAAA despues: 0.0004914061282761395\n",
      "loss en el callback: 0.007181390188634396, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.96213579]\n",
      " [0.96257144]\n",
      " [0.96250331]\n",
      " [0.96168441]\n",
      " [0.96142823]\n",
      " [0.96138138]\n",
      " [0.96220082]\n",
      " [0.96255124]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9629252]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.96213579]\n",
      "  [0.96257144]\n",
      "  [0.96250331]\n",
      "  [0.96168441]\n",
      "  [0.96142823]\n",
      "  [0.96138138]\n",
      "  [0.96220082]\n",
      "  [0.96255124]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.150966798188165e-05\n",
      "Predicción post entrenamiento : [[0.9633203]]\n",
      "PERDIDAAAA despues: 8.410631562583148e-05\n",
      "loss en el callback: 0.009415742941200733, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.96257144]\n",
      " [0.96250331]\n",
      " [0.96168441]\n",
      " [0.96142823]\n",
      " [0.96138138]\n",
      " [0.96220082]\n",
      " [0.96255124]\n",
      " [0.9629252 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9632939]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.96257144]\n",
      "  [0.96250331]\n",
      "  [0.96168441]\n",
      "  [0.96142823]\n",
      "  [0.96138138]\n",
      "  [0.96220082]\n",
      "  [0.96255124]\n",
      "  [0.9629252 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011293988209217787\n",
      "Predicción post entrenamiento : [[0.96398854]]\n",
      "PERDIDAAAA despues: 0.0010831929976120591\n",
      "loss en el callback: 0.03392113745212555, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.96250331]\n",
      " [0.96168441]\n",
      " [0.96142823]\n",
      " [0.96138138]\n",
      " [0.96220082]\n",
      " [0.96255124]\n",
      " [0.9629252 ]\n",
      " [0.96329391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9638305]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.96250331]\n",
      "  [0.96168441]\n",
      "  [0.96142823]\n",
      "  [0.96138138]\n",
      "  [0.96220082]\n",
      "  [0.96255124]\n",
      "  [0.9629252 ]\n",
      "  [0.96329391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001599911629455164\n",
      "Predicción post entrenamiento : [[0.96370625]]\n",
      "PERDIDAAAA despues: 0.0001568642328493297\n",
      "loss en el callback: 0.0008811862790025771, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.96168441]\n",
      " [0.96142823]\n",
      " [0.96138138]\n",
      " [0.96220082]\n",
      " [0.96255124]\n",
      " [0.9629252 ]\n",
      " [0.96329391]\n",
      " [0.96383047]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.96357715]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.96168441]\n",
      "  [0.96142823]\n",
      "  [0.96138138]\n",
      "  [0.96220082]\n",
      "  [0.96255124]\n",
      "  [0.9629252 ]\n",
      "  [0.96329391]\n",
      "  [0.96383047]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004596886690706015\n",
      "Predicción post entrenamiento : [[0.9632318]]\n",
      "PERDIDAAAA despues: 0.004550176206976175\n",
      "loss en el callback: 0.0062029543332755566, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.96142823]\n",
      " [0.96138138]\n",
      " [0.96220082]\n",
      " [0.96255124]\n",
      " [0.9629252 ]\n",
      " [0.96329391]\n",
      " [0.96383047]\n",
      " [0.96357715]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9633912]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.96142823]\n",
      "  [0.96138138]\n",
      "  [0.96220082]\n",
      "  [0.96255124]\n",
      "  [0.9629252 ]\n",
      "  [0.96329391]\n",
      "  [0.96383047]\n",
      "  [0.96357715]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006715784315019846\n",
      "Predicción post entrenamiento : [[0.96281856]]\n",
      "PERDIDAAAA despues: 0.006622259505093098\n",
      "loss en el callback: 0.016136670485138893, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.96138138]\n",
      " [0.96220082]\n",
      " [0.96255124]\n",
      " [0.9629252 ]\n",
      " [0.96329391]\n",
      " [0.96383047]\n",
      " [0.96357715]\n",
      " [0.96339118]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9631395]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.96138138]\n",
      "  [0.96220082]\n",
      "  [0.96255124]\n",
      "  [0.9629252 ]\n",
      "  [0.96329391]\n",
      "  [0.96383047]\n",
      "  [0.96357715]\n",
      "  [0.96339118]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002120883669704199\n",
      "Predicción post entrenamiento : [[0.96308374]]\n",
      "PERDIDAAAA despues: 0.0021157534793019295\n",
      "loss en el callback: 0.00019947827968280762, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.96220082]\n",
      " [0.96255124]\n",
      " [0.9629252 ]\n",
      " [0.96329391]\n",
      " [0.96383047]\n",
      " [0.96357715]\n",
      " [0.96339118]\n",
      " [0.96313947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.96351635]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.96220082]\n",
      "  [0.96255124]\n",
      "  [0.9629252 ]\n",
      "  [0.96329391]\n",
      "  [0.96383047]\n",
      "  [0.96357715]\n",
      "  [0.96339118]\n",
      "  [0.96313947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019112462177872658\n",
      "Predicción post entrenamiento : [[0.9621756]]\n",
      "PERDIDAAAA despues: 0.0017958147218450904\n",
      "loss en el callback: 0.07241346687078476, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.96255124]\n",
      " [0.9629252 ]\n",
      " [0.96329391]\n",
      " [0.96383047]\n",
      " [0.96357715]\n",
      " [0.96339118]\n",
      " [0.96313947]\n",
      " [0.96351635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.96244925]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.96255124]\n",
      "  [0.9629252 ]\n",
      "  [0.96329391]\n",
      "  [0.96383047]\n",
      "  [0.96357715]\n",
      "  [0.96339118]\n",
      "  [0.96313947]\n",
      "  [0.96351635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.503629492726759e-07\n",
      "Predicción post entrenamiento : [[0.96267587]]\n",
      "PERDIDAAAA despues: 1.067228822648758e-06\n",
      "loss en el callback: 0.003792052622884512, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.9629252 ]\n",
      " [0.96329391]\n",
      " [0.96383047]\n",
      " [0.96357715]\n",
      " [0.96339118]\n",
      " [0.96313947]\n",
      " [0.96351635]\n",
      " [0.96244925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.96289355]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.9629252 ]\n",
      "  [0.96329391]\n",
      "  [0.96383047]\n",
      "  [0.96357715]\n",
      "  [0.96339118]\n",
      "  [0.96313947]\n",
      "  [0.96351635]\n",
      "  [0.96244925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.8470843972172588e-05\n",
      "Predicción post entrenamiento : [[0.96313167]]\n",
      "PERDIDAAAA despues: 2.5986415494116955e-05\n",
      "loss en el callback: 0.003478097729384899, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.96329391]\n",
      " [0.96383047]\n",
      " [0.96357715]\n",
      " [0.96339118]\n",
      " [0.96313947]\n",
      " [0.96351635]\n",
      " [0.96244925]\n",
      " [0.96289355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9632612]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.96329391]\n",
      "  [0.96383047]\n",
      "  [0.96357715]\n",
      "  [0.96339118]\n",
      "  [0.96313947]\n",
      "  [0.96351635]\n",
      "  [0.96244925]\n",
      "  [0.96289355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.017157723661512e-05\n",
      "Predicción post entrenamiento : [[0.9627047]]\n",
      "PERDIDAAAA despues: 2.436801696603652e-05\n",
      "loss en el callback: 0.015100193209946156, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22102536]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03059672750532627\n",
      "Predicción post entrenamiento : [[0.18913792]]\n",
      "PERDIDAAAA despues: 0.02045808546245098\n",
      "loss en el callback: 0.0375087708234787, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22102536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17344287]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22102536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004791366867721081\n",
      "Predicción post entrenamiento : [[0.16360319]]\n",
      "PERDIDAAAA despues: 0.003525986336171627\n",
      "loss en el callback: 0.0044912537559866905, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22102536]\n",
      " [0.17344287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1672552]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22102536]\n",
      "  [0.17344287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017033879703376442\n",
      "Predicción post entrenamiento : [[0.16583174]]\n",
      "PERDIDAAAA despues: 0.00013520904758479446\n",
      "loss en el callback: 0.00021769055456388742, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22102536]\n",
      " [0.17344287]\n",
      " [0.16725519]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17654261]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22102536]\n",
      "  [0.17344287]\n",
      "  [0.16725519]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043218364589847624\n",
      "Predicción post entrenamiento : [[0.17445979]]\n",
      "PERDIDAAAA despues: 0.0003499220183584839\n",
      "loss en el callback: 0.0007952820742502809, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22102536]\n",
      " [0.17344287]\n",
      " [0.16725519]\n",
      " [0.17654261]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18596789]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22102536]\n",
      "  [0.17344287]\n",
      "  [0.16725519]\n",
      "  [0.17654261]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003652406856417656\n",
      "Predicción post entrenamiento : [[0.1841897]]\n",
      "PERDIDAAAA despues: 0.00344063900411129\n",
      "loss en el callback: 0.001085103489458561, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22102536]\n",
      " [0.17344287]\n",
      " [0.16725519]\n",
      " [0.17654261]\n",
      " [0.18596789]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19254424]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22102536]\n",
      "  [0.17344287]\n",
      "  [0.16725519]\n",
      "  [0.17654261]\n",
      "  [0.18596789]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021962597966194153\n",
      "Predicción post entrenamiento : [[0.18817954]]\n",
      "PERDIDAAAA despues: 0.0018062136368826032\n",
      "loss en el callback: 0.005547280889004469, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.22102536]\n",
      " [0.17344287]\n",
      " [0.16725519]\n",
      " [0.17654261]\n",
      " [0.18596789]\n",
      " [0.19254424]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20705338]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22102536]\n",
      "  [0.17344287]\n",
      "  [0.16725519]\n",
      "  [0.17654261]\n",
      "  [0.18596789]\n",
      "  [0.19254424]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036721809301525354\n",
      "Predicción post entrenamiento : [[0.20326279]]\n",
      "PERDIDAAAA despues: 0.0032271414529532194\n",
      "loss en el callback: 0.006037350744009018, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.22102536]\n",
      " [0.17344287]\n",
      " [0.16725519]\n",
      " [0.17654261]\n",
      " [0.18596789]\n",
      " [0.19254424]\n",
      " [0.20705338]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22612916]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.22102536]\n",
      "  [0.17344287]\n",
      "  [0.16725519]\n",
      "  [0.17654261]\n",
      "  [0.18596789]\n",
      "  [0.19254424]\n",
      "  [0.20705338]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009048739448189735\n",
      "Predicción post entrenamiento : [[0.22488536]]\n",
      "PERDIDAAAA despues: 0.000831591198220849\n",
      "loss en el callback: 0.0009441997390240431, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.22102536]\n",
      " [0.17344287]\n",
      " [0.16725519]\n",
      " [0.17654261]\n",
      " [0.18596789]\n",
      " [0.19254424]\n",
      " [0.20705338]\n",
      " [0.22612916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2521376]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.22102536]\n",
      "  [0.17344287]\n",
      "  [0.16725519]\n",
      "  [0.17654261]\n",
      "  [0.18596789]\n",
      "  [0.19254424]\n",
      "  [0.20705338]\n",
      "  [0.22612916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00046685393317602575\n",
      "Predicción post entrenamiento : [[0.25257257]]\n",
      "PERDIDAAAA despues: 0.0004858395259361714\n",
      "loss en el callback: 0.00016818071890156716, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17344287]\n",
      " [0.16725519]\n",
      " [0.17654261]\n",
      " [0.18596789]\n",
      " [0.19254424]\n",
      " [0.20705338]\n",
      " [0.22612916]\n",
      " [0.2521376 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24576306]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17344287]\n",
      "  [0.16725519]\n",
      "  [0.17654261]\n",
      "  [0.18596789]\n",
      "  [0.19254424]\n",
      "  [0.20705338]\n",
      "  [0.22612916]\n",
      "  [0.2521376 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013925379607826471\n",
      "Predicción post entrenamiento : [[0.24431403]]\n",
      "PERDIDAAAA despues: 0.00128649128600955\n",
      "loss en el callback: 0.0019245522562414408, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16725519]\n",
      " [0.17654261]\n",
      " [0.18596789]\n",
      " [0.19254424]\n",
      " [0.20705338]\n",
      " [0.22612916]\n",
      " [0.2521376 ]\n",
      " [0.24576306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24805543]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16725519]\n",
      "  [0.17654261]\n",
      "  [0.18596789]\n",
      "  [0.19254424]\n",
      "  [0.20705338]\n",
      "  [0.22612916]\n",
      "  [0.2521376 ]\n",
      "  [0.24576306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013048038817942142\n",
      "Predicción post entrenamiento : [[0.24625133]]\n",
      "PERDIDAAAA despues: 0.001177723053842783\n",
      "loss en el callback: 0.0031106944661587477, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17654261]\n",
      " [0.18596789]\n",
      " [0.19254424]\n",
      " [0.20705338]\n",
      " [0.22612916]\n",
      " [0.2521376 ]\n",
      " [0.24576306]\n",
      " [0.24805543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25335464]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17654261]\n",
      "  [0.18596789]\n",
      "  [0.19254424]\n",
      "  [0.20705338]\n",
      "  [0.22612916]\n",
      "  [0.2521376 ]\n",
      "  [0.24576306]\n",
      "  [0.24805543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002122503472492099\n",
      "Predicción post entrenamiento : [[0.2519951]]\n",
      "PERDIDAAAA despues: 0.001999080879613757\n",
      "loss en el callback: 0.0023716643918305635, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18596789]\n",
      " [0.19254424]\n",
      " [0.20705338]\n",
      " [0.22612916]\n",
      " [0.2521376 ]\n",
      " [0.24576306]\n",
      " [0.24805543]\n",
      " [0.25335464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25956705]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18596789]\n",
      "  [0.19254424]\n",
      "  [0.20705338]\n",
      "  [0.22612916]\n",
      "  [0.2521376 ]\n",
      "  [0.24576306]\n",
      "  [0.24805543]\n",
      "  [0.25335464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004438034724444151\n",
      "Predicción post entrenamiento : [[0.25822756]]\n",
      "PERDIDAAAA despues: 0.004261358641088009\n",
      "loss en el callback: 0.0027700134087353945, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.19254424]\n",
      " [0.20705338]\n",
      " [0.22612916]\n",
      " [0.2521376 ]\n",
      " [0.24576306]\n",
      " [0.24805543]\n",
      " [0.25335464]\n",
      " [0.25956705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26618764]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.19254424]\n",
      "  [0.20705338]\n",
      "  [0.22612916]\n",
      "  [0.2521376 ]\n",
      "  [0.24576306]\n",
      "  [0.24805543]\n",
      "  [0.25335464]\n",
      "  [0.25956705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004811461083590984\n",
      "Predicción post entrenamiento : [[0.2645835]]\n",
      "PERDIDAAAA despues: 0.004591492936015129\n",
      "loss en el callback: 0.004385930951684713, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20705338]\n",
      " [0.22612916]\n",
      " [0.2521376 ]\n",
      " [0.24576306]\n",
      " [0.24805543]\n",
      " [0.25335464]\n",
      " [0.25956705]\n",
      " [0.26618764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27347058]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20705338]\n",
      "  [0.22612916]\n",
      "  [0.2521376 ]\n",
      "  [0.24576306]\n",
      "  [0.24805543]\n",
      "  [0.25335464]\n",
      "  [0.25956705]\n",
      "  [0.26618764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00350612448528409\n",
      "Predicción post entrenamiento : [[0.27129036]]\n",
      "PERDIDAAAA despues: 0.003252685070037842\n",
      "loss en el callback: 0.007484490983188152, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22612916]\n",
      " [0.2521376 ]\n",
      " [0.24576306]\n",
      " [0.24805543]\n",
      " [0.25335464]\n",
      " [0.25956705]\n",
      " [0.26618764]\n",
      " [0.27347058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27923143]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22612916]\n",
      "  [0.2521376 ]\n",
      "  [0.24576306]\n",
      "  [0.24805543]\n",
      "  [0.25335464]\n",
      "  [0.25956705]\n",
      "  [0.26618764]\n",
      "  [0.27347058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009585656225681305\n",
      "Predicción post entrenamiento : [[0.2764718]]\n",
      "PERDIDAAAA despues: 0.009052900597453117\n",
      "loss en el callback: 0.014173734933137894, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.2521376 ]\n",
      " [0.24576306]\n",
      " [0.24805543]\n",
      " [0.25335464]\n",
      " [0.25956705]\n",
      " [0.26618764]\n",
      " [0.27347058]\n",
      " [0.27923143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.282041]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.2521376 ]\n",
      "  [0.24576306]\n",
      "  [0.24805543]\n",
      "  [0.25335464]\n",
      "  [0.25956705]\n",
      "  [0.26618764]\n",
      "  [0.27347058]\n",
      "  [0.27923143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011430835351347923\n",
      "Predicción post entrenamiento : [[0.2785013]]\n",
      "PERDIDAAAA despues: 0.010686468333005905\n",
      "loss en el callback: 0.023949265480041504, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24576306]\n",
      " [0.24805543]\n",
      " [0.25335464]\n",
      " [0.25956705]\n",
      " [0.26618764]\n",
      " [0.27347058]\n",
      " [0.27923143]\n",
      " [0.28204101]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.27957684]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24576306]\n",
      "  [0.24805543]\n",
      "  [0.25335464]\n",
      "  [0.25956705]\n",
      "  [0.26618764]\n",
      "  [0.27347058]\n",
      "  [0.27923143]\n",
      "  [0.28204101]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01731123961508274\n",
      "Predicción post entrenamiento : [[0.2776498]]\n",
      "PERDIDAAAA despues: 0.016807861626148224\n",
      "loss en el callback: 0.01087227277457714, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24805543]\n",
      " [0.25335464]\n",
      " [0.25956705]\n",
      " [0.26618764]\n",
      " [0.27347058]\n",
      " [0.27923143]\n",
      " [0.28204101]\n",
      " [0.27957684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.28098094]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24805543]\n",
      "  [0.25335464]\n",
      "  [0.25956705]\n",
      "  [0.26618764]\n",
      "  [0.27347058]\n",
      "  [0.27923143]\n",
      "  [0.28204101]\n",
      "  [0.27957684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014915196225047112\n",
      "Predicción post entrenamiento : [[0.27950227]]\n",
      "PERDIDAAAA despues: 0.01455620862543583\n",
      "loss en el callback: 0.007457510568201542, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25335464]\n",
      " [0.25956705]\n",
      " [0.26618764]\n",
      " [0.27347058]\n",
      " [0.27923143]\n",
      " [0.28204101]\n",
      " [0.27957684]\n",
      " [0.28098094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.28343698]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25335464]\n",
      "  [0.25956705]\n",
      "  [0.26618764]\n",
      "  [0.27347058]\n",
      "  [0.27923143]\n",
      "  [0.28204101]\n",
      "  [0.27957684]\n",
      "  [0.28098094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00832901056855917\n",
      "Predicción post entrenamiento : [[0.28233674]]\n",
      "PERDIDAAAA despues: 0.00812939740717411\n",
      "loss en el callback: 0.005003888159990311, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25956705]\n",
      " [0.26618764]\n",
      " [0.27347058]\n",
      " [0.27923143]\n",
      " [0.28204101]\n",
      " [0.27957684]\n",
      " [0.28098094]\n",
      " [0.28343698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.28618455]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25956705]\n",
      "  [0.26618764]\n",
      "  [0.27347058]\n",
      "  [0.27923143]\n",
      "  [0.28204101]\n",
      "  [0.27957684]\n",
      "  [0.28098094]\n",
      "  [0.28343698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010042067617177963\n",
      "Predicción post entrenamiento : [[0.28483507]]\n",
      "PERDIDAAAA despues: 0.00977342575788498\n",
      "loss en el callback: 0.006889453157782555, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26618764]\n",
      " [0.27347058]\n",
      " [0.27923143]\n",
      " [0.28204101]\n",
      " [0.27957684]\n",
      " [0.28098094]\n",
      " [0.28343698]\n",
      " [0.28618455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.28825775]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26618764]\n",
      "  [0.27347058]\n",
      "  [0.27923143]\n",
      "  [0.28204101]\n",
      "  [0.27957684]\n",
      "  [0.28098094]\n",
      "  [0.28343698]\n",
      "  [0.28618455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045398660586215556\n",
      "Predicción post entrenamiento : [[0.28877315]]\n",
      "PERDIDAAAA despues: 0.0004762155294883996\n",
      "loss en el callback: 0.0014032638864591718, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27347058]\n",
      " [0.27923143]\n",
      " [0.28204101]\n",
      " [0.27957684]\n",
      " [0.28098094]\n",
      " [0.28343698]\n",
      " [0.28618455]\n",
      " [0.28825775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29150873]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27347058]\n",
      "  [0.27923143]\n",
      "  [0.28204101]\n",
      "  [0.27957684]\n",
      "  [0.28098094]\n",
      "  [0.28343698]\n",
      "  [0.28618455]\n",
      "  [0.28825775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0272779036313295e-06\n",
      "Predicción post entrenamiento : [[0.29225525]]\n",
      "PERDIDAAAA despues: 7.130438461899757e-08\n",
      "loss en el callback: 0.0029713755939155817, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27923143]\n",
      " [0.28204101]\n",
      " [0.27957684]\n",
      " [0.28098094]\n",
      " [0.28343698]\n",
      " [0.28618455]\n",
      " [0.28825775]\n",
      " [0.29150873]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.29396886]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27923143]\n",
      "  [0.28204101]\n",
      "  [0.27957684]\n",
      "  [0.28098094]\n",
      "  [0.28343698]\n",
      "  [0.28618455]\n",
      "  [0.28825775]\n",
      "  [0.29150873]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005634670378640294\n",
      "Predicción post entrenamiento : [[0.29368472]]\n",
      "PERDIDAAAA despues: 0.000577037048060447\n",
      "loss en el callback: 0.0002946476452052593, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28204101]\n",
      " [0.27957684]\n",
      " [0.28098094]\n",
      " [0.28343698]\n",
      " [0.28618455]\n",
      " [0.28825775]\n",
      " [0.29150873]\n",
      " [0.29396886]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.294546]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28204101]\n",
      "  [0.27957684]\n",
      "  [0.28098094]\n",
      "  [0.28343698]\n",
      "  [0.28618455]\n",
      "  [0.28825775]\n",
      "  [0.29150873]\n",
      "  [0.29396886]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000328461523167789\n",
      "Predicción post entrenamiento : [[0.29507494]]\n",
      "PERDIDAAAA despues: 0.0003095690917689353\n",
      "loss en el callback: 0.0014478361699730158, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27957684]\n",
      " [0.28098094]\n",
      " [0.28343698]\n",
      " [0.28618455]\n",
      " [0.28825775]\n",
      " [0.29150873]\n",
      " [0.29396886]\n",
      " [0.29454601]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.29565525]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27957684]\n",
      "  [0.28098094]\n",
      "  [0.28343698]\n",
      "  [0.28618455]\n",
      "  [0.28825775]\n",
      "  [0.29150873]\n",
      "  [0.29396886]\n",
      "  [0.29454601]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.382426413940266e-05\n",
      "Predicción post entrenamiento : [[0.29585987]]\n",
      "PERDIDAAAA despues: 4.6575336455134675e-05\n",
      "loss en el callback: 0.00025810053921304643, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28098094]\n",
      " [0.28343698]\n",
      " [0.28618455]\n",
      " [0.28825775]\n",
      " [0.29150873]\n",
      " [0.29396886]\n",
      " [0.29454601]\n",
      " [0.29565525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.29737765]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28098094]\n",
      "  [0.28343698]\n",
      "  [0.28618455]\n",
      "  [0.28825775]\n",
      "  [0.29150873]\n",
      "  [0.29396886]\n",
      "  [0.29454601]\n",
      "  [0.29565525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002114562812494114\n",
      "Predicción post entrenamiento : [[0.2967618]]\n",
      "PERDIDAAAA despues: 0.000193925152416341\n",
      "loss en el callback: 0.0018548339139670134, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28343698]\n",
      " [0.28618455]\n",
      " [0.28825775]\n",
      " [0.29150873]\n",
      " [0.29396886]\n",
      " [0.29454601]\n",
      " [0.29565525]\n",
      " [0.29737765]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.29846042]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28343698]\n",
      "  [0.28618455]\n",
      "  [0.28825775]\n",
      "  [0.29150873]\n",
      "  [0.29396886]\n",
      "  [0.29454601]\n",
      "  [0.29565525]\n",
      "  [0.29737765]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0730865369623643e-06\n",
      "Predicción post entrenamiento : [[0.29848838]]\n",
      "PERDIDAAAA despues: 1.0159518524233135e-06\n",
      "loss en el callback: 4.698155407822924e-06, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.28618455]\n",
      " [0.28825775]\n",
      " [0.29150873]\n",
      " [0.29396886]\n",
      " [0.29454601]\n",
      " [0.29565525]\n",
      " [0.29737765]\n",
      " [0.29846042]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.3001259]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.28618455]\n",
      "  [0.28825775]\n",
      "  [0.29150873]\n",
      "  [0.29396886]\n",
      "  [0.29454601]\n",
      "  [0.29565525]\n",
      "  [0.29737765]\n",
      "  [0.29846042]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005887334118597209\n",
      "Predicción post entrenamiento : [[0.299009]]\n",
      "PERDIDAAAA despues: 0.0005357802729122341\n",
      "loss en el callback: 0.006155823357403278, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28825775]\n",
      " [0.29150873]\n",
      " [0.29396886]\n",
      " [0.29454601]\n",
      " [0.29565525]\n",
      " [0.29737765]\n",
      " [0.29846042]\n",
      " [0.3001259 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30047768]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28825775]\n",
      "  [0.29150873]\n",
      "  [0.29396886]\n",
      "  [0.29454601]\n",
      "  [0.29565525]\n",
      "  [0.29737765]\n",
      "  [0.29846042]\n",
      "  [0.3001259 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006645035464316607\n",
      "Predicción post entrenamiento : [[0.3000018]]\n",
      "PERDIDAAAA despues: 0.0006401953869499266\n",
      "loss en el callback: 0.0013817412545904517, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29150873]\n",
      " [0.29396886]\n",
      " [0.29454601]\n",
      " [0.29565525]\n",
      " [0.29737765]\n",
      " [0.29846042]\n",
      " [0.3001259 ]\n",
      " [0.30047768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.3014058]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29150873]\n",
      "  [0.29396886]\n",
      "  [0.29454601]\n",
      "  [0.29565525]\n",
      "  [0.29737765]\n",
      "  [0.29846042]\n",
      "  [0.3001259 ]\n",
      "  [0.30047768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006724260747432709\n",
      "Predicción post entrenamiento : [[0.30041444]]\n",
      "PERDIDAAAA despues: 0.0006219953647814691\n",
      "loss en el callback: 0.005950557067990303, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.29396886]\n",
      " [0.29454601]\n",
      " [0.29565525]\n",
      " [0.29737765]\n",
      " [0.29846042]\n",
      " [0.3001259 ]\n",
      " [0.30047768]\n",
      " [0.30140579]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3014381]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.29396886]\n",
      "  [0.29454601]\n",
      "  [0.29565525]\n",
      "  [0.29737765]\n",
      "  [0.29846042]\n",
      "  [0.3001259 ]\n",
      "  [0.30047768]\n",
      "  [0.30140579]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011099469847977161\n",
      "Predicción post entrenamiento : [[0.3022278]]\n",
      "PERDIDAAAA despues: 0.0010579514782875776\n",
      "loss en el callback: 0.006797762122005224, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.29454601]\n",
      " [0.29565525]\n",
      " [0.29737765]\n",
      " [0.29846042]\n",
      " [0.3001259 ]\n",
      " [0.30047768]\n",
      " [0.30140579]\n",
      " [0.30143809]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.30297562]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.29454601]\n",
      "  [0.29565525]\n",
      "  [0.29737765]\n",
      "  [0.29846042]\n",
      "  [0.3001259 ]\n",
      "  [0.30047768]\n",
      "  [0.30140579]\n",
      "  [0.30143809]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002777338493615389\n",
      "Predicción post entrenamiento : [[0.3032874]]\n",
      "PERDIDAAAA despues: 0.0027445757295936346\n",
      "loss en el callback: 0.000667835702188313, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.29565525]\n",
      " [0.29737765]\n",
      " [0.29846042]\n",
      " [0.3001259 ]\n",
      " [0.30047768]\n",
      " [0.30140579]\n",
      " [0.30143809]\n",
      " [0.30297562]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30414897]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.29565525]\n",
      "  [0.29737765]\n",
      "  [0.29846042]\n",
      "  [0.3001259 ]\n",
      "  [0.30047768]\n",
      "  [0.30140579]\n",
      "  [0.30143809]\n",
      "  [0.30297562]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010589966550469398\n",
      "Predicción post entrenamiento : [[0.30405542]]\n",
      "PERDIDAAAA despues: 0.0010650940239429474\n",
      "loss en el callback: 6.06618013989646e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.29737765]\n",
      " [0.29846042]\n",
      " [0.3001259 ]\n",
      " [0.30047768]\n",
      " [0.30140579]\n",
      " [0.30143809]\n",
      " [0.30297562]\n",
      " [0.30414897]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3049149]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.29737765]\n",
      "  [0.29846042]\n",
      "  [0.3001259 ]\n",
      "  [0.30047768]\n",
      "  [0.30140579]\n",
      "  [0.30143809]\n",
      "  [0.30297562]\n",
      "  [0.30414897]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008223559125326574\n",
      "Predicción post entrenamiento : [[0.30527723]]\n",
      "PERDIDAAAA despues: 0.000801705929916352\n",
      "loss en el callback: 0.0012423613807186484, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.29846042]\n",
      " [0.3001259 ]\n",
      " [0.30047768]\n",
      " [0.30140579]\n",
      " [0.30143809]\n",
      " [0.30297562]\n",
      " [0.30414897]\n",
      " [0.30491489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.30598024]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.29846042]\n",
      "  [0.3001259 ]\n",
      "  [0.30047768]\n",
      "  [0.30140579]\n",
      "  [0.30143809]\n",
      "  [0.30297562]\n",
      "  [0.30414897]\n",
      "  [0.30491489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006202250253409147\n",
      "Predicción post entrenamiento : [[0.3068289]]\n",
      "PERDIDAAAA despues: 0.006069300230592489\n",
      "loss en el callback: 0.006842935457825661, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.3001259 ]\n",
      " [0.30047768]\n",
      " [0.30140579]\n",
      " [0.30143809]\n",
      " [0.30297562]\n",
      " [0.30414897]\n",
      " [0.30491489]\n",
      " [0.30598024]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.30749816]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.3001259 ]\n",
      "  [0.30047768]\n",
      "  [0.30140579]\n",
      "  [0.30143809]\n",
      "  [0.30297562]\n",
      "  [0.30414897]\n",
      "  [0.30491489]\n",
      "  [0.30598024]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06948407739400864\n",
      "Predicción post entrenamiento : [[0.30995405]]\n",
      "PERDIDAAAA despues: 0.06819537281990051\n",
      "loss en el callback: 0.053960151970386505, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30047768]\n",
      " [0.30140579]\n",
      " [0.30143809]\n",
      " [0.30297562]\n",
      " [0.30414897]\n",
      " [0.30491489]\n",
      " [0.30598024]\n",
      " [0.30749816]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.3104495]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30047768]\n",
      "  [0.30140579]\n",
      "  [0.30143809]\n",
      "  [0.30297562]\n",
      "  [0.30414897]\n",
      "  [0.30491489]\n",
      "  [0.30598024]\n",
      "  [0.30749816]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08169936388731003\n",
      "Predicción post entrenamiento : [[0.31329468]]\n",
      "PERDIDAAAA despues: 0.08008098602294922\n",
      "loss en el callback: 0.09523438662290573, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30140579]\n",
      " [0.30143809]\n",
      " [0.30297562]\n",
      " [0.30414897]\n",
      " [0.30491489]\n",
      " [0.30598024]\n",
      " [0.30749816]\n",
      " [0.31044951]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.31391916]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30140579]\n",
      "  [0.30143809]\n",
      "  [0.30297562]\n",
      "  [0.30414897]\n",
      "  [0.30491489]\n",
      "  [0.30598024]\n",
      "  [0.30749816]\n",
      "  [0.31044951]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06794588267803192\n",
      "Predicción post entrenamiento : [[0.31645882]]\n",
      "PERDIDAAAA despues: 0.0666283369064331\n",
      "loss en el callback: 0.07467012852430344, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30143809]\n",
      " [0.30297562]\n",
      " [0.30414897]\n",
      " [0.30491489]\n",
      " [0.30598024]\n",
      " [0.30749816]\n",
      " [0.31044951]\n",
      " [0.31391916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3171283]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30143809]\n",
      "  [0.30297562]\n",
      "  [0.30414897]\n",
      "  [0.30491489]\n",
      "  [0.30598024]\n",
      "  [0.30749816]\n",
      "  [0.31044951]\n",
      "  [0.31391916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0836515724658966\n",
      "Predicción post entrenamiento : [[0.3198291]]\n",
      "PERDIDAAAA despues: 0.08209658414125443\n",
      "loss en el callback: 0.103020079433918, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30297562]\n",
      " [0.30414897]\n",
      " [0.30491489]\n",
      " [0.30598024]\n",
      " [0.30749816]\n",
      " [0.31044951]\n",
      " [0.31391916]\n",
      " [0.3171283 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3208078]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30297562]\n",
      "  [0.30414897]\n",
      "  [0.30491489]\n",
      "  [0.30598024]\n",
      "  [0.30749816]\n",
      "  [0.31044951]\n",
      "  [0.31391916]\n",
      "  [0.3171283 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06961645931005478\n",
      "Predicción post entrenamiento : [[0.32299533]]\n",
      "PERDIDAAAA despues: 0.06846689432859421\n",
      "loss en el callback: 0.04472155496478081, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30414897]\n",
      " [0.30491489]\n",
      " [0.30598024]\n",
      " [0.30749816]\n",
      " [0.31044951]\n",
      " [0.31391916]\n",
      " [0.3171283 ]\n",
      " [0.32080781]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3240206]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30414897]\n",
      "  [0.30491489]\n",
      "  [0.30598024]\n",
      "  [0.30749816]\n",
      "  [0.31044951]\n",
      "  [0.31391916]\n",
      "  [0.3171283 ]\n",
      "  [0.32080781]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05990314111113548\n",
      "Predicción post entrenamiento : [[0.32631153]]\n",
      "PERDIDAAAA despues: 0.05878697335720062\n",
      "loss en el callback: 0.09449753910303116, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.30491489]\n",
      " [0.30598024]\n",
      " [0.30749816]\n",
      " [0.31044951]\n",
      " [0.31391916]\n",
      " [0.3171283 ]\n",
      " [0.32080781]\n",
      " [0.32402059]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32752874]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.30491489]\n",
      "  [0.30598024]\n",
      "  [0.30749816]\n",
      "  [0.31044951]\n",
      "  [0.31391916]\n",
      "  [0.3171283 ]\n",
      "  [0.32080781]\n",
      "  [0.32402059]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09937963634729385\n",
      "Predicción post entrenamiento : [[0.33023167]]\n",
      "PERDIDAAAA despues: 0.09768277406692505\n",
      "loss en el callback: 0.10468769818544388, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.30598024]\n",
      " [0.30749816]\n",
      " [0.31044951]\n",
      " [0.31391916]\n",
      " [0.3171283 ]\n",
      " [0.32080781]\n",
      " [0.32402059]\n",
      " [0.32752874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.33182138]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.30598024]\n",
      "  [0.30749816]\n",
      "  [0.31044951]\n",
      "  [0.31391916]\n",
      "  [0.3171283 ]\n",
      "  [0.32080781]\n",
      "  [0.32402059]\n",
      "  [0.32752874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10885884612798691\n",
      "Predicción post entrenamiento : [[0.3344311]]\n",
      "PERDIDAAAA despues: 0.10714355856180191\n",
      "loss en el callback: 0.15596289932727814, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30749816]\n",
      " [0.31044951]\n",
      " [0.31391916]\n",
      " [0.3171283 ]\n",
      " [0.32080781]\n",
      " [0.32402059]\n",
      " [0.32752874]\n",
      " [0.33182138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33642644]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30749816]\n",
      "  [0.31044951]\n",
      "  [0.31391916]\n",
      "  [0.3171283 ]\n",
      "  [0.32080781]\n",
      "  [0.32402059]\n",
      "  [0.32752874]\n",
      "  [0.33182138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11327838152647018\n",
      "Predicción post entrenamiento : [[0.33929142]]\n",
      "PERDIDAAAA despues: 0.11135806143283844\n",
      "loss en el callback: 0.11119161546230316, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.31044951]\n",
      " [0.31391916]\n",
      " [0.3171283 ]\n",
      " [0.32080781]\n",
      " [0.32402059]\n",
      " [0.32752874]\n",
      " [0.33182138]\n",
      " [0.33642644]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3416856]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.31044951]\n",
      "  [0.31391916]\n",
      "  [0.3171283 ]\n",
      "  [0.32080781]\n",
      "  [0.32402059]\n",
      "  [0.32752874]\n",
      "  [0.33182138]\n",
      "  [0.33642644]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13608109951019287\n",
      "Predicción post entrenamiento : [[0.3446969]]\n",
      "PERDIDAAAA despues: 0.13386847078800201\n",
      "loss en el callback: 0.1626165807247162, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31391916]\n",
      " [0.3171283 ]\n",
      " [0.32080781]\n",
      " [0.32402059]\n",
      " [0.32752874]\n",
      " [0.33182138]\n",
      " [0.33642644]\n",
      " [0.34168559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34723797]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31391916]\n",
      "  [0.3171283 ]\n",
      "  [0.32080781]\n",
      "  [0.32402059]\n",
      "  [0.32752874]\n",
      "  [0.33182138]\n",
      "  [0.33642644]\n",
      "  [0.34168559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12727250158786774\n",
      "Predicción post entrenamiento : [[0.3501815]]\n",
      "PERDIDAAAA despues: 0.12518095970153809\n",
      "loss en el callback: 0.136179581284523, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.3171283 ]\n",
      " [0.32080781]\n",
      " [0.32402059]\n",
      " [0.32752874]\n",
      " [0.33182138]\n",
      " [0.33642644]\n",
      " [0.34168559]\n",
      " [0.34723797]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35279953]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.3171283 ]\n",
      "  [0.32080781]\n",
      "  [0.32402059]\n",
      "  [0.32752874]\n",
      "  [0.33182138]\n",
      "  [0.33642644]\n",
      "  [0.34168559]\n",
      "  [0.34723797]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1402038037776947\n",
      "Predicción post entrenamiento : [[0.35579655]]\n",
      "PERDIDAAAA despues: 0.13796840608119965\n",
      "loss en el callback: 0.13517332077026367, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32080781]\n",
      " [0.32402059]\n",
      " [0.32752874]\n",
      " [0.33182138]\n",
      " [0.33642644]\n",
      " [0.34168559]\n",
      " [0.34723797]\n",
      " [0.35279953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3586091]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32080781]\n",
      "  [0.32402059]\n",
      "  [0.32752874]\n",
      "  [0.33182138]\n",
      "  [0.33642644]\n",
      "  [0.34168559]\n",
      "  [0.34723797]\n",
      "  [0.35279953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13248072564601898\n",
      "Predicción post entrenamiento : [[0.36144093]]\n",
      "PERDIDAAAA despues: 0.1304273009300232\n",
      "loss en el callback: 0.09233324229717255, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32402059]\n",
      " [0.32752874]\n",
      " [0.33182138]\n",
      " [0.33642644]\n",
      " [0.34168559]\n",
      " [0.34723797]\n",
      " [0.35279953]\n",
      " [0.35860911]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36440855]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32402059]\n",
      "  [0.32752874]\n",
      "  [0.33182138]\n",
      "  [0.33642644]\n",
      "  [0.34168559]\n",
      "  [0.34723797]\n",
      "  [0.35279953]\n",
      "  [0.35860911]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1659628301858902\n",
      "Predicción post entrenamiento : [[0.36756736]]\n",
      "PERDIDAAAA despues: 0.1633991003036499\n",
      "loss en el callback: 0.17346058785915375, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32752874]\n",
      " [0.33182138]\n",
      " [0.33642644]\n",
      " [0.34168559]\n",
      " [0.34723797]\n",
      " [0.35279953]\n",
      " [0.35860911]\n",
      " [0.36440855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37087753]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32752874]\n",
      "  [0.33182138]\n",
      "  [0.33642644]\n",
      "  [0.34168559]\n",
      "  [0.34723797]\n",
      "  [0.35279953]\n",
      "  [0.35860911]\n",
      "  [0.36440855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12506680190563202\n",
      "Predicción post entrenamiento : [[0.37362984]]\n",
      "PERDIDAAAA despues: 0.12312769144773483\n",
      "loss en el callback: 0.15656320750713348, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33182138]\n",
      " [0.33642644]\n",
      " [0.34168559]\n",
      " [0.34723797]\n",
      " [0.35279953]\n",
      " [0.35860911]\n",
      " [0.36440855]\n",
      " [0.37087753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37730774]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33182138]\n",
      "  [0.33642644]\n",
      "  [0.34168559]\n",
      "  [0.34723797]\n",
      "  [0.35279953]\n",
      "  [0.35860911]\n",
      "  [0.36440855]\n",
      "  [0.37087753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08628904074430466\n",
      "Predicción post entrenamiento : [[0.37934744]]\n",
      "PERDIDAAAA despues: 0.0850948765873909\n",
      "loss en el callback: 0.06300027668476105, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33642644]\n",
      " [0.34168559]\n",
      " [0.34723797]\n",
      " [0.35279953]\n",
      " [0.35860911]\n",
      " [0.36440855]\n",
      " [0.37087753]\n",
      " [0.37730774]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38329217]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33642644]\n",
      "  [0.34168559]\n",
      "  [0.34723797]\n",
      "  [0.35279953]\n",
      "  [0.35860911]\n",
      "  [0.36440855]\n",
      "  [0.37087753]\n",
      "  [0.37730774]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08437727391719818\n",
      "Predicción post entrenamiento : [[0.38542107]]\n",
      "PERDIDAAAA despues: 0.08314500749111176\n",
      "loss en el callback: 0.08125423640012741, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34168559]\n",
      " [0.34723797]\n",
      " [0.35279953]\n",
      " [0.35860911]\n",
      " [0.36440855]\n",
      " [0.37087753]\n",
      " [0.37730774]\n",
      " [0.38329217]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.38962466]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34168559]\n",
      "  [0.34723797]\n",
      "  [0.35279953]\n",
      "  [0.35860911]\n",
      "  [0.36440855]\n",
      "  [0.37087753]\n",
      "  [0.37730774]\n",
      "  [0.38329217]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10551266372203827\n",
      "Predicción post entrenamiento : [[0.39188504]]\n",
      "PERDIDAAAA despues: 0.10404931008815765\n",
      "loss en el callback: 0.0759056881070137, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34723797]\n",
      " [0.35279953]\n",
      " [0.35860911]\n",
      " [0.36440855]\n",
      " [0.37087753]\n",
      " [0.37730774]\n",
      " [0.38329217]\n",
      " [0.38962466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39624485]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34723797]\n",
      "  [0.35279953]\n",
      "  [0.35860911]\n",
      "  [0.36440855]\n",
      "  [0.37087753]\n",
      "  [0.37730774]\n",
      "  [0.38329217]\n",
      "  [0.38962466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12086252868175507\n",
      "Predicción post entrenamiento : [[0.3988665]]\n",
      "PERDIDAAAA despues: 0.11904655396938324\n",
      "loss en el callback: 0.2079107165336609, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35279953]\n",
      " [0.35860911]\n",
      " [0.36440855]\n",
      " [0.37087753]\n",
      " [0.37730774]\n",
      " [0.38329217]\n",
      " [0.38962466]\n",
      " [0.39624485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40334955]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35279953]\n",
      "  [0.35860911]\n",
      "  [0.36440855]\n",
      "  [0.37087753]\n",
      "  [0.37730774]\n",
      "  [0.38329217]\n",
      "  [0.38962466]\n",
      "  [0.39624485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10191326588392258\n",
      "Predicción post entrenamiento : [[0.40566462]]\n",
      "PERDIDAAAA despues: 0.10044050216674805\n",
      "loss en el callback: 0.15163865685462952, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35860911]\n",
      " [0.36440855]\n",
      " [0.37087753]\n",
      " [0.37730774]\n",
      " [0.38329217]\n",
      " [0.38962466]\n",
      " [0.39624485]\n",
      " [0.40334955]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41030395]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35860911]\n",
      "  [0.36440855]\n",
      "  [0.37087753]\n",
      "  [0.37730774]\n",
      "  [0.38329217]\n",
      "  [0.38962466]\n",
      "  [0.39624485]\n",
      "  [0.40334955]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08354262262582779\n",
      "Predicción post entrenamiento : [[0.41242123]]\n",
      "PERDIDAAAA despues: 0.08232316374778748\n",
      "loss en el callback: 0.09938247501850128, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36440855]\n",
      " [0.37087753]\n",
      " [0.37730774]\n",
      " [0.38329217]\n",
      " [0.38962466]\n",
      " [0.39624485]\n",
      " [0.40334955]\n",
      " [0.41030395]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4171944]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36440855]\n",
      "  [0.37087753]\n",
      "  [0.37730774]\n",
      "  [0.38329217]\n",
      "  [0.38962466]\n",
      "  [0.39624485]\n",
      "  [0.40334955]\n",
      "  [0.41030395]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10247471928596497\n",
      "Predicción post entrenamiento : [[0.41939536]]\n",
      "PERDIDAAAA despues: 0.10107043385505676\n",
      "loss en el callback: 0.08217290788888931, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37087753]\n",
      " [0.37730774]\n",
      " [0.38329217]\n",
      " [0.38962466]\n",
      " [0.39624485]\n",
      " [0.40334955]\n",
      " [0.41030395]\n",
      " [0.4171944 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.42434216]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37087753]\n",
      "  [0.37730774]\n",
      "  [0.38329217]\n",
      "  [0.38962466]\n",
      "  [0.39624485]\n",
      "  [0.40334955]\n",
      "  [0.41030395]\n",
      "  [0.4171944 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08825871348381042\n",
      "Predicción post entrenamiento : [[0.42634368]]\n",
      "PERDIDAAAA despues: 0.08707347512245178\n",
      "loss en el callback: 0.07364526391029358, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37730774]\n",
      " [0.38329217]\n",
      " [0.38962466]\n",
      " [0.39624485]\n",
      " [0.40334955]\n",
      " [0.41030395]\n",
      " [0.4171944 ]\n",
      " [0.42434216]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.43133256]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37730774]\n",
      "  [0.38329217]\n",
      "  [0.38962466]\n",
      "  [0.39624485]\n",
      "  [0.40334955]\n",
      "  [0.41030395]\n",
      "  [0.4171944 ]\n",
      "  [0.42434216]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08258792012929916\n",
      "Predicción post entrenamiento : [[0.43345413]]\n",
      "PERDIDAAAA despues: 0.08137302845716476\n",
      "loss en el callback: 0.11495716124773026, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38329217]\n",
      " [0.38962466]\n",
      " [0.39624485]\n",
      " [0.40334955]\n",
      " [0.41030395]\n",
      " [0.4171944 ]\n",
      " [0.42434216]\n",
      " [0.43133256]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4385156]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38329217]\n",
      "  [0.38962466]\n",
      "  [0.39624485]\n",
      "  [0.40334955]\n",
      "  [0.41030395]\n",
      "  [0.4171944 ]\n",
      "  [0.42434216]\n",
      "  [0.43133256]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05552702024579048\n",
      "Predicción post entrenamiento : [[0.44026545]]\n",
      "PERDIDAAAA despues: 0.054705407470464706\n",
      "loss en el callback: 0.07517211884260178, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.38962466]\n",
      " [0.39624485]\n",
      " [0.40334955]\n",
      " [0.41030395]\n",
      " [0.4171944 ]\n",
      " [0.42434216]\n",
      " [0.43133256]\n",
      " [0.4385156 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44554055]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.38962466]\n",
      "  [0.39624485]\n",
      "  [0.40334955]\n",
      "  [0.41030395]\n",
      "  [0.4171944 ]\n",
      "  [0.42434216]\n",
      "  [0.43133256]\n",
      "  [0.4385156 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06402210146188736\n",
      "Predicción post entrenamiento : [[0.4474948]]\n",
      "PERDIDAAAA despues: 0.0630369633436203\n",
      "loss en el callback: 0.10730820894241333, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39624485]\n",
      " [0.40334955]\n",
      " [0.41030395]\n",
      " [0.4171944 ]\n",
      " [0.42434216]\n",
      " [0.43133256]\n",
      " [0.4385156 ]\n",
      " [0.44554055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.45293733]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39624485]\n",
      "  [0.40334955]\n",
      "  [0.41030395]\n",
      "  [0.4171944 ]\n",
      "  [0.42434216]\n",
      "  [0.43133256]\n",
      "  [0.4385156 ]\n",
      "  [0.44554055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07187815010547638\n",
      "Predicción post entrenamiento : [[0.4545904]]\n",
      "PERDIDAAAA despues: 0.07099450379610062\n",
      "loss en el callback: 0.051014501601457596, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40334955]\n",
      " [0.41030395]\n",
      " [0.4171944 ]\n",
      " [0.42434216]\n",
      " [0.43133256]\n",
      " [0.4385156 ]\n",
      " [0.44554055]\n",
      " [0.45293733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4601559]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40334955]\n",
      "  [0.41030395]\n",
      "  [0.4171944 ]\n",
      "  [0.42434216]\n",
      "  [0.43133256]\n",
      "  [0.4385156 ]\n",
      "  [0.44554055]\n",
      "  [0.45293733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0688706710934639\n",
      "Predicción post entrenamiento : [[0.46176293]]\n",
      "PERDIDAAAA despues: 0.06802977621555328\n",
      "loss en el callback: 0.055186957120895386, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.41030395]\n",
      " [0.4171944 ]\n",
      " [0.42434216]\n",
      " [0.43133256]\n",
      " [0.4385156 ]\n",
      " [0.44554055]\n",
      " [0.45293733]\n",
      " [0.4601559 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4673446]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.41030395]\n",
      "  [0.4171944 ]\n",
      "  [0.42434216]\n",
      "  [0.43133256]\n",
      "  [0.4385156 ]\n",
      "  [0.44554055]\n",
      "  [0.45293733]\n",
      "  [0.4601559 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08349292725324631\n",
      "Predicción post entrenamiento : [[0.46917877]]\n",
      "PERDIDAAAA despues: 0.08243633061647415\n",
      "loss en el callback: 0.07002032548189163, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.4171944 ]\n",
      " [0.42434216]\n",
      " [0.43133256]\n",
      " [0.4385156 ]\n",
      " [0.44554055]\n",
      " [0.45293733]\n",
      " [0.4601559 ]\n",
      " [0.46734461]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.47482097]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.4171944 ]\n",
      "  [0.42434216]\n",
      "  [0.43133256]\n",
      "  [0.4385156 ]\n",
      "  [0.44554055]\n",
      "  [0.45293733]\n",
      "  [0.4601559 ]\n",
      "  [0.46734461]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12444332987070084\n",
      "Predicción post entrenamiento : [[0.47712928]]\n",
      "PERDIDAAAA despues: 0.12282007932662964\n",
      "loss en el callback: 0.11265937983989716, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.42434216]\n",
      " [0.43133256]\n",
      " [0.4385156 ]\n",
      " [0.44554055]\n",
      " [0.45293733]\n",
      " [0.4601559 ]\n",
      " [0.46734461]\n",
      " [0.47482097]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.48286268]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.42434216]\n",
      "  [0.43133256]\n",
      "  [0.4385156 ]\n",
      "  [0.44554055]\n",
      "  [0.45293733]\n",
      "  [0.4601559 ]\n",
      "  [0.46734461]\n",
      "  [0.47482097]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12670716643333435\n",
      "Predicción post entrenamiento : [[0.4853167]]\n",
      "PERDIDAAAA despues: 0.12496612966060638\n",
      "loss en el callback: 0.1707996279001236, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.43133256]\n",
      " [0.4385156 ]\n",
      " [0.44554055]\n",
      " [0.45293733]\n",
      " [0.4601559 ]\n",
      " [0.46734461]\n",
      " [0.47482097]\n",
      " [0.48286268]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.49109283]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.43133256]\n",
      "  [0.4385156 ]\n",
      "  [0.44554055]\n",
      "  [0.45293733]\n",
      "  [0.4601559 ]\n",
      "  [0.46734461]\n",
      "  [0.47482097]\n",
      "  [0.48286268]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0919138565659523\n",
      "Predicción post entrenamiento : [[0.49318334]]\n",
      "PERDIDAAAA despues: 0.09065064787864685\n",
      "loss en el callback: 0.10211876034736633, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.4385156 ]\n",
      " [0.44554055]\n",
      " [0.45293733]\n",
      " [0.4601559 ]\n",
      " [0.46734461]\n",
      " [0.47482097]\n",
      " [0.48286268]\n",
      " [0.49109283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.49906105]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.4385156 ]\n",
      "  [0.44554055]\n",
      "  [0.45293733]\n",
      "  [0.4601559 ]\n",
      "  [0.46734461]\n",
      "  [0.47482097]\n",
      "  [0.48286268]\n",
      "  [0.49109283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08107895404100418\n",
      "Predicción post entrenamiento : [[0.5008975]]\n",
      "PERDIDAAAA despues: 0.0800364762544632\n",
      "loss en el callback: 0.07742023468017578, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44554055]\n",
      " [0.45293733]\n",
      " [0.4601559 ]\n",
      " [0.46734461]\n",
      " [0.47482097]\n",
      " [0.48286268]\n",
      " [0.49109283]\n",
      " [0.49906105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.50685525]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44554055]\n",
      "  [0.45293733]\n",
      "  [0.4601559 ]\n",
      "  [0.46734461]\n",
      "  [0.47482097]\n",
      "  [0.48286268]\n",
      "  [0.49109283]\n",
      "  [0.49906105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06815449893474579\n",
      "Predicción post entrenamiento : [[0.508653]]\n",
      "PERDIDAAAA despues: 0.0672190859913826\n",
      "loss en el callback: 0.08676900714635849, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.45293733]\n",
      " [0.4601559 ]\n",
      " [0.46734461]\n",
      " [0.47482097]\n",
      " [0.48286268]\n",
      " [0.49109283]\n",
      " [0.49906105]\n",
      " [0.50685525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.51476187]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.45293733]\n",
      "  [0.4601559 ]\n",
      "  [0.46734461]\n",
      "  [0.47482097]\n",
      "  [0.48286268]\n",
      "  [0.49109283]\n",
      "  [0.49906105]\n",
      "  [0.50685525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0728016272187233\n",
      "Predicción post entrenamiento : [[0.5163054]]\n",
      "PERDIDAAAA despues: 0.07197107374668121\n",
      "loss en el callback: 0.049575433135032654, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.4601559 ]\n",
      " [0.46734461]\n",
      " [0.47482097]\n",
      " [0.48286268]\n",
      " [0.49109283]\n",
      " [0.49906105]\n",
      " [0.50685525]\n",
      " [0.51476187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5225013]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.4601559 ]\n",
      "  [0.46734461]\n",
      "  [0.47482097]\n",
      "  [0.48286268]\n",
      "  [0.49109283]\n",
      "  [0.49906105]\n",
      "  [0.50685525]\n",
      "  [0.51476187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12689830362796783\n",
      "Predicción post entrenamiento : [[0.5246792]]\n",
      "PERDIDAAAA despues: 0.12535138428211212\n",
      "loss en el callback: 0.10863853991031647, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.46734461]\n",
      " [0.47482097]\n",
      " [0.48286268]\n",
      " [0.49109283]\n",
      " [0.49906105]\n",
      " [0.50685525]\n",
      " [0.51476187]\n",
      " [0.52250129]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.53103745]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.46734461]\n",
      "  [0.47482097]\n",
      "  [0.48286268]\n",
      "  [0.49109283]\n",
      "  [0.49906105]\n",
      "  [0.50685525]\n",
      "  [0.51476187]\n",
      "  [0.52250129]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11874375492334366\n",
      "Predicción post entrenamiento : [[0.53313]]\n",
      "PERDIDAAAA despues: 0.11730598658323288\n",
      "loss en el callback: 0.09783302247524261, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.47482097]\n",
      " [0.48286268]\n",
      " [0.49109283]\n",
      " [0.49906105]\n",
      " [0.50685525]\n",
      " [0.51476187]\n",
      " [0.52250129]\n",
      " [0.53103745]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5396931]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.47482097]\n",
      "  [0.48286268]\n",
      "  [0.49109283]\n",
      "  [0.49906105]\n",
      "  [0.50685525]\n",
      "  [0.51476187]\n",
      "  [0.52250129]\n",
      "  [0.53103745]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09560628980398178\n",
      "Predicción post entrenamiento : [[0.54174423]]\n",
      "PERDIDAAAA despues: 0.09434207528829575\n",
      "loss en el callback: 0.10061932355165482, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.48286268]\n",
      " [0.49109283]\n",
      " [0.49906105]\n",
      " [0.50685525]\n",
      " [0.51476187]\n",
      " [0.52250129]\n",
      " [0.53103745]\n",
      " [0.53969312]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5484709]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.48286268]\n",
      "  [0.49109283]\n",
      "  [0.49906105]\n",
      "  [0.50685525]\n",
      "  [0.51476187]\n",
      "  [0.52250129]\n",
      "  [0.53103745]\n",
      "  [0.53969312]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07280098646879196\n",
      "Predicción post entrenamiento : [[0.55009645]]\n",
      "PERDIDAAAA despues: 0.07192643731832504\n",
      "loss en el callback: 0.06304905563592911, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.49109283]\n",
      " [0.49906105]\n",
      " [0.50685525]\n",
      " [0.51476187]\n",
      " [0.52250129]\n",
      " [0.53103745]\n",
      " [0.53969312]\n",
      " [0.54847091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5568595]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.49109283]\n",
      "  [0.49906105]\n",
      "  [0.50685525]\n",
      "  [0.51476187]\n",
      "  [0.52250129]\n",
      "  [0.53103745]\n",
      "  [0.53969312]\n",
      "  [0.54847091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07287398725748062\n",
      "Predicción post entrenamiento : [[0.55836123]]\n",
      "PERDIDAAAA despues: 0.07206544280052185\n",
      "loss en el callback: 0.04626567289233208, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.49906105]\n",
      " [0.50685525]\n",
      " [0.51476187]\n",
      " [0.52250129]\n",
      " [0.53103745]\n",
      " [0.53969312]\n",
      " [0.54847091]\n",
      " [0.55685949]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5651216]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.49906105]\n",
      "  [0.50685525]\n",
      "  [0.51476187]\n",
      "  [0.52250129]\n",
      "  [0.53103745]\n",
      "  [0.53969312]\n",
      "  [0.54847091]\n",
      "  [0.55685949]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04850253090262413\n",
      "Predicción post entrenamiento : [[0.56663424]]\n",
      "PERDIDAAAA despues: 0.04783855006098747\n",
      "loss en el callback: 0.06317663192749023, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.50685525]\n",
      " [0.51476187]\n",
      " [0.52250129]\n",
      " [0.53103745]\n",
      " [0.53969312]\n",
      " [0.54847091]\n",
      " [0.55685949]\n",
      " [0.56512159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.57347554]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.50685525]\n",
      "  [0.51476187]\n",
      "  [0.52250129]\n",
      "  [0.53103745]\n",
      "  [0.53969312]\n",
      "  [0.54847091]\n",
      "  [0.55685949]\n",
      "  [0.56512159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04654954373836517\n",
      "Predicción post entrenamiento : [[0.5746718]]\n",
      "PERDIDAAAA despues: 0.04603477939963341\n",
      "loss en el callback: 0.0307935681194067, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.51476187]\n",
      " [0.52250129]\n",
      " [0.53103745]\n",
      " [0.53969312]\n",
      " [0.54847091]\n",
      " [0.55685949]\n",
      " [0.56512159]\n",
      " [0.57347554]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5816652]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.51476187]\n",
      "  [0.52250129]\n",
      "  [0.53103745]\n",
      "  [0.53969312]\n",
      "  [0.54847091]\n",
      "  [0.55685949]\n",
      "  [0.56512159]\n",
      "  [0.57347554]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06376007199287415\n",
      "Predicción post entrenamiento : [[0.5831303]]\n",
      "PERDIDAAAA despues: 0.06302233040332794\n",
      "loss en el callback: 0.05479300767183304, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.52250129]\n",
      " [0.53103745]\n",
      " [0.53969312]\n",
      " [0.54847091]\n",
      " [0.55685949]\n",
      " [0.56512159]\n",
      " [0.57347554]\n",
      " [0.58166522]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5902741]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.52250129]\n",
      "  [0.53103745]\n",
      "  [0.53969312]\n",
      "  [0.54847091]\n",
      "  [0.55685949]\n",
      "  [0.56512159]\n",
      "  [0.57347554]\n",
      "  [0.58166522]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04937359690666199\n",
      "Predicción post entrenamiento : [[0.5916917]]\n",
      "PERDIDAAAA despues: 0.04874563217163086\n",
      "loss en el callback: 0.05072661116719246, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.53103745]\n",
      " [0.53969312]\n",
      " [0.54847091]\n",
      " [0.55685949]\n",
      " [0.56512159]\n",
      " [0.57347554]\n",
      " [0.58166522]\n",
      " [0.5902741 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5990555]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.53103745]\n",
      "  [0.53969312]\n",
      "  [0.54847091]\n",
      "  [0.55685949]\n",
      "  [0.56512159]\n",
      "  [0.57347554]\n",
      "  [0.58166522]\n",
      "  [0.5902741 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040878500789403915\n",
      "Predicción post entrenamiento : [[0.60005915]]\n",
      "PERDIDAAAA despues: 0.04047367349267006\n",
      "loss en el callback: 0.023320313543081284, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.53969312]\n",
      " [0.54847091]\n",
      " [0.55685949]\n",
      " [0.56512159]\n",
      " [0.57347554]\n",
      " [0.58166522]\n",
      " [0.5902741 ]\n",
      " [0.59905553]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.607442]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.53969312]\n",
      "  [0.54847091]\n",
      "  [0.55685949]\n",
      "  [0.56512159]\n",
      "  [0.57347554]\n",
      "  [0.58166522]\n",
      "  [0.5902741 ]\n",
      "  [0.59905553]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03831220418214798\n",
      "Predicción post entrenamiento : [[0.60832936]]\n",
      "PERDIDAAAA despues: 0.037965625524520874\n",
      "loss en el callback: 0.018617836758494377, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.54847091]\n",
      " [0.55685949]\n",
      " [0.56512159]\n",
      " [0.57347554]\n",
      " [0.58166522]\n",
      " [0.5902741 ]\n",
      " [0.59905553]\n",
      " [0.60744202]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.61569095]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.54847091]\n",
      "  [0.55685949]\n",
      "  [0.56512159]\n",
      "  [0.57347554]\n",
      "  [0.58166522]\n",
      "  [0.5902741 ]\n",
      "  [0.59905553]\n",
      "  [0.60744202]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0316128171980381\n",
      "Predicción post entrenamiento : [[0.6156319]]\n",
      "PERDIDAAAA despues: 0.031633827835321426\n",
      "loss en el callback: 6.2284801970236e-05, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.55685949]\n",
      " [0.56512159]\n",
      " [0.57347554]\n",
      " [0.58166522]\n",
      " [0.5902741 ]\n",
      " [0.59905553]\n",
      " [0.60744202]\n",
      " [0.61569095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6229234]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.55685949]\n",
      "  [0.56512159]\n",
      "  [0.57347554]\n",
      "  [0.58166522]\n",
      "  [0.5902741 ]\n",
      "  [0.59905553]\n",
      "  [0.60744202]\n",
      "  [0.61569095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018836762756109238\n",
      "Predicción post entrenamiento : [[0.6236265]]\n",
      "PERDIDAAAA despues: 0.018644260242581367\n",
      "loss en el callback: 0.012672821059823036, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.56512159]\n",
      " [0.57347554]\n",
      " [0.58166522]\n",
      " [0.5902741 ]\n",
      " [0.59905553]\n",
      " [0.60744202]\n",
      " [0.61569095]\n",
      " [0.62292337]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6309424]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.56512159]\n",
      "  [0.57347554]\n",
      "  [0.58166522]\n",
      "  [0.5902741 ]\n",
      "  [0.59905553]\n",
      "  [0.60744202]\n",
      "  [0.61569095]\n",
      "  [0.62292337]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01090594008564949\n",
      "Predicción post entrenamiento : [[0.63136953]]\n",
      "PERDIDAAAA despues: 0.010816912166774273\n",
      "loss en el callback: 0.004413028247654438, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.57347554]\n",
      " [0.58166522]\n",
      " [0.5902741 ]\n",
      " [0.59905553]\n",
      " [0.60744202]\n",
      " [0.61569095]\n",
      " [0.62292337]\n",
      " [0.6309424 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.63873565]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.57347554]\n",
      "  [0.58166522]\n",
      "  [0.5902741 ]\n",
      "  [0.59905553]\n",
      "  [0.60744202]\n",
      "  [0.61569095]\n",
      "  [0.62292337]\n",
      "  [0.6309424 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005105698015540838\n",
      "Predicción post entrenamiento : [[0.6397943]]\n",
      "PERDIDAAAA despues: 0.004955530632287264\n",
      "loss en el callback: 0.047148287296295166, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.58166522]\n",
      " [0.5902741 ]\n",
      " [0.59905553]\n",
      " [0.60744202]\n",
      " [0.61569095]\n",
      " [0.62292337]\n",
      " [0.6309424 ]\n",
      " [0.63873565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6471752]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.58166522]\n",
      "  [0.5902741 ]\n",
      "  [0.59905553]\n",
      "  [0.60744202]\n",
      "  [0.61569095]\n",
      "  [0.62292337]\n",
      "  [0.6309424 ]\n",
      "  [0.63873565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042187487706542015\n",
      "Predicción post entrenamiento : [[0.64799756]]\n",
      "PERDIDAAAA despues: 0.004112596623599529\n",
      "loss en el callback: 0.02452135644853115, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.5902741 ]\n",
      " [0.59905553]\n",
      " [0.60744202]\n",
      " [0.61569095]\n",
      " [0.62292337]\n",
      " [0.6309424 ]\n",
      " [0.63873565]\n",
      " [0.64717519]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.65542233]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.5902741 ]\n",
      "  [0.59905553]\n",
      "  [0.60744202]\n",
      "  [0.61569095]\n",
      "  [0.62292337]\n",
      "  [0.6309424 ]\n",
      "  [0.63873565]\n",
      "  [0.64717519]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007091912906616926\n",
      "Predicción post entrenamiento : [[0.655923]]\n",
      "PERDIDAAAA despues: 0.007007835432887077\n",
      "loss en el callback: 0.007167375180870295, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.59905553]\n",
      " [0.60744202]\n",
      " [0.61569095]\n",
      " [0.62292337]\n",
      " [0.6309424 ]\n",
      " [0.63873565]\n",
      " [0.64717519]\n",
      " [0.65542233]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.66325545]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.59905553]\n",
      "  [0.60744202]\n",
      "  [0.61569095]\n",
      "  [0.62292337]\n",
      "  [0.6309424 ]\n",
      "  [0.63873565]\n",
      "  [0.64717519]\n",
      "  [0.65542233]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00531343650072813\n",
      "Predicción post entrenamiento : [[0.66405386]]\n",
      "PERDIDAAAA despues: 0.005197677295655012\n",
      "loss en el callback: 0.023217426612973213, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.60744202]\n",
      " [0.61569095]\n",
      " [0.62292337]\n",
      " [0.6309424 ]\n",
      " [0.63873565]\n",
      " [0.64717519]\n",
      " [0.65542233]\n",
      " [0.66325545]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6712148]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.60744202]\n",
      "  [0.61569095]\n",
      "  [0.62292337]\n",
      "  [0.6309424 ]\n",
      "  [0.63873565]\n",
      "  [0.64717519]\n",
      "  [0.65542233]\n",
      "  [0.66325545]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3279528502607718e-05\n",
      "Predicción post entrenamiento : [[0.67158216]]\n",
      "PERDIDAAAA despues: 1.6091747966129333e-05\n",
      "loss en el callback: 0.004740139469504356, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.61569095]\n",
      " [0.62292337]\n",
      " [0.6309424 ]\n",
      " [0.63873565]\n",
      " [0.64717519]\n",
      " [0.65542233]\n",
      " [0.66325545]\n",
      " [0.67121482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.67865247]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.61569095]\n",
      "  [0.62292337]\n",
      "  [0.6309424 ]\n",
      "  [0.63873565]\n",
      "  [0.64717519]\n",
      "  [0.65542233]\n",
      "  [0.66325545]\n",
      "  [0.67121482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.668601028854027e-05\n",
      "Predicción post entrenamiento : [[0.67810196]]\n",
      "PERDIDAAAA despues: 6.73473987262696e-05\n",
      "loss en el callback: 0.006649129558354616, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.62292337]\n",
      " [0.6309424 ]\n",
      " [0.63873565]\n",
      " [0.64717519]\n",
      " [0.65542233]\n",
      " [0.66325545]\n",
      " [0.67121482]\n",
      " [0.67865247]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.68510085]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.62292337]\n",
      "  [0.6309424 ]\n",
      "  [0.63873565]\n",
      "  [0.64717519]\n",
      "  [0.65542233]\n",
      "  [0.66325545]\n",
      "  [0.67121482]\n",
      "  [0.67865247]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001329033839283511\n",
      "Predicción post entrenamiento : [[0.6853797]]\n",
      "PERDIDAAAA despues: 0.0001265522005269304\n",
      "loss en el callback: 0.002346114022657275, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.6309424 ]\n",
      " [0.63873565]\n",
      " [0.64717519]\n",
      " [0.65542233]\n",
      " [0.66325545]\n",
      " [0.67121482]\n",
      " [0.67865247]\n",
      " [0.68510085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6925914]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.6309424 ]\n",
      "  [0.63873565]\n",
      "  [0.64717519]\n",
      "  [0.65542233]\n",
      "  [0.66325545]\n",
      "  [0.67121482]\n",
      "  [0.67865247]\n",
      "  [0.68510085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001342790201306343\n",
      "Predicción post entrenamiento : [[0.69234246]]\n",
      "PERDIDAAAA despues: 0.0013246056623756886\n",
      "loss en el callback: 0.001748831826262176, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.63873565]\n",
      " [0.64717519]\n",
      " [0.65542233]\n",
      " [0.66325545]\n",
      " [0.67121482]\n",
      " [0.67865247]\n",
      " [0.68510085]\n",
      " [0.69259143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.69954246]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.63873565]\n",
      "  [0.64717519]\n",
      "  [0.65542233]\n",
      "  [0.66325545]\n",
      "  [0.67121482]\n",
      "  [0.67865247]\n",
      "  [0.68510085]\n",
      "  [0.69259143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004299734137021005\n",
      "Predicción post entrenamiento : [[0.69907963]]\n",
      "PERDIDAAAA despues: 0.0004109933215659112\n",
      "loss en el callback: 0.0052220881916582584, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.64717519]\n",
      " [0.65542233]\n",
      " [0.66325545]\n",
      " [0.67121482]\n",
      " [0.67865247]\n",
      " [0.68510085]\n",
      " [0.69259143]\n",
      " [0.69954246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7063017]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.64717519]\n",
      "  [0.65542233]\n",
      "  [0.66325545]\n",
      "  [0.67121482]\n",
      "  [0.67865247]\n",
      "  [0.68510085]\n",
      "  [0.69259143]\n",
      "  [0.69954246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009124723146669567\n",
      "Predicción post entrenamiento : [[0.7056228]]\n",
      "PERDIDAAAA despues: 0.0008719181641936302\n",
      "loss en el callback: 0.011033592745661736, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.65542233]\n",
      " [0.66325545]\n",
      " [0.67121482]\n",
      " [0.67865247]\n",
      " [0.68510085]\n",
      " [0.69259143]\n",
      " [0.69954246]\n",
      " [0.70630169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7126383]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.65542233]\n",
      "  [0.66325545]\n",
      "  [0.67121482]\n",
      "  [0.67865247]\n",
      "  [0.68510085]\n",
      "  [0.69259143]\n",
      "  [0.69954246]\n",
      "  [0.70630169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028641652897931635\n",
      "Predicción post entrenamiento : [[0.71237296]]\n",
      "PERDIDAAAA despues: 0.00029546875157393515\n",
      "loss en el callback: 0.0017951480112969875, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.66325545]\n",
      " [0.67121482]\n",
      " [0.67865247]\n",
      " [0.68510085]\n",
      " [0.69259143]\n",
      " [0.69954246]\n",
      " [0.70630169]\n",
      " [0.71263832]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7191704]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.66325545]\n",
      "  [0.67121482]\n",
      "  [0.67865247]\n",
      "  [0.68510085]\n",
      "  [0.69259143]\n",
      "  [0.69954246]\n",
      "  [0.70630169]\n",
      "  [0.71263832]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032011736766435206\n",
      "Predicción post entrenamiento : [[0.7188987]]\n",
      "PERDIDAAAA despues: 0.00031046956428326666\n",
      "loss en el callback: 0.0019667292945086956, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.67121482]\n",
      " [0.67865247]\n",
      " [0.68510085]\n",
      " [0.69259143]\n",
      " [0.69954246]\n",
      " [0.70630169]\n",
      " [0.71263832]\n",
      " [0.71917039]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.72553396]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.67121482]\n",
      "  [0.67865247]\n",
      "  [0.68510085]\n",
      "  [0.69259143]\n",
      "  [0.69954246]\n",
      "  [0.70630169]\n",
      "  [0.71263832]\n",
      "  [0.71917039]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001763834385201335\n",
      "Predicción post entrenamiento : [[0.7254815]]\n",
      "PERDIDAAAA despues: 0.0017682429170235991\n",
      "loss en el callback: 7.246767927426845e-05, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.67865247]\n",
      " [0.68510085]\n",
      " [0.69259143]\n",
      " [0.69954246]\n",
      " [0.70630169]\n",
      " [0.71263832]\n",
      " [0.71917039]\n",
      " [0.72553396]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7318612]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.67865247]\n",
      "  [0.68510085]\n",
      "  [0.69259143]\n",
      "  [0.69954246]\n",
      "  [0.70630169]\n",
      "  [0.71263832]\n",
      "  [0.71917039]\n",
      "  [0.72553396]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005416099447757006\n",
      "Predicción post entrenamiento : [[0.731938]]\n",
      "PERDIDAAAA despues: 0.000538039777893573\n",
      "loss en el callback: 0.0001608684251550585, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.68510085]\n",
      " [0.69259143]\n",
      " [0.69954246]\n",
      " [0.70630169]\n",
      " [0.71263832]\n",
      " [0.71917039]\n",
      " [0.72553396]\n",
      " [0.73186117]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.73815525]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.68510085]\n",
      "  [0.69259143]\n",
      "  [0.69954246]\n",
      "  [0.70630169]\n",
      "  [0.71263832]\n",
      "  [0.71917039]\n",
      "  [0.72553396]\n",
      "  [0.73186117]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.767599966726266e-05\n",
      "Predicción post entrenamiento : [[0.7377657]]\n",
      "PERDIDAAAA despues: 5.32067715539597e-05\n",
      "loss en el callback: 0.003735447069630027, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.69259143]\n",
      " [0.69954246]\n",
      " [0.70630169]\n",
      " [0.71263832]\n",
      " [0.71917039]\n",
      " [0.72553396]\n",
      " [0.73186117]\n",
      " [0.73815525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.744073]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.69259143]\n",
      "  [0.69954246]\n",
      "  [0.70630169]\n",
      "  [0.71263832]\n",
      "  [0.71917039]\n",
      "  [0.72553396]\n",
      "  [0.73186117]\n",
      "  [0.73815525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.337902595987543e-05\n",
      "Predicción post entrenamiento : [[0.74439406]]\n",
      "PERDIDAAAA despues: 5.836966374772601e-05\n",
      "loss en el callback: 0.003357113339006901, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.69954246]\n",
      " [0.70630169]\n",
      " [0.71263832]\n",
      " [0.71917039]\n",
      " [0.72553396]\n",
      " [0.73186117]\n",
      " [0.73815525]\n",
      " [0.74407297]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7504668]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.69954246]\n",
      "  [0.70630169]\n",
      "  [0.71263832]\n",
      "  [0.71917039]\n",
      "  [0.72553396]\n",
      "  [0.73186117]\n",
      "  [0.73815525]\n",
      "  [0.74407297]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016535961767658591\n",
      "Predicción post entrenamiento : [[0.74990803]]\n",
      "PERDIDAAAA despues: 0.0016084624221548438\n",
      "loss en el callback: 0.008495836518704891, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.70630169]\n",
      " [0.71263832]\n",
      " [0.71917039]\n",
      " [0.72553396]\n",
      " [0.73186117]\n",
      " [0.73815525]\n",
      " [0.74407297]\n",
      " [0.75046682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7558517]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.70630169]\n",
      "  [0.71263832]\n",
      "  [0.71917039]\n",
      "  [0.72553396]\n",
      "  [0.73186117]\n",
      "  [0.73815525]\n",
      "  [0.74407297]\n",
      "  [0.75046682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042799911461770535\n",
      "Predicción post entrenamiento : [[0.7551963]]\n",
      "PERDIDAAAA despues: 0.004194664303213358\n",
      "loss en el callback: 0.011838411912322044, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.71263832]\n",
      " [0.71917039]\n",
      " [0.72553396]\n",
      " [0.73186117]\n",
      " [0.73815525]\n",
      " [0.74407297]\n",
      " [0.75046682]\n",
      " [0.75585169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.76103073]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.71263832]\n",
      "  [0.71917039]\n",
      "  [0.72553396]\n",
      "  [0.73186117]\n",
      "  [0.73815525]\n",
      "  [0.74407297]\n",
      "  [0.75046682]\n",
      "  [0.75585169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.451511995284818e-05\n",
      "Predicción post entrenamiento : [[0.76081496]]\n",
      "PERDIDAAAA despues: 4.168246960034594e-05\n",
      "loss en el callback: 0.0013306476175785065, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.71917039]\n",
      " [0.72553396]\n",
      " [0.73186117]\n",
      " [0.73815525]\n",
      " [0.74407297]\n",
      " [0.75046682]\n",
      " [0.75585169]\n",
      " [0.76103073]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7666322]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.71917039]\n",
      "  [0.72553396]\n",
      "  [0.73186117]\n",
      "  [0.73815525]\n",
      "  [0.74407297]\n",
      "  [0.75046682]\n",
      "  [0.75585169]\n",
      "  [0.76103073]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019741589203476906\n",
      "Predicción post entrenamiento : [[0.7667377]]\n",
      "PERDIDAAAA despues: 0.001983545022085309\n",
      "loss en el callback: 0.00040814411477185786, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.72553396]\n",
      " [0.73186117]\n",
      " [0.73815525]\n",
      " [0.74407297]\n",
      " [0.75046682]\n",
      " [0.75585169]\n",
      " [0.76103073]\n",
      " [0.7666322 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7724506]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.72553396]\n",
      "  [0.73186117]\n",
      "  [0.73815525]\n",
      "  [0.74407297]\n",
      "  [0.75046682]\n",
      "  [0.75585169]\n",
      "  [0.76103073]\n",
      "  [0.7666322 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005784778390079737\n",
      "Predicción post entrenamiento : [[0.7729511]]\n",
      "PERDIDAAAA despues: 0.005708895158022642\n",
      "loss en el callback: 0.007422334514558315, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.73186117]\n",
      " [0.73815525]\n",
      " [0.74407297]\n",
      " [0.75046682]\n",
      " [0.75585169]\n",
      " [0.76103073]\n",
      " [0.7666322 ]\n",
      " [0.77245063]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.778572]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.73186117]\n",
      "  [0.73815525]\n",
      "  [0.74407297]\n",
      "  [0.75046682]\n",
      "  [0.75585169]\n",
      "  [0.76103073]\n",
      "  [0.7666322 ]\n",
      "  [0.77245063]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01610131561756134\n",
      "Predicción post entrenamiento : [[0.77949107]]\n",
      "PERDIDAAAA despues: 0.01586892269551754\n",
      "loss en el callback: 0.02923082932829857, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.73815525]\n",
      " [0.74407297]\n",
      " [0.75046682]\n",
      " [0.75585169]\n",
      " [0.76103073]\n",
      " [0.7666322 ]\n",
      " [0.77245063]\n",
      " [0.77857202]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.78499854]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.73815525]\n",
      "  [0.74407297]\n",
      "  [0.75046682]\n",
      "  [0.75585169]\n",
      "  [0.76103073]\n",
      "  [0.7666322 ]\n",
      "  [0.77245063]\n",
      "  [0.77857202]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009451277554035187\n",
      "Predicción post entrenamiento : [[0.7846494]]\n",
      "PERDIDAAAA despues: 0.009519289247691631\n",
      "loss en el callback: 0.0028936497401446104, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.74407297]\n",
      " [0.75046682]\n",
      " [0.75585169]\n",
      " [0.76103073]\n",
      " [0.7666322 ]\n",
      " [0.77245063]\n",
      " [0.77857202]\n",
      " [0.78499854]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.79002374]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.74407297]\n",
      "  [0.75046682]\n",
      "  [0.75585169]\n",
      "  [0.76103073]\n",
      "  [0.7666322 ]\n",
      "  [0.77245063]\n",
      "  [0.77857202]\n",
      "  [0.78499854]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013868344947695732\n",
      "Predicción post entrenamiento : [[0.791356]]\n",
      "PERDIDAAAA despues: 0.013556329533457756\n",
      "loss en el callback: 0.07796423137187958, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.75046682]\n",
      " [0.75585169]\n",
      " [0.76103073]\n",
      " [0.7666322 ]\n",
      " [0.77245063]\n",
      " [0.77857202]\n",
      " [0.78499854]\n",
      " [0.79002374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.7966922]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.75046682]\n",
      "  [0.75585169]\n",
      "  [0.76103073]\n",
      "  [0.7666322 ]\n",
      "  [0.77245063]\n",
      "  [0.77857202]\n",
      "  [0.78499854]\n",
      "  [0.79002374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008627714589238167\n",
      "Predicción post entrenamiento : [[0.7967669]]\n",
      "PERDIDAAAA despues: 0.008613846264779568\n",
      "loss en el callback: 0.0001514604955445975, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.75585169]\n",
      " [0.76103073]\n",
      " [0.7666322 ]\n",
      " [0.77245063]\n",
      " [0.77857202]\n",
      " [0.78499854]\n",
      " [0.79002374]\n",
      " [0.79669219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8019144]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.75585169]\n",
      "  [0.76103073]\n",
      "  [0.7666322 ]\n",
      "  [0.77245063]\n",
      "  [0.77857202]\n",
      "  [0.78499854]\n",
      "  [0.79002374]\n",
      "  [0.79669219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00532028591260314\n",
      "Predicción post entrenamiento : [[0.8020126]]\n",
      "PERDIDAAAA despues: 0.005305965896695852\n",
      "loss en el callback: 0.00028082740027457476, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.76103073]\n",
      " [0.7666322 ]\n",
      " [0.77245063]\n",
      " [0.77857202]\n",
      " [0.78499854]\n",
      " [0.79002374]\n",
      " [0.79669219]\n",
      " [0.80191439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8072635]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.76103073]\n",
      "  [0.7666322 ]\n",
      "  [0.77245063]\n",
      "  [0.77857202]\n",
      "  [0.78499854]\n",
      "  [0.79002374]\n",
      "  [0.79669219]\n",
      "  [0.80191439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011225073598325253\n",
      "Predicción post entrenamiento : [[0.8076198]]\n",
      "PERDIDAAAA despues: 0.011149697937071323\n",
      "loss en el callback: 0.0038286023773252964, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.7666322 ]\n",
      " [0.77245063]\n",
      " [0.77857202]\n",
      " [0.78499854]\n",
      " [0.79002374]\n",
      " [0.79669219]\n",
      " [0.80191439]\n",
      " [0.80726349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8130592]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.7666322 ]\n",
      "  [0.77245063]\n",
      "  [0.77857202]\n",
      "  [0.78499854]\n",
      "  [0.79002374]\n",
      "  [0.79669219]\n",
      "  [0.80191439]\n",
      "  [0.80726349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03494685888290405\n",
      "Predicción post entrenamiento : [[0.81416374]]\n",
      "PERDIDAAAA despues: 0.03453511372208595\n",
      "loss en el callback: 0.04191294685006142, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.77245063]\n",
      " [0.77857202]\n",
      " [0.78499854]\n",
      " [0.79002374]\n",
      " [0.79669219]\n",
      " [0.80191439]\n",
      " [0.80726349]\n",
      " [0.81305921]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.819687]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.77245063]\n",
      "  [0.77857202]\n",
      "  [0.78499854]\n",
      "  [0.79002374]\n",
      "  [0.79669219]\n",
      "  [0.80191439]\n",
      "  [0.80726349]\n",
      "  [0.81305921]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022760864347219467\n",
      "Predicción post entrenamiento : [[0.82026637]]\n",
      "PERDIDAAAA despues: 0.022586388513445854\n",
      "loss en el callback: 0.010001590475440025, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.77857202]\n",
      " [0.78499854]\n",
      " [0.79002374]\n",
      " [0.79669219]\n",
      " [0.80191439]\n",
      " [0.80726349]\n",
      " [0.81305921]\n",
      " [0.81968701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.82581216]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.77857202]\n",
      "  [0.78499854]\n",
      "  [0.79002374]\n",
      "  [0.79669219]\n",
      "  [0.80191439]\n",
      "  [0.80726349]\n",
      "  [0.81305921]\n",
      "  [0.81968701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003967816475778818\n",
      "Predicción post entrenamiento : [[0.8265363]]\n",
      "PERDIDAAAA despues: 0.0038771131075918674\n",
      "loss en el callback: 0.02080860547721386, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.78499854]\n",
      " [0.79002374]\n",
      " [0.79669219]\n",
      " [0.80191439]\n",
      " [0.80726349]\n",
      " [0.81305921]\n",
      " [0.81968701]\n",
      " [0.82581216]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.83201087]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.78499854]\n",
      "  [0.79002374]\n",
      "  [0.79669219]\n",
      "  [0.80191439]\n",
      "  [0.80726349]\n",
      "  [0.81305921]\n",
      "  [0.81968701]\n",
      "  [0.82581216]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002110799541696906\n",
      "Predicción post entrenamiento : [[0.83236665]]\n",
      "PERDIDAAAA despues: 0.0020782346837222576\n",
      "loss en el callback: 0.004561553709208965, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.79002374]\n",
      " [0.79669219]\n",
      " [0.80191439]\n",
      " [0.80726349]\n",
      " [0.81305921]\n",
      " [0.81968701]\n",
      " [0.82581216]\n",
      " [0.83201087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.83766747]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.79002374]\n",
      "  [0.79669219]\n",
      "  [0.80191439]\n",
      "  [0.80726349]\n",
      "  [0.81305921]\n",
      "  [0.81968701]\n",
      "  [0.82581216]\n",
      "  [0.83201087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001260752324014902\n",
      "Predicción post entrenamiento : [[0.8375198]]\n",
      "PERDIDAAAA despues: 0.00012941255408804864\n",
      "loss en el callback: 0.0007066820980980992, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.79669219]\n",
      " [0.80191439]\n",
      " [0.80726349]\n",
      " [0.81305921]\n",
      " [0.81968701]\n",
      " [0.82581216]\n",
      " [0.83201087]\n",
      " [0.83766747]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.84306496]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.79669219]\n",
      "  [0.80191439]\n",
      "  [0.80726349]\n",
      "  [0.81305921]\n",
      "  [0.81968701]\n",
      "  [0.82581216]\n",
      "  [0.83201087]\n",
      "  [0.83766747]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.907083636382595e-05\n",
      "Predicción post entrenamiento : [[0.84351504]]\n",
      "PERDIDAAAA despues: 8.727769454708323e-05\n",
      "loss en el callback: 0.008498726412653923, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.80191439]\n",
      " [0.80726349]\n",
      " [0.81305921]\n",
      " [0.81968701]\n",
      " [0.82581216]\n",
      " [0.83201087]\n",
      " [0.83766747]\n",
      " [0.84306496]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8488355]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.80191439]\n",
      "  [0.80726349]\n",
      "  [0.81305921]\n",
      "  [0.81968701]\n",
      "  [0.82581216]\n",
      "  [0.83201087]\n",
      "  [0.83766747]\n",
      "  [0.84306496]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.9179860323201865e-05\n",
      "Predicción post entrenamiento : [[0.8482671]]\n",
      "PERDIDAAAA despues: 4.6619279601145536e-05\n",
      "loss en el callback: 0.008949998766183853, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.80726349]\n",
      " [0.81305921]\n",
      " [0.81968701]\n",
      " [0.82581216]\n",
      " [0.83201087]\n",
      " [0.83766747]\n",
      " [0.84306496]\n",
      " [0.84883553]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8537816]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.80726349]\n",
      "  [0.81305921]\n",
      "  [0.81968701]\n",
      "  [0.82581216]\n",
      "  [0.83201087]\n",
      "  [0.83766747]\n",
      "  [0.84306496]\n",
      "  [0.84883553]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00046055702841840684\n",
      "Predicción post entrenamiento : [[0.8540209]]\n",
      "PERDIDAAAA despues: 0.0004503427189774811\n",
      "loss en el callback: 0.0020051803439855576, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.81305921]\n",
      " [0.81968701]\n",
      " [0.82581216]\n",
      " [0.83201087]\n",
      " [0.83766747]\n",
      " [0.84306496]\n",
      " [0.84883553]\n",
      " [0.85378158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.85971504]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.81305921]\n",
      "  [0.81968701]\n",
      "  [0.82581216]\n",
      "  [0.83201087]\n",
      "  [0.83766747]\n",
      "  [0.84306496]\n",
      "  [0.84883553]\n",
      "  [0.85378158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.197762897703797e-06\n",
      "Predicción post entrenamiento : [[0.85987246]]\n",
      "PERDIDAAAA despues: 8.067193448368926e-06\n",
      "loss en el callback: 0.0010393812553957105, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.81968701]\n",
      " [0.82581216]\n",
      " [0.83201087]\n",
      " [0.83766747]\n",
      " [0.84306496]\n",
      " [0.84883553]\n",
      " [0.85378158]\n",
      " [0.85971504]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8656149]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.81968701]\n",
      "  [0.82581216]\n",
      "  [0.83201087]\n",
      "  [0.83766747]\n",
      "  [0.84306496]\n",
      "  [0.84883553]\n",
      "  [0.85378158]\n",
      "  [0.85971504]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024201255291700363\n",
      "Predicción post entrenamiento : [[0.8655242]]\n",
      "PERDIDAAAA despues: 0.0002391982270637527\n",
      "loss en el callback: 0.0002721062919590622, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.82581216]\n",
      " [0.83201087]\n",
      " [0.83766747]\n",
      " [0.84306496]\n",
      " [0.84883553]\n",
      " [0.85378158]\n",
      " [0.85971504]\n",
      " [0.86561489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8710399]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.82581216]\n",
      "  [0.83201087]\n",
      "  [0.83766747]\n",
      "  [0.84306496]\n",
      "  [0.84883553]\n",
      "  [0.85378158]\n",
      "  [0.85971504]\n",
      "  [0.86561489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008033437770791352\n",
      "Predicción post entrenamiento : [[0.8697203]]\n",
      "PERDIDAAAA despues: 0.0007302789017558098\n",
      "loss en el callback: 0.04614633694291115, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.83201087]\n",
      " [0.83766747]\n",
      " [0.84306496]\n",
      " [0.84883553]\n",
      " [0.85378158]\n",
      " [0.85971504]\n",
      " [0.86561489]\n",
      " [0.87103993]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.87511337]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.83201087]\n",
      "  [0.83766747]\n",
      "  [0.84306496]\n",
      "  [0.84883553]\n",
      "  [0.85378158]\n",
      "  [0.85971504]\n",
      "  [0.86561489]\n",
      "  [0.87103993]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002722390927374363\n",
      "Predicción post entrenamiento : [[0.87430286]]\n",
      "PERDIDAAAA despues: 0.0026384692173451185\n",
      "loss en el callback: 0.020455241203308105, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.83766747]\n",
      " [0.84306496]\n",
      " [0.84883553]\n",
      " [0.85378158]\n",
      " [0.85971504]\n",
      " [0.86561489]\n",
      " [0.87103993]\n",
      " [0.87511337]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.87951636]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.83766747]\n",
      "  [0.84306496]\n",
      "  [0.84883553]\n",
      "  [0.85378158]\n",
      "  [0.85971504]\n",
      "  [0.86561489]\n",
      "  [0.87103993]\n",
      "  [0.87511337]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011027169413864613\n",
      "Predicción post entrenamiento : [[0.8789054]]\n",
      "PERDIDAAAA despues: 0.01089923083782196\n",
      "loss en el callback: 0.013715970329940319, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.84306496]\n",
      " [0.84883553]\n",
      " [0.85378158]\n",
      " [0.85971504]\n",
      " [0.86561489]\n",
      " [0.87103993]\n",
      " [0.87511337]\n",
      " [0.87951636]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8840634]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.84306496]\n",
      "  [0.84883553]\n",
      "  [0.85378158]\n",
      "  [0.85971504]\n",
      "  [0.86561489]\n",
      "  [0.87103993]\n",
      "  [0.87511337]\n",
      "  [0.87951636]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00997427199035883\n",
      "Predicción post entrenamiento : [[0.8839191]]\n",
      "PERDIDAAAA despues: 0.009945469908416271\n",
      "loss en el callback: 0.0008723300416022539, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.84883553]\n",
      " [0.85378158]\n",
      " [0.85971504]\n",
      " [0.86561489]\n",
      " [0.87103993]\n",
      " [0.87511337]\n",
      " [0.87951636]\n",
      " [0.88406342]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8890706]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.84883553]\n",
      "  [0.85378158]\n",
      "  [0.85971504]\n",
      "  [0.86561489]\n",
      "  [0.87103993]\n",
      "  [0.87511337]\n",
      "  [0.87951636]\n",
      "  [0.88406342]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008600295404903591\n",
      "Predicción post entrenamiento : [[0.88904077]]\n",
      "PERDIDAAAA despues: 0.0008582824375480413\n",
      "loss en el callback: 3.571995330275968e-05, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.85378158]\n",
      " [0.85971504]\n",
      " [0.86561489]\n",
      " [0.87103993]\n",
      " [0.87511337]\n",
      " [0.87951636]\n",
      " [0.88406342]\n",
      " [0.88907057]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.89403933]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.85378158]\n",
      "  [0.85971504]\n",
      "  [0.86561489]\n",
      "  [0.87103993]\n",
      "  [0.87511337]\n",
      "  [0.87951636]\n",
      "  [0.88406342]\n",
      "  [0.88907057]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015776214422658086\n",
      "Predicción post entrenamiento : [[0.8935309]]\n",
      "PERDIDAAAA despues: 0.001537491218186915\n",
      "loss en el callback: 0.00854447204619646, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.85971504]\n",
      " [0.86561489]\n",
      " [0.87103993]\n",
      " [0.87511337]\n",
      " [0.87951636]\n",
      " [0.88406342]\n",
      " [0.88907057]\n",
      " [0.89403933]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8985846]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.85971504]\n",
      "  [0.86561489]\n",
      "  [0.87103993]\n",
      "  [0.87511337]\n",
      "  [0.87951636]\n",
      "  [0.88406342]\n",
      "  [0.88907057]\n",
      "  [0.89403933]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038068515714257956\n",
      "Predicción post entrenamiento : [[0.8980332]]\n",
      "PERDIDAAAA despues: 0.0037391127552837133\n",
      "loss en el callback: 0.009812741540372372, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.86561489]\n",
      " [0.87103993]\n",
      " [0.87511337]\n",
      " [0.87951636]\n",
      " [0.88406342]\n",
      " [0.88907057]\n",
      " [0.89403933]\n",
      " [0.8985846 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.90281105]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.86561489]\n",
      "  [0.87103993]\n",
      "  [0.87511337]\n",
      "  [0.87951636]\n",
      "  [0.88406342]\n",
      "  [0.88907057]\n",
      "  [0.89403933]\n",
      "  [0.8985846 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005314435809850693\n",
      "Predicción post entrenamiento : [[0.90230644]]\n",
      "PERDIDAAAA despues: 0.005241117440164089\n",
      "loss en el callback: 0.009487876668572426, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.87103993]\n",
      " [0.87511337]\n",
      " [0.87951636]\n",
      " [0.88406342]\n",
      " [0.88907057]\n",
      " [0.89403933]\n",
      " [0.8985846 ]\n",
      " [0.90281105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9067553]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.87103993]\n",
      "  [0.87511337]\n",
      "  [0.87951636]\n",
      "  [0.88406342]\n",
      "  [0.88907057]\n",
      "  [0.89403933]\n",
      "  [0.8985846 ]\n",
      "  [0.90281105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000380341341951862\n",
      "Predicción post entrenamiento : [[0.90553266]]\n",
      "PERDIDAAAA despues: 0.00033414640347473323\n",
      "loss en el callback: 0.03975166380405426, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.87511337]\n",
      " [0.87951636]\n",
      " [0.88406342]\n",
      " [0.88907057]\n",
      " [0.89403933]\n",
      " [0.8985846 ]\n",
      " [0.90281105]\n",
      " [0.90675533]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9097397]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.87511337]\n",
      "  [0.87951636]\n",
      "  [0.88406342]\n",
      "  [0.88907057]\n",
      "  [0.89403933]\n",
      "  [0.8985846 ]\n",
      "  [0.90281105]\n",
      "  [0.90675533]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024995363783091307\n",
      "Predicción post entrenamiento : [[0.91030097]]\n",
      "PERDIDAAAA despues: 0.0025559759233146906\n",
      "loss en el callback: 0.015955163165926933, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.87951636]\n",
      " [0.88406342]\n",
      " [0.88907057]\n",
      " [0.89403933]\n",
      " [0.8985846 ]\n",
      " [0.90281105]\n",
      " [0.90675533]\n",
      " [0.90973967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.91464543]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.87951636]\n",
      "  [0.88406342]\n",
      "  [0.88907057]\n",
      "  [0.89403933]\n",
      "  [0.8985846 ]\n",
      "  [0.90281105]\n",
      "  [0.90675533]\n",
      "  [0.90973967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005632260348647833\n",
      "Predicción post entrenamiento : [[0.915066]]\n",
      "PERDIDAAAA despues: 0.005695563741028309\n",
      "loss en el callback: 0.01017539668828249, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.88406342]\n",
      " [0.88907057]\n",
      " [0.89403933]\n",
      " [0.8985846 ]\n",
      " [0.90281105]\n",
      " [0.90675533]\n",
      " [0.90973967]\n",
      " [0.91464543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9194485]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.88406342]\n",
      "  [0.88907057]\n",
      "  [0.89403933]\n",
      "  [0.8985846 ]\n",
      "  [0.90281105]\n",
      "  [0.90675533]\n",
      "  [0.90973967]\n",
      "  [0.91464543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018399234861135483\n",
      "Predicción post entrenamiento : [[0.9194971]]\n",
      "PERDIDAAAA despues: 0.01841241680085659\n",
      "loss en el callback: 0.00011543813889147714, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.88907057]\n",
      " [0.89403933]\n",
      " [0.8985846 ]\n",
      " [0.90281105]\n",
      " [0.90675533]\n",
      " [0.90973967]\n",
      " [0.91464543]\n",
      " [0.91944849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.92385817]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.88907057]\n",
      "  [0.89403933]\n",
      "  [0.8985846 ]\n",
      "  [0.90281105]\n",
      "  [0.90675533]\n",
      "  [0.90973967]\n",
      "  [0.91464543]\n",
      "  [0.91944849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011145167052745819\n",
      "Predicción post entrenamiento : [[0.92241967]]\n",
      "PERDIDAAAA despues: 0.010843509808182716\n",
      "loss en el callback: 0.06187915802001953, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.89403933]\n",
      " [0.8985846 ]\n",
      " [0.90281105]\n",
      " [0.90675533]\n",
      " [0.90973967]\n",
      " [0.91464543]\n",
      " [0.91944849]\n",
      " [0.92385817]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.92659074]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.89403933]\n",
      "  [0.8985846 ]\n",
      "  [0.90281105]\n",
      "  [0.90675533]\n",
      "  [0.90973967]\n",
      "  [0.91464543]\n",
      "  [0.91944849]\n",
      "  [0.92385817]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01833980903029442\n",
      "Predicción post entrenamiento : [[0.9256459]]\n",
      "PERDIDAAAA despues: 0.01808479055762291\n",
      "loss en el callback: 0.03195453807711601, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.8985846 ]\n",
      " [0.90281105]\n",
      " [0.90675533]\n",
      " [0.90973967]\n",
      " [0.91464543]\n",
      " [0.91944849]\n",
      " [0.92385817]\n",
      " [0.92659074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.929595]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.8985846 ]\n",
      "  [0.90281105]\n",
      "  [0.90675533]\n",
      "  [0.90973967]\n",
      "  [0.91464543]\n",
      "  [0.91944849]\n",
      "  [0.92385817]\n",
      "  [0.92659074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028573522344231606\n",
      "Predicción post entrenamiento : [[0.9289943]]\n",
      "PERDIDAAAA despues: 0.028370803222060204\n",
      "loss en el callback: 0.015457055531442165, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.90281105]\n",
      " [0.90675533]\n",
      " [0.90973967]\n",
      " [0.91464543]\n",
      " [0.91944849]\n",
      " [0.92385817]\n",
      " [0.92659074]\n",
      " [0.92959499]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9328066]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.90281105]\n",
      "  [0.90675533]\n",
      "  [0.90973967]\n",
      "  [0.91464543]\n",
      "  [0.91944849]\n",
      "  [0.92385817]\n",
      "  [0.92659074]\n",
      "  [0.92959499]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01995239220559597\n",
      "Predicción post entrenamiento : [[0.9311567]]\n",
      "PERDIDAAAA despues: 0.019489003345370293\n",
      "loss en el callback: 0.0836191326379776, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.90675533]\n",
      " [0.90973967]\n",
      " [0.91464543]\n",
      " [0.91944849]\n",
      " [0.92385817]\n",
      " [0.92659074]\n",
      " [0.92959499]\n",
      " [0.93280661]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.93489397]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.90675533]\n",
      "  [0.90973967]\n",
      "  [0.91464543]\n",
      "  [0.91944849]\n",
      "  [0.92385817]\n",
      "  [0.92659074]\n",
      "  [0.92959499]\n",
      "  [0.93280661]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02762233465909958\n",
      "Predicción post entrenamiento : [[0.9344713]]\n",
      "PERDIDAAAA despues: 0.02748202346265316\n",
      "loss en el callback: 0.008135998621582985, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.90973967]\n",
      " [0.91464543]\n",
      " [0.91944849]\n",
      " [0.92385817]\n",
      " [0.92659074]\n",
      " [0.92959499]\n",
      " [0.93280661]\n",
      " [0.93489397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.93818545]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.90973967]\n",
      "  [0.91464543]\n",
      "  [0.91944849]\n",
      "  [0.92385817]\n",
      "  [0.92659074]\n",
      "  [0.92959499]\n",
      "  [0.93280661]\n",
      "  [0.93489397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028727257624268532\n",
      "Predicción post entrenamiento : [[0.9378554]]\n",
      "PERDIDAAAA despues: 0.028615491464734077\n",
      "loss en el callback: 0.005395440850406885, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.91464543]\n",
      " [0.91944849]\n",
      " [0.92385817]\n",
      " [0.92659074]\n",
      " [0.92959499]\n",
      " [0.93280661]\n",
      " [0.93489397]\n",
      " [0.93818545]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9418086]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.91464543]\n",
      "  [0.91944849]\n",
      "  [0.92385817]\n",
      "  [0.92659074]\n",
      "  [0.92959499]\n",
      "  [0.93280661]\n",
      "  [0.93489397]\n",
      "  [0.93818545]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02041853405535221\n",
      "Predicción post entrenamiento : [[0.9411168]]\n",
      "PERDIDAAAA despues: 0.02022131346166134\n",
      "loss en el callback: 0.018922822549939156, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.91944849]\n",
      " [0.92385817]\n",
      " [0.92659074]\n",
      " [0.92959499]\n",
      " [0.93280661]\n",
      " [0.93489397]\n",
      " [0.93818545]\n",
      " [0.94180858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9446913]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.91944849]\n",
      "  [0.92385817]\n",
      "  [0.92659074]\n",
      "  [0.92959499]\n",
      "  [0.93280661]\n",
      "  [0.93489397]\n",
      "  [0.93818545]\n",
      "  [0.94180858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023928193375468254\n",
      "Predicción post entrenamiento : [[0.94377595]]\n",
      "PERDIDAAAA despues: 0.02364584431052208\n",
      "loss en el callback: 0.03343928977847099, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.92385817]\n",
      " [0.92659074]\n",
      " [0.92959499]\n",
      " [0.93280661]\n",
      " [0.93489397]\n",
      " [0.93818545]\n",
      " [0.94180858]\n",
      " [0.9446913 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.94690835]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.92385817]\n",
      "  [0.92659074]\n",
      "  [0.92959499]\n",
      "  [0.93280661]\n",
      "  [0.93489397]\n",
      "  [0.93818545]\n",
      "  [0.94180858]\n",
      "  [0.9446913 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034871041774749756\n",
      "Predicción post entrenamiento : [[0.94627136]]\n",
      "PERDIDAAAA despues: 0.03463354334235191\n",
      "loss en el callback: 0.017853403463959694, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.92659074]\n",
      " [0.92959499]\n",
      " [0.93280661]\n",
      " [0.93489397]\n",
      " [0.93818545]\n",
      " [0.94180858]\n",
      " [0.9446913 ]\n",
      " [0.94690835]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.94899803]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.92659074]\n",
      "  [0.92959499]\n",
      "  [0.93280661]\n",
      "  [0.93489397]\n",
      "  [0.93818545]\n",
      "  [0.94180858]\n",
      "  [0.9446913 ]\n",
      "  [0.94690835]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06948746740818024\n",
      "Predicción post entrenamiento : [[0.946916]]\n",
      "PERDIDAAAA despues: 0.06839412450790405\n",
      "loss en el callback: 0.1521896868944168, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.92959499]\n",
      " [0.93280661]\n",
      " [0.93489397]\n",
      " [0.93818545]\n",
      " [0.94180858]\n",
      " [0.9446913 ]\n",
      " [0.94690835]\n",
      " [0.94899803]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.94969386]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.92959499]\n",
      "  [0.93280661]\n",
      "  [0.93489397]\n",
      "  [0.93818545]\n",
      "  [0.94180858]\n",
      "  [0.9446913 ]\n",
      "  [0.94690835]\n",
      "  [0.94899803]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11868169158697128\n",
      "Predicción post entrenamiento : [[0.9475105]]\n",
      "PERDIDAAAA despues: 0.11718209832906723\n",
      "loss en el callback: 0.17817193269729614, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.93280661]\n",
      " [0.93489397]\n",
      " [0.93818545]\n",
      " [0.94180858]\n",
      " [0.9446913 ]\n",
      " [0.94690835]\n",
      " [0.94899803]\n",
      " [0.94969386]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.95023954]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.93280661]\n",
      "  [0.93489397]\n",
      "  [0.93818545]\n",
      "  [0.94180858]\n",
      "  [0.9446913 ]\n",
      "  [0.94690835]\n",
      "  [0.94899803]\n",
      "  [0.94969386]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08144228905439377\n",
      "Predicción post entrenamiento : [[0.9476479]]\n",
      "PERDIDAAAA despues: 0.07996981590986252\n",
      "loss en el callback: 0.21860571205615997, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.93489397]\n",
      " [0.93818545]\n",
      " [0.94180858]\n",
      " [0.9446913 ]\n",
      " [0.94690835]\n",
      " [0.94899803]\n",
      " [0.94969386]\n",
      " [0.95023954]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9502152]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.93489397]\n",
      "  [0.93818545]\n",
      "  [0.94180858]\n",
      "  [0.9446913 ]\n",
      "  [0.94690835]\n",
      "  [0.94899803]\n",
      "  [0.94969386]\n",
      "  [0.95023954]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05873354151844978\n",
      "Predicción post entrenamiento : [[0.94874024]]\n",
      "PERDIDAAAA despues: 0.05802079662680626\n",
      "loss en el callback: 0.08989017456769943, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.93818545]\n",
      " [0.94180858]\n",
      " [0.9446913 ]\n",
      " [0.94690835]\n",
      " [0.94899803]\n",
      " [0.94969386]\n",
      " [0.95023954]\n",
      " [0.95021522]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.95141685]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.93818545]\n",
      "  [0.94180858]\n",
      "  [0.9446913 ]\n",
      "  [0.94690835]\n",
      "  [0.94899803]\n",
      "  [0.94969386]\n",
      "  [0.95023954]\n",
      "  [0.95021522]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08211564272642136\n",
      "Predicción post entrenamiento : [[0.94974756]]\n",
      "PERDIDAAAA despues: 0.081161729991436\n",
      "loss en el callback: 0.11209854483604431, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.94180858]\n",
      " [0.9446913 ]\n",
      " [0.94690835]\n",
      " [0.94899803]\n",
      " [0.94969386]\n",
      " [0.95023954]\n",
      " [0.95021522]\n",
      " [0.95141685]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.95209527]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.94180858]\n",
      "  [0.9446913 ]\n",
      "  [0.94690835]\n",
      "  [0.94899803]\n",
      "  [0.94969386]\n",
      "  [0.95023954]\n",
      "  [0.95021522]\n",
      "  [0.95141685]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0579572394490242\n",
      "Predicción post entrenamiento : [[0.94977033]]\n",
      "PERDIDAAAA despues: 0.05684322118759155\n",
      "loss en el callback: 0.18123136460781097, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.9446913 ]\n",
      " [0.94690835]\n",
      " [0.94899803]\n",
      " [0.94969386]\n",
      " [0.95023954]\n",
      " [0.95021522]\n",
      " [0.95141685]\n",
      " [0.95209527]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.95155877]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.9446913 ]\n",
      "  [0.94690835]\n",
      "  [0.94899803]\n",
      "  [0.94969386]\n",
      "  [0.95023954]\n",
      "  [0.95021522]\n",
      "  [0.95141685]\n",
      "  [0.95209527]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07524152845144272\n",
      "Predicción post entrenamiento : [[0.94987714]]\n",
      "PERDIDAAAA despues: 0.07432180643081665\n",
      "loss en el callback: 0.11189743876457214, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.94690835]\n",
      " [0.94899803]\n",
      " [0.94969386]\n",
      " [0.95023954]\n",
      " [0.95021522]\n",
      " [0.95141685]\n",
      " [0.95209527]\n",
      " [0.95155877]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9511909]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.94690835]\n",
      "  [0.94899803]\n",
      "  [0.94969386]\n",
      "  [0.95023954]\n",
      "  [0.95021522]\n",
      "  [0.95141685]\n",
      "  [0.95209527]\n",
      "  [0.95155877]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035752441734075546\n",
      "Predicción post entrenamiento : [[0.9513097]]\n",
      "PERDIDAAAA despues: 0.03579737991094589\n",
      "loss en el callback: 0.0009175712475553155, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.94899803]\n",
      " [0.94969386]\n",
      " [0.95023954]\n",
      " [0.95021522]\n",
      " [0.95141685]\n",
      " [0.95209527]\n",
      " [0.95155877]\n",
      " [0.95119089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.95223355]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.94899803]\n",
      "  [0.94969386]\n",
      "  [0.95023954]\n",
      "  [0.95021522]\n",
      "  [0.95141685]\n",
      "  [0.95209527]\n",
      "  [0.95155877]\n",
      "  [0.95119089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021077817305922508\n",
      "Predicción post entrenamiento : [[0.9511651]]\n",
      "PERDIDAAAA despues: 0.02076871320605278\n",
      "loss en el callback: 0.04480960592627525, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.94969386]\n",
      " [0.95023954]\n",
      " [0.95021522]\n",
      " [0.95141685]\n",
      " [0.95209527]\n",
      " [0.95155877]\n",
      " [0.95119089]\n",
      " [0.95223355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9516465]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.94969386]\n",
      "  [0.95023954]\n",
      "  [0.95021522]\n",
      "  [0.95141685]\n",
      "  [0.95209527]\n",
      "  [0.95155877]\n",
      "  [0.95119089]\n",
      "  [0.95223355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018620943650603294\n",
      "Predicción post entrenamiento : [[0.95079297]]\n",
      "PERDIDAAAA despues: 0.01838872581720352\n",
      "loss en el callback: 0.030732640996575356, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.95023954]\n",
      " [0.95021522]\n",
      " [0.95141685]\n",
      " [0.95209527]\n",
      " [0.95155877]\n",
      " [0.95119089]\n",
      " [0.95223355]\n",
      " [0.95164651]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.95118266]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.95023954]\n",
      "  [0.95021522]\n",
      "  [0.95141685]\n",
      "  [0.95209527]\n",
      "  [0.95155877]\n",
      "  [0.95119089]\n",
      "  [0.95223355]\n",
      "  [0.95164651]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020200316794216633\n",
      "Predicción post entrenamiento : [[0.950566]]\n",
      "PERDIDAAAA despues: 0.0019649798050522804\n",
      "loss en el callback: 0.015246815048158169, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.95021522]\n",
      " [0.95141685]\n",
      " [0.95209527]\n",
      " [0.95155877]\n",
      " [0.95119089]\n",
      " [0.95223355]\n",
      " [0.95164651]\n",
      " [0.95118266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9508795]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.95021522]\n",
      "  [0.95141685]\n",
      "  [0.95209527]\n",
      "  [0.95155877]\n",
      "  [0.95119089]\n",
      "  [0.95223355]\n",
      "  [0.95164651]\n",
      "  [0.95118266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.789858500473201e-05\n",
      "Predicción post entrenamiento : [[0.9514296]]\n",
      "PERDIDAAAA despues: 6.84909537085332e-05\n",
      "loss en el callback: 0.020936138927936554, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.95141685]\n",
      " [0.95209527]\n",
      " [0.95155877]\n",
      " [0.95119089]\n",
      " [0.95223355]\n",
      " [0.95164651]\n",
      " [0.95118266]\n",
      " [0.95087951]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9518131]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.95141685]\n",
      "  [0.95209527]\n",
      "  [0.95155877]\n",
      "  [0.95119089]\n",
      "  [0.95223355]\n",
      "  [0.95164651]\n",
      "  [0.95118266]\n",
      "  [0.95087951]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001572960172779858\n",
      "Predicción post entrenamiento : [[0.9521855]]\n",
      "PERDIDAAAA despues: 0.00014809335698373616\n",
      "loss en el callback: 0.007519653532654047, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.95209527]\n",
      " [0.95155877]\n",
      " [0.95119089]\n",
      " [0.95223355]\n",
      " [0.95164651]\n",
      " [0.95118266]\n",
      " [0.95087951]\n",
      " [0.9518131 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9522463]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.95209527]\n",
      "  [0.95155877]\n",
      "  [0.95119089]\n",
      "  [0.95223355]\n",
      "  [0.95164651]\n",
      "  [0.95118266]\n",
      "  [0.95087951]\n",
      "  [0.9518131 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004124002996832132\n",
      "Predicción post entrenamiento : [[0.9523801]]\n",
      "PERDIDAAAA despues: 0.004141207318753004\n",
      "loss en el callback: 0.001100576133467257, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.95155877]\n",
      " [0.95119089]\n",
      " [0.95223355]\n",
      " [0.95164651]\n",
      " [0.95118266]\n",
      " [0.95087951]\n",
      " [0.9518131 ]\n",
      " [0.95224631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9522311]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.95155877]\n",
      "  [0.95119089]\n",
      "  [0.95223355]\n",
      "  [0.95164651]\n",
      "  [0.95118266]\n",
      "  [0.95087951]\n",
      "  [0.9518131 ]\n",
      "  [0.95224631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035466623958200216\n",
      "Predicción post entrenamiento : [[0.95197785]]\n",
      "PERDIDAAAA despues: 0.0035165613517165184\n",
      "loss en el callback: 0.0035235562827438116, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.95119089]\n",
      " [0.95223355]\n",
      " [0.95164651]\n",
      " [0.95118266]\n",
      " [0.95087951]\n",
      " [0.9518131 ]\n",
      " [0.95224631]\n",
      " [0.95223111]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9519791]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.95119089]\n",
      "  [0.95223355]\n",
      "  [0.95164651]\n",
      "  [0.95118266]\n",
      "  [0.95087951]\n",
      "  [0.9518131 ]\n",
      "  [0.95224631]\n",
      "  [0.95223111]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005888556130230427\n",
      "Predicción post entrenamiento : [[0.9518157]]\n",
      "PERDIDAAAA despues: 0.005863508675247431\n",
      "loss en el callback: 0.0015833843499422073, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.95223355]\n",
      " [0.95164651]\n",
      " [0.95118266]\n",
      " [0.95087951]\n",
      " [0.9518131 ]\n",
      " [0.95224631]\n",
      " [0.95223111]\n",
      " [0.9519791 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9519427]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.95223355]\n",
      "  [0.95164651]\n",
      "  [0.95118266]\n",
      "  [0.95087951]\n",
      "  [0.9518131 ]\n",
      "  [0.95224631]\n",
      "  [0.95223111]\n",
      "  [0.9519791 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010223167948424816\n",
      "Predicción post entrenamiento : [[0.95190877]]\n",
      "PERDIDAAAA despues: 0.010216310620307922\n",
      "loss en el callback: 7.170554454205558e-05, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.95164651]\n",
      " [0.95118266]\n",
      " [0.95087951]\n",
      " [0.9518131 ]\n",
      " [0.95224631]\n",
      " [0.95223111]\n",
      " [0.9519791 ]\n",
      " [0.95194268]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.95173824]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.95164651]\n",
      "  [0.95118266]\n",
      "  [0.95087951]\n",
      "  [0.9518131 ]\n",
      "  [0.95224631]\n",
      "  [0.95223111]\n",
      "  [0.9519791 ]\n",
      "  [0.95194268]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010576569475233555\n",
      "Predicción post entrenamiento : [[0.9514731]]\n",
      "PERDIDAAAA despues: 0.010522108525037766\n",
      "loss en el callback: 0.004158562980592251, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.95118266]\n",
      " [0.95087951]\n",
      " [0.9518131 ]\n",
      " [0.95224631]\n",
      " [0.95223111]\n",
      " [0.9519791 ]\n",
      " [0.95194268]\n",
      " [0.95173824]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.951479]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.95118266]\n",
      "  [0.95087951]\n",
      "  [0.9518131 ]\n",
      "  [0.95224631]\n",
      "  [0.95223111]\n",
      "  [0.9519791 ]\n",
      "  [0.95194268]\n",
      "  [0.95173824]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011965393787249923\n",
      "Predicción post entrenamiento : [[0.95095336]]\n",
      "PERDIDAAAA despues: 0.0001314301189268008\n",
      "loss en el callback: 0.012484640814363956, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.95087951]\n",
      " [0.9518131 ]\n",
      " [0.95224631]\n",
      " [0.95223111]\n",
      " [0.9519791 ]\n",
      " [0.95194268]\n",
      " [0.95173824]\n",
      " [0.95147902]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.95112365]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.95087951]\n",
      "  [0.9518131 ]\n",
      "  [0.95224631]\n",
      "  [0.95223111]\n",
      "  [0.9519791 ]\n",
      "  [0.95194268]\n",
      "  [0.95173824]\n",
      "  [0.95147902]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027950049843639135\n",
      "Predicción post entrenamiento : [[0.9517384]]\n",
      "PERDIDAAAA despues: 0.00025932290009222925\n",
      "loss en el callback: 0.026355568319559097, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.9518131 ]\n",
      " [0.95224631]\n",
      " [0.95223111]\n",
      " [0.9519791 ]\n",
      " [0.95194268]\n",
      " [0.95173824]\n",
      " [0.95147902]\n",
      " [0.95112365]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.95203376]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.9518131 ]\n",
      "  [0.95224631]\n",
      "  [0.95223111]\n",
      "  [0.9519791 ]\n",
      "  [0.95194268]\n",
      "  [0.95173824]\n",
      "  [0.95147902]\n",
      "  [0.95112365]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012798579700756818\n",
      "Predicción post entrenamiento : [[0.95202297]]\n",
      "PERDIDAAAA despues: 0.00012774180504493415\n",
      "loss en el callback: 6.968073648749851e-06, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.95224631]\n",
      " [0.95223111]\n",
      " [0.9519791 ]\n",
      " [0.95194268]\n",
      " [0.95173824]\n",
      " [0.95147902]\n",
      " [0.95112365]\n",
      " [0.95203376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9520591]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.95224631]\n",
      "  [0.95223111]\n",
      "  [0.9519791 ]\n",
      "  [0.95194268]\n",
      "  [0.95173824]\n",
      "  [0.95147902]\n",
      "  [0.95112365]\n",
      "  [0.95203376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041747375507839024\n",
      "Predicción post entrenamiento : [[0.95236623]]\n",
      "PERDIDAAAA despues: 0.00040501687908545136\n",
      "loss en el callback: 0.005798041820526123, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.95223111]\n",
      " [0.9519791 ]\n",
      " [0.95194268]\n",
      " [0.95173824]\n",
      " [0.95147902]\n",
      " [0.95112365]\n",
      " [0.95203376]\n",
      " [0.95205909]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.95225704]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.95223111]\n",
      "  [0.9519791 ]\n",
      "  [0.95194268]\n",
      "  [0.95173824]\n",
      "  [0.95147902]\n",
      "  [0.95112365]\n",
      "  [0.95203376]\n",
      "  [0.95205909]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019930333364754915\n",
      "Predicción post entrenamiento : [[0.95277715]]\n",
      "PERDIDAAAA despues: 0.0019468648824840784\n",
      "loss en el callback: 0.018425699323415756, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.9519791 ]\n",
      " [0.95194268]\n",
      " [0.95173824]\n",
      " [0.95147902]\n",
      " [0.95112365]\n",
      " [0.95203376]\n",
      " [0.95205909]\n",
      " [0.95225704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9526484]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.9519791 ]\n",
      "  [0.95194268]\n",
      "  [0.95173824]\n",
      "  [0.95147902]\n",
      "  [0.95112365]\n",
      "  [0.95203376]\n",
      "  [0.95205909]\n",
      "  [0.95225704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.1511839349841466e-06\n",
      "Predicción post entrenamiento : [[0.95178264]]\n",
      "PERDIDAAAA despues: 3.6112169254920445e-07\n",
      "loss en el callback: 0.03147382289171219, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.95194268]\n",
      " [0.95173824]\n",
      " [0.95147902]\n",
      " [0.95112365]\n",
      " [0.95203376]\n",
      " [0.95205909]\n",
      " [0.95225704]\n",
      " [0.9526484 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9517197]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.95194268]\n",
      "  [0.95173824]\n",
      "  [0.95147902]\n",
      "  [0.95112365]\n",
      "  [0.95203376]\n",
      "  [0.95205909]\n",
      "  [0.95225704]\n",
      "  [0.9526484 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031296072993427515\n",
      "Predicción post entrenamiento : [[0.9506989]]\n",
      "PERDIDAAAA despues: 0.003016437403857708\n",
      "loss en el callback: 0.04422524943947792, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.95173824]\n",
      " [0.95147902]\n",
      " [0.95112365]\n",
      " [0.95203376]\n",
      " [0.95205909]\n",
      " [0.95225704]\n",
      " [0.9526484 ]\n",
      " [0.9517197 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.95065033]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.95173824]\n",
      "  [0.95147902]\n",
      "  [0.95112365]\n",
      "  [0.95203376]\n",
      "  [0.95205909]\n",
      "  [0.95225704]\n",
      "  [0.9526484 ]\n",
      "  [0.9517197 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047898911871016026\n",
      "Predicción post entrenamiento : [[0.94970083]]\n",
      "PERDIDAAAA despues: 0.004659364465624094\n",
      "loss en el callback: 0.04193789139389992, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.95147902]\n",
      " [0.95112365]\n",
      " [0.95203376]\n",
      " [0.95205909]\n",
      " [0.95225704]\n",
      " [0.9526484 ]\n",
      " [0.9517197 ]\n",
      " [0.95065033]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9497189]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.95147902]\n",
      "  [0.95112365]\n",
      "  [0.95203376]\n",
      "  [0.95205909]\n",
      "  [0.95225704]\n",
      "  [0.9526484 ]\n",
      "  [0.9517197 ]\n",
      "  [0.95065033]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010648780735209584\n",
      "Predicción post entrenamiento : [[0.9490791]]\n",
      "PERDIDAAAA despues: 0.0010235311929136515\n",
      "loss en el callback: 0.020041601732373238, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.95112365]\n",
      " [0.95203376]\n",
      " [0.95205909]\n",
      " [0.95225704]\n",
      " [0.9526484 ]\n",
      " [0.9517197 ]\n",
      " [0.95065033]\n",
      " [0.94971889]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9491751]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.95112365]\n",
      "  [0.95203376]\n",
      "  [0.95205909]\n",
      "  [0.95225704]\n",
      "  [0.9526484 ]\n",
      "  [0.9517197 ]\n",
      "  [0.95065033]\n",
      "  [0.94971889]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008629826479591429\n",
      "Predicción post entrenamiento : [[0.948712]]\n",
      "PERDIDAAAA despues: 0.0008359869243577123\n",
      "loss en el callback: 0.01183764636516571, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.95203376]\n",
      " [0.95205909]\n",
      " [0.95225704]\n",
      " [0.9526484 ]\n",
      " [0.9517197 ]\n",
      " [0.95065033]\n",
      " [0.94971889]\n",
      " [0.94917512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9489002]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.95203376]\n",
      "  [0.95205909]\n",
      "  [0.95225704]\n",
      "  [0.9526484 ]\n",
      "  [0.9517197 ]\n",
      "  [0.95065033]\n",
      "  [0.94971889]\n",
      "  [0.94917512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001623733260203153\n",
      "Predicción post entrenamiento : [[0.9490058]]\n",
      "PERDIDAAAA despues: 0.00015969426021911204\n",
      "loss en el callback: 0.00070781703107059, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.95205909]\n",
      " [0.95225704]\n",
      " [0.9526484 ]\n",
      " [0.9517197 ]\n",
      " [0.95065033]\n",
      " [0.94971889]\n",
      " [0.94917512]\n",
      " [0.94890022]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9488691]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.95205909]\n",
      "  [0.95225704]\n",
      "  [0.9526484 ]\n",
      "  [0.9517197 ]\n",
      "  [0.95065033]\n",
      "  [0.94971889]\n",
      "  [0.94917512]\n",
      "  [0.94890022]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003748190647456795\n",
      "Predicción post entrenamiento : [[0.94917667]]\n",
      "PERDIDAAAA despues: 0.00036300477222539485\n",
      "loss en el callback: 0.006492847576737404, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.95225704]\n",
      " [0.9526484 ]\n",
      " [0.9517197 ]\n",
      " [0.95065033]\n",
      " [0.94971889]\n",
      " [0.94917512]\n",
      " [0.94890022]\n",
      " [0.94886911]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9489216]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.95225704]\n",
      "  [0.9526484 ]\n",
      "  [0.9517197 ]\n",
      "  [0.95065033]\n",
      "  [0.94971889]\n",
      "  [0.94917512]\n",
      "  [0.94890022]\n",
      "  [0.94886911]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.826410728739575e-05\n",
      "Predicción post entrenamiento : [[0.9493268]]\n",
      "PERDIDAAAA despues: 7.125905540306121e-05\n",
      "loss en el callback: 0.01281698141247034, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21542424]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028668612241744995\n",
      "Predicción post entrenamiento : [[0.1899905]]\n",
      "PERDIDAAAA despues: 0.020702704787254333\n",
      "loss en el callback: 0.028025221079587936, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21542424]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17416437]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21542424]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004891771357506514\n",
      "Predicción post entrenamiento : [[0.16720995]]\n",
      "PERDIDAAAA despues: 0.003967334982007742\n",
      "loss en el callback: 0.0028210990130901337, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21542424]\n",
      " [0.17416437]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1708439]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21542424]\n",
      "  [0.17416437]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027689282433129847\n",
      "Predicción post entrenamiento : [[0.16809191]]\n",
      "PERDIDAAAA despues: 0.00019287948089186102\n",
      "loss en el callback: 0.0007111383602023125, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21542424]\n",
      " [0.17416437]\n",
      " [0.1708439 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17881665]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21542424]\n",
      "  [0.17416437]\n",
      "  [0.1708439 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005319049232639372\n",
      "Predicción post entrenamiento : [[0.17603208]]\n",
      "PERDIDAAAA despues: 0.0004112175083719194\n",
      "loss en el callback: 0.0011997551191598177, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21542424]\n",
      " [0.17416437]\n",
      " [0.1708439 ]\n",
      " [0.17881665]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.1875539]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21542424]\n",
      "  [0.17416437]\n",
      "  [0.1708439 ]\n",
      "  [0.17881665]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038466232363134623\n",
      "Predicción post entrenamiento : [[0.18151931]]\n",
      "PERDIDAAAA despues: 0.003134495811536908\n",
      "loss en el callback: 0.007832475937902927, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21542424]\n",
      " [0.17416437]\n",
      " [0.1708439 ]\n",
      " [0.17881665]\n",
      " [0.1875539 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18985587]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21542424]\n",
      "  [0.17416437]\n",
      "  [0.1708439 ]\n",
      "  [0.17881665]\n",
      "  [0.1875539 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019515109015628695\n",
      "Predicción post entrenamiento : [[0.18618266]]\n",
      "PERDIDAAAA despues: 0.001640468486584723\n",
      "loss en el callback: 0.0042633782140910625, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21542424]\n",
      " [0.17416437]\n",
      " [0.1708439 ]\n",
      " [0.17881665]\n",
      " [0.1875539 ]\n",
      " [0.18985587]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20511371]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21542424]\n",
      "  [0.17416437]\n",
      "  [0.1708439 ]\n",
      "  [0.17881665]\n",
      "  [0.1875539 ]\n",
      "  [0.18985587]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034408611245453358\n",
      "Predicción post entrenamiento : [[0.20142175]]\n",
      "PERDIDAAAA despues: 0.0030213596764951944\n",
      "loss en el callback: 0.006010766141116619, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.21542424]\n",
      " [0.17416437]\n",
      " [0.1708439 ]\n",
      " [0.17881665]\n",
      " [0.1875539 ]\n",
      " [0.18985587]\n",
      " [0.20511371]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22437868]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.21542424]\n",
      "  [0.17416437]\n",
      "  [0.1708439 ]\n",
      "  [0.17881665]\n",
      "  [0.1875539 ]\n",
      "  [0.18985587]\n",
      "  [0.20511371]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008026250870898366\n",
      "Predicción post entrenamiento : [[0.22338568]]\n",
      "PERDIDAAAA despues: 0.0007473466102965176\n",
      "loss en el callback: 0.0006254690233618021, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21542424]\n",
      " [0.17416437]\n",
      " [0.1708439 ]\n",
      " [0.17881665]\n",
      " [0.1875539 ]\n",
      " [0.18985587]\n",
      " [0.20511371]\n",
      " [0.22437868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2507563]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21542424]\n",
      "  [0.17416437]\n",
      "  [0.1708439 ]\n",
      "  [0.17881665]\n",
      "  [0.1875539 ]\n",
      "  [0.18985587]\n",
      "  [0.20511371]\n",
      "  [0.22437868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00040907066431827843\n",
      "Predicción post entrenamiento : [[0.251369]]\n",
      "PERDIDAAAA despues: 0.00043423063470982015\n",
      "loss en el callback: 0.0003231339214835316, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17416437]\n",
      " [0.1708439 ]\n",
      " [0.17881665]\n",
      " [0.1875539 ]\n",
      " [0.18985587]\n",
      " [0.20511371]\n",
      " [0.22437868]\n",
      " [0.25075629]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24573618]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17416437]\n",
      "  [0.1708439 ]\n",
      "  [0.17881665]\n",
      "  [0.1875539 ]\n",
      "  [0.18985587]\n",
      "  [0.20511371]\n",
      "  [0.22437868]\n",
      "  [0.25075629]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013905323576182127\n",
      "Predicción post entrenamiento : [[0.24407312]]\n",
      "PERDIDAAAA despues: 0.001269267755560577\n",
      "loss en el callback: 0.0023353274445980787, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.1708439 ]\n",
      " [0.17881665]\n",
      " [0.1875539 ]\n",
      " [0.18985587]\n",
      " [0.20511371]\n",
      " [0.22437868]\n",
      " [0.25075629]\n",
      " [0.24573618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24778679]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.1708439 ]\n",
      "  [0.17881665]\n",
      "  [0.1875539 ]\n",
      "  [0.18985587]\n",
      "  [0.20511371]\n",
      "  [0.22437868]\n",
      "  [0.25075629]\n",
      "  [0.24573618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012854684609919786\n",
      "Predicción post entrenamiento : [[0.2473376]]\n",
      "PERDIDAAAA despues: 0.0012534598354250193\n",
      "loss en el callback: 0.0002490738406777382, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17881665]\n",
      " [0.1875539 ]\n",
      " [0.18985587]\n",
      " [0.20511371]\n",
      " [0.22437868]\n",
      " [0.25075629]\n",
      " [0.24573618]\n",
      " [0.24778679]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2537238]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17881665]\n",
      "  [0.1875539 ]\n",
      "  [0.18985587]\n",
      "  [0.20511371]\n",
      "  [0.22437868]\n",
      "  [0.25075629]\n",
      "  [0.24573618]\n",
      "  [0.24778679]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002156654605641961\n",
      "Predicción post entrenamiento : [[0.2524961]]\n",
      "PERDIDAAAA despues: 0.0020441331434994936\n",
      "loss en el callback: 0.001911167986690998, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.1875539 ]\n",
      " [0.18985587]\n",
      " [0.20511371]\n",
      " [0.22437868]\n",
      " [0.25075629]\n",
      " [0.24573618]\n",
      " [0.24778679]\n",
      " [0.2537238 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25948548]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.1875539 ]\n",
      "  [0.18985587]\n",
      "  [0.20511371]\n",
      "  [0.22437868]\n",
      "  [0.25075629]\n",
      "  [0.24573618]\n",
      "  [0.24778679]\n",
      "  [0.2537238 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004427173174917698\n",
      "Predicción post entrenamiento : [[0.2580509]]\n",
      "PERDIDAAAA despues: 0.004238324239850044\n",
      "loss en el callback: 0.0031331677455455065, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18985587]\n",
      " [0.20511371]\n",
      " [0.22437868]\n",
      " [0.25075629]\n",
      " [0.24573618]\n",
      " [0.24778679]\n",
      " [0.2537238 ]\n",
      " [0.25948548]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26548105]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18985587]\n",
      "  [0.20511371]\n",
      "  [0.22437868]\n",
      "  [0.25075629]\n",
      "  [0.24573618]\n",
      "  [0.24778679]\n",
      "  [0.2537238 ]\n",
      "  [0.25948548]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00471393670886755\n",
      "Predicción post entrenamiento : [[0.26503715]]\n",
      "PERDIDAAAA despues: 0.004653178155422211\n",
      "loss en el callback: 0.00047604189603589475, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20511371]\n",
      " [0.22437868]\n",
      " [0.25075629]\n",
      " [0.24573618]\n",
      " [0.24778679]\n",
      " [0.2537238 ]\n",
      " [0.25948548]\n",
      " [0.26548105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27431995]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20511371]\n",
      "  [0.22437868]\n",
      "  [0.25075629]\n",
      "  [0.24573618]\n",
      "  [0.24778679]\n",
      "  [0.2537238 ]\n",
      "  [0.25948548]\n",
      "  [0.26548105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036074321251362562\n",
      "Predicción post entrenamiento : [[0.27340978]]\n",
      "PERDIDAAAA despues: 0.0034989281557500362\n",
      "loss en el callback: 0.0017024911940097809, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22437868]\n",
      " [0.25075629]\n",
      " [0.24573618]\n",
      " [0.24778679]\n",
      " [0.2537238 ]\n",
      " [0.25948548]\n",
      " [0.26548105]\n",
      " [0.27431995]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2816736]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22437868]\n",
      "  [0.25075629]\n",
      "  [0.24573618]\n",
      "  [0.24778679]\n",
      "  [0.2537238 ]\n",
      "  [0.25948548]\n",
      "  [0.26548105]\n",
      "  [0.27431995]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010069831274449825\n",
      "Predicción post entrenamiento : [[0.28025138]]\n",
      "PERDIDAAAA despues: 0.00978641677647829\n",
      "loss en el callback: 0.005230078939348459, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25075629]\n",
      " [0.24573618]\n",
      " [0.24778679]\n",
      " [0.2537238 ]\n",
      " [0.25948548]\n",
      " [0.26548105]\n",
      " [0.27431995]\n",
      " [0.28167361]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2861724]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25075629]\n",
      "  [0.24573618]\n",
      "  [0.24778679]\n",
      "  [0.2537238 ]\n",
      "  [0.25948548]\n",
      "  [0.26548105]\n",
      "  [0.27431995]\n",
      "  [0.28167361]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01233131717890501\n",
      "Predicción post entrenamiento : [[0.28374958]]\n",
      "PERDIDAAAA despues: 0.011799097992479801\n",
      "loss en el callback: 0.014030936174094677, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24573618]\n",
      " [0.24778679]\n",
      " [0.2537238 ]\n",
      " [0.25948548]\n",
      " [0.26548105]\n",
      " [0.27431995]\n",
      " [0.28167361]\n",
      " [0.28617239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.28515288]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24573618]\n",
      "  [0.24778679]\n",
      "  [0.2537238 ]\n",
      "  [0.25948548]\n",
      "  [0.26548105]\n",
      "  [0.27431995]\n",
      "  [0.28167361]\n",
      "  [0.28617239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018809637054800987\n",
      "Predicción post entrenamiento : [[0.28306532]]\n",
      "PERDIDAAAA despues: 0.018241383135318756\n",
      "loss en el callback: 0.01279908511787653, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24778679]\n",
      " [0.2537238 ]\n",
      " [0.25948548]\n",
      " [0.26548105]\n",
      " [0.27431995]\n",
      " [0.28167361]\n",
      " [0.28617239]\n",
      " [0.28515288]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2865531]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24778679]\n",
      "  [0.2537238 ]\n",
      "  [0.25948548]\n",
      "  [0.26548105]\n",
      "  [0.27431995]\n",
      "  [0.28167361]\n",
      "  [0.28617239]\n",
      "  [0.28515288]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016307279467582703\n",
      "Predicción post entrenamiento : [[0.28477508]]\n",
      "PERDIDAAAA despues: 0.01585632935166359\n",
      "loss en el callback: 0.010685620829463005, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.2537238 ]\n",
      " [0.25948548]\n",
      " [0.26548105]\n",
      " [0.27431995]\n",
      " [0.28167361]\n",
      " [0.28617239]\n",
      " [0.28515288]\n",
      " [0.28655311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.28904295]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.2537238 ]\n",
      "  [0.25948548]\n",
      "  [0.26548105]\n",
      "  [0.27431995]\n",
      "  [0.28167361]\n",
      "  [0.28617239]\n",
      "  [0.28515288]\n",
      "  [0.28655311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009383676573634148\n",
      "Predicción post entrenamiento : [[0.28650442]]\n",
      "PERDIDAAAA despues: 0.008898308500647545\n",
      "loss en el callback: 0.016857493668794632, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25948548]\n",
      " [0.26548105]\n",
      " [0.27431995]\n",
      " [0.28167361]\n",
      " [0.28617239]\n",
      " [0.28515288]\n",
      " [0.28655311]\n",
      " [0.28904295]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.29069138]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25948548]\n",
      "  [0.26548105]\n",
      "  [0.27431995]\n",
      "  [0.28167361]\n",
      "  [0.28617239]\n",
      "  [0.28515288]\n",
      "  [0.28655311]\n",
      "  [0.28904295]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010965637862682343\n",
      "Predicción post entrenamiento : [[0.28812453]]\n",
      "PERDIDAAAA despues: 0.010434642434120178\n",
      "loss en el callback: 0.01906643621623516, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26548105]\n",
      " [0.27431995]\n",
      " [0.28167361]\n",
      " [0.28617239]\n",
      " [0.28515288]\n",
      " [0.28655311]\n",
      " [0.28904295]\n",
      " [0.29069138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29214707]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26548105]\n",
      "  [0.27431995]\n",
      "  [0.28167361]\n",
      "  [0.28617239]\n",
      "  [0.28515288]\n",
      "  [0.28655311]\n",
      "  [0.28904295]\n",
      "  [0.29069138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006348527385853231\n",
      "Predicción post entrenamiento : [[0.2902273]]\n",
      "PERDIDAAAA despues: 0.0005417958018369973\n",
      "loss en el callback: 0.009918435476720333, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27431995]\n",
      " [0.28167361]\n",
      " [0.28617239]\n",
      " [0.28515288]\n",
      " [0.28655311]\n",
      " [0.28904295]\n",
      " [0.29069138]\n",
      " [0.29214707]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2938859]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27431995]\n",
      "  [0.28167361]\n",
      "  [0.28617239]\n",
      "  [0.28515288]\n",
      "  [0.28655311]\n",
      "  [0.28904295]\n",
      "  [0.29069138]\n",
      "  [0.29214707]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8594192852106062e-06\n",
      "Predicción post entrenamiento : [[0.2943157]]\n",
      "PERDIDAAAA despues: 3.2163350169867044e-06\n",
      "loss en el callback: 0.0009777642553672194, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.28167361]\n",
      " [0.28617239]\n",
      " [0.28515288]\n",
      " [0.28655311]\n",
      " [0.28904295]\n",
      " [0.29069138]\n",
      " [0.29214707]\n",
      " [0.29388589]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.29677293]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.28167361]\n",
      "  [0.28617239]\n",
      "  [0.28515288]\n",
      "  [0.28655311]\n",
      "  [0.28904295]\n",
      "  [0.29069138]\n",
      "  [0.29214707]\n",
      "  [0.29388589]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004382068000268191\n",
      "Predicción post entrenamiento : [[0.2967196]]\n",
      "PERDIDAAAA despues: 0.000440441828686744\n",
      "loss en el callback: 1.1286017070233356e-05, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28617239]\n",
      " [0.28515288]\n",
      " [0.28655311]\n",
      " [0.28904295]\n",
      " [0.29069138]\n",
      " [0.29214707]\n",
      " [0.29388589]\n",
      " [0.29677293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.29805925]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28617239]\n",
      "  [0.28515288]\n",
      "  [0.28655311]\n",
      "  [0.28904295]\n",
      "  [0.29069138]\n",
      "  [0.29214707]\n",
      "  [0.29388589]\n",
      "  [0.29677293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002134597161784768\n",
      "Predicción post entrenamiento : [[0.29875556]]\n",
      "PERDIDAAAA despues: 0.00019359825819265097\n",
      "loss en el callback: 0.002668644767254591, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28515288]\n",
      " [0.28655311]\n",
      " [0.28904295]\n",
      " [0.29069138]\n",
      " [0.29214707]\n",
      " [0.29388589]\n",
      " [0.29677293]\n",
      " [0.29805925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.29945442]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28515288]\n",
      "  [0.28655311]\n",
      "  [0.28904295]\n",
      "  [0.29069138]\n",
      "  [0.29214707]\n",
      "  [0.29388589]\n",
      "  [0.29677293]\n",
      "  [0.29805925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010855889559024945\n",
      "Predicción post entrenamiento : [[0.29887405]]\n",
      "PERDIDAAAA despues: 9.680178482085466e-05\n",
      "loss en el callback: 0.0014569632476195693, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28655311]\n",
      " [0.28904295]\n",
      " [0.29069138]\n",
      " [0.29214707]\n",
      " [0.29388589]\n",
      " [0.29677293]\n",
      " [0.29805925]\n",
      " [0.29945442]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.30014807]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28655311]\n",
      "  [0.28904295]\n",
      "  [0.29069138]\n",
      "  [0.29214707]\n",
      "  [0.29388589]\n",
      "  [0.29677293]\n",
      "  [0.29805925]\n",
      "  [0.29945442]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002997039700858295\n",
      "Predicción post entrenamiento : [[0.29999632]]\n",
      "PERDIDAAAA despues: 0.0002944727020803839\n",
      "loss en el callback: 0.00013491118443198502, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28904295]\n",
      " [0.29069138]\n",
      " [0.29214707]\n",
      " [0.29388589]\n",
      " [0.29677293]\n",
      " [0.29805925]\n",
      " [0.29945442]\n",
      " [0.30014807]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.301367]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28904295]\n",
      "  [0.29069138]\n",
      "  [0.29214707]\n",
      "  [0.29388589]\n",
      "  [0.29677293]\n",
      "  [0.29805925]\n",
      "  [0.29945442]\n",
      "  [0.30014807]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.4994877751159947e-06\n",
      "Predicción post entrenamiento : [[0.30089346]]\n",
      "PERDIDAAAA despues: 1.951980266312603e-06\n",
      "loss en el callback: 0.0011028017615899444, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29069138]\n",
      " [0.29214707]\n",
      " [0.29388589]\n",
      " [0.29677293]\n",
      " [0.29805925]\n",
      " [0.29945442]\n",
      " [0.30014807]\n",
      " [0.30136701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30210364]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29069138]\n",
      "  [0.29214707]\n",
      "  [0.29388589]\n",
      "  [0.29677293]\n",
      "  [0.29805925]\n",
      "  [0.29945442]\n",
      "  [0.30014807]\n",
      "  [0.30136701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006886200280860066\n",
      "Predicción post entrenamiento : [[0.30136803]]\n",
      "PERDIDAAAA despues: 0.0006505540222860873\n",
      "loss en el callback: 0.00286852871067822, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29214707]\n",
      " [0.29388589]\n",
      " [0.29677293]\n",
      " [0.29805925]\n",
      " [0.29945442]\n",
      " [0.30014807]\n",
      " [0.30136701]\n",
      " [0.30210364]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30257386]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29214707]\n",
      "  [0.29388589]\n",
      "  [0.29677293]\n",
      "  [0.29805925]\n",
      "  [0.29945442]\n",
      "  [0.30014807]\n",
      "  [0.30136701]\n",
      "  [0.30210364]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007769677904434502\n",
      "Predicción post entrenamiento : [[0.3026972]]\n",
      "PERDIDAAAA despues: 0.0007838596357032657\n",
      "loss en el callback: 0.0001236767420778051, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29388589]\n",
      " [0.29677293]\n",
      " [0.29805925]\n",
      " [0.29945442]\n",
      " [0.30014807]\n",
      " [0.30136701]\n",
      " [0.30210364]\n",
      " [0.30257386]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30392298]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29388589]\n",
      "  [0.29677293]\n",
      "  [0.29805925]\n",
      "  [0.29945442]\n",
      "  [0.30014807]\n",
      "  [0.30136701]\n",
      "  [0.30210364]\n",
      "  [0.30257386]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008093099459074438\n",
      "Predicción post entrenamiento : [[0.3027258]]\n",
      "PERDIDAAAA despues: 0.0007426270167343318\n",
      "loss en el callback: 0.008294655941426754, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.29677293]\n",
      " [0.29805925]\n",
      " [0.29945442]\n",
      " [0.30014807]\n",
      " [0.30136701]\n",
      " [0.30210364]\n",
      " [0.30257386]\n",
      " [0.30392298]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.30388275]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.29677293]\n",
      "  [0.29805925]\n",
      "  [0.29945442]\n",
      "  [0.30014807]\n",
      "  [0.30136701]\n",
      "  [0.30210364]\n",
      "  [0.30257386]\n",
      "  [0.30392298]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009530317620374262\n",
      "Predicción post entrenamiento : [[0.30450132]]\n",
      "PERDIDAAAA despues: 0.000915221928153187\n",
      "loss en el callback: 0.0031287469901144505, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.29805925]\n",
      " [0.29945442]\n",
      " [0.30014807]\n",
      " [0.30136701]\n",
      " [0.30210364]\n",
      " [0.30257386]\n",
      " [0.30392298]\n",
      " [0.30388275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.3052805]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.29805925]\n",
      "  [0.29945442]\n",
      "  [0.30014807]\n",
      "  [0.30136701]\n",
      "  [0.30210364]\n",
      "  [0.30257386]\n",
      "  [0.30392298]\n",
      "  [0.30388275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025397143326699734\n",
      "Predicción post entrenamiento : [[0.30592757]]\n",
      "PERDIDAAAA despues: 0.0024749143049120903\n",
      "loss en el callback: 0.003380014793947339, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.29945442]\n",
      " [0.30014807]\n",
      " [0.30136701]\n",
      " [0.30210364]\n",
      " [0.30257386]\n",
      " [0.30392298]\n",
      " [0.30388275]\n",
      " [0.30528051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30663472]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.29945442]\n",
      "  [0.30014807]\n",
      "  [0.30136701]\n",
      "  [0.30210364]\n",
      "  [0.30257386]\n",
      "  [0.30392298]\n",
      "  [0.30388275]\n",
      "  [0.30528051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009033918031491339\n",
      "Predicción post entrenamiento : [[0.30655852]]\n",
      "PERDIDAAAA despues: 0.0009079784504137933\n",
      "loss en el callback: 4.472175351111218e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.30014807]\n",
      " [0.30136701]\n",
      " [0.30210364]\n",
      " [0.30257386]\n",
      " [0.30392298]\n",
      " [0.30388275]\n",
      " [0.30528051]\n",
      " [0.30663472]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.30715194]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.30014807]\n",
      "  [0.30136701]\n",
      "  [0.30210364]\n",
      "  [0.30257386]\n",
      "  [0.30392298]\n",
      "  [0.30388275]\n",
      "  [0.30528051]\n",
      "  [0.30663472]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000699057534802705\n",
      "Predicción post entrenamiento : [[0.3069334]]\n",
      "PERDIDAAAA despues: 0.0007106615812517703\n",
      "loss en el callback: 0.00037550830165855587, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30136701]\n",
      " [0.30210364]\n",
      " [0.30257386]\n",
      " [0.30392298]\n",
      " [0.30388275]\n",
      " [0.30528051]\n",
      " [0.30663472]\n",
      " [0.30715194]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3075619]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30136701]\n",
      "  [0.30210364]\n",
      "  [0.30257386]\n",
      "  [0.30392298]\n",
      "  [0.30388275]\n",
      "  [0.30528051]\n",
      "  [0.30663472]\n",
      "  [0.30715194]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059556253254413605\n",
      "Predicción post entrenamiento : [[0.30873746]]\n",
      "PERDIDAAAA despues: 0.00577556574717164\n",
      "loss en el callback: 0.019203241914510727, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30210364]\n",
      " [0.30257386]\n",
      " [0.30392298]\n",
      " [0.30388275]\n",
      " [0.30528051]\n",
      " [0.30663472]\n",
      " [0.30715194]\n",
      " [0.3075619 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.30928093]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30210364]\n",
      "  [0.30257386]\n",
      "  [0.30392298]\n",
      "  [0.30388275]\n",
      "  [0.30528051]\n",
      "  [0.30663472]\n",
      "  [0.30715194]\n",
      "  [0.3075619 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06854738295078278\n",
      "Predicción post entrenamiento : [[0.3116212]]\n",
      "PERDIDAAAA despues: 0.06732742488384247\n",
      "loss en el callback: 0.04177085682749748, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30257386]\n",
      " [0.30392298]\n",
      " [0.30388275]\n",
      " [0.30528051]\n",
      " [0.30663472]\n",
      " [0.30715194]\n",
      " [0.3075619 ]\n",
      " [0.30928093]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.31218502]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30257386]\n",
      "  [0.30392298]\n",
      "  [0.30388275]\n",
      "  [0.30528051]\n",
      "  [0.30663472]\n",
      "  [0.30715194]\n",
      "  [0.3075619 ]\n",
      "  [0.30928093]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08071024715900421\n",
      "Predicción post entrenamiento : [[0.31471643]]\n",
      "PERDIDAAAA despues: 0.07927833497524261\n",
      "loss en el callback: 0.04852335527539253, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30392298]\n",
      " [0.30388275]\n",
      " [0.30528051]\n",
      " [0.30663472]\n",
      " [0.30715194]\n",
      " [0.3075619 ]\n",
      " [0.30928093]\n",
      " [0.31218502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.31538287]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30392298]\n",
      "  [0.30388275]\n",
      "  [0.30528051]\n",
      "  [0.30663472]\n",
      "  [0.30715194]\n",
      "  [0.3075619 ]\n",
      "  [0.30928093]\n",
      "  [0.31218502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06718495488166809\n",
      "Predicción post entrenamiento : [[0.31782684]]\n",
      "PERDIDAAAA despues: 0.06592396646738052\n",
      "loss en el callback: 0.06412207335233688, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30388275]\n",
      " [0.30528051]\n",
      " [0.30663472]\n",
      " [0.30715194]\n",
      " [0.3075619 ]\n",
      " [0.30928093]\n",
      " [0.31218502]\n",
      " [0.31538287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.31842765]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30388275]\n",
      "  [0.30528051]\n",
      "  [0.30663472]\n",
      "  [0.30715194]\n",
      "  [0.3075619 ]\n",
      "  [0.30928093]\n",
      "  [0.31218502]\n",
      "  [0.31538287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08290164917707443\n",
      "Predicción post entrenamiento : [[0.32121995]]\n",
      "PERDIDAAAA despues: 0.0813014954328537\n",
      "loss en el callback: 0.09609891474246979, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30528051]\n",
      " [0.30663472]\n",
      " [0.30715194]\n",
      " [0.3075619 ]\n",
      " [0.30928093]\n",
      " [0.31218502]\n",
      " [0.31538287]\n",
      " [0.31842765]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.32211894]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30528051]\n",
      "  [0.30663472]\n",
      "  [0.30715194]\n",
      "  [0.3075619 ]\n",
      "  [0.30928093]\n",
      "  [0.31218502]\n",
      "  [0.31538287]\n",
      "  [0.31842765]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06892630457878113\n",
      "Predicción post entrenamiento : [[0.3243804]]\n",
      "PERDIDAAAA despues: 0.06774397939443588\n",
      "loss en el callback: 0.05060777813196182, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30663472]\n",
      " [0.30715194]\n",
      " [0.3075619 ]\n",
      " [0.30928093]\n",
      " [0.31218502]\n",
      " [0.31538287]\n",
      " [0.31842765]\n",
      " [0.32211894]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32532668]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30663472]\n",
      "  [0.30715194]\n",
      "  [0.3075619 ]\n",
      "  [0.30928093]\n",
      "  [0.31218502]\n",
      "  [0.31538287]\n",
      "  [0.31842765]\n",
      "  [0.32211894]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05926551669836044\n",
      "Predicción post entrenamiento : [[0.32755193]]\n",
      "PERDIDAAAA despues: 0.05818701535463333\n",
      "loss en el callback: 0.06813718378543854, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.30715194]\n",
      " [0.3075619 ]\n",
      " [0.30928093]\n",
      " [0.31218502]\n",
      " [0.31538287]\n",
      " [0.31842765]\n",
      " [0.32211894]\n",
      " [0.32532668]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32861537]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.30715194]\n",
      "  [0.3075619 ]\n",
      "  [0.30928093]\n",
      "  [0.31218502]\n",
      "  [0.31538287]\n",
      "  [0.31842765]\n",
      "  [0.32211894]\n",
      "  [0.32532668]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09869571030139923\n",
      "Predicción post entrenamiento : [[0.33122662]]\n",
      "PERDIDAAAA despues: 0.09706183522939682\n",
      "loss en el callback: 0.08369997143745422, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.3075619 ]\n",
      " [0.30928093]\n",
      " [0.31218502]\n",
      " [0.31538287]\n",
      " [0.31842765]\n",
      " [0.32211894]\n",
      " [0.32532668]\n",
      " [0.32861537]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3326831]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.3075619 ]\n",
      "  [0.30928093]\n",
      "  [0.31218502]\n",
      "  [0.31538287]\n",
      "  [0.31842765]\n",
      "  [0.32211894]\n",
      "  [0.32532668]\n",
      "  [0.32861537]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10829097032546997\n",
      "Predicción post entrenamiento : [[0.33546948]]\n",
      "PERDIDAAAA despues: 0.10646486282348633\n",
      "loss en el callback: 0.08991460502147675, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30928093]\n",
      " [0.31218502]\n",
      " [0.31538287]\n",
      " [0.31842765]\n",
      " [0.32211894]\n",
      " [0.32532668]\n",
      " [0.32861537]\n",
      " [0.33268309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33745712]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30928093]\n",
      "  [0.31218502]\n",
      "  [0.31538287]\n",
      "  [0.31842765]\n",
      "  [0.32211894]\n",
      "  [0.32532668]\n",
      "  [0.32861537]\n",
      "  [0.33268309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11258564889431\n",
      "Predicción post entrenamiento : [[0.3402063]]\n",
      "PERDIDAAAA despues: 0.1107483059167862\n",
      "loss en el callback: 0.10434257984161377, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.31218502]\n",
      " [0.31538287]\n",
      " [0.31842765]\n",
      " [0.32211894]\n",
      " [0.32532668]\n",
      " [0.32861537]\n",
      " [0.33268309]\n",
      " [0.33745712]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34252968]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.31218502]\n",
      "  [0.31538287]\n",
      "  [0.31842765]\n",
      "  [0.32211894]\n",
      "  [0.32532668]\n",
      "  [0.32861537]\n",
      "  [0.33268309]\n",
      "  [0.33745712]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1354590505361557\n",
      "Predicción post entrenamiento : [[0.34561297]]\n",
      "PERDIDAAAA despues: 0.13319896161556244\n",
      "loss en el callback: 0.15308977663516998, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31538287]\n",
      " [0.31842765]\n",
      " [0.32211894]\n",
      " [0.32532668]\n",
      " [0.32861537]\n",
      " [0.33268309]\n",
      " [0.33745712]\n",
      " [0.34252968]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34806776]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31538287]\n",
      "  [0.31842765]\n",
      "  [0.32211894]\n",
      "  [0.32532668]\n",
      "  [0.32861537]\n",
      "  [0.33268309]\n",
      "  [0.33745712]\n",
      "  [0.34252968]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1266811341047287\n",
      "Predicción post entrenamiento : [[0.35102323]]\n",
      "PERDIDAAAA despues: 0.12458603829145432\n",
      "loss en el callback: 0.12144286930561066, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31842765]\n",
      " [0.32211894]\n",
      " [0.32532668]\n",
      " [0.32861537]\n",
      " [0.33268309]\n",
      " [0.33745712]\n",
      " [0.34252968]\n",
      " [0.34806776]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3535939]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31842765]\n",
      "  [0.32211894]\n",
      "  [0.32532668]\n",
      "  [0.32861537]\n",
      "  [0.33268309]\n",
      "  [0.33745712]\n",
      "  [0.34252968]\n",
      "  [0.34806776]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13960956037044525\n",
      "Predicción post entrenamiento : [[0.35663867]]\n",
      "PERDIDAAAA despues: 0.13734351098537445\n",
      "loss en el callback: 0.1557958722114563, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32211894]\n",
      " [0.32532668]\n",
      " [0.32861537]\n",
      " [0.33268309]\n",
      " [0.33745712]\n",
      " [0.34252968]\n",
      " [0.34806776]\n",
      " [0.35359389]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35942453]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32211894]\n",
      "  [0.32532668]\n",
      "  [0.32861537]\n",
      "  [0.33268309]\n",
      "  [0.33745712]\n",
      "  [0.34252968]\n",
      "  [0.34806776]\n",
      "  [0.35359389]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1318877935409546\n",
      "Predicción post entrenamiento : [[0.36241788]]\n",
      "PERDIDAAAA despues: 0.12972261011600494\n",
      "loss en el callback: 0.1850319802761078, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32532668]\n",
      " [0.32861537]\n",
      " [0.33268309]\n",
      " [0.33745712]\n",
      " [0.34252968]\n",
      " [0.34806776]\n",
      " [0.35359389]\n",
      " [0.35942453]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36533993]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32532668]\n",
      "  [0.32861537]\n",
      "  [0.33268309]\n",
      "  [0.33745712]\n",
      "  [0.34252968]\n",
      "  [0.34806776]\n",
      "  [0.35359389]\n",
      "  [0.35942453]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16520482301712036\n",
      "Predicción post entrenamiento : [[0.36861902]]\n",
      "PERDIDAAAA despues: 0.16254998743534088\n",
      "loss en el callback: 0.21025578677654266, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32861537]\n",
      " [0.33268309]\n",
      " [0.33745712]\n",
      " [0.34252968]\n",
      " [0.34806776]\n",
      " [0.35359389]\n",
      " [0.35942453]\n",
      " [0.36533993]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37186903]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32861537]\n",
      "  [0.33268309]\n",
      "  [0.33745712]\n",
      "  [0.34252968]\n",
      "  [0.34806776]\n",
      "  [0.35359389]\n",
      "  [0.35942453]\n",
      "  [0.36533993]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12436651438474655\n",
      "Predicción post entrenamiento : [[0.37462837]]\n",
      "PERDIDAAAA despues: 0.12242793291807175\n",
      "loss en el callback: 0.11763343960046768, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33268309]\n",
      " [0.33745712]\n",
      " [0.34252968]\n",
      " [0.34806776]\n",
      " [0.35359389]\n",
      " [0.35942453]\n",
      " [0.36533993]\n",
      " [0.37186903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37828663]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33268309]\n",
      "  [0.33745712]\n",
      "  [0.34252968]\n",
      "  [0.34806776]\n",
      "  [0.35359389]\n",
      "  [0.35942453]\n",
      "  [0.36533993]\n",
      "  [0.37186903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0857148990035057\n",
      "Predicción post entrenamiento : [[0.3803257]]\n",
      "PERDIDAAAA despues: 0.08452509343624115\n",
      "loss en el callback: 0.06123355031013489, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33745712]\n",
      " [0.34252968]\n",
      " [0.34806776]\n",
      " [0.35359389]\n",
      " [0.35942453]\n",
      " [0.36533993]\n",
      " [0.37186903]\n",
      " [0.37828663]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3843014]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33745712]\n",
      "  [0.34252968]\n",
      "  [0.34806776]\n",
      "  [0.35359389]\n",
      "  [0.35942453]\n",
      "  [0.36533993]\n",
      "  [0.37186903]\n",
      "  [0.37828663]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08379197865724564\n",
      "Predicción post entrenamiento : [[0.38650224]]\n",
      "PERDIDAAAA despues: 0.0825226679444313\n",
      "loss en el callback: 0.12258147448301315, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34252968]\n",
      " [0.34806776]\n",
      " [0.35359389]\n",
      " [0.35942453]\n",
      " [0.36533993]\n",
      " [0.37186903]\n",
      " [0.37828663]\n",
      " [0.38430139]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3906982]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34252968]\n",
      "  [0.34806776]\n",
      "  [0.35359389]\n",
      "  [0.35942453]\n",
      "  [0.36533993]\n",
      "  [0.37186903]\n",
      "  [0.37828663]\n",
      "  [0.38430139]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10481639206409454\n",
      "Predicción post entrenamiento : [[0.39318284]]\n",
      "PERDIDAAAA despues: 0.10321373492479324\n",
      "loss en el callback: 0.14723965525627136, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34806776]\n",
      " [0.35359389]\n",
      " [0.35942453]\n",
      " [0.36533993]\n",
      " [0.37186903]\n",
      " [0.37828663]\n",
      " [0.38430139]\n",
      " [0.39069819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39758158]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34806776]\n",
      "  [0.35359389]\n",
      "  [0.35942453]\n",
      "  [0.36533993]\n",
      "  [0.37186903]\n",
      "  [0.37828663]\n",
      "  [0.38430139]\n",
      "  [0.39069819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11993487924337387\n",
      "Predicción post entrenamiento : [[0.40005872]]\n",
      "PERDIDAAAA despues: 0.11822526901960373\n",
      "loss en el callback: 0.14039252698421478, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35359389]\n",
      " [0.35942453]\n",
      " [0.36533993]\n",
      " [0.37186903]\n",
      " [0.37828663]\n",
      " [0.38430139]\n",
      " [0.39069819]\n",
      " [0.39758158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40459323]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35359389]\n",
      "  [0.35942453]\n",
      "  [0.36533993]\n",
      "  [0.37186903]\n",
      "  [0.37828663]\n",
      "  [0.38430139]\n",
      "  [0.39069819]\n",
      "  [0.39758158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10112075507640839\n",
      "Predicción post entrenamiento : [[0.40649045]]\n",
      "PERDIDAAAA despues: 0.09991773962974548\n",
      "loss en el callback: 0.04786426201462746, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35942453]\n",
      " [0.36533993]\n",
      " [0.37186903]\n",
      " [0.37828663]\n",
      " [0.38430139]\n",
      " [0.39069819]\n",
      " [0.39758158]\n",
      " [0.40459323]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4112018]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35942453]\n",
      "  [0.36533993]\n",
      "  [0.37186903]\n",
      "  [0.37828663]\n",
      "  [0.38430139]\n",
      "  [0.39069819]\n",
      "  [0.39758158]\n",
      "  [0.40459323]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08302440494298935\n",
      "Predicción post entrenamiento : [[0.41318095]]\n",
      "PERDIDAAAA despues: 0.08188778162002563\n",
      "loss en el callback: 0.06839501857757568, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36533993]\n",
      " [0.37186903]\n",
      " [0.37828663]\n",
      " [0.38430139]\n",
      " [0.39069819]\n",
      " [0.39758158]\n",
      " [0.40459323]\n",
      " [0.4112018 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4180343]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36533993]\n",
      "  [0.37186903]\n",
      "  [0.37828663]\n",
      "  [0.38430139]\n",
      "  [0.39069819]\n",
      "  [0.39758158]\n",
      "  [0.40459323]\n",
      "  [0.4112018 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10193770378828049\n",
      "Predicción post entrenamiento : [[0.4203527]]\n",
      "PERDIDAAAA despues: 0.1004626452922821\n",
      "loss en el callback: 0.0932043045759201, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37186903]\n",
      " [0.37828663]\n",
      " [0.38430139]\n",
      " [0.39069819]\n",
      " [0.39758158]\n",
      " [0.40459323]\n",
      " [0.4112018 ]\n",
      " [0.41803429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.42536205]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37186903]\n",
      "  [0.37828663]\n",
      "  [0.38430139]\n",
      "  [0.39069819]\n",
      "  [0.39758158]\n",
      "  [0.40459323]\n",
      "  [0.4112018 ]\n",
      "  [0.41803429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0876537635922432\n",
      "Predicción post entrenamiento : [[0.42706513]]\n",
      "PERDIDAAAA despues: 0.08664821833372116\n",
      "loss en el callback: 0.04017740860581398, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37828663]\n",
      " [0.38430139]\n",
      " [0.39069819]\n",
      " [0.39758158]\n",
      " [0.40459323]\n",
      " [0.4112018 ]\n",
      " [0.41803429]\n",
      " [0.42536205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.43210542]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37828663]\n",
      "  [0.38430139]\n",
      "  [0.39069819]\n",
      "  [0.39758158]\n",
      "  [0.40459323]\n",
      "  [0.4112018 ]\n",
      "  [0.41803429]\n",
      "  [0.42536205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08214430510997772\n",
      "Predicción post entrenamiento : [[0.4342972]]\n",
      "PERDIDAAAA despues: 0.08089274168014526\n",
      "loss en el callback: 0.12490526586771011, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38430139]\n",
      " [0.39069819]\n",
      " [0.39758158]\n",
      " [0.40459323]\n",
      " [0.4112018 ]\n",
      " [0.41803429]\n",
      " [0.42536205]\n",
      " [0.43210542]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.43941405]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38430139]\n",
      "  [0.39069819]\n",
      "  [0.39758158]\n",
      "  [0.40459323]\n",
      "  [0.4112018 ]\n",
      "  [0.41803429]\n",
      "  [0.42536205]\n",
      "  [0.43210542]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05510440096259117\n",
      "Predicción post entrenamiento : [[0.4408025]]\n",
      "PERDIDAAAA despues: 0.054454464465379715\n",
      "loss en el callback: 0.03910723328590393, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39069819]\n",
      " [0.39758158]\n",
      " [0.40459323]\n",
      " [0.4112018 ]\n",
      " [0.41803429]\n",
      " [0.42536205]\n",
      " [0.43210542]\n",
      " [0.43941405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4461239]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39069819]\n",
      "  [0.39758158]\n",
      "  [0.40459323]\n",
      "  [0.4112018 ]\n",
      "  [0.41803429]\n",
      "  [0.42536205]\n",
      "  [0.43210542]\n",
      "  [0.43941405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0637272372841835\n",
      "Predicción post entrenamiento : [[0.44721252]]\n",
      "PERDIDAAAA despues: 0.06317879259586334\n",
      "loss en el callback: 0.017630120739340782, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39758158]\n",
      " [0.40459323]\n",
      " [0.4112018 ]\n",
      " [0.41803429]\n",
      " [0.42536205]\n",
      " [0.43210542]\n",
      " [0.43941405]\n",
      " [0.4461239 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4526765]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39758158]\n",
      "  [0.40459323]\n",
      "  [0.4112018 ]\n",
      "  [0.41803429]\n",
      "  [0.42536205]\n",
      "  [0.43210542]\n",
      "  [0.43941405]\n",
      "  [0.4461239 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07201807200908661\n",
      "Predicción post entrenamiento : [[0.45465204]]\n",
      "PERDIDAAAA despues: 0.07096166163682938\n",
      "loss en el callback: 0.10705634951591492, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40459323]\n",
      " [0.4112018 ]\n",
      " [0.41803429]\n",
      " [0.42536205]\n",
      " [0.43210542]\n",
      " [0.43941405]\n",
      " [0.4461239 ]\n",
      " [0.4526765 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.46015343]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40459323]\n",
      "  [0.4112018 ]\n",
      "  [0.41803429]\n",
      "  [0.42536205]\n",
      "  [0.43210542]\n",
      "  [0.43941405]\n",
      "  [0.4461239 ]\n",
      "  [0.4526765 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06887196749448776\n",
      "Predicción post entrenamiento : [[0.4619659]]\n",
      "PERDIDAAAA despues: 0.06792394816875458\n",
      "loss en el callback: 0.07520464807748795, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.4112018 ]\n",
      " [0.41803429]\n",
      " [0.42536205]\n",
      " [0.43210542]\n",
      " [0.43941405]\n",
      " [0.4461239 ]\n",
      " [0.4526765 ]\n",
      " [0.46015343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.46747345]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.4112018 ]\n",
      "  [0.41803429]\n",
      "  [0.42536205]\n",
      "  [0.43210542]\n",
      "  [0.43941405]\n",
      "  [0.4461239 ]\n",
      "  [0.4526765 ]\n",
      "  [0.46015343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08341848850250244\n",
      "Predicción post entrenamiento : [[0.4690704]]\n",
      "PERDIDAAAA despues: 0.08249856531620026\n",
      "loss en el callback: 0.045395638793706894, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41803429]\n",
      " [0.42536205]\n",
      " [0.43210542]\n",
      " [0.43941405]\n",
      " [0.4461239 ]\n",
      " [0.4526765 ]\n",
      " [0.46015343]\n",
      " [0.46747345]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.47469246]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41803429]\n",
      "  [0.42536205]\n",
      "  [0.43210542]\n",
      "  [0.43941405]\n",
      "  [0.4461239 ]\n",
      "  [0.4526765 ]\n",
      "  [0.46015343]\n",
      "  [0.46747345]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.124534010887146\n",
      "Predicción post entrenamiento : [[0.47703966]]\n",
      "PERDIDAAAA despues: 0.1228828951716423\n",
      "loss en el callback: 0.11656869202852249, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.42536205]\n",
      " [0.43210542]\n",
      " [0.43941405]\n",
      " [0.4461239 ]\n",
      " [0.4526765 ]\n",
      " [0.46015343]\n",
      " [0.46747345]\n",
      " [0.47469246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.4827376]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.42536205]\n",
      "  [0.43210542]\n",
      "  [0.43941405]\n",
      "  [0.4461239 ]\n",
      "  [0.4526765 ]\n",
      "  [0.46015343]\n",
      "  [0.46747345]\n",
      "  [0.47469246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12679623067378998\n",
      "Predicción post entrenamiento : [[0.48516557]]\n",
      "PERDIDAAAA despues: 0.12507300078868866\n",
      "loss en el callback: 0.13614803552627563, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.43210542]\n",
      " [0.43941405]\n",
      " [0.4461239 ]\n",
      " [0.4526765 ]\n",
      " [0.46015343]\n",
      " [0.46747345]\n",
      " [0.47469246]\n",
      " [0.4827376 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.4908227]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.43210542]\n",
      "  [0.43941405]\n",
      "  [0.4461239 ]\n",
      "  [0.4526765 ]\n",
      "  [0.46015343]\n",
      "  [0.46747345]\n",
      "  [0.47469246]\n",
      "  [0.4827376 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09207771718502045\n",
      "Predicción post entrenamiento : [[0.49274302]]\n",
      "PERDIDAAAA despues: 0.0909159928560257\n",
      "loss en el callback: 0.07445358484983444, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.43941405]\n",
      " [0.4461239 ]\n",
      " [0.4526765 ]\n",
      " [0.46015343]\n",
      " [0.46747345]\n",
      " [0.47469246]\n",
      " [0.4827376 ]\n",
      " [0.4908227 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.49852204]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.43941405]\n",
      "  [0.4461239 ]\n",
      "  [0.4526765 ]\n",
      "  [0.46015343]\n",
      "  [0.46747345]\n",
      "  [0.47469246]\n",
      "  [0.4827376 ]\n",
      "  [0.4908227 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08138620108366013\n",
      "Predicción post entrenamiento : [[0.50027776]]\n",
      "PERDIDAAAA despues: 0.08038753271102905\n",
      "loss en el callback: 0.06310663372278214, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.4461239 ]\n",
      " [0.4526765 ]\n",
      " [0.46015343]\n",
      " [0.46747345]\n",
      " [0.47469246]\n",
      " [0.4827376 ]\n",
      " [0.4908227 ]\n",
      " [0.49852204]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.506062]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.4461239 ]\n",
      "  [0.4526765 ]\n",
      "  [0.46015343]\n",
      "  [0.46747345]\n",
      "  [0.47469246]\n",
      "  [0.4827376 ]\n",
      "  [0.4908227 ]\n",
      "  [0.49852204]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06856932491064072\n",
      "Predicción post entrenamiento : [[0.5078788]]\n",
      "PERDIDAAAA despues: 0.0676211342215538\n",
      "loss en el callback: 0.09049420803785324, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.4526765 ]\n",
      " [0.46015343]\n",
      " [0.46747345]\n",
      " [0.47469246]\n",
      " [0.4827376 ]\n",
      " [0.4908227 ]\n",
      " [0.49852204]\n",
      " [0.50606197]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5138511]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.4526765 ]\n",
      "  [0.46015343]\n",
      "  [0.46747345]\n",
      "  [0.47469246]\n",
      "  [0.4827376 ]\n",
      "  [0.4908227 ]\n",
      "  [0.49852204]\n",
      "  [0.50606197]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07329393923282623\n",
      "Predicción post entrenamiento : [[0.51568043]]\n",
      "PERDIDAAAA despues: 0.07230678200721741\n",
      "loss en el callback: 0.08653156459331512, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.46015343]\n",
      " [0.46747345]\n",
      " [0.47469246]\n",
      " [0.4827376 ]\n",
      " [0.4908227 ]\n",
      " [0.49852204]\n",
      " [0.50606197]\n",
      " [0.51385111]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5219305]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.46015343]\n",
      "  [0.46747345]\n",
      "  [0.47469246]\n",
      "  [0.4827376 ]\n",
      "  [0.4908227 ]\n",
      "  [0.49852204]\n",
      "  [0.50606197]\n",
      "  [0.51385111]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.127305269241333\n",
      "Predicción post entrenamiento : [[0.5242882]]\n",
      "PERDIDAAAA despues: 0.12562841176986694\n",
      "loss en el callback: 0.13698673248291016, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.46747345]\n",
      " [0.47469246]\n",
      " [0.4827376 ]\n",
      " [0.4908227 ]\n",
      " [0.49852204]\n",
      " [0.50606197]\n",
      " [0.51385111]\n",
      " [0.52193052]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.53061646]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.46747345]\n",
      "  [0.47469246]\n",
      "  [0.4827376 ]\n",
      "  [0.4908227 ]\n",
      "  [0.49852204]\n",
      "  [0.50606197]\n",
      "  [0.51385111]\n",
      "  [0.52193052]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1190340667963028\n",
      "Predicción post entrenamiento : [[0.5329216]]\n",
      "PERDIDAAAA despues: 0.11744876950979233\n",
      "loss en el callback: 0.1752287745475769, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.47469246]\n",
      " [0.4827376 ]\n",
      " [0.4908227 ]\n",
      " [0.49852204]\n",
      " [0.50606197]\n",
      " [0.51385111]\n",
      " [0.52193052]\n",
      " [0.53061646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.53939223]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.47469246]\n",
      "  [0.4827376 ]\n",
      "  [0.4908227 ]\n",
      "  [0.49852204]\n",
      "  [0.50606197]\n",
      "  [0.51385111]\n",
      "  [0.52193052]\n",
      "  [0.53061646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09579245001077652\n",
      "Predicción post entrenamiento : [[0.54133135]]\n",
      "PERDIDAAAA despues: 0.09459588676691055\n",
      "loss en el callback: 0.08324924856424332, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.4827376 ]\n",
      " [0.4908227 ]\n",
      " [0.49852204]\n",
      " [0.50606197]\n",
      " [0.51385111]\n",
      " [0.52193052]\n",
      " [0.53061646]\n",
      " [0.53939223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.54800624]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.4827376 ]\n",
      "  [0.4908227 ]\n",
      "  [0.49852204]\n",
      "  [0.50606197]\n",
      "  [0.51385111]\n",
      "  [0.52193052]\n",
      "  [0.53061646]\n",
      "  [0.53939223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07305195927619934\n",
      "Predicción post entrenamiento : [[0.5497552]]\n",
      "PERDIDAAAA despues: 0.07210958003997803\n",
      "loss en el callback: 0.07043959200382233, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.4908227 ]\n",
      " [0.49852204]\n",
      " [0.50606197]\n",
      " [0.51385111]\n",
      " [0.52193052]\n",
      " [0.53061646]\n",
      " [0.53939223]\n",
      " [0.54800624]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5564473]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.4908227 ]\n",
      "  [0.49852204]\n",
      "  [0.50606197]\n",
      "  [0.51385111]\n",
      "  [0.52193052]\n",
      "  [0.53061646]\n",
      "  [0.53939223]\n",
      "  [0.54800624]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07309668511152267\n",
      "Predicción post entrenamiento : [[0.5581356]]\n",
      "PERDIDAAAA despues: 0.07218662649393082\n",
      "loss en el callback: 0.07556691020727158, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.49852204]\n",
      " [0.50606197]\n",
      " [0.51385111]\n",
      " [0.52193052]\n",
      " [0.53061646]\n",
      " [0.53939223]\n",
      " [0.54800624]\n",
      " [0.55644733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5648507]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.49852204]\n",
      "  [0.50606197]\n",
      "  [0.51385111]\n",
      "  [0.52193052]\n",
      "  [0.53061646]\n",
      "  [0.53939223]\n",
      "  [0.54800624]\n",
      "  [0.55644733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04862193018198013\n",
      "Predicción post entrenamiento : [[0.56601024]]\n",
      "PERDIDAAAA despues: 0.04811190441250801\n",
      "loss en el callback: 0.029413608834147453, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.50606197]\n",
      " [0.51385111]\n",
      " [0.52193052]\n",
      " [0.53061646]\n",
      " [0.53939223]\n",
      " [0.54800624]\n",
      " [0.55644733]\n",
      " [0.56485069]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5728761]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.50606197]\n",
      "  [0.51385111]\n",
      "  [0.52193052]\n",
      "  [0.53061646]\n",
      "  [0.53939223]\n",
      "  [0.54800624]\n",
      "  [0.55644733]\n",
      "  [0.56485069]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04680856689810753\n",
      "Predicción post entrenamiento : [[0.57417876]]\n",
      "PERDIDAAAA despues: 0.046246595680713654\n",
      "loss en el callback: 0.04222824424505234, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.51385111]\n",
      " [0.52193052]\n",
      " [0.53061646]\n",
      " [0.53939223]\n",
      " [0.54800624]\n",
      " [0.55644733]\n",
      " [0.56485069]\n",
      " [0.5728761 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5812776]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.51385111]\n",
      "  [0.52193052]\n",
      "  [0.53061646]\n",
      "  [0.53939223]\n",
      "  [0.54800624]\n",
      "  [0.55644733]\n",
      "  [0.56485069]\n",
      "  [0.5728761 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06395597010850906\n",
      "Predicción post entrenamiento : [[0.5830912]]\n",
      "PERDIDAAAA despues: 0.06304196268320084\n",
      "loss en el callback: 0.10390031337738037, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.52193052]\n",
      " [0.53061646]\n",
      " [0.53939223]\n",
      " [0.54800624]\n",
      " [0.55644733]\n",
      " [0.56485069]\n",
      " [0.5728761 ]\n",
      " [0.58127761]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5903934]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.52193052]\n",
      "  [0.53061646]\n",
      "  [0.53939223]\n",
      "  [0.54800624]\n",
      "  [0.55644733]\n",
      "  [0.56485069]\n",
      "  [0.5728761 ]\n",
      "  [0.58127761]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049320582300424576\n",
      "Predicción post entrenamiento : [[0.59169966]]\n",
      "PERDIDAAAA despues: 0.048742104321718216\n",
      "loss en el callback: 0.03871958702802658, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.53061646]\n",
      " [0.53939223]\n",
      " [0.54800624]\n",
      " [0.55644733]\n",
      " [0.56485069]\n",
      " [0.5728761 ]\n",
      " [0.58127761]\n",
      " [0.59039342]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5991495]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.53061646]\n",
      "  [0.53939223]\n",
      "  [0.54800624]\n",
      "  [0.55644733]\n",
      "  [0.56485069]\n",
      "  [0.5728761 ]\n",
      "  [0.58127761]\n",
      "  [0.59039342]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040840499103069305\n",
      "Predicción post entrenamiento : [[0.6008379]]\n",
      "PERDIDAAAA despues: 0.04016094654798508\n",
      "loss en el callback: 0.10043390840291977, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.53939223]\n",
      " [0.54800624]\n",
      " [0.55644733]\n",
      " [0.56485069]\n",
      " [0.5728761 ]\n",
      " [0.58127761]\n",
      " [0.59039342]\n",
      " [0.59914953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6082797]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.53939223]\n",
      "  [0.54800624]\n",
      "  [0.55644733]\n",
      "  [0.56485069]\n",
      "  [0.5728761 ]\n",
      "  [0.58127761]\n",
      "  [0.59039342]\n",
      "  [0.59914953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.037984978407621384\n",
      "Predicción post entrenamiento : [[0.6096467]]\n",
      "PERDIDAAAA despues: 0.03745400905609131\n",
      "loss en el callback: 0.0540480799973011, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.54800624]\n",
      " [0.55644733]\n",
      " [0.56485069]\n",
      " [0.5728761 ]\n",
      " [0.58127761]\n",
      " [0.59039342]\n",
      " [0.59914953]\n",
      " [0.60827971]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6170507]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.54800624]\n",
      "  [0.55644733]\n",
      "  [0.56485069]\n",
      "  [0.5728761 ]\n",
      "  [0.58127761]\n",
      "  [0.59039342]\n",
      "  [0.59914953]\n",
      "  [0.60827971]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031131137162446976\n",
      "Predicción post entrenamiento : [[0.6179569]]\n",
      "PERDIDAAAA despues: 0.030812188982963562\n",
      "loss en el callback: 0.02081175334751606, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.55644733]\n",
      " [0.56485069]\n",
      " [0.5728761 ]\n",
      " [0.58127761]\n",
      " [0.59039342]\n",
      " [0.59914953]\n",
      " [0.60827971]\n",
      " [0.61705071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.62536716]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.55644733]\n",
      "  [0.56485069]\n",
      "  [0.5728761 ]\n",
      "  [0.58127761]\n",
      "  [0.59039342]\n",
      "  [0.59914953]\n",
      "  [0.60827971]\n",
      "  [0.61705071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018171928822994232\n",
      "Predicción post entrenamiento : [[0.62567776]]\n",
      "PERDIDAAAA despues: 0.018088284879922867\n",
      "loss en el callback: 0.0020190407522022724, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.56485069]\n",
      " [0.5728761 ]\n",
      " [0.58127761]\n",
      " [0.59039342]\n",
      " [0.59914953]\n",
      " [0.60827971]\n",
      " [0.61705071]\n",
      " [0.62536716]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.63314986]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.56485069]\n",
      "  [0.5728761 ]\n",
      "  [0.58127761]\n",
      "  [0.59039342]\n",
      "  [0.59914953]\n",
      "  [0.60827971]\n",
      "  [0.61705071]\n",
      "  [0.62536716]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010449756868183613\n",
      "Predicción post entrenamiento : [[0.63358265]]\n",
      "PERDIDAAAA despues: 0.010361460968852043\n",
      "loss en el callback: 0.004592409823089838, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.5728761 ]\n",
      " [0.58127761]\n",
      " [0.59039342]\n",
      " [0.59914953]\n",
      " [0.60827971]\n",
      " [0.61705071]\n",
      " [0.62536716]\n",
      " [0.63314986]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6411383]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.5728761 ]\n",
      "  [0.58127761]\n",
      "  [0.59039342]\n",
      "  [0.59914953]\n",
      "  [0.60827971]\n",
      "  [0.61705071]\n",
      "  [0.62536716]\n",
      "  [0.63314986]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00476811034604907\n",
      "Predicción post entrenamiento : [[0.6411167]]\n",
      "PERDIDAAAA despues: 0.004771098960191011\n",
      "loss en el callback: 1.0547027159191202e-05, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.58127761]\n",
      " [0.59039342]\n",
      " [0.59914953]\n",
      " [0.60827971]\n",
      " [0.61705071]\n",
      " [0.62536716]\n",
      " [0.63314986]\n",
      " [0.64113832]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.64886916]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.58127761]\n",
      "  [0.59039342]\n",
      "  [0.59914953]\n",
      "  [0.60827971]\n",
      "  [0.61705071]\n",
      "  [0.62536716]\n",
      "  [0.63314986]\n",
      "  [0.64113832]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004001566208899021\n",
      "Predicción post entrenamiento : [[0.64897573]]\n",
      "PERDIDAAAA despues: 0.003988094162195921\n",
      "loss en el callback: 0.00025180692318826914, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.59039342]\n",
      " [0.59914953]\n",
      " [0.60827971]\n",
      " [0.61705071]\n",
      " [0.62536716]\n",
      " [0.63314986]\n",
      " [0.64113832]\n",
      " [0.64886916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6568224]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.59039342]\n",
      "  [0.59914953]\n",
      "  [0.60827971]\n",
      "  [0.61705071]\n",
      "  [0.62536716]\n",
      "  [0.63314986]\n",
      "  [0.64113832]\n",
      "  [0.64886916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006858066190034151\n",
      "Predicción post entrenamiento : [[0.6579363]]\n",
      "PERDIDAAAA despues: 0.006674816366285086\n",
      "loss en el callback: 0.050240255892276764, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.59914953]\n",
      " [0.60827971]\n",
      " [0.61705071]\n",
      " [0.62536716]\n",
      " [0.63314986]\n",
      " [0.64113832]\n",
      " [0.64886916]\n",
      " [0.65682238]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.66565156]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.59914953]\n",
      "  [0.60827971]\n",
      "  [0.61705071]\n",
      "  [0.62536716]\n",
      "  [0.63314986]\n",
      "  [0.64113832]\n",
      "  [0.64886916]\n",
      "  [0.65682238]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004969857167452574\n",
      "Predicción post entrenamiento : [[0.66599655]]\n",
      "PERDIDAAAA despues: 0.004921334329992533\n",
      "loss en el callback: 0.0033089928328990936, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.60827971]\n",
      " [0.61705071]\n",
      " [0.62536716]\n",
      " [0.63314986]\n",
      " [0.64113832]\n",
      " [0.64886916]\n",
      " [0.65682238]\n",
      " [0.66565156]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6736341]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.60827971]\n",
      "  [0.61705071]\n",
      "  [0.62536716]\n",
      "  [0.63314986]\n",
      "  [0.64113832]\n",
      "  [0.64886916]\n",
      "  [0.65682238]\n",
      "  [0.66565156]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.676483902381733e-05\n",
      "Predicción post entrenamiento : [[0.6730699]]\n",
      "PERDIDAAAA despues: 3.0241026252042502e-05\n",
      "loss en el callback: 0.006961369421333075, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.61705071]\n",
      " [0.62536716]\n",
      " [0.63314986]\n",
      " [0.64113832]\n",
      " [0.64886916]\n",
      " [0.65682238]\n",
      " [0.66565156]\n",
      " [0.67363411]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6804799]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.61705071]\n",
      "  [0.62536716]\n",
      "  [0.63314986]\n",
      "  [0.64113832]\n",
      "  [0.64886916]\n",
      "  [0.65682238]\n",
      "  [0.66565156]\n",
      "  [0.67363411]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011203108442714438\n",
      "Predicción post entrenamiento : [[0.6809063]]\n",
      "PERDIDAAAA despues: 0.00012123959459131584\n",
      "loss en el callback: 0.006122370716184378, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.62536716]\n",
      " [0.63314986]\n",
      " [0.64113832]\n",
      " [0.64886916]\n",
      " [0.65682238]\n",
      " [0.66565156]\n",
      " [0.67363411]\n",
      " [0.68047988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.68814456]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.62536716]\n",
      "  [0.63314986]\n",
      "  [0.64113832]\n",
      "  [0.64886916]\n",
      "  [0.65682238]\n",
      "  [0.66565156]\n",
      "  [0.67363411]\n",
      "  [0.68047988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.198948151199147e-05\n",
      "Predicción post entrenamiento : [[0.687466]]\n",
      "PERDIDAAAA despues: 8.396425255341455e-05\n",
      "loss en el callback: 0.010009340941905975, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.63314986]\n",
      " [0.64113832]\n",
      " [0.64886916]\n",
      " [0.65682238]\n",
      " [0.66565156]\n",
      " [0.67363411]\n",
      " [0.68047988]\n",
      " [0.68814456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.69462377]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.63314986]\n",
      "  [0.64113832]\n",
      "  [0.64886916]\n",
      "  [0.65682238]\n",
      "  [0.66565156]\n",
      "  [0.67363411]\n",
      "  [0.68047988]\n",
      "  [0.68814456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014958670362830162\n",
      "Predicción post entrenamiento : [[0.6938]]\n",
      "PERDIDAAAA despues: 0.001432822784408927\n",
      "loss en el callback: 0.015585298649966717, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.64113832]\n",
      " [0.64886916]\n",
      " [0.65682238]\n",
      " [0.66565156]\n",
      " [0.67363411]\n",
      " [0.68047988]\n",
      " [0.68814456]\n",
      " [0.69462377]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.701005]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.64113832]\n",
      "  [0.64886916]\n",
      "  [0.65682238]\n",
      "  [0.66565156]\n",
      "  [0.67363411]\n",
      "  [0.68047988]\n",
      "  [0.68814456]\n",
      "  [0.69462377]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004927653935737908\n",
      "Predicción post entrenamiento : [[0.70081496]]\n",
      "PERDIDAAAA despues: 0.00048436527140438557\n",
      "loss en el callback: 0.0010111699812114239, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.64886916]\n",
      " [0.65682238]\n",
      " [0.66565156]\n",
      " [0.67363411]\n",
      " [0.68047988]\n",
      " [0.68814456]\n",
      " [0.69462377]\n",
      " [0.70100498]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7079841]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.64886916]\n",
      "  [0.65682238]\n",
      "  [0.66565156]\n",
      "  [0.67363411]\n",
      "  [0.68047988]\n",
      "  [0.68814456]\n",
      "  [0.69462377]\n",
      "  [0.70100498]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010169439483433962\n",
      "Predicción post entrenamiento : [[0.7083616]]\n",
      "PERDIDAAAA despues: 0.0010411653202027082\n",
      "loss en el callback: 0.005248300265520811, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.65682238]\n",
      " [0.66565156]\n",
      " [0.67363411]\n",
      " [0.68047988]\n",
      " [0.68814456]\n",
      " [0.69462377]\n",
      " [0.70100498]\n",
      " [0.70798409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7155299]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.65682238]\n",
      "  [0.66565156]\n",
      "  [0.67363411]\n",
      "  [0.68047988]\n",
      "  [0.68814456]\n",
      "  [0.69462377]\n",
      "  [0.70100498]\n",
      "  [0.70798409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019690388580784202\n",
      "Predicción post entrenamiento : [[0.715664]]\n",
      "PERDIDAAAA despues: 0.00019315813551656902\n",
      "loss en el callback: 0.0005428868462331593, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.66565156]\n",
      " [0.67363411]\n",
      " [0.68047988]\n",
      " [0.68814456]\n",
      " [0.69462377]\n",
      " [0.70100498]\n",
      " [0.70798409]\n",
      " [0.71552992]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.722723]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.66565156]\n",
      "  [0.67363411]\n",
      "  [0.68047988]\n",
      "  [0.68814456]\n",
      "  [0.69462377]\n",
      "  [0.70100498]\n",
      "  [0.70798409]\n",
      "  [0.71552992]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004598640080075711\n",
      "Predicción post entrenamiento : [[0.7230264]]\n",
      "PERDIDAAAA despues: 0.00047296800767071545\n",
      "loss en el callback: 0.0031717289239168167, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.67363411]\n",
      " [0.68047988]\n",
      " [0.68814456]\n",
      " [0.69462377]\n",
      " [0.70100498]\n",
      " [0.70798409]\n",
      " [0.71552992]\n",
      " [0.72272301]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7296604]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.67363411]\n",
      "  [0.68047988]\n",
      "  [0.68814456]\n",
      "  [0.69462377]\n",
      "  [0.70100498]\n",
      "  [0.70798409]\n",
      "  [0.71552992]\n",
      "  [0.72272301]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014342580689117312\n",
      "Predicción post entrenamiento : [[0.7303265]]\n",
      "PERDIDAAAA despues: 0.0013842504704371095\n",
      "loss en el callback: 0.016346704214811325, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.68047988]\n",
      " [0.68814456]\n",
      " [0.69462377]\n",
      " [0.70100498]\n",
      " [0.70798409]\n",
      " [0.71552992]\n",
      " [0.72272301]\n",
      " [0.72966039]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7367098]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.68047988]\n",
      "  [0.68814456]\n",
      "  [0.69462377]\n",
      "  [0.70100498]\n",
      "  [0.70798409]\n",
      "  [0.71552992]\n",
      "  [0.72272301]\n",
      "  [0.72966039]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003394406521692872\n",
      "Predicción post entrenamiento : [[0.7371905]]\n",
      "PERDIDAAAA despues: 0.0003219585632905364\n",
      "loss en el callback: 0.007958227768540382, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.68814456]\n",
      " [0.69462377]\n",
      " [0.70100498]\n",
      " [0.70798409]\n",
      " [0.71552992]\n",
      " [0.72272301]\n",
      " [0.72966039]\n",
      " [0.73670977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.743627]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.68814456]\n",
      "  [0.69462377]\n",
      "  [0.70100498]\n",
      "  [0.70798409]\n",
      "  [0.71552992]\n",
      "  [0.72272301]\n",
      "  [0.72966039]\n",
      "  [0.73670977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.0535317162284628e-06\n",
      "Predicción post entrenamiento : [[0.7434377]]\n",
      "PERDIDAAAA despues: 2.6319196422264213e-06\n",
      "loss en el callback: 0.0009626019163988531, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.69462377]\n",
      " [0.70100498]\n",
      " [0.70798409]\n",
      " [0.71552992]\n",
      " [0.72272301]\n",
      " [0.72966039]\n",
      " [0.73670977]\n",
      " [0.74362701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7496844]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.69462377]\n",
      "  [0.70100498]\n",
      "  [0.70798409]\n",
      "  [0.71552992]\n",
      "  [0.72272301]\n",
      "  [0.72966039]\n",
      "  [0.73670977]\n",
      "  [0.74362701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.520971171790734e-06\n",
      "Predicción post entrenamiento : [[0.7497882]]\n",
      "PERDIDAAAA despues: 5.043812507210532e-06\n",
      "loss en el callback: 0.00032053980976343155, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.70100498]\n",
      " [0.70798409]\n",
      " [0.71552992]\n",
      " [0.72272301]\n",
      " [0.72966039]\n",
      " [0.73670977]\n",
      " [0.74362701]\n",
      " [0.74968439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7561792]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.70100498]\n",
      "  [0.70798409]\n",
      "  [0.71552992]\n",
      "  [0.72272301]\n",
      "  [0.72966039]\n",
      "  [0.73670977]\n",
      "  [0.74362701]\n",
      "  [0.74968439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002150809857994318\n",
      "Predicción post entrenamiento : [[0.7552276]]\n",
      "PERDIDAAAA despues: 0.0020634520333260298\n",
      "loss en el callback: 0.022132594138383865, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.70798409]\n",
      " [0.71552992]\n",
      " [0.72272301]\n",
      " [0.72966039]\n",
      " [0.73670977]\n",
      " [0.74362701]\n",
      " [0.74968439]\n",
      " [0.75617921]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.76180464]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.70798409]\n",
      "  [0.71552992]\n",
      "  [0.72272301]\n",
      "  [0.72966039]\n",
      "  [0.73670977]\n",
      "  [0.74362701]\n",
      "  [0.74968439]\n",
      "  [0.75617921]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005094332620501518\n",
      "Predicción post entrenamiento : [[0.7602367]]\n",
      "PERDIDAAAA despues: 0.004872966557741165\n",
      "loss en el callback: 0.05587059259414673, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.71552992]\n",
      " [0.72272301]\n",
      " [0.72966039]\n",
      " [0.73670977]\n",
      " [0.74362701]\n",
      " [0.74968439]\n",
      " [0.75617921]\n",
      " [0.76180464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7668169]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.71552992]\n",
      "  [0.72272301]\n",
      "  [0.72966039]\n",
      "  [0.73670977]\n",
      "  [0.74362701]\n",
      "  [0.74968439]\n",
      "  [0.75617921]\n",
      "  [0.76180464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015520538727287203\n",
      "Predicción post entrenamiento : [[0.7668168]]\n",
      "PERDIDAAAA despues: 0.00015520241868216544\n",
      "loss en el callback: 5.376001865897706e-10, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.72272301]\n",
      " [0.72966039]\n",
      " [0.73670977]\n",
      " [0.74362701]\n",
      " [0.74968439]\n",
      " [0.75617921]\n",
      " [0.76180464]\n",
      " [0.76681691]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.77319175]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.72272301]\n",
      "  [0.72966039]\n",
      "  [0.73670977]\n",
      "  [0.74362701]\n",
      "  [0.74968439]\n",
      "  [0.75617921]\n",
      "  [0.76180464]\n",
      "  [0.76681691]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026000880170613527\n",
      "Predicción post entrenamiento : [[0.77244765]]\n",
      "PERDIDAAAA despues: 0.002524756360799074\n",
      "loss en el callback: 0.01385505311191082, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.72966039]\n",
      " [0.73670977]\n",
      " [0.74362701]\n",
      " [0.74968439]\n",
      " [0.75617921]\n",
      " [0.76180464]\n",
      " [0.76681691]\n",
      " [0.77319175]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.77865064]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.72966039]\n",
      "  [0.73670977]\n",
      "  [0.74362701]\n",
      "  [0.74968439]\n",
      "  [0.75617921]\n",
      "  [0.76180464]\n",
      "  [0.76681691]\n",
      "  [0.77319175]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00488010048866272\n",
      "Predicción post entrenamiento : [[0.77956605]]\n",
      "PERDIDAAAA despues: 0.004753042012453079\n",
      "loss en el callback: 0.03386159986257553, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.73670977]\n",
      " [0.74362701]\n",
      " [0.74968439]\n",
      " [0.75617921]\n",
      " [0.76180464]\n",
      " [0.76681691]\n",
      " [0.77319175]\n",
      " [0.77865064]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7856153]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.73670977]\n",
      "  [0.74362701]\n",
      "  [0.74968439]\n",
      "  [0.75617921]\n",
      "  [0.76180464]\n",
      "  [0.76681691]\n",
      "  [0.77319175]\n",
      "  [0.77865064]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01436346024274826\n",
      "Predicción post entrenamiento : [[0.7859813]]\n",
      "PERDIDAAAA despues: 0.014275872148573399\n",
      "loss en el callback: 0.0037321620620787144, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.74362701]\n",
      " [0.74968439]\n",
      " [0.75617921]\n",
      " [0.76180464]\n",
      " [0.76681691]\n",
      " [0.77319175]\n",
      " [0.77865064]\n",
      " [0.78561532]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7917881]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.74362701]\n",
      "  [0.74968439]\n",
      "  [0.75617921]\n",
      "  [0.76180464]\n",
      "  [0.76681691]\n",
      "  [0.77319175]\n",
      "  [0.77865064]\n",
      "  [0.78561532]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00817724410444498\n",
      "Predicción post entrenamiento : [[0.7925662]]\n",
      "PERDIDAAAA despues: 0.008037128485739231\n",
      "loss en el callback: 0.019591836258769035, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.74968439]\n",
      " [0.75617921]\n",
      " [0.76180464]\n",
      " [0.76681691]\n",
      " [0.77319175]\n",
      " [0.77865064]\n",
      " [0.78561532]\n",
      " [0.7917881 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.79812104]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.74968439]\n",
      "  [0.75617921]\n",
      "  [0.76180464]\n",
      "  [0.76681691]\n",
      "  [0.77319175]\n",
      "  [0.77865064]\n",
      "  [0.78561532]\n",
      "  [0.7917881 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0120267728343606\n",
      "Predicción post entrenamiento : [[0.79802155]]\n",
      "PERDIDAAAA despues: 0.012048602104187012\n",
      "loss en el callback: 0.000235735482419841, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.75617921]\n",
      " [0.76180464]\n",
      " [0.76681691]\n",
      " [0.77319175]\n",
      " [0.77865064]\n",
      " [0.78561532]\n",
      " [0.7917881 ]\n",
      " [0.79812104]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.803552]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.75617921]\n",
      "  [0.76180464]\n",
      "  [0.76681691]\n",
      "  [0.77319175]\n",
      "  [0.77865064]\n",
      "  [0.78561532]\n",
      "  [0.7917881 ]\n",
      "  [0.79812104]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007400423754006624\n",
      "Predicción post entrenamiento : [[0.80369306]]\n",
      "PERDIDAAAA despues: 0.007376169785857201\n",
      "loss en el callback: 0.0005477333907037973, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.76180464]\n",
      " [0.76681691]\n",
      " [0.77319175]\n",
      " [0.77865064]\n",
      " [0.78561532]\n",
      " [0.7917881 ]\n",
      " [0.79812104]\n",
      " [0.80355197]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.80906564]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.76180464]\n",
      "  [0.76681691]\n",
      "  [0.77319175]\n",
      "  [0.77865064]\n",
      "  [0.78561532]\n",
      "  [0.7917881 ]\n",
      "  [0.79812104]\n",
      "  [0.80355197]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0043281982652843\n",
      "Predicción post entrenamiento : [[0.8095522]]\n",
      "PERDIDAAAA despues: 0.004264415241777897\n",
      "loss en el callback: 0.0073935952968895435, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.76681691]\n",
      " [0.77319175]\n",
      " [0.77865064]\n",
      " [0.78561532]\n",
      " [0.7917881 ]\n",
      " [0.79812104]\n",
      " [0.80355197]\n",
      " [0.80906564]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.81502193]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.76681691]\n",
      "  [0.77319175]\n",
      "  [0.77865064]\n",
      "  [0.78561532]\n",
      "  [0.7917881 ]\n",
      "  [0.79812104]\n",
      "  [0.80355197]\n",
      "  [0.80906564]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009641277603805065\n",
      "Predicción post entrenamiento : [[0.8157209]]\n",
      "PERDIDAAAA despues: 0.009504499845206738\n",
      "loss en el callback: 0.01680227555334568, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.77319175]\n",
      " [0.77865064]\n",
      " [0.78561532]\n",
      " [0.7917881 ]\n",
      " [0.79812104]\n",
      " [0.80355197]\n",
      " [0.80906564]\n",
      " [0.81502193]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.82149684]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.77319175]\n",
      "  [0.77865064]\n",
      "  [0.78561532]\n",
      "  [0.7917881 ]\n",
      "  [0.79812104]\n",
      "  [0.80355197]\n",
      "  [0.80906564]\n",
      "  [0.81502193]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03186337649822235\n",
      "Predicción post entrenamiento : [[0.82242906]]\n",
      "PERDIDAAAA despues: 0.0315314382314682\n",
      "loss en el callback: 0.030845992267131805, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.77865064]\n",
      " [0.78561532]\n",
      " [0.7917881 ]\n",
      " [0.79812104]\n",
      " [0.80355197]\n",
      " [0.80906564]\n",
      " [0.81502193]\n",
      " [0.82149684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8281284]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.77865064]\n",
      "  [0.78561532]\n",
      "  [0.7917881 ]\n",
      "  [0.79812104]\n",
      "  [0.80355197]\n",
      "  [0.80906564]\n",
      "  [0.81502193]\n",
      "  [0.82149684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020285068079829216\n",
      "Predicción post entrenamiento : [[0.8285074]]\n",
      "PERDIDAAAA despues: 0.020177245140075684\n",
      "loss en el callback: 0.003973051905632019, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.78561532]\n",
      " [0.7917881 ]\n",
      " [0.79812104]\n",
      " [0.80355197]\n",
      " [0.80906564]\n",
      " [0.81502193]\n",
      " [0.82149684]\n",
      " [0.8281284 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8343984]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.78561532]\n",
      "  [0.7917881 ]\n",
      "  [0.79812104]\n",
      "  [0.80355197]\n",
      "  [0.80906564]\n",
      "  [0.81502193]\n",
      "  [0.82149684]\n",
      "  [0.8281284 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029598362743854523\n",
      "Predicción post entrenamiento : [[0.8351216]]\n",
      "PERDIDAAAA despues: 0.002881670603528619\n",
      "loss en el callback: 0.019271867349743843, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.7917881 ]\n",
      " [0.79812104]\n",
      " [0.80355197]\n",
      " [0.80906564]\n",
      " [0.81502193]\n",
      " [0.82149684]\n",
      " [0.8281284 ]\n",
      " [0.83439839]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.84075934]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.7917881 ]\n",
      "  [0.79812104]\n",
      "  [0.80355197]\n",
      "  [0.80906564]\n",
      "  [0.81502193]\n",
      "  [0.82149684]\n",
      "  [0.8281284 ]\n",
      "  [0.83439839]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013834655983373523\n",
      "Predicción post entrenamiento : [[0.84089315]]\n",
      "PERDIDAAAA despues: 0.001373529201373458\n",
      "loss en el callback: 0.0005688634118996561, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.79812104]\n",
      " [0.80355197]\n",
      " [0.80906564]\n",
      " [0.81502193]\n",
      " [0.82149684]\n",
      " [0.8281284 ]\n",
      " [0.83439839]\n",
      " [0.84075934]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.846491]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.79812104]\n",
      "  [0.80355197]\n",
      "  [0.80906564]\n",
      "  [0.81502193]\n",
      "  [0.82149684]\n",
      "  [0.8281284 ]\n",
      "  [0.83439839]\n",
      "  [0.84075934]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.783106189483078e-06\n",
      "Predicción post entrenamiento : [[0.8464244]]\n",
      "PERDIDAAAA despues: 6.1077557802491356e-06\n",
      "loss en el callback: 0.00014740796177648008, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.80355197]\n",
      " [0.80906564]\n",
      " [0.81502193]\n",
      " [0.82149684]\n",
      " [0.8281284 ]\n",
      " [0.83439839]\n",
      " [0.84075934]\n",
      " [0.84649098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8519362]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.80355197]\n",
      "  [0.80906564]\n",
      "  [0.81502193]\n",
      "  [0.82149684]\n",
      "  [0.8281284 ]\n",
      "  [0.83439839]\n",
      "  [0.84075934]\n",
      "  [0.84649098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00031553965527564287\n",
      "Predicción post entrenamiento : [[0.85180867]]\n",
      "PERDIDAAAA despues: 0.0003110243414994329\n",
      "loss en el callback: 0.0005393152241595089, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.80906564]\n",
      " [0.81502193]\n",
      " [0.82149684]\n",
      " [0.8281284 ]\n",
      " [0.83439839]\n",
      " [0.84075934]\n",
      " [0.84649098]\n",
      " [0.85193622]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8575143]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.80906564]\n",
      "  [0.81502193]\n",
      "  [0.82149684]\n",
      "  [0.8281284 ]\n",
      "  [0.83439839]\n",
      "  [0.84075934]\n",
      "  [0.84649098]\n",
      "  [0.85193622]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.853555194335058e-06\n",
      "Predicción post entrenamiento : [[0.8581878]]\n",
      "PERDIDAAAA despues: 9.565937943989411e-06\n",
      "loss en el callback: 0.021904001012444496, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.81502193]\n",
      " [0.82149684]\n",
      " [0.8281284 ]\n",
      " [0.83439839]\n",
      " [0.84075934]\n",
      " [0.84649098]\n",
      " [0.85193622]\n",
      " [0.85751432]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.86409044]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.81502193]\n",
      "  [0.82149684]\n",
      "  [0.8281284 ]\n",
      "  [0.83439839]\n",
      "  [0.84075934]\n",
      "  [0.84649098]\n",
      "  [0.85193622]\n",
      "  [0.85751432]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012436110409907997\n",
      "Predicción post entrenamiento : [[0.86411995]]\n",
      "PERDIDAAAA despues: 0.0001237039250554517\n",
      "loss en el callback: 2.7171872716280632e-05, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.82149684]\n",
      " [0.8281284 ]\n",
      " [0.83439839]\n",
      " [0.84075934]\n",
      " [0.84649098]\n",
      " [0.85193622]\n",
      " [0.85751432]\n",
      " [0.86409044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.87009645]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.82149684]\n",
      "  [0.8281284 ]\n",
      "  [0.83439839]\n",
      "  [0.84075934]\n",
      "  [0.84649098]\n",
      "  [0.85193622]\n",
      "  [0.85751432]\n",
      "  [0.86409044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017067503358703107\n",
      "Predicción post entrenamiento : [[0.8701034]]\n",
      "PERDIDAAAA despues: 0.00017085728177335113\n",
      "loss en el callback: 1.879222168099659e-06, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.8281284 ]\n",
      " [0.83439839]\n",
      " [0.84075934]\n",
      " [0.84649098]\n",
      " [0.85193622]\n",
      " [0.85751432]\n",
      " [0.86409044]\n",
      " [0.87009645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.87598485]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.8281284 ]\n",
      "  [0.83439839]\n",
      "  [0.84075934]\n",
      "  [0.84649098]\n",
      "  [0.85193622]\n",
      "  [0.85751432]\n",
      "  [0.86409044]\n",
      "  [0.87009645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006721942336298525\n",
      "Predicción post entrenamiento : [[0.8758137]]\n",
      "PERDIDAAAA despues: 0.0006633501034229994\n",
      "loss en el callback: 0.001002711709588766, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.83439839]\n",
      " [0.84075934]\n",
      " [0.84649098]\n",
      " [0.85193622]\n",
      " [0.85751432]\n",
      " [0.86409044]\n",
      " [0.87009645]\n",
      " [0.87598485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.88152134]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.83439839]\n",
      "  [0.84075934]\n",
      "  [0.84649098]\n",
      "  [0.85193622]\n",
      "  [0.85751432]\n",
      "  [0.86409044]\n",
      "  [0.87009645]\n",
      "  [0.87598485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015073602553457022\n",
      "Predicción post entrenamiento : [[0.8816458]]\n",
      "PERDIDAAAA despues: 0.0015170394908636808\n",
      "loss en el callback: 0.000614918943028897, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.84075934]\n",
      " [0.84649098]\n",
      " [0.85193622]\n",
      " [0.85751432]\n",
      " [0.86409044]\n",
      " [0.87009645]\n",
      " [0.87598485]\n",
      " [0.88152134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8872584]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.84075934]\n",
      "  [0.84649098]\n",
      "  [0.85193622]\n",
      "  [0.85751432]\n",
      "  [0.86409044]\n",
      "  [0.87009645]\n",
      "  [0.87598485]\n",
      "  [0.88152134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004137265495955944\n",
      "Predicción post entrenamiento : [[0.8875164]]\n",
      "PERDIDAAAA despues: 0.004170517902821302\n",
      "loss en el callback: 0.0031340369023382664, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.84649098]\n",
      " [0.85193622]\n",
      " [0.85751432]\n",
      " [0.86409044]\n",
      " [0.87009645]\n",
      " [0.87598485]\n",
      " [0.88152134]\n",
      " [0.88725841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.89298785]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.84649098]\n",
      "  [0.85193622]\n",
      "  [0.85751432]\n",
      "  [0.86409044]\n",
      "  [0.87009645]\n",
      "  [0.87598485]\n",
      "  [0.88152134]\n",
      "  [0.88725841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01403794065117836\n",
      "Predicción post entrenamiento : [[0.8918501]]\n",
      "PERDIDAAAA despues: 0.013769633136689663\n",
      "loss en el callback: 0.04001322761178017, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.85193622]\n",
      " [0.85751432]\n",
      " [0.86409044]\n",
      " [0.87009645]\n",
      " [0.87598485]\n",
      " [0.88152134]\n",
      " [0.88725841]\n",
      " [0.89298785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8973543]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.85193622]\n",
      "  [0.85751432]\n",
      "  [0.86409044]\n",
      "  [0.87009645]\n",
      "  [0.87598485]\n",
      "  [0.88152134]\n",
      "  [0.88725841]\n",
      "  [0.89298785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012805674225091934\n",
      "Predicción post entrenamiento : [[0.8961283]]\n",
      "PERDIDAAAA despues: 0.012529701925814152\n",
      "loss en el callback: 0.04525326192378998, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.85751432]\n",
      " [0.86409044]\n",
      " [0.87009645]\n",
      " [0.87598485]\n",
      " [0.88152134]\n",
      " [0.88725841]\n",
      " [0.89298785]\n",
      " [0.8973543 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.90175086]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.85751432]\n",
      "  [0.86409044]\n",
      "  [0.87009645]\n",
      "  [0.87598485]\n",
      "  [0.88152134]\n",
      "  [0.88725841]\n",
      "  [0.89298785]\n",
      "  [0.8973543 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017645504558458924\n",
      "Predicción post entrenamiento : [[0.90011525]]\n",
      "PERDIDAAAA despues: 0.0016298128757625818\n",
      "loss en el callback: 0.06673192232847214, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.86409044]\n",
      " [0.87009645]\n",
      " [0.87598485]\n",
      " [0.88152134]\n",
      " [0.88725841]\n",
      " [0.89298785]\n",
      " [0.8973543 ]\n",
      " [0.90175086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9058044]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.86409044]\n",
      "  [0.87009645]\n",
      "  [0.87598485]\n",
      "  [0.88152134]\n",
      "  [0.88725841]\n",
      "  [0.89298785]\n",
      "  [0.8973543 ]\n",
      "  [0.90175086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026506378781050444\n",
      "Predicción post entrenamiento : [[0.9053987]]\n",
      "PERDIDAAAA despues: 0.0026090312749147415\n",
      "loss en el callback: 0.005652883090078831, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.87009645]\n",
      " [0.87598485]\n",
      " [0.88152134]\n",
      " [0.88725841]\n",
      " [0.89298785]\n",
      " [0.8973543 ]\n",
      " [0.90175086]\n",
      " [0.9058044 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.91080767]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.87009645]\n",
      "  [0.87598485]\n",
      "  [0.88152134]\n",
      "  [0.88725841]\n",
      "  [0.89298785]\n",
      "  [0.8973543 ]\n",
      "  [0.90175086]\n",
      "  [0.9058044 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005464573390781879\n",
      "Predicción post entrenamiento : [[0.91110957]]\n",
      "PERDIDAAAA despues: 0.005509298760443926\n",
      "loss en el callback: 0.004937630146741867, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.87598485]\n",
      " [0.88152134]\n",
      " [0.88725841]\n",
      " [0.89298785]\n",
      " [0.8973543 ]\n",
      " [0.90175086]\n",
      " [0.9058044 ]\n",
      " [0.91080767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.91633457]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.87598485]\n",
      "  [0.88152134]\n",
      "  [0.88725841]\n",
      "  [0.89298785]\n",
      "  [0.8973543 ]\n",
      "  [0.90175086]\n",
      "  [0.9058044 ]\n",
      "  [0.91080767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007469055242836475\n",
      "Predicción post entrenamiento : [[0.91568404]]\n",
      "PERDIDAAAA despues: 0.0073570366948843\n",
      "loss en el callback: 0.013622255064547062, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.88152134]\n",
      " [0.88725841]\n",
      " [0.89298785]\n",
      " [0.8973543 ]\n",
      " [0.90175086]\n",
      " [0.9058044 ]\n",
      " [0.91080767]\n",
      " [0.91633457]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9206981]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.88152134]\n",
      "  [0.88725841]\n",
      "  [0.89298785]\n",
      "  [0.8973543 ]\n",
      "  [0.90175086]\n",
      "  [0.9058044 ]\n",
      "  [0.91080767]\n",
      "  [0.91633457]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001118576037697494\n",
      "Predicción post entrenamiento : [[0.91979724]]\n",
      "PERDIDAAAA despues: 0.0010591285536065698\n",
      "loss en el callback: 0.024382462725043297, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.88725841]\n",
      " [0.89298785]\n",
      " [0.8973543 ]\n",
      " [0.90175086]\n",
      " [0.9058044 ]\n",
      " [0.91080767]\n",
      " [0.91633457]\n",
      " [0.92069811]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9246516]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.88725841]\n",
      "  [0.89298785]\n",
      "  [0.8973543 ]\n",
      "  [0.90175086]\n",
      "  [0.9058044 ]\n",
      "  [0.91080767]\n",
      "  [0.91633457]\n",
      "  [0.92069811]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004212959203869104\n",
      "Predicción post entrenamiento : [[0.9236692]]\n",
      "PERDIDAAAA despues: 0.004086393862962723\n",
      "loss en el callback: 0.028292808681726456, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.89298785]\n",
      " [0.8973543 ]\n",
      " [0.90175086]\n",
      " [0.9058044 ]\n",
      " [0.91080767]\n",
      " [0.91633457]\n",
      " [0.92069811]\n",
      " [0.92465162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.92825294]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.89298785]\n",
      "  [0.8973543 ]\n",
      "  [0.90175086]\n",
      "  [0.9058044 ]\n",
      "  [0.91080767]\n",
      "  [0.91633457]\n",
      "  [0.92069811]\n",
      "  [0.92465162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007859867066144943\n",
      "Predicción post entrenamiento : [[0.9275672]]\n",
      "PERDIDAAAA despues: 0.007738745305687189\n",
      "loss en el callback: 0.015924399718642235, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.8973543 ]\n",
      " [0.90175086]\n",
      " [0.9058044 ]\n",
      " [0.91080767]\n",
      " [0.91633457]\n",
      " [0.92069811]\n",
      " [0.92465162]\n",
      " [0.92825294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.93182266]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.8973543 ]\n",
      "  [0.90175086]\n",
      "  [0.9058044 ]\n",
      "  [0.91080767]\n",
      "  [0.91633457]\n",
      "  [0.92069811]\n",
      "  [0.92465162]\n",
      "  [0.92825294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021909311413764954\n",
      "Predicción post entrenamiento : [[0.93189645]]\n",
      "PERDIDAAAA despues: 0.021931162104010582\n",
      "loss en el callback: 0.0002837998035829514, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.90175086]\n",
      " [0.9058044 ]\n",
      " [0.91080767]\n",
      " [0.91633457]\n",
      " [0.92069811]\n",
      " [0.92465162]\n",
      " [0.92825294]\n",
      " [0.93182266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9361935]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.90175086]\n",
      "  [0.9058044 ]\n",
      "  [0.91080767]\n",
      "  [0.91633457]\n",
      "  [0.92069811]\n",
      "  [0.92465162]\n",
      "  [0.92825294]\n",
      "  [0.93182266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013901832513511181\n",
      "Predicción post entrenamiento : [[0.9357626]]\n",
      "PERDIDAAAA despues: 0.013800397515296936\n",
      "loss en el callback: 0.007553173694759607, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.9058044 ]\n",
      " [0.91080767]\n",
      " [0.91633457]\n",
      " [0.92069811]\n",
      " [0.92465162]\n",
      " [0.92825294]\n",
      " [0.93182266]\n",
      " [0.93619353]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9400807]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.9058044 ]\n",
      "  [0.91080767]\n",
      "  [0.91633457]\n",
      "  [0.92069811]\n",
      "  [0.92465162]\n",
      "  [0.92825294]\n",
      "  [0.93182266]\n",
      "  [0.93619353]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022175533697009087\n",
      "Predicción post entrenamiento : [[0.93819755]]\n",
      "PERDIDAAAA despues: 0.021618222817778587\n",
      "loss en el callback: 0.1069665178656578, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.91080767]\n",
      " [0.91633457]\n",
      " [0.92069811]\n",
      " [0.92465162]\n",
      " [0.92825294]\n",
      " [0.93182266]\n",
      " [0.93619353]\n",
      " [0.9400807 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.94262165]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.91080767]\n",
      "  [0.91633457]\n",
      "  [0.92069811]\n",
      "  [0.92465162]\n",
      "  [0.92825294]\n",
      "  [0.93182266]\n",
      "  [0.93619353]\n",
      "  [0.9400807 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033147189766168594\n",
      "Predicción post entrenamiento : [[0.9409071]]\n",
      "PERDIDAAAA despues: 0.03252582252025604\n",
      "loss en el callback: 0.0910087525844574, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.91633457]\n",
      " [0.92069811]\n",
      " [0.92465162]\n",
      " [0.92825294]\n",
      " [0.93182266]\n",
      " [0.93619353]\n",
      " [0.9400807 ]\n",
      " [0.94262165]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9451119]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.91633457]\n",
      "  [0.92069811]\n",
      "  [0.92465162]\n",
      "  [0.92825294]\n",
      "  [0.93182266]\n",
      "  [0.93619353]\n",
      "  [0.9400807 ]\n",
      "  [0.94262165]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023580119013786316\n",
      "Predicción post entrenamiento : [[0.9446156]]\n",
      "PERDIDAAAA despues: 0.02342795394361019\n",
      "loss en el callback: 0.010698437690734863, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.92069811]\n",
      " [0.92465162]\n",
      " [0.92825294]\n",
      " [0.93182266]\n",
      " [0.93619353]\n",
      " [0.9400807 ]\n",
      " [0.94262165]\n",
      " [0.94511187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9483606]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.92069811]\n",
      "  [0.92465162]\n",
      "  [0.92825294]\n",
      "  [0.93182266]\n",
      "  [0.93619353]\n",
      "  [0.9400807 ]\n",
      "  [0.94262165]\n",
      "  [0.94511187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03227999433875084\n",
      "Predicción post entrenamiento : [[0.9477156]]\n",
      "PERDIDAAAA despues: 0.03204862400889397\n",
      "loss en el callback: 0.01659880019724369, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.92465162]\n",
      " [0.92825294]\n",
      " [0.93182266]\n",
      " [0.93619353]\n",
      " [0.9400807 ]\n",
      " [0.94262165]\n",
      " [0.94511187]\n",
      " [0.94836062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9512663]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.92465162]\n",
      "  [0.92825294]\n",
      "  [0.93182266]\n",
      "  [0.93619353]\n",
      "  [0.9400807 ]\n",
      "  [0.94262165]\n",
      "  [0.94511187]\n",
      "  [0.94836062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03333253785967827\n",
      "Predicción post entrenamiento : [[0.95100784]]\n",
      "PERDIDAAAA despues: 0.033238235861063004\n",
      "loss en el callback: 0.0030372082255780697, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.92825294]\n",
      " [0.93182266]\n",
      " [0.93619353]\n",
      " [0.9400807 ]\n",
      " [0.94262165]\n",
      " [0.94511187]\n",
      " [0.94836062]\n",
      " [0.95126629]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.954437]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.92825294]\n",
      "  [0.93182266]\n",
      "  [0.93619353]\n",
      "  [0.9400807 ]\n",
      "  [0.94262165]\n",
      "  [0.94511187]\n",
      "  [0.94836062]\n",
      "  [0.95126629]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024187052622437477\n",
      "Predicción post entrenamiento : [[0.9530577]]\n",
      "PERDIDAAAA despues: 0.023759927600622177\n",
      "loss en el callback: 0.062281619757413864, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93182266]\n",
      " [0.93619353]\n",
      " [0.9400807 ]\n",
      " [0.94262165]\n",
      " [0.94511187]\n",
      " [0.94836062]\n",
      " [0.95126629]\n",
      " [0.95443702]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9564306]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93182266]\n",
      "  [0.93619353]\n",
      "  [0.9400807 ]\n",
      "  [0.94262165]\n",
      "  [0.94511187]\n",
      "  [0.94836062]\n",
      "  [0.95126629]\n",
      "  [0.95443702]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02769785188138485\n",
      "Predicción post entrenamiento : [[0.9549425]]\n",
      "PERDIDAAAA despues: 0.02720475196838379\n",
      "loss en el callback: 0.0740586370229721, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93619353]\n",
      " [0.9400807 ]\n",
      " [0.94262165]\n",
      " [0.94511187]\n",
      " [0.94836062]\n",
      " [0.95126629]\n",
      " [0.95443702]\n",
      " [0.95643061]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.95822895]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93619353]\n",
      "  [0.9400807 ]\n",
      "  [0.94262165]\n",
      "  [0.94511187]\n",
      "  [0.94836062]\n",
      "  [0.95126629]\n",
      "  [0.95443702]\n",
      "  [0.95643061]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.039227165281772614\n",
      "Predicción post entrenamiento : [[0.95640135]]\n",
      "PERDIDAAAA despues: 0.038506560027599335\n",
      "loss en el callback: 0.10904303193092346, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.9400807 ]\n",
      " [0.94262165]\n",
      " [0.94511187]\n",
      " [0.94836062]\n",
      " [0.95126629]\n",
      " [0.95443702]\n",
      " [0.95643061]\n",
      " [0.95822895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.95929617]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.9400807 ]\n",
      "  [0.94262165]\n",
      "  [0.94511187]\n",
      "  [0.94836062]\n",
      "  [0.95126629]\n",
      "  [0.95443702]\n",
      "  [0.95643061]\n",
      "  [0.95822895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07502279430627823\n",
      "Predicción post entrenamiento : [[0.9578051]]\n",
      "PERDIDAAAA despues: 0.07420819997787476\n",
      "loss en el callback: 0.08867032080888748, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.94262165]\n",
      " [0.94511187]\n",
      " [0.94836062]\n",
      " [0.95126629]\n",
      " [0.95443702]\n",
      " [0.95643061]\n",
      " [0.95822895]\n",
      " [0.95929617]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.96036804]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.94262165]\n",
      "  [0.94511187]\n",
      "  [0.94836062]\n",
      "  [0.95126629]\n",
      "  [0.95443702]\n",
      "  [0.95643061]\n",
      "  [0.95822895]\n",
      "  [0.95929617]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12615017592906952\n",
      "Predicción post entrenamiento : [[0.95962256]]\n",
      "PERDIDAAAA despues: 0.12562118470668793\n",
      "loss en el callback: 0.03156832233071327, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94511187]\n",
      " [0.94836062]\n",
      " [0.95126629]\n",
      " [0.95443702]\n",
      " [0.95643061]\n",
      " [0.95822895]\n",
      " [0.95929617]\n",
      " [0.96036804]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9621957]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94511187]\n",
      "  [0.94836062]\n",
      "  [0.95126629]\n",
      "  [0.95443702]\n",
      "  [0.95643061]\n",
      "  [0.95822895]\n",
      "  [0.95929617]\n",
      "  [0.96036804]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08840935677289963\n",
      "Predicción post entrenamiento : [[0.96127665]]\n",
      "PERDIDAAAA despues: 0.08786367624998093\n",
      "loss en el callback: 0.04244013875722885, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.94836062]\n",
      " [0.95126629]\n",
      " [0.95443702]\n",
      " [0.95643061]\n",
      " [0.95822895]\n",
      " [0.95929617]\n",
      " [0.96036804]\n",
      " [0.96219569]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9638351]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.94836062]\n",
      "  [0.95126629]\n",
      "  [0.95443702]\n",
      "  [0.95643061]\n",
      "  [0.95822895]\n",
      "  [0.95929617]\n",
      "  [0.96036804]\n",
      "  [0.96219569]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06552061438560486\n",
      "Predicción post entrenamiento : [[0.9624158]]\n",
      "PERDIDAAAA despues: 0.06479602307081223\n",
      "loss en el callback: 0.08075938373804092, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.95126629]\n",
      " [0.95443702]\n",
      " [0.95643061]\n",
      " [0.95822895]\n",
      " [0.95929617]\n",
      " [0.96036804]\n",
      " [0.96219569]\n",
      " [0.96383512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9646673]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.95126629]\n",
      "  [0.95443702]\n",
      "  [0.95643061]\n",
      "  [0.95822895]\n",
      "  [0.95929617]\n",
      "  [0.96036804]\n",
      "  [0.96219569]\n",
      "  [0.96383512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08988527953624725\n",
      "Predicción post entrenamiento : [[0.9631312]]\n",
      "PERDIDAAAA despues: 0.08896654844284058\n",
      "loss en el callback: 0.1002352386713028, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.95443702]\n",
      " [0.95643061]\n",
      " [0.95822895]\n",
      " [0.95929617]\n",
      " [0.96036804]\n",
      " [0.96219569]\n",
      " [0.96383512]\n",
      " [0.96466732]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.96509206]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.95443702]\n",
      "  [0.95643061]\n",
      "  [0.95822895]\n",
      "  [0.95929617]\n",
      "  [0.96036804]\n",
      "  [0.96219569]\n",
      "  [0.96383512]\n",
      "  [0.96466732]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06438393145799637\n",
      "Predicción post entrenamiento : [[0.96329445]]\n",
      "PERDIDAAAA despues: 0.06347490847110748\n",
      "loss en el callback: 0.12057480961084366, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.95643061]\n",
      " [0.95822895]\n",
      " [0.95929617]\n",
      " [0.96036804]\n",
      " [0.96219569]\n",
      " [0.96383512]\n",
      " [0.96466732]\n",
      " [0.96509206]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.96479744]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.95643061]\n",
      "  [0.95822895]\n",
      "  [0.95929617]\n",
      "  [0.96036804]\n",
      "  [0.96219569]\n",
      "  [0.96383512]\n",
      "  [0.96466732]\n",
      "  [0.96509206]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08267956972122192\n",
      "Predicción post entrenamiento : [[0.962987]]\n",
      "PERDIDAAAA despues: 0.08164170384407043\n",
      "loss en el callback: 0.12380553781986237, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.95822895]\n",
      " [0.95929617]\n",
      " [0.96036804]\n",
      " [0.96219569]\n",
      " [0.96383512]\n",
      " [0.96466732]\n",
      " [0.96509206]\n",
      " [0.96479744]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9643019]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.95822895]\n",
      "  [0.95929617]\n",
      "  [0.96036804]\n",
      "  [0.96219569]\n",
      "  [0.96383512]\n",
      "  [0.96466732]\n",
      "  [0.96509206]\n",
      "  [0.96479744]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040882475674152374\n",
      "Predicción post entrenamiento : [[0.9637534]]\n",
      "PERDIDAAAA despues: 0.040660977363586426\n",
      "loss en el callback: 0.015042722225189209, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.95929617]\n",
      " [0.96036804]\n",
      " [0.96219569]\n",
      " [0.96383512]\n",
      " [0.96466732]\n",
      " [0.96509206]\n",
      " [0.96479744]\n",
      " [0.96430188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9648779]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.95929617]\n",
      "  [0.96036804]\n",
      "  [0.96219569]\n",
      "  [0.96383512]\n",
      "  [0.96466732]\n",
      "  [0.96509206]\n",
      "  [0.96479744]\n",
      "  [0.96430188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024909161031246185\n",
      "Predicción post entrenamiento : [[0.9638264]]\n",
      "PERDIDAAAA despues: 0.024578362703323364\n",
      "loss en el callback: 0.04559941589832306, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.96036804]\n",
      " [0.96219569]\n",
      " [0.96383512]\n",
      " [0.96466732]\n",
      " [0.96509206]\n",
      " [0.96479744]\n",
      " [0.96430188]\n",
      " [0.9648779 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.96492565]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.96036804]\n",
      "  [0.96219569]\n",
      "  [0.96383512]\n",
      "  [0.96466732]\n",
      "  [0.96509206]\n",
      "  [0.96479744]\n",
      "  [0.96430188]\n",
      "  [0.9648779 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02242138423025608\n",
      "Predicción post entrenamiento : [[0.9646575]]\n",
      "PERDIDAAAA despues: 0.02234114706516266\n",
      "loss en el callback: 0.003828720422461629, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.96219569]\n",
      " [0.96383512]\n",
      " [0.96466732]\n",
      " [0.96509206]\n",
      " [0.96479744]\n",
      " [0.96430188]\n",
      " [0.9648779 ]\n",
      " [0.96492565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9656829]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.96219569]\n",
      "  [0.96383512]\n",
      "  [0.96466732]\n",
      "  [0.96509206]\n",
      "  [0.96479744]\n",
      "  [0.96430188]\n",
      "  [0.9648779 ]\n",
      "  [0.96492565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003533710725605488\n",
      "Predicción post entrenamiento : [[0.9648148]]\n",
      "PERDIDAAAA despues: 0.0034312510397285223\n",
      "loss en el callback: 0.02853073738515377, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.96383512]\n",
      " [0.96466732]\n",
      " [0.96509206]\n",
      " [0.96479744]\n",
      " [0.96430188]\n",
      " [0.9648779 ]\n",
      " [0.96492565]\n",
      " [0.96568292]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.96547526]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.96383512]\n",
      "  [0.96466732]\n",
      "  [0.96509206]\n",
      "  [0.96479744]\n",
      "  [0.96430188]\n",
      "  [0.9648779 ]\n",
      "  [0.96492565]\n",
      "  [0.96568292]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.3289779821643606e-05\n",
      "Predicción post entrenamiento : [[0.9652246]]\n",
      "PERDIDAAAA despues: 3.0460378184216097e-05\n",
      "loss en el callback: 0.0027917688712477684, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.96466732]\n",
      " [0.96509206]\n",
      " [0.96479744]\n",
      " [0.96430188]\n",
      " [0.9648779 ]\n",
      " [0.96492565]\n",
      " [0.96568292]\n",
      " [0.96547526]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.96549666]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.96466732]\n",
      "  [0.96509206]\n",
      "  [0.96479744]\n",
      "  [0.96430188]\n",
      "  [0.9648779 ]\n",
      "  [0.96492565]\n",
      "  [0.96568292]\n",
      "  [0.96547526]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3036765267315786e-06\n",
      "Predicción post entrenamiento : [[0.96550494]]\n",
      "PERDIDAAAA despues: 1.3226647297415184e-06\n",
      "loss en el callback: 3.100559069935116e-06, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.96509206]\n",
      " [0.96479744]\n",
      " [0.96430188]\n",
      " [0.9648779 ]\n",
      " [0.96492565]\n",
      " [0.96568292]\n",
      " [0.96547526]\n",
      " [0.96549666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9655742]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.96509206]\n",
      "  [0.96479744]\n",
      "  [0.96430188]\n",
      "  [0.9648779 ]\n",
      "  [0.96492565]\n",
      "  [0.96568292]\n",
      "  [0.96547526]\n",
      "  [0.96549666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0060134283266961575\n",
      "Predicción post entrenamiento : [[0.96450895]]\n",
      "PERDIDAAAA despues: 0.005849350243806839\n",
      "loss en el callback: 0.04592057317495346, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.96479744]\n",
      " [0.96430188]\n",
      " [0.9648779 ]\n",
      " [0.96492565]\n",
      " [0.96568292]\n",
      " [0.96547526]\n",
      " [0.96549666]\n",
      " [0.9655742 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.96447545]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.96479744]\n",
      "  [0.96430188]\n",
      "  [0.9648779 ]\n",
      "  [0.96492565]\n",
      "  [0.96568292]\n",
      "  [0.96547526]\n",
      "  [0.96549666]\n",
      "  [0.9655742 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0051549822092056274\n",
      "Predicción post entrenamiento : [[0.9632647]]\n",
      "PERDIDAAAA despues: 0.004982588812708855\n",
      "loss en el callback: 0.05581749230623245, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.96430188]\n",
      " [0.9648779 ]\n",
      " [0.96492565]\n",
      " [0.96568292]\n",
      " [0.96547526]\n",
      " [0.96549666]\n",
      " [0.9655742 ]\n",
      " [0.96447545]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9633394]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.96430188]\n",
      "  [0.9648779 ]\n",
      "  [0.96492565]\n",
      "  [0.96568292]\n",
      "  [0.96547526]\n",
      "  [0.96549666]\n",
      "  [0.9655742 ]\n",
      "  [0.96447545]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007761119399219751\n",
      "Predicción post entrenamiento : [[0.9625655]]\n",
      "PERDIDAAAA despues: 0.007625360041856766\n",
      "loss en el callback: 0.027953457087278366, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.9648779 ]\n",
      " [0.96492565]\n",
      " [0.96568292]\n",
      " [0.96547526]\n",
      " [0.96549666]\n",
      " [0.9655742 ]\n",
      " [0.96447545]\n",
      " [0.96333939]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9628132]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.9648779 ]\n",
      "  [0.96492565]\n",
      "  [0.96568292]\n",
      "  [0.96547526]\n",
      "  [0.96549666]\n",
      "  [0.9655742 ]\n",
      "  [0.96447545]\n",
      "  [0.96333939]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012539565563201904\n",
      "Predicción post entrenamiento : [[0.9617384]]\n",
      "PERDIDAAAA despues: 0.012300009839236736\n",
      "loss en el callback: 0.05066302418708801, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.96492565]\n",
      " [0.96568292]\n",
      " [0.96547526]\n",
      " [0.96549666]\n",
      " [0.9655742 ]\n",
      " [0.96447545]\n",
      " [0.96333939]\n",
      " [0.9628132 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9618168]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.96492565]\n",
      "  [0.96568292]\n",
      "  [0.96547526]\n",
      "  [0.96549666]\n",
      "  [0.9655742 ]\n",
      "  [0.96447545]\n",
      "  [0.96333939]\n",
      "  [0.9628132 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01275115180760622\n",
      "Predicción post entrenamiento : [[0.9620293]]\n",
      "PERDIDAAAA despues: 0.012799186632037163\n",
      "loss en el callback: 0.0029924374539405107, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.96568292]\n",
      " [0.96547526]\n",
      " [0.96549666]\n",
      " [0.9655742 ]\n",
      " [0.96447545]\n",
      " [0.96333939]\n",
      " [0.9628132 ]\n",
      " [0.96181679]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.96204585]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.96568292]\n",
      "  [0.96547526]\n",
      "  [0.96549666]\n",
      "  [0.9655742 ]\n",
      "  [0.96447545]\n",
      "  [0.96333939]\n",
      "  [0.9628132 ]\n",
      "  [0.96181679]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3824548261709424e-07\n",
      "Predicción post entrenamiento : [[0.96097046]]\n",
      "PERDIDAAAA despues: 2.0943900835845852e-06\n",
      "loss en el callback: 0.043625328689813614, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.96547526]\n",
      " [0.96549666]\n",
      " [0.9655742 ]\n",
      " [0.96447545]\n",
      " [0.96333939]\n",
      " [0.9628132 ]\n",
      " [0.96181679]\n",
      " [0.96204585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.96066284]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.96547526]\n",
      "  [0.96549666]\n",
      "  [0.9655742 ]\n",
      "  [0.96447545]\n",
      "  [0.96333939]\n",
      "  [0.9628132 ]\n",
      "  [0.96181679]\n",
      "  [0.96204585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.1539209380280226e-05\n",
      "Predicción post entrenamiento : [[0.96091366]]\n",
      "PERDIDAAAA despues: 4.800085662282072e-05\n",
      "loss en el callback: 0.003977892454713583, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.96549666]\n",
      " [0.9655742 ]\n",
      " [0.96447545]\n",
      " [0.96333939]\n",
      " [0.9628132 ]\n",
      " [0.96181679]\n",
      " [0.96204585]\n",
      " [0.96066284]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.96051687]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.96549666]\n",
      "  [0.9655742 ]\n",
      "  [0.96447545]\n",
      "  [0.96333939]\n",
      "  [0.9628132 ]\n",
      "  [0.96181679]\n",
      "  [0.96204585]\n",
      "  [0.96066284]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039188924711197615\n",
      "Predicción post entrenamiento : [[0.9603115]]\n",
      "PERDIDAAAA despues: 0.0003837992553599179\n",
      "loss en el callback: 0.0021121306344866753, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.9655742 ]\n",
      " [0.96447545]\n",
      " [0.96333939]\n",
      " [0.9628132 ]\n",
      " [0.96181679]\n",
      " [0.96204585]\n",
      " [0.96066284]\n",
      " [0.96051687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9597285]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.9655742 ]\n",
      "  [0.96447545]\n",
      "  [0.96333939]\n",
      "  [0.9628132 ]\n",
      "  [0.96181679]\n",
      "  [0.96204585]\n",
      "  [0.96066284]\n",
      "  [0.96051687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001628886820981279\n",
      "Predicción post entrenamiento : [[0.9596518]]\n",
      "PERDIDAAAA despues: 0.000164851124281995\n",
      "loss en el callback: 0.0003183942171745002, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.96447545]\n",
      " [0.96333939]\n",
      " [0.9628132 ]\n",
      " [0.96181679]\n",
      " [0.96204585]\n",
      " [0.96066284]\n",
      " [0.96051687]\n",
      " [0.95972848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9588351]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.96447545]\n",
      "  [0.96333939]\n",
      "  [0.9628132 ]\n",
      "  [0.96181679]\n",
      "  [0.96204585]\n",
      "  [0.96066284]\n",
      "  [0.96051687]\n",
      "  [0.95972848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001448968192562461\n",
      "Predicción post entrenamiento : [[0.95892924]]\n",
      "PERDIDAAAA despues: 0.0014418119098991156\n",
      "loss en el callback: 0.0004542215901892632, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.96333939]\n",
      " [0.9628132 ]\n",
      " [0.96181679]\n",
      " [0.96204585]\n",
      " [0.96066284]\n",
      " [0.96051687]\n",
      " [0.95972848]\n",
      " [0.95883512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9582215]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.96333939]\n",
      "  [0.9628132 ]\n",
      "  [0.96181679]\n",
      "  [0.96204585]\n",
      "  [0.96066284]\n",
      "  [0.96051687]\n",
      "  [0.95972848]\n",
      "  [0.95883512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.955857730237767e-05\n",
      "Predicción post entrenamiento : [[0.9582643]]\n",
      "PERDIDAAAA despues: 5.016296199755743e-05\n",
      "loss en el callback: 0.00011196926061529666, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.9628132 ]\n",
      " [0.96181679]\n",
      " [0.96204585]\n",
      " [0.96066284]\n",
      " [0.96051687]\n",
      " [0.95972848]\n",
      " [0.95883512]\n",
      " [0.9582215 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9576988]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.9628132 ]\n",
      "  [0.96181679]\n",
      "  [0.96204585]\n",
      "  [0.96066284]\n",
      "  [0.96051687]\n",
      "  [0.95972848]\n",
      "  [0.95883512]\n",
      "  [0.9582215 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003834335831925273\n",
      "Predicción post entrenamiento : [[0.957235]]\n",
      "PERDIDAAAA despues: 0.0037771067582070827\n",
      "loss en el callback: 0.011307255364954472, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.96181679]\n",
      " [0.96204585]\n",
      " [0.96066284]\n",
      " [0.96051687]\n",
      " [0.95972848]\n",
      " [0.95883512]\n",
      " [0.9582215 ]\n",
      " [0.95769882]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9566405]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.96181679]\n",
      "  [0.96204585]\n",
      "  [0.96066284]\n",
      "  [0.96051687]\n",
      "  [0.95972848]\n",
      "  [0.95883512]\n",
      "  [0.9582215 ]\n",
      "  [0.95769882]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005654917564243078\n",
      "Predicción post entrenamiento : [[0.9563713]]\n",
      "PERDIDAAAA despues: 0.005614506546407938\n",
      "loss en el callback: 0.004176701884716749, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.96204585]\n",
      " [0.96066284]\n",
      " [0.96051687]\n",
      " [0.95972848]\n",
      " [0.95883512]\n",
      " [0.9582215 ]\n",
      " [0.95769882]\n",
      " [0.95664048]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.95588684]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.96204585]\n",
      "  [0.96066284]\n",
      "  [0.96051687]\n",
      "  [0.95972848]\n",
      "  [0.95883512]\n",
      "  [0.9582215 ]\n",
      "  [0.95769882]\n",
      "  [0.95664048]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015054724644869566\n",
      "Predicción post entrenamiento : [[0.9562389]]\n",
      "PERDIDAAAA despues: 0.0015329185407608747\n",
      "loss en el callback: 0.009136444889008999, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.96066284]\n",
      " [0.96051687]\n",
      " [0.95972848]\n",
      " [0.95883512]\n",
      " [0.9582215 ]\n",
      " [0.95769882]\n",
      " [0.95664048]\n",
      " [0.95588684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9554865]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.96066284]\n",
      "  [0.96051687]\n",
      "  [0.95972848]\n",
      "  [0.95883512]\n",
      "  [0.9582215 ]\n",
      "  [0.95769882]\n",
      "  [0.95664048]\n",
      "  [0.95588684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001273627858608961\n",
      "Predicción post entrenamiento : [[0.95553666]]\n",
      "PERDIDAAAA despues: 0.001277212519198656\n",
      "loss en el callback: 0.00016452069394290447, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.96051687]\n",
      " [0.95972848]\n",
      " [0.95883512]\n",
      " [0.9582215 ]\n",
      " [0.95769882]\n",
      " [0.95664048]\n",
      " [0.95588684]\n",
      " [0.95548648]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.95498425]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.96051687]\n",
      "  [0.95972848]\n",
      "  [0.95883512]\n",
      "  [0.9582215 ]\n",
      "  [0.95769882]\n",
      "  [0.95664048]\n",
      "  [0.95588684]\n",
      "  [0.95548648]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.433634239831008e-05\n",
      "Predicción post entrenamiento : [[0.9551545]]\n",
      "PERDIDAAAA despues: 4.2098337871721014e-05\n",
      "loss en el callback: 0.0018063478637486696, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.95972848]\n",
      " [0.95883512]\n",
      " [0.9582215 ]\n",
      " [0.95769882]\n",
      " [0.95664048]\n",
      " [0.95588684]\n",
      " [0.95548648]\n",
      " [0.95498425]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.95444155]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.95972848]\n",
      "  [0.95883512]\n",
      "  [0.9582215 ]\n",
      "  [0.95769882]\n",
      "  [0.95664048]\n",
      "  [0.95588684]\n",
      "  [0.95548648]\n",
      "  [0.95498425]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019010360119864345\n",
      "Predicción post entrenamiento : [[0.95427406]]\n",
      "PERDIDAAAA despues: 0.00019475026056170464\n",
      "loss en el callback: 0.0014627637574449182, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.95883512]\n",
      " [0.9582215 ]\n",
      " [0.95769882]\n",
      " [0.95664048]\n",
      " [0.95588684]\n",
      " [0.95548648]\n",
      " [0.95498425]\n",
      " [0.95444155]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9535827]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.95883512]\n",
      "  [0.9582215 ]\n",
      "  [0.95769882]\n",
      "  [0.95664048]\n",
      "  [0.95588684]\n",
      "  [0.95548648]\n",
      "  [0.95498425]\n",
      "  [0.95444155]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7519389075459912e-05\n",
      "Predicción post entrenamiento : [[0.9535101]]\n",
      "PERDIDAAAA despues: 1.8132399418391287e-05\n",
      "loss en el callback: 0.0003099992172792554, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21161528]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027393268421292305\n",
      "Predicción post entrenamiento : [[0.18494105]]\n",
      "PERDIDAAAA despues: 0.019275126978754997\n",
      "loss en el callback: 0.02915119379758835, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21161528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16907799]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21161528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004206147976219654\n",
      "Predicción post entrenamiento : [[0.16195783]]\n",
      "PERDIDAAAA despues: 0.0033332910388708115\n",
      "loss en el callback: 0.0025472796987742186, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21161528]\n",
      " [0.16907799]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1655398]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21161528]\n",
      "  [0.16907799]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012850486382376403\n",
      "Predicción post entrenamiento : [[0.16070372]]\n",
      "PERDIDAAAA despues: 4.224891381454654e-05\n",
      "loss en el callback: 0.0017466925783082843, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21161528]\n",
      " [0.16907799]\n",
      " [0.1655398 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1712942]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21161528]\n",
      "  [0.16907799]\n",
      "  [0.1655398 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024151070101652294\n",
      "Predicción post entrenamiento : [[0.16855192]]\n",
      "PERDIDAAAA despues: 0.00016379747830796987\n",
      "loss en el callback: 0.0010926049435511231, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21161528]\n",
      " [0.16907799]\n",
      " [0.1655398 ]\n",
      " [0.1712942 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17981866]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21161528]\n",
      "  [0.16907799]\n",
      "  [0.1655398 ]\n",
      "  [0.1712942 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029469605069607496\n",
      "Predicción post entrenamiento : [[0.17741643]]\n",
      "PERDIDAAAA despues: 0.002691916422918439\n",
      "loss en el callback: 0.0016318552661687136, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21161528]\n",
      " [0.16907799]\n",
      " [0.1655398 ]\n",
      " [0.1712942 ]\n",
      " [0.17981866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18535358]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21161528]\n",
      "  [0.16907799]\n",
      "  [0.1655398 ]\n",
      "  [0.1712942 ]\n",
      "  [0.17981866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001573995454236865\n",
      "Predicción post entrenamiento : [[0.1837151]]\n",
      "PERDIDAAAA despues: 0.0014466717839241028\n",
      "loss en el callback: 0.0011325619416311383, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21161528]\n",
      " [0.16907799]\n",
      " [0.1655398 ]\n",
      " [0.1712942 ]\n",
      " [0.17981866]\n",
      " [0.18535358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20208745]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21161528]\n",
      "  [0.16907799]\n",
      "  [0.1655398 ]\n",
      "  [0.1712942 ]\n",
      "  [0.17981866]\n",
      "  [0.18535358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030949851498007774\n",
      "Predicción post entrenamiento : [[0.19848274]]\n",
      "PERDIDAAAA despues: 0.0027069004718214273\n",
      "loss en el callback: 0.0054363468661904335, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.21161528]\n",
      " [0.16907799]\n",
      " [0.1655398 ]\n",
      " [0.1712942 ]\n",
      " [0.17981866]\n",
      " [0.18535358]\n",
      " [0.20208745]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.2206729]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.21161528]\n",
      "  [0.16907799]\n",
      "  [0.1655398 ]\n",
      "  [0.1712942 ]\n",
      "  [0.17981866]\n",
      "  [0.18535358]\n",
      "  [0.20208745]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000606384186539799\n",
      "Predicción post entrenamiento : [[0.21977346]]\n",
      "PERDIDAAAA despues: 0.000562895555049181\n",
      "loss en el callback: 0.0005026799626648426, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21161528]\n",
      " [0.16907799]\n",
      " [0.1655398 ]\n",
      " [0.1712942 ]\n",
      " [0.17981866]\n",
      " [0.18535358]\n",
      " [0.20208745]\n",
      " [0.22067291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24616055]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21161528]\n",
      "  [0.16907799]\n",
      "  [0.1655398 ]\n",
      "  [0.1712942 ]\n",
      "  [0.17981866]\n",
      "  [0.18535358]\n",
      "  [0.20208745]\n",
      "  [0.22067291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002442892000544816\n",
      "Predicción post entrenamiento : [[0.24506897]]\n",
      "PERDIDAAAA despues: 0.00021135836141183972\n",
      "loss en el callback: 0.000760725059080869, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16907799]\n",
      " [0.1655398 ]\n",
      " [0.1712942 ]\n",
      " [0.17981866]\n",
      " [0.18535358]\n",
      " [0.20208745]\n",
      " [0.22067291]\n",
      " [0.24616055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23909403]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16907799]\n",
      "  [0.1655398 ]\n",
      "  [0.1712942 ]\n",
      "  [0.17981866]\n",
      "  [0.18535358]\n",
      "  [0.20208745]\n",
      "  [0.22067291]\n",
      "  [0.24616055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009392811916768551\n",
      "Predicción post entrenamiento : [[0.23751642]]\n",
      "PERDIDAAAA despues: 0.0008450695313513279\n",
      "loss en el callback: 0.0020975377410650253, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.1655398 ]\n",
      " [0.1712942 ]\n",
      " [0.17981866]\n",
      " [0.18535358]\n",
      " [0.20208745]\n",
      " [0.22067291]\n",
      " [0.24616055]\n",
      " [0.23909403]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24113262]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.1655398 ]\n",
      "  [0.1712942 ]\n",
      "  [0.17981866]\n",
      "  [0.18535358]\n",
      "  [0.20208745]\n",
      "  [0.22067291]\n",
      "  [0.24616055]\n",
      "  [0.23909403]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008525966550223529\n",
      "Predicción post entrenamiento : [[0.23980518]]\n",
      "PERDIDAAAA despues: 0.0007768382201902568\n",
      "loss en el callback: 0.0018261856166645885, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.1712942 ]\n",
      " [0.17981866]\n",
      " [0.18535358]\n",
      " [0.20208745]\n",
      " [0.22067291]\n",
      " [0.24616055]\n",
      " [0.23909403]\n",
      " [0.24113262]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24614063]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.1712942 ]\n",
      "  [0.17981866]\n",
      "  [0.18535358]\n",
      "  [0.20208745]\n",
      "  [0.22067291]\n",
      "  [0.24616055]\n",
      "  [0.23909403]\n",
      "  [0.24113262]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015098373405635357\n",
      "Predicción post entrenamiento : [[0.24419016]]\n",
      "PERDIDAAAA despues: 0.001362064154818654\n",
      "loss en el callback: 0.004182389471679926, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17981866]\n",
      " [0.18535358]\n",
      " [0.20208745]\n",
      " [0.22067291]\n",
      " [0.24616055]\n",
      " [0.23909403]\n",
      " [0.24113262]\n",
      " [0.24614063]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25162488]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17981866]\n",
      "  [0.18535358]\n",
      "  [0.20208745]\n",
      "  [0.22067291]\n",
      "  [0.24616055]\n",
      "  [0.23909403]\n",
      "  [0.24113262]\n",
      "  [0.24614063]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003442920744419098\n",
      "Predicción post entrenamiento : [[0.25077182]]\n",
      "PERDIDAAAA despues: 0.00334353931248188\n",
      "loss en el callback: 0.001232922193594277, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18535358]\n",
      " [0.20208745]\n",
      " [0.22067291]\n",
      " [0.24616055]\n",
      " [0.23909403]\n",
      " [0.24113262]\n",
      " [0.24614063]\n",
      " [0.25162488]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.25875401]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18535358]\n",
      "  [0.20208745]\n",
      "  [0.22067291]\n",
      "  [0.24616055]\n",
      "  [0.23909403]\n",
      "  [0.24113262]\n",
      "  [0.24614063]\n",
      "  [0.25162488]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003835457842797041\n",
      "Predicción post entrenamiento : [[0.25709817]]\n",
      "PERDIDAAAA despues: 0.0036331028677523136\n",
      "loss en el callback: 0.004767402540892363, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20208745]\n",
      " [0.22067291]\n",
      " [0.24616055]\n",
      " [0.23909403]\n",
      " [0.24113262]\n",
      " [0.24614063]\n",
      " [0.25162488]\n",
      " [0.25875401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2662222]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20208745]\n",
      "  [0.22067291]\n",
      "  [0.24616055]\n",
      "  [0.23909403]\n",
      "  [0.24113262]\n",
      "  [0.24614063]\n",
      "  [0.25162488]\n",
      "  [0.25875401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002700274344533682\n",
      "Predicción post entrenamiento : [[0.26476657]]\n",
      "PERDIDAAAA despues: 0.0025511113926768303\n",
      "loss en el callback: 0.003966506104916334, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22067291]\n",
      " [0.24616055]\n",
      " [0.23909403]\n",
      " [0.24113262]\n",
      " [0.24614063]\n",
      " [0.25162488]\n",
      " [0.25875401]\n",
      " [0.26622221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27242804]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22067291]\n",
      "  [0.24616055]\n",
      "  [0.23909403]\n",
      "  [0.24113262]\n",
      "  [0.24614063]\n",
      "  [0.25162488]\n",
      "  [0.25875401]\n",
      "  [0.26622221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008299751207232475\n",
      "Predicción post entrenamiento : [[0.27019763]]\n",
      "PERDIDAAAA despues: 0.007898333482444286\n",
      "loss en el callback: 0.010043691843748093, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24616055]\n",
      " [0.23909403]\n",
      " [0.24113262]\n",
      " [0.24614063]\n",
      " [0.25162488]\n",
      " [0.25875401]\n",
      " [0.26622221]\n",
      " [0.27242804]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.27550405]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24616055]\n",
      "  [0.23909403]\n",
      "  [0.24113262]\n",
      "  [0.24614063]\n",
      "  [0.25162488]\n",
      "  [0.25875401]\n",
      "  [0.26622221]\n",
      "  [0.27242804]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010075768455862999\n",
      "Predicción post entrenamiento : [[0.27311966]]\n",
      "PERDIDAAAA despues: 0.009602771140635014\n",
      "loss en el callback: 0.01247768197208643, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.23909403]\n",
      " [0.24113262]\n",
      " [0.24614063]\n",
      " [0.25162488]\n",
      " [0.25875401]\n",
      " [0.26622221]\n",
      " [0.27242804]\n",
      " [0.27550405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.27396464]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.23909403]\n",
      "  [0.24113262]\n",
      "  [0.24614063]\n",
      "  [0.25162488]\n",
      "  [0.25875401]\n",
      "  [0.26622221]\n",
      "  [0.27242804]\n",
      "  [0.27550405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01586592011153698\n",
      "Predicción post entrenamiento : [[0.27177042]]\n",
      "PERDIDAAAA despues: 0.015317965298891068\n",
      "loss en el callback: 0.013668403960764408, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24113262]\n",
      " [0.24614063]\n",
      " [0.25162488]\n",
      " [0.25875401]\n",
      " [0.26622221]\n",
      " [0.27242804]\n",
      " [0.27550405]\n",
      " [0.27396464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.27501148]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24113262]\n",
      "  [0.24614063]\n",
      "  [0.25162488]\n",
      "  [0.25875401]\n",
      "  [0.26622221]\n",
      "  [0.27242804]\n",
      "  [0.27550405]\n",
      "  [0.27396464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013492755591869354\n",
      "Predicción post entrenamiento : [[0.27287734]]\n",
      "PERDIDAAAA despues: 0.013001512736082077\n",
      "loss en el callback: 0.01489896047860384, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.24614063]\n",
      " [0.25162488]\n",
      " [0.25875401]\n",
      " [0.26622221]\n",
      " [0.27242804]\n",
      " [0.27550405]\n",
      " [0.27396464]\n",
      " [0.27501148]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.27678466]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.24614063]\n",
      "  [0.25162488]\n",
      "  [0.25875401]\n",
      "  [0.26622221]\n",
      "  [0.27242804]\n",
      "  [0.27550405]\n",
      "  [0.27396464]\n",
      "  [0.27501148]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007159036118537188\n",
      "Predicción post entrenamiento : [[0.27502984]]\n",
      "PERDIDAAAA despues: 0.006865161005407572\n",
      "loss en el callback: 0.00905731599777937, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25162488]\n",
      " [0.25875401]\n",
      " [0.26622221]\n",
      " [0.27242804]\n",
      " [0.27550405]\n",
      " [0.27396464]\n",
      " [0.27501148]\n",
      " [0.27678466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.27893576]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25162488]\n",
      "  [0.25875401]\n",
      "  [0.26622221]\n",
      "  [0.27242804]\n",
      "  [0.27550405]\n",
      "  [0.27396464]\n",
      "  [0.27501148]\n",
      "  [0.27678466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008641808293759823\n",
      "Predicción post entrenamiento : [[0.27752936]]\n",
      "PERDIDAAAA despues: 0.008382304571568966\n",
      "loss en el callback: 0.007009759079664946, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.25875401]\n",
      " [0.26622221]\n",
      " [0.27242804]\n",
      " [0.27550405]\n",
      " [0.27396464]\n",
      " [0.27501148]\n",
      " [0.27678466]\n",
      " [0.27893576]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.28120974]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.25875401]\n",
      "  [0.26622221]\n",
      "  [0.27242804]\n",
      "  [0.27550405]\n",
      "  [0.27396464]\n",
      "  [0.27501148]\n",
      "  [0.27678466]\n",
      "  [0.27893576]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002033176861004904\n",
      "Predicción post entrenamiento : [[0.28138524]]\n",
      "PERDIDAAAA despues: 0.00020835355098824948\n",
      "loss en el callback: 0.00013153058534953743, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.26622221]\n",
      " [0.27242804]\n",
      " [0.27550405]\n",
      " [0.27396464]\n",
      " [0.27501148]\n",
      " [0.27678466]\n",
      " [0.27893576]\n",
      " [0.28120974]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2843086]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.26622221]\n",
      "  [0.27242804]\n",
      "  [0.27550405]\n",
      "  [0.27396464]\n",
      "  [0.27501148]\n",
      "  [0.27678466]\n",
      "  [0.27893576]\n",
      "  [0.28120974]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.74643597449176e-05\n",
      "Predicción post entrenamiento : [[0.28481323]]\n",
      "PERDIDAAAA despues: 5.9429545217426494e-05\n",
      "loss en el callback: 0.0011756069725379348, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27242804]\n",
      " [0.27550405]\n",
      " [0.27396464]\n",
      " [0.27501148]\n",
      " [0.27678466]\n",
      " [0.27893576]\n",
      " [0.28120974]\n",
      " [0.28430861]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.2866932]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27242804]\n",
      "  [0.27550405]\n",
      "  [0.27396464]\n",
      "  [0.27501148]\n",
      "  [0.27678466]\n",
      "  [0.27893576]\n",
      "  [0.28120974]\n",
      "  [0.28430861]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009618143085390329\n",
      "Predicción post entrenamiento : [[0.287008]]\n",
      "PERDIDAAAA despues: 0.0009423874435015023\n",
      "loss en el callback: 0.0004149298765696585, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.27550405]\n",
      " [0.27396464]\n",
      " [0.27501148]\n",
      " [0.27678466]\n",
      " [0.27893576]\n",
      " [0.28120974]\n",
      " [0.28430861]\n",
      " [0.28669319]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.28793857]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.27550405]\n",
      "  [0.27396464]\n",
      "  [0.27501148]\n",
      "  [0.27678466]\n",
      "  [0.27893576]\n",
      "  [0.28120974]\n",
      "  [0.28430861]\n",
      "  [0.28669319]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006116199074313045\n",
      "Predicción post entrenamiento : [[0.2879328]]\n",
      "PERDIDAAAA despues: 0.0006119044264778495\n",
      "loss en el callback: 1.442486450287106e-07, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27396464]\n",
      " [0.27501148]\n",
      " [0.27678466]\n",
      " [0.27893576]\n",
      " [0.28120974]\n",
      " [0.28430861]\n",
      " [0.28669319]\n",
      " [0.28793857]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.28850907]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27396464]\n",
      "  [0.27501148]\n",
      "  [0.27678466]\n",
      "  [0.27893576]\n",
      "  [0.28120974]\n",
      "  [0.28430861]\n",
      "  [0.28669319]\n",
      "  [0.28793857]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.7687570991474786e-07\n",
      "Predicción post entrenamiento : [[0.2884035]]\n",
      "PERDIDAAAA despues: 3.991075914200337e-07\n",
      "loss en el callback: 5.8263154642190784e-05, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.27501148]\n",
      " [0.27678466]\n",
      " [0.27893576]\n",
      " [0.28120974]\n",
      " [0.28430861]\n",
      " [0.28669319]\n",
      " [0.28793857]\n",
      " [0.28850907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.28968292]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.27501148]\n",
      "  [0.27678466]\n",
      "  [0.27893576]\n",
      "  [0.28120974]\n",
      "  [0.28430861]\n",
      "  [0.28669319]\n",
      "  [0.28793857]\n",
      "  [0.28850907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.687888213084079e-05\n",
      "Predicción post entrenamiento : [[0.29026332]]\n",
      "PERDIDAAAA despues: 5.516353121493012e-05\n",
      "loss en el callback: 0.0027174886781722307, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.27678466]\n",
      " [0.27893576]\n",
      " [0.28120974]\n",
      " [0.28430861]\n",
      " [0.28669319]\n",
      " [0.28793857]\n",
      " [0.28850907]\n",
      " [0.28968292]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.291754]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.27678466]\n",
      "  [0.27893576]\n",
      "  [0.28120974]\n",
      "  [0.28430861]\n",
      "  [0.28669319]\n",
      "  [0.28793857]\n",
      "  [0.28850907]\n",
      "  [0.28968292]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.9943449741695076e-05\n",
      "Predicción post entrenamiento : [[0.29190284]]\n",
      "PERDIDAAAA despues: 5.766097820014693e-05\n",
      "loss en el callback: 0.00013672278146259487, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.27893576]\n",
      " [0.28120974]\n",
      " [0.28430861]\n",
      " [0.28669319]\n",
      " [0.28793857]\n",
      " [0.28850907]\n",
      " [0.28968292]\n",
      " [0.29175401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.29345274]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.27893576]\n",
      "  [0.28120974]\n",
      "  [0.28430861]\n",
      "  [0.28669319]\n",
      "  [0.28793857]\n",
      "  [0.28850907]\n",
      "  [0.28968292]\n",
      "  [0.29175401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030943172168917954\n",
      "Predicción post entrenamiento : [[0.29279798]]\n",
      "PERDIDAAAA despues: 0.0002868252049665898\n",
      "loss en el callback: 0.0024683980736881495, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28120974]\n",
      " [0.28430861]\n",
      " [0.28669319]\n",
      " [0.28793857]\n",
      " [0.28850907]\n",
      " [0.28968292]\n",
      " [0.29175401]\n",
      " [0.29345274]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.29430625]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28120974]\n",
      "  [0.28430861]\n",
      "  [0.28669319]\n",
      "  [0.28793857]\n",
      "  [0.28850907]\n",
      "  [0.28968292]\n",
      "  [0.29175401]\n",
      "  [0.29345274]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00038441605283878744\n",
      "Predicción post entrenamiento : [[0.29366502]]\n",
      "PERDIDAAAA despues: 0.00035968274460174143\n",
      "loss en el callback: 0.0023768777027726173, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.28430861]\n",
      " [0.28669319]\n",
      " [0.28793857]\n",
      " [0.28850907]\n",
      " [0.28968292]\n",
      " [0.29175401]\n",
      " [0.29345274]\n",
      " [0.29430625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.2950732]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.28430861]\n",
      "  [0.28669319]\n",
      "  [0.28793857]\n",
      "  [0.28850907]\n",
      "  [0.28968292]\n",
      "  [0.29175401]\n",
      "  [0.29345274]\n",
      "  [0.29430625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00038410525303334\n",
      "Predicción post entrenamiento : [[0.29451507]]\n",
      "PERDIDAAAA despues: 0.0003625393146649003\n",
      "loss en el callback: 0.001956233521923423, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.28669319]\n",
      " [0.28793857]\n",
      " [0.28850907]\n",
      " [0.28968292]\n",
      " [0.29175401]\n",
      " [0.29345274]\n",
      " [0.29430625]\n",
      " [0.29507321]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2955888]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.28669319]\n",
      "  [0.28793857]\n",
      "  [0.28850907]\n",
      "  [0.28968292]\n",
      "  [0.29175401]\n",
      "  [0.29345274]\n",
      "  [0.29430625]\n",
      "  [0.29507321]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001533910515718162\n",
      "Predicción post entrenamiento : [[0.2961987]]\n",
      "PERDIDAAAA despues: 0.001486508408561349\n",
      "loss en el callback: 0.0030795885249972343, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.28793857]\n",
      " [0.28850907]\n",
      " [0.28968292]\n",
      " [0.29175401]\n",
      " [0.29345274]\n",
      " [0.29430625]\n",
      " [0.29507321]\n",
      " [0.29558879]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.29703736]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.28793857]\n",
      "  [0.28850907]\n",
      "  [0.28968292]\n",
      "  [0.29175401]\n",
      "  [0.29345274]\n",
      "  [0.29430625]\n",
      "  [0.29507321]\n",
      "  [0.29558879]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034384997561573982\n",
      "Predicción post entrenamiento : [[0.29793373]]\n",
      "PERDIDAAAA despues: 0.0033341797534376383\n",
      "loss en el callback: 0.008481025695800781, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28850907]\n",
      " [0.28968292]\n",
      " [0.29175401]\n",
      " [0.29345274]\n",
      " [0.29430625]\n",
      " [0.29507321]\n",
      " [0.29558879]\n",
      " [0.29703736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.29876304]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28850907]\n",
      "  [0.28968292]\n",
      "  [0.29175401]\n",
      "  [0.29345274]\n",
      "  [0.29430625]\n",
      "  [0.29507321]\n",
      "  [0.29558879]\n",
      "  [0.29703736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014385456452146173\n",
      "Predicción post entrenamiento : [[0.29904932]]\n",
      "PERDIDAAAA despues: 0.0014169113710522652\n",
      "loss en el callback: 0.0006314047495834529, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28968292]\n",
      " [0.29175401]\n",
      " [0.29345274]\n",
      " [0.29430625]\n",
      " [0.29507321]\n",
      " [0.29558879]\n",
      " [0.29703736]\n",
      " [0.29876304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3000266]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28968292]\n",
      "  [0.29175401]\n",
      "  [0.29345274]\n",
      "  [0.29430625]\n",
      "  [0.29507321]\n",
      "  [0.29558879]\n",
      "  [0.29703736]\n",
      "  [0.29876304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011266121873632073\n",
      "Predicción post entrenamiento : [[0.30034086]]\n",
      "PERDIDAAAA despues: 0.001105614355765283\n",
      "loss en el callback: 0.0008912399644032121, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.29175401]\n",
      " [0.29345274]\n",
      " [0.29430625]\n",
      " [0.29507321]\n",
      " [0.29558879]\n",
      " [0.29703736]\n",
      " [0.29876304]\n",
      " [0.3000266 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3013423]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.29175401]\n",
      "  [0.29345274]\n",
      "  [0.29430625]\n",
      "  [0.29507321]\n",
      "  [0.29558879]\n",
      "  [0.29703736]\n",
      "  [0.29876304]\n",
      "  [0.3000266 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006954274605959654\n",
      "Predicción post entrenamiento : [[0.3013335]]\n",
      "PERDIDAAAA despues: 0.006955745629966259\n",
      "loss en el callback: 5.105680997985473e-07, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.29345274]\n",
      " [0.29430625]\n",
      " [0.29507321]\n",
      " [0.29558879]\n",
      " [0.29703736]\n",
      " [0.29876304]\n",
      " [0.3000266 ]\n",
      " [0.30134231]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.30214483]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.29345274]\n",
      "  [0.29430625]\n",
      "  [0.29507321]\n",
      "  [0.29558879]\n",
      "  [0.29703736]\n",
      "  [0.29876304]\n",
      "  [0.3000266 ]\n",
      "  [0.30134231]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07233498990535736\n",
      "Predicción post entrenamiento : [[0.30483308]]\n",
      "PERDIDAAAA despues: 0.0708961933851242\n",
      "loss en el callback: 0.08164457976818085, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.29430625]\n",
      " [0.29507321]\n",
      " [0.29558879]\n",
      " [0.29703736]\n",
      " [0.29876304]\n",
      " [0.3000266 ]\n",
      " [0.30134231]\n",
      " [0.30214483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.30551374]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.29430625]\n",
      "  [0.29507321]\n",
      "  [0.29558879]\n",
      "  [0.29703736]\n",
      "  [0.29876304]\n",
      "  [0.3000266 ]\n",
      "  [0.30134231]\n",
      "  [0.30214483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0845453143119812\n",
      "Predicción post entrenamiento : [[0.30828798]]\n",
      "PERDIDAAAA despues: 0.08293969929218292\n",
      "loss en el callback: 0.07872626185417175, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.29507321]\n",
      " [0.29558879]\n",
      " [0.29703736]\n",
      " [0.29876304]\n",
      " [0.3000266 ]\n",
      " [0.30134231]\n",
      " [0.30214483]\n",
      " [0.30551374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.30903482]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.29507321]\n",
      "  [0.29558879]\n",
      "  [0.29703736]\n",
      "  [0.29876304]\n",
      "  [0.3000266 ]\n",
      "  [0.30134231]\n",
      "  [0.30214483]\n",
      "  [0.30551374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07051608711481094\n",
      "Predicción post entrenamiento : [[0.31166464]]\n",
      "PERDIDAAAA despues: 0.06912630796432495\n",
      "loss en el callback: 0.08117367327213287, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29558879]\n",
      " [0.29703736]\n",
      " [0.29876304]\n",
      " [0.3000266 ]\n",
      " [0.30134231]\n",
      " [0.30214483]\n",
      " [0.30551374]\n",
      " [0.30903482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.31253842]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29558879]\n",
      "  [0.29703736]\n",
      "  [0.29876304]\n",
      "  [0.3000266 ]\n",
      "  [0.30134231]\n",
      "  [0.30214483]\n",
      "  [0.30551374]\n",
      "  [0.30903482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08632766455411911\n",
      "Predicción post entrenamiento : [[0.3152882]]\n",
      "PERDIDAAAA despues: 0.08471937477588654\n",
      "loss en el callback: 0.1362934112548828, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29703736]\n",
      " [0.29876304]\n",
      " [0.3000266 ]\n",
      " [0.30134231]\n",
      " [0.30214483]\n",
      " [0.30551374]\n",
      " [0.30903482]\n",
      " [0.31253842]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.31640947]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29703736]\n",
      "  [0.29876304]\n",
      "  [0.3000266 ]\n",
      "  [0.30134231]\n",
      "  [0.30214483]\n",
      "  [0.30551374]\n",
      "  [0.30903482]\n",
      "  [0.31253842]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0719568058848381\n",
      "Predicción post entrenamiento : [[0.3188586]]\n",
      "PERDIDAAAA despues: 0.07064886391162872\n",
      "loss en el callback: 0.09348523616790771, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29876304]\n",
      " [0.3000266 ]\n",
      " [0.30134231]\n",
      " [0.30214483]\n",
      " [0.30551374]\n",
      " [0.30903482]\n",
      " [0.31253842]\n",
      " [0.31640947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32008728]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29876304]\n",
      "  [0.3000266 ]\n",
      "  [0.30134231]\n",
      "  [0.30214483]\n",
      "  [0.30551374]\n",
      "  [0.30903482]\n",
      "  [0.31253842]\n",
      "  [0.31640947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061843980103731155\n",
      "Predicción post entrenamiento : [[0.3223248]]\n",
      "PERDIDAAAA despues: 0.06073610857129097\n",
      "loss en el callback: 0.0791606679558754, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.3000266 ]\n",
      " [0.30134231]\n",
      " [0.30214483]\n",
      " [0.30551374]\n",
      " [0.30903482]\n",
      " [0.31253842]\n",
      " [0.31640947]\n",
      " [0.32008728]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32366085]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.3000266 ]\n",
      "  [0.30134231]\n",
      "  [0.30214483]\n",
      "  [0.30551374]\n",
      "  [0.30903482]\n",
      "  [0.31253842]\n",
      "  [0.31640947]\n",
      "  [0.32008728]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1018332690000534\n",
      "Predicción post entrenamiento : [[0.32654375]]\n",
      "PERDIDAAAA despues: 0.10000164061784744\n",
      "loss en el callback: 0.10032062232494354, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.30134231]\n",
      " [0.30214483]\n",
      " [0.30551374]\n",
      " [0.30903482]\n",
      " [0.31253842]\n",
      " [0.31640947]\n",
      " [0.32008728]\n",
      " [0.32366085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32816902]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.30134231]\n",
      "  [0.30214483]\n",
      "  [0.30551374]\n",
      "  [0.30903482]\n",
      "  [0.31253842]\n",
      "  [0.31640947]\n",
      "  [0.32008728]\n",
      "  [0.32366085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11128228902816772\n",
      "Predicción post entrenamiento : [[0.33094767]]\n",
      "PERDIDAAAA despues: 0.10943614691495895\n",
      "loss en el callback: 0.11801581084728241, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30214483]\n",
      " [0.30551374]\n",
      " [0.30903482]\n",
      " [0.31253842]\n",
      " [0.31640947]\n",
      " [0.32008728]\n",
      " [0.32366085]\n",
      " [0.32816902]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33294657]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30214483]\n",
      "  [0.30551374]\n",
      "  [0.30903482]\n",
      "  [0.31253842]\n",
      "  [0.31640947]\n",
      "  [0.32008728]\n",
      "  [0.32366085]\n",
      "  [0.32816902]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11563291400671005\n",
      "Predicción post entrenamiento : [[0.335834]]\n",
      "PERDIDAAAA despues: 0.11367752403020859\n",
      "loss en el callback: 0.13197053968906403, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30551374]\n",
      " [0.30903482]\n",
      " [0.31253842]\n",
      " [0.31640947]\n",
      " [0.32008728]\n",
      " [0.32366085]\n",
      " [0.32816902]\n",
      " [0.33294657]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.33843654]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30551374]\n",
      "  [0.30903482]\n",
      "  [0.31253842]\n",
      "  [0.31640947]\n",
      "  [0.32008728]\n",
      "  [0.32366085]\n",
      "  [0.32816902]\n",
      "  [0.33294657]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1384887546300888\n",
      "Predicción post entrenamiento : [[0.34144655]]\n",
      "PERDIDAAAA despues: 0.13625751435756683\n",
      "loss en el callback: 0.19621799886226654, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30903482]\n",
      " [0.31253842]\n",
      " [0.31640947]\n",
      " [0.32008728]\n",
      " [0.32366085]\n",
      " [0.32816902]\n",
      " [0.33294657]\n",
      " [0.33843654]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3441554]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30903482]\n",
      "  [0.31253842]\n",
      "  [0.31640947]\n",
      "  [0.32008728]\n",
      "  [0.32366085]\n",
      "  [0.32816902]\n",
      "  [0.33294657]\n",
      "  [0.33843654]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12948143482208252\n",
      "Predicción post entrenamiento : [[0.34694877]]\n",
      "PERDIDAAAA despues: 0.1274789422750473\n",
      "loss en el callback: 0.11021243780851364, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31253842]\n",
      " [0.31640947]\n",
      " [0.32008728]\n",
      " [0.32366085]\n",
      " [0.32816902]\n",
      " [0.33294657]\n",
      " [0.33843654]\n",
      " [0.3441554 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34977645]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31253842]\n",
      "  [0.31640947]\n",
      "  [0.32008728]\n",
      "  [0.32366085]\n",
      "  [0.32816902]\n",
      "  [0.33294657]\n",
      "  [0.33843654]\n",
      "  [0.3441554 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1424768567085266\n",
      "Predicción post entrenamiento : [[0.35258138]]\n",
      "PERDIDAAAA despues: 0.14036722481250763\n",
      "loss en el callback: 0.09271149337291718, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31640947]\n",
      " [0.32008728]\n",
      " [0.32366085]\n",
      " [0.32816902]\n",
      " [0.33294657]\n",
      " [0.33843654]\n",
      " [0.3441554 ]\n",
      " [0.34977645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3555904]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31640947]\n",
      "  [0.32008728]\n",
      "  [0.32366085]\n",
      "  [0.32816902]\n",
      "  [0.33294657]\n",
      "  [0.33843654]\n",
      "  [0.3441554 ]\n",
      "  [0.34977645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13468731939792633\n",
      "Predicción post entrenamiento : [[0.3585416]]\n",
      "PERDIDAAAA despues: 0.1325298696756363\n",
      "loss en el callback: 0.1603216677904129, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32008728]\n",
      " [0.32366085]\n",
      " [0.32816902]\n",
      " [0.33294657]\n",
      " [0.33843654]\n",
      " [0.3441554 ]\n",
      " [0.34977645]\n",
      " [0.3555904 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36171246]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32008728]\n",
      "  [0.32366085]\n",
      "  [0.32816902]\n",
      "  [0.33294657]\n",
      "  [0.33843654]\n",
      "  [0.3441554 ]\n",
      "  [0.34977645]\n",
      "  [0.3555904 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16816678643226624\n",
      "Predicción post entrenamiento : [[0.36485118]]\n",
      "PERDIDAAAA despues: 0.16560238599777222\n",
      "loss en el callback: 0.14060670137405396, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32366085]\n",
      " [0.32816902]\n",
      " [0.33294657]\n",
      " [0.33843654]\n",
      " [0.3441554 ]\n",
      " [0.34977645]\n",
      " [0.3555904 ]\n",
      " [0.36171246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36830252]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32366085]\n",
      "  [0.32816902]\n",
      "  [0.33294657]\n",
      "  [0.33843654]\n",
      "  [0.3441554 ]\n",
      "  [0.34977645]\n",
      "  [0.3555904 ]\n",
      "  [0.36171246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1268947273492813\n",
      "Predicción post entrenamiento : [[0.37095445]]\n",
      "PERDIDAAAA despues: 0.12501241266727448\n",
      "loss en el callback: 0.12682503461837769, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32816902]\n",
      " [0.33294657]\n",
      " [0.33843654]\n",
      " [0.3441554 ]\n",
      " [0.34977645]\n",
      " [0.3555904 ]\n",
      " [0.36171246]\n",
      " [0.36830252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37479946]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32816902]\n",
      "  [0.33294657]\n",
      "  [0.33843654]\n",
      "  [0.3441554 ]\n",
      "  [0.34977645]\n",
      "  [0.3555904 ]\n",
      "  [0.36171246]\n",
      "  [0.36830252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08776894211769104\n",
      "Predicción post entrenamiento : [[0.3769289]]\n",
      "PERDIDAAAA despues: 0.0865117534995079\n",
      "loss en el callback: 0.0828857272863388, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33294657]\n",
      " [0.33843654]\n",
      " [0.3441554 ]\n",
      " [0.34977645]\n",
      " [0.3555904 ]\n",
      " [0.36171246]\n",
      " [0.36830252]\n",
      " [0.37479946]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38103026]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33294657]\n",
      "  [0.33843654]\n",
      "  [0.3441554 ]\n",
      "  [0.34977645]\n",
      "  [0.3555904 ]\n",
      "  [0.36171246]\n",
      "  [0.36830252]\n",
      "  [0.37479946]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08569645881652832\n",
      "Predicción post entrenamiento : [[0.38315883]]\n",
      "PERDIDAAAA despues: 0.08445475250482559\n",
      "loss en el callback: 0.06473392248153687, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33843654]\n",
      " [0.3441554 ]\n",
      " [0.34977645]\n",
      " [0.3555904 ]\n",
      " [0.36171246]\n",
      " [0.36830252]\n",
      " [0.37479946]\n",
      " [0.38103026]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.38751692]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33843654]\n",
      "  [0.3441554 ]\n",
      "  [0.34977645]\n",
      "  [0.3555904 ]\n",
      "  [0.36171246]\n",
      "  [0.36830252]\n",
      "  [0.37479946]\n",
      "  [0.38103026]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10688640922307968\n",
      "Predicción post entrenamiento : [[0.38999292]]\n",
      "PERDIDAAAA despues: 0.10527355968952179\n",
      "loss en el callback: 0.12080495059490204, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.3441554 ]\n",
      " [0.34977645]\n",
      " [0.3555904 ]\n",
      " [0.36171246]\n",
      " [0.36830252]\n",
      " [0.37479946]\n",
      " [0.38103026]\n",
      " [0.38751692]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39448857]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.3441554 ]\n",
      "  [0.34977645]\n",
      "  [0.3555904 ]\n",
      "  [0.36171246]\n",
      "  [0.36830252]\n",
      "  [0.37479946]\n",
      "  [0.38103026]\n",
      "  [0.38751692]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12208676338195801\n",
      "Predicción post entrenamiento : [[0.39685947]]\n",
      "PERDIDAAAA despues: 0.12043555825948715\n",
      "loss en el callback: 0.08634952455759048, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.34977645]\n",
      " [0.3555904 ]\n",
      " [0.36171246]\n",
      " [0.36830252]\n",
      " [0.37479946]\n",
      " [0.38103026]\n",
      " [0.38751692]\n",
      " [0.39448857]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40147355]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.34977645]\n",
      "  [0.3555904 ]\n",
      "  [0.36171246]\n",
      "  [0.36830252]\n",
      "  [0.37479946]\n",
      "  [0.38103026]\n",
      "  [0.38751692]\n",
      "  [0.39448857]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10311456769704819\n",
      "Predicción post entrenamiento : [[0.4037646]]\n",
      "PERDIDAAAA despues: 0.10164843499660492\n",
      "loss en el callback: 0.1055283322930336, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.3555904 ]\n",
      " [0.36171246]\n",
      " [0.36830252]\n",
      " [0.37479946]\n",
      " [0.38103026]\n",
      " [0.38751692]\n",
      " [0.39448857]\n",
      " [0.40147355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.40855837]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.3555904 ]\n",
      "  [0.36171246]\n",
      "  [0.36830252]\n",
      "  [0.37479946]\n",
      "  [0.38103026]\n",
      "  [0.38751692]\n",
      "  [0.39448857]\n",
      "  [0.40147355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0845547467470169\n",
      "Predicción post entrenamiento : [[0.41040152]]\n",
      "PERDIDAAAA despues: 0.08348622918128967\n",
      "loss en el callback: 0.05069071799516678, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36171246]\n",
      " [0.36830252]\n",
      " [0.37479946]\n",
      " [0.38103026]\n",
      " [0.38751692]\n",
      " [0.39448857]\n",
      " [0.40147355]\n",
      " [0.40855837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4153697]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36171246]\n",
      "  [0.36830252]\n",
      "  [0.37479946]\n",
      "  [0.38103026]\n",
      "  [0.38751692]\n",
      "  [0.39448857]\n",
      "  [0.40147355]\n",
      "  [0.40855837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10364628583192825\n",
      "Predicción post entrenamiento : [[0.41757143]]\n",
      "PERDIDAAAA despues: 0.10223347693681717\n",
      "loss en el callback: 0.09138070046901703, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.36830252]\n",
      " [0.37479946]\n",
      " [0.38103026]\n",
      " [0.38751692]\n",
      " [0.39448857]\n",
      " [0.40147355]\n",
      " [0.40855837]\n",
      " [0.41536969]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.42267615]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.36830252]\n",
      "  [0.37479946]\n",
      "  [0.38103026]\n",
      "  [0.38751692]\n",
      "  [0.39448857]\n",
      "  [0.40147355]\n",
      "  [0.40855837]\n",
      "  [0.41536969]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08925137668848038\n",
      "Predicción post entrenamiento : [[0.42459944]]\n",
      "PERDIDAAAA despues: 0.08810590952634811\n",
      "loss en el callback: 0.06009044125676155, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37479946]\n",
      " [0.38103026]\n",
      " [0.38751692]\n",
      " [0.39448857]\n",
      " [0.40147355]\n",
      " [0.40855837]\n",
      " [0.41536969]\n",
      " [0.42267615]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4297507]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37479946]\n",
      "  [0.38103026]\n",
      "  [0.38751692]\n",
      "  [0.39448857]\n",
      "  [0.40147355]\n",
      "  [0.40855837]\n",
      "  [0.41536969]\n",
      "  [0.42267615]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08349961042404175\n",
      "Predicción post entrenamiento : [[0.43176594]]\n",
      "PERDIDAAAA despues: 0.08233901858329773\n",
      "loss en el callback: 0.09200751781463623, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38103026]\n",
      " [0.38751692]\n",
      " [0.39448857]\n",
      " [0.40147355]\n",
      " [0.40855837]\n",
      " [0.41536969]\n",
      " [0.42267615]\n",
      " [0.42975071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.43700698]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38103026]\n",
      "  [0.38751692]\n",
      "  [0.39448857]\n",
      "  [0.40147355]\n",
      "  [0.40855837]\n",
      "  [0.41536969]\n",
      "  [0.42267615]\n",
      "  [0.42975071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05624028295278549\n",
      "Predicción post entrenamiento : [[0.43857852]]\n",
      "PERDIDAAAA despues: 0.05549737438559532\n",
      "loss en el callback: 0.04801652580499649, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.38751692]\n",
      " [0.39448857]\n",
      " [0.40147355]\n",
      " [0.40855837]\n",
      " [0.41536969]\n",
      " [0.42267615]\n",
      " [0.42975071]\n",
      " [0.43700698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44400346]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.38751692]\n",
      "  [0.39448857]\n",
      "  [0.40147355]\n",
      "  [0.40855837]\n",
      "  [0.41536969]\n",
      "  [0.42267615]\n",
      "  [0.42975071]\n",
      "  [0.43700698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06480231136083603\n",
      "Predicción post entrenamiento : [[0.44575575]]\n",
      "PERDIDAAAA despues: 0.0639132410287857\n",
      "loss en el callback: 0.06116160750389099, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39448857]\n",
      " [0.40147355]\n",
      " [0.40855837]\n",
      " [0.41536969]\n",
      " [0.42267615]\n",
      " [0.42975071]\n",
      " [0.43700698]\n",
      " [0.44400346]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4513341]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39448857]\n",
      "  [0.40147355]\n",
      "  [0.40855837]\n",
      "  [0.41536969]\n",
      "  [0.42267615]\n",
      "  [0.42975071]\n",
      "  [0.43700698]\n",
      "  [0.44400346]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07274038344621658\n",
      "Predicción post entrenamiento : [[0.45311922]]\n",
      "PERDIDAAAA despues: 0.07178065925836563\n",
      "loss en el callback: 0.06655070930719376, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40147355]\n",
      " [0.40855837]\n",
      " [0.41536969]\n",
      " [0.42267615]\n",
      " [0.42975071]\n",
      " [0.43700698]\n",
      " [0.44400346]\n",
      " [0.45133409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.45874932]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40147355]\n",
      "  [0.40855837]\n",
      "  [0.41536969]\n",
      "  [0.42267615]\n",
      "  [0.42975071]\n",
      "  [0.43700698]\n",
      "  [0.44400346]\n",
      "  [0.45133409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06961090862751007\n",
      "Predicción post entrenamiento : [[0.46039924]]\n",
      "PERDIDAAAA despues: 0.0687430128455162\n",
      "loss en el callback: 0.056271880865097046, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.40855837]\n",
      " [0.41536969]\n",
      " [0.42267615]\n",
      " [0.42975071]\n",
      " [0.43700698]\n",
      " [0.44400346]\n",
      " [0.45133409]\n",
      " [0.45874932]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.46608642]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.40855837]\n",
      "  [0.41536969]\n",
      "  [0.42267615]\n",
      "  [0.42975071]\n",
      "  [0.43700698]\n",
      "  [0.44400346]\n",
      "  [0.45133409]\n",
      "  [0.45874932]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08422162383794785\n",
      "Predicción post entrenamiento : [[0.46811855]]\n",
      "PERDIDAAAA despues: 0.08304626494646072\n",
      "loss en el callback: 0.12820658087730408, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41536969]\n",
      " [0.42267615]\n",
      " [0.42975071]\n",
      " [0.43700698]\n",
      " [0.44400346]\n",
      " [0.45133409]\n",
      " [0.45874932]\n",
      " [0.46608642]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.47384867]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41536969]\n",
      "  [0.42267615]\n",
      "  [0.42975071]\n",
      "  [0.43700698]\n",
      "  [0.44400346]\n",
      "  [0.45133409]\n",
      "  [0.45874932]\n",
      "  [0.46608642]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12513026595115662\n",
      "Predicción post entrenamiento : [[0.47635865]]\n",
      "PERDIDAAAA despues: 0.12336081266403198\n",
      "loss en el callback: 0.19828423857688904, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.42267615]\n",
      " [0.42975071]\n",
      " [0.43700698]\n",
      " [0.44400346]\n",
      " [0.45133409]\n",
      " [0.45874932]\n",
      " [0.46608642]\n",
      " [0.47384867]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.48221782]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.42267615]\n",
      "  [0.42975071]\n",
      "  [0.43700698]\n",
      "  [0.44400346]\n",
      "  [0.45133409]\n",
      "  [0.45874932]\n",
      "  [0.46608642]\n",
      "  [0.47384867]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12716667354106903\n",
      "Predicción post entrenamiento : [[0.4844744]]\n",
      "PERDIDAAAA despues: 0.12556235492229462\n",
      "loss en el callback: 0.10911114513874054, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.42975071]\n",
      " [0.43700698]\n",
      " [0.44400346]\n",
      " [0.45133409]\n",
      " [0.45874932]\n",
      " [0.46608642]\n",
      " [0.47384867]\n",
      " [0.48221782]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.49035817]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.42975071]\n",
      "  [0.43700698]\n",
      "  [0.44400346]\n",
      "  [0.45133409]\n",
      "  [0.45874932]\n",
      "  [0.46608642]\n",
      "  [0.47384867]\n",
      "  [0.48221782]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09235984832048416\n",
      "Predicción post entrenamiento : [[0.4919995]]\n",
      "PERDIDAAAA despues: 0.09136491268873215\n",
      "loss en el callback: 0.04728567972779274, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.43700698]\n",
      " [0.44400346]\n",
      " [0.45133409]\n",
      " [0.45874932]\n",
      " [0.46608642]\n",
      " [0.47384867]\n",
      " [0.48221782]\n",
      " [0.49035817]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.49798667]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.43700698]\n",
      "  [0.44400346]\n",
      "  [0.45133409]\n",
      "  [0.45874932]\n",
      "  [0.46608642]\n",
      "  [0.47384867]\n",
      "  [0.48221782]\n",
      "  [0.49035817]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08169195055961609\n",
      "Predicción post entrenamiento : [[0.49988234]]\n",
      "PERDIDAAAA despues: 0.08061191439628601\n",
      "loss en el callback: 0.10106004774570465, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44400346]\n",
      " [0.45133409]\n",
      " [0.45874932]\n",
      " [0.46608642]\n",
      " [0.47384867]\n",
      " [0.48221782]\n",
      " [0.49035817]\n",
      " [0.49798667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5059565]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44400346]\n",
      "  [0.45133409]\n",
      "  [0.45874932]\n",
      "  [0.46608642]\n",
      "  [0.47384867]\n",
      "  [0.48221782]\n",
      "  [0.49035817]\n",
      "  [0.49798667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0686245858669281\n",
      "Predicción post entrenamiento : [[0.507905]]\n",
      "PERDIDAAAA despues: 0.06760749220848083\n",
      "loss en el callback: 0.10571491718292236, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.45133409]\n",
      " [0.45874932]\n",
      " [0.46608642]\n",
      " [0.47384867]\n",
      " [0.48221782]\n",
      " [0.49035817]\n",
      " [0.49798667]\n",
      " [0.50595647]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5141668]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.45133409]\n",
      "  [0.45874932]\n",
      "  [0.46608642]\n",
      "  [0.47384867]\n",
      "  [0.48221782]\n",
      "  [0.49035817]\n",
      "  [0.49798667]\n",
      "  [0.50595647]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07312311977148056\n",
      "Predicción post entrenamiento : [[0.515906]]\n",
      "PERDIDAAAA despues: 0.07218553125858307\n",
      "loss en el callback: 0.07293426990509033, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.45874932]\n",
      " [0.46608642]\n",
      " [0.47384867]\n",
      " [0.48221782]\n",
      " [0.49035817]\n",
      " [0.49798667]\n",
      " [0.50595647]\n",
      " [0.51416677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5223055]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.45874932]\n",
      "  [0.46608642]\n",
      "  [0.47384867]\n",
      "  [0.48221782]\n",
      "  [0.49035817]\n",
      "  [0.49798667]\n",
      "  [0.50595647]\n",
      "  [0.51416677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12703783810138702\n",
      "Predicción post entrenamiento : [[0.5245972]]\n",
      "PERDIDAAAA despues: 0.12540942430496216\n",
      "loss en el callback: 0.1470390409231186, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.46608642]\n",
      " [0.47384867]\n",
      " [0.48221782]\n",
      " [0.49035817]\n",
      " [0.49798667]\n",
      " [0.50595647]\n",
      " [0.51416677]\n",
      " [0.52230549]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5311445]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.46608642]\n",
      "  [0.47384867]\n",
      "  [0.48221782]\n",
      "  [0.49035817]\n",
      "  [0.49798667]\n",
      "  [0.50595647]\n",
      "  [0.51416677]\n",
      "  [0.52230549]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11866998672485352\n",
      "Predicción post entrenamiento : [[0.533246]]\n",
      "PERDIDAAAA despues: 0.11722654849290848\n",
      "loss en el callback: 0.09036339819431305, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.47384867]\n",
      " [0.48221782]\n",
      " [0.49035817]\n",
      " [0.49798667]\n",
      " [0.50595647]\n",
      " [0.51416677]\n",
      " [0.52230549]\n",
      " [0.5311445 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5399948]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.47384867]\n",
      "  [0.48221782]\n",
      "  [0.49035817]\n",
      "  [0.49798667]\n",
      "  [0.50595647]\n",
      "  [0.51416677]\n",
      "  [0.52230549]\n",
      "  [0.5311445 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09541983157396317\n",
      "Predicción post entrenamiento : [[0.541883]]\n",
      "PERDIDAAAA despues: 0.09425685554742813\n",
      "loss en el callback: 0.06927752494812012, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.48221782]\n",
      " [0.49035817]\n",
      " [0.49798667]\n",
      " [0.50595647]\n",
      " [0.51416677]\n",
      " [0.52230549]\n",
      " [0.5311445 ]\n",
      " [0.53999478]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5487548]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.48221782]\n",
      "  [0.49035817]\n",
      "  [0.49798667]\n",
      "  [0.50595647]\n",
      "  [0.51416677]\n",
      "  [0.52230549]\n",
      "  [0.5311445 ]\n",
      "  [0.53999478]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07264786958694458\n",
      "Predicción post entrenamiento : [[0.5506806]]\n",
      "PERDIDAAAA despues: 0.07161346077919006\n",
      "loss en el callback: 0.1318073272705078, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.49035817]\n",
      " [0.49798667]\n",
      " [0.50595647]\n",
      " [0.51416677]\n",
      " [0.52230549]\n",
      " [0.5311445 ]\n",
      " [0.53999478]\n",
      " [0.54875481]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5575342]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.49035817]\n",
      "  [0.49798667]\n",
      "  [0.50595647]\n",
      "  [0.51416677]\n",
      "  [0.52230549]\n",
      "  [0.5311445 ]\n",
      "  [0.53999478]\n",
      "  [0.54875481]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07251015305519104\n",
      "Predicción post entrenamiento : [[0.55942094]]\n",
      "PERDIDAAAA despues: 0.0714976117014885\n",
      "loss en el callback: 0.11218425631523132, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.49798667]\n",
      " [0.50595647]\n",
      " [0.51416677]\n",
      " [0.52230549]\n",
      " [0.5311445 ]\n",
      " [0.53999478]\n",
      " [0.54875481]\n",
      " [0.55753422]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.566333]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.49798667]\n",
      "  [0.50595647]\n",
      "  [0.51416677]\n",
      "  [0.52230549]\n",
      "  [0.5311445 ]\n",
      "  [0.53999478]\n",
      "  [0.54875481]\n",
      "  [0.55753422]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04797041788697243\n",
      "Predicción post entrenamiento : [[0.5676417]]\n",
      "PERDIDAAAA despues: 0.047398872673511505\n",
      "loss en el callback: 0.038231492042541504, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.50595647]\n",
      " [0.51416677]\n",
      " [0.52230549]\n",
      " [0.5311445 ]\n",
      " [0.53999478]\n",
      " [0.54875481]\n",
      " [0.55753422]\n",
      " [0.566333  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.57478285]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.50595647]\n",
      "  [0.51416677]\n",
      "  [0.52230549]\n",
      "  [0.5311445 ]\n",
      "  [0.53999478]\n",
      "  [0.54875481]\n",
      "  [0.55753422]\n",
      "  [0.566333  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04598714038729668\n",
      "Predicción post entrenamiento : [[0.5760452]]\n",
      "PERDIDAAAA despues: 0.04544731602072716\n",
      "loss en el callback: 0.03887723758816719, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.51416677]\n",
      " [0.52230549]\n",
      " [0.5311445 ]\n",
      " [0.53999478]\n",
      " [0.54875481]\n",
      " [0.55753422]\n",
      " [0.566333  ]\n",
      " [0.57478285]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5833677]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.51416677]\n",
      "  [0.52230549]\n",
      "  [0.5311445 ]\n",
      "  [0.53999478]\n",
      "  [0.54875481]\n",
      "  [0.55753422]\n",
      "  [0.566333  ]\n",
      "  [0.57478285]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06290318816900253\n",
      "Predicción post entrenamiento : [[0.5850234]]\n",
      "PERDIDAAAA despues: 0.0620754137635231\n",
      "loss en el callback: 0.0735117495059967, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.52230549]\n",
      " [0.5311445 ]\n",
      " [0.53999478]\n",
      " [0.54875481]\n",
      " [0.55753422]\n",
      " [0.566333  ]\n",
      " [0.57478285]\n",
      " [0.58336771]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.59249336]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.52230549]\n",
      "  [0.5311445 ]\n",
      "  [0.53999478]\n",
      "  [0.54875481]\n",
      "  [0.55753422]\n",
      "  [0.566333  ]\n",
      "  [0.57478285]\n",
      "  [0.58336771]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04839227721095085\n",
      "Predicción post entrenamiento : [[0.5939555]]\n",
      "PERDIDAAAA despues: 0.04775111377239227\n",
      "loss en el callback: 0.05889234319329262, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.5311445 ]\n",
      " [0.53999478]\n",
      " [0.54875481]\n",
      " [0.55753422]\n",
      " [0.566333  ]\n",
      " [0.57478285]\n",
      " [0.58336771]\n",
      " [0.59249336]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.60161597]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.5311445 ]\n",
      "  [0.53999478]\n",
      "  [0.54875481]\n",
      "  [0.55753422]\n",
      "  [0.566333  ]\n",
      "  [0.57478285]\n",
      "  [0.58336771]\n",
      "  [0.59249336]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.039849694818258286\n",
      "Predicción post entrenamiento : [[0.60306716]]\n",
      "PERDIDAAAA despues: 0.03927241265773773\n",
      "loss en el callback: 0.06117705628275871, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.53999478]\n",
      " [0.54875481]\n",
      " [0.55753422]\n",
      " [0.566333  ]\n",
      " [0.57478285]\n",
      " [0.58336771]\n",
      " [0.59249336]\n",
      " [0.60161597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6107428]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.53999478]\n",
      "  [0.54875481]\n",
      "  [0.55753422]\n",
      "  [0.566333  ]\n",
      "  [0.57478285]\n",
      "  [0.58336771]\n",
      "  [0.59249336]\n",
      "  [0.60161597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03703094273805618\n",
      "Predicción post entrenamiento : [[0.6116359]]\n",
      "PERDIDAAAA despues: 0.03668800741434097\n",
      "loss en el callback: 0.017269747331738472, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.54875481]\n",
      " [0.55753422]\n",
      " [0.566333  ]\n",
      " [0.57478285]\n",
      " [0.58336771]\n",
      " [0.59249336]\n",
      " [0.60161597]\n",
      " [0.61074281]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.61932194]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.54875481]\n",
      "  [0.55753422]\n",
      "  [0.566333  ]\n",
      "  [0.57478285]\n",
      "  [0.58336771]\n",
      "  [0.59249336]\n",
      "  [0.60161597]\n",
      "  [0.61074281]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030334820970892906\n",
      "Predicción post entrenamiento : [[0.62057716]]\n",
      "PERDIDAAAA despues: 0.02989915758371353\n",
      "loss en el callback: 0.04549345374107361, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.55753422]\n",
      " [0.566333  ]\n",
      " [0.57478285]\n",
      " [0.58336771]\n",
      " [0.59249336]\n",
      " [0.60161597]\n",
      " [0.61074281]\n",
      " [0.61932194]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6283029]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.55753422]\n",
      "  [0.566333  ]\n",
      "  [0.57478285]\n",
      "  [0.58336771]\n",
      "  [0.59249336]\n",
      "  [0.60161597]\n",
      "  [0.61074281]\n",
      "  [0.61932194]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01738906092941761\n",
      "Predicción post entrenamiento : [[0.6288213]]\n",
      "PERDIDAAAA despues: 0.017252597957849503\n",
      "loss en el callback: 0.006222488824278116, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.566333  ]\n",
      " [0.57478285]\n",
      " [0.58336771]\n",
      " [0.59249336]\n",
      " [0.60161597]\n",
      " [0.61074281]\n",
      " [0.61932194]\n",
      " [0.62830287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6365852]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.566333  ]\n",
      "  [0.57478285]\n",
      "  [0.58336771]\n",
      "  [0.59249336]\n",
      "  [0.60161597]\n",
      "  [0.61074281]\n",
      "  [0.61932194]\n",
      "  [0.62830287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009759214706718922\n",
      "Predicción post entrenamiento : [[0.6376073]]\n",
      "PERDIDAAAA despues: 0.009558315388858318\n",
      "loss en el callback: 0.03619011119008064, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.57478285]\n",
      " [0.58336771]\n",
      " [0.59249336]\n",
      " [0.60161597]\n",
      " [0.61074281]\n",
      " [0.61932194]\n",
      " [0.62830287]\n",
      " [0.63658518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6454097]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.57478285]\n",
      "  [0.58336771]\n",
      "  [0.59249336]\n",
      "  [0.60161597]\n",
      "  [0.61074281]\n",
      "  [0.61932194]\n",
      "  [0.62830287]\n",
      "  [0.63658518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004196463618427515\n",
      "Predicción post entrenamiento : [[0.64613]]\n",
      "PERDIDAAAA despues: 0.004103657323867083\n",
      "loss en el callback: 0.016063354909420013, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.58336771]\n",
      " [0.59249336]\n",
      " [0.60161597]\n",
      " [0.61074281]\n",
      " [0.61932194]\n",
      " [0.62830287]\n",
      " [0.63658518]\n",
      " [0.6454097 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6540737]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.58336771]\n",
      "  [0.59249336]\n",
      "  [0.60161597]\n",
      "  [0.61074281]\n",
      "  [0.61932194]\n",
      "  [0.62830287]\n",
      "  [0.63658518]\n",
      "  [0.6454097 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033701942302286625\n",
      "Predicción post entrenamiento : [[0.65501463]]\n",
      "PERDIDAAAA despues: 0.003261832520365715\n",
      "loss en el callback: 0.03173300623893738, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.59249336]\n",
      " [0.60161597]\n",
      " [0.61074281]\n",
      " [0.61932194]\n",
      " [0.62830287]\n",
      " [0.63658518]\n",
      " [0.6454097 ]\n",
      " [0.65407372]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6630722]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.59249336]\n",
      "  [0.60161597]\n",
      "  [0.61074281]\n",
      "  [0.61932194]\n",
      "  [0.62830287]\n",
      "  [0.63658518]\n",
      "  [0.6454097 ]\n",
      "  [0.65407372]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005861984565854073\n",
      "Predicción post entrenamiento : [[0.6632335]]\n",
      "PERDIDAAAA despues: 0.005837312433868647\n",
      "loss en el callback: 0.0006071307579986751, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.60161597]\n",
      " [0.61074281]\n",
      " [0.61932194]\n",
      " [0.62830287]\n",
      " [0.63658518]\n",
      " [0.6454097 ]\n",
      " [0.65407372]\n",
      " [0.66307223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6712442]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.60161597]\n",
      "  [0.61074281]\n",
      "  [0.61932194]\n",
      "  [0.62830287]\n",
      "  [0.63658518]\n",
      "  [0.6454097 ]\n",
      "  [0.65407372]\n",
      "  [0.66307223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004212603438645601\n",
      "Predicción post entrenamiento : [[0.67187935]]\n",
      "PERDIDAAAA despues: 0.004130558576434851\n",
      "loss en el callback: 0.011891065165400505, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.61074281]\n",
      " [0.61932194]\n",
      " [0.62830287]\n",
      " [0.63658518]\n",
      " [0.6454097 ]\n",
      " [0.65407372]\n",
      " [0.66307223]\n",
      " [0.6712442 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6798237]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.61074281]\n",
      "  [0.61932194]\n",
      "  [0.62830287]\n",
      "  [0.63658518]\n",
      "  [0.6454097 ]\n",
      "  [0.65407372]\n",
      "  [0.66307223]\n",
      "  [0.6712442 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015013567463029176\n",
      "Predicción post entrenamiento : [[0.679957]]\n",
      "PERDIDAAAA despues: 0.0001534195034764707\n",
      "loss en el callback: 0.0005175796686671674, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.61932194]\n",
      " [0.62830287]\n",
      " [0.63658518]\n",
      " [0.6454097 ]\n",
      " [0.65407372]\n",
      " [0.66307223]\n",
      " [0.6712442 ]\n",
      " [0.6798237 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6878074]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.61932194]\n",
      "  [0.62830287]\n",
      "  [0.63658518]\n",
      "  [0.6454097 ]\n",
      "  [0.65407372]\n",
      "  [0.66307223]\n",
      "  [0.6712442 ]\n",
      "  [0.6798237 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032083867699839175\n",
      "Predicción post entrenamiento : [[0.6881076]]\n",
      "PERDIDAAAA despues: 0.0003316841903142631\n",
      "loss en el callback: 0.0028599414508789778, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.62830287]\n",
      " [0.63658518]\n",
      " [0.6454097 ]\n",
      " [0.65407372]\n",
      " [0.66307223]\n",
      " [0.6712442 ]\n",
      " [0.6798237 ]\n",
      " [0.68780738]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.69600123]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.62830287]\n",
      "  [0.63658518]\n",
      "  [0.6454097 ]\n",
      "  [0.65407372]\n",
      "  [0.66307223]\n",
      "  [0.6712442 ]\n",
      "  [0.6798237 ]\n",
      "  [0.68780738]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.9437713894585613e-07\n",
      "Predicción post entrenamiento : [[0.6958549]]\n",
      "PERDIDAAAA despues: 5.995775609335396e-07\n",
      "loss en el callback: 0.0005370834260247648, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.63658518]\n",
      " [0.6454097 ]\n",
      " [0.65407372]\n",
      " [0.66307223]\n",
      " [0.6712442 ]\n",
      " [0.6798237 ]\n",
      " [0.68780738]\n",
      " [0.69600123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.70366067]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.63658518]\n",
      "  [0.6454097 ]\n",
      "  [0.65407372]\n",
      "  [0.66307223]\n",
      "  [0.6712442 ]\n",
      "  [0.6798237 ]\n",
      "  [0.68780738]\n",
      "  [0.69600123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022765628527849913\n",
      "Predicción post entrenamiento : [[0.7024602]]\n",
      "PERDIDAAAA despues: 0.002163450000807643\n",
      "loss en el callback: 0.0296322014182806, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.6454097 ]\n",
      " [0.65407372]\n",
      " [0.66307223]\n",
      " [0.6712442 ]\n",
      " [0.6798237 ]\n",
      " [0.68780738]\n",
      " [0.69600123]\n",
      " [0.70366067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7103514]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.6454097 ]\n",
      "  [0.65407372]\n",
      "  [0.66307223]\n",
      "  [0.6712442 ]\n",
      "  [0.6798237 ]\n",
      "  [0.68780738]\n",
      "  [0.69600123]\n",
      "  [0.70366067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000995070906355977\n",
      "Predicción post entrenamiento : [[0.7106092]]\n",
      "PERDIDAAAA despues: 0.0010114011820405722\n",
      "loss en el callback: 0.002384488470852375, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.65407372]\n",
      " [0.66307223]\n",
      " [0.6712442 ]\n",
      " [0.6798237 ]\n",
      " [0.68780738]\n",
      " [0.69600123]\n",
      " [0.70366067]\n",
      " [0.71035141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7184088]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.65407372]\n",
      "  [0.66307223]\n",
      "  [0.6712442 ]\n",
      "  [0.6798237 ]\n",
      "  [0.68780738]\n",
      "  [0.69600123]\n",
      "  [0.70366067]\n",
      "  [0.71035141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017904991982504725\n",
      "Predicción post entrenamiento : [[0.7183295]]\n",
      "PERDIDAAAA despues: 0.0017837915802374482\n",
      "loss en el callback: 0.0001745780900819227, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.66307223]\n",
      " [0.6712442 ]\n",
      " [0.6798237 ]\n",
      " [0.68780738]\n",
      " [0.69600123]\n",
      " [0.70366067]\n",
      " [0.71035141]\n",
      " [0.71840882]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.72603476]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.66307223]\n",
      "  [0.6712442 ]\n",
      "  [0.6798237 ]\n",
      "  [0.68780738]\n",
      "  [0.69600123]\n",
      "  [0.70366067]\n",
      "  [0.71035141]\n",
      "  [0.71840882]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2442571460269392e-05\n",
      "Predicción post entrenamiento : [[0.726381]]\n",
      "PERDIDAAAA despues: 1.0119775652128737e-05\n",
      "loss en el callback: 0.0036350612062960863, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.6712442 ]\n",
      " [0.6798237 ]\n",
      " [0.68780738]\n",
      " [0.69600123]\n",
      " [0.70366067]\n",
      " [0.71035141]\n",
      " [0.71840882]\n",
      " [0.72603476]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7338428]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.6712442 ]\n",
      "  [0.6798237 ]\n",
      "  [0.68780738]\n",
      "  [0.69600123]\n",
      "  [0.70366067]\n",
      "  [0.71035141]\n",
      "  [0.71840882]\n",
      "  [0.72603476]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010604285635054111\n",
      "Predicción post entrenamiento : [[0.7330915]]\n",
      "PERDIDAAAA despues: 0.0010120610240846872\n",
      "loss en el callback: 0.013528445735573769, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.6798237 ]\n",
      " [0.68780738]\n",
      " [0.69600123]\n",
      " [0.70366067]\n",
      " [0.71035141]\n",
      " [0.71840882]\n",
      " [0.72603476]\n",
      " [0.73384279]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.74049276]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.6798237 ]\n",
      "  [0.68780738]\n",
      "  [0.69600123]\n",
      "  [0.70366067]\n",
      "  [0.71035141]\n",
      "  [0.71840882]\n",
      "  [0.72603476]\n",
      "  [0.73384279]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007311199442483485\n",
      "Predicción post entrenamiento : [[0.74096674]]\n",
      "PERDIDAAAA despues: 0.0007057127077132463\n",
      "loss en el callback: 0.00692784134298563, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.68780738]\n",
      " [0.69600123]\n",
      " [0.70366067]\n",
      " [0.71035141]\n",
      " [0.71840882]\n",
      " [0.72603476]\n",
      " [0.73384279]\n",
      " [0.74049276]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7481529]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.68780738]\n",
      "  [0.69600123]\n",
      "  [0.70366067]\n",
      "  [0.71035141]\n",
      "  [0.71840882]\n",
      "  [0.72603476]\n",
      "  [0.73384279]\n",
      "  [0.74049276]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.873124635196291e-05\n",
      "Predicción post entrenamiento : [[0.7473218]]\n",
      "PERDIDAAAA despues: 6.1025843024253845e-05\n",
      "loss en el callback: 0.014693260192871094, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.69600123]\n",
      " [0.70366067]\n",
      " [0.71035141]\n",
      " [0.71840882]\n",
      " [0.72603476]\n",
      " [0.73384279]\n",
      " [0.74049276]\n",
      " [0.74815291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.754418]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.69600123]\n",
      "  [0.70366067]\n",
      "  [0.71035141]\n",
      "  [0.71840882]\n",
      "  [0.72603476]\n",
      "  [0.73384279]\n",
      "  [0.74049276]\n",
      "  [0.74815291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.757195610087365e-05\n",
      "Predicción post entrenamiento : [[0.7538921]]\n",
      "PERDIDAAAA despues: 7.800594175932929e-05\n",
      "loss en el callback: 0.0071966927498579025, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.70366067]\n",
      " [0.71035141]\n",
      " [0.71840882]\n",
      " [0.72603476]\n",
      " [0.73384279]\n",
      " [0.74049276]\n",
      " [0.74815291]\n",
      " [0.75441802]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7608005]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.70366067]\n",
      "  [0.71035141]\n",
      "  [0.71840882]\n",
      "  [0.72603476]\n",
      "  [0.73384279]\n",
      "  [0.74049276]\n",
      "  [0.74815291]\n",
      "  [0.75441802]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.684999582124874e-05\n",
      "Predicción post entrenamiento : [[0.759663]]\n",
      "PERDIDAAAA despues: 5.8200384955853224e-05\n",
      "loss en el callback: 0.026241296902298927, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.71035141]\n",
      " [0.71840882]\n",
      " [0.72603476]\n",
      " [0.73384279]\n",
      " [0.74049276]\n",
      " [0.74815291]\n",
      " [0.75441802]\n",
      " [0.76080048]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7664962]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.71035141]\n",
      "  [0.71840882]\n",
      "  [0.72603476]\n",
      "  [0.73384279]\n",
      "  [0.74049276]\n",
      "  [0.74815291]\n",
      "  [0.75441802]\n",
      "  [0.76080048]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003214186057448387\n",
      "Predicción post entrenamiento : [[0.76614904]]\n",
      "PERDIDAAAA despues: 0.003174945479258895\n",
      "loss en el callback: 0.0035100325476378202, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.71840882]\n",
      " [0.72603476]\n",
      " [0.73384279]\n",
      " [0.74049276]\n",
      " [0.74815291]\n",
      " [0.75441802]\n",
      " [0.76080048]\n",
      " [0.76649618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.77316606]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.71840882]\n",
      "  [0.72603476]\n",
      "  [0.73384279]\n",
      "  [0.74049276]\n",
      "  [0.74815291]\n",
      "  [0.75441802]\n",
      "  [0.76080048]\n",
      "  [0.76649618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006845248397439718\n",
      "Predicción post entrenamiento : [[0.77298677]]\n",
      "PERDIDAAAA despues: 0.006815612781792879\n",
      "loss en el callback: 0.0010635403450578451, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.72603476]\n",
      " [0.73384279]\n",
      " [0.74049276]\n",
      " [0.74815291]\n",
      " [0.75441802]\n",
      " [0.76080048]\n",
      " [0.76649618]\n",
      " [0.77316606]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7797525]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.72603476]\n",
      "  [0.73384279]\n",
      "  [0.74049276]\n",
      "  [0.74815291]\n",
      "  [0.75441802]\n",
      "  [0.76080048]\n",
      "  [0.76649618]\n",
      "  [0.77316606]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000644841231405735\n",
      "Predicción post entrenamiento : [[0.7801199]]\n",
      "PERDIDAAAA despues: 0.0006636356702074409\n",
      "loss en el callback: 0.005071929190307856, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.73384279]\n",
      " [0.74049276]\n",
      " [0.74815291]\n",
      " [0.75441802]\n",
      " [0.76080048]\n",
      " [0.76649618]\n",
      " [0.77316606]\n",
      " [0.77975249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.78669095]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.73384279]\n",
      "  [0.74049276]\n",
      "  [0.74815291]\n",
      "  [0.75441802]\n",
      "  [0.76080048]\n",
      "  [0.76649618]\n",
      "  [0.77316606]\n",
      "  [0.77975249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004158993251621723\n",
      "Predicción post entrenamiento : [[0.7865701]]\n",
      "PERDIDAAAA despues: 0.004143417347222567\n",
      "loss en el callback: 0.0005190398078411818, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.74049276]\n",
      " [0.74815291]\n",
      " [0.75441802]\n",
      " [0.76080048]\n",
      " [0.76649618]\n",
      " [0.77316606]\n",
      " [0.77975249]\n",
      " [0.78669095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7928306]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.74049276]\n",
      "  [0.74815291]\n",
      "  [0.75441802]\n",
      "  [0.76080048]\n",
      "  [0.76649618]\n",
      "  [0.77316606]\n",
      "  [0.77975249]\n",
      "  [0.78669095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003100014291703701\n",
      "Predicción post entrenamiento : [[0.79335636]]\n",
      "PERDIDAAAA despues: 0.003041743068024516\n",
      "loss en el callback: 0.008829173631966114, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.74815291]\n",
      " [0.75441802]\n",
      " [0.76080048]\n",
      " [0.76649618]\n",
      " [0.77316606]\n",
      " [0.77975249]\n",
      " [0.78669095]\n",
      " [0.79283059]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.79960304]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.74815291]\n",
      "  [0.75441802]\n",
      "  [0.76080048]\n",
      "  [0.76649618]\n",
      "  [0.77316606]\n",
      "  [0.77975249]\n",
      "  [0.78669095]\n",
      "  [0.79283059]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011206326074898243\n",
      "Predicción post entrenamiento : [[0.8007789]]\n",
      "PERDIDAAAA despues: 0.010958751663565636\n",
      "loss en el callback: 0.06035829707980156, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.75441802]\n",
      " [0.76080048]\n",
      " [0.76649618]\n",
      " [0.77316606]\n",
      " [0.77975249]\n",
      " [0.78669095]\n",
      " [0.79283059]\n",
      " [0.79960304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8066887]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.75441802]\n",
      "  [0.76080048]\n",
      "  [0.76649618]\n",
      "  [0.77316606]\n",
      "  [0.77975249]\n",
      "  [0.78669095]\n",
      "  [0.79283059]\n",
      "  [0.79960304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0057044015266001225\n",
      "Predicción post entrenamiento : [[0.8072771]]\n",
      "PERDIDAAAA despues: 0.005615873262286186\n",
      "loss en el callback: 0.0113388542085886, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.76080048]\n",
      " [0.76649618]\n",
      " [0.77316606]\n",
      " [0.77975249]\n",
      " [0.78669095]\n",
      " [0.79283059]\n",
      " [0.79960304]\n",
      " [0.80668873]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8132396]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.76080048]\n",
      "  [0.76649618]\n",
      "  [0.77316606]\n",
      "  [0.77975249]\n",
      "  [0.78669095]\n",
      "  [0.79283059]\n",
      "  [0.79960304]\n",
      "  [0.80668873]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008939344435930252\n",
      "Predicción post entrenamiento : [[0.8137929]]\n",
      "PERDIDAAAA despues: 0.008835021406412125\n",
      "loss en el callback: 0.008920700289309025, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.76649618]\n",
      " [0.77316606]\n",
      " [0.77975249]\n",
      " [0.78669095]\n",
      " [0.79283059]\n",
      " [0.79960304]\n",
      " [0.80668873]\n",
      " [0.81323957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8197917]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.76649618]\n",
      "  [0.77316606]\n",
      "  [0.77975249]\n",
      "  [0.78669095]\n",
      "  [0.79283059]\n",
      "  [0.79960304]\n",
      "  [0.80668873]\n",
      "  [0.81323957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004870087374001741\n",
      "Predicción post entrenamiento : [[0.8193643]]\n",
      "PERDIDAAAA despues: 0.004929918330162764\n",
      "loss en el callback: 0.0050704521127045155, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.77316606]\n",
      " [0.77975249]\n",
      " [0.78669095]\n",
      " [0.79283059]\n",
      " [0.79960304]\n",
      " [0.80668873]\n",
      " [0.81323957]\n",
      " [0.81979167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.82562864]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.77316606]\n",
      "  [0.77975249]\n",
      "  [0.78669095]\n",
      "  [0.79283059]\n",
      "  [0.79960304]\n",
      "  [0.80668873]\n",
      "  [0.81323957]\n",
      "  [0.81979167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024232035502791405\n",
      "Predicción post entrenamiento : [[0.8249942]]\n",
      "PERDIDAAAA despues: 0.0024860671255737543\n",
      "loss en el callback: 0.009415130130946636, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.77975249]\n",
      " [0.78669095]\n",
      " [0.79283059]\n",
      " [0.79960304]\n",
      " [0.80668873]\n",
      " [0.81323957]\n",
      " [0.81979167]\n",
      " [0.82562864]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8312569]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.77975249]\n",
      "  [0.78669095]\n",
      "  [0.79283059]\n",
      "  [0.79960304]\n",
      "  [0.80668873]\n",
      "  [0.81323957]\n",
      "  [0.81979167]\n",
      "  [0.82562864]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006716624367982149\n",
      "Predicción post entrenamiento : [[0.83122474]]\n",
      "PERDIDAAAA despues: 0.00672190124168992\n",
      "loss en el callback: 2.8479751563281752e-05, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.78669095]\n",
      " [0.79283059]\n",
      " [0.79960304]\n",
      " [0.80668873]\n",
      " [0.81323957]\n",
      " [0.81979167]\n",
      " [0.82562864]\n",
      " [0.83125693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8375003]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.78669095]\n",
      "  [0.79283059]\n",
      "  [0.79960304]\n",
      "  [0.80668873]\n",
      "  [0.81323957]\n",
      "  [0.81979167]\n",
      "  [0.82562864]\n",
      "  [0.83125693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02640616148710251\n",
      "Predicción post entrenamiento : [[0.8380346]]\n",
      "PERDIDAAAA despues: 0.026232799515128136\n",
      "loss en el callback: 0.00796542875468731, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.79283059]\n",
      " [0.79960304]\n",
      " [0.80668873]\n",
      " [0.81323957]\n",
      " [0.81979167]\n",
      " [0.82562864]\n",
      " [0.83125693]\n",
      " [0.83750027]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8441972]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.79283059]\n",
      "  [0.79960304]\n",
      "  [0.80668873]\n",
      "  [0.81323957]\n",
      "  [0.81979167]\n",
      "  [0.82562864]\n",
      "  [0.83125693]\n",
      "  [0.83750027]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015966050326824188\n",
      "Predicción post entrenamiento : [[0.8443608]]\n",
      "PERDIDAAAA despues: 0.01592472940683365\n",
      "loss en el callback: 0.0006757253431715071, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.79960304]\n",
      " [0.80668873]\n",
      " [0.81323957]\n",
      " [0.81979167]\n",
      " [0.82562864]\n",
      " [0.83125693]\n",
      " [0.83750027]\n",
      " [0.84419721]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.85062706]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.79960304]\n",
      "  [0.80668873]\n",
      "  [0.81323957]\n",
      "  [0.81979167]\n",
      "  [0.82562864]\n",
      "  [0.83125693]\n",
      "  [0.83750027]\n",
      "  [0.84419721]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014573842054232955\n",
      "Predicción post entrenamiento : [[0.85052097]]\n",
      "PERDIDAAAA despues: 0.0014654961414635181\n",
      "loss en el callback: 0.0003026613558176905, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.80668873]\n",
      " [0.81323957]\n",
      " [0.81979167]\n",
      " [0.82562864]\n",
      " [0.83125693]\n",
      " [0.83750027]\n",
      " [0.84419721]\n",
      " [0.85062706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8566897]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.80668873]\n",
      "  [0.81323957]\n",
      "  [0.81979167]\n",
      "  [0.82562864]\n",
      "  [0.83125693]\n",
      "  [0.83750027]\n",
      "  [0.84419721]\n",
      "  [0.85062706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045218373998068273\n",
      "Predicción post entrenamiento : [[0.8571684]]\n",
      "PERDIDAAAA despues: 0.0004320548032410443\n",
      "loss en el callback: 0.00792812928557396, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.81323957]\n",
      " [0.81979167]\n",
      " [0.82562864]\n",
      " [0.83125693]\n",
      " [0.83750027]\n",
      " [0.84419721]\n",
      " [0.85062706]\n",
      " [0.85668969]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.86311275]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.81323957]\n",
      "  [0.81979167]\n",
      "  [0.82562864]\n",
      "  [0.83125693]\n",
      "  [0.83750027]\n",
      "  [0.84419721]\n",
      "  [0.85062706]\n",
      "  [0.85668969]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020212194067426026\n",
      "Predicción post entrenamiento : [[0.86334556]]\n",
      "PERDIDAAAA despues: 0.00020879600197076797\n",
      "loss en el callback: 0.0019485800294205546, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.81979167]\n",
      " [0.82562864]\n",
      " [0.83125693]\n",
      " [0.83750027]\n",
      " [0.84419721]\n",
      " [0.85062706]\n",
      " [0.85668969]\n",
      " [0.86311275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.86919546]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.81979167]\n",
      "  [0.82562864]\n",
      "  [0.83125693]\n",
      "  [0.83750027]\n",
      "  [0.84419721]\n",
      "  [0.85062706]\n",
      "  [0.85668969]\n",
      "  [0.86311275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012265878031030297\n",
      "Predicción post entrenamiento : [[0.86929303]]\n",
      "PERDIDAAAA despues: 0.0012334318598732352\n",
      "loss en el callback: 0.0003375303640495986, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.82562864]\n",
      " [0.83125693]\n",
      " [0.83750027]\n",
      " [0.84419721]\n",
      " [0.85062706]\n",
      " [0.85668969]\n",
      " [0.86311275]\n",
      " [0.86919546]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8750365]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.82562864]\n",
      "  [0.83125693]\n",
      "  [0.83750027]\n",
      "  [0.84419721]\n",
      "  [0.85062706]\n",
      "  [0.85668969]\n",
      "  [0.86311275]\n",
      "  [0.86919546]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003976661537308246\n",
      "Predicción post entrenamiento : [[0.87424076]]\n",
      "PERDIDAAAA despues: 0.00036656344309449196\n",
      "loss en el callback: 0.01655936799943447, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.83125693]\n",
      " [0.83750027]\n",
      " [0.84419721]\n",
      " [0.85062706]\n",
      " [0.85668969]\n",
      " [0.86311275]\n",
      " [0.86919546]\n",
      " [0.87503648]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.88009083]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.83125693]\n",
      "  [0.83750027]\n",
      "  [0.84419721]\n",
      "  [0.85062706]\n",
      "  [0.85668969]\n",
      "  [0.86311275]\n",
      "  [0.86919546]\n",
      "  [0.87503648]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.3509493985329755e-05\n",
      "Predicción post entrenamiento : [[0.8803887]]\n",
      "PERDIDAAAA despues: 2.6486497517907992e-05\n",
      "loss en el callback: 0.0032928839791566133, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.83750027]\n",
      " [0.84419721]\n",
      " [0.85062706]\n",
      " [0.85668969]\n",
      " [0.86311275]\n",
      " [0.86919546]\n",
      " [0.87503648]\n",
      " [0.88009083]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8864243]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.83750027]\n",
      "  [0.84419721]\n",
      "  [0.85062706]\n",
      "  [0.85668969]\n",
      "  [0.86311275]\n",
      "  [0.86919546]\n",
      "  [0.87503648]\n",
      "  [0.88009083]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008638969156891108\n",
      "Predicción post entrenamiento : [[0.88555735]]\n",
      "PERDIDAAAA despues: 0.0008136855321936309\n",
      "loss en el callback: 0.020443173125386238, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.84419721]\n",
      " [0.85062706]\n",
      " [0.85668969]\n",
      " [0.86311275]\n",
      " [0.86919546]\n",
      " [0.87503648]\n",
      " [0.88009083]\n",
      " [0.8864243 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8915925]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.84419721]\n",
      "  [0.85062706]\n",
      "  [0.85668969]\n",
      "  [0.86311275]\n",
      "  [0.86919546]\n",
      "  [0.87503648]\n",
      "  [0.88009083]\n",
      "  [0.8864243 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017251033568754792\n",
      "Predicción post entrenamiento : [[0.892305]]\n",
      "PERDIDAAAA despues: 0.001784798689186573\n",
      "loss en el callback: 0.024394843727350235, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.85062706]\n",
      " [0.85668969]\n",
      " [0.86311275]\n",
      " [0.86919546]\n",
      " [0.87503648]\n",
      " [0.88009083]\n",
      " [0.8864243 ]\n",
      " [0.8915925 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.89817435]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.85062706]\n",
      "  [0.85668969]\n",
      "  [0.86311275]\n",
      "  [0.86919546]\n",
      "  [0.87503648]\n",
      "  [0.88009083]\n",
      "  [0.8864243 ]\n",
      "  [0.8915925 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030777794308960438\n",
      "Predicción post entrenamiento : [[0.8984588]]\n",
      "PERDIDAAAA despues: 0.0031094197183847427\n",
      "loss en el callback: 0.0035207688342779875, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.85668969]\n",
      " [0.86311275]\n",
      " [0.86919546]\n",
      " [0.87503648]\n",
      " [0.88009083]\n",
      " [0.8864243 ]\n",
      " [0.8915925 ]\n",
      " [0.89817435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.90420294]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.85668969]\n",
      "  [0.86311275]\n",
      "  [0.86919546]\n",
      "  [0.87503648]\n",
      "  [0.88009083]\n",
      "  [0.8864243 ]\n",
      "  [0.8915925 ]\n",
      "  [0.89817435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006604179739952087\n",
      "Predicción post entrenamiento : [[0.9046361]]\n",
      "PERDIDAAAA despues: 0.006674767937511206\n",
      "loss en el callback: 0.009012925438582897, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.86311275]\n",
      " [0.86919546]\n",
      " [0.87503648]\n",
      " [0.88009083]\n",
      " [0.8864243 ]\n",
      " [0.8915925 ]\n",
      " [0.89817435]\n",
      " [0.90420294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.91034293]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.86311275]\n",
      "  [0.86919546]\n",
      "  [0.87503648]\n",
      "  [0.88009083]\n",
      "  [0.8864243 ]\n",
      "  [0.8915925 ]\n",
      "  [0.89817435]\n",
      "  [0.90420294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018451662734150887\n",
      "Predicción post entrenamiento : [[0.9098806]]\n",
      "PERDIDAAAA despues: 0.01832626760005951\n",
      "loss en el callback: 0.008205252699553967, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.86919546]\n",
      " [0.87503648]\n",
      " [0.88009083]\n",
      " [0.8864243 ]\n",
      " [0.8915925 ]\n",
      " [0.89817435]\n",
      " [0.90420294]\n",
      " [0.91034293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9154245]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.86919546]\n",
      "  [0.87503648]\n",
      "  [0.88009083]\n",
      "  [0.8864243 ]\n",
      "  [0.8915925 ]\n",
      "  [0.89817435]\n",
      "  [0.90420294]\n",
      "  [0.91034293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017221936956048012\n",
      "Predicción post entrenamiento : [[0.9146913]]\n",
      "PERDIDAAAA despues: 0.017030037939548492\n",
      "loss en el callback: 0.01788683608174324, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.87503648]\n",
      " [0.88009083]\n",
      " [0.8864243 ]\n",
      " [0.8915925 ]\n",
      " [0.89817435]\n",
      " [0.90420294]\n",
      " [0.91034293]\n",
      " [0.91542453]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.92015517]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.87503648]\n",
      "  [0.88009083]\n",
      "  [0.8864243 ]\n",
      "  [0.8915925 ]\n",
      "  [0.89817435]\n",
      "  [0.90420294]\n",
      "  [0.91034293]\n",
      "  [0.91542453]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036494715604931116\n",
      "Predicción post entrenamiento : [[0.91968286]]\n",
      "PERDIDAAAA despues: 0.003592629684135318\n",
      "loss en el callback: 0.007506210822612047, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.88009083]\n",
      " [0.8864243 ]\n",
      " [0.8915925 ]\n",
      " [0.89817435]\n",
      " [0.90420294]\n",
      " [0.91034293]\n",
      " [0.91542453]\n",
      " [0.92015517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9251297]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.88009083]\n",
      "  [0.8864243 ]\n",
      "  [0.8915925 ]\n",
      "  [0.89817435]\n",
      "  [0.90420294]\n",
      "  [0.91034293]\n",
      "  [0.91542453]\n",
      "  [0.92015517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00501400837674737\n",
      "Predicción post entrenamiento : [[0.92409307]]\n",
      "PERDIDAAAA despues: 0.004868274088948965\n",
      "loss en el callback: 0.030121468007564545, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.8864243 ]\n",
      " [0.8915925 ]\n",
      " [0.89817435]\n",
      " [0.90420294]\n",
      " [0.91034293]\n",
      " [0.91542453]\n",
      " [0.92015517]\n",
      " [0.92512971]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9297595]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.8864243 ]\n",
      "  [0.8915925 ]\n",
      "  [0.89817435]\n",
      "  [0.90420294]\n",
      "  [0.91034293]\n",
      "  [0.91542453]\n",
      "  [0.92015517]\n",
      "  [0.92512971]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008625688962638378\n",
      "Predicción post entrenamiento : [[0.9288204]]\n",
      "PERDIDAAAA despues: 0.008452127687633038\n",
      "loss en el callback: 0.026757480576634407, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.8915925 ]\n",
      " [0.89817435]\n",
      " [0.90420294]\n",
      " [0.91034293]\n",
      " [0.91542453]\n",
      " [0.92015517]\n",
      " [0.92512971]\n",
      " [0.9297595 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.93430394]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.8915925 ]\n",
      "  [0.89817435]\n",
      "  [0.90420294]\n",
      "  [0.91034293]\n",
      "  [0.91542453]\n",
      "  [0.92015517]\n",
      "  [0.92512971]\n",
      "  [0.9297595 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010897912085056305\n",
      "Predicción post entrenamiento : [[0.93319786]]\n",
      "PERDIDAAAA despues: 0.010668200440704823\n",
      "loss en el callback: 0.042040660977363586, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.89817435]\n",
      " [0.90420294]\n",
      " [0.91034293]\n",
      " [0.91542453]\n",
      " [0.92015517]\n",
      " [0.92512971]\n",
      " [0.9297595 ]\n",
      " [0.93430394]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.93880594]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.89817435]\n",
      "  [0.90420294]\n",
      "  [0.91034293]\n",
      "  [0.91542453]\n",
      "  [0.92015517]\n",
      "  [0.92512971]\n",
      "  [0.9297595 ]\n",
      "  [0.93430394]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026577068492770195\n",
      "Predicción post entrenamiento : [[0.9391913]]\n",
      "PERDIDAAAA despues: 0.0026975865475833416\n",
      "loss en el callback: 0.00871834997087717, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.90420294]\n",
      " [0.91034293]\n",
      " [0.91542453]\n",
      " [0.92015517]\n",
      " [0.92512971]\n",
      " [0.9297595 ]\n",
      " [0.93430394]\n",
      " [0.93880594]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.944449]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.90420294]\n",
      "  [0.91034293]\n",
      "  [0.91542453]\n",
      "  [0.92015517]\n",
      "  [0.92512971]\n",
      "  [0.9297595 ]\n",
      "  [0.93430394]\n",
      "  [0.93880594]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007174885831773281\n",
      "Predicción post entrenamiento : [[0.94370127]]\n",
      "PERDIDAAAA despues: 0.007048770785331726\n",
      "loss en el callback: 0.018291572108864784, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.91034293]\n",
      " [0.91542453]\n",
      " [0.92015517]\n",
      " [0.92512971]\n",
      " [0.9297595 ]\n",
      " [0.93430394]\n",
      " [0.93880594]\n",
      " [0.94444901]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9486946]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.91034293]\n",
      "  [0.91542453]\n",
      "  [0.92015517]\n",
      "  [0.92512971]\n",
      "  [0.9297595 ]\n",
      "  [0.93430394]\n",
      "  [0.93880594]\n",
      "  [0.94444901]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011902273632586002\n",
      "Predicción post entrenamiento : [[0.94744915]]\n",
      "PERDIDAAAA despues: 0.011632075533270836\n",
      "loss en el callback: 0.048161834478378296, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.91542453]\n",
      " [0.92015517]\n",
      " [0.92512971]\n",
      " [0.9297595 ]\n",
      " [0.93430394]\n",
      " [0.93880594]\n",
      " [0.94444901]\n",
      " [0.94869459]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9520774]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.91542453]\n",
      "  [0.92015517]\n",
      "  [0.92512971]\n",
      "  [0.9297595 ]\n",
      "  [0.93430394]\n",
      "  [0.93880594]\n",
      "  [0.94444901]\n",
      "  [0.94869459]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028315693140029907\n",
      "Predicción post entrenamiento : [[0.95265377]]\n",
      "PERDIDAAAA despues: 0.02851000241935253\n",
      "loss en el callback: 0.025437017902731895, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.92015517]\n",
      " [0.92512971]\n",
      " [0.9297595 ]\n",
      " [0.93430394]\n",
      " [0.93880594]\n",
      " [0.94444901]\n",
      " [0.94869459]\n",
      " [0.95207739]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9571867]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.92015517]\n",
      "  [0.92512971]\n",
      "  [0.9297595 ]\n",
      "  [0.93430394]\n",
      "  [0.93880594]\n",
      "  [0.94444901]\n",
      "  [0.94869459]\n",
      "  [0.95207739]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019292989745736122\n",
      "Predicción post entrenamiento : [[0.9560488]]\n",
      "PERDIDAAAA despues: 0.018978174775838852\n",
      "loss en el callback: 0.04227244853973389, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.92512971]\n",
      " [0.9297595 ]\n",
      " [0.93430394]\n",
      " [0.93880594]\n",
      " [0.94444901]\n",
      " [0.94869459]\n",
      " [0.95207739]\n",
      " [0.9571867 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9605701]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.92512971]\n",
      "  [0.9297595 ]\n",
      "  [0.93430394]\n",
      "  [0.93880594]\n",
      "  [0.94444901]\n",
      "  [0.94869459]\n",
      "  [0.95207739]\n",
      "  [0.9571867 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028697684407234192\n",
      "Predicción post entrenamiento : [[0.9589864]]\n",
      "PERDIDAAAA despues: 0.028163624927401543\n",
      "loss en el callback: 0.07962068170309067, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.9297595 ]\n",
      " [0.93430394]\n",
      " [0.93880594]\n",
      " [0.94444901]\n",
      " [0.94869459]\n",
      " [0.95207739]\n",
      " [0.9571867 ]\n",
      " [0.9605701 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9633992]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.9297595 ]\n",
      "  [0.93430394]\n",
      "  [0.93880594]\n",
      "  [0.94444901]\n",
      "  [0.94869459]\n",
      "  [0.95207739]\n",
      "  [0.9571867 ]\n",
      "  [0.9605701 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.041144561022520065\n",
      "Predicción post entrenamiento : [[0.9621667]]\n",
      "PERDIDAAAA despues: 0.04064609855413437\n",
      "loss en el callback: 0.05336499586701393, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.93430394]\n",
      " [0.93880594]\n",
      " [0.94444901]\n",
      " [0.94869459]\n",
      " [0.95207739]\n",
      " [0.9571867 ]\n",
      " [0.9605701 ]\n",
      " [0.96339917]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.96653944]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.93430394]\n",
      "  [0.93880594]\n",
      "  [0.94444901]\n",
      "  [0.94869459]\n",
      "  [0.95207739]\n",
      "  [0.9571867 ]\n",
      "  [0.9605701 ]\n",
      "  [0.96339917]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030620018020272255\n",
      "Predicción post entrenamiento : [[0.9658507]]\n",
      "PERDIDAAAA despues: 0.030379455536603928\n",
      "loss en el callback: 0.019304830580949783, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.93880594]\n",
      " [0.94444901]\n",
      " [0.94869459]\n",
      " [0.95207739]\n",
      " [0.9571867 ]\n",
      " [0.9605701 ]\n",
      " [0.96339917]\n",
      " [0.96653944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9701688]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.93880594]\n",
      "  [0.94444901]\n",
      "  [0.94869459]\n",
      "  [0.95207739]\n",
      "  [0.9571867 ]\n",
      "  [0.9605701 ]\n",
      "  [0.96339917]\n",
      "  [0.96653944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04059199243783951\n",
      "Predicción post entrenamiento : [[0.9683173]]\n",
      "PERDIDAAAA despues: 0.03984933719038963\n",
      "loss en el callback: 0.10572462528944016, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.94444901]\n",
      " [0.94869459]\n",
      " [0.95207739]\n",
      " [0.9571867 ]\n",
      " [0.9605701 ]\n",
      " [0.96339917]\n",
      " [0.96653944]\n",
      " [0.97016883]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9725404]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.94444901]\n",
      "  [0.94869459]\n",
      "  [0.95207739]\n",
      "  [0.9571867 ]\n",
      "  [0.9605701 ]\n",
      "  [0.96339917]\n",
      "  [0.96653944]\n",
      "  [0.97016883]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.041553232818841934\n",
      "Predicción post entrenamiento : [[0.9713803]]\n",
      "PERDIDAAAA despues: 0.04108161851763725\n",
      "loss en el callback: 0.051769088953733444, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.94869459]\n",
      " [0.95207739]\n",
      " [0.9571867 ]\n",
      " [0.9605701 ]\n",
      " [0.96339917]\n",
      " [0.96653944]\n",
      " [0.97016883]\n",
      " [0.97254038]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9750811]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.94869459]\n",
      "  [0.95207739]\n",
      "  [0.9571867 ]\n",
      "  [0.9605701 ]\n",
      "  [0.96339917]\n",
      "  [0.96653944]\n",
      "  [0.97016883]\n",
      "  [0.97254038]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03103443793952465\n",
      "Predicción post entrenamiento : [[0.9741903]]\n",
      "PERDIDAAAA despues: 0.030721377581357956\n",
      "loss en el callback: 0.032355621457099915, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.95207739]\n",
      " [0.9571867 ]\n",
      " [0.9605701 ]\n",
      " [0.96339917]\n",
      " [0.96653944]\n",
      " [0.97016883]\n",
      " [0.97254038]\n",
      " [0.97508109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9776959]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.95207739]\n",
      "  [0.9571867 ]\n",
      "  [0.9605701 ]\n",
      "  [0.96339917]\n",
      "  [0.96653944]\n",
      "  [0.97016883]\n",
      "  [0.97254038]\n",
      "  [0.97508109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03522828221321106\n",
      "Predicción post entrenamiento : [[0.9769866]]\n",
      "PERDIDAAAA despues: 0.034962527453899384\n",
      "loss en el callback: 0.02276088297367096, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.9571867 ]\n",
      " [0.9605701 ]\n",
      " [0.96339917]\n",
      " [0.96653944]\n",
      " [0.97016883]\n",
      " [0.97254038]\n",
      " [0.97508109]\n",
      " [0.97769588]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.98050505]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.9571867 ]\n",
      "  [0.9605701 ]\n",
      "  [0.96339917]\n",
      "  [0.96653944]\n",
      "  [0.97016883]\n",
      "  [0.97254038]\n",
      "  [0.97508109]\n",
      "  [0.97769588]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04854733124375343\n",
      "Predicción post entrenamiento : [[0.9790509]]\n",
      "PERDIDAAAA despues: 0.047908637672662735\n",
      "loss en el callback: 0.07565724849700928, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.9605701 ]\n",
      " [0.96339917]\n",
      " [0.96653944]\n",
      " [0.97016883]\n",
      " [0.97254038]\n",
      " [0.97508109]\n",
      " [0.97769588]\n",
      " [0.98050505]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.98199266]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.9605701 ]\n",
      "  [0.96339917]\n",
      "  [0.96653944]\n",
      "  [0.97016883]\n",
      "  [0.97254038]\n",
      "  [0.97508109]\n",
      "  [0.97769588]\n",
      "  [0.98050505]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08797119557857513\n",
      "Predicción post entrenamiento : [[0.9801036]]\n",
      "PERDIDAAAA despues: 0.08685418218374252\n",
      "loss en el callback: 0.13040003180503845, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.96339917]\n",
      " [0.96653944]\n",
      " [0.97016883]\n",
      " [0.97254038]\n",
      " [0.97508109]\n",
      " [0.97769588]\n",
      " [0.98050505]\n",
      " [0.98199266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9829034]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.96339917]\n",
      "  [0.96653944]\n",
      "  [0.97016883]\n",
      "  [0.97254038]\n",
      "  [0.97508109]\n",
      "  [0.97769588]\n",
      "  [0.98050505]\n",
      "  [0.98199266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14266608655452728\n",
      "Predicción post entrenamiento : [[0.97983974]]\n",
      "PERDIDAAAA despues: 0.14036110043525696\n",
      "loss en el callback: 0.2974914312362671, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.96653944]\n",
      " [0.97016883]\n",
      " [0.97254038]\n",
      " [0.97508109]\n",
      " [0.97769588]\n",
      " [0.98050505]\n",
      " [0.98199266]\n",
      " [0.98290342]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.98261845]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.96653944]\n",
      "  [0.97016883]\n",
      "  [0.97254038]\n",
      "  [0.97508109]\n",
      "  [0.97769588]\n",
      "  [0.98050505]\n",
      "  [0.98199266]\n",
      "  [0.98290342]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10097133368253708\n",
      "Predicción post entrenamiento : [[0.9824338]]\n",
      "PERDIDAAAA despues: 0.10085401684045792\n",
      "loss en el callback: 0.0021768948063254356, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.97016883]\n",
      " [0.97254038]\n",
      " [0.97508109]\n",
      " [0.97769588]\n",
      " [0.98050505]\n",
      " [0.98199266]\n",
      " [0.98290342]\n",
      " [0.98261845]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.98503816]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.97016883]\n",
      "  [0.97254038]\n",
      "  [0.97508109]\n",
      "  [0.97769588]\n",
      "  [0.98050505]\n",
      "  [0.98199266]\n",
      "  [0.98290342]\n",
      "  [0.98261845]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0768248587846756\n",
      "Predicción post entrenamiento : [[0.98343116]]\n",
      "PERDIDAAAA despues: 0.07593660801649094\n",
      "loss en el callback: 0.10413219034671783, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.97254038]\n",
      " [0.97508109]\n",
      " [0.97769588]\n",
      " [0.98050505]\n",
      " [0.98199266]\n",
      " [0.98290342]\n",
      " [0.98261845]\n",
      " [0.98503816]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.98562384]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.97254038]\n",
      "  [0.97508109]\n",
      "  [0.97769588]\n",
      "  [0.98050505]\n",
      "  [0.98199266]\n",
      "  [0.98290342]\n",
      "  [0.98261845]\n",
      "  [0.98503816]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10289034992456436\n",
      "Predicción post entrenamiento : [[0.98497117]]\n",
      "PERDIDAAAA despues: 0.10247206687927246\n",
      "loss en el callback: 0.0252838172018528, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.97508109]\n",
      " [0.97769588]\n",
      " [0.98050505]\n",
      " [0.98199266]\n",
      " [0.98290342]\n",
      " [0.98261845]\n",
      " [0.98503816]\n",
      " [0.98562384]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.98704004]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.97508109]\n",
      "  [0.97769588]\n",
      "  [0.98050505]\n",
      "  [0.98199266]\n",
      "  [0.98290342]\n",
      "  [0.98261845]\n",
      "  [0.98503816]\n",
      "  [0.98562384]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07600380480289459\n",
      "Predicción post entrenamiento : [[0.9864892]]\n",
      "PERDIDAAAA despues: 0.07570037245750427\n",
      "loss en el callback: 0.016133656725287437, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.97769588]\n",
      " [0.98050505]\n",
      " [0.98199266]\n",
      " [0.98290342]\n",
      " [0.98261845]\n",
      " [0.98503816]\n",
      " [0.98562384]\n",
      " [0.98704004]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9883153]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.97769588]\n",
      "  [0.98050505]\n",
      "  [0.98199266]\n",
      "  [0.98290342]\n",
      "  [0.98261845]\n",
      "  [0.98503816]\n",
      "  [0.98562384]\n",
      "  [0.98704004]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09675733000040054\n",
      "Predicción post entrenamiento : [[0.9864214]]\n",
      "PERDIDAAAA despues: 0.09558270126581192\n",
      "loss en el callback: 0.14186102151870728, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.98050505]\n",
      " [0.98199266]\n",
      " [0.98290342]\n",
      " [0.98261845]\n",
      " [0.98503816]\n",
      " [0.98562384]\n",
      " [0.98704004]\n",
      " [0.98831528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.98790497]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.98050505]\n",
      "  [0.98199266]\n",
      "  [0.98290342]\n",
      "  [0.98261845]\n",
      "  [0.98503816]\n",
      "  [0.98562384]\n",
      "  [0.98704004]\n",
      "  [0.98831528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05098439007997513\n",
      "Predicción post entrenamiento : [[0.9865188]]\n",
      "PERDIDAAAA despues: 0.05036032944917679\n",
      "loss en el callback: 0.07521457970142365, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.98199266]\n",
      " [0.98290342]\n",
      " [0.98261845]\n",
      " [0.98503816]\n",
      " [0.98562384]\n",
      " [0.98704004]\n",
      " [0.98831528]\n",
      " [0.98790497]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9875154]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.98199266]\n",
      "  [0.98290342]\n",
      "  [0.98261845]\n",
      "  [0.98503816]\n",
      "  [0.98562384]\n",
      "  [0.98704004]\n",
      "  [0.98831528]\n",
      "  [0.98790497]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03256720304489136\n",
      "Predicción post entrenamiento : [[0.9864207]]\n",
      "PERDIDAAAA despues: 0.032173290848731995\n",
      "loss en el callback: 0.0495569072663784, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.98290342]\n",
      " [0.98261845]\n",
      " [0.98503816]\n",
      " [0.98562384]\n",
      " [0.98704004]\n",
      " [0.98831528]\n",
      " [0.98790497]\n",
      " [0.98751539]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9872576]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.98290342]\n",
      "  [0.98261845]\n",
      "  [0.98503816]\n",
      "  [0.98562384]\n",
      "  [0.98704004]\n",
      "  [0.98831528]\n",
      "  [0.98790497]\n",
      "  [0.98751539]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029607970267534256\n",
      "Predicción post entrenamiento : [[0.9876291]]\n",
      "PERDIDAAAA despues: 0.02973596192896366\n",
      "loss en el callback: 0.010636039078235626, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.98261845]\n",
      " [0.98503816]\n",
      " [0.98562384]\n",
      " [0.98704004]\n",
      " [0.98831528]\n",
      " [0.98790497]\n",
      " [0.98751539]\n",
      " [0.9872576 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9884449]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.98261845]\n",
      "  [0.98503816]\n",
      "  [0.98562384]\n",
      "  [0.98704004]\n",
      "  [0.98831528]\n",
      "  [0.98790497]\n",
      "  [0.98751539]\n",
      "  [0.9872576 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006757994648069143\n",
      "Predicción post entrenamiento : [[0.9883933]]\n",
      "PERDIDAAAA despues: 0.006749510765075684\n",
      "loss en el callback: 0.00013709870108868927, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.98503816]\n",
      " [0.98562384]\n",
      " [0.98704004]\n",
      " [0.98831528]\n",
      " [0.98790497]\n",
      " [0.98751539]\n",
      " [0.9872576 ]\n",
      " [0.98844492]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.989541]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.98503816]\n",
      "  [0.98562384]\n",
      "  [0.98704004]\n",
      "  [0.98831528]\n",
      "  [0.98790497]\n",
      "  [0.98751539]\n",
      "  [0.9872576 ]\n",
      "  [0.98844492]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008901547989808023\n",
      "Predicción post entrenamiento : [[0.9894241]]\n",
      "PERDIDAAAA despues: 0.0008831938612274826\n",
      "loss en el callback: 0.0005986657342873514, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.98562384]\n",
      " [0.98704004]\n",
      " [0.98831528]\n",
      " [0.98790497]\n",
      " [0.98751539]\n",
      " [0.9872576 ]\n",
      " [0.98844492]\n",
      " [0.98954099]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9900602]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.98562384]\n",
      "  [0.98704004]\n",
      "  [0.98831528]\n",
      "  [0.98790497]\n",
      "  [0.98751539]\n",
      "  [0.9872576 ]\n",
      "  [0.98844492]\n",
      "  [0.98954099]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006607644027099013\n",
      "Predicción post entrenamiento : [[0.99042296]]\n",
      "PERDIDAAAA despues: 0.0006795453955419362\n",
      "loss en el callback: 0.007431970909237862, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.98704004]\n",
      " [0.98831528]\n",
      " [0.98790497]\n",
      " [0.98751539]\n",
      " [0.9872576 ]\n",
      " [0.98844492]\n",
      " [0.98954099]\n",
      " [0.99006021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.99103653]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.98704004]\n",
      "  [0.98831528]\n",
      "  [0.98790497]\n",
      "  [0.98751539]\n",
      "  [0.9872576 ]\n",
      "  [0.98844492]\n",
      "  [0.98954099]\n",
      "  [0.99006021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010610777884721756\n",
      "Predicción post entrenamiento : [[0.9909055]]\n",
      "PERDIDAAAA despues: 0.010583803988993168\n",
      "loss en el callback: 0.0009365175501443446, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.98831528]\n",
      " [0.98790497]\n",
      " [0.98751539]\n",
      " [0.9872576 ]\n",
      " [0.98844492]\n",
      " [0.98954099]\n",
      " [0.99006021]\n",
      " [0.99103653]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.99122447]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.98831528]\n",
      "  [0.98790497]\n",
      "  [0.98751539]\n",
      "  [0.9872576 ]\n",
      "  [0.98844492]\n",
      "  [0.98954099]\n",
      "  [0.99006021]\n",
      "  [0.99103653]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009711554273962975\n",
      "Predicción post entrenamiento : [[0.9904462]]\n",
      "PERDIDAAAA despues: 0.00955876987427473\n",
      "loss en el callback: 0.02424739859998226, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.98790497]\n",
      " [0.98751539]\n",
      " [0.9872576 ]\n",
      " [0.98844492]\n",
      " [0.98954099]\n",
      " [0.99006021]\n",
      " [0.99103653]\n",
      " [0.99122447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9904816]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.98790497]\n",
      "  [0.98751539]\n",
      "  [0.9872576 ]\n",
      "  [0.98844492]\n",
      "  [0.98954099]\n",
      "  [0.99006021]\n",
      "  [0.99103653]\n",
      "  [0.99122447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013280129060149193\n",
      "Predicción post entrenamiento : [[0.98965466]]\n",
      "PERDIDAAAA despues: 0.013090217486023903\n",
      "loss en el callback: 0.02936827950179577, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.98751539]\n",
      " [0.9872576 ]\n",
      " [0.98844492]\n",
      " [0.98954099]\n",
      " [0.99006021]\n",
      " [0.99103653]\n",
      " [0.99122447]\n",
      " [0.99048162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9899166]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.98751539]\n",
      "  [0.9872576 ]\n",
      "  [0.98844492]\n",
      "  [0.98954099]\n",
      "  [0.99006021]\n",
      "  [0.99103653]\n",
      "  [0.99122447]\n",
      "  [0.99048162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019344255328178406\n",
      "Predicción post entrenamiento : [[0.9892285]]\n",
      "PERDIDAAAA despues: 0.019153311848640442\n",
      "loss en el callback: 0.022766441106796265, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.9872576 ]\n",
      " [0.98844492]\n",
      " [0.98954099]\n",
      " [0.99006021]\n",
      " [0.99103653]\n",
      " [0.99122447]\n",
      " [0.99048162]\n",
      " [0.98991662]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.98974615]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.9872576 ]\n",
      "  [0.98844492]\n",
      "  [0.98954099]\n",
      "  [0.99006021]\n",
      "  [0.99103653]\n",
      "  [0.99122447]\n",
      "  [0.99048162]\n",
      "  [0.98991662]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01983882486820221\n",
      "Predicción post entrenamiento : [[0.98863244]]\n",
      "PERDIDAAAA despues: 0.01952633261680603\n",
      "loss en el callback: 0.05696558579802513, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.98844492]\n",
      " [0.98954099]\n",
      " [0.99006021]\n",
      " [0.99103653]\n",
      " [0.99122447]\n",
      " [0.99048162]\n",
      " [0.98991662]\n",
      " [0.98974615]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9893817]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.98844492]\n",
      "  [0.98954099]\n",
      "  [0.99006021]\n",
      "  [0.99103653]\n",
      "  [0.99122447]\n",
      "  [0.99048162]\n",
      "  [0.98991662]\n",
      "  [0.98974615]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007270577480085194\n",
      "Predicción post entrenamiento : [[0.9892198]]\n",
      "PERDIDAAAA despues: 0.0007183537818491459\n",
      "loss en el callback: 0.0012795226648449898, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.98954099]\n",
      " [0.99006021]\n",
      " [0.99103653]\n",
      " [0.99122447]\n",
      " [0.99048162]\n",
      " [0.98991662]\n",
      " [0.98974615]\n",
      " [0.98938167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9897371]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.98954099]\n",
      "  [0.99006021]\n",
      "  [0.99103653]\n",
      "  [0.99122447]\n",
      "  [0.99048162]\n",
      "  [0.98991662]\n",
      "  [0.98974615]\n",
      "  [0.98938167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004793984699063003\n",
      "Predicción post entrenamiento : [[0.98948604]]\n",
      "PERDIDAAAA despues: 0.00046846774057485163\n",
      "loss en el callback: 0.0029837056063115597, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.99006021]\n",
      " [0.99103653]\n",
      " [0.99122447]\n",
      " [0.99048162]\n",
      " [0.98991662]\n",
      " [0.98974615]\n",
      " [0.98938167]\n",
      " [0.98973709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9897292]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.99006021]\n",
      "  [0.99103653]\n",
      "  [0.99122447]\n",
      "  [0.99048162]\n",
      "  [0.98991662]\n",
      "  [0.98974615]\n",
      "  [0.98938167]\n",
      "  [0.98973709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002401837846264243\n",
      "Predicción post entrenamiento : [[0.9894373]]\n",
      "PERDIDAAAA despues: 0.002373307477682829\n",
      "loss en el callback: 0.003902168245986104, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.99103653]\n",
      " [0.99122447]\n",
      " [0.99048162]\n",
      " [0.98991662]\n",
      " [0.98974615]\n",
      " [0.98938167]\n",
      " [0.98973709]\n",
      " [0.98972923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9895251]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.99103653]\n",
      "  [0.99122447]\n",
      "  [0.99048162]\n",
      "  [0.98991662]\n",
      "  [0.98974615]\n",
      "  [0.98938167]\n",
      "  [0.98973709]\n",
      "  [0.98972923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002901508705690503\n",
      "Predicción post entrenamiento : [[0.98928237]]\n",
      "PERDIDAAAA despues: 0.00028194120386615396\n",
      "loss en el callback: 0.0028663647826761007, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.99122447]\n",
      " [0.99048162]\n",
      " [0.98991662]\n",
      " [0.98974615]\n",
      " [0.98938167]\n",
      " [0.98973709]\n",
      " [0.98972923]\n",
      " [0.98952508]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9890337]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.99122447]\n",
      "  [0.99048162]\n",
      "  [0.98991662]\n",
      "  [0.98974615]\n",
      "  [0.98938167]\n",
      "  [0.98973709]\n",
      "  [0.98972923]\n",
      "  [0.98952508]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.188559927977622e-05\n",
      "Predicción post entrenamiento : [[0.9885438]]\n",
      "PERDIDAAAA despues: 6.983328057685867e-05\n",
      "loss en el callback: 0.010526755824685097, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.99048162]\n",
      " [0.98991662]\n",
      " [0.98974615]\n",
      " [0.98938167]\n",
      " [0.98973709]\n",
      " [0.98972923]\n",
      " [0.98952508]\n",
      " [0.9890337 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.98816067]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.99048162]\n",
      "  [0.98991662]\n",
      "  [0.98974615]\n",
      "  [0.98938167]\n",
      "  [0.98973709]\n",
      "  [0.98972923]\n",
      "  [0.98952508]\n",
      "  [0.9890337 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001367443474009633\n",
      "Predicción post entrenamiento : [[0.9883445]]\n",
      "PERDIDAAAA despues: 0.0013810722157359123\n",
      "loss en el callback: 0.002001386834308505, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.98991662]\n",
      " [0.98974615]\n",
      " [0.98938167]\n",
      " [0.98973709]\n",
      " [0.98972923]\n",
      " [0.98952508]\n",
      " [0.9890337 ]\n",
      " [0.98816067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.98810774]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.98991662]\n",
      "  [0.98974615]\n",
      "  [0.98938167]\n",
      "  [0.98973709]\n",
      "  [0.98972923]\n",
      "  [0.98952508]\n",
      "  [0.9890337 ]\n",
      "  [0.98816067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008525000885128975\n",
      "Predicción post entrenamiento : [[0.9870928]]\n",
      "PERDIDAAAA despues: 0.008338608779013157\n",
      "loss en el callback: 0.04760318994522095, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.98974615]\n",
      " [0.98938167]\n",
      " [0.98973709]\n",
      " [0.98972923]\n",
      " [0.98952508]\n",
      " [0.9890337 ]\n",
      " [0.98816067]\n",
      " [0.98810774]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9869682]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.98974615]\n",
      "  [0.98938167]\n",
      "  [0.98973709]\n",
      "  [0.98972923]\n",
      "  [0.98952508]\n",
      "  [0.9890337 ]\n",
      "  [0.98816067]\n",
      "  [0.98810774]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011135932058095932\n",
      "Predicción post entrenamiento : [[0.98642045]]\n",
      "PERDIDAAAA despues: 0.01102062314748764\n",
      "loss en el callback: 0.015887323766946793, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.98938167]\n",
      " [0.98973709]\n",
      " [0.98972923]\n",
      " [0.98952508]\n",
      " [0.9890337 ]\n",
      " [0.98816067]\n",
      " [0.98810774]\n",
      " [0.98696822]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.98628736]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.98938167]\n",
      "  [0.98973709]\n",
      "  [0.98972923]\n",
      "  [0.98952508]\n",
      "  [0.9890337 ]\n",
      "  [0.98816067]\n",
      "  [0.98810774]\n",
      "  [0.98696822]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004788768943399191\n",
      "Predicción post entrenamiento : [[0.98602986]]\n",
      "PERDIDAAAA despues: 0.004753198008984327\n",
      "loss en el callback: 0.003777582896873355, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.98973709]\n",
      " [0.98972923]\n",
      " [0.98952508]\n",
      " [0.9890337 ]\n",
      " [0.98816067]\n",
      " [0.98810774]\n",
      " [0.98696822]\n",
      " [0.98628736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9859293]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.98973709]\n",
      "  [0.98972923]\n",
      "  [0.98952508]\n",
      "  [0.9890337 ]\n",
      "  [0.98816067]\n",
      "  [0.98810774]\n",
      "  [0.98696822]\n",
      "  [0.98628736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004373277071863413\n",
      "Predicción post entrenamiento : [[0.9850368]]\n",
      "PERDIDAAAA despues: 0.00425602775067091\n",
      "loss en el callback: 0.0351564958691597, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.98972923]\n",
      " [0.98952508]\n",
      " [0.9890337 ]\n",
      " [0.98816067]\n",
      " [0.98810774]\n",
      " [0.98696822]\n",
      " [0.98628736]\n",
      " [0.98592931]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9847246]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.98972923]\n",
      "  [0.98952508]\n",
      "  [0.9890337 ]\n",
      "  [0.98816067]\n",
      "  [0.98810774]\n",
      "  [0.98696822]\n",
      "  [0.98628736]\n",
      "  [0.98592931]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005327685503289104\n",
      "Predicción post entrenamiento : [[0.98521143]]\n",
      "PERDIDAAAA despues: 0.0005554803065024316\n",
      "loss en el callback: 0.018397942185401917, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.98952508]\n",
      " [0.9890337 ]\n",
      " [0.98816067]\n",
      " [0.98810774]\n",
      " [0.98696822]\n",
      " [0.98628736]\n",
      " [0.98592931]\n",
      " [0.98472458]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9847517]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.98952508]\n",
      "  [0.9890337 ]\n",
      "  [0.98816067]\n",
      "  [0.98810774]\n",
      "  [0.98696822]\n",
      "  [0.98628736]\n",
      "  [0.98592931]\n",
      "  [0.98472458]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027298799250274897\n",
      "Predicción post entrenamiento : [[0.98420274]]\n",
      "PERDIDAAAA despues: 0.0002551491488702595\n",
      "loss en el callback: 0.013870085589587688, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.9890337 ]\n",
      " [0.98816067]\n",
      " [0.98810774]\n",
      " [0.98696822]\n",
      " [0.98628736]\n",
      " [0.98592931]\n",
      " [0.98472458]\n",
      " [0.9847517 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.98362815]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.9890337 ]\n",
      "  [0.98816067]\n",
      "  [0.98810774]\n",
      "  [0.98696822]\n",
      "  [0.98628736]\n",
      "  [0.98592931]\n",
      "  [0.98472458]\n",
      "  [0.9847517 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006687309360131621\n",
      "Predicción post entrenamiento : [[0.9837048]]\n",
      "PERDIDAAAA despues: 0.0006727012223564088\n",
      "loss en el callback: 0.0003583320358302444, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21038333]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0269869863986969\n",
      "Predicción post entrenamiento : [[0.17682633]]\n",
      "PERDIDAAAA despues: 0.01708776317536831\n",
      "loss en el callback: 0.03709711134433746, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21038333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16096981]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21038333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003220180980861187\n",
      "Predicción post entrenamiento : [[0.15161824]]\n",
      "PERDIDAAAA despues: 0.002246293006464839\n",
      "loss en el callback: 0.003668760182335973, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21038333]\n",
      " [0.16096981]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15514874]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21038333]\n",
      "  [0.16096981]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.929158070714038e-07\n",
      "Predicción post entrenamiento : [[0.15469103]]\n",
      "PERDIDAAAA despues: 2.3738651577787095e-07\n",
      "loss en el callback: 2.0588031475199386e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21038333]\n",
      " [0.16096981]\n",
      " [0.15514874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1651509]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21038333]\n",
      "  [0.16096981]\n",
      "  [0.15514874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.830949082039297e-05\n",
      "Predicción post entrenamiento : [[0.16478087]]\n",
      "PERDIDAAAA despues: 8.14919185359031e-05\n",
      "loss en el callback: 2.582804881967604e-05, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21038333]\n",
      " [0.16096981]\n",
      " [0.15514874]\n",
      " [0.1651509 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17578596]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21038333]\n",
      "  [0.16096981]\n",
      "  [0.15514874]\n",
      "  [0.1651509 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002525385469198227\n",
      "Predicción post entrenamiento : [[0.17176066]]\n",
      "PERDIDAAAA despues: 0.002137020230293274\n",
      "loss en el callback: 0.0039268797263503075, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21038333]\n",
      " [0.16096981]\n",
      " [0.15514874]\n",
      " [0.1651509 ]\n",
      " [0.17578596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.17923489]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21038333]\n",
      "  [0.16096981]\n",
      "  [0.15514874]\n",
      "  [0.1651509 ]\n",
      "  [0.17578596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011259331367909908\n",
      "Predicción post entrenamiento : [[0.1753481]]\n",
      "PERDIDAAAA despues: 0.0008801983785815537\n",
      "loss en el callback: 0.004483594559133053, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21038333]\n",
      " [0.16096981]\n",
      " [0.15514874]\n",
      " [0.1651509 ]\n",
      " [0.17578596]\n",
      " [0.17923489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.19301409]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21038333]\n",
      "  [0.16096981]\n",
      "  [0.15514874]\n",
      "  [0.1651509 ]\n",
      "  [0.17578596]\n",
      "  [0.17923489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002167761791497469\n",
      "Predicción post entrenamiento : [[0.19021805]]\n",
      "PERDIDAAAA despues: 0.001915216795168817\n",
      "loss en el callback: 0.0034824719186872244, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.21038333]\n",
      " [0.16096981]\n",
      " [0.15514874]\n",
      " [0.1651509 ]\n",
      " [0.17578596]\n",
      " [0.17923489]\n",
      " [0.19301409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21145155]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.21038333]\n",
      "  [0.16096981]\n",
      "  [0.15514874]\n",
      "  [0.1651509 ]\n",
      "  [0.17578596]\n",
      "  [0.17923489]\n",
      "  [0.19301409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002372680901316926\n",
      "Predicción post entrenamiento : [[0.20955476]]\n",
      "PERDIDAAAA despues: 0.00018243162776343524\n",
      "loss en el callback: 0.0018110615201294422, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21038333]\n",
      " [0.16096981]\n",
      " [0.15514874]\n",
      " [0.1651509 ]\n",
      " [0.17578596]\n",
      " [0.17923489]\n",
      " [0.19301409]\n",
      " [0.21145155]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.23466589]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21038333]\n",
      "  [0.16096981]\n",
      "  [0.15514874]\n",
      "  [0.1651509 ]\n",
      "  [0.17578596]\n",
      "  [0.17923489]\n",
      "  [0.19301409]\n",
      "  [0.21145155]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.709894604573492e-05\n",
      "Predicción post entrenamiento : [[0.23311172]]\n",
      "PERDIDAAAA despues: 6.661178304057103e-06\n",
      "loss en el callback: 0.0014566835016012192, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16096981]\n",
      " [0.15514874]\n",
      " [0.1651509 ]\n",
      " [0.17578596]\n",
      " [0.17923489]\n",
      " [0.19301409]\n",
      " [0.21145155]\n",
      " [0.23466589]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.22597355]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16096981]\n",
      "  [0.15514874]\n",
      "  [0.1651509 ]\n",
      "  [0.17578596]\n",
      "  [0.17923489]\n",
      "  [0.19301409]\n",
      "  [0.21145155]\n",
      "  [0.23466589]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003072030085604638\n",
      "Predicción post entrenamiento : [[0.2255821]]\n",
      "PERDIDAAAA despues: 0.0002936340752057731\n",
      "loss en el callback: 0.00014302768977358937, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.15514874]\n",
      " [0.1651509 ]\n",
      " [0.17578596]\n",
      " [0.17923489]\n",
      " [0.19301409]\n",
      " [0.21145155]\n",
      " [0.23466589]\n",
      " [0.22597355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.22925805]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.15514874]\n",
      "  [0.1651509 ]\n",
      "  [0.17578596]\n",
      "  [0.17923489]\n",
      "  [0.19301409]\n",
      "  [0.21145155]\n",
      "  [0.23466589]\n",
      "  [0.22597355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030014474759809673\n",
      "Predicción post entrenamiento : [[0.22875625]]\n",
      "PERDIDAAAA despues: 0.00028300960548222065\n",
      "loss en el callback: 0.0002971149515360594, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.1651509 ]\n",
      " [0.17578596]\n",
      " [0.17923489]\n",
      " [0.19301409]\n",
      " [0.21145155]\n",
      " [0.23466589]\n",
      " [0.22597355]\n",
      " [0.22925805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.23558709]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.1651509 ]\n",
      "  [0.17578596]\n",
      "  [0.17923489]\n",
      "  [0.19301409]\n",
      "  [0.21145155]\n",
      "  [0.23466589]\n",
      "  [0.22597355]\n",
      "  [0.22925805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008010647143237293\n",
      "Predicción post entrenamiento : [[0.23612201]]\n",
      "PERDIDAAAA despues: 0.0008316307212226093\n",
      "loss en el callback: 0.0005453478079289198, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17578596]\n",
      " [0.17923489]\n",
      " [0.19301409]\n",
      " [0.21145155]\n",
      " [0.23466589]\n",
      " [0.22597355]\n",
      " [0.22925805]\n",
      " [0.23558709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.24308369]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17578596]\n",
      "  [0.17923489]\n",
      "  [0.19301409]\n",
      "  [0.21145155]\n",
      "  [0.23466589]\n",
      "  [0.22597355]\n",
      "  [0.22925805]\n",
      "  [0.23558709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025135392788797617\n",
      "Predicción post entrenamiento : [[0.24004072]]\n",
      "PERDIDAAAA despues: 0.0022176795173436403\n",
      "loss en el callback: 0.010221989825367928, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.17923489]\n",
      " [0.19301409]\n",
      " [0.21145155]\n",
      " [0.23466589]\n",
      " [0.22597355]\n",
      " [0.22925805]\n",
      " [0.23558709]\n",
      " [0.24308369]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.24687476]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.17923489]\n",
      "  [0.19301409]\n",
      "  [0.21145155]\n",
      "  [0.23466589]\n",
      "  [0.22597355]\n",
      "  [0.22925805]\n",
      "  [0.23558709]\n",
      "  [0.24308369]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002505185082554817\n",
      "Predicción post entrenamiento : [[0.24453758]]\n",
      "PERDIDAAAA despues: 0.0022766864858567715\n",
      "loss en el callback: 0.00775217404589057, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.19301409]\n",
      " [0.21145155]\n",
      " [0.23466589]\n",
      " [0.22597355]\n",
      " [0.22925805]\n",
      " [0.23558709]\n",
      " [0.24308369]\n",
      " [0.24687476]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.25271833]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.19301409]\n",
      "  [0.21145155]\n",
      "  [0.23466589]\n",
      "  [0.22597355]\n",
      "  [0.22925805]\n",
      "  [0.23558709]\n",
      "  [0.24308369]\n",
      "  [0.24687476]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014791934518143535\n",
      "Predicción post entrenamiento : [[0.25125164]]\n",
      "PERDIDAAAA despues: 0.00136852590367198\n",
      "loss en el callback: 0.003675078274682164, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.21145155]\n",
      " [0.23466589]\n",
      " [0.22597355]\n",
      " [0.22925805]\n",
      " [0.23558709]\n",
      " [0.24308369]\n",
      " [0.24687476]\n",
      " [0.25271833]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2584664]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.21145155]\n",
      "  [0.23466589]\n",
      "  [0.22597355]\n",
      "  [0.22925805]\n",
      "  [0.23558709]\n",
      "  [0.24308369]\n",
      "  [0.24687476]\n",
      "  [0.25271833]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059507847763597965\n",
      "Predicción post entrenamiento : [[0.25512695]]\n",
      "PERDIDAAAA despues: 0.005446719005703926\n",
      "loss en el callback: 0.017661066725850105, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.23466589]\n",
      " [0.22597355]\n",
      " [0.22925805]\n",
      " [0.23558709]\n",
      " [0.24308369]\n",
      " [0.24687476]\n",
      " [0.25271833]\n",
      " [0.25846639]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.25993675]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.23466589]\n",
      "  [0.22597355]\n",
      "  [0.22925805]\n",
      "  [0.23558709]\n",
      "  [0.24308369]\n",
      "  [0.24687476]\n",
      "  [0.25271833]\n",
      "  [0.25846639]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007192875724285841\n",
      "Predicción post entrenamiento : [[0.25907668]]\n",
      "PERDIDAAAA despues: 0.007047729566693306\n",
      "loss en el callback: 0.0020952029153704643, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.22597355]\n",
      " [0.22925805]\n",
      " [0.23558709]\n",
      " [0.24308369]\n",
      " [0.24687476]\n",
      " [0.25271833]\n",
      " [0.25846639]\n",
      " [0.25993675]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.25987187]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.22597355]\n",
      "  [0.22925805]\n",
      "  [0.23558709]\n",
      "  [0.24308369]\n",
      "  [0.24687476]\n",
      "  [0.25271833]\n",
      "  [0.25846639]\n",
      "  [0.25993675]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012514274567365646\n",
      "Predicción post entrenamiento : [[0.25799808]]\n",
      "PERDIDAAAA despues: 0.012098554521799088\n",
      "loss en el callback: 0.010074739344418049, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.22925805]\n",
      " [0.23558709]\n",
      " [0.24308369]\n",
      " [0.24687476]\n",
      " [0.25271833]\n",
      " [0.25846639]\n",
      " [0.25993675]\n",
      " [0.25987187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2614916]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.22925805]\n",
      "  [0.23558709]\n",
      "  [0.24308369]\n",
      "  [0.24687476]\n",
      "  [0.25271833]\n",
      "  [0.25846639]\n",
      "  [0.25993675]\n",
      "  [0.25987187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010534648783504963\n",
      "Predicción post entrenamiento : [[0.2598841]]\n",
      "PERDIDAAAA despues: 0.010207248851656914\n",
      "loss en el callback: 0.007911155000329018, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.23558709]\n",
      " [0.24308369]\n",
      " [0.24687476]\n",
      " [0.25271833]\n",
      " [0.25846639]\n",
      " [0.25993675]\n",
      " [0.25987187]\n",
      " [0.2614916 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.26373065]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.23558709]\n",
      "  [0.24308369]\n",
      "  [0.24687476]\n",
      "  [0.25271833]\n",
      "  [0.25846639]\n",
      "  [0.25993675]\n",
      "  [0.25987187]\n",
      "  [0.2614916 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005120414774864912\n",
      "Predicción post entrenamiento : [[0.26063338]]\n",
      "PERDIDAAAA despues: 0.004686745349317789\n",
      "loss en el callback: 0.02155974693596363, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24308369]\n",
      " [0.24687476]\n",
      " [0.25271833]\n",
      " [0.25846639]\n",
      " [0.25993675]\n",
      " [0.25987187]\n",
      " [0.2614916 ]\n",
      " [0.26373065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26409015]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24308369]\n",
      "  [0.24687476]\n",
      "  [0.25271833]\n",
      "  [0.25846639]\n",
      "  [0.25993675]\n",
      "  [0.25987187]\n",
      "  [0.2614916 ]\n",
      "  [0.26373065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006102065090090036\n",
      "Predicción post entrenamiento : [[0.26237336]]\n",
      "PERDIDAAAA despues: 0.005836795549839735\n",
      "loss en el callback: 0.009331872686743736, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.24687476]\n",
      " [0.25271833]\n",
      " [0.25846639]\n",
      " [0.25993675]\n",
      " [0.25987187]\n",
      " [0.2614916 ]\n",
      " [0.26373065]\n",
      " [0.26409015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2650053]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.24687476]\n",
      "  [0.25271833]\n",
      "  [0.25846639]\n",
      "  [0.25993675]\n",
      "  [0.25987187]\n",
      "  [0.2614916 ]\n",
      "  [0.26373065]\n",
      "  [0.26409015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.784953150898218e-06\n",
      "Predicción post entrenamiento : [[0.26537496]]\n",
      "PERDIDAAAA despues: 2.4832327198964776e-06\n",
      "loss en el callback: 0.000664923049043864, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.25271833]\n",
      " [0.25846639]\n",
      " [0.25993675]\n",
      " [0.25987187]\n",
      " [0.2614916 ]\n",
      " [0.26373065]\n",
      " [0.26409015]\n",
      " [0.26500529]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2678246]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.25271833]\n",
      "  [0.25846639]\n",
      "  [0.25993675]\n",
      "  [0.25987187]\n",
      "  [0.2614916 ]\n",
      "  [0.26373065]\n",
      "  [0.26409015]\n",
      "  [0.26500529]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006099759484641254\n",
      "Predicción post entrenamiento : [[0.26797843]]\n",
      "PERDIDAAAA despues: 0.000602400628849864\n",
      "loss en el callback: 8.655252895550802e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.25846639]\n",
      " [0.25993675]\n",
      " [0.25987187]\n",
      " [0.2614916 ]\n",
      " [0.26373065]\n",
      " [0.26409015]\n",
      " [0.26500529]\n",
      " [0.26782459]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26967058]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.25846639]\n",
      "  [0.25993675]\n",
      "  [0.25987187]\n",
      "  [0.2614916 ]\n",
      "  [0.26373065]\n",
      "  [0.26409015]\n",
      "  [0.26500529]\n",
      "  [0.26782459]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002307432470843196\n",
      "Predicción post entrenamiento : [[0.2707111]]\n",
      "PERDIDAAAA despues: 0.002208550926297903\n",
      "loss en el callback: 0.005854794289916754, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.25993675]\n",
      " [0.25987187]\n",
      " [0.2614916 ]\n",
      " [0.26373065]\n",
      " [0.26409015]\n",
      " [0.26500529]\n",
      " [0.26782459]\n",
      " [0.26967058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27150688]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.25993675]\n",
      "  [0.25987187]\n",
      "  [0.2614916 ]\n",
      "  [0.26373065]\n",
      "  [0.26409015]\n",
      "  [0.26500529]\n",
      "  [0.26782459]\n",
      "  [0.26967058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016943629598245025\n",
      "Predicción post entrenamiento : [[0.27160132]]\n",
      "PERDIDAAAA despues: 0.0016865967772901058\n",
      "loss en el callback: 3.622257645474747e-05, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.25987187]\n",
      " [0.2614916 ]\n",
      " [0.26373065]\n",
      " [0.26409015]\n",
      " [0.26500529]\n",
      " [0.26782459]\n",
      " [0.26967058]\n",
      " [0.27150688]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27235657]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.25987187]\n",
      "  [0.2614916 ]\n",
      "  [0.26373065]\n",
      "  [0.26409015]\n",
      "  [0.26500529]\n",
      "  [0.26782459]\n",
      "  [0.26967058]\n",
      "  [0.27150688]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027817871887236834\n",
      "Predicción post entrenamiento : [[0.27214047]]\n",
      "PERDIDAAAA despues: 0.00028543383814394474\n",
      "loss en el callback: 0.00020466189016588032, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.2614916 ]\n",
      " [0.26373065]\n",
      " [0.26409015]\n",
      " [0.26500529]\n",
      " [0.26782459]\n",
      " [0.26967058]\n",
      " [0.27150688]\n",
      " [0.27235657]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27322248]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.2614916 ]\n",
      "  [0.26373065]\n",
      "  [0.26409015]\n",
      "  [0.26500529]\n",
      "  [0.26782459]\n",
      "  [0.26967058]\n",
      "  [0.27150688]\n",
      "  [0.27235657]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.24219420994632e-05\n",
      "Predicción post entrenamiento : [[0.2732514]]\n",
      "PERDIDAAAA despues: 9.18663790798746e-05\n",
      "loss en el callback: 4.782246378454147e-06, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.26373065]\n",
      " [0.26409015]\n",
      " [0.26500529]\n",
      " [0.26782459]\n",
      " [0.26967058]\n",
      " [0.27150688]\n",
      " [0.27235657]\n",
      " [0.27322248]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2743215]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.26373065]\n",
      "  [0.26409015]\n",
      "  [0.26500529]\n",
      "  [0.26782459]\n",
      "  [0.26967058]\n",
      "  [0.27150688]\n",
      "  [0.27235657]\n",
      "  [0.27322248]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006337718805298209\n",
      "Predicción post entrenamiento : [[0.2744041]]\n",
      "PERDIDAAAA despues: 0.0006296192295849323\n",
      "loss en el callback: 3.938645022572018e-05, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.26409015]\n",
      " [0.26500529]\n",
      " [0.26782459]\n",
      " [0.26967058]\n",
      " [0.27150688]\n",
      " [0.27235657]\n",
      " [0.27322248]\n",
      " [0.2743215 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2753095]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.26409015]\n",
      "  [0.26500529]\n",
      "  [0.26782459]\n",
      "  [0.26967058]\n",
      "  [0.27150688]\n",
      "  [0.27235657]\n",
      "  [0.27322248]\n",
      "  [0.2743215 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.053279158393707e-07\n",
      "Predicción post entrenamiento : [[0.2754801]]\n",
      "PERDIDAAAA despues: 1.4590594332730689e-07\n",
      "loss en el callback: 0.00020890712039545178, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.26500529]\n",
      " [0.26782459]\n",
      " [0.26967058]\n",
      " [0.27150688]\n",
      " [0.27235657]\n",
      " [0.27322248]\n",
      " [0.2743215 ]\n",
      " [0.2753095 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27662897]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.26500529]\n",
      "  [0.26782459]\n",
      "  [0.26967058]\n",
      "  [0.27150688]\n",
      "  [0.27235657]\n",
      "  [0.27322248]\n",
      "  [0.2743215 ]\n",
      "  [0.2753095 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.722018391272286e-06\n",
      "Predicción post entrenamiento : [[0.27678725]]\n",
      "PERDIDAAAA despues: 4.3577961150731426e-06\n",
      "loss en el callback: 0.00017782591748982668, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.26782459]\n",
      " [0.26967058]\n",
      " [0.27150688]\n",
      " [0.27235657]\n",
      " [0.27322248]\n",
      " [0.2743215 ]\n",
      " [0.2753095 ]\n",
      " [0.27662897]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27807653]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.26782459]\n",
      "  [0.26967058]\n",
      "  [0.27150688]\n",
      "  [0.27235657]\n",
      "  [0.27322248]\n",
      "  [0.2743215 ]\n",
      "  [0.2753095 ]\n",
      "  [0.27662897]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.769995707145426e-06\n",
      "Predicción post entrenamiento : [[0.27700233]]\n",
      "PERDIDAAAA despues: 2.33394871429482e-06\n",
      "loss en el callback: 0.005857198033481836, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.26967058]\n",
      " [0.27150688]\n",
      " [0.27235657]\n",
      " [0.27322248]\n",
      " [0.2743215 ]\n",
      " [0.2753095 ]\n",
      " [0.27662897]\n",
      " [0.27807653]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27798805]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.26967058]\n",
      "  [0.27150688]\n",
      "  [0.27235657]\n",
      "  [0.27322248]\n",
      "  [0.2743215 ]\n",
      "  [0.2753095 ]\n",
      "  [0.27662897]\n",
      "  [0.27807653]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032223688904196024\n",
      "Predicción post entrenamiento : [[0.27842745]]\n",
      "PERDIDAAAA despues: 0.0031726756133139133\n",
      "loss en el callback: 0.0013378889998421073, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.27150688]\n",
      " [0.27235657]\n",
      " [0.27322248]\n",
      " [0.2743215 ]\n",
      " [0.2753095 ]\n",
      " [0.27662897]\n",
      " [0.27807653]\n",
      " [0.27798805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.279274]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.27150688]\n",
      "  [0.27235657]\n",
      "  [0.27322248]\n",
      "  [0.2743215 ]\n",
      "  [0.2753095 ]\n",
      "  [0.27662897]\n",
      "  [0.27807653]\n",
      "  [0.27798805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00583728076890111\n",
      "Predicción post entrenamiento : [[0.2796543]]\n",
      "PERDIDAAAA despues: 0.0057793124578893185\n",
      "loss en el callback: 0.0010017002932727337, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.27235657]\n",
      " [0.27322248]\n",
      " [0.2743215 ]\n",
      " [0.2753095 ]\n",
      " [0.27662897]\n",
      " [0.27807653]\n",
      " [0.27798805]\n",
      " [0.27927399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2803322]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.27235657]\n",
      "  [0.27322248]\n",
      "  [0.2743215 ]\n",
      "  [0.2753095 ]\n",
      "  [0.27662897]\n",
      "  [0.27807653]\n",
      "  [0.27798805]\n",
      "  [0.27927399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031763361766934395\n",
      "Predicción post entrenamiento : [[0.28091413]]\n",
      "PERDIDAAAA despues: 0.0031110818963497877\n",
      "loss en el callback: 0.0029502229299396276, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.27322248]\n",
      " [0.2743215 ]\n",
      " [0.2753095 ]\n",
      " [0.27662897]\n",
      " [0.27807653]\n",
      " [0.27798805]\n",
      " [0.27927399]\n",
      " [0.28033221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28162596]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.27322248]\n",
      "  [0.2743215 ]\n",
      "  [0.2753095 ]\n",
      "  [0.27662897]\n",
      "  [0.27807653]\n",
      "  [0.27798805]\n",
      "  [0.27927399]\n",
      "  [0.28033221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002700432203710079\n",
      "Predicción post entrenamiento : [[0.28210142]]\n",
      "PERDIDAAAA despues: 0.0026512425392866135\n",
      "loss en el callback: 0.0021319135557860136, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.2743215 ]\n",
      " [0.2753095 ]\n",
      " [0.27662897]\n",
      " [0.27807653]\n",
      " [0.27798805]\n",
      " [0.27927399]\n",
      " [0.28033221]\n",
      " [0.28162596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28284892]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.2743215 ]\n",
      "  [0.2753095 ]\n",
      "  [0.27662897]\n",
      "  [0.27807653]\n",
      "  [0.27798805]\n",
      "  [0.27927399]\n",
      "  [0.28033221]\n",
      "  [0.28162596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010380690917372704\n",
      "Predicción post entrenamiento : [[0.28405124]]\n",
      "PERDIDAAAA despues: 0.01013713888823986\n",
      "loss en el callback: 0.01962473802268505, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.2753095 ]\n",
      " [0.27662897]\n",
      " [0.27807653]\n",
      " [0.27798805]\n",
      " [0.27927399]\n",
      " [0.28033221]\n",
      " [0.28162596]\n",
      " [0.28284892]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2847856]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.2753095 ]\n",
      "  [0.27662897]\n",
      "  [0.27807653]\n",
      "  [0.27798805]\n",
      "  [0.27927399]\n",
      "  [0.28033221]\n",
      "  [0.28162596]\n",
      "  [0.28284892]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08197391778230667\n",
      "Predicción post entrenamiento : [[0.2876294]]\n",
      "PERDIDAAAA despues: 0.08035358786582947\n",
      "loss en el callback: 0.09938988089561462, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.27662897]\n",
      " [0.27807653]\n",
      " [0.27798805]\n",
      " [0.27927399]\n",
      " [0.28033221]\n",
      " [0.28162596]\n",
      " [0.28284892]\n",
      " [0.2847856 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28838092]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.27662897]\n",
      "  [0.27807653]\n",
      "  [0.27798805]\n",
      "  [0.27927399]\n",
      "  [0.28033221]\n",
      "  [0.28162596]\n",
      "  [0.28284892]\n",
      "  [0.2847856 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09480216354131699\n",
      "Predicción post entrenamiento : [[0.29111746]]\n",
      "PERDIDAAAA despues: 0.09312449395656586\n",
      "loss en el callback: 0.06810498237609863, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.27807653]\n",
      " [0.27798805]\n",
      " [0.27927399]\n",
      " [0.28033221]\n",
      " [0.28162596]\n",
      " [0.28284892]\n",
      " [0.2847856 ]\n",
      " [0.28838092]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.291829]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.27807653]\n",
      "  [0.27798805]\n",
      "  [0.27927399]\n",
      "  [0.28033221]\n",
      "  [0.28162596]\n",
      "  [0.28284892]\n",
      "  [0.2847856 ]\n",
      "  [0.28838092]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07995009422302246\n",
      "Predicción post entrenamiento : [[0.29441762]]\n",
      "PERDIDAAAA despues: 0.0784929022192955\n",
      "loss en el callback: 0.12911652028560638, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.27798805]\n",
      " [0.27927399]\n",
      " [0.28033221]\n",
      " [0.28162596]\n",
      " [0.28284892]\n",
      " [0.2847856 ]\n",
      " [0.28838092]\n",
      " [0.29182899]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.2950869]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.27798805]\n",
      "  [0.27927399]\n",
      "  [0.28033221]\n",
      "  [0.28162596]\n",
      "  [0.28284892]\n",
      "  [0.2847856 ]\n",
      "  [0.28838092]\n",
      "  [0.29182899]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09688728302717209\n",
      "Predicción post entrenamiento : [[0.29792508]]\n",
      "PERDIDAAAA despues: 0.09512846916913986\n",
      "loss en el callback: 0.09737898409366608, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.27927399]\n",
      " [0.28033221]\n",
      " [0.28162596]\n",
      " [0.28284892]\n",
      " [0.2847856 ]\n",
      " [0.28838092]\n",
      " [0.29182899]\n",
      " [0.29508689]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29896092]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.27927399]\n",
      "  [0.28033221]\n",
      "  [0.28162596]\n",
      "  [0.28284892]\n",
      "  [0.2847856 ]\n",
      "  [0.28838092]\n",
      "  [0.29182899]\n",
      "  [0.29508689]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08162232488393784\n",
      "Predicción post entrenamiento : [[0.3014491]]\n",
      "PERDIDAAAA despues: 0.08020679652690887\n",
      "loss en el callback: 0.07161843776702881, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.28033221]\n",
      " [0.28162596]\n",
      " [0.28284892]\n",
      " [0.2847856 ]\n",
      " [0.28838092]\n",
      " [0.29182899]\n",
      " [0.29508689]\n",
      " [0.29896092]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.30263528]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.28033221]\n",
      "  [0.28162596]\n",
      "  [0.28284892]\n",
      "  [0.2847856 ]\n",
      "  [0.28838092]\n",
      "  [0.29182899]\n",
      "  [0.29508689]\n",
      "  [0.29896092]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0708286315202713\n",
      "Predicción post entrenamiento : [[0.30485168]]\n",
      "PERDIDAAAA despues: 0.06965381652116776\n",
      "loss en el callback: 0.0681515634059906, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.28162596]\n",
      " [0.28284892]\n",
      " [0.2847856 ]\n",
      " [0.28838092]\n",
      " [0.29182899]\n",
      " [0.29508689]\n",
      " [0.29896092]\n",
      " [0.30263528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3063195]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.28162596]\n",
      "  [0.28284892]\n",
      "  [0.2847856 ]\n",
      "  [0.28838092]\n",
      "  [0.29182899]\n",
      "  [0.29508689]\n",
      "  [0.29896092]\n",
      "  [0.30263528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11320170015096664\n",
      "Predicción post entrenamiento : [[0.3091082]]\n",
      "PERDIDAAAA despues: 0.11133293807506561\n",
      "loss en el callback: 0.09631619602441788, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.28284892]\n",
      " [0.2847856 ]\n",
      " [0.28838092]\n",
      " [0.29182899]\n",
      " [0.29508689]\n",
      " [0.29896092]\n",
      " [0.30263528]\n",
      " [0.3063195 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31089592]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.28284892]\n",
      "  [0.2847856 ]\n",
      "  [0.28838092]\n",
      "  [0.29182899]\n",
      "  [0.29508689]\n",
      "  [0.29896092]\n",
      "  [0.30263528]\n",
      "  [0.3063195 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12310491502285004\n",
      "Predicción post entrenamiento : [[0.3136922]]\n",
      "PERDIDAAAA despues: 0.12115050107240677\n",
      "loss en el callback: 0.08948922157287598, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.2847856 ]\n",
      " [0.28838092]\n",
      " [0.29182899]\n",
      " [0.29508689]\n",
      " [0.29896092]\n",
      " [0.30263528]\n",
      " [0.3063195 ]\n",
      " [0.31089592]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.31591237]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.2847856 ]\n",
      "  [0.28838092]\n",
      "  [0.29182899]\n",
      "  [0.29508689]\n",
      "  [0.29896092]\n",
      "  [0.30263528]\n",
      "  [0.3063195 ]\n",
      "  [0.31089592]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1275079846382141\n",
      "Predicción post entrenamiento : [[0.3186936]]\n",
      "PERDIDAAAA despues: 0.1255294531583786\n",
      "loss en el callback: 0.09397432208061218, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.28838092]\n",
      " [0.29182899]\n",
      " [0.29508689]\n",
      " [0.29896092]\n",
      " [0.30263528]\n",
      " [0.3063195 ]\n",
      " [0.31089592]\n",
      " [0.31591237]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3212799]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.28838092]\n",
      "  [0.29182899]\n",
      "  [0.29508689]\n",
      "  [0.29896092]\n",
      "  [0.30263528]\n",
      "  [0.3063195 ]\n",
      "  [0.31089592]\n",
      "  [0.31591237]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1515524685382843\n",
      "Predicción post entrenamiento : [[0.3244834]]\n",
      "PERDIDAAAA despues: 0.14906850457191467\n",
      "loss en el callback: 0.11864598840475082, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.29182899]\n",
      " [0.29508689]\n",
      " [0.29896092]\n",
      " [0.30263528]\n",
      " [0.3063195 ]\n",
      " [0.31089592]\n",
      " [0.31591237]\n",
      " [0.32127991]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3271231]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.29182899]\n",
      "  [0.29508689]\n",
      "  [0.29896092]\n",
      "  [0.30263528]\n",
      "  [0.3063195 ]\n",
      "  [0.31089592]\n",
      "  [0.31591237]\n",
      "  [0.32127991]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14202918112277985\n",
      "Predicción post entrenamiento : [[0.3301062]]\n",
      "PERDIDAAAA despues: 0.1397896260023117\n",
      "loss en el callback: 0.18662647902965546, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.29508689]\n",
      " [0.29896092]\n",
      " [0.30263528]\n",
      " [0.3063195 ]\n",
      " [0.31089592]\n",
      " [0.31591237]\n",
      " [0.32127991]\n",
      " [0.32712311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.33287874]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.29508689]\n",
      "  [0.29896092]\n",
      "  [0.30263528]\n",
      "  [0.3063195 ]\n",
      "  [0.31089592]\n",
      "  [0.31591237]\n",
      "  [0.32127991]\n",
      "  [0.32712311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15551884472370148\n",
      "Predicción post entrenamiento : [[0.33595744]]\n",
      "PERDIDAAAA despues: 0.15310010313987732\n",
      "loss en el callback: 0.1354280412197113, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.29896092]\n",
      " [0.30263528]\n",
      " [0.3063195 ]\n",
      " [0.31089592]\n",
      " [0.31591237]\n",
      " [0.32127991]\n",
      " [0.32712311]\n",
      " [0.33287874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.33897397]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.29896092]\n",
      "  [0.30263528]\n",
      "  [0.3063195 ]\n",
      "  [0.31089592]\n",
      "  [0.31591237]\n",
      "  [0.32127991]\n",
      "  [0.32712311]\n",
      "  [0.33287874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14715981483459473\n",
      "Predicción post entrenamiento : [[0.3419827]]\n",
      "PERDIDAAAA despues: 0.14486049115657806\n",
      "loss en el callback: 0.1333646923303604, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.30263528]\n",
      " [0.3063195 ]\n",
      " [0.31089592]\n",
      " [0.31591237]\n",
      " [0.32127991]\n",
      " [0.32712311]\n",
      " [0.33287874]\n",
      " [0.33897397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3451764]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.30263528]\n",
      "  [0.3063195 ]\n",
      "  [0.31089592]\n",
      "  [0.31591237]\n",
      "  [0.32127991]\n",
      "  [0.32712311]\n",
      "  [0.33287874]\n",
      "  [0.33897397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1820024996995926\n",
      "Predicción post entrenamiento : [[0.34841126]]\n",
      "PERDIDAAAA despues: 0.17925286293029785\n",
      "loss en el callback: 0.18861623108386993, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.3063195 ]\n",
      " [0.31089592]\n",
      " [0.31591237]\n",
      " [0.32127991]\n",
      " [0.32712311]\n",
      " [0.33287874]\n",
      " [0.33897397]\n",
      " [0.3451764 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.351906]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.3063195 ]\n",
      "  [0.31089592]\n",
      "  [0.31591237]\n",
      "  [0.32127991]\n",
      "  [0.32712311]\n",
      "  [0.33287874]\n",
      "  [0.33897397]\n",
      "  [0.3451764 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13884520530700684\n",
      "Predicción post entrenamiento : [[0.35454118]]\n",
      "PERDIDAAAA despues: 0.1368883103132248\n",
      "loss en el callback: 0.08220284432172775, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.31089592]\n",
      " [0.31591237]\n",
      " [0.32127991]\n",
      " [0.32712311]\n",
      " [0.33287874]\n",
      " [0.33897397]\n",
      " [0.3451764 ]\n",
      " [0.351906  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.35842618]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.31089592]\n",
      "  [0.31591237]\n",
      "  [0.32127991]\n",
      "  [0.32712311]\n",
      "  [0.33287874]\n",
      "  [0.33897397]\n",
      "  [0.3451764 ]\n",
      "  [0.351906  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09773846715688705\n",
      "Predicción post entrenamiento : [[0.36075154]]\n",
      "PERDIDAAAA despues: 0.09628991037607193\n",
      "loss en el callback: 0.08516594767570496, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.31591237]\n",
      " [0.32127991]\n",
      " [0.32712311]\n",
      " [0.33287874]\n",
      " [0.33897397]\n",
      " [0.3451764 ]\n",
      " [0.351906  ]\n",
      " [0.35842618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.36490253]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.31591237]\n",
      "  [0.32127991]\n",
      "  [0.32712311]\n",
      "  [0.33287874]\n",
      "  [0.33897397]\n",
      "  [0.3451764 ]\n",
      "  [0.351906  ]\n",
      "  [0.35842618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09539901465177536\n",
      "Predicción post entrenamiento : [[0.36711746]]\n",
      "PERDIDAAAA despues: 0.09403567761182785\n",
      "loss en el callback: 0.0813365951180458, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.32127991]\n",
      " [0.32712311]\n",
      " [0.33287874]\n",
      " [0.33897397]\n",
      " [0.3451764 ]\n",
      " [0.351906  ]\n",
      " [0.35842618]\n",
      " [0.36490253]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.37149438]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.32127991]\n",
      "  [0.32712311]\n",
      "  [0.33287874]\n",
      "  [0.33897397]\n",
      "  [0.3451764 ]\n",
      "  [0.351906  ]\n",
      "  [0.35842618]\n",
      "  [0.36490253]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11761978268623352\n",
      "Predicción post entrenamiento : [[0.37393716]]\n",
      "PERDIDAAAA despues: 0.11595021188259125\n",
      "loss en el callback: 0.11441649496555328, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.32712311]\n",
      " [0.33287874]\n",
      " [0.33897397]\n",
      " [0.3451764 ]\n",
      " [0.351906  ]\n",
      " [0.35842618]\n",
      " [0.36490253]\n",
      " [0.37149438]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.37850997]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.32712311]\n",
      "  [0.33287874]\n",
      "  [0.33897397]\n",
      "  [0.3451764 ]\n",
      "  [0.351906  ]\n",
      "  [0.35842618]\n",
      "  [0.36490253]\n",
      "  [0.37149438]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13350822031497955\n",
      "Predicción post entrenamiento : [[0.3810273]]\n",
      "PERDIDAAAA despues: 0.13167494535446167\n",
      "loss en el callback: 0.09454470872879028, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.33287874]\n",
      " [0.33897397]\n",
      " [0.3451764 ]\n",
      " [0.351906  ]\n",
      " [0.35842618]\n",
      " [0.36490253]\n",
      " [0.37149438]\n",
      " [0.37850997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3857241]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.33287874]\n",
      "  [0.33897397]\n",
      "  [0.3451764 ]\n",
      "  [0.351906  ]\n",
      "  [0.35842618]\n",
      "  [0.36490253]\n",
      "  [0.37149438]\n",
      "  [0.37850997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11347737163305283\n",
      "Predicción post entrenamiento : [[0.38811457]]\n",
      "PERDIDAAAA despues: 0.11187255382537842\n",
      "loss en el callback: 0.1142253428697586, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.33897397]\n",
      " [0.3451764 ]\n",
      " [0.351906  ]\n",
      " [0.35842618]\n",
      " [0.36490253]\n",
      " [0.37149438]\n",
      " [0.37850997]\n",
      " [0.3857241 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.3929935]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.33897397]\n",
      "  [0.3451764 ]\n",
      "  [0.351906  ]\n",
      "  [0.35842618]\n",
      "  [0.36490253]\n",
      "  [0.37149438]\n",
      "  [0.37850997]\n",
      "  [0.3857241 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09384900331497192\n",
      "Predicción post entrenamiento : [[0.39488918]]\n",
      "PERDIDAAAA despues: 0.09269113093614578\n",
      "loss en el callback: 0.05219893530011177, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.3451764 ]\n",
      " [0.351906  ]\n",
      " [0.35842618]\n",
      " [0.36490253]\n",
      " [0.37149438]\n",
      " [0.37850997]\n",
      " [0.3857241 ]\n",
      " [0.39299351]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.39990732]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.3451764 ]\n",
      "  [0.351906  ]\n",
      "  [0.35842618]\n",
      "  [0.36490253]\n",
      "  [0.37149438]\n",
      "  [0.37850997]\n",
      "  [0.3857241 ]\n",
      "  [0.39299351]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11384132504463196\n",
      "Predicción post entrenamiento : [[0.40230593]]\n",
      "PERDIDAAAA despues: 0.11222848296165466\n",
      "loss en el callback: 0.1527712494134903, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.351906  ]\n",
      " [0.35842618]\n",
      " [0.36490253]\n",
      " [0.37149438]\n",
      " [0.37850997]\n",
      " [0.3857241 ]\n",
      " [0.39299351]\n",
      " [0.39990732]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4074722]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.351906  ]\n",
      "  [0.35842618]\n",
      "  [0.36490253]\n",
      "  [0.37149438]\n",
      "  [0.37850997]\n",
      "  [0.3857241 ]\n",
      "  [0.39299351]\n",
      "  [0.39990732]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09856688976287842\n",
      "Predicción post entrenamiento : [[0.409671]]\n",
      "PERDIDAAAA despues: 0.09719107300043106\n",
      "loss en el callback: 0.12039504200220108, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.35842618]\n",
      " [0.36490253]\n",
      " [0.37149438]\n",
      " [0.37850997]\n",
      " [0.3857241 ]\n",
      " [0.39299351]\n",
      " [0.39990732]\n",
      " [0.40747219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.41488448]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.35842618]\n",
      "  [0.36490253]\n",
      "  [0.37149438]\n",
      "  [0.37850997]\n",
      "  [0.3857241 ]\n",
      "  [0.39299351]\n",
      "  [0.39990732]\n",
      "  [0.40747219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09231219440698624\n",
      "Predicción post entrenamiento : [[0.4170376]]\n",
      "PERDIDAAAA despues: 0.09100846946239471\n",
      "loss en el callback: 0.12532919645309448, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.36490253]\n",
      " [0.37149438]\n",
      " [0.37850997]\n",
      " [0.3857241 ]\n",
      " [0.39299351]\n",
      " [0.39990732]\n",
      " [0.40747219]\n",
      " [0.41488448]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4223734]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.36490253]\n",
      "  [0.37149438]\n",
      "  [0.37850997]\n",
      "  [0.3857241 ]\n",
      "  [0.39299351]\n",
      "  [0.39990732]\n",
      "  [0.40747219]\n",
      "  [0.41488448]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06339513510465622\n",
      "Predicción post entrenamiento : [[0.4239882]]\n",
      "PERDIDAAAA despues: 0.06258459389209747\n",
      "loss en el callback: 0.049778055399656296, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.37149438]\n",
      " [0.37850997]\n",
      " [0.3857241 ]\n",
      " [0.39299351]\n",
      " [0.39990732]\n",
      " [0.40747219]\n",
      " [0.41488448]\n",
      " [0.42237341]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.42948937]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.37149438]\n",
      "  [0.37850997]\n",
      "  [0.3857241 ]\n",
      "  [0.39299351]\n",
      "  [0.39990732]\n",
      "  [0.40747219]\n",
      "  [0.41488448]\n",
      "  [0.42237341]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0724024623632431\n",
      "Predicción post entrenamiento : [[0.431221]]\n",
      "PERDIDAAAA despues: 0.07147357612848282\n",
      "loss en el callback: 0.05539466440677643, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.37850997]\n",
      " [0.3857241 ]\n",
      " [0.39299351]\n",
      " [0.39990732]\n",
      " [0.40747219]\n",
      " [0.41488448]\n",
      " [0.42237341]\n",
      " [0.42948937]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4368932]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.37850997]\n",
      "  [0.3857241 ]\n",
      "  [0.39299351]\n",
      "  [0.39990732]\n",
      "  [0.40747219]\n",
      "  [0.41488448]\n",
      "  [0.42237341]\n",
      "  [0.42948937]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08073846250772476\n",
      "Predicción post entrenamiento : [[0.4388528]]\n",
      "PERDIDAAAA despues: 0.07962868362665176\n",
      "loss en el callback: 0.0875164195895195, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.3857241 ]\n",
      " [0.39299351]\n",
      " [0.39990732]\n",
      " [0.40747219]\n",
      " [0.41488448]\n",
      " [0.42237341]\n",
      " [0.42948937]\n",
      " [0.43689319]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.44461602]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.3857241 ]\n",
      "  [0.39299351]\n",
      "  [0.39990732]\n",
      "  [0.40747219]\n",
      "  [0.41488448]\n",
      "  [0.42237341]\n",
      "  [0.42948937]\n",
      "  [0.43689319]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07726848870515823\n",
      "Predicción post entrenamiento : [[0.44632858]]\n",
      "PERDIDAAAA despues: 0.07631933689117432\n",
      "loss en el callback: 0.05540120229125023, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.39299351]\n",
      " [0.39990732]\n",
      " [0.40747219]\n",
      " [0.41488448]\n",
      " [0.42237341]\n",
      " [0.42948937]\n",
      " [0.43689319]\n",
      " [0.44461602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4521453]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.39299351]\n",
      "  [0.39990732]\n",
      "  [0.40747219]\n",
      "  [0.41488448]\n",
      "  [0.42237341]\n",
      "  [0.42948937]\n",
      "  [0.43689319]\n",
      "  [0.44461602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09250766783952713\n",
      "Predicción post entrenamiento : [[0.45422563]]\n",
      "PERDIDAAAA despues: 0.09124653041362762\n",
      "loss en el callback: 0.09567371755838394, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.39990732]\n",
      " [0.40747219]\n",
      " [0.41488448]\n",
      " [0.42237341]\n",
      " [0.42948937]\n",
      " [0.43689319]\n",
      " [0.44461602]\n",
      " [0.45214531]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.460092]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.39990732]\n",
      "  [0.40747219]\n",
      "  [0.41488448]\n",
      "  [0.42237341]\n",
      "  [0.42948937]\n",
      "  [0.43689319]\n",
      "  [0.44461602]\n",
      "  [0.45214531]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13505201041698456\n",
      "Predicción post entrenamiento : [[0.4625782]]\n",
      "PERDIDAAAA despues: 0.13323086500167847\n",
      "loss en el callback: 0.1679134964942932, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.40747219]\n",
      " [0.41488448]\n",
      " [0.42237341]\n",
      " [0.42948937]\n",
      " [0.43689319]\n",
      " [0.44461602]\n",
      " [0.45214531]\n",
      " [0.46009201]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.46860334]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.40747219]\n",
      "  [0.41488448]\n",
      "  [0.42237341]\n",
      "  [0.42948937]\n",
      "  [0.43689319]\n",
      "  [0.44461602]\n",
      "  [0.45214531]\n",
      "  [0.46009201]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13706199824810028\n",
      "Predicción post entrenamiento : [[0.47079718]]\n",
      "PERDIDAAAA despues: 0.13544240593910217\n",
      "loss en el callback: 0.0836884006857872, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.41488448]\n",
      " [0.42237341]\n",
      " [0.42948937]\n",
      " [0.43689319]\n",
      " [0.44461602]\n",
      " [0.45214531]\n",
      " [0.46009201]\n",
      " [0.46860334]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.47683665]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.41488448]\n",
      "  [0.42237341]\n",
      "  [0.42948937]\n",
      "  [0.43689319]\n",
      "  [0.44461602]\n",
      "  [0.45214531]\n",
      "  [0.46009201]\n",
      "  [0.46860334]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10076127201318741\n",
      "Predicción post entrenamiento : [[0.47895035]]\n",
      "PERDIDAAAA despues: 0.0994238331913948\n",
      "loss en el callback: 0.11554251611232758, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.42237341]\n",
      " [0.42948937]\n",
      " [0.43689319]\n",
      " [0.44461602]\n",
      " [0.45214531]\n",
      " [0.46009201]\n",
      " [0.46860334]\n",
      " [0.47683665]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.48505938]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.42237341]\n",
      "  [0.42948937]\n",
      "  [0.43689319]\n",
      "  [0.44461602]\n",
      "  [0.45214531]\n",
      "  [0.46009201]\n",
      "  [0.46860334]\n",
      "  [0.47683665]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08924877643585205\n",
      "Predicción post entrenamiento : [[0.48693618]]\n",
      "PERDIDAAAA despues: 0.08813092857599258\n",
      "loss en el callback: 0.07301004230976105, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.42948937]\n",
      " [0.43689319]\n",
      " [0.44461602]\n",
      " [0.45214531]\n",
      " [0.46009201]\n",
      " [0.46860334]\n",
      " [0.47683665]\n",
      " [0.48505938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.49312034]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.42948937]\n",
      "  [0.43689319]\n",
      "  [0.44461602]\n",
      "  [0.45214531]\n",
      "  [0.46009201]\n",
      "  [0.46860334]\n",
      "  [0.47683665]\n",
      "  [0.48505938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0755145326256752\n",
      "Predicción post entrenamiento : [[0.4947016]]\n",
      "PERDIDAAAA despues: 0.07464797794818878\n",
      "loss en el callback: 0.050198208540678024, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.43689319]\n",
      " [0.44461602]\n",
      " [0.45214531]\n",
      " [0.46009201]\n",
      " [0.46860334]\n",
      " [0.47683665]\n",
      " [0.48505938]\n",
      " [0.49312034]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.50109166]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.43689319]\n",
      "  [0.44461602]\n",
      "  [0.45214531]\n",
      "  [0.46009201]\n",
      "  [0.46860334]\n",
      "  [0.47683665]\n",
      "  [0.48505938]\n",
      "  [0.49312034]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08036543428897858\n",
      "Predicción post entrenamiento : [[0.50285]]\n",
      "PERDIDAAAA despues: 0.07937158644199371\n",
      "loss en el callback: 0.07361169159412384, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.44461602]\n",
      " [0.45214531]\n",
      " [0.46009201]\n",
      " [0.46860334]\n",
      " [0.47683665]\n",
      " [0.48505938]\n",
      " [0.49312034]\n",
      " [0.50109166]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5094127]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.44461602]\n",
      "  [0.45214531]\n",
      "  [0.46009201]\n",
      "  [0.46860334]\n",
      "  [0.47683665]\n",
      "  [0.48505938]\n",
      "  [0.49312034]\n",
      "  [0.50109166]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1363946497440338\n",
      "Predicción post entrenamiento : [[0.5114781]]\n",
      "PERDIDAAAA despues: 0.13487333059310913\n",
      "loss en el callback: 0.07606267184019089, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.45214531]\n",
      " [0.46009201]\n",
      " [0.46860334]\n",
      " [0.47683665]\n",
      " [0.48505938]\n",
      " [0.49312034]\n",
      " [0.50109166]\n",
      " [0.50941271]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5181606]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.45214531]\n",
      "  [0.46009201]\n",
      "  [0.46860334]\n",
      "  [0.47683665]\n",
      "  [0.48505938]\n",
      "  [0.49312034]\n",
      "  [0.50109166]\n",
      "  [0.50941271]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1277841031551361\n",
      "Predicción post entrenamiento : [[0.52047014]]\n",
      "PERDIDAAAA despues: 0.12613824009895325\n",
      "loss en el callback: 0.1348775327205658, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.46009201]\n",
      " [0.46860334]\n",
      " [0.47683665]\n",
      " [0.48505938]\n",
      " [0.49312034]\n",
      " [0.50109166]\n",
      " [0.50941271]\n",
      " [0.51816058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.52735025]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.46009201]\n",
      "  [0.46860334]\n",
      "  [0.47683665]\n",
      "  [0.48505938]\n",
      "  [0.49312034]\n",
      "  [0.50109166]\n",
      "  [0.50941271]\n",
      "  [0.51816058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10339153558015823\n",
      "Predicción post entrenamiento : [[0.529546]]\n",
      "PERDIDAAAA despues: 0.10198426991701126\n",
      "loss en el callback: 0.14163002371788025, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.46860334]\n",
      " [0.47683665]\n",
      " [0.48505938]\n",
      " [0.49312034]\n",
      " [0.50109166]\n",
      " [0.50941271]\n",
      " [0.51816058]\n",
      " [0.52735025]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5365438]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.46860334]\n",
      "  [0.47683665]\n",
      "  [0.48505938]\n",
      "  [0.49312034]\n",
      "  [0.50109166]\n",
      "  [0.50941271]\n",
      "  [0.51816058]\n",
      "  [0.52735025]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07937951385974884\n",
      "Predicción post entrenamiento : [[0.538333]]\n",
      "PERDIDAAAA despues: 0.07837451994419098\n",
      "loss en el callback: 0.08050712943077087, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.47683665]\n",
      " [0.48505938]\n",
      " [0.49312034]\n",
      " [0.50109166]\n",
      " [0.50941271]\n",
      " [0.51816058]\n",
      " [0.52735025]\n",
      " [0.53654379]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.54531556]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.47683665]\n",
      "  [0.48505938]\n",
      "  [0.49312034]\n",
      "  [0.50109166]\n",
      "  [0.50941271]\n",
      "  [0.51816058]\n",
      "  [0.52735025]\n",
      "  [0.53654379]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0792398601770401\n",
      "Predicción post entrenamiento : [[0.54719824]]\n",
      "PERDIDAAAA despues: 0.07818347215652466\n",
      "loss en el callback: 0.0983581617474556, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.48505938]\n",
      " [0.49312034]\n",
      " [0.50109166]\n",
      " [0.50941271]\n",
      " [0.51816058]\n",
      " [0.52735025]\n",
      " [0.53654379]\n",
      " [0.54531556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.55425566]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.48505938]\n",
      "  [0.49312034]\n",
      "  [0.50109166]\n",
      "  [0.50941271]\n",
      "  [0.51816058]\n",
      "  [0.52735025]\n",
      "  [0.53654379]\n",
      "  [0.54531556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053406670689582825\n",
      "Predicción post entrenamiento : [[0.55592245]]\n",
      "PERDIDAAAA despues: 0.05263906344771385\n",
      "loss en el callback: 0.0960894301533699, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.49312034]\n",
      " [0.50109166]\n",
      " [0.50941271]\n",
      " [0.51816058]\n",
      " [0.52735025]\n",
      " [0.53654379]\n",
      " [0.54531556]\n",
      " [0.55425566]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5630866]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.49312034]\n",
      "  [0.50109166]\n",
      "  [0.50941271]\n",
      "  [0.51816058]\n",
      "  [0.52735025]\n",
      "  [0.53654379]\n",
      "  [0.54531556]\n",
      "  [0.55425566]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05114036053419113\n",
      "Predicción post entrenamiento : [[0.5641353]]\n",
      "PERDIDAAAA despues: 0.05066715553402901\n",
      "loss en el callback: 0.022361982613801956, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.50109166]\n",
      " [0.50941271]\n",
      " [0.51816058]\n",
      " [0.52735025]\n",
      " [0.53654379]\n",
      " [0.54531556]\n",
      " [0.55425566]\n",
      " [0.56308663]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.57148325]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.50109166]\n",
      "  [0.50941271]\n",
      "  [0.51816058]\n",
      "  [0.52735025]\n",
      "  [0.53654379]\n",
      "  [0.54531556]\n",
      "  [0.55425566]\n",
      "  [0.56308663]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06900578737258911\n",
      "Predicción post entrenamiento : [[0.57311285]]\n",
      "PERDIDAAAA despues: 0.0681522935628891\n",
      "loss en el callback: 0.06923200935125351, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.50941271]\n",
      " [0.51816058]\n",
      " [0.52735025]\n",
      " [0.53654379]\n",
      " [0.54531556]\n",
      " [0.55425566]\n",
      " [0.56308663]\n",
      " [0.57148325]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.58071065]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.50941271]\n",
      "  [0.51816058]\n",
      "  [0.52735025]\n",
      "  [0.53654379]\n",
      "  [0.54531556]\n",
      "  [0.55425566]\n",
      "  [0.56308663]\n",
      "  [0.57148325]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05371508374810219\n",
      "Predicción post entrenamiento : [[0.5824193]]\n",
      "PERDIDAAAA despues: 0.05292600393295288\n",
      "loss en el callback: 0.09625512361526489, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.51816058]\n",
      " [0.52735025]\n",
      " [0.53654379]\n",
      " [0.54531556]\n",
      " [0.55425566]\n",
      " [0.56308663]\n",
      " [0.57148325]\n",
      " [0.58071065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.590207]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.51816058]\n",
      "  [0.52735025]\n",
      "  [0.53654379]\n",
      "  [0.54531556]\n",
      "  [0.55425566]\n",
      "  [0.56308663]\n",
      "  [0.57148325]\n",
      "  [0.58071065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044534869492053986\n",
      "Predicción post entrenamiento : [[0.5918631]]\n",
      "PERDIDAAAA despues: 0.04383862391114235\n",
      "loss en el callback: 0.0838606059551239, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.52735025]\n",
      " [0.53654379]\n",
      " [0.54531556]\n",
      " [0.55425566]\n",
      " [0.56308663]\n",
      " [0.57148325]\n",
      " [0.58071065]\n",
      " [0.59020698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.5997428]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.52735025]\n",
      "  [0.53654379]\n",
      "  [0.54531556]\n",
      "  [0.55425566]\n",
      "  [0.56308663]\n",
      "  [0.57148325]\n",
      "  [0.58071065]\n",
      "  [0.59020698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04138548672199249\n",
      "Predicción post entrenamiento : [[0.6007752]]\n",
      "PERDIDAAAA despues: 0.040966518223285675\n",
      "loss en el callback: 0.02541225031018257, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.53654379]\n",
      " [0.54531556]\n",
      " [0.55425566]\n",
      " [0.56308663]\n",
      " [0.57148325]\n",
      " [0.58071065]\n",
      " [0.59020698]\n",
      " [0.59974283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6086278]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.53654379]\n",
      "  [0.54531556]\n",
      "  [0.55425566]\n",
      "  [0.56308663]\n",
      "  [0.57148325]\n",
      "  [0.58071065]\n",
      "  [0.59020698]\n",
      "  [0.59974283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0341743640601635\n",
      "Predicción post entrenamiento : [[0.6100136]]\n",
      "PERDIDAAAA despues: 0.03366391360759735\n",
      "loss en el callback: 0.0635262206196785, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.54531556]\n",
      " [0.55425566]\n",
      " [0.56308663]\n",
      " [0.57148325]\n",
      " [0.58071065]\n",
      " [0.59020698]\n",
      " [0.59974283]\n",
      " [0.6086278 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6178354]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.54531556]\n",
      "  [0.55425566]\n",
      "  [0.56308663]\n",
      "  [0.57148325]\n",
      "  [0.58071065]\n",
      "  [0.59020698]\n",
      "  [0.59974283]\n",
      "  [0.6086278 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020259268581867218\n",
      "Predicción post entrenamiento : [[0.6181861]]\n",
      "PERDIDAAAA despues: 0.020159553736448288\n",
      "loss en el callback: 0.0025480627082288265, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.55425566]\n",
      " [0.56308663]\n",
      " [0.57148325]\n",
      " [0.58071065]\n",
      " [0.59020698]\n",
      " [0.59974283]\n",
      " [0.6086278 ]\n",
      " [0.6178354 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.62609625]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.55425566]\n",
      "  [0.56308663]\n",
      "  [0.57148325]\n",
      "  [0.58071065]\n",
      "  [0.59020698]\n",
      "  [0.59974283]\n",
      "  [0.6086278 ]\n",
      "  [0.6178354 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011941608041524887\n",
      "Predicción post entrenamiento : [[0.6272362]]\n",
      "PERDIDAAAA despues: 0.011693768203258514\n",
      "loss en el callback: 0.04778832197189331, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.56308663]\n",
      " [0.57148325]\n",
      " [0.58071065]\n",
      " [0.59020698]\n",
      " [0.59974283]\n",
      " [0.6086278 ]\n",
      " [0.6178354 ]\n",
      " [0.62609625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.63520324]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.56308663]\n",
      "  [0.57148325]\n",
      "  [0.58071065]\n",
      "  [0.59020698]\n",
      "  [0.59974283]\n",
      "  [0.6086278 ]\n",
      "  [0.6178354 ]\n",
      "  [0.62609625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005622986704111099\n",
      "Predicción post entrenamiento : [[0.63591135]]\n",
      "PERDIDAAAA despues: 0.005517291836440563\n",
      "loss en el callback: 0.015381073579192162, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.57148325]\n",
      " [0.58071065]\n",
      " [0.59020698]\n",
      " [0.59974283]\n",
      " [0.6086278 ]\n",
      " [0.6178354 ]\n",
      " [0.62609625]\n",
      " [0.63520324]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.643971]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.57148325]\n",
      "  [0.58071065]\n",
      "  [0.59020698]\n",
      "  [0.59974283]\n",
      "  [0.6086278 ]\n",
      "  [0.6178354 ]\n",
      "  [0.62609625]\n",
      "  [0.63520324]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0046452488750219345\n",
      "Predicción post entrenamiento : [[0.6441643]]\n",
      "PERDIDAAAA despues: 0.004618937615305185\n",
      "loss en el callback: 0.0008952516946010292, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.58071065]\n",
      " [0.59020698]\n",
      " [0.59974283]\n",
      " [0.6086278 ]\n",
      " [0.6178354 ]\n",
      " [0.62609625]\n",
      " [0.63520324]\n",
      " [0.64397103]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6524492]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.58071065]\n",
      "  [0.59020698]\n",
      "  [0.59974283]\n",
      "  [0.6086278 ]\n",
      "  [0.6178354 ]\n",
      "  [0.62609625]\n",
      "  [0.63520324]\n",
      "  [0.64397103]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007601509336382151\n",
      "Predicción post entrenamiento : [[0.65329546]]\n",
      "PERDIDAAAA despues: 0.007454659324139357\n",
      "loss en el callback: 0.02744845673441887, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.59020698]\n",
      " [0.59974283]\n",
      " [0.6086278 ]\n",
      " [0.6178354 ]\n",
      " [0.62609625]\n",
      " [0.63520324]\n",
      " [0.64397103]\n",
      " [0.65244919]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6615764]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.59020698]\n",
      "  [0.59974283]\n",
      "  [0.6086278 ]\n",
      "  [0.6178354 ]\n",
      "  [0.62609625]\n",
      "  [0.63520324]\n",
      "  [0.64397103]\n",
      "  [0.65244919]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005561040714383125\n",
      "Predicción post entrenamiento : [[0.6625953]]\n",
      "PERDIDAAAA despues: 0.0054101175628602505\n",
      "loss en el callback: 0.04083336889743805, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.59974283]\n",
      " [0.6086278 ]\n",
      " [0.6178354 ]\n",
      " [0.62609625]\n",
      " [0.63520324]\n",
      " [0.64397103]\n",
      " [0.65244919]\n",
      " [0.66157639]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6707701]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.59974283]\n",
      "  [0.6086278 ]\n",
      "  [0.6178354 ]\n",
      "  [0.62609625]\n",
      "  [0.63520324]\n",
      "  [0.64397103]\n",
      "  [0.65244919]\n",
      "  [0.66157639]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0236150956188794e-05\n",
      "Predicción post entrenamiento : [[0.6709948]]\n",
      "PERDIDAAAA despues: 1.1724515388777945e-05\n",
      "loss en el callback: 0.0016159533988684416, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.6086278 ]\n",
      " [0.6178354 ]\n",
      " [0.62609625]\n",
      " [0.63520324]\n",
      " [0.64397103]\n",
      " [0.65244919]\n",
      " [0.66157639]\n",
      " [0.67077011]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6790166]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.6086278 ]\n",
      "  [0.6178354 ]\n",
      "  [0.62609625]\n",
      "  [0.63520324]\n",
      "  [0.64397103]\n",
      "  [0.65244919]\n",
      "  [0.66157639]\n",
      "  [0.67077011]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.31959187053144e-05\n",
      "Predicción post entrenamiento : [[0.67902565]]\n",
      "PERDIDAAAA despues: 8.336127211805433e-05\n",
      "loss en el callback: 2.3510992832598276e-06, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.6178354 ]\n",
      " [0.62609625]\n",
      " [0.63520324]\n",
      " [0.64397103]\n",
      " [0.65244919]\n",
      " [0.66157639]\n",
      " [0.67077011]\n",
      " [0.67901659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.6870552]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.6178354 ]\n",
      "  [0.62609625]\n",
      "  [0.63520324]\n",
      "  [0.64397103]\n",
      "  [0.65244919]\n",
      "  [0.66157639]\n",
      "  [0.67077011]\n",
      "  [0.67901659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.166254312731326e-05\n",
      "Predicción post entrenamiento : [[0.68734866]]\n",
      "PERDIDAAAA despues: 8.61288353917189e-05\n",
      "loss en el callback: 0.0026635299436748028, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.62609625]\n",
      " [0.63520324]\n",
      " [0.64397103]\n",
      " [0.65244919]\n",
      " [0.66157639]\n",
      " [0.67077011]\n",
      " [0.67901659]\n",
      " [0.68705517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6952807]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.62609625]\n",
      "  [0.63520324]\n",
      "  [0.64397103]\n",
      "  [0.65244919]\n",
      "  [0.66157639]\n",
      "  [0.67077011]\n",
      "  [0.67901659]\n",
      "  [0.68705517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015471118967980146\n",
      "Predicción post entrenamiento : [[0.69592345]]\n",
      "PERDIDAAAA despues: 0.0015980901662260294\n",
      "loss en el callback: 0.01979365013539791, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.63520324]\n",
      " [0.64397103]\n",
      " [0.65244919]\n",
      " [0.66157639]\n",
      " [0.67077011]\n",
      " [0.67901659]\n",
      " [0.68705517]\n",
      " [0.69528067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7040171]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.63520324]\n",
      "  [0.64397103]\n",
      "  [0.65244919]\n",
      "  [0.66157639]\n",
      "  [0.67077011]\n",
      "  [0.67901659]\n",
      "  [0.68705517]\n",
      "  [0.69528067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006355663063004613\n",
      "Predicción post entrenamiento : [[0.7040278]]\n",
      "PERDIDAAAA despues: 0.0006361043779179454\n",
      "loss en el callback: 3.3394594538549427e-06, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.64397103]\n",
      " [0.65244919]\n",
      " [0.66157639]\n",
      " [0.67077011]\n",
      " [0.67901659]\n",
      " [0.68705517]\n",
      " [0.69528067]\n",
      " [0.7040171 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.71203214]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.64397103]\n",
      "  [0.65244919]\n",
      "  [0.66157639]\n",
      "  [0.67077011]\n",
      "  [0.67901659]\n",
      "  [0.68705517]\n",
      "  [0.69528067]\n",
      "  [0.7040171 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012915115803480148\n",
      "Predicción post entrenamiento : [[0.7121249]]\n",
      "PERDIDAAAA despues: 0.0012981862528249621\n",
      "loss en el callback: 0.00027006701566278934, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.65244919]\n",
      " [0.66157639]\n",
      " [0.67077011]\n",
      " [0.67901659]\n",
      " [0.68705517]\n",
      " [0.69528067]\n",
      " [0.7040171 ]\n",
      " [0.71203214]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.72010976]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.65244919]\n",
      "  [0.66157639]\n",
      "  [0.67077011]\n",
      "  [0.67901659]\n",
      "  [0.68705517]\n",
      "  [0.69528067]\n",
      "  [0.7040171 ]\n",
      "  [0.71203214]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.934791549108922e-05\n",
      "Predicción post entrenamiento : [[0.72021836]]\n",
      "PERDIDAAAA despues: 8.730665285838768e-05\n",
      "loss en el callback: 0.0003335125802550465, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.66157639]\n",
      " [0.67077011]\n",
      " [0.67901659]\n",
      " [0.68705517]\n",
      " [0.69528067]\n",
      " [0.7040171 ]\n",
      " [0.71203214]\n",
      " [0.72010976]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.728248]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.66157639]\n",
      "  [0.67077011]\n",
      "  [0.67901659]\n",
      "  [0.68705517]\n",
      "  [0.69528067]\n",
      "  [0.7040171 ]\n",
      "  [0.71203214]\n",
      "  [0.72010976]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007273502997122705\n",
      "Predicción post entrenamiento : [[0.72842926]]\n",
      "PERDIDAAAA despues: 0.0007371599785983562\n",
      "loss en el callback: 0.001067073200829327, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.67077011]\n",
      " [0.67901659]\n",
      " [0.68705517]\n",
      " [0.69528067]\n",
      " [0.7040171 ]\n",
      " [0.71203214]\n",
      " [0.72010976]\n",
      " [0.728248  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7362888]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.67077011]\n",
      "  [0.67901659]\n",
      "  [0.68705517]\n",
      "  [0.69528067]\n",
      "  [0.7040171 ]\n",
      "  [0.71203214]\n",
      "  [0.72010976]\n",
      "  [0.728248  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009761378751136363\n",
      "Predicción post entrenamiento : [[0.7367154]]\n",
      "PERDIDAAAA despues: 0.0009496637503616512\n",
      "loss en el callback: 0.006309264339506626, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.67901659]\n",
      " [0.68705517]\n",
      " [0.69528067]\n",
      " [0.7040171 ]\n",
      " [0.71203214]\n",
      " [0.72010976]\n",
      " [0.728248  ]\n",
      " [0.73628879]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7443395]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.67901659]\n",
      "  [0.68705517]\n",
      "  [0.69528067]\n",
      "  [0.7040171 ]\n",
      "  [0.71203214]\n",
      "  [0.72010976]\n",
      "  [0.728248  ]\n",
      "  [0.73628879]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011651394743239507\n",
      "Predicción post entrenamiento : [[0.74464786]]\n",
      "PERDIDAAAA despues: 0.00010995259071933106\n",
      "loss en el callback: 0.0028677498921751976, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.68705517]\n",
      " [0.69528067]\n",
      " [0.7040171 ]\n",
      " [0.71203214]\n",
      " [0.72010976]\n",
      " [0.728248  ]\n",
      " [0.73628879]\n",
      " [0.74433953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.75228]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.68705517]\n",
      "  [0.69528067]\n",
      "  [0.7040171 ]\n",
      "  [0.71203214]\n",
      "  [0.72010976]\n",
      "  [0.728248  ]\n",
      "  [0.73628879]\n",
      "  [0.74433953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.212796895648353e-05\n",
      "Predicción post entrenamiento : [[0.7521536]]\n",
      "PERDIDAAAA despues: 5.03184346598573e-05\n",
      "loss en el callback: 0.00044771056855097413, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.69528067]\n",
      " [0.7040171 ]\n",
      " [0.71203214]\n",
      " [0.72010976]\n",
      " [0.728248  ]\n",
      " [0.73628879]\n",
      " [0.74433953]\n",
      " [0.75228   ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.75984794]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.69528067]\n",
      "  [0.7040171 ]\n",
      "  [0.71203214]\n",
      "  [0.72010976]\n",
      "  [0.728248  ]\n",
      "  [0.73628879]\n",
      "  [0.74433953]\n",
      "  [0.75228   ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.105657666921616e-05\n",
      "Predicción post entrenamiento : [[0.7589289]]\n",
      "PERDIDAAAA despues: 4.753863686346449e-05\n",
      "loss en el callback: 0.018285106867551804, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.7040171 ]\n",
      " [0.71203214]\n",
      " [0.72010976]\n",
      " [0.728248  ]\n",
      " [0.73628879]\n",
      " [0.74433953]\n",
      " [0.75228   ]\n",
      " [0.75984794]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7666196]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.7040171 ]\n",
      "  [0.71203214]\n",
      "  [0.72010976]\n",
      "  [0.728248  ]\n",
      "  [0.73628879]\n",
      "  [0.74433953]\n",
      "  [0.75228   ]\n",
      "  [0.75984794]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032281980384141207\n",
      "Predicción post entrenamiento : [[0.76531327]]\n",
      "PERDIDAAAA despues: 0.0030814576894044876\n",
      "loss en el callback: 0.03700470179319382, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.71203214]\n",
      " [0.72010976]\n",
      " [0.728248  ]\n",
      " [0.73628879]\n",
      " [0.74433953]\n",
      " [0.75228   ]\n",
      " [0.75984794]\n",
      " [0.76661962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7728176]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.71203214]\n",
      "  [0.72010976]\n",
      "  [0.728248  ]\n",
      "  [0.73628879]\n",
      "  [0.74433953]\n",
      "  [0.75228   ]\n",
      "  [0.75984794]\n",
      "  [0.76661962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006787711288779974\n",
      "Predicción post entrenamiento : [[0.7720777]]\n",
      "PERDIDAAAA despues: 0.0066663362085819244\n",
      "loss en el callback: 0.014363103546202183, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.72010976]\n",
      " [0.728248  ]\n",
      " [0.73628879]\n",
      " [0.74433953]\n",
      " [0.75228   ]\n",
      " [0.75984794]\n",
      " [0.76661962]\n",
      " [0.77281761]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7795619]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.72010976]\n",
      "  [0.728248  ]\n",
      "  [0.73628879]\n",
      "  [0.74433953]\n",
      "  [0.75228   ]\n",
      "  [0.75984794]\n",
      "  [0.76661962]\n",
      "  [0.77281761]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006351966876536608\n",
      "Predicción post entrenamiento : [[0.7782989]]\n",
      "PERDIDAAAA despues: 0.0005731306155212224\n",
      "loss en el callback: 0.03270093351602554, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.728248  ]\n",
      " [0.73628879]\n",
      " [0.74433953]\n",
      " [0.75228   ]\n",
      " [0.75984794]\n",
      " [0.76661962]\n",
      " [0.77281761]\n",
      " [0.77956188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.78569937]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.728248  ]\n",
      "  [0.73628879]\n",
      "  [0.74433953]\n",
      "  [0.75228   ]\n",
      "  [0.75984794]\n",
      "  [0.76661962]\n",
      "  [0.77281761]\n",
      "  [0.77956188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004032081924378872\n",
      "Predicción post entrenamiento : [[0.78475344]]\n",
      "PERDIDAAAA despues: 0.0039128465577960014\n",
      "loss en el callback: 0.022586066275835037, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.73628879]\n",
      " [0.74433953]\n",
      " [0.75228   ]\n",
      " [0.75984794]\n",
      " [0.76661962]\n",
      " [0.77281761]\n",
      " [0.77956188]\n",
      " [0.78569937]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.79199183]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.73628879]\n",
      "  [0.74433953]\n",
      "  [0.75228   ]\n",
      "  [0.75984794]\n",
      "  [0.76661962]\n",
      "  [0.77281761]\n",
      "  [0.77956188]\n",
      "  [0.78569937]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003194117918610573\n",
      "Predicción post entrenamiento : [[0.79188365]]\n",
      "PERDIDAAAA despues: 0.0032063578255474567\n",
      "loss en el callback: 0.0002976098330691457, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.74433953]\n",
      " [0.75228   ]\n",
      " [0.75984794]\n",
      " [0.76661962]\n",
      " [0.77281761]\n",
      " [0.77956188]\n",
      " [0.78569937]\n",
      " [0.79199183]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7989163]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.74433953]\n",
      "  [0.75228   ]\n",
      "  [0.75984794]\n",
      "  [0.76661962]\n",
      "  [0.77281761]\n",
      "  [0.77956188]\n",
      "  [0.78569937]\n",
      "  [0.79199183]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011352199129760265\n",
      "Predicción post entrenamiento : [[0.79842454]]\n",
      "PERDIDAAAA despues: 0.011457227170467377\n",
      "loss en el callback: 0.005455782171338797, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.75228   ]\n",
      " [0.75984794]\n",
      " [0.76661962]\n",
      " [0.77281761]\n",
      " [0.77956188]\n",
      " [0.78569937]\n",
      " [0.79199183]\n",
      " [0.79891628]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.80517]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.75228   ]\n",
      "  [0.75984794]\n",
      "  [0.76661962]\n",
      "  [0.77281761]\n",
      "  [0.77956188]\n",
      "  [0.78569937]\n",
      "  [0.79199183]\n",
      "  [0.79891628]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005936119239777327\n",
      "Predicción post entrenamiento : [[0.80510414]]\n",
      "PERDIDAAAA despues: 0.0059462725184857845\n",
      "loss en el callback: 0.0001059263595379889, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.75984794]\n",
      " [0.76661962]\n",
      " [0.77281761]\n",
      " [0.77956188]\n",
      " [0.78569937]\n",
      " [0.79199183]\n",
      " [0.79891628]\n",
      " [0.80517   ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.81151885]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.75984794]\n",
      "  [0.76661962]\n",
      "  [0.77281761]\n",
      "  [0.77956188]\n",
      "  [0.78569937]\n",
      "  [0.79199183]\n",
      "  [0.79891628]\n",
      "  [0.80517   ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009267687797546387\n",
      "Predicción post entrenamiento : [[0.81224525]]\n",
      "PERDIDAAAA despues: 0.009128356352448463\n",
      "loss en el callback: 0.017810294404625893, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.76661962]\n",
      " [0.77281761]\n",
      " [0.77956188]\n",
      " [0.78569937]\n",
      " [0.79199183]\n",
      " [0.79891628]\n",
      " [0.80517   ]\n",
      " [0.81151885]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8183754]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.76661962]\n",
      "  [0.77281761]\n",
      "  [0.77956188]\n",
      "  [0.78569937]\n",
      "  [0.79199183]\n",
      "  [0.79891628]\n",
      "  [0.80517   ]\n",
      "  [0.81151885]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005069764330983162\n",
      "Predicción post entrenamiento : [[0.8184135]]\n",
      "PERDIDAAAA despues: 0.005064342170953751\n",
      "loss en el callback: 3.755838770302944e-05, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.77281761]\n",
      " [0.77956188]\n",
      " [0.78569937]\n",
      " [0.79199183]\n",
      " [0.79891628]\n",
      " [0.80517   ]\n",
      " [0.81151885]\n",
      " [0.81837541]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8244575]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.77281761]\n",
      "  [0.77956188]\n",
      "  [0.78569937]\n",
      "  [0.79199183]\n",
      "  [0.79891628]\n",
      "  [0.80517   ]\n",
      "  [0.81151885]\n",
      "  [0.81837541]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025398735888302326\n",
      "Predicción post entrenamiento : [[0.8241659]]\n",
      "PERDIDAAAA despues: 0.0025693548377603292\n",
      "loss en el callback: 0.0022220786195248365, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.77956188]\n",
      " [0.78569937]\n",
      " [0.79199183]\n",
      " [0.79891628]\n",
      " [0.80517   ]\n",
      " [0.81151885]\n",
      " [0.81837541]\n",
      " [0.82445753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8302902]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.77956188]\n",
      "  [0.78569937]\n",
      "  [0.79199183]\n",
      "  [0.79891628]\n",
      "  [0.80517   ]\n",
      "  [0.81151885]\n",
      "  [0.81837541]\n",
      "  [0.82445753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006876015570014715\n",
      "Predicción post entrenamiento : [[0.83106613]]\n",
      "PERDIDAAAA despues: 0.00674793403595686\n",
      "loss en el callback: 0.02286374568939209, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.78569937]\n",
      " [0.79199183]\n",
      " [0.79891628]\n",
      " [0.80517   ]\n",
      " [0.81151885]\n",
      " [0.81837541]\n",
      " [0.82445753]\n",
      " [0.8302902 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8371085]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.78569937]\n",
      "  [0.79199183]\n",
      "  [0.79891628]\n",
      "  [0.80517   ]\n",
      "  [0.81151885]\n",
      "  [0.81837541]\n",
      "  [0.82445753]\n",
      "  [0.8302902 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026533642783761024\n",
      "Predicción post entrenamiento : [[0.8372553]]\n",
      "PERDIDAAAA despues: 0.026485837996006012\n",
      "loss en el callback: 0.0005103423027321696, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.79199183]\n",
      " [0.79891628]\n",
      " [0.80517   ]\n",
      " [0.81151885]\n",
      " [0.81837541]\n",
      " [0.82445753]\n",
      " [0.8302902 ]\n",
      " [0.83710849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8433891]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.79199183]\n",
      "  [0.79891628]\n",
      "  [0.80517   ]\n",
      "  [0.81151885]\n",
      "  [0.81837541]\n",
      "  [0.82445753]\n",
      "  [0.8302902 ]\n",
      "  [0.83710849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0161709263920784\n",
      "Predicción post entrenamiento : [[0.84379625]]\n",
      "PERDIDAAAA despues: 0.016067540273070335\n",
      "loss en el callback: 0.0044862967915833, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.79891628]\n",
      " [0.80517   ]\n",
      " [0.81151885]\n",
      " [0.81837541]\n",
      " [0.82445753]\n",
      " [0.8302902 ]\n",
      " [0.83710849]\n",
      " [0.84338909]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.84998184]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.79891628]\n",
      "  [0.80517   ]\n",
      "  [0.81151885]\n",
      "  [0.81837541]\n",
      "  [0.82445753]\n",
      "  [0.8302902 ]\n",
      "  [0.83710849]\n",
      "  [0.84338909]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015070639783516526\n",
      "Predicción post entrenamiento : [[0.85066307]]\n",
      "PERDIDAAAA despues: 0.0014546368038281798\n",
      "loss en el callback: 0.01855693757534027, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.80517   ]\n",
      " [0.81151885]\n",
      " [0.81837541]\n",
      " [0.82445753]\n",
      " [0.8302902 ]\n",
      " [0.83710849]\n",
      " [0.84338909]\n",
      " [0.84998184]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8567029]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.80517   ]\n",
      "  [0.81151885]\n",
      "  [0.81837541]\n",
      "  [0.82445753]\n",
      "  [0.8302902 ]\n",
      "  [0.83710849]\n",
      "  [0.84338909]\n",
      "  [0.84998184]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045162116293795407\n",
      "Predicción post entrenamiento : [[0.85652554]]\n",
      "PERDIDAAAA despues: 0.00045919191325083375\n",
      "loss en el callback: 0.0009510124218650162, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.81151885]\n",
      " [0.81837541]\n",
      " [0.82445753]\n",
      " [0.8302902 ]\n",
      " [0.83710849]\n",
      " [0.84338909]\n",
      " [0.84998184]\n",
      " [0.85670292]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.86260706]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.81151885]\n",
      "  [0.81837541]\n",
      "  [0.82445753]\n",
      "  [0.8302902 ]\n",
      "  [0.83710849]\n",
      "  [0.84338909]\n",
      "  [0.84998184]\n",
      "  [0.85670292]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001879990304587409\n",
      "Predicción post entrenamiento : [[0.8625227]]\n",
      "PERDIDAAAA despues: 0.00018569330859463662\n",
      "loss en el callback: 0.00022623507538810372, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.81837541]\n",
      " [0.82445753]\n",
      " [0.8302902 ]\n",
      " [0.83710849]\n",
      " [0.84338909]\n",
      " [0.84998184]\n",
      " [0.85670292]\n",
      " [0.86260706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.86862236]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.81837541]\n",
      "  [0.82445753]\n",
      "  [0.8302902 ]\n",
      "  [0.83710849]\n",
      "  [0.84338909]\n",
      "  [0.84998184]\n",
      "  [0.85670292]\n",
      "  [0.86260706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011867734137922525\n",
      "Predicción post entrenamiento : [[0.86783606]]\n",
      "PERDIDAAAA despues: 0.001133215962909162\n",
      "loss en el callback: 0.016735540702939034, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.82445753]\n",
      " [0.8302902 ]\n",
      " [0.83710849]\n",
      " [0.84338909]\n",
      " [0.84998184]\n",
      " [0.85670292]\n",
      " [0.86260706]\n",
      " [0.86862236]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.87379]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.82445753]\n",
      "  [0.8302902 ]\n",
      "  [0.83710849]\n",
      "  [0.84338909]\n",
      "  [0.84998184]\n",
      "  [0.85670292]\n",
      "  [0.86260706]\n",
      "  [0.86862236]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003495073760859668\n",
      "Predicción post entrenamiento : [[0.8739663]]\n",
      "PERDIDAAAA despues: 0.00035612849751487374\n",
      "loss en el callback: 0.0011840193765237927, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.8302902 ]\n",
      " [0.83710849]\n",
      " [0.84338909]\n",
      " [0.84998184]\n",
      " [0.85670292]\n",
      " [0.86260706]\n",
      " [0.86862236]\n",
      " [0.87379003]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.87999344]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.8302902 ]\n",
      "  [0.83710849]\n",
      "  [0.84338909]\n",
      "  [0.84998184]\n",
      "  [0.85670292]\n",
      "  [0.86260706]\n",
      "  [0.86862236]\n",
      "  [0.87379003]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2574518879991956e-05\n",
      "Predicción post entrenamiento : [[0.8800997]]\n",
      "PERDIDAAAA despues: 2.3595695893163793e-05\n",
      "loss en el callback: 0.0003869186621159315, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.83710849]\n",
      " [0.84338909]\n",
      " [0.84998184]\n",
      " [0.85670292]\n",
      " [0.86260706]\n",
      " [0.86862236]\n",
      " [0.87379003]\n",
      " [0.87999344]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8862776]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.83710849]\n",
      "  [0.84338909]\n",
      "  [0.84998184]\n",
      "  [0.85670292]\n",
      "  [0.86260706]\n",
      "  [0.86862236]\n",
      "  [0.87379003]\n",
      "  [0.87999344]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008552955114282668\n",
      "Predicción post entrenamiento : [[0.8862534]]\n",
      "PERDIDAAAA despues: 0.0008538806578144431\n",
      "loss en el callback: 2.161748125217855e-05, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.84338909]\n",
      " [0.84998184]\n",
      " [0.85670292]\n",
      " [0.86260706]\n",
      " [0.86862236]\n",
      " [0.87379003]\n",
      " [0.87999344]\n",
      " [0.88627762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.89227086]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.84338909]\n",
      "  [0.84998184]\n",
      "  [0.85670292]\n",
      "  [0.86260706]\n",
      "  [0.86862236]\n",
      "  [0.87379003]\n",
      "  [0.87999344]\n",
      "  [0.88627762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017819141503423452\n",
      "Predicción post entrenamiento : [[0.89183706]]\n",
      "PERDIDAAAA despues: 0.0017454783665016294\n",
      "loss en el callback: 0.0055963085032999516, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.84998184]\n",
      " [0.85670292]\n",
      " [0.86260706]\n",
      " [0.86862236]\n",
      " [0.87379003]\n",
      " [0.87999344]\n",
      " [0.88627762]\n",
      " [0.89227086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8978223]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.84998184]\n",
      "  [0.85670292]\n",
      "  [0.86260706]\n",
      "  [0.86862236]\n",
      "  [0.87379003]\n",
      "  [0.87999344]\n",
      "  [0.88627762]\n",
      "  [0.89227086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030388443265110254\n",
      "Predicción post entrenamiento : [[0.89745986]]\n",
      "PERDIDAAAA despues: 0.0029990144539624453\n",
      "loss en el callback: 0.004471649415791035, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.85670292]\n",
      " [0.86260706]\n",
      " [0.86862236]\n",
      " [0.87379003]\n",
      " [0.87999344]\n",
      " [0.88627762]\n",
      " [0.89227086]\n",
      " [0.89782232]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9032916]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.85670292]\n",
      "  [0.86260706]\n",
      "  [0.86862236]\n",
      "  [0.87379003]\n",
      "  [0.87999344]\n",
      "  [0.88627762]\n",
      "  [0.89227086]\n",
      "  [0.89782232]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006456885952502489\n",
      "Predicción post entrenamiento : [[0.90312725]]\n",
      "PERDIDAAAA despues: 0.006430503446608782\n",
      "loss en el callback: 0.000987586798146367, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.86260706]\n",
      " [0.86862236]\n",
      " [0.87379003]\n",
      " [0.87999344]\n",
      " [0.88627762]\n",
      " [0.89227086]\n",
      " [0.89782232]\n",
      " [0.90329158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9087282]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.86260706]\n",
      "  [0.86862236]\n",
      "  [0.87379003]\n",
      "  [0.87999344]\n",
      "  [0.88627762]\n",
      "  [0.89227086]\n",
      "  [0.89782232]\n",
      "  [0.90329158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018015585839748383\n",
      "Predicción post entrenamiento : [[0.90786546]]\n",
      "PERDIDAAAA despues: 0.017784738913178444\n",
      "loss en el callback: 0.024562086910009384, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.86862236]\n",
      " [0.87379003]\n",
      " [0.87999344]\n",
      " [0.88627762]\n",
      " [0.89227086]\n",
      " [0.89782232]\n",
      " [0.90329158]\n",
      " [0.90872818]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9134509]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.86862236]\n",
      "  [0.87379003]\n",
      "  [0.87999344]\n",
      "  [0.88627762]\n",
      "  [0.89227086]\n",
      "  [0.89782232]\n",
      "  [0.90329158]\n",
      "  [0.90872818]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016707824543118477\n",
      "Predicción post entrenamiento : [[0.91166514]]\n",
      "PERDIDAAAA despues: 0.016249364241957664\n",
      "loss en el callback: 0.08871196955442429, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.87379003]\n",
      " [0.87999344]\n",
      " [0.88627762]\n",
      " [0.89227086]\n",
      " [0.89782232]\n",
      " [0.90329158]\n",
      " [0.90872818]\n",
      " [0.9134509 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.91718274]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.87379003]\n",
      "  [0.87999344]\n",
      "  [0.88627762]\n",
      "  [0.89227086]\n",
      "  [0.89782232]\n",
      "  [0.90329158]\n",
      "  [0.90872818]\n",
      "  [0.9134509 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003299173666164279\n",
      "Predicción post entrenamiento : [[0.917146]]\n",
      "PERDIDAAAA despues: 0.0032949571032077074\n",
      "loss en el callback: 5.197574137127958e-05, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.87999344]\n",
      " [0.88627762]\n",
      " [0.89227086]\n",
      " [0.89782232]\n",
      " [0.90329158]\n",
      " [0.90872818]\n",
      " [0.9134509 ]\n",
      " [0.91718274]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.92283314]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.87999344]\n",
      "  [0.88627762]\n",
      "  [0.89227086]\n",
      "  [0.89782232]\n",
      "  [0.90329158]\n",
      "  [0.90872818]\n",
      "  [0.9134509 ]\n",
      "  [0.91718274]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004694044124335051\n",
      "Predicción post entrenamiento : [[0.9218734]]\n",
      "PERDIDAAAA despues: 0.004563454072922468\n",
      "loss en el callback: 0.027289148420095444, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.88627762]\n",
      " [0.89227086]\n",
      " [0.89782232]\n",
      " [0.90329158]\n",
      " [0.90872818]\n",
      " [0.9134509 ]\n",
      " [0.91718274]\n",
      " [0.92283314]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.92738503]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.88627762]\n",
      "  [0.89227086]\n",
      "  [0.89782232]\n",
      "  [0.90329158]\n",
      "  [0.90872818]\n",
      "  [0.9134509 ]\n",
      "  [0.91718274]\n",
      "  [0.92283314]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008190271444618702\n",
      "Predicción post entrenamiento : [[0.92749226]]\n",
      "PERDIDAAAA despues: 0.008209691382944584\n",
      "loss en el callback: 0.00046623338130302727, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.89227086]\n",
      " [0.89782232]\n",
      " [0.90329158]\n",
      " [0.90872818]\n",
      " [0.9134509 ]\n",
      " [0.91718274]\n",
      " [0.92283314]\n",
      " [0.92738503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9327375]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.89227086]\n",
      "  [0.89782232]\n",
      "  [0.90329158]\n",
      "  [0.90872818]\n",
      "  [0.9134509 ]\n",
      "  [0.91718274]\n",
      "  [0.92283314]\n",
      "  [0.92738503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010573321022093296\n",
      "Predicción post entrenamiento : [[0.9311426]]\n",
      "PERDIDAAAA despues: 0.010247867554426193\n",
      "loss en el callback: 0.06570831686258316, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.89782232]\n",
      " [0.90329158]\n",
      " [0.90872818]\n",
      " [0.9134509 ]\n",
      " [0.91718274]\n",
      " [0.92283314]\n",
      " [0.92738503]\n",
      " [0.93273753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.93614095]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.89782232]\n",
      "  [0.90329158]\n",
      "  [0.90872818]\n",
      "  [0.9134509 ]\n",
      "  [0.91718274]\n",
      "  [0.92283314]\n",
      "  [0.92738503]\n",
      "  [0.93273753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002390033332630992\n",
      "Predicción post entrenamiento : [[0.9366669]]\n",
      "PERDIDAAAA despues: 0.0024417354725301266\n",
      "loss en el callback: 0.012482495978474617, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.90329158]\n",
      " [0.90872818]\n",
      " [0.9134509 ]\n",
      " [0.91718274]\n",
      " [0.92283314]\n",
      " [0.92738503]\n",
      " [0.93273753]\n",
      " [0.93614095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.94149977]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.90329158]\n",
      "  [0.90872818]\n",
      "  [0.9134509 ]\n",
      "  [0.91718274]\n",
      "  [0.92283314]\n",
      "  [0.92738503]\n",
      "  [0.93273753]\n",
      "  [0.93614095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0066839549690485\n",
      "Predicción post entrenamiento : [[0.941006]]\n",
      "PERDIDAAAA despues: 0.006603463087230921\n",
      "loss en el callback: 0.009622441604733467, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.90872818]\n",
      " [0.9134509 ]\n",
      " [0.91718274]\n",
      " [0.92283314]\n",
      " [0.92738503]\n",
      " [0.93273753]\n",
      " [0.93614095]\n",
      " [0.94149977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.94565386]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.90872818]\n",
      "  [0.9134509 ]\n",
      "  [0.91718274]\n",
      "  [0.92283314]\n",
      "  [0.92738503]\n",
      "  [0.93273753]\n",
      "  [0.93614095]\n",
      "  [0.94149977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011248046532273293\n",
      "Predicción post entrenamiento : [[0.9454624]]\n",
      "PERDIDAAAA despues: 0.011207474395632744\n",
      "loss en el callback: 0.0014980717096477747, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.9134509 ]\n",
      " [0.91718274]\n",
      " [0.92283314]\n",
      " [0.92738503]\n",
      " [0.93273753]\n",
      " [0.93614095]\n",
      " [0.94149977]\n",
      " [0.94565386]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9498972]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.9134509 ]\n",
      "  [0.91718274]\n",
      "  [0.92283314]\n",
      "  [0.92738503]\n",
      "  [0.93273753]\n",
      "  [0.93614095]\n",
      "  [0.94149977]\n",
      "  [0.94565386]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027586722746491432\n",
      "Predicción post entrenamiento : [[0.94912726]]\n",
      "PERDIDAAAA despues: 0.02733154222369194\n",
      "loss en el callback: 0.022471265867352486, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.91718274]\n",
      " [0.92283314]\n",
      " [0.92738503]\n",
      " [0.93273753]\n",
      " [0.93614095]\n",
      " [0.94149977]\n",
      " [0.94565386]\n",
      " [0.94989723]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.95353746]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.91718274]\n",
      "  [0.92283314]\n",
      "  [0.92738503]\n",
      "  [0.93273753]\n",
      "  [0.93614095]\n",
      "  [0.94149977]\n",
      "  [0.94565386]\n",
      "  [0.94989723]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018292555585503578\n",
      "Predicción post entrenamiento : [[0.9533851]]\n",
      "PERDIDAAAA despues: 0.018251366913318634\n",
      "loss en el callback: 0.0009901883313432336, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.92283314]\n",
      " [0.92738503]\n",
      " [0.93273753]\n",
      " [0.93614095]\n",
      " [0.94149977]\n",
      " [0.94565386]\n",
      " [0.94989723]\n",
      " [0.95353746]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9580737]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.92283314]\n",
      "  [0.92738503]\n",
      "  [0.93273753]\n",
      "  [0.93614095]\n",
      "  [0.94149977]\n",
      "  [0.94565386]\n",
      "  [0.94989723]\n",
      "  [0.95353746]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027858110144734383\n",
      "Predicción post entrenamiento : [[0.95686764]]\n",
      "PERDIDAAAA despues: 0.027456970885396004\n",
      "loss en el callback: 0.048866063356399536, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.92738503]\n",
      " [0.93273753]\n",
      " [0.93614095]\n",
      " [0.94149977]\n",
      " [0.94565386]\n",
      " [0.94989723]\n",
      " [0.95353746]\n",
      " [0.95807368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9612368]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.92738503]\n",
      "  [0.93273753]\n",
      "  [0.93614095]\n",
      "  [0.94149977]\n",
      "  [0.94565386]\n",
      "  [0.94989723]\n",
      "  [0.95353746]\n",
      "  [0.95807368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04027199000120163\n",
      "Predicción post entrenamiento : [[0.9593119]]\n",
      "PERDIDAAAA despues: 0.03950313478708267\n",
      "loss en el callback: 0.10948913544416428, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.93273753]\n",
      " [0.93614095]\n",
      " [0.94149977]\n",
      " [0.94565386]\n",
      " [0.94989723]\n",
      " [0.95353746]\n",
      " [0.95807368]\n",
      " [0.96123677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.96363884]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.93273753]\n",
      "  [0.93614095]\n",
      "  [0.94149977]\n",
      "  [0.94565386]\n",
      "  [0.94989723]\n",
      "  [0.95353746]\n",
      "  [0.95807368]\n",
      "  [0.96123677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029613304883241653\n",
      "Predicción post entrenamiento : [[0.96359473]]\n",
      "PERDIDAAAA despues: 0.02959812618792057\n",
      "loss en el callback: 9.807322203414515e-05, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.93614095]\n",
      " [0.94149977]\n",
      " [0.94565386]\n",
      " [0.94989723]\n",
      " [0.95353746]\n",
      " [0.95807368]\n",
      " [0.96123677]\n",
      " [0.96363884]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.96758705]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.93614095]\n",
      "  [0.94149977]\n",
      "  [0.94565386]\n",
      "  [0.94989723]\n",
      "  [0.95353746]\n",
      "  [0.95807368]\n",
      "  [0.96123677]\n",
      "  [0.96363884]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03955833613872528\n",
      "Predicción post entrenamiento : [[0.96614957]]\n",
      "PERDIDAAAA despues: 0.038988590240478516\n",
      "loss en el callback: 0.06921698153018951, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.94149977]\n",
      " [0.94565386]\n",
      " [0.94989723]\n",
      " [0.95353746]\n",
      " [0.95807368]\n",
      " [0.96123677]\n",
      " [0.96363884]\n",
      " [0.96758705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9703494]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.94149977]\n",
      "  [0.94565386]\n",
      "  [0.94989723]\n",
      "  [0.95353746]\n",
      "  [0.95807368]\n",
      "  [0.96123677]\n",
      "  [0.96363884]\n",
      "  [0.96758705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04066477343440056\n",
      "Predicción post entrenamiento : [[0.96848565]]\n",
      "PERDIDAAAA despues: 0.039916593581438065\n",
      "loss en el callback: 0.1094353049993515, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.94565386]\n",
      " [0.94989723]\n",
      " [0.95353746]\n",
      " [0.95807368]\n",
      " [0.96123677]\n",
      " [0.96363884]\n",
      " [0.96758705]\n",
      " [0.97034937]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9722568]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.94565386]\n",
      "  [0.94989723]\n",
      "  [0.95353746]\n",
      "  [0.95807368]\n",
      "  [0.96123677]\n",
      "  [0.96363884]\n",
      "  [0.96758705]\n",
      "  [0.97034937]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030047321692109108\n",
      "Predicción post entrenamiento : [[0.9711807]]\n",
      "PERDIDAAAA despues: 0.02967541292309761\n",
      "loss en el callback: 0.04516804590821266, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.94989723]\n",
      " [0.95353746]\n",
      " [0.95807368]\n",
      " [0.96123677]\n",
      " [0.96363884]\n",
      " [0.96758705]\n",
      " [0.97034937]\n",
      " [0.97225678]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.97480315]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.94989723]\n",
      "  [0.95353746]\n",
      "  [0.95807368]\n",
      "  [0.96123677]\n",
      "  [0.96363884]\n",
      "  [0.96758705]\n",
      "  [0.97034937]\n",
      "  [0.97225678]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03415076434612274\n",
      "Predicción post entrenamiento : [[0.9738559]]\n",
      "PERDIDAAAA despues: 0.03380156308412552\n",
      "loss en el callback: 0.03742123022675514, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.95353746]\n",
      " [0.95807368]\n",
      " [0.96123677]\n",
      " [0.96363884]\n",
      " [0.96758705]\n",
      " [0.97034937]\n",
      " [0.97225678]\n",
      " [0.97480315]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.97723645]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.95353746]\n",
      "  [0.95807368]\n",
      "  [0.96123677]\n",
      "  [0.96363884]\n",
      "  [0.96758705]\n",
      "  [0.97034937]\n",
      "  [0.97225678]\n",
      "  [0.97480315]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04711764305830002\n",
      "Predicción post entrenamiento : [[0.97660536]]\n",
      "PERDIDAAAA despues: 0.04684406518936157\n",
      "loss en el callback: 0.017760470509529114, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.95807368]\n",
      " [0.96123677]\n",
      " [0.96363884]\n",
      " [0.96758705]\n",
      " [0.97034937]\n",
      " [0.97225678]\n",
      " [0.97480315]\n",
      " [0.97723645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.97985935]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.95807368]\n",
      "  [0.96123677]\n",
      "  [0.96363884]\n",
      "  [0.96758705]\n",
      "  [0.97034937]\n",
      "  [0.97225678]\n",
      "  [0.97480315]\n",
      "  [0.97723645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08671027421951294\n",
      "Predicción post entrenamiento : [[0.9793045]]\n",
      "PERDIDAAAA despues: 0.08638380467891693\n",
      "loss en el callback: 0.017564652487635612, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.96123677]\n",
      " [0.96363884]\n",
      " [0.96758705]\n",
      " [0.97034937]\n",
      " [0.97225678]\n",
      " [0.97480315]\n",
      " [0.97723645]\n",
      " [0.97985935]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.98208845]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.96123677]\n",
      "  [0.96363884]\n",
      "  [0.96758705]\n",
      "  [0.97034937]\n",
      "  [0.97225678]\n",
      "  [0.97480315]\n",
      "  [0.97723645]\n",
      "  [0.97985935]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.142051100730896\n",
      "Predicción post entrenamiento : [[0.9797606]]\n",
      "PERDIDAAAA despues: 0.14030179381370544\n",
      "loss en el callback: 0.19682295620441437, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.96363884]\n",
      " [0.96758705]\n",
      " [0.97034937]\n",
      " [0.97225678]\n",
      " [0.97480315]\n",
      " [0.97723645]\n",
      " [0.97985935]\n",
      " [0.98208845]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.98241705]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.96363884]\n",
      "  [0.96758705]\n",
      "  [0.97034937]\n",
      "  [0.97225678]\n",
      "  [0.97480315]\n",
      "  [0.97723645]\n",
      "  [0.97985935]\n",
      "  [0.98208845]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10084337741136551\n",
      "Predicción post entrenamiento : [[0.98065823]]\n",
      "PERDIDAAAA despues: 0.09972941875457764\n",
      "loss en el callback: 0.11900799721479416, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.96758705]\n",
      " [0.97034937]\n",
      " [0.97225678]\n",
      " [0.97480315]\n",
      " [0.97723645]\n",
      " [0.97985935]\n",
      " [0.98208845]\n",
      " [0.98241705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9833812]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.96758705]\n",
      "  [0.97034937]\n",
      "  [0.97225678]\n",
      "  [0.97480315]\n",
      "  [0.97723645]\n",
      "  [0.97985935]\n",
      "  [0.98208845]\n",
      "  [0.98241705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0759090855717659\n",
      "Predicción post entrenamiento : [[0.9820789]]\n",
      "PERDIDAAAA despues: 0.07519316673278809\n",
      "loss en el callback: 0.07051292061805725, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.97034937]\n",
      " [0.97225678]\n",
      " [0.97480315]\n",
      " [0.97723645]\n",
      " [0.97985935]\n",
      " [0.98208845]\n",
      " [0.98241705]\n",
      " [0.98338121]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9843403]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.97034937]\n",
      "  [0.97225678]\n",
      "  [0.97480315]\n",
      "  [0.97723645]\n",
      "  [0.97985935]\n",
      "  [0.98208845]\n",
      "  [0.98241705]\n",
      "  [0.98338121]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10206857323646545\n",
      "Predicción post entrenamiento : [[0.9821707]]\n",
      "PERDIDAAAA despues: 0.10068698227405548\n",
      "loss en el callback: 0.1628066450357437, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.97225678]\n",
      " [0.97480315]\n",
      " [0.97723645]\n",
      " [0.97985935]\n",
      " [0.98208845]\n",
      " [0.98241705]\n",
      " [0.98338121]\n",
      " [0.98434031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9842382]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.97225678]\n",
      "  [0.97480315]\n",
      "  [0.97723645]\n",
      "  [0.97985935]\n",
      "  [0.98208845]\n",
      "  [0.98241705]\n",
      "  [0.98338121]\n",
      "  [0.98434031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07446678727865219\n",
      "Predicción post entrenamiento : [[0.9829952]]\n",
      "PERDIDAAAA despues: 0.07378993928432465\n",
      "loss en el callback: 0.06812397390604019, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.97480315]\n",
      " [0.97723645]\n",
      " [0.97985935]\n",
      " [0.98208845]\n",
      " [0.98241705]\n",
      " [0.98338121]\n",
      " [0.98434031]\n",
      " [0.98423821]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9850655]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.97480315]\n",
      "  [0.97723645]\n",
      "  [0.97985935]\n",
      "  [0.98208845]\n",
      "  [0.98241705]\n",
      "  [0.98338121]\n",
      "  [0.98434031]\n",
      "  [0.98423821]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09474615752696991\n",
      "Predicción post entrenamiento : [[0.9833364]]\n",
      "PERDIDAAAA despues: 0.09368466585874557\n",
      "loss en el callback: 0.11620915681123734, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.97723645]\n",
      " [0.97985935]\n",
      " [0.98208845]\n",
      " [0.98241705]\n",
      " [0.98338121]\n",
      " [0.98434031]\n",
      " [0.98423821]\n",
      " [0.98506552]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.98514706]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.97723645]\n",
      "  [0.97985935]\n",
      "  [0.98208845]\n",
      "  [0.98241705]\n",
      "  [0.98338121]\n",
      "  [0.98434031]\n",
      "  [0.98423821]\n",
      "  [0.98506552]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049746543169021606\n",
      "Predicción post entrenamiento : [[0.98343307]]\n",
      "PERDIDAAAA despues: 0.04898490384221077\n",
      "loss en el callback: 0.10630077868700027, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.97985935]\n",
      " [0.98208845]\n",
      " [0.98241705]\n",
      " [0.98338121]\n",
      " [0.98434031]\n",
      " [0.98423821]\n",
      " [0.98506552]\n",
      " [0.98514706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9849213]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.97985935]\n",
      "  [0.98208845]\n",
      "  [0.98241705]\n",
      "  [0.98338121]\n",
      "  [0.98434031]\n",
      "  [0.98423821]\n",
      "  [0.98506552]\n",
      "  [0.98514706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03163764253258705\n",
      "Predicción post entrenamiento : [[0.9845988]]\n",
      "PERDIDAAAA despues: 0.03152303397655487\n",
      "loss en el callback: 0.005424788221716881, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.98208845]\n",
      " [0.98241705]\n",
      " [0.98338121]\n",
      " [0.98434031]\n",
      " [0.98423821]\n",
      " [0.98506552]\n",
      " [0.98514706]\n",
      " [0.98492128]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9856003]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.98208845]\n",
      "  [0.98241705]\n",
      "  [0.98338121]\n",
      "  [0.98434031]\n",
      "  [0.98423821]\n",
      "  [0.98506552]\n",
      "  [0.98514706]\n",
      "  [0.98492128]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029040373861789703\n",
      "Predicción post entrenamiento : [[0.9856092]]\n",
      "PERDIDAAAA despues: 0.029043400660157204\n",
      "loss en el callback: 4.797378551302245e-06, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.98241705]\n",
      " [0.98338121]\n",
      " [0.98434031]\n",
      " [0.98423821]\n",
      " [0.98506552]\n",
      " [0.98514706]\n",
      " [0.98492128]\n",
      " [0.98560029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9861399]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.98241705]\n",
      "  [0.98338121]\n",
      "  [0.98434031]\n",
      "  [0.98423821]\n",
      "  [0.98506552]\n",
      "  [0.98514706]\n",
      "  [0.98492128]\n",
      "  [0.98560029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006384328473359346\n",
      "Predicción post entrenamiento : [[0.9865049]]\n",
      "PERDIDAAAA despues: 0.006442793179303408\n",
      "loss en el callback: 0.00782777089625597, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.98338121]\n",
      " [0.98434031]\n",
      " [0.98423821]\n",
      " [0.98506552]\n",
      " [0.98514706]\n",
      " [0.98492128]\n",
      " [0.98560029]\n",
      " [0.98613989]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9870839]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.98338121]\n",
      "  [0.98434031]\n",
      "  [0.98423821]\n",
      "  [0.98506552]\n",
      "  [0.98514706]\n",
      "  [0.98492128]\n",
      "  [0.98560029]\n",
      "  [0.98613989]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007495757308788598\n",
      "Predicción post entrenamiento : [[0.9868821]]\n",
      "PERDIDAAAA despues: 0.000738565344363451\n",
      "loss en el callback: 0.0018506443593651056, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.98434031]\n",
      " [0.98423821]\n",
      " [0.98506552]\n",
      " [0.98514706]\n",
      " [0.98492128]\n",
      " [0.98560029]\n",
      " [0.98613989]\n",
      " [0.98708391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.98730546]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.98434031]\n",
      "  [0.98423821]\n",
      "  [0.98506552]\n",
      "  [0.98514706]\n",
      "  [0.98492128]\n",
      "  [0.98560029]\n",
      "  [0.98613989]\n",
      "  [0.98708391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000526729563716799\n",
      "Predicción post entrenamiento : [[0.9871018]]\n",
      "PERDIDAAAA despues: 0.0005174223915673792\n",
      "loss en el callback: 0.001831652014516294, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.98423821]\n",
      " [0.98506552]\n",
      " [0.98514706]\n",
      " [0.98492128]\n",
      " [0.98560029]\n",
      " [0.98613989]\n",
      " [0.98708391]\n",
      " [0.98730546]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9873463]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.98423821]\n",
      "  [0.98506552]\n",
      "  [0.98514706]\n",
      "  [0.98492128]\n",
      "  [0.98560029]\n",
      "  [0.98613989]\n",
      "  [0.98708391]\n",
      "  [0.98730546]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0098641412332654\n",
      "Predicción post entrenamiento : [[0.9871631]]\n",
      "PERDIDAAAA despues: 0.009827791713178158\n",
      "loss en el callback: 0.0015402924036607146, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.98506552]\n",
      " [0.98514706]\n",
      " [0.98492128]\n",
      " [0.98560029]\n",
      " [0.98613989]\n",
      " [0.98708391]\n",
      " [0.98730546]\n",
      " [0.98734629]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9875447]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.98506552]\n",
      "  [0.98514706]\n",
      "  [0.98492128]\n",
      "  [0.98560029]\n",
      "  [0.98613989]\n",
      "  [0.98708391]\n",
      "  [0.98730546]\n",
      "  [0.98734629]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008999836631119251\n",
      "Predicción post entrenamiento : [[0.9873425]]\n",
      "PERDIDAAAA despues: 0.008961505256593227\n",
      "loss en el callback: 0.0021329291630536318, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.98514706]\n",
      " [0.98492128]\n",
      " [0.98560029]\n",
      " [0.98613989]\n",
      " [0.98708391]\n",
      " [0.98730546]\n",
      " [0.98734629]\n",
      " [0.98754472]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.98758703]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.98514706]\n",
      "  [0.98492128]\n",
      "  [0.98560029]\n",
      "  [0.98613989]\n",
      "  [0.98708391]\n",
      "  [0.98730546]\n",
      "  [0.98734629]\n",
      "  [0.98754472]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01262136735022068\n",
      "Predicción post entrenamiento : [[0.9870074]]\n",
      "PERDIDAAAA despues: 0.012491460889577866\n",
      "loss en el callback: 0.017061693593859673, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.98492128]\n",
      " [0.98560029]\n",
      " [0.98613989]\n",
      " [0.98708391]\n",
      " [0.98730546]\n",
      " [0.98734629]\n",
      " [0.98754472]\n",
      " [0.98758703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9873328]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.98492128]\n",
      "  [0.98560029]\n",
      "  [0.98613989]\n",
      "  [0.98708391]\n",
      "  [0.98730546]\n",
      "  [0.98734629]\n",
      "  [0.98754472]\n",
      "  [0.98758703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018632201477885246\n",
      "Predicción post entrenamiento : [[0.98678595]]\n",
      "PERDIDAAAA despues: 0.018483204767107964\n",
      "loss en el callback: 0.013317205011844635, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.98560029]\n",
      " [0.98613989]\n",
      " [0.98708391]\n",
      " [0.98730546]\n",
      " [0.98734629]\n",
      " [0.98754472]\n",
      " [0.98758703]\n",
      " [0.98733282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.98729646]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.98560029]\n",
      "  [0.98613989]\n",
      "  [0.98708391]\n",
      "  [0.98730546]\n",
      "  [0.98734629]\n",
      "  [0.98754472]\n",
      "  [0.98758703]\n",
      "  [0.98733282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01915474608540535\n",
      "Predicción post entrenamiento : [[0.98732644]]\n",
      "PERDIDAAAA despues: 0.019163046032190323\n",
      "loss en el callback: 6.18199774180539e-05, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.98613989]\n",
      " [0.98708391]\n",
      " [0.98730546]\n",
      " [0.98734629]\n",
      " [0.98754472]\n",
      " [0.98758703]\n",
      " [0.98733282]\n",
      " [0.98729646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9877429]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.98613989]\n",
      "  [0.98708391]\n",
      "  [0.98730546]\n",
      "  [0.98734629]\n",
      "  [0.98754472]\n",
      "  [0.98758703]\n",
      "  [0.98733282]\n",
      "  [0.98729646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006413676892407238\n",
      "Predicción post entrenamiento : [[0.98766]]\n",
      "PERDIDAAAA despues: 0.0006371751660481095\n",
      "loss en el callback: 0.0003566731174942106, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.98708391]\n",
      " [0.98730546]\n",
      " [0.98734629]\n",
      " [0.98754472]\n",
      " [0.98758703]\n",
      " [0.98733282]\n",
      " [0.98729646]\n",
      " [0.9877429 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.98799425]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.98708391]\n",
      "  [0.98730546]\n",
      "  [0.98734629]\n",
      "  [0.98754472]\n",
      "  [0.98758703]\n",
      "  [0.98733282]\n",
      "  [0.98729646]\n",
      "  [0.9877429 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00040611642180010676\n",
      "Predicción post entrenamiento : [[0.98827934]]\n",
      "PERDIDAAAA despues: 0.0004176881047897041\n",
      "loss en el callback: 0.004844324197620153, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.98730546]\n",
      " [0.98734629]\n",
      " [0.98754472]\n",
      " [0.98758703]\n",
      " [0.98733282]\n",
      " [0.98729646]\n",
      " [0.9877429 ]\n",
      " [0.98799425]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9883776]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.98730546]\n",
      "  [0.98734629]\n",
      "  [0.98754472]\n",
      "  [0.98758703]\n",
      "  [0.98733282]\n",
      "  [0.98729646]\n",
      "  [0.9877429 ]\n",
      "  [0.98799425]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00227117957547307\n",
      "Predicción post entrenamiento : [[0.9880373]]\n",
      "PERDIDAAAA despues: 0.0022388617508113384\n",
      "loss en el callback: 0.005573786795139313, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.98734629]\n",
      " [0.98754472]\n",
      " [0.98758703]\n",
      " [0.98733282]\n",
      " [0.98729646]\n",
      " [0.9877429 ]\n",
      " [0.98799425]\n",
      " [0.98837757]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9880936]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.98734629]\n",
      "  [0.98754472]\n",
      "  [0.98758703]\n",
      "  [0.98733282]\n",
      "  [0.98729646]\n",
      "  [0.9877429 ]\n",
      "  [0.98799425]\n",
      "  [0.98837757]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024343332916032523\n",
      "Predicción post entrenamiento : [[0.9882643]]\n",
      "PERDIDAAAA despues: 0.0002487893507350236\n",
      "loss en el callback: 0.0016184269916266203, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.98754472]\n",
      " [0.98758703]\n",
      " [0.98733282]\n",
      " [0.98729646]\n",
      " [0.9877429 ]\n",
      " [0.98799425]\n",
      " [0.98837757]\n",
      " [0.98809361]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.98833317]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.98754472]\n",
      "  [0.98758703]\n",
      "  [0.98733282]\n",
      "  [0.98729646]\n",
      "  [0.9877429 ]\n",
      "  [0.98799425]\n",
      "  [0.98837757]\n",
      "  [0.98809361]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.339817966567352e-05\n",
      "Predicción post entrenamiento : [[0.9887539]]\n",
      "PERDIDAAAA despues: 6.636585749220103e-05\n",
      "loss en el callback: 0.011010401882231236, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.98758703]\n",
      " [0.98733282]\n",
      " [0.98729646]\n",
      " [0.9877429 ]\n",
      " [0.98799425]\n",
      " [0.98837757]\n",
      " [0.98809361]\n",
      " [0.98833317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.98879075]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.98758703]\n",
      "  [0.98733282]\n",
      "  [0.98729646]\n",
      "  [0.9877429 ]\n",
      "  [0.98799425]\n",
      "  [0.98837757]\n",
      "  [0.98809361]\n",
      "  [0.98833317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014144399901852012\n",
      "Predicción post entrenamiento : [[0.9889117]]\n",
      "PERDIDAAAA despues: 0.0014235512353479862\n",
      "loss en el callback: 0.0008148523047566414, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.98733282]\n",
      " [0.98729646]\n",
      " [0.9877429 ]\n",
      " [0.98799425]\n",
      " [0.98837757]\n",
      " [0.98809361]\n",
      " [0.98833317]\n",
      " [0.98879075]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9889682]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.98733282]\n",
      "  [0.98729646]\n",
      "  [0.9877429 ]\n",
      "  [0.98799425]\n",
      "  [0.98837757]\n",
      "  [0.98809361]\n",
      "  [0.98833317]\n",
      "  [0.98879075]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008684634231030941\n",
      "Predicción post entrenamiento : [[0.9892172]]\n",
      "PERDIDAAAA despues: 0.008731110952794552\n",
      "loss en el callback: 0.00451069138944149, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.98729646]\n",
      " [0.9877429 ]\n",
      " [0.98799425]\n",
      " [0.98837757]\n",
      " [0.98809361]\n",
      " [0.98833317]\n",
      " [0.98879075]\n",
      " [0.98896819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9893977]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.98729646]\n",
      "  [0.9877429 ]\n",
      "  [0.98799425]\n",
      "  [0.98837757]\n",
      "  [0.98809361]\n",
      "  [0.98833317]\n",
      "  [0.98879075]\n",
      "  [0.98896819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011654586531221867\n",
      "Predicción post entrenamiento : [[0.9888306]]\n",
      "PERDIDAAAA despues: 0.011532468721270561\n",
      "loss en el callback: 0.017002854496240616, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.9877429 ]\n",
      " [0.98799425]\n",
      " [0.98837757]\n",
      " [0.98809361]\n",
      " [0.98833317]\n",
      " [0.98879075]\n",
      " [0.98896819]\n",
      " [0.9893977 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.989087]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.9877429 ]\n",
      "  [0.98799425]\n",
      "  [0.98837757]\n",
      "  [0.98809361]\n",
      "  [0.98833317]\n",
      "  [0.98879075]\n",
      "  [0.98896819]\n",
      "  [0.9893977 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005184080917388201\n",
      "Predicción post entrenamiento : [[0.9890504]]\n",
      "PERDIDAAAA despues: 0.005178812425583601\n",
      "loss en el callback: 8.069672185229138e-05, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.98799425]\n",
      " [0.98837757]\n",
      " [0.98809361]\n",
      " [0.98833317]\n",
      " [0.98879075]\n",
      " [0.98896819]\n",
      " [0.9893977 ]\n",
      " [0.98908699]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9892379]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.98799425]\n",
      "  [0.98837757]\n",
      "  [0.98809361]\n",
      "  [0.98833317]\n",
      "  [0.98879075]\n",
      "  [0.98896819]\n",
      "  [0.9893977 ]\n",
      "  [0.98908699]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0048218234442174435\n",
      "Predicción post entrenamiento : [[0.9890236]]\n",
      "PERDIDAAAA despues: 0.004792110528796911\n",
      "loss en el callback: 0.002622047672048211, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.98837757]\n",
      " [0.98809361]\n",
      " [0.98833317]\n",
      " [0.98879075]\n",
      " [0.98896819]\n",
      " [0.9893977 ]\n",
      " [0.98908699]\n",
      " [0.9892379 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9891916]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.98837757]\n",
      "  [0.98809361]\n",
      "  [0.98833317]\n",
      "  [0.98879075]\n",
      "  [0.98896819]\n",
      "  [0.9893977 ]\n",
      "  [0.98908699]\n",
      "  [0.9892379 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007589358137920499\n",
      "Predicción post entrenamiento : [[0.98938257]]\n",
      "PERDIDAAAA despues: 0.0007694944506511092\n",
      "loss en el callback: 0.002244217786937952, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.98809361]\n",
      " [0.98833317]\n",
      " [0.98879075]\n",
      " [0.98896819]\n",
      " [0.9893977 ]\n",
      " [0.98908699]\n",
      " [0.9892379 ]\n",
      " [0.98919159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9894832]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.98809361]\n",
      "  [0.98833317]\n",
      "  [0.98879075]\n",
      "  [0.98896819]\n",
      "  [0.9893977 ]\n",
      "  [0.98908699]\n",
      "  [0.9892379 ]\n",
      "  [0.98919159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045172503450885415\n",
      "Predicción post entrenamiento : [[0.9891233]]\n",
      "PERDIDAAAA despues: 0.00043655638000927866\n",
      "loss en el callback: 0.006540318951010704, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.98833317]\n",
      " [0.98879075]\n",
      " [0.98896819]\n",
      " [0.9893977 ]\n",
      " [0.98908699]\n",
      " [0.9892379 ]\n",
      " [0.98919159]\n",
      " [0.98948318]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.98935866]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.98833317]\n",
      "  [0.98879075]\n",
      "  [0.98896819]\n",
      "  [0.9893977 ]\n",
      "  [0.98908699]\n",
      "  [0.9892379 ]\n",
      "  [0.98919159]\n",
      "  [0.98948318]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009979497408494353\n",
      "Predicción post entrenamiento : [[0.98924184]]\n",
      "PERDIDAAAA despues: 0.000990582280792296\n",
      "loss en el callback: 0.0008013076731003821, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21036898]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026982272043824196\n",
      "Predicción post entrenamiento : [[0.19171092]]\n",
      "PERDIDAAAA despues: 0.021200746297836304\n",
      "loss en el callback: 0.01884896121919155, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21036898]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.1755877]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21036898]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005092896055430174\n",
      "Predicción post entrenamiento : [[0.16699913]]\n",
      "PERDIDAAAA despues: 0.003940821625292301\n",
      "loss en el callback: 0.003875132417306304, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21036898]\n",
      " [0.1755877 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1706523]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21036898]\n",
      "  [0.1755877 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027055307873524725\n",
      "Predicción post entrenamiento : [[0.17134875]]\n",
      "PERDIDAAAA despues: 0.0002939492405857891\n",
      "loss en el callback: 6.684793333988637e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21036898]\n",
      " [0.1755877 ]\n",
      " [0.1706523 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1822093]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21036898]\n",
      "  [0.1755877 ]\n",
      "  [0.1706523 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006999048637226224\n",
      "Predicción post entrenamiento : [[0.17837812]]\n",
      "PERDIDAAAA despues: 0.000511869671754539\n",
      "loss en el callback: 0.0022103076335042715, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21036898]\n",
      " [0.1755877 ]\n",
      " [0.1706523 ]\n",
      " [0.1822093 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19003095]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21036898]\n",
      "  [0.1755877 ]\n",
      "  [0.1706523 ]\n",
      "  [0.1822093 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0041600177064538\n",
      "Predicción post entrenamiento : [[0.18585448]]\n",
      "PERDIDAAAA despues: 0.0036387115251272917\n",
      "loss en el callback: 0.004305975511670113, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21036898]\n",
      " [0.1755877 ]\n",
      " [0.1706523 ]\n",
      " [0.1822093 ]\n",
      " [0.19003095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19428815]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21036898]\n",
      "  [0.1755877 ]\n",
      "  [0.1706523 ]\n",
      "  [0.1822093 ]\n",
      "  [0.19003095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023627555929124355\n",
      "Predicción post entrenamiento : [[0.19188705]]\n",
      "PERDIDAAAA despues: 0.0021350947208702564\n",
      "loss en el callback: 0.002202265430241823, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21036898]\n",
      " [0.1755877 ]\n",
      " [0.1706523 ]\n",
      " [0.1822093 ]\n",
      " [0.19003095]\n",
      " [0.19428815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.21118054]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21036898]\n",
      "  [0.1755877 ]\n",
      "  [0.1706523 ]\n",
      "  [0.1822093 ]\n",
      "  [0.19003095]\n",
      "  [0.19428815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004189413972198963\n",
      "Predicción post entrenamiento : [[0.20846966]]\n",
      "PERDIDAAAA despues: 0.003845835803076625\n",
      "loss en el callback: 0.003638916416093707, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.21036898]\n",
      " [0.1755877 ]\n",
      " [0.1706523 ]\n",
      " [0.1822093 ]\n",
      " [0.19003095]\n",
      " [0.19428815]\n",
      " [0.21118054]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.23197599]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.21036898]\n",
      "  [0.1755877 ]\n",
      "  [0.1706523 ]\n",
      "  [0.1822093 ]\n",
      "  [0.19003095]\n",
      "  [0.19428815]\n",
      "  [0.21118054]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012908177450299263\n",
      "Predicción post entrenamiento : [[0.22921208]]\n",
      "PERDIDAAAA despues: 0.0010998535435646772\n",
      "loss en el callback: 0.003727962961420417, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21036898]\n",
      " [0.1755877 ]\n",
      " [0.1706523 ]\n",
      " [0.1822093 ]\n",
      " [0.19003095]\n",
      " [0.19428815]\n",
      " [0.21118054]\n",
      " [0.23197599]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.25733602]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21036898]\n",
      "  [0.1755877 ]\n",
      "  [0.1706523 ]\n",
      "  [0.1822093 ]\n",
      "  [0.19003095]\n",
      "  [0.19428815]\n",
      "  [0.21118054]\n",
      "  [0.23197599]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007185199065133929\n",
      "Predicción post entrenamiento : [[0.25706628]]\n",
      "PERDIDAAAA despues: 0.0007041317876428366\n",
      "loss en el callback: 5.732134741265327e-05, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.1755877 ]\n",
      " [0.1706523 ]\n",
      " [0.1822093 ]\n",
      " [0.19003095]\n",
      " [0.19428815]\n",
      " [0.21118054]\n",
      " [0.23197599]\n",
      " [0.25733602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.25286853]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.1755877 ]\n",
      "  [0.1706523 ]\n",
      "  [0.1822093 ]\n",
      "  [0.19003095]\n",
      "  [0.19428815]\n",
      "  [0.21118054]\n",
      "  [0.23197599]\n",
      "  [0.25733602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019733314402401447\n",
      "Predicción post entrenamiento : [[0.24946326]]\n",
      "PERDIDAAAA despues: 0.0016823878977447748\n",
      "loss en el callback: 0.007822616957128048, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.1706523 ]\n",
      " [0.1822093 ]\n",
      " [0.19003095]\n",
      " [0.19428815]\n",
      " [0.21118054]\n",
      " [0.23197599]\n",
      " [0.25733602]\n",
      " [0.25286853]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25370243]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.1706523 ]\n",
      "  [0.1822093 ]\n",
      "  [0.19003095]\n",
      "  [0.19428815]\n",
      "  [0.21118054]\n",
      "  [0.23197599]\n",
      "  [0.25733602]\n",
      "  [0.25286853]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017446554265916348\n",
      "Predicción post entrenamiento : [[0.25303108]]\n",
      "PERDIDAAAA despues: 0.0016890221741050482\n",
      "loss en el callback: 0.0005231440882198513, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.1822093 ]\n",
      " [0.19003095]\n",
      " [0.19428815]\n",
      " [0.21118054]\n",
      " [0.23197599]\n",
      " [0.25733602]\n",
      " [0.25286853]\n",
      " [0.25370243]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2605516]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.1822093 ]\n",
      "  [0.19003095]\n",
      "  [0.19428815]\n",
      "  [0.21118054]\n",
      "  [0.23197599]\n",
      "  [0.25733602]\n",
      "  [0.25286853]\n",
      "  [0.25370243]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028374369721859694\n",
      "Predicción post entrenamiento : [[0.2605512]]\n",
      "PERDIDAAAA despues: 0.0028373957611620426\n",
      "loss en el callback: 3.091749078976136e-10, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.19003095]\n",
      " [0.19428815]\n",
      " [0.21118054]\n",
      " [0.23197599]\n",
      " [0.25733602]\n",
      " [0.25286853]\n",
      " [0.25370243]\n",
      " [0.2605516 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.26811975]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.19003095]\n",
      "  [0.19428815]\n",
      "  [0.21118054]\n",
      "  [0.23197599]\n",
      "  [0.25733602]\n",
      "  [0.25286853]\n",
      "  [0.25370243]\n",
      "  [0.2605516 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005650721024721861\n",
      "Predicción post entrenamiento : [[0.26513407]]\n",
      "PERDIDAAAA despues: 0.005210759583860636\n",
      "loss en el callback: 0.010917667299509048, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.19428815]\n",
      " [0.21118054]\n",
      " [0.23197599]\n",
      " [0.25733602]\n",
      " [0.25286853]\n",
      " [0.25370243]\n",
      " [0.2605516 ]\n",
      " [0.26811975]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.27349478]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.19428815]\n",
      "  [0.21118054]\n",
      "  [0.23197599]\n",
      "  [0.25733602]\n",
      "  [0.25286853]\n",
      "  [0.25370243]\n",
      "  [0.2605516 ]\n",
      "  [0.26811975]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005878570955246687\n",
      "Predicción post entrenamiento : [[0.27134082]]\n",
      "PERDIDAAAA despues: 0.005552913993597031\n",
      "loss en el callback: 0.006882442161440849, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.21118054]\n",
      " [0.23197599]\n",
      " [0.25733602]\n",
      " [0.25286853]\n",
      " [0.25370243]\n",
      " [0.2605516 ]\n",
      " [0.26811975]\n",
      " [0.27349478]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2813062]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.21118054]\n",
      "  [0.23197599]\n",
      "  [0.25733602]\n",
      "  [0.25286853]\n",
      "  [0.25370243]\n",
      "  [0.2605516 ]\n",
      "  [0.26811975]\n",
      "  [0.27349478]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0044954558834433556\n",
      "Predicción post entrenamiento : [[0.27982506]]\n",
      "PERDIDAAAA despues: 0.004299033433198929\n",
      "loss en el callback: 0.003866327926516533, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.23197599]\n",
      " [0.25733602]\n",
      " [0.25286853]\n",
      " [0.25370243]\n",
      " [0.2605516 ]\n",
      " [0.26811975]\n",
      " [0.27349478]\n",
      " [0.28130621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2884695]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.23197599]\n",
      "  [0.25733602]\n",
      "  [0.25286853]\n",
      "  [0.25370243]\n",
      "  [0.2605516 ]\n",
      "  [0.26811975]\n",
      "  [0.27349478]\n",
      "  [0.28130621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011479929089546204\n",
      "Predicción post entrenamiento : [[0.28576273]]\n",
      "PERDIDAAAA despues: 0.01090722531080246\n",
      "loss en el callback: 0.01347860787063837, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25733602]\n",
      " [0.25286853]\n",
      " [0.25370243]\n",
      " [0.2605516 ]\n",
      " [0.26811975]\n",
      " [0.27349478]\n",
      " [0.28130621]\n",
      " [0.28846949]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.29169196]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25733602]\n",
      "  [0.25286853]\n",
      "  [0.25370243]\n",
      "  [0.2605516 ]\n",
      "  [0.26811975]\n",
      "  [0.27349478]\n",
      "  [0.28130621]\n",
      "  [0.28846949]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013587639667093754\n",
      "Predicción post entrenamiento : [[0.28986403]]\n",
      "PERDIDAAAA despues: 0.013164833188056946\n",
      "loss en el callback: 0.008763762190937996, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.25286853]\n",
      " [0.25370243]\n",
      " [0.2605516 ]\n",
      " [0.26811975]\n",
      " [0.27349478]\n",
      " [0.28130621]\n",
      " [0.28846949]\n",
      " [0.29169196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2914109]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.25286853]\n",
      "  [0.25370243]\n",
      "  [0.2605516 ]\n",
      "  [0.26811975]\n",
      "  [0.27349478]\n",
      "  [0.28130621]\n",
      "  [0.28846949]\n",
      "  [0.29169196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020565349608659744\n",
      "Predicción post entrenamiento : [[0.29006296]]\n",
      "PERDIDAAAA despues: 0.020180564373731613\n",
      "loss en el callback: 0.006676679477095604, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.25370243]\n",
      " [0.2605516 ]\n",
      " [0.26811975]\n",
      " [0.27349478]\n",
      " [0.28130621]\n",
      " [0.28846949]\n",
      " [0.29169196]\n",
      " [0.29141089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.29362032]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.25370243]\n",
      "  [0.2605516 ]\n",
      "  [0.26811975]\n",
      "  [0.27349478]\n",
      "  [0.28130621]\n",
      "  [0.28846949]\n",
      "  [0.29169196]\n",
      "  [0.29141089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018162187188863754\n",
      "Predicción post entrenamiento : [[0.29227123]]\n",
      "PERDIDAAAA despues: 0.017800381407141685\n",
      "loss en el callback: 0.006842496804893017, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.2605516 ]\n",
      " [0.26811975]\n",
      " [0.27349478]\n",
      " [0.28130621]\n",
      " [0.28846949]\n",
      " [0.29169196]\n",
      " [0.29141089]\n",
      " [0.29362032]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.29690376]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.2605516 ]\n",
      "  [0.26811975]\n",
      "  [0.27349478]\n",
      "  [0.28130621]\n",
      "  [0.28846949]\n",
      "  [0.29169196]\n",
      "  [0.29141089]\n",
      "  [0.29362032]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010968412272632122\n",
      "Predicción post entrenamiento : [[0.29487175]]\n",
      "PERDIDAAAA despues: 0.010546915233135223\n",
      "loss en el callback: 0.013264589011669159, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.26811975]\n",
      " [0.27349478]\n",
      " [0.28130621]\n",
      " [0.28846949]\n",
      " [0.29169196]\n",
      " [0.29141089]\n",
      " [0.29362032]\n",
      " [0.29690376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2992322]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.26811975]\n",
      "  [0.27349478]\n",
      "  [0.28130621]\n",
      "  [0.28846949]\n",
      "  [0.29169196]\n",
      "  [0.29141089]\n",
      "  [0.29362032]\n",
      "  [0.29690376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01282732468098402\n",
      "Predicción post entrenamiento : [[0.29834682]]\n",
      "PERDIDAAAA despues: 0.012627552263438702\n",
      "loss en el callback: 0.003737678751349449, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.27349478]\n",
      " [0.28130621]\n",
      " [0.28846949]\n",
      " [0.29169196]\n",
      " [0.29141089]\n",
      " [0.29362032]\n",
      " [0.29690376]\n",
      " [0.29923221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.30211222]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.27349478]\n",
      "  [0.28130621]\n",
      "  [0.28846949]\n",
      "  [0.29169196]\n",
      "  [0.29141089]\n",
      "  [0.29362032]\n",
      "  [0.29690376]\n",
      "  [0.29923221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001236326526850462\n",
      "Predicción post entrenamiento : [[0.30150077]]\n",
      "PERDIDAAAA despues: 0.0011937011731788516\n",
      "loss en el callback: 0.0014232678804546595, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.28130621]\n",
      " [0.28846949]\n",
      " [0.29169196]\n",
      " [0.29141089]\n",
      " [0.29362032]\n",
      " [0.29690376]\n",
      " [0.29923221]\n",
      " [0.30211222]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.30500537]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.28130621]\n",
      "  [0.28846949]\n",
      "  [0.29169196]\n",
      "  [0.29141089]\n",
      "  [0.29362032]\n",
      "  [0.29690376]\n",
      "  [0.29923221]\n",
      "  [0.30211222]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015582753985654563\n",
      "Predicción post entrenamiento : [[0.30469036]]\n",
      "PERDIDAAAA despues: 0.00014806215767748654\n",
      "loss en el callback: 0.0003897140850313008, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.28846949]\n",
      " [0.29169196]\n",
      " [0.29141089]\n",
      " [0.29362032]\n",
      " [0.29690376]\n",
      " [0.29923221]\n",
      " [0.30211222]\n",
      " [0.30500537]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.30722725]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.28846949]\n",
      "  [0.29169196]\n",
      "  [0.29141089]\n",
      "  [0.29362032]\n",
      "  [0.29690376]\n",
      "  [0.29923221]\n",
      "  [0.30211222]\n",
      "  [0.30500537]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010981076047755778\n",
      "Predicción post entrenamiento : [[0.30735588]]\n",
      "PERDIDAAAA despues: 0.0001071315273293294\n",
      "loss en el callback: 7.108858699211851e-05, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.29169196]\n",
      " [0.29141089]\n",
      " [0.29362032]\n",
      " [0.29690376]\n",
      " [0.29923221]\n",
      " [0.30211222]\n",
      " [0.30500537]\n",
      " [0.30722725]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.3088796]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.29169196]\n",
      "  [0.29141089]\n",
      "  [0.29362032]\n",
      "  [0.29690376]\n",
      "  [0.29923221]\n",
      "  [0.30211222]\n",
      "  [0.30500537]\n",
      "  [0.30722725]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4363355148816481e-05\n",
      "Predicción post entrenamiento : [[0.30906528]]\n",
      "PERDIDAAAA despues: 1.2990497452847194e-05\n",
      "loss en el callback: 0.00016499579942319542, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.29141089]\n",
      " [0.29362032]\n",
      " [0.29690376]\n",
      " [0.29923221]\n",
      " [0.30211222]\n",
      " [0.30500537]\n",
      " [0.30722725]\n",
      " [0.30887961]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.31036043]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.29141089]\n",
      "  [0.29362032]\n",
      "  [0.29690376]\n",
      "  [0.29923221]\n",
      "  [0.30211222]\n",
      "  [0.30500537]\n",
      "  [0.30722725]\n",
      "  [0.30887961]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045476292143575847\n",
      "Predicción post entrenamiento : [[0.31036028]]\n",
      "PERDIDAAAA despues: 0.0004547565768007189\n",
      "loss en el callback: 1.4640377798968984e-10, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.29362032]\n",
      " [0.29690376]\n",
      " [0.29923221]\n",
      " [0.30211222]\n",
      " [0.30500537]\n",
      " [0.30722725]\n",
      " [0.30887961]\n",
      " [0.31036043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.31224748]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.29362032]\n",
      "  [0.29690376]\n",
      "  [0.29923221]\n",
      "  [0.30211222]\n",
      "  [0.30500537]\n",
      "  [0.30722725]\n",
      "  [0.30887961]\n",
      "  [0.31036043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008650289964862168\n",
      "Predicción post entrenamiento : [[0.31261933]]\n",
      "PERDIDAAAA despues: 0.0008870401652529836\n",
      "loss en el callback: 0.0010360288433730602, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.29690376]\n",
      " [0.29923221]\n",
      " [0.30211222]\n",
      " [0.30500537]\n",
      " [0.30722725]\n",
      " [0.30887961]\n",
      " [0.31036043]\n",
      " [0.31224748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.31458125]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.29690376]\n",
      "  [0.29923221]\n",
      "  [0.30211222]\n",
      "  [0.30500537]\n",
      "  [0.30722725]\n",
      "  [0.30887961]\n",
      "  [0.31036043]\n",
      "  [0.31224748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022755487589165568\n",
      "Predicción post entrenamiento : [[0.31416646]]\n",
      "PERDIDAAAA despues: 0.00021521281450986862\n",
      "loss en el callback: 0.0008751560817472637, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29923221]\n",
      " [0.30211222]\n",
      " [0.30500537]\n",
      " [0.30722725]\n",
      " [0.30887961]\n",
      " [0.31036043]\n",
      " [0.31224748]\n",
      " [0.31458125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.31593168]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29923221]\n",
      "  [0.30211222]\n",
      "  [0.30500537]\n",
      "  [0.30722725]\n",
      "  [0.30887961]\n",
      "  [0.31036043]\n",
      "  [0.31224748]\n",
      "  [0.31458125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016055736923590302\n",
      "Predicción post entrenamiento : [[0.31563017]]\n",
      "PERDIDAAAA despues: 0.001581501797772944\n",
      "loss en el callback: 0.0006240648799575865, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.30211222]\n",
      " [0.30500537]\n",
      " [0.30722725]\n",
      " [0.30887961]\n",
      " [0.31036043]\n",
      " [0.31224748]\n",
      " [0.31458125]\n",
      " [0.31593168]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.31737828]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.30211222]\n",
      "  [0.30500537]\n",
      "  [0.30722725]\n",
      "  [0.30887961]\n",
      "  [0.31036043]\n",
      "  [0.31224748]\n",
      "  [0.31458125]\n",
      "  [0.31593168]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018214598530903459\n",
      "Predicción post entrenamiento : [[0.31706885]]\n",
      "PERDIDAAAA despues: 0.0017951428890228271\n",
      "loss en el callback: 0.0006581026245839894, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.30500537]\n",
      " [0.30722725]\n",
      " [0.30887961]\n",
      " [0.31036043]\n",
      " [0.31224748]\n",
      " [0.31458125]\n",
      " [0.31593168]\n",
      " [0.31737828]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.31864208]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.30500537]\n",
      "  [0.30722725]\n",
      "  [0.30887961]\n",
      "  [0.31036043]\n",
      "  [0.31224748]\n",
      "  [0.31458125]\n",
      "  [0.31593168]\n",
      "  [0.31737828]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018634306034073234\n",
      "Predicción post entrenamiento : [[0.31849897]]\n",
      "PERDIDAAAA despues: 0.0018510957015678287\n",
      "loss en el callback: 0.00017328026297036558, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.30722725]\n",
      " [0.30887961]\n",
      " [0.31036043]\n",
      " [0.31224748]\n",
      " [0.31458125]\n",
      " [0.31593168]\n",
      " [0.31737828]\n",
      " [0.31864208]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3198467]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.30722725]\n",
      "  [0.30887961]\n",
      "  [0.31036043]\n",
      "  [0.31224748]\n",
      "  [0.31458125]\n",
      "  [0.31593168]\n",
      "  [0.31737828]\n",
      "  [0.31864208]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022222672123461962\n",
      "Predicción post entrenamiento : [[0.31992245]]\n",
      "PERDIDAAAA despues: 0.00021997377916704863\n",
      "loss en el callback: 3.863852543872781e-05, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.30887961]\n",
      " [0.31036043]\n",
      " [0.31224748]\n",
      " [0.31458125]\n",
      " [0.31593168]\n",
      " [0.31737828]\n",
      " [0.31864208]\n",
      " [0.31984669]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.32115868]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.30887961]\n",
      "  [0.31036043]\n",
      "  [0.31224748]\n",
      "  [0.31458125]\n",
      "  [0.31593168]\n",
      "  [0.31737828]\n",
      "  [0.31864208]\n",
      "  [0.31984669]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001191451447084546\n",
      "Predicción post entrenamiento : [[0.32162336]]\n",
      "PERDIDAAAA despues: 0.0011595883406698704\n",
      "loss en el callback: 0.0019094537710770965, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.31036043]\n",
      " [0.31224748]\n",
      " [0.31458125]\n",
      " [0.31593168]\n",
      " [0.31737828]\n",
      " [0.31864208]\n",
      " [0.31984669]\n",
      " [0.32115868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.32285884]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.31036043]\n",
      "  [0.31224748]\n",
      "  [0.31458125]\n",
      "  [0.31593168]\n",
      "  [0.31737828]\n",
      "  [0.31864208]\n",
      "  [0.31984669]\n",
      "  [0.32115868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019133419846184552\n",
      "Predicción post entrenamiento : [[0.32308987]]\n",
      "PERDIDAAAA despues: 0.00018499625730328262\n",
      "loss en el callback: 0.0005065508303232491, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.31224748]\n",
      " [0.31458125]\n",
      " [0.31593168]\n",
      " [0.31737828]\n",
      " [0.31864208]\n",
      " [0.31984669]\n",
      " [0.32115868]\n",
      " [0.32285884]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.32435694]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.31224748]\n",
      "  [0.31458125]\n",
      "  [0.31593168]\n",
      "  [0.31737828]\n",
      "  [0.31864208]\n",
      "  [0.31984669]\n",
      "  [0.32115868]\n",
      "  [0.32285884]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.527962199877948e-05\n",
      "Predicción post entrenamiento : [[0.32482198]]\n",
      "PERDIDAAAA despues: 7.690695929341018e-05\n",
      "loss en el callback: 0.0024358925875276327, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.31458125]\n",
      " [0.31593168]\n",
      " [0.31737828]\n",
      " [0.31864208]\n",
      " [0.31984669]\n",
      " [0.32115868]\n",
      " [0.32285884]\n",
      " [0.32435694]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.32601658]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.31458125]\n",
      "  [0.31593168]\n",
      "  [0.31737828]\n",
      "  [0.31864208]\n",
      "  [0.31984669]\n",
      "  [0.32115868]\n",
      "  [0.32285884]\n",
      "  [0.32435694]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034478064626455307\n",
      "Predicción post entrenamiento : [[0.32700288]]\n",
      "PERDIDAAAA despues: 0.0033329513389617205\n",
      "loss en el callback: 0.013139561749994755, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.31593168]\n",
      " [0.31737828]\n",
      " [0.31864208]\n",
      " [0.31984669]\n",
      " [0.32115868]\n",
      " [0.32285884]\n",
      " [0.32435694]\n",
      " [0.32601658]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.32799828]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.31593168]\n",
      "  [0.31737828]\n",
      "  [0.31864208]\n",
      "  [0.31984669]\n",
      "  [0.32115868]\n",
      "  [0.32285884]\n",
      "  [0.32435694]\n",
      "  [0.32601658]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05909673497080803\n",
      "Predicción post entrenamiento : [[0.3305453]]\n",
      "PERDIDAAAA despues: 0.05786486715078354\n",
      "loss en el callback: 0.07948719710111618, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.31737828]\n",
      " [0.31864208]\n",
      " [0.31984669]\n",
      " [0.32115868]\n",
      " [0.32285884]\n",
      " [0.32435694]\n",
      " [0.32601658]\n",
      " [0.32799828]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.33155614]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.31737828]\n",
      "  [0.31864208]\n",
      "  [0.31984669]\n",
      "  [0.32115868]\n",
      "  [0.32285884]\n",
      "  [0.32435694]\n",
      "  [0.32601658]\n",
      "  [0.32799828]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07007899135351181\n",
      "Predicción post entrenamiento : [[0.33417526]]\n",
      "PERDIDAAAA despues: 0.06869916617870331\n",
      "loss en el callback: 0.057955317199230194, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.31864208]\n",
      " [0.31984669]\n",
      " [0.32115868]\n",
      " [0.32285884]\n",
      " [0.32435694]\n",
      " [0.32601658]\n",
      " [0.32799828]\n",
      " [0.33155614]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.33519834]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.31864208]\n",
      "  [0.31984669]\n",
      "  [0.32115868]\n",
      "  [0.32285884]\n",
      "  [0.32435694]\n",
      "  [0.32601658]\n",
      "  [0.32799828]\n",
      "  [0.33155614]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057305239140987396\n",
      "Predicción post entrenamiento : [[0.3375689]]\n",
      "PERDIDAAAA despues: 0.05617590248584747\n",
      "loss en el callback: 0.060583699494600296, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31984669]\n",
      " [0.32115868]\n",
      " [0.32285884]\n",
      " [0.32435694]\n",
      " [0.32601658]\n",
      " [0.32799828]\n",
      " [0.33155614]\n",
      " [0.33519834]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.33868262]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31984669]\n",
      "  [0.32115868]\n",
      "  [0.32285884]\n",
      "  [0.32435694]\n",
      "  [0.32601658]\n",
      "  [0.32799828]\n",
      "  [0.33155614]\n",
      "  [0.33519834]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07164803147315979\n",
      "Predicción post entrenamiento : [[0.3413812]]\n",
      "PERDIDAAAA despues: 0.07021065056324005\n",
      "loss en el callback: 0.08983243256807327, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.32115868]\n",
      " [0.32285884]\n",
      " [0.32435694]\n",
      " [0.32601658]\n",
      " [0.32799828]\n",
      " [0.33155614]\n",
      " [0.33519834]\n",
      " [0.33868262]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.34265637]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.32115868]\n",
      "  [0.32285884]\n",
      "  [0.32435694]\n",
      "  [0.32601658]\n",
      "  [0.32799828]\n",
      "  [0.33155614]\n",
      "  [0.33519834]\n",
      "  [0.33868262]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05856436863541603\n",
      "Predicción post entrenamiento : [[0.34503385]]\n",
      "PERDIDAAAA despues: 0.0574193149805069\n",
      "loss en el callback: 0.09020185470581055, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.32285884]\n",
      " [0.32435694]\n",
      " [0.32601658]\n",
      " [0.32799828]\n",
      " [0.33155614]\n",
      " [0.33519834]\n",
      " [0.33868262]\n",
      " [0.34265637]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.34651786]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.32285884]\n",
      "  [0.32435694]\n",
      "  [0.32601658]\n",
      "  [0.32799828]\n",
      "  [0.33155614]\n",
      "  [0.33519834]\n",
      "  [0.33868262]\n",
      "  [0.34265637]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049396805465221405\n",
      "Predicción post entrenamiento : [[0.34818146]]\n",
      "PERDIDAAAA despues: 0.04866009205579758\n",
      "loss en el callback: 0.024588819593191147, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.32435694]\n",
      " [0.32601658]\n",
      " [0.32799828]\n",
      " [0.33155614]\n",
      " [0.33519834]\n",
      " [0.33868262]\n",
      " [0.34265637]\n",
      " [0.34651786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.34986052]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.32435694]\n",
      "  [0.32601658]\n",
      "  [0.32799828]\n",
      "  [0.33155614]\n",
      "  [0.33519834]\n",
      "  [0.33868262]\n",
      "  [0.34265637]\n",
      "  [0.34651786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08579836785793304\n",
      "Predicción post entrenamiento : [[0.35234085]]\n",
      "PERDIDAAAA despues: 0.08435148000717163\n",
      "loss en el callback: 0.06765103340148926, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.32601658]\n",
      " [0.32799828]\n",
      " [0.33155614]\n",
      " [0.33519834]\n",
      " [0.33868262]\n",
      " [0.34265637]\n",
      " [0.34651786]\n",
      " [0.34986052]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.35434285]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.32601658]\n",
      "  [0.32799828]\n",
      "  [0.33155614]\n",
      "  [0.33519834]\n",
      "  [0.33868262]\n",
      "  [0.34265637]\n",
      "  [0.34651786]\n",
      "  [0.34986052]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0945046991109848\n",
      "Predicción post entrenamiento : [[0.3571462]]\n",
      "PERDIDAAAA despues: 0.09278896450996399\n",
      "loss en el callback: 0.10570121556520462, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.32799828]\n",
      " [0.33155614]\n",
      " [0.33519834]\n",
      " [0.33868262]\n",
      " [0.34265637]\n",
      " [0.34651786]\n",
      " [0.34986052]\n",
      " [0.35434285]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.35952222]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.32799828]\n",
      "  [0.33155614]\n",
      "  [0.33519834]\n",
      "  [0.33868262]\n",
      "  [0.34265637]\n",
      "  [0.34651786]\n",
      "  [0.34986052]\n",
      "  [0.35434285]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0982651636004448\n",
      "Predicción post entrenamiento : [[0.36231863]]\n",
      "PERDIDAAAA despues: 0.09651978313922882\n",
      "loss en el callback: 0.10370317101478577, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.33155614]\n",
      " [0.33519834]\n",
      " [0.33868262]\n",
      " [0.34265637]\n",
      " [0.34651786]\n",
      " [0.34986052]\n",
      " [0.35434285]\n",
      " [0.35952222]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.36508203]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.33155614]\n",
      "  [0.33519834]\n",
      "  [0.33868262]\n",
      "  [0.34265637]\n",
      "  [0.34651786]\n",
      "  [0.34986052]\n",
      "  [0.35434285]\n",
      "  [0.35952222]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11936698853969574\n",
      "Predicción post entrenamiento : [[0.36793965]]\n",
      "PERDIDAAAA despues: 0.11740056425333023\n",
      "loss en el callback: 0.11764081567525864, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.33519834]\n",
      " [0.33868262]\n",
      " [0.34265637]\n",
      " [0.34651786]\n",
      " [0.34986052]\n",
      " [0.35434285]\n",
      " [0.35952222]\n",
      " [0.36508203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.37078464]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.33519834]\n",
      "  [0.33868262]\n",
      "  [0.34265637]\n",
      "  [0.34651786]\n",
      "  [0.34986052]\n",
      "  [0.35434285]\n",
      "  [0.35952222]\n",
      "  [0.36508203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11102627962827682\n",
      "Predicción post entrenamiento : [[0.37348968]]\n",
      "PERDIDAAAA despues: 0.10923092067241669\n",
      "loss en el callback: 0.09529447555541992, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.33868262]\n",
      " [0.34265637]\n",
      " [0.34651786]\n",
      " [0.34986052]\n",
      " [0.35434285]\n",
      " [0.35952222]\n",
      " [0.36508203]\n",
      " [0.37078464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3764416]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.33868262]\n",
      "  [0.34265637]\n",
      "  [0.34651786]\n",
      "  [0.34986052]\n",
      "  [0.35434285]\n",
      "  [0.35952222]\n",
      "  [0.36508203]\n",
      "  [0.37078464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1230577826499939\n",
      "Predicción post entrenamiento : [[0.3793242]]\n",
      "PERDIDAAAA despues: 0.12104368209838867\n",
      "loss en el callback: 0.17857086658477783, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.34265637]\n",
      " [0.34651786]\n",
      " [0.34986052]\n",
      " [0.35434285]\n",
      " [0.35952222]\n",
      " [0.36508203]\n",
      " [0.37078464]\n",
      " [0.3764416 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.38248172]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.34265637]\n",
      "  [0.34651786]\n",
      "  [0.34986052]\n",
      "  [0.35434285]\n",
      "  [0.35952222]\n",
      "  [0.36508203]\n",
      "  [0.37078464]\n",
      "  [0.3764416 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11567236483097076\n",
      "Predicción post entrenamiento : [[0.3853095]]\n",
      "PERDIDAAAA despues: 0.11375688016414642\n",
      "loss en el callback: 0.11030896008014679, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.34651786]\n",
      " [0.34986052]\n",
      " [0.35434285]\n",
      " [0.35952222]\n",
      " [0.36508203]\n",
      " [0.37078464]\n",
      " [0.3764416 ]\n",
      " [0.38248172]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.38862538]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.34651786]\n",
      "  [0.34986052]\n",
      "  [0.35434285]\n",
      "  [0.35952222]\n",
      "  [0.36508203]\n",
      "  [0.37078464]\n",
      "  [0.3764416 ]\n",
      "  [0.38248172]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1468181163072586\n",
      "Predicción post entrenamiento : [[0.3917392]]\n",
      "PERDIDAAAA despues: 0.14444158971309662\n",
      "loss en el callback: 0.16484366357326508, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.34986052]\n",
      " [0.35434285]\n",
      " [0.35952222]\n",
      " [0.36508203]\n",
      " [0.37078464]\n",
      " [0.3764416 ]\n",
      " [0.38248172]\n",
      " [0.38862538]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.39531484]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.34986052]\n",
      "  [0.35434285]\n",
      "  [0.35952222]\n",
      "  [0.36508203]\n",
      "  [0.37078464]\n",
      "  [0.3764416 ]\n",
      "  [0.38248172]\n",
      "  [0.38862538]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10837958753108978\n",
      "Predicción post entrenamiento : [[0.3979612]]\n",
      "PERDIDAAAA despues: 0.1066441684961319\n",
      "loss en el callback: 0.13198596239089966, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.35434285]\n",
      " [0.35952222]\n",
      " [0.36508203]\n",
      " [0.37078464]\n",
      " [0.3764416 ]\n",
      " [0.38248172]\n",
      " [0.38862538]\n",
      " [0.39531484]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.4020173]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.35434285]\n",
      "  [0.35952222]\n",
      "  [0.36508203]\n",
      "  [0.37078464]\n",
      "  [0.3764416 ]\n",
      "  [0.38248172]\n",
      "  [0.38862538]\n",
      "  [0.39531484]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07238274067640305\n",
      "Predicción post entrenamiento : [[0.40377265]]\n",
      "PERDIDAAAA despues: 0.07144130021333694\n",
      "loss en el callback: 0.03627946227788925, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.35952222]\n",
      " [0.36508203]\n",
      " [0.37078464]\n",
      " [0.3764416 ]\n",
      " [0.38248172]\n",
      " [0.38862538]\n",
      " [0.39531484]\n",
      " [0.4020173 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.40812677]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.35952222]\n",
      "  [0.36508203]\n",
      "  [0.37078464]\n",
      "  [0.3764416 ]\n",
      "  [0.38248172]\n",
      "  [0.38862538]\n",
      "  [0.39531484]\n",
      "  [0.4020173 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07056623697280884\n",
      "Predicción post entrenamiento : [[0.4103133]]\n",
      "PERDIDAAAA despues: 0.0694093406200409\n",
      "loss en el callback: 0.10139043629169464, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.36508203]\n",
      " [0.37078464]\n",
      " [0.3764416 ]\n",
      " [0.38248172]\n",
      " [0.38862538]\n",
      " [0.39531484]\n",
      " [0.4020173 ]\n",
      " [0.40812677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.41485882]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.36508203]\n",
      "  [0.37078464]\n",
      "  [0.3764416 ]\n",
      "  [0.38248172]\n",
      "  [0.38862538]\n",
      "  [0.39531484]\n",
      "  [0.4020173 ]\n",
      "  [0.40812677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08975595235824585\n",
      "Predicción post entrenamiento : [[0.41703638]]\n",
      "PERDIDAAAA despues: 0.0884559229016304\n",
      "loss en el callback: 0.07468153536319733, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.37078464]\n",
      " [0.3764416 ]\n",
      " [0.38248172]\n",
      " [0.38862538]\n",
      " [0.39531484]\n",
      " [0.4020173 ]\n",
      " [0.40812677]\n",
      " [0.41485882]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.42172477]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.37078464]\n",
      "  [0.3764416 ]\n",
      "  [0.38248172]\n",
      "  [0.38862538]\n",
      "  [0.39531484]\n",
      "  [0.4020173 ]\n",
      "  [0.40812677]\n",
      "  [0.41485882]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10379542410373688\n",
      "Predicción post entrenamiento : [[0.42415148]]\n",
      "PERDIDAAAA despues: 0.10223767161369324\n",
      "loss en el callback: 0.09255281090736389, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.3764416 ]\n",
      " [0.38248172]\n",
      " [0.38862538]\n",
      " [0.39531484]\n",
      " [0.4020173 ]\n",
      " [0.40812677]\n",
      " [0.41485882]\n",
      " [0.42172477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42898676]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.3764416 ]\n",
      "  [0.38248172]\n",
      "  [0.38862538]\n",
      "  [0.39531484]\n",
      "  [0.4020173 ]\n",
      "  [0.40812677]\n",
      "  [0.41485882]\n",
      "  [0.42172477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0862017571926117\n",
      "Predicción post entrenamiento : [[0.43123046]]\n",
      "PERDIDAAAA despues: 0.08488929271697998\n",
      "loss en el callback: 0.13482046127319336, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.38248172]\n",
      " [0.38862538]\n",
      " [0.39531484]\n",
      " [0.4020173 ]\n",
      " [0.40812677]\n",
      " [0.41485882]\n",
      " [0.42172477]\n",
      " [0.42898676]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.43626553]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.38248172]\n",
      "  [0.38862538]\n",
      "  [0.39531484]\n",
      "  [0.4020173 ]\n",
      "  [0.40812677]\n",
      "  [0.41485882]\n",
      "  [0.42172477]\n",
      "  [0.42898676]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06920889019966125\n",
      "Predicción post entrenamiento : [[0.4381716]]\n",
      "PERDIDAAAA despues: 0.06820964068174362\n",
      "loss en el callback: 0.06307945400476456, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.38862538]\n",
      " [0.39531484]\n",
      " [0.4020173 ]\n",
      " [0.40812677]\n",
      " [0.41485882]\n",
      " [0.42172477]\n",
      " [0.42898676]\n",
      " [0.43626553]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.44335333]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.38862538]\n",
      "  [0.39531484]\n",
      "  [0.4020173 ]\n",
      "  [0.40812677]\n",
      "  [0.41485882]\n",
      "  [0.42172477]\n",
      "  [0.42898676]\n",
      "  [0.43626553]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08641118556261063\n",
      "Predicción post entrenamiento : [[0.4455864]]\n",
      "PERDIDAAAA despues: 0.08510331064462662\n",
      "loss en el callback: 0.10863930732011795, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.39531484]\n",
      " [0.4020173 ]\n",
      " [0.40812677]\n",
      " [0.41485882]\n",
      " [0.42172477]\n",
      " [0.42898676]\n",
      " [0.43626553]\n",
      " [0.44335333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.45092693]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.39531484]\n",
      "  [0.4020173 ]\n",
      "  [0.40812677]\n",
      "  [0.41485882]\n",
      "  [0.42172477]\n",
      "  [0.42898676]\n",
      "  [0.43626553]\n",
      "  [0.44335333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07316965609788895\n",
      "Predicción post entrenamiento : [[0.45283002]]\n",
      "PERDIDAAAA despues: 0.07214371114969254\n",
      "loss en el callback: 0.05808423087000847, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.4020173 ]\n",
      " [0.40812677]\n",
      " [0.41485882]\n",
      " [0.42172477]\n",
      " [0.42898676]\n",
      " [0.43626553]\n",
      " [0.44335333]\n",
      " [0.45092693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45822212]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.4020173 ]\n",
      "  [0.40812677]\n",
      "  [0.41485882]\n",
      "  [0.42172477]\n",
      "  [0.42898676]\n",
      "  [0.43626553]\n",
      "  [0.44335333]\n",
      "  [0.45092693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06785586476325989\n",
      "Predicción post entrenamiento : [[0.46020433]]\n",
      "PERDIDAAAA despues: 0.06682709604501724\n",
      "loss en el callback: 0.0906904935836792, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.40812677]\n",
      " [0.41485882]\n",
      " [0.42172477]\n",
      " [0.42898676]\n",
      " [0.43626553]\n",
      " [0.44335333]\n",
      " [0.45092693]\n",
      " [0.45822212]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4656686]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.40812677]\n",
      "  [0.41485882]\n",
      "  [0.42172477]\n",
      "  [0.42898676]\n",
      "  [0.43626553]\n",
      "  [0.44335333]\n",
      "  [0.45092693]\n",
      "  [0.45822212]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043467551469802856\n",
      "Predicción post entrenamiento : [[0.46717808]]\n",
      "PERDIDAAAA despues: 0.04284040629863739\n",
      "loss en el callback: 0.04365401715040207, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.41485882]\n",
      " [0.42172477]\n",
      " [0.42898676]\n",
      " [0.43626553]\n",
      " [0.44335333]\n",
      " [0.45092693]\n",
      " [0.45822212]\n",
      " [0.46566859]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47290152]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.41485882]\n",
      "  [0.42172477]\n",
      "  [0.42898676]\n",
      "  [0.43626553]\n",
      "  [0.44335333]\n",
      "  [0.45092693]\n",
      "  [0.45822212]\n",
      "  [0.46566859]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05092465505003929\n",
      "Predicción post entrenamiento : [[0.47451344]]\n",
      "PERDIDAAAA despues: 0.05019974336028099\n",
      "loss en el callback: 0.052935533225536346, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.42172477]\n",
      " [0.42898676]\n",
      " [0.43626553]\n",
      " [0.44335333]\n",
      " [0.45092693]\n",
      " [0.45822212]\n",
      " [0.46566859]\n",
      " [0.47290152]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.48037943]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.42172477]\n",
      "  [0.42898676]\n",
      "  [0.43626553]\n",
      "  [0.44335333]\n",
      "  [0.45092693]\n",
      "  [0.45822212]\n",
      "  [0.46566859]\n",
      "  [0.47290152]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05791671201586723\n",
      "Predicción post entrenamiento : [[0.48234624]]\n",
      "PERDIDAAAA despues: 0.05697391927242279\n",
      "loss en el callback: 0.09008104354143143, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42898676]\n",
      " [0.43626553]\n",
      " [0.44335333]\n",
      " [0.45092693]\n",
      " [0.45822212]\n",
      " [0.46566859]\n",
      " [0.47290152]\n",
      " [0.48037943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4883463]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42898676]\n",
      "  [0.43626553]\n",
      "  [0.44335333]\n",
      "  [0.45092693]\n",
      "  [0.45822212]\n",
      "  [0.46566859]\n",
      "  [0.47290152]\n",
      "  [0.48037943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05486922711133957\n",
      "Predicción post entrenamiento : [[0.49010137]]\n",
      "PERDIDAAAA despues: 0.05405009165406227\n",
      "loss en el callback: 0.06735673546791077, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.43626553]\n",
      " [0.44335333]\n",
      " [0.45092693]\n",
      " [0.45822212]\n",
      " [0.46566859]\n",
      " [0.47290152]\n",
      " [0.48037943]\n",
      " [0.48834631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.49615115]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.43626553]\n",
      "  [0.44335333]\n",
      "  [0.45092693]\n",
      "  [0.45822212]\n",
      "  [0.46566859]\n",
      "  [0.47290152]\n",
      "  [0.48037943]\n",
      "  [0.48834631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06767536699771881\n",
      "Predicción post entrenamiento : [[0.49816415]]\n",
      "PERDIDAAAA despues: 0.06663207709789276\n",
      "loss en el callback: 0.08915595710277557, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44335333]\n",
      " [0.45092693]\n",
      " [0.45822212]\n",
      " [0.46566859]\n",
      " [0.47290152]\n",
      " [0.48037943]\n",
      " [0.48834631]\n",
      " [0.49615115]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5042722]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44335333]\n",
      "  [0.45092693]\n",
      "  [0.45822212]\n",
      "  [0.46566859]\n",
      "  [0.47290152]\n",
      "  [0.48037943]\n",
      "  [0.48834631]\n",
      "  [0.49615115]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10453195124864578\n",
      "Predicción post entrenamiento : [[0.50626487]]\n",
      "PERDIDAAAA despues: 0.10324741899967194\n",
      "loss en el callback: 0.06852678209543228, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.45092693]\n",
      " [0.45822212]\n",
      " [0.46566859]\n",
      " [0.47290152]\n",
      " [0.48037943]\n",
      " [0.48834631]\n",
      " [0.49615115]\n",
      " [0.50427222]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.51250213]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.45092693]\n",
      "  [0.45822212]\n",
      "  [0.46566859]\n",
      "  [0.47290152]\n",
      "  [0.48037943]\n",
      "  [0.48834631]\n",
      "  [0.49615115]\n",
      "  [0.50427222]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1064847782254219\n",
      "Predicción post entrenamiento : [[0.5148126]]\n",
      "PERDIDAAAA despues: 0.10498221963644028\n",
      "loss en el callback: 0.1276736557483673, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.45822212]\n",
      " [0.46566859]\n",
      " [0.47290152]\n",
      " [0.48037943]\n",
      " [0.48834631]\n",
      " [0.49615115]\n",
      " [0.50427222]\n",
      " [0.51250213]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5210763]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.45822212]\n",
      "  [0.46566859]\n",
      "  [0.47290152]\n",
      "  [0.48037943]\n",
      "  [0.48834631]\n",
      "  [0.49615115]\n",
      "  [0.50427222]\n",
      "  [0.51250213]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07463249564170837\n",
      "Predicción post entrenamiento : [[0.52286696]]\n",
      "PERDIDAAAA despues: 0.0736573338508606\n",
      "loss en el callback: 0.06144631654024124, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.46566859]\n",
      " [0.47290152]\n",
      " [0.48037943]\n",
      " [0.48834631]\n",
      " [0.49615115]\n",
      " [0.50427222]\n",
      " [0.51250213]\n",
      " [0.52107632]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5292537]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.46566859]\n",
      "  [0.47290152]\n",
      "  [0.48037943]\n",
      "  [0.48834631]\n",
      "  [0.49615115]\n",
      "  [0.50427222]\n",
      "  [0.51250213]\n",
      "  [0.52107632]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06479620933532715\n",
      "Predicción post entrenamiento : [[0.5309573]]\n",
      "PERDIDAAAA despues: 0.06393182277679443\n",
      "loss en el callback: 0.06238608807325363, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.47290152]\n",
      " [0.48037943]\n",
      " [0.48834631]\n",
      " [0.49615115]\n",
      " [0.50427222]\n",
      " [0.51250213]\n",
      " [0.52107632]\n",
      " [0.52925372]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.53746235]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.47290152]\n",
      "  [0.48037943]\n",
      "  [0.48834631]\n",
      "  [0.49615115]\n",
      "  [0.50427222]\n",
      "  [0.51250213]\n",
      "  [0.52107632]\n",
      "  [0.52925372]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05311046168208122\n",
      "Predicción post entrenamiento : [[0.53891677]]\n",
      "PERDIDAAAA despues: 0.052442215383052826\n",
      "loss en el callback: 0.042642224580049515, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.48037943]\n",
      " [0.48834631]\n",
      " [0.49615115]\n",
      " [0.50427222]\n",
      " [0.51250213]\n",
      " [0.52107632]\n",
      " [0.52925372]\n",
      " [0.53746235]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.54563546]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.48037943]\n",
      "  [0.48834631]\n",
      "  [0.49615115]\n",
      "  [0.50427222]\n",
      "  [0.51250213]\n",
      "  [0.52107632]\n",
      "  [0.52925372]\n",
      "  [0.53746235]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05709431692957878\n",
      "Predicción post entrenamiento : [[0.5469939]]\n",
      "PERDIDAAAA despues: 0.05644697695970535\n",
      "loss en el callback: 0.03443191200494766, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.48834631]\n",
      " [0.49615115]\n",
      " [0.50427222]\n",
      " [0.51250213]\n",
      " [0.52107632]\n",
      " [0.52925372]\n",
      " [0.53746235]\n",
      " [0.54563546]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5539016]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.48834631]\n",
      "  [0.49615115]\n",
      "  [0.50427222]\n",
      "  [0.51250213]\n",
      "  [0.52107632]\n",
      "  [0.52925372]\n",
      "  [0.53746235]\n",
      "  [0.54563546]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10551293939352036\n",
      "Predicción post entrenamiento : [[0.55621916]]\n",
      "PERDIDAAAA despues: 0.10401270538568497\n",
      "loss en el callback: 0.14808662235736847, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.49615115]\n",
      " [0.50427222]\n",
      " [0.51250213]\n",
      " [0.52107632]\n",
      " [0.52925372]\n",
      " [0.53746235]\n",
      " [0.54563546]\n",
      " [0.55390161]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.56321466]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.49615115]\n",
      "  [0.50427222]\n",
      "  [0.51250213]\n",
      "  [0.52107632]\n",
      "  [0.52925372]\n",
      "  [0.53746235]\n",
      "  [0.54563546]\n",
      "  [0.55390161]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09760309755802155\n",
      "Predicción post entrenamiento : [[0.56512886]]\n",
      "PERDIDAAAA despues: 0.09641070663928986\n",
      "loss en el callback: 0.069094218313694, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.50427222]\n",
      " [0.51250213]\n",
      " [0.52107632]\n",
      " [0.52925372]\n",
      " [0.53746235]\n",
      " [0.54563546]\n",
      " [0.55390161]\n",
      " [0.56321466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5722766]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.50427222]\n",
      "  [0.51250213]\n",
      "  [0.52107632]\n",
      "  [0.52925372]\n",
      "  [0.53746235]\n",
      "  [0.54563546]\n",
      "  [0.55390161]\n",
      "  [0.56321466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07651817798614502\n",
      "Predicción post entrenamiento : [[0.5737038]]\n",
      "PERDIDAAAA despues: 0.07573061436414719\n",
      "loss en el callback: 0.03463685140013695, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.51250213]\n",
      " [0.52107632]\n",
      " [0.52925372]\n",
      " [0.53746235]\n",
      " [0.54563546]\n",
      " [0.55390161]\n",
      " [0.56321466]\n",
      " [0.57227659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5809437]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.51250213]\n",
      "  [0.52107632]\n",
      "  [0.52925372]\n",
      "  [0.53746235]\n",
      "  [0.54563546]\n",
      "  [0.55390161]\n",
      "  [0.56321466]\n",
      "  [0.57227659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.056332074105739594\n",
      "Predicción post entrenamiento : [[0.5828808]]\n",
      "PERDIDAAAA despues: 0.05541631206870079\n",
      "loss en el callback: 0.12394961714744568, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.52107632]\n",
      " [0.52925372]\n",
      " [0.53746235]\n",
      " [0.54563546]\n",
      " [0.55390161]\n",
      " [0.56321466]\n",
      " [0.57227659]\n",
      " [0.5809437 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5902064]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.52107632]\n",
      "  [0.52925372]\n",
      "  [0.53746235]\n",
      "  [0.54563546]\n",
      "  [0.55390161]\n",
      "  [0.56321466]\n",
      "  [0.57227659]\n",
      "  [0.5809437 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055981893092393875\n",
      "Predicción post entrenamiento : [[0.5919417]]\n",
      "PERDIDAAAA despues: 0.055163729935884476\n",
      "loss en el callback: 0.07546525448560715, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.52925372]\n",
      " [0.53746235]\n",
      " [0.54563546]\n",
      " [0.55390161]\n",
      " [0.56321466]\n",
      " [0.57227659]\n",
      " [0.5809437 ]\n",
      " [0.59020638]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5992787]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.52925372]\n",
      "  [0.53746235]\n",
      "  [0.54563546]\n",
      "  [0.55390161]\n",
      "  [0.56321466]\n",
      "  [0.57227659]\n",
      "  [0.5809437 ]\n",
      "  [0.59020638]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03462420403957367\n",
      "Predicción post entrenamiento : [[0.60008556]]\n",
      "PERDIDAAAA despues: 0.03432457894086838\n",
      "loss en el callback: 0.013278617523610592, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.53746235]\n",
      " [0.54563546]\n",
      " [0.55390161]\n",
      " [0.56321466]\n",
      " [0.57227659]\n",
      " [0.5809437 ]\n",
      " [0.59020638]\n",
      " [0.59927869]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6075644]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.53746235]\n",
      "  [0.54563546]\n",
      "  [0.55390161]\n",
      "  [0.56321466]\n",
      "  [0.57227659]\n",
      "  [0.5809437 ]\n",
      "  [0.59020638]\n",
      "  [0.59927869]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03300202265381813\n",
      "Predicción post entrenamiento : [[0.60829574]]\n",
      "PERDIDAAAA despues: 0.03273683786392212\n",
      "loss en el callback: 0.009727773256599903, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.54563546]\n",
      " [0.55390161]\n",
      " [0.56321466]\n",
      " [0.57227659]\n",
      " [0.5809437 ]\n",
      " [0.59020638]\n",
      " [0.59927869]\n",
      " [0.60756439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.61594194]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.54563546]\n",
      "  [0.55390161]\n",
      "  [0.56321466]\n",
      "  [0.57227659]\n",
      "  [0.5809437 ]\n",
      "  [0.59020638]\n",
      "  [0.59927869]\n",
      "  [0.60756439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047624699771404266\n",
      "Predicción post entrenamiento : [[0.6174346]]\n",
      "PERDIDAAAA despues: 0.046975430101156235\n",
      "loss en el callback: 0.04971612989902496, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.55390161]\n",
      " [0.56321466]\n",
      " [0.57227659]\n",
      " [0.5809437 ]\n",
      " [0.59020638]\n",
      " [0.59927869]\n",
      " [0.60756439]\n",
      " [0.61594194]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6252912]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.55390161]\n",
      "  [0.56321466]\n",
      "  [0.57227659]\n",
      "  [0.5809437 ]\n",
      "  [0.59020638]\n",
      "  [0.59927869]\n",
      "  [0.60756439]\n",
      "  [0.61594194]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035038065165281296\n",
      "Predicción post entrenamiento : [[0.6265529]]\n",
      "PERDIDAAAA despues: 0.03456733375787735\n",
      "loss en el callback: 0.04001134634017944, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.56321466]\n",
      " [0.57227659]\n",
      " [0.5809437 ]\n",
      " [0.59020638]\n",
      " [0.59927869]\n",
      " [0.60756439]\n",
      " [0.61594194]\n",
      " [0.62529123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.63462055]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.56321466]\n",
      "  [0.57227659]\n",
      "  [0.5809437 ]\n",
      "  [0.59020638]\n",
      "  [0.59927869]\n",
      "  [0.60756439]\n",
      "  [0.61594194]\n",
      "  [0.62529123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027761992067098618\n",
      "Predicción post entrenamiento : [[0.6350887]]\n",
      "PERDIDAAAA despues: 0.027606209740042686\n",
      "loss en el callback: 0.0039903754368424416, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.57227659]\n",
      " [0.5809437 ]\n",
      " [0.59020638]\n",
      " [0.59927869]\n",
      " [0.60756439]\n",
      " [0.61594194]\n",
      " [0.62529123]\n",
      " [0.63462055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6430779]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.57227659]\n",
      "  [0.5809437 ]\n",
      "  [0.59020638]\n",
      "  [0.59927869]\n",
      "  [0.60756439]\n",
      "  [0.61594194]\n",
      "  [0.62529123]\n",
      "  [0.63462055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02563173696398735\n",
      "Predicción post entrenamiento : [[0.6442479]]\n",
      "PERDIDAAAA despues: 0.02525848150253296\n",
      "loss en el callback: 0.03445925936102867, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.5809437 ]\n",
      " [0.59020638]\n",
      " [0.59927869]\n",
      " [0.60756439]\n",
      " [0.61594194]\n",
      " [0.62529123]\n",
      " [0.63462055]\n",
      " [0.64307791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.65221417]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.5809437 ]\n",
      "  [0.59020638]\n",
      "  [0.59927869]\n",
      "  [0.60756439]\n",
      "  [0.61594194]\n",
      "  [0.62529123]\n",
      "  [0.63462055]\n",
      "  [0.64307791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019959110766649246\n",
      "Predicción post entrenamiento : [[0.6531119]]\n",
      "PERDIDAAAA despues: 0.01970626600086689\n",
      "loss en el callback: 0.019005905836820602, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.59020638]\n",
      " [0.59927869]\n",
      " [0.60756439]\n",
      " [0.61594194]\n",
      " [0.62529123]\n",
      " [0.63462055]\n",
      " [0.64307791]\n",
      " [0.65221417]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.66116387]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.59020638]\n",
      "  [0.59927869]\n",
      "  [0.60756439]\n",
      "  [0.61594194]\n",
      "  [0.62529123]\n",
      "  [0.63462055]\n",
      "  [0.64307791]\n",
      "  [0.65221417]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00980230513960123\n",
      "Predicción post entrenamiento : [[0.6614192]]\n",
      "PERDIDAAAA despues: 0.00975180882960558\n",
      "loss en el callback: 0.0013781632296741009, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.59927869]\n",
      " [0.60756439]\n",
      " [0.61594194]\n",
      " [0.62529123]\n",
      " [0.63462055]\n",
      " [0.64307791]\n",
      " [0.65221417]\n",
      " [0.66116387]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6693856]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.59927869]\n",
      "  [0.60756439]\n",
      "  [0.61594194]\n",
      "  [0.62529123]\n",
      "  [0.63462055]\n",
      "  [0.64307791]\n",
      "  [0.65221417]\n",
      "  [0.66116387]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004354455973953009\n",
      "Predicción post entrenamiento : [[0.66905355]]\n",
      "PERDIDAAAA despues: 0.004398390185087919\n",
      "loss en el callback: 0.002147615421563387, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.60756439]\n",
      " [0.61594194]\n",
      " [0.62529123]\n",
      " [0.63462055]\n",
      " [0.64307791]\n",
      " [0.65221417]\n",
      " [0.66116387]\n",
      " [0.66938561]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6769718]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.60756439]\n",
      "  [0.61594194]\n",
      "  [0.62529123]\n",
      "  [0.63462055]\n",
      "  [0.64307791]\n",
      "  [0.65221417]\n",
      "  [0.66116387]\n",
      "  [0.66938561]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011034372728317976\n",
      "Predicción post entrenamiento : [[0.6769322]]\n",
      "PERDIDAAAA despues: 0.0011060681426897645\n",
      "loss en el callback: 3.6483481380855665e-05, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.61594194]\n",
      " [0.62529123]\n",
      " [0.63462055]\n",
      " [0.64307791]\n",
      " [0.65221417]\n",
      " [0.66116387]\n",
      " [0.66938561]\n",
      " [0.67697179]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.68502396]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.61594194]\n",
      "  [0.62529123]\n",
      "  [0.63462055]\n",
      "  [0.64307791]\n",
      "  [0.65221417]\n",
      "  [0.66116387]\n",
      "  [0.66938561]\n",
      "  [0.67697179]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007345794583670795\n",
      "Predicción post entrenamiento : [[0.6852301]]\n",
      "PERDIDAAAA despues: 0.0007234493386931717\n",
      "loss en el callback: 0.0010375988204032183, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.62529123]\n",
      " [0.63462055]\n",
      " [0.64307791]\n",
      " [0.65221417]\n",
      " [0.66116387]\n",
      " [0.66938561]\n",
      " [0.67697179]\n",
      " [0.68502396]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.69347394]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.62529123]\n",
      "  [0.63462055]\n",
      "  [0.64307791]\n",
      "  [0.65221417]\n",
      "  [0.66116387]\n",
      "  [0.66938561]\n",
      "  [0.67697179]\n",
      "  [0.68502396]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021309200674295425\n",
      "Predicción post entrenamiento : [[0.6939762]]\n",
      "PERDIDAAAA despues: 0.002084799110889435\n",
      "loss en el callback: 0.006718705873936415, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.63462055]\n",
      " [0.64307791]\n",
      " [0.65221417]\n",
      " [0.66116387]\n",
      " [0.66938561]\n",
      " [0.67697179]\n",
      " [0.68502396]\n",
      " [0.69347394]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7020696]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.63462055]\n",
      "  [0.64307791]\n",
      "  [0.65221417]\n",
      "  [0.66116387]\n",
      "  [0.66938561]\n",
      "  [0.67697179]\n",
      "  [0.68502396]\n",
      "  [0.69347394]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011613914975896478\n",
      "Predicción post entrenamiento : [[0.70271266]]\n",
      "PERDIDAAAA despues: 0.001117974054068327\n",
      "loss en el callback: 0.011591662652790546, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.64307791]\n",
      " [0.65221417]\n",
      " [0.66116387]\n",
      " [0.66938561]\n",
      " [0.67697179]\n",
      " [0.68502396]\n",
      " [0.69347394]\n",
      " [0.70206958]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.71060926]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.64307791]\n",
      "  [0.65221417]\n",
      "  [0.66116387]\n",
      "  [0.66938561]\n",
      "  [0.67697179]\n",
      "  [0.68502396]\n",
      "  [0.69347394]\n",
      "  [0.70206958]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018523165490478277\n",
      "Predicción post entrenamiento : [[0.71029854]]\n",
      "PERDIDAAAA despues: 0.001825667335651815\n",
      "loss en el callback: 0.0026508464943617582, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.65221417]\n",
      " [0.66116387]\n",
      " [0.66938561]\n",
      " [0.67697179]\n",
      " [0.68502396]\n",
      " [0.69347394]\n",
      " [0.70206958]\n",
      " [0.71060926]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7182111]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.65221417]\n",
      "  [0.66116387]\n",
      "  [0.66938561]\n",
      "  [0.67697179]\n",
      "  [0.68502396]\n",
      "  [0.69347394]\n",
      "  [0.70206958]\n",
      "  [0.71060926]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023344072978943586\n",
      "Predicción post entrenamiento : [[0.71843666]]\n",
      "PERDIDAAAA despues: 0.002356252633035183\n",
      "loss en el callback: 0.0015095409471541643, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.66116387]\n",
      " [0.66938561]\n",
      " [0.67697179]\n",
      " [0.68502396]\n",
      " [0.69347394]\n",
      " [0.70206958]\n",
      " [0.71060926]\n",
      " [0.71821111]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.72614396]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.66116387]\n",
      "  [0.66938561]\n",
      "  [0.67697179]\n",
      "  [0.68502396]\n",
      "  [0.69347394]\n",
      "  [0.70206958]\n",
      "  [0.71060926]\n",
      "  [0.71821111]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008711192640475929\n",
      "Predicción post entrenamiento : [[0.7261998]]\n",
      "PERDIDAAAA despues: 0.0008744191727600992\n",
      "loss en el callback: 9.161233174381778e-05, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.66938561]\n",
      " [0.67697179]\n",
      " [0.68502396]\n",
      " [0.69347394]\n",
      " [0.70206958]\n",
      " [0.71060926]\n",
      " [0.71821111]\n",
      " [0.72614396]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.733714]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.66938561]\n",
      "  [0.67697179]\n",
      "  [0.68502396]\n",
      "  [0.69347394]\n",
      "  [0.70206958]\n",
      "  [0.71060926]\n",
      "  [0.71821111]\n",
      "  [0.72614396]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006047653034329414\n",
      "Predicción post entrenamiento : [[0.7328509]]\n",
      "PERDIDAAAA despues: 0.00591416098177433\n",
      "loss en el callback: 0.017740093171596527, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.67697179]\n",
      " [0.68502396]\n",
      " [0.69347394]\n",
      " [0.70206958]\n",
      " [0.71060926]\n",
      " [0.71821111]\n",
      " [0.72614396]\n",
      " [0.73371398]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7403548]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.67697179]\n",
      "  [0.68502396]\n",
      "  [0.69347394]\n",
      "  [0.70206958]\n",
      "  [0.71060926]\n",
      "  [0.71821111]\n",
      "  [0.72614396]\n",
      "  [0.73371398]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037881704047322273\n",
      "Predicción post entrenamiento : [[0.7396065]]\n",
      "PERDIDAAAA despues: 0.0036966202314943075\n",
      "loss en el callback: 0.012723544612526894, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.68502396]\n",
      " [0.69347394]\n",
      " [0.70206958]\n",
      " [0.71060926]\n",
      " [0.71821111]\n",
      " [0.72614396]\n",
      " [0.73371398]\n",
      " [0.74035478]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.74727875]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.68502396]\n",
      "  [0.69347394]\n",
      "  [0.70206958]\n",
      "  [0.71060926]\n",
      "  [0.71821111]\n",
      "  [0.72614396]\n",
      "  [0.73371398]\n",
      "  [0.74035478]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005067192949354649\n",
      "Predicción post entrenamiento : [[0.7469586]]\n",
      "PERDIDAAAA despues: 0.005021717865020037\n",
      "loss en el callback: 0.0027023747097700834, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.69347394]\n",
      " [0.70206958]\n",
      " [0.71060926]\n",
      " [0.71821111]\n",
      " [0.72614396]\n",
      " [0.73371398]\n",
      " [0.74035478]\n",
      " [0.74727875]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.75465125]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.69347394]\n",
      "  [0.70206958]\n",
      "  [0.71060926]\n",
      "  [0.71821111]\n",
      "  [0.72614396]\n",
      "  [0.73371398]\n",
      "  [0.74035478]\n",
      "  [0.74727875]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006294621853157878\n",
      "Predicción post entrenamiento : [[0.7542617]]\n",
      "PERDIDAAAA despues: 0.0006100657628849149\n",
      "loss en el callback: 0.0035792093258351088, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.70206958]\n",
      " [0.71060926]\n",
      " [0.71821111]\n",
      " [0.72614396]\n",
      " [0.73371398]\n",
      " [0.74035478]\n",
      " [0.74727875]\n",
      " [0.75465125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.76181287]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.70206958]\n",
      "  [0.71060926]\n",
      "  [0.71821111]\n",
      "  [0.72614396]\n",
      "  [0.73371398]\n",
      "  [0.74035478]\n",
      "  [0.74727875]\n",
      "  [0.75465125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036644013598561287\n",
      "Predicción post entrenamiento : [[0.7609808]]\n",
      "PERDIDAAAA despues: 0.003564354730769992\n",
      "loss en el callback: 0.016384555026888847, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.71060926]\n",
      " [0.71821111]\n",
      " [0.72614396]\n",
      " [0.73371398]\n",
      " [0.74035478]\n",
      " [0.74727875]\n",
      " [0.75465125]\n",
      " [0.76181287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.76828116]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.71060926]\n",
      "  [0.71821111]\n",
      "  [0.72614396]\n",
      "  [0.73371398]\n",
      "  [0.74035478]\n",
      "  [0.74727875]\n",
      "  [0.75465125]\n",
      "  [0.76181287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.612568543256202e-07\n",
      "Predicción post entrenamiento : [[0.7684498]]\n",
      "PERDIDAAAA despues: 8.423427289017127e-07\n",
      "loss en el callback: 0.0008317149477079511, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.71821111]\n",
      " [0.72614396]\n",
      " [0.73371398]\n",
      " [0.74035478]\n",
      " [0.74727875]\n",
      " [0.75465125]\n",
      " [0.76181287]\n",
      " [0.76828116]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.77544415]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.71821111]\n",
      "  [0.72614396]\n",
      "  [0.73371398]\n",
      "  [0.74035478]\n",
      "  [0.74727875]\n",
      "  [0.75465125]\n",
      "  [0.76181287]\n",
      "  [0.76828116]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041251484071835876\n",
      "Predicción post entrenamiento : [[0.7756835]]\n",
      "PERDIDAAAA despues: 0.0004222956777084619\n",
      "loss en el callback: 0.001655914238654077, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.72614396]\n",
      " [0.73371398]\n",
      " [0.74035478]\n",
      " [0.74727875]\n",
      " [0.75465125]\n",
      " [0.76181287]\n",
      " [0.76828116]\n",
      " [0.77544415]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7825912]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.72614396]\n",
      "  [0.73371398]\n",
      "  [0.74035478]\n",
      "  [0.74727875]\n",
      "  [0.75465125]\n",
      "  [0.76181287]\n",
      "  [0.76828116]\n",
      "  [0.77544415]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014085907023400068\n",
      "Predicción post entrenamiento : [[0.7824409]]\n",
      "PERDIDAAAA despues: 0.0013973297318443656\n",
      "loss en el callback: 0.0006163357174955308, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.73371398]\n",
      " [0.74035478]\n",
      " [0.74727875]\n",
      " [0.75465125]\n",
      " [0.76181287]\n",
      " [0.76828116]\n",
      " [0.77544415]\n",
      " [0.78259122]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.789126]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.73371398]\n",
      "  [0.74035478]\n",
      "  [0.74727875]\n",
      "  [0.75465125]\n",
      "  [0.76181287]\n",
      "  [0.76828116]\n",
      "  [0.77544415]\n",
      "  [0.78259122]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013758098939433694\n",
      "Predicción post entrenamiento : [[0.78884846]]\n",
      "PERDIDAAAA despues: 0.0013552993768826127\n",
      "loss en el callback: 0.0019476382294669747, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.74035478]\n",
      " [0.74727875]\n",
      " [0.75465125]\n",
      " [0.76181287]\n",
      " [0.76828116]\n",
      " [0.77544415]\n",
      " [0.78259122]\n",
      " [0.78912598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.79537827]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.74035478]\n",
      "  [0.74727875]\n",
      "  [0.75465125]\n",
      "  [0.76181287]\n",
      "  [0.76828116]\n",
      "  [0.77544415]\n",
      "  [0.78259122]\n",
      "  [0.78912598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00732323108240962\n",
      "Predicción post entrenamiento : [[0.7939529]]\n",
      "PERDIDAAAA despues: 0.007081305608153343\n",
      "loss en el callback: 0.04440980404615402, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.74727875]\n",
      " [0.75465125]\n",
      " [0.76181287]\n",
      " [0.76828116]\n",
      " [0.77544415]\n",
      " [0.78259122]\n",
      " [0.78912598]\n",
      " [0.79537827]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.800582]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.74727875]\n",
      "  [0.75465125]\n",
      "  [0.76181287]\n",
      "  [0.76828116]\n",
      "  [0.77544415]\n",
      "  [0.78259122]\n",
      "  [0.78912598]\n",
      "  [0.79537827]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01213345117866993\n",
      "Predicción post entrenamiento : [[0.8005234]]\n",
      "PERDIDAAAA despues: 0.012120546773076057\n",
      "loss en el callback: 0.0001278186246054247, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.75465125]\n",
      " [0.76181287]\n",
      " [0.76828116]\n",
      " [0.77544415]\n",
      " [0.78259122]\n",
      " [0.78912598]\n",
      " [0.79537827]\n",
      " [0.80058199]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8071606]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.75465125]\n",
      "  [0.76181287]\n",
      "  [0.76828116]\n",
      "  [0.77544415]\n",
      "  [0.78259122]\n",
      "  [0.78912598]\n",
      "  [0.79537827]\n",
      "  [0.80058199]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002788035199046135\n",
      "Predicción post entrenamiento : [[0.8066984]]\n",
      "PERDIDAAAA despues: 0.002739435061812401\n",
      "loss en el callback: 0.0058099390007555485, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.76181287]\n",
      " [0.76828116]\n",
      " [0.77544415]\n",
      " [0.78259122]\n",
      " [0.78912598]\n",
      " [0.79537827]\n",
      " [0.80058199]\n",
      " [0.80716062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.81317306]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.76181287]\n",
      "  [0.76828116]\n",
      "  [0.77544415]\n",
      "  [0.78259122]\n",
      "  [0.78912598]\n",
      "  [0.79537827]\n",
      "  [0.80058199]\n",
      "  [0.80716062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008275970816612244\n",
      "Predicción post entrenamiento : [[0.81215125]]\n",
      "PERDIDAAAA despues: 0.008091103285551071\n",
      "loss en el callback: 0.025333277881145477, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.76828116]\n",
      " [0.77544415]\n",
      " [0.78259122]\n",
      " [0.78912598]\n",
      " [0.79537827]\n",
      " [0.80058199]\n",
      " [0.80716062]\n",
      " [0.81317306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.81847346]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.76828116]\n",
      "  [0.77544415]\n",
      "  [0.78259122]\n",
      "  [0.78912598]\n",
      "  [0.79537827]\n",
      "  [0.80058199]\n",
      "  [0.80716062]\n",
      "  [0.81317306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009020952275022864\n",
      "Predicción post entrenamiento : [[0.8184507]]\n",
      "PERDIDAAAA despues: 0.0009034634567797184\n",
      "loss en el callback: 1.3509012205759063e-05, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.77544415]\n",
      " [0.78259122]\n",
      " [0.78912598]\n",
      " [0.79537827]\n",
      " [0.80058199]\n",
      " [0.80716062]\n",
      " [0.81317306]\n",
      " [0.81847346]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.82478607]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.77544415]\n",
      "  [0.78259122]\n",
      "  [0.78912598]\n",
      "  [0.79537827]\n",
      "  [0.80058199]\n",
      "  [0.80716062]\n",
      "  [0.81317306]\n",
      "  [0.81847346]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00650876434519887\n",
      "Predicción post entrenamiento : [[0.8247845]]\n",
      "PERDIDAAAA despues: 0.006509014405310154\n",
      "loss en el callback: 6.73189788358286e-08, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.78259122]\n",
      " [0.78912598]\n",
      " [0.79537827]\n",
      " [0.80058199]\n",
      " [0.80716062]\n",
      " [0.81317306]\n",
      " [0.81847346]\n",
      " [0.82478607]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.83088374]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.78259122]\n",
      "  [0.78912598]\n",
      "  [0.79537827]\n",
      "  [0.80058199]\n",
      "  [0.80716062]\n",
      "  [0.81317306]\n",
      "  [0.81847346]\n",
      "  [0.82478607]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002635022858157754\n",
      "Predicción post entrenamiento : [[0.8316002]]\n",
      "PERDIDAAAA despues: 0.002561982022598386\n",
      "loss en el callback: 0.016576092690229416, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.78912598]\n",
      " [0.79537827]\n",
      " [0.80058199]\n",
      " [0.80716062]\n",
      " [0.81317306]\n",
      " [0.81847346]\n",
      " [0.82478607]\n",
      " [0.83088374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8374089]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.78912598]\n",
      "  [0.79537827]\n",
      "  [0.80058199]\n",
      "  [0.80716062]\n",
      "  [0.81317306]\n",
      "  [0.81847346]\n",
      "  [0.82478607]\n",
      "  [0.83088374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0049531725235283375\n",
      "Predicción post entrenamiento : [[0.83817595]]\n",
      "PERDIDAAAA despues: 0.004845792893320322\n",
      "loss en el callback: 0.021153932437300682, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.79537827]\n",
      " [0.80058199]\n",
      " [0.80716062]\n",
      " [0.81317306]\n",
      " [0.81847346]\n",
      " [0.82478607]\n",
      " [0.83088374]\n",
      " [0.8374089 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8438356]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.79537827]\n",
      "  [0.80058199]\n",
      "  [0.80716062]\n",
      "  [0.81317306]\n",
      "  [0.81847346]\n",
      "  [0.82478607]\n",
      "  [0.83088374]\n",
      "  [0.8374089 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020923390984535217\n",
      "Predicción post entrenamiento : [[0.84379923]]\n",
      "PERDIDAAAA despues: 0.002095666714012623\n",
      "loss en el callback: 3.361590643180534e-05, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.80058199]\n",
      " [0.80716062]\n",
      " [0.81317306]\n",
      " [0.81847346]\n",
      " [0.82478607]\n",
      " [0.83088374]\n",
      " [0.8374089 ]\n",
      " [0.84383559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.84938043]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.80058199]\n",
      "  [0.80716062]\n",
      "  [0.81317306]\n",
      "  [0.81847346]\n",
      "  [0.82478607]\n",
      "  [0.83088374]\n",
      "  [0.8374089 ]\n",
      "  [0.84383559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006489374209195375\n",
      "Predicción post entrenamiento : [[0.8496433]]\n",
      "PERDIDAAAA despues: 0.0006356143858283758\n",
      "loss en el callback: 0.0022766594775021076, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.80716062]\n",
      " [0.81317306]\n",
      " [0.81847346]\n",
      " [0.82478607]\n",
      " [0.83088374]\n",
      " [0.8374089 ]\n",
      " [0.84383559]\n",
      " [0.84938043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8554755]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.80716062]\n",
      "  [0.81317306]\n",
      "  [0.81847346]\n",
      "  [0.82478607]\n",
      "  [0.83088374]\n",
      "  [0.8374089 ]\n",
      "  [0.84383559]\n",
      "  [0.84938043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003333498490974307\n",
      "Predicción post entrenamiento : [[0.8561625]]\n",
      "PERDIDAAAA despues: 0.0032546401489526033\n",
      "loss en el callback: 0.016393955796957016, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.81317306]\n",
      " [0.81847346]\n",
      " [0.82478607]\n",
      " [0.83088374]\n",
      " [0.8374089 ]\n",
      " [0.84383559]\n",
      " [0.84938043]\n",
      " [0.85547549]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.86185086]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.81317306]\n",
      "  [0.81847346]\n",
      "  [0.82478607]\n",
      "  [0.83088374]\n",
      "  [0.8374089 ]\n",
      "  [0.84383559]\n",
      "  [0.84938043]\n",
      "  [0.85547549]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01908518560230732\n",
      "Predicción post entrenamiento : [[0.8632299]]\n",
      "PERDIDAAAA despues: 0.0187060683965683\n",
      "loss en el callback: 0.07708005607128143, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.81847346]\n",
      " [0.82478607]\n",
      " [0.83088374]\n",
      " [0.8374089 ]\n",
      " [0.84383559]\n",
      " [0.84938043]\n",
      " [0.85547549]\n",
      " [0.86185086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8689394]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.81847346]\n",
      "  [0.82478607]\n",
      "  [0.83088374]\n",
      "  [0.8374089 ]\n",
      "  [0.84383559]\n",
      "  [0.84938043]\n",
      "  [0.85547549]\n",
      "  [0.86185086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010325537994503975\n",
      "Predicción post entrenamiento : [[0.8700577]]\n",
      "PERDIDAAAA despues: 0.010099516250193119\n",
      "loss en el callback: 0.04656665027141571, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.82478607]\n",
      " [0.83088374]\n",
      " [0.8374089 ]\n",
      " [0.84383559]\n",
      " [0.84938043]\n",
      " [0.85547549]\n",
      " [0.86185086]\n",
      " [0.8689394 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8760293]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.82478607]\n",
      "  [0.83088374]\n",
      "  [0.8374089 ]\n",
      "  [0.84383559]\n",
      "  [0.84938043]\n",
      "  [0.85547549]\n",
      "  [0.86185086]\n",
      "  [0.8689394 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016316113760694861\n",
      "Predicción post entrenamiento : [[0.8762941]]\n",
      "PERDIDAAAA despues: 0.000156467329361476\n",
      "loss en el callback: 0.002290781820192933, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.83088374]\n",
      " [0.8374089 ]\n",
      " [0.84383559]\n",
      " [0.84938043]\n",
      " [0.85547549]\n",
      " [0.86185086]\n",
      " [0.8689394 ]\n",
      " [0.87602931]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.88225394]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.83088374]\n",
      "  [0.8374089 ]\n",
      "  [0.84383559]\n",
      "  [0.84938043]\n",
      "  [0.85547549]\n",
      "  [0.86185086]\n",
      "  [0.8689394 ]\n",
      "  [0.87602931]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8486909539205953e-05\n",
      "Predicción post entrenamiento : [[0.8821964]]\n",
      "PERDIDAAAA despues: 1.7995600501308218e-05\n",
      "loss en el callback: 0.00010039717017207295, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.8374089 ]\n",
      " [0.84383559]\n",
      " [0.84938043]\n",
      " [0.85547549]\n",
      " [0.86185086]\n",
      " [0.8689394 ]\n",
      " [0.87602931]\n",
      " [0.88225394]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.888221]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.8374089 ]\n",
      "  [0.84383559]\n",
      "  [0.84938043]\n",
      "  [0.85547549]\n",
      "  [0.86185086]\n",
      "  [0.8689394 ]\n",
      "  [0.87602931]\n",
      "  [0.88225394]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015464742900803685\n",
      "Predicción post entrenamiento : [[0.8870836]]\n",
      "PERDIDAAAA despues: 0.0014583081938326359\n",
      "loss en el callback: 0.03173608332872391, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.84383559]\n",
      " [0.84938043]\n",
      " [0.85547549]\n",
      " [0.86185086]\n",
      " [0.8689394 ]\n",
      " [0.87602931]\n",
      " [0.88225394]\n",
      " [0.88822103]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.89305294]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.84383559]\n",
      "  [0.84938043]\n",
      "  [0.85547549]\n",
      "  [0.86185086]\n",
      "  [0.8689394 ]\n",
      "  [0.87602931]\n",
      "  [0.88225394]\n",
      "  [0.88822103]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034668720327317715\n",
      "Predicción post entrenamiento : [[0.8927184]]\n",
      "PERDIDAAAA despues: 0.0034275860525667667\n",
      "loss en el callback: 0.0035769131500273943, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.84938043]\n",
      " [0.85547549]\n",
      " [0.86185086]\n",
      " [0.8689394 ]\n",
      " [0.87602931]\n",
      " [0.88225394]\n",
      " [0.88822103]\n",
      " [0.89305294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8986581]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.84938043]\n",
      "  [0.85547549]\n",
      "  [0.86185086]\n",
      "  [0.8689394 ]\n",
      "  [0.87602931]\n",
      "  [0.88225394]\n",
      "  [0.88822103]\n",
      "  [0.89305294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018977512372657657\n",
      "Predicción post entrenamiento : [[0.89821386]]\n",
      "PERDIDAAAA despues: 0.001859244192019105\n",
      "loss en el callback: 0.005983210168778896, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.85547549]\n",
      " [0.86185086]\n",
      " [0.8689394 ]\n",
      " [0.87602931]\n",
      " [0.88225394]\n",
      " [0.88822103]\n",
      " [0.89305294]\n",
      " [0.8986581 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.90439385]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.85547549]\n",
      "  [0.86185086]\n",
      "  [0.8689394 ]\n",
      "  [0.87602931]\n",
      "  [0.88225394]\n",
      "  [0.88822103]\n",
      "  [0.89305294]\n",
      "  [0.8986581 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008498203242197633\n",
      "Predicción post entrenamiento : [[0.9041196]]\n",
      "PERDIDAAAA despues: 0.0008339063497260213\n",
      "loss en el callback: 0.00234598689712584, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.86185086]\n",
      " [0.8689394 ]\n",
      " [0.87602931]\n",
      " [0.88225394]\n",
      " [0.88822103]\n",
      " [0.89305294]\n",
      " [0.8986581 ]\n",
      " [0.90439385]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.91037595]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.86185086]\n",
      "  [0.8689394 ]\n",
      "  [0.87602931]\n",
      "  [0.88225394]\n",
      "  [0.88822103]\n",
      "  [0.89305294]\n",
      "  [0.8986581 ]\n",
      "  [0.90439385]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028455581050366163\n",
      "Predicción post entrenamiento : [[0.9101562]]\n",
      "PERDIDAAAA despues: 0.0028221604879945517\n",
      "loss en el callback: 0.0016436446458101273, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.8689394 ]\n",
      " [0.87602931]\n",
      " [0.88225394]\n",
      " [0.88822103]\n",
      " [0.89305294]\n",
      " [0.8986581 ]\n",
      " [0.90439385]\n",
      " [0.91037595]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9163754]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.8689394 ]\n",
      "  [0.87602931]\n",
      "  [0.88225394]\n",
      "  [0.88822103]\n",
      "  [0.89305294]\n",
      "  [0.8986581 ]\n",
      "  [0.90439385]\n",
      "  [0.91037595]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0043979790061712265\n",
      "Predicción post entrenamiento : [[0.9163425]]\n",
      "PERDIDAAAA despues: 0.00439361622557044\n",
      "loss en el callback: 3.915747947758064e-05, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.87602931]\n",
      " [0.88225394]\n",
      " [0.88822103]\n",
      " [0.89305294]\n",
      " [0.8986581 ]\n",
      " [0.90439385]\n",
      " [0.91037595]\n",
      " [0.9163754 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9222562]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.87602931]\n",
      "  [0.88225394]\n",
      "  [0.88822103]\n",
      "  [0.89305294]\n",
      "  [0.8986581 ]\n",
      "  [0.90439385]\n",
      "  [0.91037595]\n",
      "  [0.9163754 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006329724099487066\n",
      "Predicción post entrenamiento : [[0.921219]]\n",
      "PERDIDAAAA despues: 0.006165764760226011\n",
      "loss en el callback: 0.028963187709450722, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.88225394]\n",
      " [0.88822103]\n",
      " [0.89305294]\n",
      " [0.8986581 ]\n",
      " [0.90439385]\n",
      " [0.91037595]\n",
      " [0.9163754 ]\n",
      " [0.92225617]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.92675555]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.88225394]\n",
      "  [0.88822103]\n",
      "  [0.89305294]\n",
      "  [0.8986581 ]\n",
      "  [0.90439385]\n",
      "  [0.91037595]\n",
      "  [0.9163754 ]\n",
      "  [0.92225617]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010778325609862804\n",
      "Predicción post entrenamiento : [[0.9261403]]\n",
      "PERDIDAAAA despues: 0.010650957003235817\n",
      "loss en el callback: 0.012284493073821068, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.88822103]\n",
      " [0.89305294]\n",
      " [0.8986581 ]\n",
      " [0.90439385]\n",
      " [0.91037595]\n",
      " [0.9163754 ]\n",
      " [0.92225617]\n",
      " [0.92675555]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9315108]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.88822103]\n",
      "  [0.89305294]\n",
      "  [0.8986581 ]\n",
      "  [0.90439385]\n",
      "  [0.91037595]\n",
      "  [0.9163754 ]\n",
      "  [0.92225617]\n",
      "  [0.92675555]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02465049922466278\n",
      "Predicción post entrenamiento : [[0.93050015]]\n",
      "PERDIDAAAA despues: 0.024334164336323738\n",
      "loss en el callback: 0.03223734349012375, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.89305294]\n",
      " [0.8986581 ]\n",
      " [0.90439385]\n",
      " [0.91037595]\n",
      " [0.9163754 ]\n",
      " [0.92225617]\n",
      " [0.92675555]\n",
      " [0.93151081]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.93575436]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.89305294]\n",
      "  [0.8986581 ]\n",
      "  [0.90439385]\n",
      "  [0.91037595]\n",
      "  [0.9163754 ]\n",
      "  [0.92225617]\n",
      "  [0.92675555]\n",
      "  [0.93151081]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022971104830503464\n",
      "Predicción post entrenamiento : [[0.9340121]]\n",
      "PERDIDAAAA despues: 0.022446023300290108\n",
      "loss en el callback: 0.0793566107749939, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.8986581 ]\n",
      " [0.90439385]\n",
      " [0.91037595]\n",
      " [0.9163754 ]\n",
      " [0.92225617]\n",
      " [0.92675555]\n",
      " [0.93151081]\n",
      " [0.93575436]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.939481]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.8986581 ]\n",
      "  [0.90439385]\n",
      "  [0.91037595]\n",
      "  [0.9163754 ]\n",
      "  [0.92225617]\n",
      "  [0.92675555]\n",
      "  [0.93151081]\n",
      "  [0.93575436]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006357942707836628\n",
      "Predicción post entrenamiento : [[0.93886167]]\n",
      "PERDIDAAAA despues: 0.006259556394070387\n",
      "loss en el callback: 0.011460825800895691, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.90439385]\n",
      " [0.91037595]\n",
      " [0.9163754 ]\n",
      " [0.92225617]\n",
      " [0.92675555]\n",
      " [0.93151081]\n",
      " [0.93575436]\n",
      " [0.93948102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9442961]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.90439385]\n",
      "  [0.91037595]\n",
      "  [0.9163754 ]\n",
      "  [0.92225617]\n",
      "  [0.92675555]\n",
      "  [0.93151081]\n",
      "  [0.93575436]\n",
      "  [0.93948102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00809569377452135\n",
      "Predicción post entrenamiento : [[0.9438507]]\n",
      "PERDIDAAAA despues: 0.008015736937522888\n",
      "loss en el callback: 0.006868415977805853, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.91037595]\n",
      " [0.9163754 ]\n",
      " [0.92225617]\n",
      " [0.92675555]\n",
      " [0.93151081]\n",
      " [0.93575436]\n",
      " [0.93948102]\n",
      " [0.94429612]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.94915664]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.91037595]\n",
      "  [0.9163754 ]\n",
      "  [0.92225617]\n",
      "  [0.92675555]\n",
      "  [0.93151081]\n",
      "  [0.93575436]\n",
      "  [0.93948102]\n",
      "  [0.94429612]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012604940682649612\n",
      "Predicción post entrenamiento : [[0.9493142]]\n",
      "PERDIDAAAA despues: 0.012640338391065598\n",
      "loss en el callback: 0.0010508347768336535, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.9163754 ]\n",
      " [0.92225617]\n",
      " [0.92675555]\n",
      " [0.93151081]\n",
      " [0.93575436]\n",
      " [0.93948102]\n",
      " [0.94429612]\n",
      " [0.94915664]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.95434713]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.9163754 ]\n",
      "  [0.92225617]\n",
      "  [0.92675555]\n",
      "  [0.93151081]\n",
      "  [0.93575436]\n",
      "  [0.93948102]\n",
      "  [0.94429612]\n",
      "  [0.94915664]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015484382398426533\n",
      "Predicción post entrenamiento : [[0.9539995]]\n",
      "PERDIDAAAA despues: 0.015397991985082626\n",
      "loss en el callback: 0.004463099874556065, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.92225617]\n",
      " [0.92675555]\n",
      " [0.93151081]\n",
      " [0.93575436]\n",
      " [0.93948102]\n",
      " [0.94429612]\n",
      " [0.94915664]\n",
      " [0.95434713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9586781]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.92225617]\n",
      "  [0.92675555]\n",
      "  [0.93151081]\n",
      "  [0.93575436]\n",
      "  [0.93948102]\n",
      "  [0.94429612]\n",
      "  [0.94915664]\n",
      "  [0.95434713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0051015508361160755\n",
      "Predicción post entrenamiento : [[0.95798355]]\n",
      "PERDIDAAAA despues: 0.005002812948077917\n",
      "loss en el callback: 0.01622173562645912, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.92675555]\n",
      " [0.93151081]\n",
      " [0.93575436]\n",
      " [0.93948102]\n",
      " [0.94429612]\n",
      " [0.94915664]\n",
      " [0.95434713]\n",
      " [0.95867813]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.96227485]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.92675555]\n",
      "  [0.93151081]\n",
      "  [0.93575436]\n",
      "  [0.93948102]\n",
      "  [0.94429612]\n",
      "  [0.94915664]\n",
      "  [0.95434713]\n",
      "  [0.95867813]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010512511245906353\n",
      "Predicción post entrenamiento : [[0.9607836]]\n",
      "PERDIDAAAA despues: 0.010208938270807266\n",
      "loss en el callback: 0.05700468271970749, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.93151081]\n",
      " [0.93575436]\n",
      " [0.93948102]\n",
      " [0.94429612]\n",
      " [0.94915664]\n",
      " [0.95434713]\n",
      " [0.95867813]\n",
      " [0.96227485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9650703]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.93151081]\n",
      "  [0.93575436]\n",
      "  [0.93948102]\n",
      "  [0.94429612]\n",
      "  [0.94915664]\n",
      "  [0.95434713]\n",
      "  [0.95867813]\n",
      "  [0.96227485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015743538737297058\n",
      "Predicción post entrenamiento : [[0.96411246]]\n",
      "PERDIDAAAA despues: 0.015504088252782822\n",
      "loss en el callback: 0.029399177059531212, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.93575436]\n",
      " [0.93948102]\n",
      " [0.94429612]\n",
      " [0.94915664]\n",
      " [0.95434713]\n",
      " [0.95867813]\n",
      " [0.96227485]\n",
      " [0.96507031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.96830225]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.93575436]\n",
      "  [0.93948102]\n",
      "  [0.94429612]\n",
      "  [0.94915664]\n",
      "  [0.95434713]\n",
      "  [0.95867813]\n",
      "  [0.96227485]\n",
      "  [0.96507031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034039340913295746\n",
      "Predicción post entrenamiento : [[0.967011]]\n",
      "PERDIDAAAA despues: 0.03356453403830528\n",
      "loss en el callback: 0.05220002308487892, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.93948102]\n",
      " [0.94429612]\n",
      " [0.94915664]\n",
      " [0.95434713]\n",
      " [0.95867813]\n",
      " [0.96227485]\n",
      " [0.96507031]\n",
      " [0.96830225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.97123474]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.93948102]\n",
      "  [0.94429612]\n",
      "  [0.94915664]\n",
      "  [0.95434713]\n",
      "  [0.95867813]\n",
      "  [0.96227485]\n",
      "  [0.96507031]\n",
      "  [0.96830225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02339285984635353\n",
      "Predicción post entrenamiento : [[0.9711165]]\n",
      "PERDIDAAAA despues: 0.02335670031607151\n",
      "loss en el callback: 0.0005995790706947446, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.94429612]\n",
      " [0.94915664]\n",
      " [0.95434713]\n",
      " [0.95867813]\n",
      " [0.96227485]\n",
      " [0.96507031]\n",
      " [0.96830225]\n",
      " [0.97123474]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.97551256]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.94429612]\n",
      "  [0.94915664]\n",
      "  [0.95434713]\n",
      "  [0.95867813]\n",
      "  [0.96227485]\n",
      "  [0.96507031]\n",
      "  [0.96830225]\n",
      "  [0.97123474]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033983588218688965\n",
      "Predicción post entrenamiento : [[0.9746073]]\n",
      "PERDIDAAAA despues: 0.03365063667297363\n",
      "loss en el callback: 0.02936243638396263, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.94915664]\n",
      " [0.95434713]\n",
      " [0.95867813]\n",
      " [0.96227485]\n",
      " [0.96507031]\n",
      " [0.96830225]\n",
      " [0.97123474]\n",
      " [0.97551256]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9788043]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.94915664]\n",
      "  [0.95434713]\n",
      "  [0.95867813]\n",
      "  [0.96227485]\n",
      "  [0.96507031]\n",
      "  [0.96830225]\n",
      "  [0.97123474]\n",
      "  [0.97551256]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04763146489858627\n",
      "Predicción post entrenamiento : [[0.9767134]]\n",
      "PERDIDAAAA despues: 0.04672318696975708\n",
      "loss en el callback: 0.13315483927726746, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.95434713]\n",
      " [0.95867813]\n",
      " [0.96227485]\n",
      " [0.96507031]\n",
      " [0.96830225]\n",
      " [0.97123474]\n",
      " [0.97551256]\n",
      " [0.97880429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.98061883]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.95434713]\n",
      "  [0.95867813]\n",
      "  [0.96227485]\n",
      "  [0.96507031]\n",
      "  [0.96830225]\n",
      "  [0.97123474]\n",
      "  [0.97551256]\n",
      "  [0.97880429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035745635628700256\n",
      "Predicción post entrenamiento : [[0.98055494]]\n",
      "PERDIDAAAA despues: 0.03572147712111473\n",
      "loss en el callback: 0.00020842754747718573, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.95867813]\n",
      " [0.96227485]\n",
      " [0.96507031]\n",
      " [0.96830225]\n",
      " [0.97123474]\n",
      " [0.97551256]\n",
      " [0.97880429]\n",
      " [0.98061883]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.98397815]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.95867813]\n",
      "  [0.96227485]\n",
      "  [0.96507031]\n",
      "  [0.96830225]\n",
      "  [0.97123474]\n",
      "  [0.97551256]\n",
      "  [0.97880429]\n",
      "  [0.98061883]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04634714499115944\n",
      "Predicción post entrenamiento : [[0.9836832]]\n",
      "PERDIDAAAA despues: 0.04622024670243263\n",
      "loss en el callback: 0.004110532812774181, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.96227485]\n",
      " [0.96507031]\n",
      " [0.96830225]\n",
      " [0.97123474]\n",
      " [0.97551256]\n",
      " [0.97880429]\n",
      " [0.98061883]\n",
      " [0.98397815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9868028]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.96227485]\n",
      "  [0.96507031]\n",
      "  [0.96830225]\n",
      "  [0.97123474]\n",
      "  [0.97551256]\n",
      "  [0.97880429]\n",
      "  [0.98061883]\n",
      "  [0.98397815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0475713312625885\n",
      "Predicción post entrenamiento : [[0.98544395]]\n",
      "PERDIDAAAA despues: 0.046980418264865875\n",
      "loss en el callback: 0.06325261294841766, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.96507031]\n",
      " [0.96830225]\n",
      " [0.97123474]\n",
      " [0.97551256]\n",
      " [0.97880429]\n",
      " [0.98061883]\n",
      " [0.98397815]\n",
      " [0.98680282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.98843646]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.96507031]\n",
      "  [0.96830225]\n",
      "  [0.97123474]\n",
      "  [0.97551256]\n",
      "  [0.97880429]\n",
      "  [0.98061883]\n",
      "  [0.98397815]\n",
      "  [0.98680282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035918328911066055\n",
      "Predicción post entrenamiento : [[0.98774403]]\n",
      "PERDIDAAAA despues: 0.03565634787082672\n",
      "loss en el callback: 0.018900984898209572, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.96830225]\n",
      " [0.97123474]\n",
      " [0.97551256]\n",
      " [0.97880429]\n",
      " [0.98061883]\n",
      " [0.98397815]\n",
      " [0.98680282]\n",
      " [0.98843646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.99083304]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.96830225]\n",
      "  [0.97123474]\n",
      "  [0.97551256]\n",
      "  [0.97880429]\n",
      "  [0.98061883]\n",
      "  [0.98397815]\n",
      "  [0.98680282]\n",
      "  [0.98843646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04033234715461731\n",
      "Predicción post entrenamiento : [[0.9898093]]\n",
      "PERDIDAAAA despues: 0.039922188967466354\n",
      "loss en el callback: 0.04257696494460106, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.97123474]\n",
      " [0.97551256]\n",
      " [0.97880429]\n",
      " [0.98061883]\n",
      " [0.98397815]\n",
      " [0.98680282]\n",
      " [0.98843646]\n",
      " [0.99083304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.99284303]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.97123474]\n",
      "  [0.97551256]\n",
      "  [0.97880429]\n",
      "  [0.98061883]\n",
      "  [0.98397815]\n",
      "  [0.98680282]\n",
      "  [0.98843646]\n",
      "  [0.99083304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054136525839567184\n",
      "Predicción post entrenamiento : [[0.9918714]]\n",
      "PERDIDAAAA despues: 0.05368533357977867\n",
      "loss en el callback: 0.03763292729854584, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.97551256]\n",
      " [0.97880429]\n",
      " [0.98061883]\n",
      " [0.98397815]\n",
      " [0.98680282]\n",
      " [0.98843646]\n",
      " [0.99083304]\n",
      " [0.99284303]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.99490315]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.97551256]\n",
      "  [0.97880429]\n",
      "  [0.98061883]\n",
      "  [0.98397815]\n",
      "  [0.98680282]\n",
      "  [0.98843646]\n",
      "  [0.99083304]\n",
      "  [0.99284303]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0957963615655899\n",
      "Predicción post entrenamiento : [[0.9934202]]\n",
      "PERDIDAAAA despues: 0.09488058090209961\n",
      "loss en el callback: 0.08780672401189804, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.97880429]\n",
      " [0.98061883]\n",
      " [0.98397815]\n",
      " [0.98680282]\n",
      " [0.98843646]\n",
      " [0.99083304]\n",
      " [0.99284303]\n",
      " [0.99490315]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.99597645]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.97880429]\n",
      "  [0.98061883]\n",
      "  [0.98397815]\n",
      "  [0.98680282]\n",
      "  [0.98843646]\n",
      "  [0.99083304]\n",
      "  [0.99284303]\n",
      "  [0.99490315]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15271267294883728\n",
      "Predicción post entrenamiento : [[0.9939546]]\n",
      "PERDIDAAAA despues: 0.15113653242588043\n",
      "loss en el callback: 0.16811752319335938, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.98061883]\n",
      " [0.98397815]\n",
      " [0.98680282]\n",
      " [0.98843646]\n",
      " [0.99083304]\n",
      " [0.99284303]\n",
      " [0.99490315]\n",
      " [0.99597645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9962482]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.98061883]\n",
      "  [0.98397815]\n",
      "  [0.98680282]\n",
      "  [0.98843646]\n",
      "  [0.99083304]\n",
      "  [0.99284303]\n",
      "  [0.99490315]\n",
      "  [0.99597645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10981906950473785\n",
      "Predicción post entrenamiento : [[0.9951518]]\n",
      "PERDIDAAAA despues: 0.10909362137317657\n",
      "loss en el callback: 0.05576466768980026, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.98397815]\n",
      " [0.98680282]\n",
      " [0.98843646]\n",
      " [0.99083304]\n",
      " [0.99284303]\n",
      " [0.99490315]\n",
      " [0.99597645]\n",
      " [0.99624819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.99758303]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.98397815]\n",
      "  [0.98680282]\n",
      "  [0.98843646]\n",
      "  [0.99083304]\n",
      "  [0.99284303]\n",
      "  [0.99490315]\n",
      "  [0.99597645]\n",
      "  [0.99624819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08393643796443939\n",
      "Predicción post entrenamiento : [[0.996682]]\n",
      "PERDIDAAAA despues: 0.08341515064239502\n",
      "loss en el callback: 0.037352196872234344, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.98680282]\n",
      " [0.98843646]\n",
      " [0.99083304]\n",
      " [0.99284303]\n",
      " [0.99490315]\n",
      " [0.99597645]\n",
      " [0.99624819]\n",
      " [0.99758303]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.998729]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.98680282]\n",
      "  [0.98843646]\n",
      "  [0.99083304]\n",
      "  [0.99284303]\n",
      "  [0.99490315]\n",
      "  [0.99597645]\n",
      "  [0.99624819]\n",
      "  [0.99758303]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11146944761276245\n",
      "Predicción post entrenamiento : [[0.9961604]]\n",
      "PERDIDAAAA despues: 0.10976088792085648\n",
      "loss en el callback: 0.22110368311405182, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.98843646]\n",
      " [0.99083304]\n",
      " [0.99284303]\n",
      " [0.99490315]\n",
      " [0.99597645]\n",
      " [0.99624819]\n",
      " [0.99758303]\n",
      " [0.99872899]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9978931]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.98843646]\n",
      "  [0.99083304]\n",
      "  [0.99284303]\n",
      "  [0.99490315]\n",
      "  [0.99597645]\n",
      "  [0.99624819]\n",
      "  [0.99758303]\n",
      "  [0.99872899]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08210570365190506\n",
      "Predicción post entrenamiento : [[0.9960817]]\n",
      "PERDIDAAAA despues: 0.0810709148645401\n",
      "loss en el callback: 0.121491439640522, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.99083304]\n",
      " [0.99284303]\n",
      " [0.99490315]\n",
      " [0.99597645]\n",
      " [0.99624819]\n",
      " [0.99758303]\n",
      " [0.99872899]\n",
      " [0.9978931 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.99779]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.99083304]\n",
      "  [0.99284303]\n",
      "  [0.99490315]\n",
      "  [0.99597645]\n",
      "  [0.99624819]\n",
      "  [0.99758303]\n",
      "  [0.99872899]\n",
      "  [0.9978931 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10274146497249603\n",
      "Predicción post entrenamiento : [[0.9970269]]\n",
      "PERDIDAAAA despues: 0.10225287824869156\n",
      "loss en el callback: 0.030503273010253906, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.99284303]\n",
      " [0.99490315]\n",
      " [0.99597645]\n",
      " [0.99624819]\n",
      " [0.99758303]\n",
      " [0.99872899]\n",
      " [0.9978931 ]\n",
      " [0.99778998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9984087]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.99284303]\n",
      "  [0.99490315]\n",
      "  [0.99597645]\n",
      "  [0.99624819]\n",
      "  [0.99758303]\n",
      "  [0.99872899]\n",
      "  [0.9978931 ]\n",
      "  [0.99778998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05583813786506653\n",
      "Predicción post entrenamiento : [[0.9978142]]\n",
      "PERDIDAAAA despues: 0.055557530373334885\n",
      "loss en el callback: 0.01817130111157894, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.99490315]\n",
      " [0.99597645]\n",
      " [0.99624819]\n",
      " [0.99758303]\n",
      " [0.99872899]\n",
      " [0.9978931 ]\n",
      " [0.99778998]\n",
      " [0.99840868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9988935]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.99490315]\n",
      "  [0.99597645]\n",
      "  [0.99624819]\n",
      "  [0.99758303]\n",
      "  [0.99872899]\n",
      "  [0.9978931 ]\n",
      "  [0.99778998]\n",
      "  [0.99840868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036803338676691055\n",
      "Predicción post entrenamiento : [[0.99829304]]\n",
      "PERDIDAAAA despues: 0.03657331317663193\n",
      "loss en el callback: 0.0169718898832798, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.99597645]\n",
      " [0.99624819]\n",
      " [0.99758303]\n",
      " [0.99872899]\n",
      " [0.9978931 ]\n",
      " [0.99778998]\n",
      " [0.99840868]\n",
      " [0.9988935 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.99896866]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.99597645]\n",
      "  [0.99624819]\n",
      "  [0.99758303]\n",
      "  [0.99872899]\n",
      "  [0.9978931 ]\n",
      "  [0.99778998]\n",
      "  [0.99840868]\n",
      "  [0.9988935 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03377535566687584\n",
      "Predicción post entrenamiento : [[0.9988821]]\n",
      "PERDIDAAAA despues: 0.03374355286359787\n",
      "loss en el callback: 0.0003854919341392815, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.99624819]\n",
      " [0.99758303]\n",
      " [0.99872899]\n",
      " [0.9978931 ]\n",
      " [0.99778998]\n",
      " [0.99840868]\n",
      " [0.9988935 ]\n",
      " [0.99896866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9993845]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.99624819]\n",
      "  [0.99758303]\n",
      "  [0.99872899]\n",
      "  [0.9978931 ]\n",
      "  [0.99778998]\n",
      "  [0.99840868]\n",
      "  [0.9988935 ]\n",
      "  [0.99896866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008676293306052685\n",
      "Predicción post entrenamiento : [[0.998395]]\n",
      "PERDIDAAAA despues: 0.008492935448884964\n",
      "loss en el callback: 0.03806727007031441, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.99758303]\n",
      " [0.99872899]\n",
      " [0.9978931 ]\n",
      " [0.99778998]\n",
      " [0.99840868]\n",
      " [0.9988935 ]\n",
      " [0.99896866]\n",
      " [0.99938452]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.99893874]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.99758303]\n",
      "  [0.99872899]\n",
      "  [0.9978931 ]\n",
      "  [0.99778998]\n",
      "  [0.99840868]\n",
      "  [0.9988935 ]\n",
      "  [0.99896866]\n",
      "  [0.99938452]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015392445493489504\n",
      "Predicción post entrenamiento : [[0.9987249]]\n",
      "PERDIDAAAA despues: 0.0015225093811750412\n",
      "loss en el callback: 0.0022081700153648853, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.99872899]\n",
      " [0.9978931 ]\n",
      " [0.99778998]\n",
      " [0.99840868]\n",
      " [0.9988935 ]\n",
      " [0.99896866]\n",
      " [0.99938452]\n",
      " [0.99893874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.998959]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.99872899]\n",
      "  [0.9978931 ]\n",
      "  [0.99778998]\n",
      "  [0.99840868]\n",
      "  [0.9988935 ]\n",
      "  [0.99896866]\n",
      "  [0.99938452]\n",
      "  [0.99893874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011974460212513804\n",
      "Predicción post entrenamiento : [[0.99791753]]\n",
      "PERDIDAAAA despues: 0.0011264521162956953\n",
      "loss en el callback: 0.03889618441462517, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.9978931 ]\n",
      " [0.99778998]\n",
      " [0.99840868]\n",
      " [0.9988935 ]\n",
      " [0.99896866]\n",
      " [0.99938452]\n",
      " [0.99893874]\n",
      " [0.998959  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.99784774]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.9978931 ]\n",
      "  [0.99778998]\n",
      "  [0.99840868]\n",
      "  [0.9988935 ]\n",
      "  [0.99896866]\n",
      "  [0.99938452]\n",
      "  [0.99893874]\n",
      "  [0.998959  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012060394510626793\n",
      "Predicción post entrenamiento : [[0.99729]]\n",
      "PERDIDAAAA despues: 0.01193820871412754\n",
      "loss en el callback: 0.013996121473610401, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.99778998]\n",
      " [0.99840868]\n",
      " [0.9988935 ]\n",
      " [0.99896866]\n",
      " [0.99938452]\n",
      " [0.99893874]\n",
      " [0.998959  ]\n",
      " [0.99784774]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.99750185]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.99778998]\n",
      "  [0.99840868]\n",
      "  [0.9988935 ]\n",
      "  [0.99896866]\n",
      "  [0.99938452]\n",
      "  [0.99893874]\n",
      "  [0.998959  ]\n",
      "  [0.99784774]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010988197289407253\n",
      "Predicción post entrenamiento : [[0.9970417]]\n",
      "PERDIDAAAA despues: 0.010891939513385296\n",
      "loss en el callback: 0.010070964694023132, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.99840868]\n",
      " [0.9988935 ]\n",
      " [0.99896866]\n",
      " [0.99938452]\n",
      " [0.99893874]\n",
      " [0.998959  ]\n",
      " [0.99784774]\n",
      " [0.99750185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.99732614]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.99840868]\n",
      "  [0.9988935 ]\n",
      "  [0.99896866]\n",
      "  [0.99938452]\n",
      "  [0.99893874]\n",
      "  [0.998959  ]\n",
      "  [0.99784774]\n",
      "  [0.99750185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01490449346601963\n",
      "Predicción post entrenamiento : [[0.99725467]]\n",
      "PERDIDAAAA despues: 0.014887048862874508\n",
      "loss en el callback: 0.000301021063933149, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.9988935 ]\n",
      " [0.99896866]\n",
      " [0.99938452]\n",
      " [0.99893874]\n",
      " [0.998959  ]\n",
      " [0.99784774]\n",
      " [0.99750185]\n",
      " [0.99732614]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9973652]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.9988935 ]\n",
      "  [0.99896866]\n",
      "  [0.99938452]\n",
      "  [0.99893874]\n",
      "  [0.998959  ]\n",
      "  [0.99784774]\n",
      "  [0.99750185]\n",
      "  [0.99732614]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021471679210662842\n",
      "Predicción post entrenamiento : [[0.997473]]\n",
      "PERDIDAAAA despues: 0.02150329016149044\n",
      "loss en el callback: 0.0008130701608024538, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.99896866]\n",
      " [0.99938452]\n",
      " [0.99893874]\n",
      " [0.998959  ]\n",
      " [0.99784774]\n",
      " [0.99750185]\n",
      " [0.99732614]\n",
      " [0.99736518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9974041]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.99896866]\n",
      "  [0.99938452]\n",
      "  [0.99893874]\n",
      "  [0.998959  ]\n",
      "  [0.99784774]\n",
      "  [0.99750185]\n",
      "  [0.99732614]\n",
      "  [0.99736518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02205471880733967\n",
      "Predicción post entrenamiento : [[0.99748665]]\n",
      "PERDIDAAAA despues: 0.022079244256019592\n",
      "loss en el callback: 0.00048497150419279933, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.99938452]\n",
      " [0.99893874]\n",
      " [0.998959  ]\n",
      " [0.99784774]\n",
      " [0.99750185]\n",
      " [0.99732614]\n",
      " [0.99736518]\n",
      " [0.9974041 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9973312]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.99938452]\n",
      "  [0.99893874]\n",
      "  [0.998959  ]\n",
      "  [0.99784774]\n",
      "  [0.99750185]\n",
      "  [0.99732614]\n",
      "  [0.99736518]\n",
      "  [0.9974041 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012189552653580904\n",
      "Predicción post entrenamiento : [[0.9981423]]\n",
      "PERDIDAAAA despues: 0.0012762498809024692\n",
      "loss en el callback: 0.04490779712796211, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.99893874]\n",
      " [0.998959  ]\n",
      " [0.99784774]\n",
      " [0.99750185]\n",
      " [0.99732614]\n",
      " [0.99736518]\n",
      " [0.9974041 ]\n",
      " [0.9973312 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9977757]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.99893874]\n",
      "  [0.998959  ]\n",
      "  [0.99784774]\n",
      "  [0.99750185]\n",
      "  [0.99732614]\n",
      "  [0.99736518]\n",
      "  [0.9974041 ]\n",
      "  [0.9973312 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000896029407158494\n",
      "Predicción post entrenamiento : [[0.99812466]]\n",
      "PERDIDAAAA despues: 0.0009170440607704222\n",
      "loss en el callback: 0.008015629835426807, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.998959  ]\n",
      " [0.99784774]\n",
      " [0.99750185]\n",
      " [0.99732614]\n",
      " [0.99736518]\n",
      " [0.9974041 ]\n",
      " [0.9973312 ]\n",
      " [0.99777567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.99780375]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.998959  ]\n",
      "  [0.99784774]\n",
      "  [0.99750185]\n",
      "  [0.99732614]\n",
      "  [0.99736518]\n",
      "  [0.9974041 ]\n",
      "  [0.9973312 ]\n",
      "  [0.99777567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032584769651293755\n",
      "Predicción post entrenamiento : [[0.9972862]]\n",
      "PERDIDAAAA despues: 0.0031996583566069603\n",
      "loss en el callback: 0.012704753316938877, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.99784774]\n",
      " [0.99750185]\n",
      " [0.99732614]\n",
      " [0.99736518]\n",
      " [0.9974041 ]\n",
      " [0.9973312 ]\n",
      " [0.99777567]\n",
      " [0.99780375]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.99688596]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.99784774]\n",
      "  [0.99750185]\n",
      "  [0.99732614]\n",
      "  [0.99736518]\n",
      "  [0.9974041 ]\n",
      "  [0.9973312 ]\n",
      "  [0.99777567]\n",
      "  [0.99780375]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005951009225100279\n",
      "Predicción post entrenamiento : [[0.9971599]]\n",
      "PERDIDAAAA despues: 0.0006085414788685739\n",
      "loss en el callback: 0.004631381947547197, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.99750185]\n",
      " [0.99732614]\n",
      " [0.99736518]\n",
      " [0.9974041 ]\n",
      " [0.9973312 ]\n",
      " [0.99777567]\n",
      " [0.99780375]\n",
      " [0.99688596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9970459]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.99750185]\n",
      "  [0.99732614]\n",
      "  [0.99736518]\n",
      "  [0.9974041 ]\n",
      "  [0.9973312 ]\n",
      "  [0.99777567]\n",
      "  [0.99780375]\n",
      "  [0.99688596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.1151436158106662e-08\n",
      "Predicción post entrenamiento : [[0.99674743]]\n",
      "PERDIDAAAA despues: 2.3410567706605434e-08\n",
      "loss en el callback: 0.004003376234322786, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.99732614]\n",
      " [0.99736518]\n",
      " [0.9974041 ]\n",
      " [0.9973312 ]\n",
      " [0.99777567]\n",
      " [0.99780375]\n",
      " [0.99688596]\n",
      " [0.99704587]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.99672455]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.99732614]\n",
      "  [0.99736518]\n",
      "  [0.9974041 ]\n",
      "  [0.9973312 ]\n",
      "  [0.99777567]\n",
      "  [0.99780375]\n",
      "  [0.99688596]\n",
      "  [0.99704587]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002074149902909994\n",
      "Predicción post entrenamiento : [[0.9965374]]\n",
      "PERDIDAAAA despues: 0.002057137433439493\n",
      "loss en el callback: 0.0017716482980176806, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.99736518]\n",
      " [0.9974041 ]\n",
      " [0.9973312 ]\n",
      " [0.99777567]\n",
      " [0.99780375]\n",
      " [0.99688596]\n",
      " [0.99704587]\n",
      " [0.99672455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9965614]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.99736518]\n",
      "  [0.9974041 ]\n",
      "  [0.9973312 ]\n",
      "  [0.99777567]\n",
      "  [0.99780375]\n",
      "  [0.99688596]\n",
      "  [0.99704587]\n",
      "  [0.99672455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010157535783946514\n",
      "Predicción post entrenamiento : [[0.996294]]\n",
      "PERDIDAAAA despues: 0.010103709995746613\n",
      "loss en el callback: 0.003994714468717575, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.9974041 ]\n",
      " [0.9973312 ]\n",
      " [0.99777567]\n",
      " [0.99780375]\n",
      " [0.99688596]\n",
      " [0.99704587]\n",
      " [0.99672455]\n",
      " [0.99656141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.99629503]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.9974041 ]\n",
      "  [0.9973312 ]\n",
      "  [0.99777567]\n",
      "  [0.99780375]\n",
      "  [0.99688596]\n",
      "  [0.99704587]\n",
      "  [0.99672455]\n",
      "  [0.99656141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013191381469368935\n",
      "Predicción post entrenamiento : [[0.9954668]]\n",
      "PERDIDAAAA despues: 0.01300182193517685\n",
      "loss en el callback: 0.03332572430372238, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.9973312 ]\n",
      " [0.99777567]\n",
      " [0.99780375]\n",
      " [0.99688596]\n",
      " [0.99704587]\n",
      " [0.99672455]\n",
      " [0.99656141]\n",
      " [0.99629503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.995431]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.9973312 ]\n",
      "  [0.99777567]\n",
      "  [0.99780375]\n",
      "  [0.99688596]\n",
      "  [0.99704587]\n",
      "  [0.99672455]\n",
      "  [0.99656141]\n",
      "  [0.99629503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006137873977422714\n",
      "Predicción post entrenamiento : [[0.99473804]]\n",
      "PERDIDAAAA despues: 0.006029773969203234\n",
      "loss en el callback: 0.023626528680324554, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.99777567]\n",
      " [0.99780375]\n",
      " [0.99688596]\n",
      " [0.99704587]\n",
      " [0.99672455]\n",
      " [0.99656141]\n",
      " [0.99629503]\n",
      " [0.99543101]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9946832]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.99777567]\n",
      "  [0.99780375]\n",
      "  [0.99688596]\n",
      "  [0.99704587]\n",
      "  [0.99672455]\n",
      "  [0.99656141]\n",
      "  [0.99629503]\n",
      "  [0.99543101]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005607711151242256\n",
      "Predicción post entrenamiento : [[0.9947442]]\n",
      "PERDIDAAAA despues: 0.005616847425699234\n",
      "loss en el callback: 0.00022906973026692867, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.99780375]\n",
      " [0.99688596]\n",
      " [0.99704587]\n",
      " [0.99672455]\n",
      " [0.99656141]\n",
      " [0.99629503]\n",
      " [0.99543101]\n",
      " [0.99468321]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.99448556]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.99780375]\n",
      "  [0.99688596]\n",
      "  [0.99704587]\n",
      "  [0.99672455]\n",
      "  [0.99656141]\n",
      "  [0.99629503]\n",
      "  [0.99543101]\n",
      "  [0.99468321]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010786466300487518\n",
      "Predicción post entrenamiento : [[0.9949198]]\n",
      "PERDIDAAAA despues: 0.0011073570931330323\n",
      "loss en el callback: 0.014021066948771477, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.99688596]\n",
      " [0.99704587]\n",
      " [0.99672455]\n",
      " [0.99656141]\n",
      " [0.99629503]\n",
      " [0.99543101]\n",
      " [0.99468321]\n",
      " [0.99448556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9945499]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.99688596]\n",
      "  [0.99704587]\n",
      "  [0.99672455]\n",
      "  [0.99656141]\n",
      "  [0.99629503]\n",
      "  [0.99543101]\n",
      "  [0.99468321]\n",
      "  [0.99448556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006927695940248668\n",
      "Predicción post entrenamiento : [[0.99304986]]\n",
      "PERDIDAAAA despues: 0.0006160575430840254\n",
      "loss en el callback: 0.08261654525995255, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.99704587]\n",
      " [0.99672455]\n",
      " [0.99656141]\n",
      " [0.99629503]\n",
      " [0.99543101]\n",
      " [0.99468321]\n",
      " [0.99448556]\n",
      " [0.99454987]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9928526]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.99704587]\n",
      "  [0.99672455]\n",
      "  [0.99656141]\n",
      "  [0.99629503]\n",
      "  [0.99543101]\n",
      "  [0.99468321]\n",
      "  [0.99448556]\n",
      "  [0.99454987]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012309085577726364\n",
      "Predicción post entrenamiento : [[0.99286675]]\n",
      "PERDIDAAAA despues: 0.0012319000670686364\n",
      "loss en el callback: 1.1385755897208583e-05, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.20581521]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02550698071718216\n",
      "Predicción post entrenamiento : [[0.18293755]]\n",
      "PERDIDAAAA despues: 0.01872282847762108\n",
      "loss en el callback: 0.023029960691928864, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20581521]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16684313]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20581521]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00392125966027379\n",
      "Predicción post entrenamiento : [[0.15697578]]\n",
      "PERDIDAAAA despues: 0.002782837487757206\n",
      "loss en el callback: 0.004341110121458769, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20581521]\n",
      " [0.16684313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1605354]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20581521]\n",
      "  [0.16684313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.008906762464903e-05\n",
      "Predicción post entrenamiento : [[0.16026081]]\n",
      "PERDIDAAAA despues: 3.66873609891627e-05\n",
      "loss en el callback: 8.052386874624062e-06, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20581521]\n",
      " [0.16684313]\n",
      " [0.1605354 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17086977]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20581521]\n",
      "  [0.16684313]\n",
      "  [0.1605354 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002284990478074178\n",
      "Predicción post entrenamiento : [[0.1670443]]\n",
      "PERDIDAAAA despues: 0.00012748021981678903\n",
      "loss en el callback: 0.0019629274029284716, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20581521]\n",
      " [0.16684313]\n",
      " [0.1605354 ]\n",
      " [0.17086977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.1782444]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20581521]\n",
      "  [0.16684313]\n",
      "  [0.1605354 ]\n",
      "  [0.17086977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027785180136561394\n",
      "Predicción post entrenamiento : [[0.1749967]]\n",
      "PERDIDAAAA despues: 0.0024466831237077713\n",
      "loss en el callback: 0.0027252668514847755, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20581521]\n",
      " [0.16684313]\n",
      " [0.1605354 ]\n",
      " [0.17086977]\n",
      " [0.1782444 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18272713]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20581521]\n",
      "  [0.16684313]\n",
      "  [0.1605354 ]\n",
      "  [0.17086977]\n",
      "  [0.1782444 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013724922901019454\n",
      "Predicción post entrenamiento : [[0.18147074]]\n",
      "PERDIDAAAA despues: 0.0012809792533516884\n",
      "loss en el callback: 0.0006352297496050596, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20581521]\n",
      " [0.16684313]\n",
      " [0.1605354 ]\n",
      " [0.17086977]\n",
      " [0.1782444 ]\n",
      " [0.18272713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.19967371]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20581521]\n",
      "  [0.16684313]\n",
      "  [0.1605354 ]\n",
      "  [0.17086977]\n",
      "  [0.1782444 ]\n",
      "  [0.18272713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028322467114776373\n",
      "Predicción post entrenamiento : [[0.19869949]]\n",
      "PERDIDAAAA despues: 0.0027295018080621958\n",
      "loss en el callback: 0.000587509770411998, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.20581521]\n",
      " [0.16684313]\n",
      " [0.1605354 ]\n",
      " [0.17086977]\n",
      " [0.1782444 ]\n",
      " [0.18272713]\n",
      " [0.19967371]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22070488]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.20581521]\n",
      "  [0.16684313]\n",
      "  [0.1605354 ]\n",
      "  [0.17086977]\n",
      "  [0.1782444 ]\n",
      "  [0.18272713]\n",
      "  [0.19967371]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006079601007513702\n",
      "Predicción post entrenamiento : [[0.21965188]]\n",
      "PERDIDAAAA despues: 0.0005571413203142583\n",
      "loss en el callback: 0.0006209626444615424, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20581521]\n",
      " [0.16684313]\n",
      " [0.1605354 ]\n",
      " [0.17086977]\n",
      " [0.1782444 ]\n",
      " [0.18272713]\n",
      " [0.19967371]\n",
      " [0.22070488]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24581523]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20581521]\n",
      "  [0.16684313]\n",
      "  [0.1605354 ]\n",
      "  [0.17086977]\n",
      "  [0.1782444 ]\n",
      "  [0.18272713]\n",
      "  [0.19967371]\n",
      "  [0.22070488]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002336139150429517\n",
      "Predicción post entrenamiento : [[0.24493757]]\n",
      "PERDIDAAAA despues: 0.00020755502919200808\n",
      "loss en el callback: 0.0005290604312904179, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16684313]\n",
      " [0.1605354 ]\n",
      " [0.17086977]\n",
      " [0.1782444 ]\n",
      " [0.18272713]\n",
      " [0.19967371]\n",
      " [0.22070488]\n",
      " [0.24581523]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23957181]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16684313]\n",
      "  [0.1605354 ]\n",
      "  [0.17086977]\n",
      "  [0.1782444 ]\n",
      "  [0.18272713]\n",
      "  [0.19967371]\n",
      "  [0.22070488]\n",
      "  [0.24581523]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009687949204817414\n",
      "Predicción post entrenamiento : [[0.23836152]]\n",
      "PERDIDAAAA despues: 0.0008949182229116559\n",
      "loss en el callback: 0.0013364581391215324, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.1605354 ]\n",
      " [0.17086977]\n",
      " [0.1782444 ]\n",
      " [0.18272713]\n",
      " [0.19967371]\n",
      " [0.22070488]\n",
      " [0.24581523]\n",
      " [0.23957181]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24207364]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.1605354 ]\n",
      "  [0.17086977]\n",
      "  [0.1782444 ]\n",
      "  [0.18272713]\n",
      "  [0.19967371]\n",
      "  [0.22070488]\n",
      "  [0.24581523]\n",
      "  [0.23957181]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009084365447051823\n",
      "Predicción post entrenamiento : [[0.24200225]]\n",
      "PERDIDAAAA despues: 0.0009041380835697055\n",
      "loss en el callback: 6.910214779054513e-06, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17086977]\n",
      " [0.1782444 ]\n",
      " [0.18272713]\n",
      " [0.19967371]\n",
      " [0.22070488]\n",
      " [0.24581523]\n",
      " [0.23957181]\n",
      " [0.24207364]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24917504]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17086977]\n",
      "  [0.1782444 ]\n",
      "  [0.18272713]\n",
      "  [0.19967371]\n",
      "  [0.22070488]\n",
      "  [0.24581523]\n",
      "  [0.23957181]\n",
      "  [0.24207364]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017548591131344438\n",
      "Predicción post entrenamiento : [[0.24870323]]\n",
      "PERDIDAAAA despues: 0.0017155520617961884\n",
      "loss en el callback: 0.00030687559046782553, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.1782444 ]\n",
      " [0.18272713]\n",
      " [0.19967371]\n",
      " [0.22070488]\n",
      " [0.24581523]\n",
      " [0.23957181]\n",
      " [0.24207364]\n",
      " [0.24917504]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25613832]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.1782444 ]\n",
      "  [0.18272713]\n",
      "  [0.19967371]\n",
      "  [0.22070488]\n",
      "  [0.24581523]\n",
      "  [0.23957181]\n",
      "  [0.24207364]\n",
      "  [0.24917504]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003992957063019276\n",
      "Predicción post entrenamiento : [[0.25450537]]\n",
      "PERDIDAAAA despues: 0.0037892507389187813\n",
      "loss en el callback: 0.003943110816180706, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18272713]\n",
      " [0.19967371]\n",
      " [0.22070488]\n",
      " [0.24581523]\n",
      " [0.23957181]\n",
      " [0.24207364]\n",
      " [0.24917504]\n",
      " [0.25613832]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26281947]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18272713]\n",
      "  [0.19967371]\n",
      "  [0.22070488]\n",
      "  [0.24581523]\n",
      "  [0.23957181]\n",
      "  [0.24207364]\n",
      "  [0.24917504]\n",
      "  [0.25613832]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00435554189607501\n",
      "Predicción post entrenamiento : [[0.2622189]]\n",
      "PERDIDAAAA despues: 0.0042766304686665535\n",
      "loss en el callback: 0.0008008825243450701, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.19967371]\n",
      " [0.22070488]\n",
      " [0.24581523]\n",
      " [0.23957181]\n",
      " [0.24207364]\n",
      " [0.24917504]\n",
      " [0.25613832]\n",
      " [0.26281947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27208915]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.19967371]\n",
      "  [0.22070488]\n",
      "  [0.24581523]\n",
      "  [0.23957181]\n",
      "  [0.24207364]\n",
      "  [0.24917504]\n",
      "  [0.25613832]\n",
      "  [0.26281947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033444371074438095\n",
      "Predicción post entrenamiento : [[0.26973182]]\n",
      "PERDIDAAAA despues: 0.0030773396138101816\n",
      "loss en el callback: 0.008226489648222923, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22070488]\n",
      " [0.24581523]\n",
      " [0.23957181]\n",
      " [0.24207364]\n",
      " [0.24917504]\n",
      " [0.25613832]\n",
      " [0.26281947]\n",
      " [0.27208915]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27827984]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22070488]\n",
      "  [0.24581523]\n",
      "  [0.23957181]\n",
      "  [0.24207364]\n",
      "  [0.24917504]\n",
      "  [0.25613832]\n",
      "  [0.26281947]\n",
      "  [0.27208915]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009400228969752789\n",
      "Predicción post entrenamiento : [[0.27726367]]\n",
      "PERDIDAAAA despues: 0.009204216301441193\n",
      "loss en el callback: 0.002809403231367469, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24581523]\n",
      " [0.23957181]\n",
      " [0.24207364]\n",
      " [0.24917504]\n",
      " [0.25613832]\n",
      " [0.26281947]\n",
      " [0.27208915]\n",
      " [0.27827984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2830852]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24581523]\n",
      "  [0.23957181]\n",
      "  [0.24207364]\n",
      "  [0.24917504]\n",
      "  [0.25613832]\n",
      "  [0.26281947]\n",
      "  [0.27208915]\n",
      "  [0.27827984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011655203998088837\n",
      "Predicción post entrenamiento : [[0.2814436]]\n",
      "PERDIDAAAA despues: 0.011303447186946869\n",
      "loss en el callback: 0.0070758843794465065, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.23957181]\n",
      " [0.24207364]\n",
      " [0.24917504]\n",
      " [0.25613832]\n",
      " [0.26281947]\n",
      " [0.27208915]\n",
      " [0.27827984]\n",
      " [0.2830852 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.28299612]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.23957181]\n",
      "  [0.24207364]\n",
      "  [0.24917504]\n",
      "  [0.25613832]\n",
      "  [0.26281947]\n",
      "  [0.27208915]\n",
      "  [0.27827984]\n",
      "  [0.2830852 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01822269707918167\n",
      "Predicción post entrenamiento : [[0.28096014]]\n",
      "PERDIDAAAA despues: 0.01767716184258461\n",
      "loss en el callback: 0.012415984645485878, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24207364]\n",
      " [0.24917504]\n",
      " [0.25613832]\n",
      " [0.26281947]\n",
      " [0.27208915]\n",
      " [0.27827984]\n",
      " [0.2830852 ]\n",
      " [0.28299612]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.28500077]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24207364]\n",
      "  [0.24917504]\n",
      "  [0.25613832]\n",
      "  [0.26281947]\n",
      "  [0.27208915]\n",
      "  [0.27827984]\n",
      "  [0.2830852 ]\n",
      "  [0.28299612]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01591322012245655\n",
      "Predicción post entrenamiento : [[0.28254375]]\n",
      "PERDIDAAAA despues: 0.015299362130463123\n",
      "loss en el callback: 0.016507601365447044, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.24917504]\n",
      " [0.25613832]\n",
      " [0.26281947]\n",
      " [0.27208915]\n",
      " [0.27827984]\n",
      " [0.2830852 ]\n",
      " [0.28299612]\n",
      " [0.28500077]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.28740266]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.24917504]\n",
      "  [0.25613832]\n",
      "  [0.26281947]\n",
      "  [0.27208915]\n",
      "  [0.27827984]\n",
      "  [0.2830852 ]\n",
      "  [0.28299612]\n",
      "  [0.28500077]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009068579412996769\n",
      "Predicción post entrenamiento : [[0.2855942]]\n",
      "PERDIDAAAA despues: 0.008727412670850754\n",
      "loss en el callback: 0.010493569076061249, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25613832]\n",
      " [0.26281947]\n",
      " [0.27208915]\n",
      " [0.27827984]\n",
      " [0.2830852 ]\n",
      " [0.28299612]\n",
      " [0.28500077]\n",
      " [0.28740266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.29022074]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25613832]\n",
      "  [0.26281947]\n",
      "  [0.27208915]\n",
      "  [0.27827984]\n",
      "  [0.2830852 ]\n",
      "  [0.28299612]\n",
      "  [0.28500077]\n",
      "  [0.28740266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010867292061448097\n",
      "Predicción post entrenamiento : [[0.28801063]]\n",
      "PERDIDAAAA despues: 0.010411384515464306\n",
      "loss en el callback: 0.014755616895854473, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26281947]\n",
      " [0.27208915]\n",
      " [0.27827984]\n",
      " [0.2830852 ]\n",
      " [0.28299612]\n",
      " [0.28500077]\n",
      " [0.28740266]\n",
      " [0.29022074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29227912]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26281947]\n",
      "  [0.27208915]\n",
      "  [0.27827984]\n",
      "  [0.2830852 ]\n",
      "  [0.28299612]\n",
      "  [0.28500077]\n",
      "  [0.28740266]\n",
      "  [0.29022074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006415247335098684\n",
      "Predicción post entrenamiento : [[0.29094815]]\n",
      "PERDIDAAAA despues: 0.0005758735933341086\n",
      "loss en el callback: 0.00512051722034812, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27208915]\n",
      " [0.27827984]\n",
      " [0.2830852 ]\n",
      " [0.28299612]\n",
      " [0.28500077]\n",
      " [0.28740266]\n",
      " [0.29022074]\n",
      " [0.29227912]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29475242]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27208915]\n",
      "  [0.27827984]\n",
      "  [0.2830852 ]\n",
      "  [0.28299612]\n",
      "  [0.28500077]\n",
      "  [0.28740266]\n",
      "  [0.29022074]\n",
      "  [0.29227912]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.973513568984345e-06\n",
      "Predicción post entrenamiento : [[0.2945281]]\n",
      "PERDIDAAAA despues: 4.023295787192183e-06\n",
      "loss en el callback: 0.00018378705135546625, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27827984]\n",
      " [0.2830852 ]\n",
      " [0.28299612]\n",
      " [0.28500077]\n",
      " [0.28740266]\n",
      " [0.29022074]\n",
      " [0.29227912]\n",
      " [0.29475242]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.2970713]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27827984]\n",
      "  [0.2830852 ]\n",
      "  [0.28299612]\n",
      "  [0.28500077]\n",
      "  [0.28740266]\n",
      "  [0.29022074]\n",
      "  [0.29227912]\n",
      "  [0.29475242]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00042580359149724245\n",
      "Predicción post entrenamiento : [[0.29693782]]\n",
      "PERDIDAAAA despues: 0.0004313303215894848\n",
      "loss en el callback: 6.553378625540063e-05, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.2830852 ]\n",
      " [0.28299612]\n",
      " [0.28500077]\n",
      " [0.28740266]\n",
      " [0.29022074]\n",
      " [0.29227912]\n",
      " [0.29475242]\n",
      " [0.29707131]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.29869527]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.2830852 ]\n",
      "  [0.28299612]\n",
      "  [0.28500077]\n",
      "  [0.28740266]\n",
      "  [0.29022074]\n",
      "  [0.29227912]\n",
      "  [0.29475242]\n",
      "  [0.29707131]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001952796446857974\n",
      "Predicción post entrenamiento : [[0.29814795]]\n",
      "PERDIDAAAA despues: 0.00021087596542201936\n",
      "loss en el callback: 0.0011234973790124059, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28299612]\n",
      " [0.28500077]\n",
      " [0.28740266]\n",
      " [0.29022074]\n",
      " [0.29227912]\n",
      " [0.29475242]\n",
      " [0.29707131]\n",
      " [0.29869527]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.29930705]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28299612]\n",
      "  [0.28500077]\n",
      "  [0.28740266]\n",
      "  [0.29022074]\n",
      "  [0.29227912]\n",
      "  [0.29475242]\n",
      "  [0.29707131]\n",
      "  [0.29869527]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010550962178967893\n",
      "Predicción post entrenamiento : [[0.29875576]]\n",
      "PERDIDAAAA despues: 9.448820492252707e-05\n",
      "loss en el callback: 0.0012810496846213937, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28500077]\n",
      " [0.28740266]\n",
      " [0.29022074]\n",
      " [0.29227912]\n",
      " [0.29475242]\n",
      " [0.29707131]\n",
      " [0.29869527]\n",
      " [0.29930705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.30039996]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28500077]\n",
      "  [0.28740266]\n",
      "  [0.29022074]\n",
      "  [0.29227912]\n",
      "  [0.29475242]\n",
      "  [0.29707131]\n",
      "  [0.29869527]\n",
      "  [0.29930705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003084888157900423\n",
      "Predicción post entrenamiento : [[0.30003235]]\n",
      "PERDIDAAAA despues: 0.0002957106044050306\n",
      "loss en el callback: 0.0006957866135053337, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28740266]\n",
      " [0.29022074]\n",
      " [0.29227912]\n",
      " [0.29475242]\n",
      " [0.29707131]\n",
      " [0.29869527]\n",
      " [0.29930705]\n",
      " [0.30039996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30172172]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28740266]\n",
      "  [0.29022074]\n",
      "  [0.29227912]\n",
      "  [0.29475242]\n",
      "  [0.29707131]\n",
      "  [0.29869527]\n",
      "  [0.29930705]\n",
      "  [0.30039996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.952400558977388e-06\n",
      "Predicción post entrenamiento : [[0.30149493]]\n",
      "PERDIDAAAA despues: 3.994415237684734e-06\n",
      "loss en el callback: 0.0002772420702967793, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29022074]\n",
      " [0.29227912]\n",
      " [0.29475242]\n",
      " [0.29707131]\n",
      " [0.29869527]\n",
      " [0.29930705]\n",
      " [0.30039996]\n",
      " [0.30172172]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30311358]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29022074]\n",
      "  [0.29227912]\n",
      "  [0.29475242]\n",
      "  [0.29707131]\n",
      "  [0.29869527]\n",
      "  [0.29930705]\n",
      "  [0.30039996]\n",
      "  [0.30172172]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007426448864862323\n",
      "Predicción post entrenamiento : [[0.30295178]]\n",
      "PERDIDAAAA despues: 0.0007338526775129139\n",
      "loss en el callback: 0.00017859615036286414, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29227912]\n",
      " [0.29475242]\n",
      " [0.29707131]\n",
      " [0.29869527]\n",
      " [0.29930705]\n",
      " [0.30039996]\n",
      " [0.30172172]\n",
      " [0.30311358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30435798]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29227912]\n",
      "  [0.29475242]\n",
      "  [0.29707131]\n",
      "  [0.29869527]\n",
      "  [0.29930705]\n",
      "  [0.30039996]\n",
      "  [0.30172172]\n",
      "  [0.30311358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000879612285643816\n",
      "Predicción post entrenamiento : [[0.30451205]]\n",
      "PERDIDAAAA despues: 0.000888775393832475\n",
      "loss en el callback: 0.0002079983678413555, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29475242]\n",
      " [0.29707131]\n",
      " [0.29869527]\n",
      " [0.29930705]\n",
      " [0.30039996]\n",
      " [0.30172172]\n",
      " [0.30311358]\n",
      " [0.30435798]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30583134]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29475242]\n",
      "  [0.29707131]\n",
      "  [0.29869527]\n",
      "  [0.29930705]\n",
      "  [0.30039996]\n",
      "  [0.30172172]\n",
      "  [0.30311358]\n",
      "  [0.30435798]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009215313475579023\n",
      "Predicción post entrenamiento : [[0.30558664]]\n",
      "PERDIDAAAA despues: 0.000906734261661768\n",
      "loss en el callback: 0.00043980535701848567, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.29707131]\n",
      " [0.29869527]\n",
      " [0.29930705]\n",
      " [0.30039996]\n",
      " [0.30172172]\n",
      " [0.30311358]\n",
      " [0.30435798]\n",
      " [0.30583134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3066859]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.29707131]\n",
      "  [0.29869527]\n",
      "  [0.29930705]\n",
      "  [0.30039996]\n",
      "  [0.30172172]\n",
      "  [0.30311358]\n",
      "  [0.30435798]\n",
      "  [0.30583134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007878163014538586\n",
      "Predicción post entrenamiento : [[0.30734742]]\n",
      "PERDIDAAAA despues: 0.000751118641346693\n",
      "loss en el callback: 0.004318047780543566, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.29869527]\n",
      " [0.29930705]\n",
      " [0.30039996]\n",
      " [0.30172172]\n",
      " [0.30311358]\n",
      " [0.30435798]\n",
      " [0.30583134]\n",
      " [0.30668589]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.3082177]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.29869527]\n",
      "  [0.29930705]\n",
      "  [0.30039996]\n",
      "  [0.30172172]\n",
      "  [0.30311358]\n",
      "  [0.30435798]\n",
      "  [0.30583134]\n",
      "  [0.30668589]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002252297941595316\n",
      "Predicción post entrenamiento : [[0.30854642]]\n",
      "PERDIDAAAA despues: 0.0022212050389498472\n",
      "loss en el callback: 0.0007983054965734482, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.29930705]\n",
      " [0.30039996]\n",
      " [0.30172172]\n",
      " [0.30311358]\n",
      " [0.30435798]\n",
      " [0.30583134]\n",
      " [0.30668589]\n",
      " [0.3082177 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30931824]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.29930705]\n",
      "  [0.30039996]\n",
      "  [0.30172172]\n",
      "  [0.30311358]\n",
      "  [0.30435798]\n",
      "  [0.30583134]\n",
      "  [0.30668589]\n",
      "  [0.3082177 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007492787553928792\n",
      "Predicción post entrenamiento : [[0.3096982]]\n",
      "PERDIDAAAA despues: 0.0007286223699338734\n",
      "loss en el callback: 0.0012250164290890098, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.30039996]\n",
      " [0.30172172]\n",
      " [0.30311358]\n",
      " [0.30435798]\n",
      " [0.30583134]\n",
      " [0.30668589]\n",
      " [0.3082177 ]\n",
      " [0.30931824]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3106059]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.30039996]\n",
      "  [0.30172172]\n",
      "  [0.30311358]\n",
      "  [0.30435798]\n",
      "  [0.30583134]\n",
      "  [0.30668589]\n",
      "  [0.3082177 ]\n",
      "  [0.30931824]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005283436039462686\n",
      "Predicción post entrenamiento : [[0.31089157]]\n",
      "PERDIDAAAA despues: 0.0005152932135388255\n",
      "loss en el callback: 0.0007463952642865479, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30172172]\n",
      " [0.30311358]\n",
      " [0.30435798]\n",
      " [0.30583134]\n",
      " [0.30668589]\n",
      " [0.3082177 ]\n",
      " [0.30931824]\n",
      " [0.31060591]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.31184155]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30172172]\n",
      "  [0.30311358]\n",
      "  [0.30435798]\n",
      "  [0.30583134]\n",
      "  [0.30668589]\n",
      "  [0.3082177 ]\n",
      "  [0.30931824]\n",
      "  [0.31060591]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0053133973851799965\n",
      "Predicción post entrenamiento : [[0.31307092]]\n",
      "PERDIDAAAA despues: 0.005135682877153158\n",
      "loss en el callback: 0.01977178268134594, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30311358]\n",
      " [0.30435798]\n",
      " [0.30583134]\n",
      " [0.30668589]\n",
      " [0.3082177 ]\n",
      " [0.30931824]\n",
      " [0.31060591]\n",
      " [0.31184155]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.31401294]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30311358]\n",
      "  [0.30435798]\n",
      "  [0.30583134]\n",
      "  [0.30668589]\n",
      "  [0.3082177 ]\n",
      "  [0.30931824]\n",
      "  [0.31060591]\n",
      "  [0.31184155]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06609194725751877\n",
      "Predicción post entrenamiento : [[0.31647786]]\n",
      "PERDIDAAAA despues: 0.06483063846826553\n",
      "loss en el callback: 0.04613024368882179, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30435798]\n",
      " [0.30583134]\n",
      " [0.30668589]\n",
      " [0.3082177 ]\n",
      " [0.30931824]\n",
      " [0.31060591]\n",
      " [0.31184155]\n",
      " [0.31401294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.31739673]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30435798]\n",
      "  [0.30583134]\n",
      "  [0.30668589]\n",
      "  [0.3082177 ]\n",
      "  [0.30931824]\n",
      "  [0.31060591]\n",
      "  [0.31184155]\n",
      "  [0.31401294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07777616381645203\n",
      "Predicción post entrenamiento : [[0.32016936]]\n",
      "PERDIDAAAA despues: 0.07623737305402756\n",
      "loss en el callback: 0.07646723836660385, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30583134]\n",
      " [0.30668589]\n",
      " [0.3082177 ]\n",
      " [0.30931824]\n",
      " [0.31060591]\n",
      " [0.31184155]\n",
      " [0.31401294]\n",
      " [0.31739673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3211126]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30583134]\n",
      "  [0.30668589]\n",
      "  [0.3082177 ]\n",
      "  [0.30931824]\n",
      "  [0.31060591]\n",
      "  [0.31184155]\n",
      "  [0.31401294]\n",
      "  [0.31739673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0642474815249443\n",
      "Predicción post entrenamiento : [[0.32368365]]\n",
      "PERDIDAAAA despues: 0.06295072287321091\n",
      "loss en el callback: 0.0777793899178505, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30668589]\n",
      " [0.3082177 ]\n",
      " [0.30931824]\n",
      " [0.31060591]\n",
      " [0.31184155]\n",
      " [0.31401294]\n",
      " [0.31739673]\n",
      " [0.3211126 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.32462925]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30668589]\n",
      "  [0.3082177 ]\n",
      "  [0.30931824]\n",
      "  [0.31060591]\n",
      "  [0.31184155]\n",
      "  [0.31401294]\n",
      "  [0.31739673]\n",
      "  [0.3211126 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07936890423297882\n",
      "Predicción post entrenamiento : [[0.3271837]]\n",
      "PERDIDAAAA despues: 0.07793612778186798\n",
      "loss en el callback: 0.06827429682016373, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.3082177 ]\n",
      " [0.30931824]\n",
      " [0.31060591]\n",
      " [0.31184155]\n",
      " [0.31401294]\n",
      " [0.31739673]\n",
      " [0.3211126 ]\n",
      " [0.32462925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3283288]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.3082177 ]\n",
      "  [0.30931824]\n",
      "  [0.31060591]\n",
      "  [0.31184155]\n",
      "  [0.31401294]\n",
      "  [0.31739673]\n",
      "  [0.3211126 ]\n",
      "  [0.32462925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06570421904325485\n",
      "Predicción post entrenamiento : [[0.330414]]\n",
      "PERDIDAAAA despues: 0.06463956832885742\n",
      "loss en el callback: 0.03982124850153923, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30931824]\n",
      " [0.31060591]\n",
      " [0.31184155]\n",
      " [0.31401294]\n",
      " [0.31739673]\n",
      " [0.3211126 ]\n",
      " [0.32462925]\n",
      " [0.32832879]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3316746]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30931824]\n",
      "  [0.31060591]\n",
      "  [0.31184155]\n",
      "  [0.31401294]\n",
      "  [0.31739673]\n",
      "  [0.3211126 ]\n",
      "  [0.32462925]\n",
      "  [0.32832879]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0562150701880455\n",
      "Predicción post entrenamiento : [[0.33391848]]\n",
      "PERDIDAAAA despues: 0.05515607073903084\n",
      "loss en el callback: 0.06783968210220337, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.31060591]\n",
      " [0.31184155]\n",
      " [0.31401294]\n",
      " [0.31739673]\n",
      " [0.3211126 ]\n",
      " [0.32462925]\n",
      " [0.32832879]\n",
      " [0.33167461]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.33547223]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.31060591]\n",
      "  [0.31184155]\n",
      "  [0.31401294]\n",
      "  [0.31739673]\n",
      "  [0.3211126 ]\n",
      "  [0.32462925]\n",
      "  [0.32832879]\n",
      "  [0.33167461]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09443444758653641\n",
      "Predicción post entrenamiento : [[0.3379369]]\n",
      "PERDIDAAAA despues: 0.09292571991682053\n",
      "loss en el callback: 0.06374971568584442, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31184155]\n",
      " [0.31401294]\n",
      " [0.31739673]\n",
      " [0.3211126 ]\n",
      " [0.32462925]\n",
      " [0.32832879]\n",
      " [0.33167461]\n",
      " [0.33547223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.33983356]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31184155]\n",
      "  [0.31401294]\n",
      "  [0.31739673]\n",
      "  [0.3211126 ]\n",
      "  [0.32462925]\n",
      "  [0.32832879]\n",
      "  [0.33167461]\n",
      "  [0.33547223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1036360040307045\n",
      "Predicción post entrenamiento : [[0.34266382]]\n",
      "PERDIDAAAA despues: 0.10182174295186996\n",
      "loss en el callback: 0.08973473310470581, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.31401294]\n",
      " [0.31739673]\n",
      " [0.3211126 ]\n",
      " [0.32462925]\n",
      " [0.32832879]\n",
      " [0.33167461]\n",
      " [0.33547223]\n",
      " [0.33983356]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34501278]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.31401294]\n",
      "  [0.31739673]\n",
      "  [0.3211126 ]\n",
      "  [0.32462925]\n",
      "  [0.32832879]\n",
      "  [0.33167461]\n",
      "  [0.33547223]\n",
      "  [0.33983356]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10757231712341309\n",
      "Predicción post entrenamiento : [[0.3478776]]\n",
      "PERDIDAAAA despues: 0.10570131242275238\n",
      "loss en el callback: 0.11643968522548676, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.31739673]\n",
      " [0.3211126 ]\n",
      " [0.32462925]\n",
      " [0.32832879]\n",
      " [0.33167461]\n",
      " [0.33547223]\n",
      " [0.33983356]\n",
      " [0.34501278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.35055214]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.31739673]\n",
      "  [0.3211126 ]\n",
      "  [0.32462925]\n",
      "  [0.32832879]\n",
      "  [0.33167461]\n",
      "  [0.33547223]\n",
      "  [0.33983356]\n",
      "  [0.34501278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12961812317371368\n",
      "Predicción post entrenamiento : [[0.3535908]]\n",
      "PERDIDAAAA despues: 0.12743937969207764\n",
      "loss en el callback: 0.14121375977993011, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.3211126 ]\n",
      " [0.32462925]\n",
      " [0.32832879]\n",
      " [0.33167461]\n",
      " [0.33547223]\n",
      " [0.33983356]\n",
      " [0.34501278]\n",
      " [0.35055214]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35636985]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.3211126 ]\n",
      "  [0.32462925]\n",
      "  [0.32832879]\n",
      "  [0.33167461]\n",
      "  [0.33547223]\n",
      "  [0.33983356]\n",
      "  [0.34501278]\n",
      "  [0.35055214]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12084025144577026\n",
      "Predicción post entrenamiento : [[0.3592033]]\n",
      "PERDIDAAAA despues: 0.11887834221124649\n",
      "loss en el callback: 0.13464856147766113, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32462925]\n",
      " [0.32832879]\n",
      " [0.33167461]\n",
      " [0.33547223]\n",
      " [0.33983356]\n",
      " [0.34501278]\n",
      " [0.35055214]\n",
      " [0.35636985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.36205566]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32462925]\n",
      "  [0.32832879]\n",
      "  [0.33167461]\n",
      "  [0.33547223]\n",
      "  [0.33983356]\n",
      "  [0.34501278]\n",
      "  [0.35055214]\n",
      "  [0.35636985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13335779309272766\n",
      "Predicción post entrenamiento : [[0.364813]]\n",
      "PERDIDAAAA despues: 0.1313515305519104\n",
      "loss en el callback: 0.0966520681977272, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32832879]\n",
      " [0.33167461]\n",
      " [0.33547223]\n",
      " [0.33983356]\n",
      " [0.34501278]\n",
      " [0.35055214]\n",
      " [0.35636985]\n",
      " [0.36205566]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3678452]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32832879]\n",
      "  [0.33167461]\n",
      "  [0.33547223]\n",
      "  [0.33983356]\n",
      "  [0.34501278]\n",
      "  [0.35055214]\n",
      "  [0.35636985]\n",
      "  [0.36205566]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12584254145622253\n",
      "Predicción post entrenamiento : [[0.37075713]]\n",
      "PERDIDAAAA despues: 0.12378504127264023\n",
      "loss en el callback: 0.1362788826227188, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.33167461]\n",
      " [0.33547223]\n",
      " [0.33983356]\n",
      " [0.34501278]\n",
      " [0.35055214]\n",
      " [0.35636985]\n",
      " [0.36205566]\n",
      " [0.36784521]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.37399966]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.33167461]\n",
      "  [0.33547223]\n",
      "  [0.33983356]\n",
      "  [0.34501278]\n",
      "  [0.35055214]\n",
      "  [0.35636985]\n",
      "  [0.36205566]\n",
      "  [0.36784521]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15824025869369507\n",
      "Predicción post entrenamiento : [[0.37715715]]\n",
      "PERDIDAAAA despues: 0.15573816001415253\n",
      "loss en el callback: 0.1791326254606247, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33547223]\n",
      " [0.33983356]\n",
      " [0.34501278]\n",
      " [0.35055214]\n",
      " [0.35636985]\n",
      " [0.36205566]\n",
      " [0.36784521]\n",
      " [0.37399966]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.38078296]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33547223]\n",
      "  [0.33983356]\n",
      "  [0.34501278]\n",
      "  [0.35055214]\n",
      "  [0.35636985]\n",
      "  [0.36205566]\n",
      "  [0.36784521]\n",
      "  [0.37399966]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11815886199474335\n",
      "Predicción post entrenamiento : [[0.38368908]]\n",
      "PERDIDAAAA despues: 0.11616939306259155\n",
      "loss en el callback: 0.1565558761358261, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33983356]\n",
      " [0.34501278]\n",
      " [0.35055214]\n",
      " [0.35636985]\n",
      " [0.36205566]\n",
      " [0.36784521]\n",
      " [0.37399966]\n",
      " [0.38078296]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38768718]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33983356]\n",
      "  [0.34501278]\n",
      "  [0.35055214]\n",
      "  [0.35636985]\n",
      "  [0.36205566]\n",
      "  [0.36784521]\n",
      "  [0.37399966]\n",
      "  [0.38078296]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08029885590076447\n",
      "Predicción post entrenamiento : [[0.38992655]]\n",
      "PERDIDAAAA despues: 0.079034723341465\n",
      "loss en el callback: 0.08745460957288742, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34501278]\n",
      " [0.35055214]\n",
      " [0.35636985]\n",
      " [0.36205566]\n",
      " [0.36784521]\n",
      " [0.37399966]\n",
      " [0.38078296]\n",
      " [0.38768718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39424855]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34501278]\n",
      "  [0.35055214]\n",
      "  [0.35636985]\n",
      "  [0.36205566]\n",
      "  [0.36784521]\n",
      "  [0.37399966]\n",
      "  [0.38078296]\n",
      "  [0.38768718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07813215255737305\n",
      "Predicción post entrenamiento : [[0.3963944]]\n",
      "PERDIDAAAA despues: 0.07693713158369064\n",
      "loss en el callback: 0.07739531993865967, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.35055214]\n",
      " [0.35636985]\n",
      " [0.36205566]\n",
      " [0.36784521]\n",
      " [0.37399966]\n",
      " [0.38078296]\n",
      " [0.38768718]\n",
      " [0.39424855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.40090993]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.35055214]\n",
      "  [0.35636985]\n",
      "  [0.36205566]\n",
      "  [0.36784521]\n",
      "  [0.37399966]\n",
      "  [0.38078296]\n",
      "  [0.38768718]\n",
      "  [0.39424855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0983084961771965\n",
      "Predicción post entrenamiento : [[0.40332243]]\n",
      "PERDIDAAAA despues: 0.09680148214101791\n",
      "loss en el callback: 0.12587100267410278, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35636985]\n",
      " [0.36205566]\n",
      " [0.36784521]\n",
      " [0.37399966]\n",
      " [0.38078296]\n",
      " [0.38768718]\n",
      " [0.39424855]\n",
      " [0.40090993]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40799376]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35636985]\n",
      "  [0.36205566]\n",
      "  [0.36784521]\n",
      "  [0.37399966]\n",
      "  [0.38078296]\n",
      "  [0.38768718]\n",
      "  [0.39424855]\n",
      "  [0.40090993]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1128314808011055\n",
      "Predicción post entrenamiento : [[0.41029045]]\n",
      "PERDIDAAAA despues: 0.11129382252693176\n",
      "loss en el callback: 0.07088429480791092, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36205566]\n",
      " [0.36784521]\n",
      " [0.37399966]\n",
      " [0.38078296]\n",
      " [0.38768718]\n",
      " [0.39424855]\n",
      " [0.40090993]\n",
      " [0.40799376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41509223]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36205566]\n",
      "  [0.36784521]\n",
      "  [0.37399966]\n",
      "  [0.38078296]\n",
      "  [0.38768718]\n",
      "  [0.39424855]\n",
      "  [0.40090993]\n",
      "  [0.40799376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09455372393131256\n",
      "Predicción post entrenamiento : [[0.4172673]]\n",
      "PERDIDAAAA despues: 0.09322080761194229\n",
      "loss en el callback: 0.0724867582321167, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36784521]\n",
      " [0.37399966]\n",
      " [0.38078296]\n",
      " [0.38768718]\n",
      " [0.39424855]\n",
      " [0.40090993]\n",
      " [0.40799376]\n",
      " [0.41509223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42227617]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36784521]\n",
      "  [0.37399966]\n",
      "  [0.38078296]\n",
      "  [0.38768718]\n",
      "  [0.39424855]\n",
      "  [0.40090993]\n",
      "  [0.40799376]\n",
      "  [0.41509223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07676512002944946\n",
      "Predicción post entrenamiento : [[0.4243842]]\n",
      "PERDIDAAAA despues: 0.07560143619775772\n",
      "loss en el callback: 0.07594743371009827, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37399966]\n",
      " [0.38078296]\n",
      " [0.38768718]\n",
      " [0.39424855]\n",
      " [0.40090993]\n",
      " [0.40799376]\n",
      " [0.41509223]\n",
      " [0.42227617]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42962497]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37399966]\n",
      "  [0.38078296]\n",
      "  [0.38768718]\n",
      "  [0.39424855]\n",
      "  [0.40090993]\n",
      "  [0.40799376]\n",
      "  [0.41509223]\n",
      "  [0.42227617]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09467076510190964\n",
      "Predicción post entrenamiento : [[0.43203348]]\n",
      "PERDIDAAAA despues: 0.09319444000720978\n",
      "loss en el callback: 0.1272093653678894, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38078296]\n",
      " [0.38768718]\n",
      " [0.39424855]\n",
      " [0.40090993]\n",
      " [0.40799376]\n",
      " [0.41509223]\n",
      " [0.42227617]\n",
      " [0.42962497]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.437462]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38078296]\n",
      "  [0.38768718]\n",
      "  [0.39424855]\n",
      "  [0.40090993]\n",
      "  [0.40799376]\n",
      "  [0.41509223]\n",
      "  [0.42227617]\n",
      "  [0.42962497]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08063545823097229\n",
      "Predicción post entrenamiento : [[0.43946016]]\n",
      "PERDIDAAAA despues: 0.07950463891029358\n",
      "loss en el callback: 0.0766599103808403, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38768718]\n",
      " [0.39424855]\n",
      " [0.40090993]\n",
      " [0.40799376]\n",
      " [0.41509223]\n",
      " [0.42227617]\n",
      " [0.42962497]\n",
      " [0.437462  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4449506]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38768718]\n",
      "  [0.39424855]\n",
      "  [0.40090993]\n",
      "  [0.40799376]\n",
      "  [0.41509223]\n",
      "  [0.42227617]\n",
      "  [0.42962497]\n",
      "  [0.437462  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07494623214006424\n",
      "Predicción post entrenamiento : [[0.4469135]]\n",
      "PERDIDAAAA despues: 0.07387534528970718\n",
      "loss en el callback: 0.07494885474443436, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39424855]\n",
      " [0.40090993]\n",
      " [0.40799376]\n",
      " [0.41509223]\n",
      " [0.42227617]\n",
      " [0.42962497]\n",
      " [0.437462  ]\n",
      " [0.44495061]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4524569]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39424855]\n",
      "  [0.40090993]\n",
      "  [0.40799376]\n",
      "  [0.41509223]\n",
      "  [0.42227617]\n",
      "  [0.42962497]\n",
      "  [0.437462  ]\n",
      "  [0.44495061]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04915108159184456\n",
      "Predicción post entrenamiento : [[0.4540006]]\n",
      "PERDIDAAAA despues: 0.04846898466348648\n",
      "loss en el callback: 0.043439049273729324, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40090993]\n",
      " [0.40799376]\n",
      " [0.41509223]\n",
      " [0.42227617]\n",
      " [0.42962497]\n",
      " [0.437462  ]\n",
      " [0.44495061]\n",
      " [0.45245689]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.45971158]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40090993]\n",
      "  [0.40799376]\n",
      "  [0.41509223]\n",
      "  [0.42227617]\n",
      "  [0.42962497]\n",
      "  [0.437462  ]\n",
      "  [0.44495061]\n",
      "  [0.45245689]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0570516437292099\n",
      "Predicción post entrenamiento : [[0.4615319]]\n",
      "PERDIDAAAA despues: 0.056185368448495865\n",
      "loss en el callback: 0.07598751783370972, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.40799376]\n",
      " [0.41509223]\n",
      " [0.42227617]\n",
      " [0.42962497]\n",
      " [0.437462  ]\n",
      " [0.44495061]\n",
      " [0.45245689]\n",
      " [0.45971158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.46742356]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.40799376]\n",
      "  [0.41509223]\n",
      "  [0.42227617]\n",
      "  [0.42962497]\n",
      "  [0.437462  ]\n",
      "  [0.44495061]\n",
      "  [0.45245689]\n",
      "  [0.45971158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06432045996189117\n",
      "Predicción post entrenamiento : [[0.46919867]]\n",
      "PERDIDAAAA despues: 0.06342321634292603\n",
      "loss en el callback: 0.061091888695955276, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.41509223]\n",
      " [0.42227617]\n",
      " [0.42962497]\n",
      " [0.437462  ]\n",
      " [0.44495061]\n",
      " [0.45245689]\n",
      " [0.45971158]\n",
      " [0.46742356]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4751919]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.41509223]\n",
      "  [0.42227617]\n",
      "  [0.42962497]\n",
      "  [0.437462  ]\n",
      "  [0.44495061]\n",
      "  [0.45245689]\n",
      "  [0.45971158]\n",
      "  [0.46742356]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06120489537715912\n",
      "Predicción post entrenamiento : [[0.4767252]]\n",
      "PERDIDAAAA despues: 0.060448579490184784\n",
      "loss en el callback: 0.041971124708652496, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.42227617]\n",
      " [0.42962497]\n",
      " [0.437462  ]\n",
      " [0.44495061]\n",
      " [0.45245689]\n",
      " [0.45971158]\n",
      " [0.46742356]\n",
      " [0.47519189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.482836]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.42227617]\n",
      "  [0.42962497]\n",
      "  [0.437462  ]\n",
      "  [0.44495061]\n",
      "  [0.45245689]\n",
      "  [0.45971158]\n",
      "  [0.46742356]\n",
      "  [0.47519189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07478038966655731\n",
      "Predicción post entrenamiento : [[0.4848399]]\n",
      "PERDIDAAAA despues: 0.07368844002485275\n",
      "loss en el callback: 0.09890273213386536, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.42962497]\n",
      " [0.437462  ]\n",
      " [0.44495061]\n",
      " [0.45245689]\n",
      " [0.45971158]\n",
      " [0.46742356]\n",
      " [0.47519189]\n",
      " [0.48283601]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49106753]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.42962497]\n",
      "  [0.437462  ]\n",
      "  [0.44495061]\n",
      "  [0.45245689]\n",
      "  [0.45971158]\n",
      "  [0.46742356]\n",
      "  [0.47519189]\n",
      "  [0.48283601]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11324483901262283\n",
      "Predicción post entrenamiento : [[0.49292138]]\n",
      "PERDIDAAAA despues: 0.11200056225061417\n",
      "loss en el callback: 0.05149325728416443, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.437462  ]\n",
      " [0.44495061]\n",
      " [0.45245689]\n",
      " [0.45971158]\n",
      " [0.46742356]\n",
      " [0.47519189]\n",
      " [0.48283601]\n",
      " [0.49106753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.49924102]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.437462  ]\n",
      "  [0.44495061]\n",
      "  [0.45245689]\n",
      "  [0.45971158]\n",
      "  [0.46742356]\n",
      "  [0.47519189]\n",
      "  [0.48283601]\n",
      "  [0.49106753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11531536281108856\n",
      "Predicción post entrenamiento : [[0.50127983]]\n",
      "PERDIDAAAA despues: 0.11393484473228455\n",
      "loss en el callback: 0.07949802279472351, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.44495061]\n",
      " [0.45245689]\n",
      " [0.45971158]\n",
      " [0.46742356]\n",
      " [0.47519189]\n",
      " [0.48283601]\n",
      " [0.49106753]\n",
      " [0.49924102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5075762]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.44495061]\n",
      "  [0.45245689]\n",
      "  [0.45971158]\n",
      "  [0.46742356]\n",
      "  [0.47519189]\n",
      "  [0.48283601]\n",
      "  [0.49106753]\n",
      "  [0.49924102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08219091594219208\n",
      "Predicción post entrenamiento : [[0.5096693]]\n",
      "PERDIDAAAA despues: 0.08099517226219177\n",
      "loss en el callback: 0.10879217088222504, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.45245689]\n",
      " [0.45971158]\n",
      " [0.46742356]\n",
      " [0.47519189]\n",
      " [0.48283601]\n",
      " [0.49106753]\n",
      " [0.49924102]\n",
      " [0.50757623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5160452]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.45245689]\n",
      "  [0.45971158]\n",
      "  [0.46742356]\n",
      "  [0.47519189]\n",
      "  [0.48283601]\n",
      "  [0.49106753]\n",
      "  [0.49924102]\n",
      "  [0.50757623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07169514894485474\n",
      "Predicción post entrenamiento : [[0.5176458]]\n",
      "PERDIDAAAA despues: 0.07084058225154877\n",
      "loss en el callback: 0.05012809485197067, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.45971158]\n",
      " [0.46742356]\n",
      " [0.47519189]\n",
      " [0.48283601]\n",
      " [0.49106753]\n",
      " [0.49924102]\n",
      " [0.50757623]\n",
      " [0.51604521]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5241227]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.45971158]\n",
      "  [0.46742356]\n",
      "  [0.47519189]\n",
      "  [0.48283601]\n",
      "  [0.49106753]\n",
      "  [0.49924102]\n",
      "  [0.50757623]\n",
      "  [0.51604521]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05943683534860611\n",
      "Predicción post entrenamiento : [[0.5258829]]\n",
      "PERDIDAAAA despues: 0.058581676334142685\n",
      "loss en el callback: 0.0721716359257698, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.46742356]\n",
      " [0.47519189]\n",
      " [0.48283601]\n",
      " [0.49106753]\n",
      " [0.49924102]\n",
      " [0.50757623]\n",
      " [0.51604521]\n",
      " [0.52412271]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5325633]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.46742356]\n",
      "  [0.47519189]\n",
      "  [0.48283601]\n",
      "  [0.49106753]\n",
      "  [0.49924102]\n",
      "  [0.50757623]\n",
      "  [0.51604521]\n",
      "  [0.52412271]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06351222097873688\n",
      "Predicción post entrenamiento : [[0.5339999]]\n",
      "PERDIDAAAA despues: 0.06279019266366959\n",
      "loss en el callback: 0.03747782111167908, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.47519189]\n",
      " [0.48283601]\n",
      " [0.49106753]\n",
      " [0.49924102]\n",
      " [0.50757623]\n",
      " [0.51604521]\n",
      " [0.52412271]\n",
      " [0.53256333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.54079866]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.47519189]\n",
      "  [0.48283601]\n",
      "  [0.49106753]\n",
      "  [0.49924102]\n",
      "  [0.50757623]\n",
      "  [0.51604521]\n",
      "  [0.52412271]\n",
      "  [0.53256333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1141970232129097\n",
      "Predicción post entrenamiento : [[0.5428296]]\n",
      "PERDIDAAAA despues: 0.11282853782176971\n",
      "loss en el callback: 0.083450548350811, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.48283601]\n",
      " [0.49106753]\n",
      " [0.49924102]\n",
      " [0.50757623]\n",
      " [0.51604521]\n",
      " [0.52412271]\n",
      " [0.53256333]\n",
      " [0.54079866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5497595]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.48283601]\n",
      "  [0.49106753]\n",
      "  [0.49924102]\n",
      "  [0.50757623]\n",
      "  [0.51604521]\n",
      "  [0.52412271]\n",
      "  [0.53256333]\n",
      "  [0.54079866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10619132220745087\n",
      "Predicción post entrenamiento : [[0.5519136]]\n",
      "PERDIDAAAA despues: 0.1047920361161232\n",
      "loss en el callback: 0.11157447099685669, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.49106753]\n",
      " [0.49924102]\n",
      " [0.50757623]\n",
      " [0.51604521]\n",
      " [0.52412271]\n",
      " [0.53256333]\n",
      " [0.54079866]\n",
      " [0.54975951]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.559039]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.49106753]\n",
      "  [0.49924102]\n",
      "  [0.50757623]\n",
      "  [0.51604521]\n",
      "  [0.52412271]\n",
      "  [0.53256333]\n",
      "  [0.54079866]\n",
      "  [0.54975951]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08401695638895035\n",
      "Predicción post entrenamiento : [[0.5608627]]\n",
      "PERDIDAAAA despues: 0.08296304941177368\n",
      "loss en el callback: 0.07709230482578278, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.49924102]\n",
      " [0.50757623]\n",
      " [0.51604521]\n",
      " [0.52412271]\n",
      " [0.53256333]\n",
      " [0.54079866]\n",
      " [0.54975951]\n",
      " [0.559039  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5680538]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.49924102]\n",
      "  [0.50757623]\n",
      "  [0.51604521]\n",
      "  [0.52412271]\n",
      "  [0.53256333]\n",
      "  [0.54079866]\n",
      "  [0.54975951]\n",
      "  [0.559039  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06261690706014633\n",
      "Predicción post entrenamiento : [[0.5695698]]\n",
      "PERDIDAAAA despues: 0.061860475689172745\n",
      "loss en el callback: 0.046422574669122696, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.50757623]\n",
      " [0.51604521]\n",
      " [0.52412271]\n",
      " [0.53256333]\n",
      " [0.54079866]\n",
      " [0.54975951]\n",
      " [0.559039  ]\n",
      " [0.56805378]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.576863]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.50757623]\n",
      "  [0.51604521]\n",
      "  [0.52412271]\n",
      "  [0.53256333]\n",
      "  [0.54079866]\n",
      "  [0.54975951]\n",
      "  [0.559039  ]\n",
      "  [0.56805378]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06247416511178017\n",
      "Predicción post entrenamiento : [[0.5786714]]\n",
      "PERDIDAAAA despues: 0.061573419719934464\n",
      "loss en el callback: 0.10091721266508102, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.51604521]\n",
      " [0.52412271]\n",
      " [0.53256333]\n",
      " [0.54079866]\n",
      " [0.54975951]\n",
      " [0.559039  ]\n",
      " [0.56805378]\n",
      " [0.57686299]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.58604985]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.51604521]\n",
      "  [0.52412271]\n",
      "  [0.53256333]\n",
      "  [0.54079866]\n",
      "  [0.54975951]\n",
      "  [0.559039  ]\n",
      "  [0.56805378]\n",
      "  [0.57686299]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03972233831882477\n",
      "Predicción post entrenamiento : [[0.5872247]]\n",
      "PERDIDAAAA despues: 0.03925540670752525\n",
      "loss en el callback: 0.03212351351976395, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.52412271]\n",
      " [0.53256333]\n",
      " [0.54079866]\n",
      " [0.54975951]\n",
      " [0.559039  ]\n",
      " [0.56805378]\n",
      " [0.57686299]\n",
      " [0.58604985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5946751]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.52412271]\n",
      "  [0.53256333]\n",
      "  [0.54079866]\n",
      "  [0.54975951]\n",
      "  [0.559039  ]\n",
      "  [0.56805378]\n",
      "  [0.57686299]\n",
      "  [0.58604985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03785119950771332\n",
      "Predicción post entrenamiento : [[0.5960117]]\n",
      "PERDIDAAAA despues: 0.037332914769649506\n",
      "loss en el callback: 0.043778643012046814, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.53256333]\n",
      " [0.54079866]\n",
      " [0.54975951]\n",
      " [0.559039  ]\n",
      " [0.56805378]\n",
      " [0.57686299]\n",
      " [0.58604985]\n",
      " [0.59467512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6036729]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.53256333]\n",
      "  [0.54079866]\n",
      "  [0.54975951]\n",
      "  [0.559039  ]\n",
      "  [0.56805378]\n",
      "  [0.57686299]\n",
      "  [0.58604985]\n",
      "  [0.59467512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05313018709421158\n",
      "Predicción post entrenamiento : [[0.6052513]]\n",
      "PERDIDAAAA despues: 0.052405040711164474\n",
      "loss en el callback: 0.06237909197807312, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.54079866]\n",
      " [0.54975951]\n",
      " [0.559039  ]\n",
      " [0.56805378]\n",
      " [0.57686299]\n",
      " [0.58604985]\n",
      " [0.59467512]\n",
      " [0.60367292]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.613059]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.54079866]\n",
      "  [0.54975951]\n",
      "  [0.559039  ]\n",
      "  [0.56805378]\n",
      "  [0.57686299]\n",
      "  [0.58604985]\n",
      "  [0.59467512]\n",
      "  [0.60367292]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0397670678794384\n",
      "Predicción post entrenamiento : [[0.6139632]]\n",
      "PERDIDAAAA despues: 0.03940725699067116\n",
      "loss en el callback: 0.01602848805487156, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.54975951]\n",
      " [0.559039  ]\n",
      " [0.56805378]\n",
      " [0.57686299]\n",
      " [0.58604985]\n",
      " [0.59467512]\n",
      " [0.60367292]\n",
      " [0.61305898]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.622001]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.54975951]\n",
      "  [0.559039  ]\n",
      "  [0.56805378]\n",
      "  [0.57686299]\n",
      "  [0.58604985]\n",
      "  [0.59467512]\n",
      "  [0.60367292]\n",
      "  [0.61305898]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032126568257808685\n",
      "Predicción post entrenamiento : [[0.62310094]]\n",
      "PERDIDAAAA despues: 0.031733471900224686\n",
      "loss en el callback: 0.026674143970012665, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.559039  ]\n",
      " [0.56805378]\n",
      " [0.57686299]\n",
      " [0.58604985]\n",
      " [0.59467512]\n",
      " [0.60367292]\n",
      " [0.61305898]\n",
      " [0.62200099]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.63118815]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.559039  ]\n",
      "  [0.56805378]\n",
      "  [0.57686299]\n",
      "  [0.58604985]\n",
      "  [0.59467512]\n",
      "  [0.60367292]\n",
      "  [0.61305898]\n",
      "  [0.62200099]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02958018332719803\n",
      "Predicción post entrenamiento : [[0.6323958]]\n",
      "PERDIDAAAA despues: 0.029166236519813538\n",
      "loss en el callback: 0.035074781626462936, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.56805378]\n",
      " [0.57686299]\n",
      " [0.58604985]\n",
      " [0.59467512]\n",
      " [0.60367292]\n",
      " [0.61305898]\n",
      " [0.62200099]\n",
      " [0.63118815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.64044034]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.56805378]\n",
      "  [0.57686299]\n",
      "  [0.58604985]\n",
      "  [0.59467512]\n",
      "  [0.60367292]\n",
      "  [0.61305898]\n",
      "  [0.62200099]\n",
      "  [0.63118815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02342446893453598\n",
      "Predicción post entrenamiento : [[0.64099085]]\n",
      "PERDIDAAAA despues: 0.02325626090168953\n",
      "loss en el callback: 0.0063190399669110775, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.57686299]\n",
      " [0.58604985]\n",
      " [0.59467512]\n",
      " [0.60367292]\n",
      " [0.61305898]\n",
      " [0.62200099]\n",
      " [0.63118815]\n",
      " [0.64044034]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.64906085]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.57686299]\n",
      "  [0.58604985]\n",
      "  [0.59467512]\n",
      "  [0.60367292]\n",
      "  [0.61305898]\n",
      "  [0.62200099]\n",
      "  [0.63118815]\n",
      "  [0.64044034]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012345346622169018\n",
      "Predicción post entrenamiento : [[0.64963]]\n",
      "PERDIDAAAA despues: 0.01221919059753418\n",
      "loss en el callback: 0.007629139348864555, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.58604985]\n",
      " [0.59467512]\n",
      " [0.60367292]\n",
      " [0.61305898]\n",
      " [0.62200099]\n",
      " [0.63118815]\n",
      " [0.64044034]\n",
      " [0.64906085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.65778965]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.58604985]\n",
      "  [0.59467512]\n",
      "  [0.60367292]\n",
      "  [0.61305898]\n",
      "  [0.62200099]\n",
      "  [0.63118815]\n",
      "  [0.64044034]\n",
      "  [0.64906085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006019318476319313\n",
      "Predicción post entrenamiento : [[0.6583581]]\n",
      "PERDIDAAAA despues: 0.005931436084210873\n",
      "loss en el callback: 0.008808821439743042, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.59467512]\n",
      " [0.60367292]\n",
      " [0.61305898]\n",
      " [0.62200099]\n",
      " [0.63118815]\n",
      " [0.64044034]\n",
      " [0.64906085]\n",
      " [0.65778965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6665024]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.59467512]\n",
      "  [0.60367292]\n",
      "  [0.61305898]\n",
      "  [0.62200099]\n",
      "  [0.63118815]\n",
      "  [0.64044034]\n",
      "  [0.64906085]\n",
      "  [0.65778965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019085891544818878\n",
      "Predicción post entrenamiento : [[0.666749]]\n",
      "PERDIDAAAA despues: 0.001887104706838727\n",
      "loss en el callback: 0.0015330351889133453, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.60367292]\n",
      " [0.61305898]\n",
      " [0.62200099]\n",
      " [0.63118815]\n",
      " [0.64044034]\n",
      " [0.64906085]\n",
      " [0.65778965]\n",
      " [0.66650242]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6750343]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.60367292]\n",
      "  [0.61305898]\n",
      "  [0.62200099]\n",
      "  [0.63118815]\n",
      "  [0.64044034]\n",
      "  [0.64906085]\n",
      "  [0.65778965]\n",
      "  [0.66650242]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001375876134261489\n",
      "Predicción post entrenamiento : [[0.6760312]]\n",
      "PERDIDAAAA despues: 0.0013029152760282159\n",
      "loss en el callback: 0.03931190073490143, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.61305898]\n",
      " [0.62200099]\n",
      " [0.63118815]\n",
      " [0.64044034]\n",
      " [0.64906085]\n",
      " [0.65778965]\n",
      " [0.66650242]\n",
      " [0.67503428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6843549]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.61305898]\n",
      "  [0.62200099]\n",
      "  [0.63118815]\n",
      "  [0.64044034]\n",
      "  [0.64906085]\n",
      "  [0.65778965]\n",
      "  [0.66650242]\n",
      "  [0.67503428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030559804290533066\n",
      "Predicción post entrenamiento : [[0.6842872]]\n",
      "PERDIDAAAA despues: 0.0030634712893515825\n",
      "loss en el callback: 9.405762830283493e-05, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.62200099]\n",
      " [0.63118815]\n",
      " [0.64044034]\n",
      " [0.64906085]\n",
      " [0.65778965]\n",
      " [0.66650242]\n",
      " [0.67503428]\n",
      " [0.6843549 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.69251597]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.62200099]\n",
      "  [0.63118815]\n",
      "  [0.64044034]\n",
      "  [0.64906085]\n",
      "  [0.65778965]\n",
      "  [0.66650242]\n",
      "  [0.67503428]\n",
      "  [0.6843549 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019038217142224312\n",
      "Predicción post entrenamiento : [[0.6932984]]\n",
      "PERDIDAAAA despues: 0.0018361546099185944\n",
      "loss en el callback: 0.019405417144298553, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.63118815]\n",
      " [0.64044034]\n",
      " [0.64906085]\n",
      " [0.65778965]\n",
      " [0.66650242]\n",
      " [0.67503428]\n",
      " [0.6843549 ]\n",
      " [0.69251597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7015402]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.63118815]\n",
      "  [0.64044034]\n",
      "  [0.64906085]\n",
      "  [0.65778965]\n",
      "  [0.66650242]\n",
      "  [0.67503428]\n",
      "  [0.6843549 ]\n",
      "  [0.69251597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011539243860170245\n",
      "Predicción post entrenamiento : [[0.70116806]]\n",
      "PERDIDAAAA despues: 0.0011287819361314178\n",
      "loss en el callback: 0.0031969482079148293, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.64044034]\n",
      " [0.64906085]\n",
      " [0.65778965]\n",
      " [0.66650242]\n",
      " [0.67503428]\n",
      " [0.6843549 ]\n",
      " [0.69251597]\n",
      " [0.70154017]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.709331]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.64044034]\n",
      "  [0.64906085]\n",
      "  [0.65778965]\n",
      "  [0.66650242]\n",
      "  [0.67503428]\n",
      "  [0.6843549 ]\n",
      "  [0.69251597]\n",
      "  [0.70154017]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015551638789474964\n",
      "Predicción post entrenamiento : [[0.70893705]]\n",
      "PERDIDAAAA despues: 0.0015242495574057102\n",
      "loss en el callback: 0.0038290745578706264, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.64906085]\n",
      " [0.65778965]\n",
      " [0.66650242]\n",
      " [0.67503428]\n",
      " [0.6843549 ]\n",
      " [0.69251597]\n",
      " [0.70154017]\n",
      " [0.70933098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7169733]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.64906085]\n",
      "  [0.65778965]\n",
      "  [0.66650242]\n",
      "  [0.67503428]\n",
      "  [0.6843549 ]\n",
      "  [0.69251597]\n",
      "  [0.70154017]\n",
      "  [0.70933098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004138815274927765\n",
      "Predicción post entrenamiento : [[0.7172151]]\n",
      "PERDIDAAAA despues: 0.0004237790417391807\n",
      "loss en el callback: 0.0017448109574615955, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.65778965]\n",
      " [0.66650242]\n",
      " [0.67503428]\n",
      " [0.6843549 ]\n",
      " [0.69251597]\n",
      " [0.70154017]\n",
      " [0.70933098]\n",
      " [0.7169733 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.72528404]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.65778965]\n",
      "  [0.66650242]\n",
      "  [0.67503428]\n",
      "  [0.6843549 ]\n",
      "  [0.69251597]\n",
      "  [0.70154017]\n",
      "  [0.70933098]\n",
      "  [0.7169733 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004807579796761274\n",
      "Predicción post entrenamiento : [[0.72381306]]\n",
      "PERDIDAAAA despues: 0.00460575707256794\n",
      "loss en el callback: 0.04185076057910919, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.66650242]\n",
      " [0.67503428]\n",
      " [0.6843549 ]\n",
      " [0.69251597]\n",
      " [0.70154017]\n",
      " [0.70933098]\n",
      " [0.7169733 ]\n",
      " [0.72528404]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.73185754]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.66650242]\n",
      "  [0.67503428]\n",
      "  [0.6843549 ]\n",
      "  [0.69251597]\n",
      "  [0.70154017]\n",
      "  [0.70933098]\n",
      "  [0.7169733 ]\n",
      "  [0.72528404]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028143953531980515\n",
      "Predicción post entrenamiento : [[0.7309282]]\n",
      "PERDIDAAAA despues: 0.0027166528161615133\n",
      "loss en el callback: 0.018139835447072983, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.67503428]\n",
      " [0.6843549 ]\n",
      " [0.69251597]\n",
      " [0.70154017]\n",
      " [0.70933098]\n",
      " [0.7169733 ]\n",
      " [0.72528404]\n",
      " [0.73185754]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.73891926]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.67503428]\n",
      "  [0.6843549 ]\n",
      "  [0.69251597]\n",
      "  [0.70154017]\n",
      "  [0.70933098]\n",
      "  [0.7169733 ]\n",
      "  [0.72528404]\n",
      "  [0.73185754]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0039469460025429726\n",
      "Predicción post entrenamiento : [[0.73792124]]\n",
      "PERDIDAAAA despues: 0.0038225415628403425\n",
      "loss en el callback: 0.023478394374251366, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.6843549 ]\n",
      " [0.69251597]\n",
      " [0.70154017]\n",
      " [0.70933098]\n",
      " [0.7169733 ]\n",
      " [0.72528404]\n",
      " [0.73185754]\n",
      " [0.73891926]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.74586356]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.6843549 ]\n",
      "  [0.69251597]\n",
      "  [0.70154017]\n",
      "  [0.70933098]\n",
      "  [0.7169733 ]\n",
      "  [0.72528404]\n",
      "  [0.73185754]\n",
      "  [0.73891926]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026573543436825275\n",
      "Predicción post entrenamiento : [[0.74638146]]\n",
      "PERDIDAAAA despues: 0.00028288879548199475\n",
      "loss en el callback: 0.009362342767417431, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.69251597]\n",
      " [0.70154017]\n",
      " [0.70933098]\n",
      " [0.7169733 ]\n",
      " [0.72528404]\n",
      " [0.73185754]\n",
      " [0.73891926]\n",
      " [0.74586356]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7539785]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.69251597]\n",
      "  [0.70154017]\n",
      "  [0.70933098]\n",
      "  [0.7169733 ]\n",
      "  [0.72528404]\n",
      "  [0.73185754]\n",
      "  [0.73891926]\n",
      "  [0.74586356]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002777281915768981\n",
      "Predicción post entrenamiento : [[0.75339895]]\n",
      "PERDIDAAAA despues: 0.002716534771025181\n",
      "loss en el callback: 0.008504551835358143, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.70154017]\n",
      " [0.70933098]\n",
      " [0.7169733 ]\n",
      " [0.72528404]\n",
      " [0.73185754]\n",
      " [0.73891926]\n",
      " [0.74586356]\n",
      " [0.75397849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.76091254]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.70154017]\n",
      "  [0.70933098]\n",
      "  [0.7169733 ]\n",
      "  [0.72528404]\n",
      "  [0.73185754]\n",
      "  [0.73891926]\n",
      "  [0.74586356]\n",
      "  [0.75397849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.3817162804771215e-05\n",
      "Predicción post entrenamiento : [[0.7607266]]\n",
      "PERDIDAAAA despues: 4.631374031305313e-05\n",
      "loss en el callback: 0.0008172838133759797, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.70933098]\n",
      " [0.7169733 ]\n",
      " [0.72528404]\n",
      " [0.73185754]\n",
      " [0.73891926]\n",
      " [0.74586356]\n",
      " [0.75397849]\n",
      " [0.76091254]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.76784277]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.70933098]\n",
      "  [0.7169733 ]\n",
      "  [0.72528404]\n",
      "  [0.73185754]\n",
      "  [0.73891926]\n",
      "  [0.74586356]\n",
      "  [0.75397849]\n",
      "  [0.76091254]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001615207438590005\n",
      "Predicción post entrenamiento : [[0.767404]]\n",
      "PERDIDAAAA despues: 0.00015056102711241692\n",
      "loss en el callback: 0.004626937676221132, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.7169733 ]\n",
      " [0.72528404]\n",
      " [0.73185754]\n",
      " [0.73891926]\n",
      " [0.74586356]\n",
      " [0.75397849]\n",
      " [0.76091254]\n",
      " [0.76784277]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7744217]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.7169733 ]\n",
      "  [0.72528404]\n",
      "  [0.73185754]\n",
      "  [0.73891926]\n",
      "  [0.74586356]\n",
      "  [0.75397849]\n",
      "  [0.76091254]\n",
      "  [0.76784277]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008621073793619871\n",
      "Predicción post entrenamiento : [[0.7739578]]\n",
      "PERDIDAAAA despues: 0.0008350806892849505\n",
      "loss en el callback: 0.005179576110094786, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.72528404]\n",
      " [0.73185754]\n",
      " [0.73891926]\n",
      " [0.74586356]\n",
      " [0.75397849]\n",
      " [0.76091254]\n",
      " [0.76784277]\n",
      " [0.77442169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.78088856]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.72528404]\n",
      "  [0.73185754]\n",
      "  [0.73891926]\n",
      "  [0.74586356]\n",
      "  [0.75397849]\n",
      "  [0.76091254]\n",
      "  [0.76784277]\n",
      "  [0.77442169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008325815433636308\n",
      "Predicción post entrenamiento : [[0.7808986]]\n",
      "PERDIDAAAA despues: 0.0008331595454365015\n",
      "loss en el callback: 3.0140588478388963e-06, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.73185754]\n",
      " [0.73891926]\n",
      " [0.74586356]\n",
      " [0.75397849]\n",
      " [0.76091254]\n",
      " [0.76784277]\n",
      " [0.77442169]\n",
      " [0.78088856]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.78750217]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.73185754]\n",
      "  [0.73891926]\n",
      "  [0.74586356]\n",
      "  [0.75397849]\n",
      "  [0.76091254]\n",
      "  [0.76784277]\n",
      "  [0.77442169]\n",
      "  [0.78088856]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006037255749106407\n",
      "Predicción post entrenamiento : [[0.7872462]]\n",
      "PERDIDAAAA despues: 0.005997547879815102\n",
      "loss en el callback: 0.001917807967402041, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.73891926]\n",
      " [0.74586356]\n",
      " [0.75397849]\n",
      " [0.76091254]\n",
      " [0.76784277]\n",
      " [0.77442169]\n",
      " [0.78088856]\n",
      " [0.78750217]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7940016]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.73891926]\n",
      "  [0.74586356]\n",
      "  [0.75397849]\n",
      "  [0.76091254]\n",
      "  [0.76784277]\n",
      "  [0.77442169]\n",
      "  [0.78088856]\n",
      "  [0.78750217]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010727062821388245\n",
      "Predicción post entrenamiento : [[0.79368544]]\n",
      "PERDIDAAAA despues: 0.010661675594747066\n",
      "loss en el callback: 0.0030857338570058346, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.74586356]\n",
      " [0.75397849]\n",
      " [0.76091254]\n",
      " [0.76784277]\n",
      " [0.77442169]\n",
      " [0.78088856]\n",
      " [0.78750217]\n",
      " [0.79400158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8004425]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.74586356]\n",
      "  [0.75397849]\n",
      "  [0.76091254]\n",
      "  [0.76784277]\n",
      "  [0.77442169]\n",
      "  [0.78088856]\n",
      "  [0.78750217]\n",
      "  [0.79400158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021237118635326624\n",
      "Predicción post entrenamiento : [[0.7998974]]\n",
      "PERDIDAAAA despues: 0.002073764568194747\n",
      "loss en el callback: 0.00813205260783434, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.75397849]\n",
      " [0.76091254]\n",
      " [0.76784277]\n",
      " [0.77442169]\n",
      " [0.78088856]\n",
      " [0.78750217]\n",
      " [0.79400158]\n",
      " [0.80044252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8066667]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.75397849]\n",
      "  [0.76091254]\n",
      "  [0.76784277]\n",
      "  [0.77442169]\n",
      "  [0.78088856]\n",
      "  [0.78750217]\n",
      "  [0.79400158]\n",
      "  [0.80044252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007134501822292805\n",
      "Predicción post entrenamiento : [[0.80592954]]\n",
      "PERDIDAAAA despues: 0.007010520435869694\n",
      "loss en el callback: 0.014100339263677597, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.76091254]\n",
      " [0.76784277]\n",
      " [0.77442169]\n",
      " [0.78088856]\n",
      " [0.78750217]\n",
      " [0.79400158]\n",
      " [0.80044252]\n",
      " [0.80666667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.81231487]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.76091254]\n",
      "  [0.76784277]\n",
      "  [0.77442169]\n",
      "  [0.78088856]\n",
      "  [0.78750217]\n",
      "  [0.79400158]\n",
      "  [0.80044252]\n",
      "  [0.80666667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001309968763962388\n",
      "Predicción post entrenamiento : [[0.8116879]]\n",
      "PERDIDAAAA despues: 0.001355747110210359\n",
      "loss en el callback: 0.008617541752755642, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.76784277]\n",
      " [0.77442169]\n",
      " [0.78088856]\n",
      " [0.78750217]\n",
      " [0.79400158]\n",
      " [0.80044252]\n",
      " [0.80666667]\n",
      " [0.81231487]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8179785]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.76784277]\n",
      "  [0.77442169]\n",
      "  [0.78088856]\n",
      "  [0.78750217]\n",
      "  [0.79400158]\n",
      "  [0.80044252]\n",
      "  [0.80666667]\n",
      "  [0.81231487]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007653533946722746\n",
      "Predicción post entrenamiento : [[0.818143]]\n",
      "PERDIDAAAA despues: 0.0076247770339250565\n",
      "loss en el callback: 0.0006958290468901396, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.77442169]\n",
      " [0.78088856]\n",
      " [0.78750217]\n",
      " [0.79400158]\n",
      " [0.80044252]\n",
      " [0.80666667]\n",
      " [0.81231487]\n",
      " [0.8179785 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8243056]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.77442169]\n",
      "  [0.78088856]\n",
      "  [0.78750217]\n",
      "  [0.79400158]\n",
      "  [0.80044252]\n",
      "  [0.80666667]\n",
      "  [0.81231487]\n",
      "  [0.8179785 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033536399714648724\n",
      "Predicción post entrenamiento : [[0.8243969]]\n",
      "PERDIDAAAA despues: 0.0033430722542107105\n",
      "loss en el callback: 0.00023683860490564257, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.78088856]\n",
      " [0.78750217]\n",
      " [0.79400158]\n",
      " [0.80044252]\n",
      " [0.80666667]\n",
      " [0.81231487]\n",
      " [0.8179785 ]\n",
      " [0.82430559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8305015]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.78088856]\n",
      "  [0.78750217]\n",
      "  [0.79400158]\n",
      "  [0.80044252]\n",
      "  [0.80666667]\n",
      "  [0.81231487]\n",
      "  [0.8179785 ]\n",
      "  [0.82430559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005973154213279486\n",
      "Predicción post entrenamiento : [[0.83071256]]\n",
      "PERDIDAAAA despues: 0.005940574686974287\n",
      "loss en el callback: 0.0011882645776495337, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.78750217]\n",
      " [0.79400158]\n",
      " [0.80044252]\n",
      " [0.80666667]\n",
      " [0.81231487]\n",
      " [0.8179785 ]\n",
      " [0.82430559]\n",
      " [0.8305015 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8367686]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.78750217]\n",
      "  [0.79400158]\n",
      "  [0.80044252]\n",
      "  [0.80666667]\n",
      "  [0.81231487]\n",
      "  [0.8179785 ]\n",
      "  [0.82430559]\n",
      "  [0.8305015 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027887967880815268\n",
      "Predicción post entrenamiento : [[0.8368443]]\n",
      "PERDIDAAAA despues: 0.002780807437375188\n",
      "loss en el callback: 0.00015894792159087956, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.79400158]\n",
      " [0.80044252]\n",
      " [0.80666667]\n",
      " [0.81231487]\n",
      " [0.8179785 ]\n",
      " [0.82430559]\n",
      " [0.8305015 ]\n",
      " [0.83676863]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8427825]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.79400158]\n",
      "  [0.80044252]\n",
      "  [0.80666667]\n",
      "  [0.81231487]\n",
      "  [0.8179785 ]\n",
      "  [0.82430559]\n",
      "  [0.8305015 ]\n",
      "  [0.83676863]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010286251781508327\n",
      "Predicción post entrenamiento : [[0.8437999]]\n",
      "PERDIDAAAA despues: 0.0009644003002904356\n",
      "loss en el callback: 0.052123408764600754, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.80044252]\n",
      " [0.80666667]\n",
      " [0.81231487]\n",
      " [0.8179785 ]\n",
      " [0.82430559]\n",
      " [0.8305015 ]\n",
      " [0.83676863]\n",
      " [0.8427825 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.84963155]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.80044252]\n",
      "  [0.80666667]\n",
      "  [0.81231487]\n",
      "  [0.8179785 ]\n",
      "  [0.82430559]\n",
      "  [0.8305015 ]\n",
      "  [0.83676863]\n",
      "  [0.8427825 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004042466636747122\n",
      "Predicción post entrenamiento : [[0.8506303]]\n",
      "PERDIDAAAA despues: 0.003916463814675808\n",
      "loss en el callback: 0.039582259953022, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.80666667]\n",
      " [0.81231487]\n",
      " [0.8179785 ]\n",
      " [0.82430559]\n",
      " [0.8305015 ]\n",
      " [0.83676863]\n",
      " [0.8427825 ]\n",
      " [0.84963155]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.856359]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.80666667]\n",
      "  [0.81231487]\n",
      "  [0.8179785 ]\n",
      "  [0.82430559]\n",
      "  [0.8305015 ]\n",
      "  [0.83676863]\n",
      "  [0.8427825 ]\n",
      "  [0.84963155]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020632734522223473\n",
      "Predicción post entrenamiento : [[0.8573797]]\n",
      "PERDIDAAAA despues: 0.020340556278824806\n",
      "loss en el callback: 0.03124372474849224, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.81231487]\n",
      " [0.8179785 ]\n",
      " [0.82430559]\n",
      " [0.8305015 ]\n",
      " [0.83676863]\n",
      " [0.8427825 ]\n",
      " [0.84963155]\n",
      " [0.856359  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8630714]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.81231487]\n",
      "  [0.8179785 ]\n",
      "  [0.82430559]\n",
      "  [0.8305015 ]\n",
      "  [0.83676863]\n",
      "  [0.8427825 ]\n",
      "  [0.84963155]\n",
      "  [0.856359  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011552524752914906\n",
      "Predicción post entrenamiento : [[0.8637021]]\n",
      "PERDIDAAAA despues: 0.011417335830628872\n",
      "loss en el callback: 0.012698344886302948, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.8179785 ]\n",
      " [0.82430559]\n",
      " [0.8305015 ]\n",
      " [0.83676863]\n",
      " [0.8427825 ]\n",
      " [0.84963155]\n",
      " [0.856359  ]\n",
      " [0.86307138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8695556]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.8179785 ]\n",
      "  [0.82430559]\n",
      "  [0.8305015 ]\n",
      "  [0.83676863]\n",
      "  [0.8427825 ]\n",
      "  [0.84963155]\n",
      "  [0.856359  ]\n",
      "  [0.86307138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003704537230078131\n",
      "Predicción post entrenamiento : [[0.8699464]]\n",
      "PERDIDAAAA despues: 0.0003555618168320507\n",
      "loss en el callback: 0.005135896150022745, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.82430559]\n",
      " [0.8305015 ]\n",
      " [0.83676863]\n",
      " [0.8427825 ]\n",
      " [0.84963155]\n",
      " [0.856359  ]\n",
      " [0.86307138]\n",
      " [0.86955559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.87599957]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.82430559]\n",
      "  [0.8305015 ]\n",
      "  [0.83676863]\n",
      "  [0.8427825 ]\n",
      "  [0.84963155]\n",
      "  [0.856359  ]\n",
      "  [0.86307138]\n",
      "  [0.86955559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.82098642148776e-06\n",
      "Predicción post entrenamiento : [[0.8760725]]\n",
      "PERDIDAAAA despues: 3.541089427017141e-06\n",
      "loss en el callback: 0.00017124394071288407, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.8305015 ]\n",
      " [0.83676863]\n",
      " [0.8427825 ]\n",
      " [0.84963155]\n",
      " [0.856359  ]\n",
      " [0.86307138]\n",
      " [0.86955559]\n",
      " [0.87599957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8821554]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.8305015 ]\n",
      "  [0.83676863]\n",
      "  [0.8427825 ]\n",
      "  [0.84963155]\n",
      "  [0.856359  ]\n",
      "  [0.86307138]\n",
      "  [0.86955559]\n",
      "  [0.87599957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00110620295163244\n",
      "Predicción post entrenamiento : [[0.881468]]\n",
      "PERDIDAAAA despues: 0.0010609488235786557\n",
      "loss en el callback: 0.013081925921142101, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.83676863]\n",
      " [0.8427825 ]\n",
      " [0.84963155]\n",
      " [0.856359  ]\n",
      " [0.86307138]\n",
      " [0.86955559]\n",
      " [0.87599957]\n",
      " [0.88215542]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8876317]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.83676863]\n",
      "  [0.8427825 ]\n",
      "  [0.84963155]\n",
      "  [0.856359  ]\n",
      "  [0.86307138]\n",
      "  [0.86955559]\n",
      "  [0.87599957]\n",
      "  [0.88215542]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028578571509569883\n",
      "Predicción post entrenamiento : [[0.88785577]]\n",
      "PERDIDAAAA despues: 0.0028818626888096333\n",
      "loss en el callback: 0.0019965367391705513, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.8427825 ]\n",
      " [0.84963155]\n",
      " [0.856359  ]\n",
      " [0.86307138]\n",
      " [0.86955559]\n",
      " [0.87599957]\n",
      " [0.88215542]\n",
      " [0.88763171]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8940896]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.8427825 ]\n",
      "  [0.84963155]\n",
      "  [0.856359  ]\n",
      "  [0.86307138]\n",
      "  [0.86955559]\n",
      "  [0.87599957]\n",
      "  [0.88215542]\n",
      "  [0.88763171]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001520584337413311\n",
      "Predicción post entrenamiento : [[0.8944807]]\n",
      "PERDIDAAAA despues: 0.0015512409154325724\n",
      "loss en el callback: 0.006063831504434347, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.84963155]\n",
      " [0.856359  ]\n",
      " [0.86307138]\n",
      " [0.86955559]\n",
      " [0.87599957]\n",
      " [0.88215542]\n",
      " [0.88763171]\n",
      " [0.89408958]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9008658]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.84963155]\n",
      "  [0.856359  ]\n",
      "  [0.86307138]\n",
      "  [0.86955559]\n",
      "  [0.87599957]\n",
      "  [0.88215542]\n",
      "  [0.88763171]\n",
      "  [0.89408958]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000656569900456816\n",
      "Predicción post entrenamiento : [[0.9014783]]\n",
      "PERDIDAAAA despues: 0.0006883338210172951\n",
      "loss en el callback: 0.017461825162172318, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.856359  ]\n",
      " [0.86307138]\n",
      " [0.86955559]\n",
      " [0.87599957]\n",
      " [0.88215542]\n",
      " [0.88763171]\n",
      " [0.89408958]\n",
      " [0.90086579]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.90775406]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.856359  ]\n",
      "  [0.86307138]\n",
      "  [0.86955559]\n",
      "  [0.87599957]\n",
      "  [0.88215542]\n",
      "  [0.88763171]\n",
      "  [0.89408958]\n",
      "  [0.90086579]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002572709461674094\n",
      "Predicción post entrenamiento : [[0.90811455]]\n",
      "PERDIDAAAA despues: 0.0026094086933881044\n",
      "loss en el callback: 0.005404866766184568, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.86307138]\n",
      " [0.86955559]\n",
      " [0.87599957]\n",
      " [0.88215542]\n",
      " [0.88763171]\n",
      " [0.89408958]\n",
      " [0.90086579]\n",
      " [0.90775406]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.91429293]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.86307138]\n",
      "  [0.86955559]\n",
      "  [0.87599957]\n",
      "  [0.88215542]\n",
      "  [0.88763171]\n",
      "  [0.89408958]\n",
      "  [0.90086579]\n",
      "  [0.90775406]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004126108717173338\n",
      "Predicción post entrenamiento : [[0.91422284]]\n",
      "PERDIDAAAA despues: 0.004117108415812254\n",
      "loss en el callback: 0.00017048974405042827, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.86955559]\n",
      " [0.87599957]\n",
      " [0.88215542]\n",
      " [0.88763171]\n",
      " [0.89408958]\n",
      " [0.90086579]\n",
      " [0.90775406]\n",
      " [0.91429293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9202913]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.86955559]\n",
      "  [0.87599957]\n",
      "  [0.88215542]\n",
      "  [0.88763171]\n",
      "  [0.89408958]\n",
      "  [0.90086579]\n",
      "  [0.90775406]\n",
      "  [0.91429293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006020937114953995\n",
      "Predicción post entrenamiento : [[0.9199364]]\n",
      "PERDIDAAAA despues: 0.005965988617390394\n",
      "loss en el callback: 0.004018770065158606, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.87599957]\n",
      " [0.88215542]\n",
      " [0.88763171]\n",
      " [0.89408958]\n",
      " [0.90086579]\n",
      " [0.90775406]\n",
      " [0.91429293]\n",
      " [0.9202913 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9259547]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.87599957]\n",
      "  [0.88215542]\n",
      "  [0.88763171]\n",
      "  [0.89408958]\n",
      "  [0.90086579]\n",
      "  [0.90775406]\n",
      "  [0.91429293]\n",
      "  [0.9202913 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010612680576741695\n",
      "Predicción post entrenamiento : [[0.9264057]]\n",
      "PERDIDAAAA despues: 0.010705811902880669\n",
      "loss en el callback: 0.008911323733627796, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.88215542]\n",
      " [0.88763171]\n",
      " [0.89408958]\n",
      " [0.90086579]\n",
      " [0.90775406]\n",
      " [0.91429293]\n",
      " [0.9202913 ]\n",
      " [0.9259547 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9323852]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.88215542]\n",
      "  [0.88763171]\n",
      "  [0.89408958]\n",
      "  [0.90086579]\n",
      "  [0.90775406]\n",
      "  [0.91429293]\n",
      "  [0.9202913 ]\n",
      "  [0.9259547 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02492583356797695\n",
      "Predicción post entrenamiento : [[0.93155587]]\n",
      "PERDIDAAAA despues: 0.02466464973986149\n",
      "loss en el callback: 0.022000348195433617, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.88763171]\n",
      " [0.89408958]\n",
      " [0.90086579]\n",
      " [0.90775406]\n",
      " [0.91429293]\n",
      " [0.9202913 ]\n",
      " [0.9259547 ]\n",
      " [0.93238521]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.93758446]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.88763171]\n",
      "  [0.89408958]\n",
      "  [0.90086579]\n",
      "  [0.90775406]\n",
      "  [0.91429293]\n",
      "  [0.9202913 ]\n",
      "  [0.9259547 ]\n",
      "  [0.93238521]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02352920174598694\n",
      "Predicción post entrenamiento : [[0.93733835]]\n",
      "PERDIDAAAA despues: 0.023453760892152786\n",
      "loss en el callback: 0.002331965835765004, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.89408958]\n",
      " [0.90086579]\n",
      " [0.90775406]\n",
      " [0.91429293]\n",
      " [0.9202913 ]\n",
      " [0.9259547 ]\n",
      " [0.93238521]\n",
      " [0.93758446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.94363755]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.89408958]\n",
      "  [0.90086579]\n",
      "  [0.90775406]\n",
      "  [0.91429293]\n",
      "  [0.9202913 ]\n",
      "  [0.9259547 ]\n",
      "  [0.93238521]\n",
      "  [0.93758446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007038075476884842\n",
      "Predicción post entrenamiento : [[0.94295293]]\n",
      "PERDIDAAAA despues: 0.0069236746057868\n",
      "loss en el callback: 0.01445299293845892, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.90086579]\n",
      " [0.90775406]\n",
      " [0.91429293]\n",
      " [0.9202913 ]\n",
      " [0.9259547 ]\n",
      " [0.93238521]\n",
      " [0.93758446]\n",
      " [0.94363755]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9492243]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.90086579]\n",
      "  [0.90775406]\n",
      "  [0.91429293]\n",
      "  [0.9202913 ]\n",
      "  [0.9259547 ]\n",
      "  [0.93238521]\n",
      "  [0.93758446]\n",
      "  [0.94363755]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00900681596249342\n",
      "Predicción post entrenamiento : [[0.94914085]]\n",
      "PERDIDAAAA despues: 0.008990983478724957\n",
      "loss en el callback: 0.0002558522974140942, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.90775406]\n",
      " [0.91429293]\n",
      " [0.9202913 ]\n",
      " [0.9259547 ]\n",
      " [0.93238521]\n",
      " [0.93758446]\n",
      " [0.94363755]\n",
      " [0.94922429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9552486]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.90775406]\n",
      "  [0.91429293]\n",
      "  [0.9202913 ]\n",
      "  [0.9259547 ]\n",
      "  [0.93238521]\n",
      "  [0.93758446]\n",
      "  [0.94363755]\n",
      "  [0.94922429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014009959995746613\n",
      "Predicción post entrenamiento : [[0.95504856]]\n",
      "PERDIDAAAA despues: 0.013962646946310997\n",
      "loss en el callback: 0.0014990685740485787, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.91429293]\n",
      " [0.9202913 ]\n",
      " [0.9259547 ]\n",
      " [0.93238521]\n",
      " [0.93758446]\n",
      " [0.94363755]\n",
      " [0.94922429]\n",
      " [0.95524859]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9609065]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.91429293]\n",
      "  [0.9202913 ]\n",
      "  [0.9259547 ]\n",
      "  [0.93238521]\n",
      "  [0.93758446]\n",
      "  [0.94363755]\n",
      "  [0.94922429]\n",
      "  [0.95524859]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017159854993224144\n",
      "Predicción post entrenamiento : [[0.9593725]]\n",
      "PERDIDAAAA despues: 0.016760317608714104\n",
      "loss en el callback: 0.06682001799345016, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.9202913 ]\n",
      " [0.9259547 ]\n",
      " [0.93238521]\n",
      " [0.93758446]\n",
      " [0.94363755]\n",
      " [0.94922429]\n",
      " [0.95524859]\n",
      " [0.96090651]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9650367]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.9202913 ]\n",
      "  [0.9259547 ]\n",
      "  [0.93238521]\n",
      "  [0.93758446]\n",
      "  [0.94363755]\n",
      "  [0.94922429]\n",
      "  [0.95524859]\n",
      "  [0.96090651]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006050304509699345\n",
      "Predicción post entrenamiento : [[0.96515566]]\n",
      "PERDIDAAAA despues: 0.006068826653063297\n",
      "loss en el callback: 0.0006342866690829396, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.9259547 ]\n",
      " [0.93238521]\n",
      " [0.93758446]\n",
      " [0.94363755]\n",
      " [0.94922429]\n",
      " [0.95524859]\n",
      " [0.96090651]\n",
      " [0.96503669]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9707584]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.9259547 ]\n",
      "  [0.93238521]\n",
      "  [0.93758446]\n",
      "  [0.94363755]\n",
      "  [0.94922429]\n",
      "  [0.95524859]\n",
      "  [0.96090651]\n",
      "  [0.96503669]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01232412364333868\n",
      "Predicción post entrenamiento : [[0.9695822]]\n",
      "PERDIDAAAA despues: 0.012064361944794655\n",
      "loss en el callback: 0.04120292887091637, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.93238521]\n",
      " [0.93758446]\n",
      " [0.94363755]\n",
      " [0.94922429]\n",
      " [0.95524859]\n",
      " [0.96090651]\n",
      " [0.96503669]\n",
      " [0.97075838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9752034]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.93238521]\n",
      "  [0.93758446]\n",
      "  [0.94363755]\n",
      "  [0.94922429]\n",
      "  [0.95524859]\n",
      "  [0.96090651]\n",
      "  [0.96503669]\n",
      "  [0.97075838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018389081582427025\n",
      "Predicción post entrenamiento : [[0.9735668]]\n",
      "PERDIDAAAA despues: 0.017947886139154434\n",
      "loss en el callback: 0.0706465020775795, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.93758446]\n",
      " [0.94363755]\n",
      " [0.94922429]\n",
      " [0.95524859]\n",
      " [0.96090651]\n",
      " [0.96503669]\n",
      " [0.97075838]\n",
      " [0.97520339]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9789359]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.93758446]\n",
      "  [0.94363755]\n",
      "  [0.94922429]\n",
      "  [0.95524859]\n",
      "  [0.96090651]\n",
      "  [0.96503669]\n",
      "  [0.97075838]\n",
      "  [0.97520339]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03807617723941803\n",
      "Predicción post entrenamiento : [[0.97784775]]\n",
      "PERDIDAAAA despues: 0.03765270113945007\n",
      "loss en el callback: 0.04267597943544388, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.94363755]\n",
      " [0.94922429]\n",
      " [0.95524859]\n",
      " [0.96090651]\n",
      " [0.96503669]\n",
      " [0.97075838]\n",
      " [0.97520339]\n",
      " [0.9789359 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.98329437]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.94363755]\n",
      "  [0.94922429]\n",
      "  [0.95524859]\n",
      "  [0.96090651]\n",
      "  [0.96503669]\n",
      "  [0.97075838]\n",
      "  [0.97520339]\n",
      "  [0.9789359 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027227269485592842\n",
      "Predicción post entrenamiento : [[0.9832898]]\n",
      "PERDIDAAAA despues: 0.027225755155086517\n",
      "loss en el callback: 1.0609574019326828e-06, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.94922429]\n",
      " [0.95524859]\n",
      " [0.96090651]\n",
      " [0.96503669]\n",
      " [0.97075838]\n",
      " [0.97520339]\n",
      " [0.9789359 ]\n",
      " [0.98329437]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.98851]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.94922429]\n",
      "  [0.95524859]\n",
      "  [0.96090651]\n",
      "  [0.96503669]\n",
      "  [0.97075838]\n",
      "  [0.97520339]\n",
      "  [0.9789359 ]\n",
      "  [0.98329437]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038944587111473083\n",
      "Predicción post entrenamiento : [[0.98798406]]\n",
      "PERDIDAAAA despues: 0.03873727470636368\n",
      "loss en el callback: 0.011759010143578053, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.95524859]\n",
      " [0.96090651]\n",
      " [0.96503669]\n",
      " [0.97075838]\n",
      " [0.97520339]\n",
      " [0.9789359 ]\n",
      " [0.98329437]\n",
      " [0.98851001]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.99305475]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.95524859]\n",
      "  [0.96090651]\n",
      "  [0.96503669]\n",
      "  [0.97075838]\n",
      "  [0.97520339]\n",
      "  [0.9789359 ]\n",
      "  [0.98329437]\n",
      "  [0.98851001]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054054759442806244\n",
      "Predicción post entrenamiento : [[0.99277997]]\n",
      "PERDIDAAAA despues: 0.053927067667245865\n",
      "loss en el callback: 0.003611374646425247, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.96090651]\n",
      " [0.96503669]\n",
      " [0.97075838]\n",
      " [0.97520339]\n",
      " [0.9789359 ]\n",
      " [0.98329437]\n",
      " [0.98851001]\n",
      " [0.99305475]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9975038]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.96090651]\n",
      "  [0.96503669]\n",
      "  [0.97075838]\n",
      "  [0.97520339]\n",
      "  [0.9789359 ]\n",
      "  [0.98329437]\n",
      "  [0.98851001]\n",
      "  [0.99305475]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04241545870900154\n",
      "Predicción post entrenamiento : [[0.996188]]\n",
      "PERDIDAAAA despues: 0.0418751984834671\n",
      "loss en el callback: 0.05823848396539688, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.96503669]\n",
      " [0.97075838]\n",
      " [0.97520339]\n",
      " [0.9789359 ]\n",
      " [0.98329437]\n",
      " [0.98851001]\n",
      " [0.99305475]\n",
      " [0.99750382]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[1.000609]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.96503669]\n",
      "  [0.97075838]\n",
      "  [0.97520339]\n",
      "  [0.9789359 ]\n",
      "  [0.98329437]\n",
      "  [0.98851001]\n",
      "  [0.99305475]\n",
      "  [0.99750382]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053784456104040146\n",
      "Predicción post entrenamiento : [[0.99902993]]\n",
      "PERDIDAAAA despues: 0.05305451154708862\n",
      "loss en el callback: 0.08076507598161697, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.97075838]\n",
      " [0.97520339]\n",
      " [0.9789359 ]\n",
      " [0.98329437]\n",
      " [0.98851001]\n",
      " [0.99305475]\n",
      " [0.99750382]\n",
      " [1.00060904]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[1.0035821]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.97075838]\n",
      "  [0.97520339]\n",
      "  [0.9789359 ]\n",
      "  [0.98329437]\n",
      "  [0.98851001]\n",
      "  [0.99305475]\n",
      "  [0.99750382]\n",
      "  [1.00060904]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05517229810357094\n",
      "Predicción post entrenamiento : [[1.0034729]]\n",
      "PERDIDAAAA despues: 0.05512101203203201\n",
      "loss en el callback: 0.0006307758740149438, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.97520339]\n",
      " [0.9789359 ]\n",
      " [0.98329437]\n",
      " [0.98851001]\n",
      " [0.99305475]\n",
      " [0.99750382]\n",
      " [1.00060904]\n",
      " [1.00358212]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[1.0076369]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.97520339]\n",
      "  [0.9789359 ]\n",
      "  [0.98329437]\n",
      "  [0.98851001]\n",
      "  [0.99305475]\n",
      "  [0.99750382]\n",
      "  [1.00060904]\n",
      "  [1.00358212]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04356477037072182\n",
      "Predicción post entrenamiento : [[1.0045666]]\n",
      "PERDIDAAAA despues: 0.04229249805212021\n",
      "loss en el callback: 0.24118326604366302, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.9789359 ]\n",
      " [0.98329437]\n",
      " [0.98851001]\n",
      " [0.99305475]\n",
      " [0.99750382]\n",
      " [1.00060904]\n",
      " [1.00358212]\n",
      " [1.0076369 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[1.0086707]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.9789359 ]\n",
      "  [0.98329437]\n",
      "  [0.98851001]\n",
      "  [0.99305475]\n",
      "  [0.99750382]\n",
      "  [1.00060904]\n",
      "  [1.00358212]\n",
      "  [1.0076369 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04781516641378403\n",
      "Predicción post entrenamiento : [[1.0078033]]\n",
      "PERDIDAAAA despues: 0.04743659123778343\n",
      "loss en el callback: 0.03165653720498085, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.98329437]\n",
      " [0.98851001]\n",
      " [0.99305475]\n",
      " [0.99750382]\n",
      " [1.00060904]\n",
      " [1.00358212]\n",
      " [1.0076369 ]\n",
      " [1.00867069]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[1.012034]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.98329437]\n",
      "  [0.98851001]\n",
      "  [0.99305475]\n",
      "  [0.99750382]\n",
      "  [1.00060904]\n",
      "  [1.00358212]\n",
      "  [1.0076369 ]\n",
      "  [1.00867069]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06343527138233185\n",
      "Predicción post entrenamiento : [[1.0100901]]\n",
      "PERDIDAAAA despues: 0.062459833920001984\n",
      "loss en el callback: 0.12562930583953857, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.98851001]\n",
      " [0.99305475]\n",
      " [0.99750382]\n",
      " [1.00060904]\n",
      " [1.00358212]\n",
      " [1.0076369 ]\n",
      " [1.00867069]\n",
      " [1.01203406]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[1.0142086]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.98851001]\n",
      "  [0.99305475]\n",
      "  [0.99750382]\n",
      "  [1.00060904]\n",
      "  [1.00358212]\n",
      "  [1.0076369 ]\n",
      "  [1.00867069]\n",
      "  [1.01203406]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10811948776245117\n",
      "Predicción post entrenamiento : [[1.0121801]]\n",
      "PERDIDAAAA despues: 0.10678962618112564\n",
      "loss en el callback: 0.1417400985956192, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.99305475]\n",
      " [0.99750382]\n",
      " [1.00060904]\n",
      " [1.00358212]\n",
      " [1.0076369 ]\n",
      " [1.00867069]\n",
      " [1.01203406]\n",
      " [1.01420856]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[1.0158263]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.99305475]\n",
      "  [0.99750382]\n",
      "  [1.00060904]\n",
      "  [1.00358212]\n",
      "  [1.0076369 ]\n",
      "  [1.00867069]\n",
      "  [1.01203406]\n",
      "  [1.01420856]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1686207503080368\n",
      "Predicción post entrenamiento : [[1.0130365]]\n",
      "PERDIDAAAA despues: 0.16633731126785278\n",
      "loss en el callback: 0.2632785439491272, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.99750382]\n",
      " [1.00060904]\n",
      " [1.00358212]\n",
      " [1.0076369 ]\n",
      " [1.00867069]\n",
      " [1.01203406]\n",
      " [1.01420856]\n",
      " [1.01582634]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[1.0162932]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.99750382]\n",
      "  [1.00060904]\n",
      "  [1.00358212]\n",
      "  [1.0076369 ]\n",
      "  [1.00867069]\n",
      "  [1.01203406]\n",
      "  [1.01420856]\n",
      "  [1.01582634]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12350627034902573\n",
      "Predicción post entrenamiento : [[1.0153452]]\n",
      "PERDIDAAAA despues: 0.12284088134765625\n",
      "loss en el callback: 0.044269610196352005, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[1.00060904]\n",
      " [1.00358212]\n",
      " [1.0076369 ]\n",
      " [1.00867069]\n",
      " [1.01203406]\n",
      " [1.01420856]\n",
      " [1.01582634]\n",
      " [1.01629317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[1.0181257]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[1.00060904]\n",
      "  [1.00358212]\n",
      "  [1.0076369 ]\n",
      "  [1.00867069]\n",
      "  [1.01203406]\n",
      "  [1.01420856]\n",
      "  [1.01582634]\n",
      "  [1.01629317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09626156091690063\n",
      "Predicción post entrenamiento : [[1.0166715]]\n",
      "PERDIDAAAA despues: 0.0953613668680191\n",
      "loss en el callback: 0.08284346759319305, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[1.00358212]\n",
      " [1.0076369 ]\n",
      " [1.00867069]\n",
      " [1.01203406]\n",
      " [1.01420856]\n",
      " [1.01582634]\n",
      " [1.01629317]\n",
      " [1.01812565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[1.0192853]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[1.00358212]\n",
      "  [1.0076369 ]\n",
      "  [1.00867069]\n",
      "  [1.01203406]\n",
      "  [1.01420856]\n",
      "  [1.01582634]\n",
      "  [1.01629317]\n",
      "  [1.01812565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12561830878257751\n",
      "Predicción post entrenamiento : [[1.018223]]\n",
      "PERDIDAAAA despues: 0.12486644834280014\n",
      "loss en el callback: 0.05598409101366997, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[1.0076369 ]\n",
      " [1.00867069]\n",
      " [1.01203406]\n",
      " [1.01420856]\n",
      " [1.01582634]\n",
      " [1.01629317]\n",
      " [1.01812565]\n",
      " [1.01928532]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[1.0206357]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[1.0076369 ]\n",
      "  [1.00867069]\n",
      "  [1.01203406]\n",
      "  [1.01420856]\n",
      "  [1.01582634]\n",
      "  [1.01629317]\n",
      "  [1.01812565]\n",
      "  [1.01928532]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09565632045269012\n",
      "Predicción post entrenamiento : [[1.0183154]]\n",
      "PERDIDAAAA despues: 0.09422644972801208\n",
      "loss en el callback: 0.1815483719110489, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[1.00867069]\n",
      " [1.01203406]\n",
      " [1.01420856]\n",
      " [1.01582634]\n",
      " [1.01629317]\n",
      " [1.01812565]\n",
      " [1.01928532]\n",
      " [1.02063572]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[1.0200981]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[1.00867069]\n",
      "  [1.01203406]\n",
      "  [1.01420856]\n",
      "  [1.01582634]\n",
      "  [1.01629317]\n",
      "  [1.01812565]\n",
      "  [1.01928532]\n",
      "  [1.02063572]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11754009127616882\n",
      "Predicción post entrenamiento : [[1.0177671]]\n",
      "PERDIDAAAA despues: 0.1159471869468689\n",
      "loss en el callback: 0.1954672634601593, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[1.01203406]\n",
      " [1.01420856]\n",
      " [1.01582634]\n",
      " [1.01629317]\n",
      " [1.01812565]\n",
      " [1.01928532]\n",
      " [1.02063572]\n",
      " [1.02009809]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[1.0197544]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[1.01203406]\n",
      "  [1.01420856]\n",
      "  [1.01582634]\n",
      "  [1.01629317]\n",
      "  [1.01812565]\n",
      "  [1.01928532]\n",
      "  [1.02063572]\n",
      "  [1.02009809]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06638181209564209\n",
      "Predicción post entrenamiento : [[1.0200248]]\n",
      "PERDIDAAAA despues: 0.06652120500802994\n",
      "loss en el callback: 0.005873288959264755, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[1.01420856]\n",
      " [1.01582634]\n",
      " [1.01629317]\n",
      " [1.01812565]\n",
      " [1.01928532]\n",
      " [1.02063572]\n",
      " [1.02009809]\n",
      " [1.01975441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[1.0214434]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[1.01420856]\n",
      "  [1.01582634]\n",
      "  [1.01629317]\n",
      "  [1.01812565]\n",
      "  [1.01928532]\n",
      "  [1.02063572]\n",
      "  [1.02009809]\n",
      "  [1.01975441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04596385732293129\n",
      "Predicción post entrenamiento : [[1.0205731]]\n",
      "PERDIDAAAA despues: 0.04559147357940674\n",
      "loss en el callback: 0.0331135131418705, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[1.01582634]\n",
      " [1.01629317]\n",
      " [1.01812565]\n",
      " [1.01928532]\n",
      " [1.02063572]\n",
      " [1.02009809]\n",
      " [1.01975441]\n",
      " [1.02144337]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[1.0216774]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[1.01582634]\n",
      "  [1.01629317]\n",
      "  [1.01812565]\n",
      "  [1.01928532]\n",
      "  [1.02063572]\n",
      "  [1.02009809]\n",
      "  [1.01975441]\n",
      "  [1.02144337]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042637892067432404\n",
      "Predicción post entrenamiento : [[1.0209925]]\n",
      "PERDIDAAAA despues: 0.042355526238679886\n",
      "loss en el callback: 0.020917685702443123, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[1.01629317]\n",
      " [1.01812565]\n",
      " [1.01928532]\n",
      " [1.02063572]\n",
      " [1.02009809]\n",
      " [1.01975441]\n",
      " [1.02144337]\n",
      " [1.02167737]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[1.021884]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[1.01629317]\n",
      "  [1.01812565]\n",
      "  [1.01928532]\n",
      "  [1.02063572]\n",
      "  [1.02009809]\n",
      "  [1.01975441]\n",
      "  [1.02144337]\n",
      "  [1.02167737]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01337401196360588\n",
      "Predicción post entrenamiento : [[1.0215523]]\n",
      "PERDIDAAAA despues: 0.013297416269779205\n",
      "loss en el callback: 0.005437113810330629, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[1.01812565]\n",
      " [1.01928532]\n",
      " [1.02063572]\n",
      " [1.02009809]\n",
      " [1.01975441]\n",
      " [1.02144337]\n",
      " [1.02167737]\n",
      " [1.02188396]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[1.022545]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[1.01812565]\n",
      "  [1.01928532]\n",
      "  [1.02063572]\n",
      "  [1.02009809]\n",
      "  [1.01975441]\n",
      "  [1.02144337]\n",
      "  [1.02167737]\n",
      "  [1.02188396]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003948796074837446\n",
      "Predicción post entrenamiento : [[1.0223212]]\n",
      "PERDIDAAAA despues: 0.003920725081115961\n",
      "loss en el callback: 0.002182298805564642, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[1.01928532]\n",
      " [1.02063572]\n",
      " [1.02009809]\n",
      " [1.01975441]\n",
      " [1.02144337]\n",
      " [1.02167737]\n",
      " [1.02188396]\n",
      " [1.02254498]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[1.0229657]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[1.01928532]\n",
      "  [1.02063572]\n",
      "  [1.02009809]\n",
      "  [1.01975441]\n",
      "  [1.02144337]\n",
      "  [1.02167737]\n",
      "  [1.02188396]\n",
      "  [1.02254498]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003435225458815694\n",
      "Predicción post entrenamiento : [[1.0217568]]\n",
      "PERDIDAAAA despues: 0.003294977592304349\n",
      "loss en el callback: 0.0521993450820446, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[1.02063572]\n",
      " [1.02009809]\n",
      " [1.01975441]\n",
      " [1.02144337]\n",
      " [1.02167737]\n",
      " [1.02188396]\n",
      " [1.02254498]\n",
      " [1.02296567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[1.0222025]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[1.02063572]\n",
      "  [1.02009809]\n",
      "  [1.01975441]\n",
      "  [1.02144337]\n",
      "  [1.02167737]\n",
      "  [1.02188396]\n",
      "  [1.02254498]\n",
      "  [1.02296567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018002819269895554\n",
      "Predicción post entrenamiento : [[1.022555]]\n",
      "PERDIDAAAA despues: 0.018097536638379097\n",
      "loss en el callback: 0.008683745749294758, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[1.02009809]\n",
      " [1.01975441]\n",
      " [1.02144337]\n",
      " [1.02167737]\n",
      " [1.02188396]\n",
      " [1.02254498]\n",
      " [1.02296567]\n",
      " [1.02220249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[1.0227026]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[1.02009809]\n",
      "  [1.01975441]\n",
      "  [1.02144337]\n",
      "  [1.02167737]\n",
      "  [1.02188396]\n",
      "  [1.02254498]\n",
      "  [1.02296567]\n",
      "  [1.02220249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016906585544347763\n",
      "Predicción post entrenamiento : [[1.0221692]]\n",
      "PERDIDAAAA despues: 0.01676817424595356\n",
      "loss en el callback: 0.013767954893410206, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[1.01975441]\n",
      " [1.02144337]\n",
      " [1.02167737]\n",
      " [1.02188396]\n",
      " [1.02254498]\n",
      " [1.02296567]\n",
      " [1.02220249]\n",
      " [1.02270257]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[1.0225823]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[1.01975441]\n",
      "  [1.02144337]\n",
      "  [1.02167737]\n",
      "  [1.02188396]\n",
      "  [1.02254498]\n",
      "  [1.02296567]\n",
      "  [1.02220249]\n",
      "  [1.02270257]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021709110587835312\n",
      "Predicción post entrenamiento : [[1.0227635]]\n",
      "PERDIDAAAA despues: 0.021762538701295853\n",
      "loss en el callback: 0.0019237430533394217, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[1.02144337]\n",
      " [1.02167737]\n",
      " [1.02188396]\n",
      " [1.02254498]\n",
      " [1.02296567]\n",
      " [1.02220249]\n",
      " [1.02270257]\n",
      " [1.02258229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[1.0234098]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[1.02144337]\n",
      "  [1.02167737]\n",
      "  [1.02188396]\n",
      "  [1.02254498]\n",
      "  [1.02296567]\n",
      "  [1.02220249]\n",
      "  [1.02270257]\n",
      "  [1.02258229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029782766476273537\n",
      "Predicción post entrenamiento : [[1.0214353]]\n",
      "PERDIDAAAA despues: 0.029105132445693016\n",
      "loss en el callback: 0.1357940435409546, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[1.02167737]\n",
      " [1.02188396]\n",
      " [1.02254498]\n",
      " [1.02296567]\n",
      " [1.02220249]\n",
      " [1.02270257]\n",
      " [1.02258229]\n",
      " [1.02340984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[1.0216777]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[1.02167737]\n",
      "  [1.02188396]\n",
      "  [1.02254498]\n",
      "  [1.02296567]\n",
      "  [1.02220249]\n",
      "  [1.02270257]\n",
      "  [1.02258229]\n",
      "  [1.02340984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02985360100865364\n",
      "Predicción post entrenamiento : [[1.0216857]]\n",
      "PERDIDAAAA despues: 0.029856359586119652\n",
      "loss en el callback: 3.7956290270813042e-06, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[1.02188396]\n",
      " [1.02254498]\n",
      " [1.02296567]\n",
      " [1.02220249]\n",
      " [1.02270257]\n",
      " [1.02258229]\n",
      " [1.02340984]\n",
      " [1.02167773]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[1.0219121]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[1.02188396]\n",
      "  [1.02254498]\n",
      "  [1.02296567]\n",
      "  [1.02220249]\n",
      "  [1.02270257]\n",
      "  [1.02258229]\n",
      "  [1.02340984]\n",
      "  [1.02167773]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003539587836712599\n",
      "Predicción post entrenamiento : [[1.0219146]]\n",
      "PERDIDAAAA despues: 0.0035398858599364758\n",
      "loss en el callback: 4.2248524323440506e-07, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[1.02254498]\n",
      " [1.02296567]\n",
      " [1.02220249]\n",
      " [1.02270257]\n",
      " [1.02258229]\n",
      " [1.02340984]\n",
      " [1.02167773]\n",
      " [1.0219121 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[1.0221152]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[1.02254498]\n",
      "  [1.02296567]\n",
      "  [1.02220249]\n",
      "  [1.02270257]\n",
      "  [1.02258229]\n",
      "  [1.02340984]\n",
      "  [1.02167773]\n",
      "  [1.0219121 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002945591928437352\n",
      "Predicción post entrenamiento : [[1.0217266]]\n",
      "PERDIDAAAA despues: 0.0029035592451691628\n",
      "loss en el callback: 0.0062989662401378155, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[1.02296567]\n",
      " [1.02220249]\n",
      " [1.02270257]\n",
      " [1.02258229]\n",
      " [1.02340984]\n",
      " [1.02167773]\n",
      " [1.0219121 ]\n",
      " [1.02211523]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[1.0217365]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[1.02296567]\n",
      "  [1.02220249]\n",
      "  [1.02270257]\n",
      "  [1.02258229]\n",
      "  [1.02340984]\n",
      "  [1.02167773]\n",
      "  [1.0219121 ]\n",
      "  [1.02211523]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006563563831150532\n",
      "Predicción post entrenamiento : [[1.0219257]]\n",
      "PERDIDAAAA despues: 0.006594253703951836\n",
      "loss en el callback: 0.001988751580938697, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[1.02220249]\n",
      " [1.02270257]\n",
      " [1.02258229]\n",
      " [1.02340984]\n",
      " [1.02167773]\n",
      " [1.0219121 ]\n",
      " [1.02211523]\n",
      " [1.0217365 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[1.0217835]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[1.02220249]\n",
      "  [1.02270257]\n",
      "  [1.02258229]\n",
      "  [1.02340984]\n",
      "  [1.02167773]\n",
      "  [1.0219121 ]\n",
      "  [1.02211523]\n",
      "  [1.0217365 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024297216441482306\n",
      "Predicción post entrenamiento : [[1.0202867]]\n",
      "PERDIDAAAA despues: 0.0022844017948955297\n",
      "loss en el callback: 0.07563725113868713, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[1.02270257]\n",
      " [1.02258229]\n",
      " [1.02340984]\n",
      " [1.02167773]\n",
      " [1.0219121 ]\n",
      " [1.02211523]\n",
      " [1.0217365 ]\n",
      " [1.02178347]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[1.0203474]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[1.02270257]\n",
      "  [1.02258229]\n",
      "  [1.02340984]\n",
      "  [1.02167773]\n",
      "  [1.0219121 ]\n",
      "  [1.02211523]\n",
      "  [1.0217365 ]\n",
      "  [1.02178347]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005497579695656896\n",
      "Predicción post entrenamiento : [[1.018598]]\n",
      "PERDIDAAAA despues: 0.0004707824264187366\n",
      "loss en el callback: 0.10113731771707535, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[1.02258229]\n",
      " [1.02340984]\n",
      " [1.02167773]\n",
      " [1.0219121 ]\n",
      " [1.02211523]\n",
      " [1.0217365 ]\n",
      " [1.02178347]\n",
      " [1.02034736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[1.018471]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[1.02258229]\n",
      "  [1.02340984]\n",
      "  [1.02167773]\n",
      "  [1.0219121 ]\n",
      "  [1.02211523]\n",
      "  [1.0217365 ]\n",
      "  [1.02178347]\n",
      "  [1.02034736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004527849145233631\n",
      "Predicción post entrenamiento : [[1.0183672]]\n",
      "PERDIDAAAA despues: 0.004513886291533709\n",
      "loss en el callback: 0.0005613085813820362, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[1.02340984]\n",
      " [1.02167773]\n",
      " [1.0219121 ]\n",
      " [1.02211523]\n",
      " [1.0217365 ]\n",
      " [1.02178347]\n",
      " [1.02034736]\n",
      " [1.018471  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[1.0182009]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[1.02340984]\n",
      "  [1.02167773]\n",
      "  [1.0219121 ]\n",
      "  [1.02211523]\n",
      "  [1.0217365 ]\n",
      "  [1.02178347]\n",
      "  [1.02034736]\n",
      "  [1.018471  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014987652190029621\n",
      "Predicción post entrenamiento : [[1.0176811]]\n",
      "PERDIDAAAA despues: 0.014860661700367928\n",
      "loss en el callback: 0.01276511512696743, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[1.02167773]\n",
      " [1.0219121 ]\n",
      " [1.02211523]\n",
      " [1.0217365 ]\n",
      " [1.02178347]\n",
      " [1.02034736]\n",
      " [1.018471  ]\n",
      " [1.01820087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[1.0171437]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[1.02167773]\n",
      "  [1.0219121 ]\n",
      "  [1.02211523]\n",
      "  [1.0217365 ]\n",
      "  [1.02178347]\n",
      "  [1.02034736]\n",
      "  [1.018471  ]\n",
      "  [1.01820087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018415149301290512\n",
      "Predicción post entrenamiento : [[1.0165704]]\n",
      "PERDIDAAAA despues: 0.018259888514876366\n",
      "loss en el callback: 0.017154842615127563, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[1.0219121 ]\n",
      " [1.02211523]\n",
      " [1.0217365 ]\n",
      " [1.02178347]\n",
      " [1.02034736]\n",
      " [1.018471  ]\n",
      " [1.01820087]\n",
      " [1.01714373]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[1.0164088]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[1.0219121 ]\n",
      "  [1.02211523]\n",
      "  [1.0217365 ]\n",
      "  [1.02178347]\n",
      "  [1.02034736]\n",
      "  [1.018471  ]\n",
      "  [1.01820087]\n",
      "  [1.01714373]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009864934720098972\n",
      "Predicción post entrenamiento : [[1.0161388]]\n",
      "PERDIDAAAA despues: 0.009811371564865112\n",
      "loss en el callback: 0.0039352490566670895, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[1.02211523]\n",
      " [1.0217365 ]\n",
      " [1.02178347]\n",
      " [1.02034736]\n",
      " [1.018471  ]\n",
      " [1.01820087]\n",
      " [1.01714373]\n",
      " [1.0164088 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[1.0157506]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[1.02211523]\n",
      "  [1.0217365 ]\n",
      "  [1.02178347]\n",
      "  [1.02034736]\n",
      "  [1.018471  ]\n",
      "  [1.01820087]\n",
      "  [1.01714373]\n",
      "  [1.0164088 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009206804446876049\n",
      "Predicción post entrenamiento : [[1.0153623]]\n",
      "PERDIDAAAA despues: 0.009132422506809235\n",
      "loss en el callback: 0.008328869007527828, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[1.0217365 ]\n",
      " [1.02178347]\n",
      " [1.02034736]\n",
      " [1.018471  ]\n",
      " [1.01820087]\n",
      " [1.01714373]\n",
      " [1.0164088 ]\n",
      " [1.01575065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[1.014698]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[1.0217365 ]\n",
      "  [1.02178347]\n",
      "  [1.02034736]\n",
      "  [1.018471  ]\n",
      "  [1.01820087]\n",
      "  [1.01714373]\n",
      "  [1.0164088 ]\n",
      "  [1.01575065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002814857056364417\n",
      "Predicción post entrenamiento : [[1.0148168]]\n",
      "PERDIDAAAA despues: 0.0028274699579924345\n",
      "loss en el callback: 0.0008116906974464655, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[1.02178347]\n",
      " [1.02034736]\n",
      " [1.018471  ]\n",
      " [1.01820087]\n",
      " [1.01714373]\n",
      " [1.0164088 ]\n",
      " [1.01575065]\n",
      " [1.01469803]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[1.0140084]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[1.02178347]\n",
      "  [1.02034736]\n",
      "  [1.018471  ]\n",
      "  [1.01820087]\n",
      "  [1.01714373]\n",
      "  [1.0164088 ]\n",
      "  [1.01575065]\n",
      "  [1.01469803]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020957214292138815\n",
      "Predicción post entrenamiento : [[1.0140132]]\n",
      "PERDIDAAAA despues: 0.0020961579866707325\n",
      "loss en el callback: 1.354385517515766e-06, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[1.02034736]\n",
      " [1.018471  ]\n",
      " [1.01820087]\n",
      " [1.01714373]\n",
      " [1.0164088 ]\n",
      " [1.01575065]\n",
      " [1.01469803]\n",
      " [1.0140084 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[1.0129012]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[1.02034736]\n",
      "  [1.018471  ]\n",
      "  [1.01820087]\n",
      "  [1.01714373]\n",
      "  [1.0164088 ]\n",
      "  [1.01575065]\n",
      "  [1.01469803]\n",
      "  [1.0140084 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003039632923901081\n",
      "Predicción post entrenamiento : [[1.0125675]]\n",
      "PERDIDAAAA despues: 0.003002952318638563\n",
      "loss en el callback: 0.005521897226572037, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14823214502064805,\n",
       " 0.1504211408895835,\n",
       " 0.1579250476575338,\n",
       " 0.1609557005876583,\n",
       " 0.1610823284985139,\n",
       " 0.16299048064544958,\n",
       " 0.1695298578964886,\n",
       " 0.17294564969966225,\n",
       " 0.16820712216253353,\n",
       " 0.17428614897573416]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.modelos.LSTM.entrenamientos as entrena_lstm\n",
    "entrena_lstm.entrena(red,c_entrenamiento_n,y_entrenamiento_n,8)\n",
    "\n",
    "# red.save('redes/DWT_LSTM/auto_predictiva/LSTM_prueba')\n",
    "# red = load_model('redes/DWT_LSTM/auto_predictiva/LSTM_ap_SGD_lr0.01_e10_bs1_df05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.src.layers.rnn.lstm.LSTM object at 0x000002112F202B50>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112EEB8050>, <keras.src.layers.rnn.lstm.LSTM object at 0x000002112F2B7FD0>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112F201310>, <keras.src.layers.rnn.lstm.LSTM object at 0x000002112E10A990>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112F2ECB50>, <keras.src.layers.rnn.lstm.LSTM object at 0x000002112F291710>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112F292210>, <keras.src.layers.core.dense.Dense object at 0x000002112F21D8D0>]\n"
     ]
    }
   ],
   "source": [
    "# print(loss_m)\n",
    "# plt.plot(range(len(loss_m)),loss_m)\n",
    "# plt.show()\n",
    "# losses = history.history['loss']\n",
    "# print(losses)\n",
    "# plt.plot(range(len(losses)),losses)\n",
    "# plt.show()\n",
    "print(red.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC3QklEQVR4nOzdd1iV9f/H8edhbxQHDhBwz1Bx5N6i5t5abrNlZbb0m9nepTZM0zK10sytufceONBUHIBbQREEZXPO/fuD333LkSGHdRjvx3VxBfe57/u8DxjnxWfqFEVREEIIIYQoJizMXYAQQgghRF6ScCOEEEKIYkXCjRBCCCGKFQk3QgghhChWJNwIIYQQoliRcCOEEEKIYkXCjRBCCCGKFQk3QgghhChWJNwIIYQQoliRcCOEyFe7d+9Gp9OxYsUKszz/woUL0el0XLlyxSzPby6jR4/G29vb6JhOp+PDDz/Ms+do37497du3z7P7CZFXJNwIkYGQkBBeeOEFqlatip2dHS4uLrRq1Yrvv/+e+Ph4o3OTk5P54YcfaNq0Kc7Ozjg5OdG0aVN++OEHkpOT093b29sbnU5H586dM3zu+fPno9Pp0Ol0HDt2TDv+4YcfotPpiIiIeGL9//33HwMHDsTLyws7OzsqV65Mly5d+PHHH43O+/zzz1mzZk02viPmceXKFe17odPpsLS0pEqVKvTr14/AwEBzl5epolp3Rs6dO8eHH35Y4sKhKNqszF2AEIXNhg0bGDRoELa2towcOZL69euTlJTE/v37efvttzl79izz5s0DIDY2lmeeeYY9e/bQs2dPRo8ejYWFBZs3b+b1119n1apVbNiwAUdHR6PnsLOzY9euXYSFhVGhQgWjx/766y/s7OxISEjIUf0HDx6kQ4cOVKlSheeff54KFSpw/fp1Dh8+zPfff8+rr76qnfv5558zcOBA+vbtm6PnKijDhg2jR48e6PV6goKCmDNnDps2beLw4cM0bNgwy2tHjBjB0KFDsbW1LZhi08hN3fkhPj4eKyvTfu2fO3eOjz76iPbt26drCdq6dWseVidE3pFwI0Qaly9fZujQoXh5ebFz504qVqyoPfbKK68QHBzMhg0btGOTJ09mz549/Pjjj0ycOFE7/tJLLzF79mwmTpzIW2+9xZw5c4yep1WrVgQEBLBs2TJef/117fiNGzfYt28f/fr1Y+XKlTl6DZ999hmurq4EBARQqlQpo8fu3LmTo3uaW+PGjXnuuee0r1u1akXv3r2ZM2cOv/zyS4bXxMbG4ujoiKWlJZaWlgVVqpHc1J0f7Ozs8vR+NjY2eXo/IfKKdEsJkcbXX3/Nw4cP+e2334yCjap69epaGLlx4wa//fYbHTt2NAo2qldeeYUOHTrw66+/cuPGDaPH7Ozs6N+/P0uWLDE6vnTpUkqXLo2/v3+OX0NISAj16tVLF2wAypcvr32u0+mIjY1l0aJFWvfJ6NGjtcdPnjxJ9+7dcXFxwcnJiU6dOnH48OF097x//z5vvPEG3t7e2Nra4uHhwciRI7PsPktMTKRnz564urpy8OBBk19jx44dgdQwCo/G1ezZs4eXX36Z8uXL4+HhYfTY490qmzZtol27djg7O+Pi4kLTpk3T/TyOHDlCt27dcHV1xcHBgXbt2nHgwAGT681J3WqNbdq0wdHREWdnZ5555hnOnj2b7r5r1qyhfv362NnZUb9+fVavXp3h82c05ubmzZuMGzeOSpUqYWtri4+PDy+99BJJSUksXLiQQYMGAdChQwft38nu3buBjMfc3Llzh3HjxuHu7o6dnR2+vr4sWrTI6By12+7bb79l3rx5VKtWDVtbW5o2bUpAQEC2v59CZEZaboRIY/369VStWpWWLVs+8dxNmzah1+sZOXJkpueMHDmSXbt2sXnzZsaPH2/02PDhw+natSshISFUq1YNgCVLljBw4ECsra1z/Bq8vLw4dOgQZ86coX79+pme98cffzB+/HiaNWvGhAkTALQ6zp49S5s2bXBxceGdd97B2tqaX375hfbt27Nnzx6aN28OwMOHD2nTpg1BQUGMHTuWxo0bExERwbp167hx4wZly5ZN97zx8fH06dOHY8eOsX37dpo2bWryawwJCQGgTJkyRsdffvllypUrx/Tp04mNjc30+oULFzJ27Fjq1avH1KlTKVWqFCdPnmTz5s0MHz4cgJ07d9K9e3f8/Pz44IMPsLCw4Pfff6djx47s27ePZs2a5Wvdf/zxB6NGjcLf35+vvvqKuLg45syZQ+vWrTl58qTWRbR161YGDBhA3bp1+eKLL7h37x5jxowxCkmZuXXrFs2aNeP+/ftMmDCB2rVrc/PmTVasWEFcXBxt27bltdde44cffuB///sfderUAdD++7j4+Hjat29PcHAwEydOxMfHh+XLlzN69Gju379v1EoJqf/eHzx4wAsvvIBOp+Prr7+mf//+hIaG5ur/ASFQhBCKoihKdHS0Aih9+vTJ1vmTJk1SAOXkyZOZnnPixAkFUCZPnqwd8/LyUp555hklJSVFqVChgvLJJ58oiqIo586dUwBlz549yu+//64ASkBAgHbdBx98oADK3bt3s6xr69atiqWlpWJpaam0aNFCeeedd5QtW7YoSUlJ6c51dHRURo0ale543759FRsbGyUkJEQ7duvWLcXZ2Vlp27atdmz69OkKoKxatSrdPQwGg6IoirJr1y4FUJYvX648ePBAadeunVK2bNksv2+qy5cvK4Dy0UcfKXfv3lXCwsKU3bt3K40aNVIAZeXKlYqiKNr3q3Xr1kpKSorRPdTHLl++rCiKoty/f19xdnZWmjdvrsTHx2dYs8FgUGrUqKH4+/trxxRFUeLi4hQfHx+lS5cu+Vr3gwcPlFKlSinPP/+80X3DwsIUV1dXo+MNGzZUKlasqNy/f187tnXrVgVQvLy8jK4HlA8++ED7euTIkYqFhYXRv7PHvxfLly9XAGXXrl3pzmnXrp3Srl077etZs2YpgPLnn39qx5KSkpQWLVooTk5OSkxMjNH3p0yZMkpkZKR27tq1axVAWb9+fbrnEsIU0i0lxP+LiYkBwNnZOVvnP3jw4Innq4+p907L0tKSwYMHs3TpUiB1ILGnpydt2rQxqe7HdenShUOHDtG7d29OnTrF119/jb+/P5UrV2bdunVPvF6v17N161b69u1L1apVteMVK1Zk+PDh7N+/X3s9K1euxNfXl379+qW7j06nM/o6Ojqarl27cv78eXbv3m3SgNoPPviAcuXKUaFCBdq3b09ISAhfffUV/fv3Nzrv+eeff+L4mm3btvHgwQOmTJmSbgyKWnNgYCCXLl1i+PDh3Lt3j4iICCIiIoiNjaVTp07s3bsXg8GQb3Vv27aN+/fvM2zYMO25IyIisLS0pHnz5uzatQuA27dvExgYyKhRo3B1ddWu79KlC3Xr1s2yNoPBwJo1a+jVqxdNmjRJ9/jjP7/s2LhxIxUqVGDYsGHaMWtra1577TUePnzInj17jM4fMmQIpUuX1r5W/+2Hhoaa/NxCpCXdUkL8PxcXF+BRaHkSNbhkdf6TAtDw4cP54YcfOHXqFEuWLGHo0KE5elN5XNOmTVm1ahVJSUmcOnWK1atXM3PmTAYOHEhgYGCWb3x3794lLi6OWrVqpXusTp06GAwGrl+/Tr169QgJCWHAgAHZqmnSpEkkJCRw8uRJ6tWrZ9LrmTBhAoMGDcLCwoJSpUpRr169DGc/+fj4PPFeatdQVl12ly5dAmDUqFGZnhMdHW30xpyXdavPr47ReZz6b/Xq1asA1KhRI905tWrV4sSJE5nWdvfuXWJiYrL8Ppjq6tWr1KhRAwsL47+b1W4stV5VlSpVjL5Wv59RUVF5VpMomSTcCPH/XFxcqFSpEmfOnMnW+eov7NOnT2faCnH69GmATMNE8+bNqVatGpMmTeLy5cvaeI+8YmNjQ9OmTWnatCk1a9ZkzJgxLF++nA8++CBPnyc7+vTpw99//82XX37J4sWL070BZqVGjRqZrguUlr29fW5K1KitMt98802mP1snJ6cn3iendavP/8cff6RbKgAweTp3YZVZK5uiKAVciShuisf/IULkkZ49ezJv3jwOHTpEixYtsjy3e/fuWFpa8scff2Q6qHjx4sVYWVnRrVu3TO8zbNgwPv30U+rUqZOva5+oXQ+3b9/WjmXUSlSuXDkcHBy4cOFCusfOnz+PhYUFnp6eQOoA5OyGwb59+9K1a1dGjx6Ns7NzuunxBUUdNH3mzBmqV6+e5TkuLi7ZCid5TX3+8uXLZ/n8Xl5ewKOWnrQy+vmlVa5cOVxcXJ748zOlJdHLy4vTp09jMBiMwuv58+eN6hUiv8mYGyHSeOedd3B0dGT8+PGEh4enezwkJITvv/8eAE9PT8aMGcP27dszfKOeO3cuO3fuZNy4cVnOXBk/fjwffPAB3333XZ68hl27dmX4l+/GjRsBjLqbHB0duX//vtF5lpaWdO3albVr1xpNnw4PD2fJkiW0bt1a6xYZMGCA1u31uIxqGDlyJD/88ANz587l3XffzcnLy7WuXbvi7OzMF198kW6hRLVmPz8/qlWrxrfffsvDhw/T3ePu3bv5WqO/vz8uLi58/vnnGa5yrT5/xYoVadiwIYsWLSI6Olp7fNu2bZw7dy7L57CwsKBv376sX7/eaCVslfq9UNfcefzfSUZ69OhBWFgYy5Yt046lpKTw448/4uTkRLt27Z54DyHygrTcCJFGtWrVWLJkCUOGDKFOnTpGKxQfPHhQm9aqmjlzJufPn+fll19m8+bNWgvNli1bWLt2Le3atXtiaPHy8srT/X5effVV4uLi6NevH7Vr19ZqX7ZsGd7e3owZM0Y718/Pj+3btzNjxgwqVaqEj48PzZs359NPP2Xbtm20bt2al19+GSsrK3755RcSExP5+uuvtevffvttVqxYwaBBgxg7dix+fn5ERkaybt065s6di6+vb7r6Jk6cSExMDO+99x6urq7873//y7PXnh0uLi7MnDmT8ePH07RpU4YPH07p0qU5deoUcXFxLFq0CAsLC3799Ve6d+9OvXr1GDNmDJUrV+bmzZvs2rULFxcX1q9fn681zpkzhxEjRtC4cWOGDh1KuXLluHbtGhs2bKBVq1b89NNPAHzxxRc888wztG7dmrFjxxIZGcmPP/5IvXr1MgxmaX3++eds3bqVdu3aMWHCBOrUqcPt27dZvnw5+/fvp1SpUjRs2BBLS0u++uoroqOjsbW1pWPHjkZrJqkmTJjAL7/8wujRozl+/Dje3t6sWLGCAwcOMGvWrGwP1hci18w6V0uIQurixYvK888/r3h7eys2NjaKs7Oz0qpVK+XHH39UEhISjM5NTExUZs6cqfj5+SmOjo6Kg4OD0rhxY2XWrFkZTr9Wp4JnJTdTwTdt2qSMHTtWqV27tuLk5KTY2Ngo1atXV1599VUlPDzc6Nzz588rbdu2Vezt7RXAaFr4iRMnFH9/f8XJyUlxcHBQOnTooBw8eDDd8927d0+ZOHGiUrlyZcXGxkbx8PBQRo0apURERCiKYjwVPK133nlHAZSffvop09eiThn+5ptvsnzNGX2/Hn9MnQquWrdundKyZUvF3t5ecXFxUZo1a6YsXbrU6JyTJ08q/fv3V8qUKaPY2toqXl5eyuDBg5UdO3ZkWU9e1K0oqd87f39/xdXVVbGzs1OqVaumjB49Wjl27JjReStXrlTq1Kmj2NraKnXr1lVWrVqljBo16olTwRVFUa5evaqMHDlSKVeunGJra6tUrVpVeeWVV5TExETtnPnz5ytVq1ZVLC0tjaaFPz4VXFEUJTw8XBkzZoxStmxZxcbGRmnQoIHy+++/Z/v7k1GNQphKpygycksIIYQQxYeMuRFCCCFEsSLhRgghhBDFioQbIYQQQhQrEm6EEEIIUaxIuBFCCCFEsSLhRgghhBDFSolbxM9gMHDr1i2cnZ3zZINCIYQQQuQ/RVF48OABlSpVeuLedCUu3Ny6dUvbF0cIIYQQRcv169ez3NIGSmC4UZf/vn79urY/jhBCCCEKt5iYGDw9PbO1jUeJCzdqV5SLi4uEGyGEEKKIyc6QEhlQLIQQQohiRcKNEEIIIYoVCTdCCCGEKFYk3AghhBCiWJFwI4QQQohiRcKNEEIIIYoVCTdCCCGEKFYk3AghhBCiWJFwI4QQQohiRcKNEEIIIYoVs4abvXv30qtXLypVqoROp2PNmjVPvGb37t00btwYW1tbqlevzsKFC/O9TiGEEEIUHWYNN7Gxsfj6+jJ79uxsnX/58mWeeeYZOnToQGBgIJMmTWL8+PFs2bIlnysVQgghRFFh1o0zu3fvTvfu3bN9/ty5c/Hx8eG7774DoE6dOuzfv5+ZM2fi7++fX2UKIUShpdfrSU5Oxs7OztylCFFoFKkxN4cOHaJz585Gx/z9/Tl06FCm1yQmJhITE2P0IYQQxYW/vz9VqlQhKirK3KUIUWgUqXATFhaGu7u70TF3d3diYmKIj4/P8JovvvgCV1dX7cPT07MgShVCiHynKAp79+7l7t277Ny509zliAK0bds27O3tWbx4sblLKZSKVLjJialTpxIdHa19XL9+3dwlCSFEnoiOjiY5ORlInaAhSo6ff/6ZhIQEVqxYYe5SCiWzjrkxVYUKFQgPDzc6Fh4ejouLC/b29hleY2tri62tbUGUJ4QQBeru3bva5xJuSo7ExES2bdsGwPnz581cTeFUpFpuWrRowY4dO4yObdu2jRYtWpipIiGEMJ+04ebUqVNER0ebsRpRUPbt20dsbCwAoaGhJCUlmbmiwses4ebhw4cEBgYSGBgIpE71DgwM5Nq1a0Bql9LIkSO181988UVCQ0N55513OH/+PD///DP//PMPb7zxhjnKF0IIs0obbhRF4cCBA2asRhSUDRs2aJ/r9XpCQkLMWE3hZNZwc+zYMRo1akSjRo0AmDx5Mo0aNWL69OkA3L59Wws6AD4+PmzYsIFt27bh6+vLd999x6+//irTwIUQJVLacAPSNVVSbNy4EQALi9S3cOmaSs+sY27at2+PoiiZPp7R6sPt27fn5MmT+ViVEEIUDWq4cXBwIC4ujn379pm5IpHfgoODuXjxIlZWVvTo0YN169ZJuMlAkRpzI4QQ4hE13KiLoQYEBBAXF2fOkkQ+U1tt2rRpQ7NmzQBpucmIhBshhCii1HDTrFkzKleuTHJyMkeOHDFzVSI/qeGmR48e1KpVC4ALFy6Ys6RCScKNEEIUUREREQCUK1eONm3aALB//35zliTyUGxsLAcPHsRgMACQkpKidT36+/tTu3ZtILXlJqshHpm5cuUK69evz9G1hZ2EGyGEKKLUlpty5cpRt25dAKNJGMK8oqOjcxwc/vvvPxo3bkyrVq1YtGgRAKdPnyYuLg5XV1fq1atH9erVsbCwIDo6Ot0acE+yf/9+fH196d27t7ZfY3Ei4UYIIYqotOGmfPnyANy5c8ecJQlSW1wmTZpE6dKlef31102+ftmyZTRv3pyLFy8CsH79egBtH8Wnn34aCwsL7Ozs8PHxAUwbd7Nx40a6du2q7bU4bdo0zp07Z3KdhZmEGyGEKKIk3BQ+p0+fpkGDBnz//fc5WnsoKSmJ8ePHEx8fT8OGDQHYtWsXer2egwcPAhgtXGvquJvw8HD69+9PfHw8zzzzDP7+/iQmJjJq1ChtK4/iQMKNEEIUQbGxsdqGweXKldM2FTa1e0LkrXfffZfLly/j6uoKpG74bIqoqCgePnwIwOHDh3F1deX+/fucPHlSa7lJG27SjrvJjqNHj5KYmEjNmjVZvXo1CxYsoHTp0hw7dowvv/zSpFoLMwk3QghRBKmtNra2tjg5OUnLTSERFBQEwC+//AKkhk11QHB23L9/HwBXV1dsbW1p3749AEuWLOHy5cvodDqaN2+unW9quDlz5gwATZo0wdramkqVKvHTTz8BqdsZ6fX6bNdamEm4EUKIIihtl5ROp9PCTWxsrLbvkChYSUlJXL9+HYCWLVsCqdsj3Lt3L9v3UMNNqVKlAOjUqRPwKCzVq1dPaxUC08PN2bNntfuohg0bxooVK9i5cyeWlpbZrrUwk3AjhBBFUNpwA+Ds7Iytra3RY6JgXbt2DYPBgL29PR4eHpQtWxYwrWsqs3CjLs74+EbRNWvWBODq1askJiY+8f5qy039+vW1YzqdjgEDBmBlZdZNC/KUhBshhCiCHg83aVtvpGvKPEJDQwGoWrUqOp2OChUqAKaNg3o83NSpU4eKFStqjz8ebsqXL4+DgwOKojxxGQC9Xq+18KRtuSmOJNwIIUQR9Hi4AWRQsZmlDTfw6OeRm5YbnU5Hx44dtccfDzc6nU6bDn758uUs7x0SEkJiYiL29vbaNcWVhBshhCiCMgo30nJjXo+HG7XlJjfhBtDCjZubm9YNlZa3tzfw5HCjdknVrVtX21G8uCo+HWxCCFGCSLgpfPIr3AwcOJAVK1bQrVu3DENJdltu1MHEacfbFFcSboQQogiScFP45Fe4cXFx0TbMzEh2w43aclPcx9uAdEsJIUSRJGNuChdFUQgJCQHSh5vcDCjODjXcXLlyJcvzSlLLjYQbIYQogqTlpnCJiorS9mpSx8DkxYDi7MhOy01SUpK2RYO03AghhCiUJNwULmqXVMWKFXFwcADyrlvqSdQwdffuXW3rhsddunSJlJQUnJ2d8fT0zPa9iyoJN0IIUcQkJiby4MEDQMJNYfH4eBt4FG4iIiKyvSllTsJNqVKltPMz65pKuzKxTqfL9r2LKgk3QghRxKitNlZWVkZvgmo3yN27d4vNHkFFRUbhpkyZMtp2BtkNnDkJN5B511RYWBiffPIJb7/9NlAyxtuAhBshhChy1HBTtmxZo7/C1eX+DQYDkZGRZqmtpFLDTdrF8SwsLEwed5OX4UZRFNq2bcv06dO5du0aLi4uDB8+3KT7FlUSboQQoojJaLwNgLW1NW5uboB0TRW0jFpuwLQZUwkJCSQkJAA5Dzdpu6Vu3brFpUuXsLCwYNGiRdy+fZsOHTqYdN+iSsKNEEIUUrGxsSiKku64OuXYw8Mj3WMy7sY8Mgs3prTcREdHA6lbKri4uJj0/BmtUnz8+HEgdUXikSNHagOdSwIJN0IIUQicPHnS6K/7f//9FycnJ2bMmJHu3FOnTgHg6+ub7jFZ66bgJScna5tWZtZyk51wo3ZJubi4mLw9QkbdUmq48fPzM+lexYGEGyGEMLOgoCCaNGlCr169tGMLFiwA4Jtvvkk30yYwMBCAhg0bpruXtNwUvFu3bqHX67G2tjbawRtyFm5M7ZIC43CjtvZJuBFCCGE2J06cwGAwEBAQQHBwMMnJyezYsQNIbYFJu/S+Xq/nv//+AzJuuZFwU/AiIiKA1O/94y0uBRVu1G6pmJgYoqKiAAk3QgghzCjtIND169dz5MgRbbVbgF9//VX7PDg4mLi4OOzt7alRo0a6e0m4KXhquFFnq6VVUOHGwcFB+9lfvnyZW7duERYWhoWFRYYtfMWdhBshhDCzq1evap+vW7eOLVu2ANCkSRMANm7cyM2bN4FH420aNGigraGSlvoGJ2NuCk52wo3688hogLgqN+EGHnVNXbhwQWu1qVOnTokaSKyScCOEEGaWtuVm3759LF++HICXX36ZNm3aYDAYWLhwIZD1YGJ4NKBYWm4KTlbhRv153Lx5k9GjR+Pi4sK6desyvE9uw03btm0B+Omnn0p0lxRIuBFCCLNTw421tTV6vV7b4LBr166MHz8eSO2a0uv1WQ4mhsLdchMdHa0FgeIkOy03sbGxLFq0iIcPH/LBBx9k2IKT23DzxhtvYGdnx6FDh5g/fz4g4UYIIYQZGAwGrVtq8ODB2vH69etTuXJlBg4ciJubG1euXGH58uVPbLmpWrUqOp2Oy5cva91bhYGiKLRs2ZL69etrb+LFRVbhxsXFRVuzpnbt2tjZ2REYGMjRo0fTnZvbcFOxYkUmTJgApM7gAgk3QgghzCAsLIykpCQsLS15+eWXteP+/v5A6kDR119/HYBp06ZpY2+eeuqpDO9XsWJFXn31VQAmTJigbbBpbhEREZw7d47w8HB2795t7nLyVFbhRqfT8ccffzBr1ixOnjzJkCFDAJg7d266c3MbbgDeffddbG1tAUrsYGKQcCOEyKG7d++yYcMGbbl4kTNql5SHhwdPP/20turwM888o53z6quv4uzsrK1MXK1aNZydnTO952effYa3tzfXrl1jypQp+Ve8CdIOmt65c6cZK8l7WYUbgN69e/P6669jZ2fHiy++CMDff/+tTdlW5UW4qVSpEs8//zyQ2lLk6OiY43sVZRJuhBA58sILL9CzZ0+qVKnC9OnTjaYui+xTw423tzcWFhasXbuWxYsXG+0BVLp0aSZOnKh9nVmXlMrJyUmbPv7zzz9r43QyExERQXx8fM5eQDalHTRd0sJNWs2bN8fX15eEhAQWLVpk9FhehBuA6dOnM3jwYD755JNc3acok3AjhMgRdS+du3fv8sknn2h/kQrTpA03AI0bN2bEiBHpznvjjTewt7cHMh9MnFanTp3o3bs3kLqVQ2YuXbqEl5cXPXv2NK1wE6UNN2fPni2UA55zypRwo9PptP9X1EG/qrwKN+XKlWPZsmX0798/V/cpyiTcCCFyRP2FPmnSJCB1fZbHtwkQT/Z4uMlMuXLl+PTTT6lQoQIDBw7M1r27dOkCwN69ezM9Z9GiRcTFxbFz505OnjyZrfvmRNpuKYBdu3bl23MVJEVRTAo3AMOGDcPKyopz585pXY2Qd+FGSLgRQuTQvXv3gNTxIGXLliU2NpYjR46YuaqiJ7vhBmDy5Mncvn2bOnXqZOve7dq1A+DgwYMZBk9FUVi6dKn29W+//Zat++aE+jrd3NyA4tM1FRMTQ0pKCgBlypTJ1jWurq60bt0awGhrDQk3eUfCjRDCZHFxcdpA4rJly9KpUycAtm/fbs6yiiRTwo2p6tWrh5ubG7GxsZw4cSLd4wEBAVr3IsCff/6Zb2Nv1Nf57LPPAsUn3KitNo6Ojlq3YXaoA8bVcJOQkKD9PyXhJvck3AghTKb+Qre2tsbZ2ZnOnTsDEm5MlXaNm/wINxYWFrRp0waAPXv2pHv877//BlLX1/H29iY6OpqVK1fmeR2Komivc8SIEVhaWhISEpKuq6ooUlsws9slperRoweQ2j0XGxtLdHQ0kDomR10XR+SchBshhMnUX+hlypRBp9Np4ebw4cMya8oE4eHhJCUlYWFhQeXKlfPlOdQl+R8PN3q9nmXLlgGprSljx44FjDfpzK4tW7ZQoUIFpk+fjl6vT/d4VFSUtt5O/fr1adq0KYC283lRZup4G1WdOnXw9vYmMTGRXbt2aV1SLi4u6XYWF6aT76AQwmRpww2ktjpUq1YNvV6f5eBVYSztGjfW1tb58hzquJv9+/cbBY/9+/dz69YtSpUqhb+/P6NHj8bCwoI9e/aYHDrWr19PeHg4n3zyCV27dk03E0p9ne7u7tjb22sLFOZHK1FBy2m40el0WuvNhg0bZLxNHpNwI4Qw2ePhBpCuqRzIz/E2Kl9fX5ydnYmJidG2bgC0gcT9+/fH1tYWT09PbTxMr169MuzGykxYWJj2+c6dO+nUqRMGg0E79njX29ChQ4HUFp+7d+/m7IUVEjkNN2A87kZd0E/CTd6QcCOEMFlGv9Al3JiuIMKNlZWVNjNHbVVLTk5mxYoVwKOgATBv3jy6detGfHw8PXr0yHYrnBpuPv74Y1xdXTl79ixbt27VHldfp5eXF5C6cm7jxo3R6/VaHUVVbsJN+/btsbOz49q1a7z55puAhJu8IuFGCGGyjFpuOnTogE6n4+zZs9y+fdtcpRUpj7/p5xe1a0pdzG/79u3cu3eP8uXLG62EbGdnx+rVq+natStxcXH06NGD/fv3P/H+arjp0KEDo0ePBmDOnDna4xmFOLWVaMmSJTl+XYVBbsKNg4MDw4cPB+DcuXNA9qeTi6xJuBFCmCyjcFOmTBkaNGgAwIEDB8xSV1Gjfh/d3d3z9XkGDx6MpaUlO3bsICAgQOuSGjRoEFZWVkbn2tnZsWbNGrp06UJsbCzdu3fn4MGDWd5fDTcVKlTghRdeAFKD1PXr14GMw82QIUPQ6XTs37+/SM+ayk24gdQB3CdOnODLL79k+PDhvPPOO3lZXokl4UYIYbLMfqGr3R8SbrJHnVmW31N/fXx8tJaS6dOns2bNGiB1pdyM2Nvbs3btWjp16sTDhw/p3bt3puvfPHz4kNjYWCA13NSpU4d27dphMBi0mVdqeEnbQlW5cmWt1SjtQoJFTW7DjU6no1GjRrz77rv89ddfNG/ePC/LK7Ek3AghgNRuhGrVqmnN41nJqOUGoFWrVoCEm+xS1zYpiHVNpk6dik6nY/PmzTx48IAqVarQokWLTM+3t7dn3bp1eHl5ce/ePdavX5/heWqrjaOjI05OTgBGeyclJydnOrZI7ZJZvnx5bl6aWeU23Ij8IeFGCEFQUBCvv/46oaGh2Rrg+aRwc+LECe2v+az8999/nDlzJgcVFw9qy42rq2u+P1ft2rUZMGCA9vWQIUOeuJ6Kg4MDzz33HJC6enFG0nZJqfr370+5cuW4ffs2r776qhbiHh9b1L59eyB1vImiKKa9oEJCwk3hJOFGiBLOYDAwYcIEbe+hoKCgJ16TWbipUqUKHh4e6PV6jh49muU9YmNjadOmDS1atCAyMjKH1RdtBdUtpXrvvfe0z9POksqK2p21adOmDKdtZxRubGxs+OqrrwD45ZdfgNSNPx0dHY2urVKlChYWFiQkJBTJXcINBkOOVygW+UvCjRAl3K+//mo0I+b8+fNPvCazv1Z1Ol22u6YuXLhAdHQ0Dx8+ZN26daaWXSyoLRoF0XID0LBhQ+bOncuMGTNo1KhRtq6pU6cOfn5+pKSk8M8//6R7PKNwAzBmzBijGVMZzQiztrbGw8MDeDTouCi5f/++tp6PzHIqXCTcCFGCJSUlMWXKFABeeeUVIDV0pF2ALaNr1KX0M/qFrg4q3r9/Pzdu3KBly5b873//S3de2hBV1Nc6yQm9Xq913RXkXkIvvPACb7zxBjqdLtvXZNU1lVm4gdSxN/Pnz8fGxkZblfhx6jicy5cvZ7uewkIN+a6urvm2wrTIGQk3QpRgN2/eJCoqCjs7O2bMmIGNjQ3x8fFZTs1Vu5B0Ol2GC46pLTeHDh2iT58+HDp0iO+//z5dYErb/bV161atFaOkUAMiFGy4yYmhQ4diYWHB4cOHCQ4ONnosq3ADMH78eO7fv8+nn36a4eM+Pj5A0Wy5kfE26SXpk7h6/yrBkcFPPjkfWT35FCFEcaUutlexYkVsbGyoWbMmZ86cISgoSHvTeZz6C93NzQ1LS8t0jzdo0AAnJydiYmI4ceIEAHFxcVy5coWqVatq56VtuUlOTubff//VxneUBGqYs7W1xdbW1szVZK1ChQp07NiR7du3s3nzZiZOnKg99qRwA6kzrzJTHFpuSkKXlKIo3Iu/x42YG9rHrQe3jD5uPrhJRFzq96SjT0d2jDTfxqgSboQowW7dugVApUqVgNTxFWfOnOH8+fPapn6Py2wwscrKyooWLVqwbds2rK2tKV26NHfu3OHMmTNG4UZtuWnSpAnHjh1jxYoVJSrcFPRg4txq1KgR27dv5+LFi0bHsxNusqKGaDXcHDp0iK5du/LNN99oU8oLq+LScqM36LkTe8couNyIucHNBzeNvk7UJ2brfjaWNujIfrdnfpBwI0QJlrblBlLDDWQ9Y+pJ4QZg7NixnDhxglmzZrFlyxb+/PNPzpw5Q+/evQFISUnh0qVLAEybNo2+ffuyadMmHjx4gLOzc+5fWBFQ0IOJc6tmzZoA+RZu1G6pJUuW8PDhQ+bMmVPow436b7gwh5sUQwq3HtzKMrjcenCLFENKtu5X3rE8lZ0rU9mlMh7OHlRyrkQl50pUdqmsfV7GvoxJY7ryg4QbIUqwjFpuIOtwk52/VocOHaotr3/jxg0Ao/VsLl++TFJSEvb29vTq1Yvq1asTHBzM8uXLGTt2bO5eVBFR1Fpu1HCjvqFD6lRodQp3TsON2i119epV9Ho9AQEBAJw+fZo7d+5Qvnz5XFSdf7Zs2cI333wDPBpEbw4PEh9wLfoaV6Ovpv73/lWuxfz/f6OvcfPBTQxK5hMEVBY6Cyo6VcTDxQMPFw8qO1fWPlc/KjlXwtaqcHehqswebmbPns0333xDWFgYvr6+/PjjjzRr1izT82fNmsWcOXO4du0aZcuWZeDAgXzxxRfY2dkVYNVCFA9quFFbbmrXrg2khhtFUTL86ys7LTeAdm39+vUB43CjjrepVasWFhYWjBs3jqlTpzJ16lT69u2Lm5tbbl5WkVDUwk2NGjWA1BaWpKQkbGxsiIyMJCUl9S/+nIaQypUrY2VlRXJyMteuXSMwMFB7bNeuXQwZMiTXtee1wMBABg4ciF6vZ+TIkYwfPz5fnsegGLgTe0cLKlejr6YLL1EJUU+8j7WFdWpLixpUnP8/wKQ5VsGpAlYWZo8Eecasr2TZsmVMnjyZuXPn0rx5c2bNmoW/vz8XLlzI8H+UJUuWMGXKFBYsWEDLli25ePEio0ePRqfTMWPGDDO8AiGKNrVbSm25qVWrFjqdjsjISCIiIihXrly6a7IbblRquLlw4QLJyclYW1tr4UYNU2+88QaLFy8mKCiId955R9uTqDgrat1SFSpUwMnJiYcPHxIaGkrt2rW1LqmyZctiY2OTo/taWlpSpUoVQkND+ffff0lMfDSuY8eOHYUy3IwdO5aHDx/SsWNH5s+fn+MuGINi4NaDW1yOuszl+5e5HHU5NcD8fyvMtehrJOmTnnif0nalqeJaBa9SXlRx+f//ulbByzX1v+5O7ljoStbkaLOGmxkzZvD8888zZswYAObOncuGDRtYsGCBtvZGWgcPHqRVq1bafiTe3t4MGzaMI0eOFGjdQhQXj7fc2Nvb4+3tzeXLlwkKCsqTcFOlShXtTTE4OJg6depo3V5qN5itrS3z5s2jTZs2/PbbbyQnJ3P48GF0Oh1bt26lSpUquX6thU1Ra7nR6XTUqFGDkydPcvHiRaNwk9MuKZWPjw+hoaHaIoEODg7ExcWxY4f5ZttkJiEhgVOnTgGwcOHCJ4a6qPgoLt+/TGhUqBZiQqNCuXz/MlfuX3lieLHQWVDJuZIWVLxcvYzCi6erJy62RePfUEEyW7hJSkri+PHjTJ06VTtmYWFB586dOXToUIbXtGzZkj///JOjR4/SrFkzQkND2bhxIyNGjMj0eRITE43+ElB/oQgh0rfcQGrgUMNN27Zt011j6gwRCwsL6tWrx5EjRzhz5gx16tRJ13IDqeMWXnjhBX755RcWL16sHX/22WfZtWsXVlbFp8kcil64gdRxNydPntTG3eRVuFHH3airWo8ZM4a5c+cSGhrKlStX0m24mZklS5ZQunRpunfvnqt6snLp0iUMBgOurq54eHiQkJLA1ftXtcByOeoyofcfBZn7CfezvJ+lzhKvUl74lPLBp5QP3qW8H7XCuFahsnNlrC1lgUBTme23RUREBHq9Hnd3d6Pj7u7umS7/Pnz4cCIiImjdujWKopCSksKLL76Y4eqnqi+++IKPPvooT2sXojhISEjQFuRLG25q167Nxo0bMx1UbGrLDaR2TanhZuDAgelablRfffUVCQkJODg40Lx5c1599VX279/Pxx9/zMcff2zS6yvsilq3FDwad6POmMrLlhtA2zyzY8eOnDx5koMHD7Jjxw7GjRv3xHtcvHiRZ599FgsLCzZt2kTXrl1zVVNacclxhEaFEhwZzMr9K6EnKD4KXrO8uBFzA4WsN/10d3THp3RqeKlauuqj/5b2wcPFo1iNdSksitR3dPfu3Xz++ef8/PPPNG/enODgYF5//XU++eQT3n///QyvmTp1KpMnT9a+jomJwdPTs6BKFqLQUt+YbG1tjVYaVgPHyZMnM7wuJ+GmXr16QOqg4jt37nD//n0sLCy0N0uVq6srCxcu1L62sbFh+PDhfPrpp3Tp0oU2bdpk+zkLu6LacgPkecvN4wtGNm3alE6dOpkUbvbs2QOkzuAaOnQox44dM1pX6UnikuMIjgzWPi7du0RwVOrnN2JuGJ/cBGKI0X6GjtaOWlipWqqqUZDxLuWNo41jBs8o8pPZwk3ZsmWxtLRMtxNseHh4pv+jvP/++4wYMUIbmd6gQQNiY2OZMGEC7733HhYW6QdMFYXVP4Uwh7TTwNMOiGzTpg0WFhbs3buXVatW0b9/f6PrcrJwWdoZU2qrjY+PzxNnOQ4bNozNmzezePFi5syZU6zCjbTcPJK226l8+fJ4eHjQqVMnPvnkE3bs2KHN3Lty5Qp+fn4MHTqU2bNnG91D3fzV0tKSqKgo+vXrx6FDh3BwcNDOSUhJ4NK9S1y4d+FRiIm8RHBkMLce3MqyRldbV2qUqcGd83e4dvIagzsP5vURr1PdrTrlHMqZfV0XYcxs4cbGxgY/Pz927NhB3759gdTEvWPHDqOlvdOKi4tLF2DU5d/V5kwhRPY8voCfqlatWkyZMoXPP/+cF198kdatW2uzF/V6PVFRqVNPTe2WAggODtY26Ew73iYrzz77LIsXL+bo0aPZfr6ioCi33Ny8eZPY2Nh8ablp2rQpOp2Op59+Gjs7O+7cucPFixepVasWa9asITIykt9++40vv/zSaMFHNdz88ssvvPvpu5yOOc1Lv72EWw03zt87z4WIC1y5fyXLLqTSdqWpUaYG1d2qU7109Uefu1XXFqZr1KgR1wKv8eykZ2np2TJXr1vkH7N2S02ePJlRo0bRpEkTmjVrxqxZs4iNjdVmT40cOZLKlSvzxRdfANCrVy9mzJhBo0aNtG6p999/n169emW4x40QInOPL+CX1vTp01m/fj3//fcfL774IitXrkSn03H//n3tDwlT1qKpUKECbm5uREZGcu7cOUqXLm00mSAr6rpXISEhREREFOrVYE1RFMONm5ub9nMMDg7Os3Dj7u6Ora0tiYmJNG3aFEhtdW/atCn79u3jwIED1KpVSxtwnJiYyPpN63mq/VOcjzhPwOUAQn1DoRNMvjOZmNGp39vFkYvhscm0rrau1Cpbi5plalK9dGpwUUOMm33W/6YNBgMXLlwAsh/OhXmYNdwMGTKEu3fvMn36dMLCwmjYsCGbN2/WBhlfu3bNqKVm2rRp6HQ6pk2bxs2bNylXrhy9evXis88+M9dLEKLIyqzlBlLfWBYvXkzTpk1ZvXo1u3fvpkOHDtpfx+7u7iata6LT6ejbty9LlizhtddeY8qUKZQuXTpb15YqVYpatWpx4cIFAgIC8nUmTEEqit1SkNp6c/jwYRYuXKhN/vDy8srVPdXxV2fOnKF58+ba8datW7PvyD5WH10NjWCTfhM8C5SFZ889C2nHvPum/icmKQYLLDBEGnCIc+DFgS9Sq2wtapetTa0ytSjvWD7HXUjXr18nPj4ea2trk8bzCDNQSpjo6GgFUKKjo81dihBmNWrUKAVQvvjii0zPeemllxRA6dmzp6IoitKpUycFUN555x2Tn89gMCiJiYk5qnXEiBEKoHzwwQc5ur4wcnd3VwAlMDDQ3KWYRP1ZqB/PPvtsntx3045NyoufvKj8evxX5c0tbyrd/+yulPu8nMKHZPpR6stSSvP5zZXaU2ortEbp/mZ35eyds0rY3TBFp9MpgHL79u08qU9RFGXTpk0KoNStWzfP7imyz5T37yI1W0oIkXeyarlRTZo0iblz5/Lvv/+yevVqduzYgYWFBS+//LLJz6fT6XK8im3z5s35448/itW4G7Vbqii23KiqV6/OnDlzTLr+QeIDzt09x9m7Z43+ey36WuoJ6zO6CGqWrsnF/Rep4lCF6OBookOiWbF2BZ06daJx48ZwEka/Opq65eoCqRNOTp8+zf79+xk4cGBOX64RtaXq8SUMROEj4UaIArJu3Tpq165t9OZgTlmNuVHVrFmTXr16sW7dOm1l8D59+uS6G8JU6ribo0ePZrrnVVGSnJxMfHw8ULTG3EDqgHMAa2tr/v7770x3cdcb9FyKvMTp8NNGH1ejr2Z674pOFalbri71ytWjXvl61C1Xl/F9xnMh8AKJXolwFfpP6k9MqRgWnF7A2rVradq0qbZicKtWrbR7tWnThtOnT7Nv3748CzfqTD8Zb1P4SbgRogCcPHmSPn364Ovra7QxoDllp+UGUgf+r1u3joSEBABeffXVfK/tcb6+vtjY2HDv3j1CQ0OpVq1agdeQl9KulJ5ZOCisevXqxfjx4+nRowd+fn4A3Iu7Zxxi7pzmzJ0zJKQkZHiPik4VU8NL2brUK1+PeuXqUadcnQwH9LZr1o4LgRe4ejU1FLVq1QobGxsWLFjAqlWrsLOzw2Aw4OPjQ+XKlbXr2rRpw+zZs9m3b1+evXZpuSk6JNwIUQDUvyzPnDmjbR5pTomJidpifFm13AC0bdsWPz8/jh8/Tv369Wnfvn0BVGjMxsaGRo0aceTIEY4cOWLWcPPDDz/w7bffsnr1au3N3VTqYGIHBwez/1swRbI+meCYYDq81oEj4UeY99c8ToefznSNGAdrBxqUb8BT7k9pH/XL13/irKS0Wrduzbx587SvW7VqRalSpXBwcODmzZt88803AOnWQFK/PnXqFDExMXnSQiYtN0WHhBshCoC6oqteryc0NFRr2jeXtKsTP2nWkk6n49tvv+X555/nq6++MluXUPPmzTly5AhHjx7VusjM4e+//+b69eu89NJLHD58OMPFQ5+kKEwDj0uO43T4aU7cPsHJ2yc5EXaCM3fOZLrRY9XSVVMDTPlHQaaaW7Vc70adtqvJx8dHa2n89ddfjTbafHwbnkqVKlG1alVCQ0M5ePAg3bp1y1Ud9+7d4+7duwBm//9XPJmEGyEKgBpuAG1BMnNKuxt4dsJK+/btjV6DOahThI8cOfKEM/PXzZs3AQgICODPP/9k5MiRJt+jsIWb6IRoAsMCU4NM2ElO3D5BUEQQBsWQ7lxnG2ejlhi1NSa/dqb28fGhQoUKhIWF0bLlo0Xzhg0bxrBhw7K8tk2bNoSGhrJ///5chxt1fRsPDw+cnJxydS+R/yTcCFEA0gaDCxcu0KtXLzNWk/3xNoWJGm5OnDhBbGwsjo4Fv1+PwWDQgiHAlClT6N+/v8lvduZc4+Ze3D2O3z5uFGSCI4MzPLe8Y3n8KvrRqEIjGldsTKOKjfAu5Z3r1hhT6HQ6/P39WbRokcmbYbZs2ZJFixYREBCQ6zrUn3tBD6YXOSPhRoh8pihKupYbc7txI3UjwKIUbqpWrYqXlxdXr15l9+7dPPPMMwVew507d0hJSUGn0+Hj40NoaCiff/45n3/++ROvffjwIbNmzWLAgAEF1nITmxTLidsnCLgVwNGbRwm4FUBoVGiG51ZxrZIaYP4/yDSu2JiKTtlr2ctvM2fOZNCgQfTo0cOk69RtHdIG0py6c+cOgLYViSjcJNwIkc/Cw8OJjY3Vvlabt81JHeBclAZG6nQ6unfvzty5c9m8ebNZwo3aJVWhQgW+++47+vXrx9dff03v3r15+umn2bZtGzNnzuTLL7/kqaeeMrp22bJlvP/++xw6dIiePXsCedtyk6xP5sydM1qIOXrzKGfvns2wa6m6W3X8KvppYaZRxUaUdSi821qULl06Rz9vNbyrLZW5oY63KVeuXK7vJfKfhBsh8pnaaqPT6VAUpVC03KiL4aVd6r4o6NatG3PnzmXTpk1meX61xcvDw4O+ffsyfPhwlixZwrPPPsunn37K6NGjSUpKwtvbm59//tno2pCQEAAOHjxI69atgZy33CiKQnBksFGQORl2MsOp15WcK9GscjOaVmpKs8rN8KvoR2n77G19UdSpe17du3ePpKSkHC8iCdJyU9RIuBEin6nhplmzZhw5coSwsLA8m5qaEw8ePODs2bMA2iaFRUXHjh2xtrYmJCSES5cuUaNGjQJ9frXlRl1PZfbs2ezfv5/Q0FCjGVzq9zctNRjdv39fC5fZ/TcQlxzHsVvHOHj9IAevH+TQjUNExEWkO8/V1pWmlZvSrFIzmlZuStNKTansUjmDO5YMbm5uWFlZkZKSwp07d/Dw8MjxvaTlpmiRcCNEPlPDTZMmTbhy5Qrh4eFcvHiRJk2aZHpNaGgoTZs2ZeTIkcycOTNP6zlx4gSKouDp6VmkxtxA6oJ3bdq0YefOnWzevLnAw03alhtI3dRz8eLFdOjQAUVRaNGiBYcOHeLs2bPpVlK+fv269vmOHTuAjLulFEXhesz11BBz/RAHbxwkMCyQFEOK0Xm2lrY0rthYa5FpWrkp1d2qF+hg38LOwsKCChUqcOPGDW7fvi3hpgSRcCNEPlPDTY0aNahZs2a2ws2KFSuIjIxkzpw5fPzxx3m6iq3aaqBuaVDUdO/enZ07d7Jp06YMV0u+ceMGP/74I926daN9+/Z5OiD28ZYbgHbt2rFq1SquXr3K2LFjcXV15d69e9y5cwd3d3ejulQPHjwAUltukvRJnLx9MrVV5kZqoLn54Ga6567kXImWni1p6dGSlp4taVSxETaWOe9mKSnUcKOu7ZRT0i1VtEi4ESKfpQ03tWrVYt++fU8cVLx3714gdSXhf//912g9j5SUFEaPHo23tzeffvqpyfUU9XDTrVs33n77bXbt2kV8fDz29vZGj7/33nssXryYr7/+mtatW/Ptt9/m2dgiNdw83gLQt29f7fOqVasSEhLC2bNntXCjKMqjcGMNeAJeMC95HtO+mEaiPtHofpY6SxpVbERLj5a08GxBS8+WeLp4FoqZS0WNOu4mt+FGWm6KFgk3QuQjRVEIDk5dQ6R69erapplZDSrW6/Xs379f+3r58uVG4SYgIIC//voLgMGDB6eblfMkRT3c1KtXDw8PD27cuMGePXuMFmdTFEXr8tHpdOzfv59hw4YRGprx9GdTqQElbctNRvWp4aZjx47cT7jPxjMbSWidAN5ARcAy9dxLSanBt4x9mdRWGc+WtPBoQZNKTXC0Kfh1fIojtes1N+FGr9cTEZE6xklabooG6ZwVIh/dunWLuLg4LC0t8fHx0VYmzqrl5syZM0RHR2NpmfoOuGnTJq0bAzDaeHPGjBkm1RMWFsa1a9fQ6XQ53hfJ3NQp4QCbN282euzSpUvcvHkTGxsbjh07BsDVq1fR6/U5ei41nBoMBqPWl6zGbvjU84E6MO/6PBr90gi3r9x4dsOz0BrwIDXYRAOn4DXv1zj/ynnuvn2XdcPWMaX1FNp5t5Ngk4fUlpvcTAePjIxEURQAypQpkyd1ifwl4UaIfBAQEMCWLVu0Lilvb2+sra2NWm7UX5aPU7ukOnXqRI0aNUhISODff//VHlfXqAFYsmSJSb+01ZVa69atW+R2o05Lba15fEr4zp07gdSVaX19fbG0tMRgMBAeHp6j51m2bBk1atTgq6++IiYmRluvKG3LzZ3YO/x95m9e/PdF6s6uy/e238MQOON4hsCwQBQUKtlWghPgfdKbXsG9YCawGobUGEKtsrWkuykf5UW3lDrexs3NrUhtdFqSSbgRIo9FR0fToUMHunXrxnPPPQegzeqpWrUqlpaWxMbGZrpqqhpu2rVrx6BBg4DUrimV2nJjZ2dHcnIyP/30U7ZrK+pdUqrOnTtjZWXFxYsXjbqc1HDTsWNHLC0ttTe2nK5Qu2fPHgD++ecfbbxNKfdS7Lyxkzc2v8FTc57C/Vt3hq0cxi/HfyEoInXXaO6A7Slblg5Yys3JN5nmOg3WgS++dG7aWbt/YdlbqjjLi3Aj422KHgk3QuSxLVu2aH/hq2+IarixsbHRloTPaNyNoijs27cPSN30Tw03ateUXq/n9OnTAHz44YcAzJkzR1sgLjObN29m0qRJ/Pbbb0DRDzcuLi7abtFq643BYGDXrl1AariB1J2h4dHPwVShoaFgCYH3A5m2cxqMg/sv3KfX0l7MOjKL/+78B8BT7k8xqfkkVg9ZzfVXr2Mx14LE1Ym0K9OOSs6VtGngnp6ePP3009r9zbG3VEmTF6sUqy03Em6KDgk3QuSxdevWATBkyBDtDbhdu3ba49WqVQPg8uXL6a69dOkS4eHh2Nra0rRpU3x9falevToJCQls3bqVS5cuER8fj6OjI5MnT6ZatWpERUVRvXp1OnTowPHjx9PdMyAggO7du/P9999z+/ZtrK2t6dSpU3689AKldk2p427+++8/IiIicHR01BYnVLuPTGm5MSgGTtw+wVf7v2Kf9z6YAoyG1fdWp85ysoCqpavyfOPn+XvA34S/Fc6pF08xs9tM+tbui4ebh/YzVhfzSztWp2HDhpQvXx4XFxd5sywAaVtuMusKfhK15UYGExcdEm6EyEPJycls2LABgIkTJ7Jv3z7CwsIYMGCAdk7VqlUBMpzBo7baNG/eHDs7O3Q6HX369AFg7dq1WpfUU089hbW1NatWrcLf3x+dTsfu3buZOnVqunuqXVpNmzblr7/+4vLlywW++F1+UAcV79y5k4SEBK1Lqk2bNtoy+9ltubkbe5e/Tv/FiNUjqPhdRfzm+TFlxxTiK8WnTt1+CLozOlgLg28NJuS1EOb1mseQ+kMo75j+Da9+/frAo3CTtuVGHewcGBiInZ1d7r8RIktquElISNA2LDWVdEsVPTIVXIg8dODAAe7fv0+ZMmVo0aIFOp3OaCE3yF64adu2rXasd+/efPfdd2zYsEH7y7Fhw4ZAasjZvHkz27dvp0uXLumW/VcUhdWrVwPw1ltvMXjw4Lx5oYXAU089RcWKFbl9+zZbt27VQmXaVqnMWm5SDCkcvnGYzcGb2RKyheO3jqPw6K96JxsnnnZ/mu3ztkMocBft8dq9nrzZaL169Vi9enWGLTeQGnJEwbC3t8fV1ZXo6Ghu376d7a5AvV6PoihYWVnJAn5FkIQbIXJp3rx5/Pnnn/z0009al1TPnj21qdyPyyrcnDx5EjAeE9OyZUvc3NyIjIxk0aJFAPj6+hpdp652fOvWLaKjo7Vf4OfOnSM4OBhbW1utpaO40Ol0dOvWjd9//11r3QLo0KGD9nnalptr0dfYEryFLSFb2B66nejEaKP7NazQkG7VuuFf3Z+Wni05sPcA249sp2zZskTwaB+n7CzhX69ePSB1Wn92p5CL/FOhQgWio6MJCwujdu0nh9OUlBQaNWoEpG5XIi03RY+EGyFy6ZtvviE4OJh27dpha2sLpLa2ZCazcJOcnMz58+cBaNCggXbcysqKZ555hj/++ENbSExtuVGVKlWKChUqEBYWxoULF7RwpLbadO7cuUhP/c7MoEGD+P3334HU4DB8+HAaN24MgN6gJ9olGjrBnnp78JrlZXRtGfsydK3WFf9q/nSt1pWKzsb7bKk/nyZNmnD16lWCglJnQmW1gJ9KXVgxMDCQK1eukJCQkO1rRd6rUKECFy5cyHTG1EcffcTff//Nnj17KF++PJcvX+bMmTNAakCVlpuiR8KNELnw4MEDbQXi+/fvA2Bra0vXrl0zvUadLXX37l0ePHighY5Lly6RlJSEk5MTVapUMbqmT58+/PHHH0DqZoBpw4+qTp06hIWFERQUlC7c9OvXLxevsvDq3r07Bw4coHTp0tSuXZuHSQ9ZFbSK9RfXs/HSRu7G3YU2kEgiFjoLnvZ4Wmud8avoh6VFxq1r8CjcVK1aFR8fHy3cZKf1pU6dOtSsWZOLFy/yww8/AKlvjGr4FQXrSTOmfvnlF27fvs22bdt49tlnjRbZDAgIkJabIkgGFAuRC+qCehUrVtS6fbp164aTk1Om17i6umqrnKadMfXff6nTiuvXr4+FhfH/ml27dtUGydasWRMHB4d0961Tpw6A9iZ89epVTpw4gYWFRZYtSUVd5bqV2fFgB93+6kbZb8oycPlAFp1axN24u7jYuMB/wEq4NvEaB8Ye4P1279OscrMsgw0Yh5u0XV3ZaX3R6XSMHDkSSH3jBBlnY05ZrXUTFRWlhZ5z584BpAs3MhW86JGWGyFyQZ295Ofnx8qVK1m/fj2tW7d+4nVVq1bl3r17hIaGal0YarjJqFXG2dmZjh07snnz5nRdUqrHw83atWsBaN26dbH6pawoCsduHWPN+TWsv7heW2tGVd2tOr1q9qJXzV608mxFKZdSxMfHkxCVAG6PzouNjUWn02UYFME43LRp0wYXFxfc3Nxwc3PL8PzHPffcc0ybNo34+HhAxtuYU1bhRv3/BTION4cPHyYyMhKQbqmiRMKNELmgDgBu1KgRNjY2RlO+s1K1alUCAgKMxt2offzqNOLHvf3225w7d44xY8Zk+LgabtRxO+vXrwcwGmxbVOkNeg5eP8jKoJWsClrF9Zjr2mMWOgtaebZKDTS1elGrjPF2BpUrVyY4OJhbt25p688kJSXRqFEj9Ho9QUFBWqtYWmnDTdmyZTlx4gS2trbZ3irBy8uLdu3aaascS8uN+WTVLaUGGng0dT9tuFH/vwTZV6ookXAjRC6oLTeZtaZkJqNBxVm13EDqqrtXr17N9J7qLJCQkBDu3bunvan27NnTpNoKi2R9Mruv7GZV0CpWn19NeOyj/aEcrR3pUaMHvWv1pnv17pRxyPxNp1KlSgQHBxutdXPkyBFt36+goKB0s89iYmK0wdvqGCk1GJli5MiR2s9BWm7MJ6uWm7TLJ4SEhJCQkKD9gaDT6Yw2zLSykrfMokJ+UkLkUHJysvZXnTptNLseDzcPHz7UPs+s5eZJKlWqhLOzMw8ePGDu3LkkJydTvXp1bbPOoiAhJYFtIdtYdX4V6y6sIzI+UnuslF0petfqTf/a/elarSv21vbZumdGa91s375d+/zMmTPpwo06Fqps2bK52v9p4MCBvPLKKyQkJEjLjRllFW7SttwYDAaOHj2qjbFp3769tqVHceraLQkk3AiRQ0FBQSQlJeHi4oK3t7dJ1z4ebtS/Ht3d3XP8S1Sn01GnTh2OHj3Kjz/+CECPHj1ydK+ClJCSwKZLm/jn3D9suLiBB0kPtMfKOZSjb+2+DKgzgA4+HbCxTN999CRquEnbcpM23KgtZmml7ZLKDRcXF9577z2WLl1K586dn3yByBdqt1RERATJyclGO3ur4cbBwYG4uDhthmGlSpXo2LGjFm5kvE3RIuFGiBxSx9s0bNgw2+MwVOqb5uXLlzEYDFoLUGZdUtmlhpvw8NQunGeeeSZX98svKYYUdoTuYOmZpaw+v5qYxEfL4ld2rkz/Ov0ZUGcArau0fuKspidRF/JTW25iYmI4cuSI9nh+hhuAadOmMW3atFzfR+RcmTJlsLS0RK/Xc+fOHS3wRkdHawssPvPMMyxfvlwLN7Vq1dL2KANpuSlqJNwIkUPqeBtTu6QgdfyFlZUVSUlJ3L59+4njbbJLHVQMqX+Jpt3GwdwMioED1w6w9MxSlp9bTkRcmlV/XTwYXHcwg+oNolnlZljo8m6Visdbbvbs2YNer9fe7NIOGI2IiMDe3j5Pw40wPwsLC8qXL8/t27cJDw/X/k2oM6UqVapEy5YtWb58uTaurVatWtrK3yDhpqiRcCNEDuV0MDGkrjrs5eVFSEgIoaGhRmvc5EbacNO5c2ezb8yoKAonbp9g6ZmlLDu7jBsxN7THyjmUY1DdQQytP5RWVVrlaaBJ6/GWG7VLauDAgSxbtoxr164RHR3NrVu3aNSoEVZWVtjbp47nkXBTfKjhRh1PA4+6pOrWrUvdunWNzq9VqxZlypShWrVqhISESLdUESPhRogcUBQlV+EGUt84Q0JCOHnyJKdPnwZy33KTdt8cc463uRFzg79O/8Xi04s5d/fRgE0XWxf61+nPsPrD6OjTESuL/P8VlLblRlEULdwMGjSIAwcOcOPGDc6cOcPmzZtJTEwkMTGR2NhYQMJNcaJuYKt22cKjcFOvXj1tPzBVrVq1AGjXrh0hISFUr169gCoVeUHCjRA5cPz4ce7fv4+1tXW6v/iyS33jfP3114HU1pyc3ivtPd3c3Hjw4EGBj7eJTYpl9fnVLD61mO2h27VdtO2s7OhdqzfD6g+jW/Vu2FkVbGuSOpg0ISGBc+fOce7cOXQ6HR06dKBBgwZauFmzZg0AU6ZM4d69eyiKQps2bQq0VpF/Mgo36kD+unXrUqlSJVxcXIiJSR3/pYabb775ht69exeJwfnikVyFm4SEBLM3ewtR0PR6PS+//DIA/fv3z3ABuOxI20pTt25dpk6diqOjY65qs7KyYufOncTFxRXIuioGxcCeK3tYfHoxK86t4GHSQ+2xNlXaMMp3FAPrDsTVzjXfa8mMnZ0dZcqU4d69e7Rr1w5IXVHazc2NBg0asGnTJtauXcuZM2ewtLTknXfeoXTp0marV+QPtVsps24pnU5H3bp1OXz4MLa2tnh5pW606ubmViwWwixpTA43BoOBzz77jLlz5xIeHs7FixepWrUq77//Pt7e3owbNy4/6hSi0Jg9ezYBAQG4uroyc+bMHN/n+eefx97envr169O0aVOTZ1xl5vE1W/LDlftXWHByAYtOLeJa9DXteLXS1RjpO5LnnnqOqqULT5eOl5cX9+7d4969ezg5OfHmm28Cj8Y4bdq0CUjtgpBgUzw93nLz4MEDrl1L/bertpjWq1ePw4cPU6NGDSwtczdLT5iXyeHm008/ZdGiRXz99dc8//zz2vH69esza9YsCTeiWLt+/TrvvfceAF999ZXW5ZETNjY2jB07Nq9Ky3dJ+iTWXVjH/BPz2RayTet2crV1ZXC9wYzyHUVLz5Z5FtLy0syZM1m9ejUdO3akS5cuWovz42Oc+vbta4bqREF4PNxcvHhRO67uF6bu85bbgf3C/EwON4sXL2bevHl06tSJF198UTvu6+urLVktRHH1+eef8/DhQ1q1amUU7ouzCxEX+O3kbywMXMjduLva8U4+nRjXaBx9a/fN9mrB5tK2bdsMp8XXrl1bmxIOFOvd00u6x7ulrly5AjzaXgNgzJgxxMbGMmjQoAKvT+Qtk8PNzZs3Mxw1bjAYSE5OzpOihCiMEhISWLp0KQAfffQRFhb5M3W5MIhPjmdl0Ermn5jP3qt7teMVnCowpuEYxjUaRzU30/daKmzs7OyoUaMG58+fp2HDhto4C1H8PN5yo3ZJpf2ZOzs7M3Xq1IIvTuQ5k8NN3bp12bdvX7pfAitWrMjRYmZCFBVr164lOjqaKlWq0KFDB3OXky9CIkP4OeBnfg/8naiEKCB11+0eNXowvtF4nqn5TIFM3y5Ifn5+nD9/nn79+pm7FJGP1HBz9+5dDAaDtlhflSpVzFmWyCcm/5aaPn06o0aN4ubNmxgMBlatWsWFCxdYvHgx//77b37UKEShsHDhQiB1p+fi1GpjUAxsCd7CTwE/senSJm0sjZerF+Mbj2d0w9F4uBTfHa0///xzGjVqxCuvvGLuUkQ+UlcY1uv1REZGZthyI4oPk8NNnz59WL9+PR9//DGOjo5Mnz6dxo0bs379erp06ZIfNQphdrdu3WLr1q1AargpDqLio/g98Hd+DviZkKgQ7Xj36t2Z2Gwi3ap3y7dVgwuTKlWqaLOnRPFlbW2Nm5sbkZGRhIeHS8tNMZej9uU2bdqwbdu2vK5FiELrzz//xGAw0KpVK2rUqGHucnLlVNgpZgfM5s/TfxKfEg9AKbtSjGk4hpebvkx1N1mJVRRP7u7uWriRlpvizeRwExAQgMFgoHnz5kbHjxw5gqWlpdFGY0IUF3/++ScAo0ePNm8hOWRQDGy4uIHvDn3Hnqt7tONPuT/FxKYTGd5gOI42uVtAUIjCzt3dnaCgIC5fvkxEROrGrdJyUzyZ3Ob8yiuvcP369XTHb968KX3WoljS6/XaSqb+/v5mrsY08cnxzDs+j7qz69L7797suboHKwsrhtQbwt7Rewl8IZDn/Z6XYCNKBHU6+LFjxwBwcXGhVKlSZqxI5BeTW27OnTtH48aN0x1v1KiR9gYgRHFy79499Ho9Op2OChUqmLucbLkbe5efA35mdsBsbW0aV1tXXvB7gVebv1qsBwgLkRl1xlRAQAAgrTbFmcnhxtbWlvDw8HS75d6+fRsrq+I1RVQISP23DVC2bFmsra3NXE3WLkRcYObhmSw6tYiElAQAqrhW4Y2n32Bco3E42zqbuUIhzEcNN6dPnwZkvE1xZnIa6dq1K1OnTmXt2rW4uqZuhnf//n3+97//yWwpUSyFhYUB5Gqrhfx2+MZhvtj/BesvrNemcjep1IS3WrzFgLoDit3aNELkhNotpS44Ky03xZfJv/G+/fZb2rZti5eXl7ZoX2BgIO7u7vzxxx95XqAQ5qa23BS2LilFUdh9ZTef7vuUnZd3asd71ezFWy3fok2VNoVynychzEVtuVFJuCm+TA43lStX5vTp0/z111+cOnUKe3t7xowZw7Bhwwp9k70QOVHYWm4URWHjpY18tu8zDt04BICVhRUjnhrBO63eoXbZ2mauUIjC6fFwI91SxVeO2qodHR2ZMGFCXtciRKFUWFpuDIqBVUGr+GzfZwSGBQJga2nL+Mbjebvl23iVkl/UQmRF7ZZSSctN8ZWtcLNu3Tq6d++OtbU169aty/Jc2VVXFDdquDFXy41BMbA6aDUf7vmQM3fOAOBo7chLTV5icovJVHQuHC1KQhR20nJTcmQr3PTt25ewsDDKly9P3759Mz1Pp9Oh1+vzqjYhCgVzdUspisL6i+v5YPcHWkuNq60rrzd/ndeav0YZhzIFWo8QRZ2DgwNOTk48fPgQKyurQtPVLPJetsKNwWDI8HMhSoKC7pZSFIXNwZuZvns6x26lLjbmbOPMpKcn8cbTb1DavnSB1CFEcVS+fHkePnyIh4cHlpaW5i5H5BOTVihOTk6mU6dOXLp0Kc8KmD17Nt7e3tjZ2dG8eXOOHj2a5fn379/nlVdeoWLFitja2lKzZk02btyYZ/UI8biCbLnZfWU3rRa0oseSHhy7dQwHawemtJrC5dcv83GHjyXYCJFLateUjLcp3kwaUGxtba0tfpQXli1bxuTJk5k7dy7Nmzdn1qxZ+Pv7c+HChXQDvwCSkpLo0qUL5cuXZ8WKFVSuXJmrV6/K8tki1wwGAy+99BLOzs58++232vGHDx/y8OFDIH9bbk6FnWLKjilsDt4MgJ2VHS83eZl3W79Lecf0/y8IIXJGDTcy3qZ4M3m21HPPPcdvv/3Gl19+mesnnzFjBs8//zxjxowBYO7cuWzYsIEFCxYwZcqUdOcvWLCAyMhIDh48qE079/b2znUdQpw+fZp58+YBMH78eGrXTp1OrbbaODo64uyc96v7Xrl/hem7pvPn6T9RULCysGJC4wlMaztNBgoLkQ88PFK3Hnl8lX1RvJgcblJSUliwYAHbt2/Hz88PR0fjDfdmzJiRrfskJSVx/Phxpk6dqh2zsLCgc+fOHDp0KMNr1q1bR4sWLXjllVdYu3Yt5cqVY/jw4bz77ruZ9p0mJiaSmJiofR0TE5Ot+kTJkvbf3MqVK3nvvfeA/JspFREXwef7Pmd2wGyS9EkADKk3hE87fkp1t+p5+lxCiEcmT56Ms7MzL774orlLEfnI5HBz5swZbePMixcvGj1mymqoERER6PX6dFPz3N3dOX/+fIbXhIaGsnPnTp599lk2btxIcHAwL7/8MsnJyXzwwQcZXvPFF1/w0UcfZbsuUTKcP3+e4OBgevbsCWQebtSWm7zqkkpMSWTW4Vl8vv9zYhJTg3ZHn4581fkrmlRqkifPIYTInI+PD59//rm5yxD5zORws2vXrvyoI1sMBgPly5dn3rx5WFpa4ufnx82bN/nmm28yDTdTp05l8uTJ2tcxMTF4enoWVMmiEFIUhZ49exISEsKePXto27atUbg5efIkISEhVKtWLc9abhRFYe2Ftby59U1Co0IB8HX35avOX9G1WlfZJkEIIfKQSbOlli1bxrPPPsugQYOYO3durp64bNmyWFpaEh4ebnQ8PDw807+SK1asSM2aNY26oOrUqUNYWBhJSUkZXmNra4uLi4vRhyjZgoKCCAkJAVL/Td+5c4fg4GAAmjRJbT1ZuXIlkDfTwM/cOUOXP7rQb1k/QqNCqehUkUV9F3HihRP4V/eXYCOEEHks2+Fmzpw5DBs2jGPHjnHp0iVeeeUV3n777Rw/sY2NDX5+fuzYsUM7ZjAY2LFjBy1atMjwmlatWhEcHGy01s7FixepWLEiNjY2Oa5FlCybN2/WPl+1ahUHDx4EUoPyuHHjAFixYgWQu2ng9+LuMXHjRHzn+rLj8g5sLW15r817XHz1IiN9R2KhM+lvCyGEENmlZFPdunWVDz/8UPv6jz/+UBwcHLJ7eYb+/vtvxdbWVlm4cKFy7tw5ZcKECUqpUqWUsLAwRVEUZcSIEcqUKVO0869du6Y4OzsrEydOVC5cuKD8+++/Svny5ZVPP/00288ZHR2tAEp0dHSuahdFV5cuXRRA+2jdurUCKGPHjlXCwsIUnU6nAMqVK1cUf39/BVAWLFiQ7fun6FOUn478pJT+srTChyh8iDJg2QAlNDI0H1+VEEIUb6a8f2d7zE1oaCijRo3Svh4+fDjjxo3j9u3bOR6PMGTIEO7evcv06dMJCwujYcOGbN68WRtkfO3aNSwsHv116+npyZYtW3jjjTd46qmnqFy5Mq+//jrvvvtujp5flDyxsbHs2bMHgObNm3PkyBH2798PQMuWLXF3d6dt27bs2bOHRYsWmdxyc+TGEV7a8BInw04C8JT7U8zyn0UHnw758GqEEEJkRKcoipKdEy0sLAgPD6dcuXLaMWdnZ06dOlWk1guIiYnB1dWV6OhoGX9TAm3YsIGePXvi5eXFDz/8QJ8+fbTHzp49S926dfn7778ZNmwY5cuXJyUlhcjISAIDA/H19c30vpHxkUzdPpX5J+ajoFDKrhSfdfyMCX4TsLIwedy+EEKIx5jy/m3Sb933338fBwcH7eukpCQ+++wzXF1dtWPZXedGCHNQx9t069aNrl27apvolSpVSlu4b8CAAXh6enL9+nXtuswGFBsUA4sCF/HO9neIiIsAYJTvKL7u8rWsLCyEEGaS7XDTtm1bLly4YHSsZcuWhIaGal/LrA9R2Knhpnv37tjZ2dGrVy+WLl1K8+bNtS5Qa2trXnvtNW3AvKWlJWXLlk13r//C/+OlDS9x4PoBAOqVq8fPz/xMW6+2BfRqhBBCZCTb3VLFhXRLlVyhoaFUq1YNKysrIiMjtW7VcePG8dlnn+Hv76+dGx0djYeHBw8fPqRixYrcunVLeywxJZFP9n7CVwe+IsWQgqO1Ix+2/5DXm7+OtaW1OV6aEEIUe/nWLSVEUaa2MtaqVUvbJ8rX15djx46lO9fV1ZXx48cza9Yso8HEh64fYty6cQRFBAHQv05/ZvnPwtNVFoYUQojCQsKNKDHi4+MBcHJyytb5U6ZM4eLFiwwfPpzYpFje2/kePxz5AQUFd0d3fn7mZ/rX6Z+fJQshhMgBCTeixIiLiwMwGhSfFXd3dzZs2MDB6wfxnetLSFTqqsajfEcxw38GbvZu+VarEEKInJNwI0oMU8NNkj6JD3d/yFcHvsKgGPB08WRer3l0q94tP8sUQgiRSyaHm+TkZKytMx40GRERkeGsEiEKAzXc2NvbP/Hcs3fO8tzq5wgMCwRgpO9Ifuj2A652rllfKIQQwuxM3txm6NChZDTBKjw8nPbt2+dFTULkC3XMTVYtNwbFwIxDM/Cb50dgWCBl7MuwYtAKFvVdJMFGCCGKCJPDzbVr1xg/frzRsbCwMNq3b68tgiZEYfSkbqlr0dfovLgzb259k0R9Ij1q9ODMy2cYUHdAQZYphBAil0wONxs3buTgwYNMnjwZgFu3btGuXTsaNGjAP//8k+cFCpFXMgs3iqLwx6k/aDCnAbuu7MLB2oFfev7Cv8P+pYJTxisTCyGEKLxMHnNTrlw5tm7dSuvWrQH4999/ady4MX/99ZfRJpdCFDYZjbmJjI/khX9fYMW5FQC08GjB4n6Lqe5W3Sw1CiGEyL0czZby9PRk27ZttGnThi5duvDHH3/I1gui0Ht8zM2BawcYtnIY12OuY2VhxUftP+KdVu/IRpdCCFHEZeu3eOnSpTMML3Fxcaxfv54yZcpoxyIjI/OuOiHykNpyY2dvx5f7v2TazmnoFT013GqwdMBS/Cr5mblCIYQQeSFb4WbWrFn5XIYQ+S8uLg4c4bfE3zi34xwAwxsMZ+4zc3G2dTZzdUIIIfJKtsLNqFGj8rsOIfLdLYtb8CKcSzyHvZU9P/X4iTENx0iXqhBCFDMmDy7YuHEjlpaWRjsoA2zduhW9Xk/37t3zrDgh8srCwIUE1A8AC/Cw9WDz2M3UK1/P3GUJIYTIByZPb5oyZQp6vT7dcYPBwJQpU/KkKCHySoohhclbJjNm7RgUCwWC4Pv630uwEUKIYszkcHPp0iXq1q2b7njt2rUJDg7Ok6KEyAtR8VH0+KsHMw/PBKDsmbLwD5RxLvOEK4UQQhRlJocbV1dXQkND0x0PDg7G0dExT4oSIreC7gbR7NdmbAvdhoO1AysGrcAxwBGU7O0tJYQQougyOdz06dOHSZMmERISoh0LDg7mzTffpHfv3nlanBA5seHiBpr/2pzgyGC8XL04OPYgA+oOMHlXcCGEEEWTyeHm66+/xtHRkdq1a+Pj44OPjw916tShTJkyfPvtt/lRoxDZoigKX+3/il5Le/Eg6QFtvdoS8HwAvhV8gextnCmEEKLoM3m2lKurKwcPHmTbtm2cOnUKe3t7nnrqKdq2bZsf9QmRLfHJ8YxfP54l/y0B4EW/F/m++/fYWNoAqcEno+0XhBBCFD85Wmdep9PRtWtXunbtmtf1CGGyGzE36Pt3X47fPo6VhRU/dPuBl5q+ZHROUlISBoMBkJYbIYQo7nK00+WePXvo1asX1atXp3r16vTu3Zt9+/bldW1CPNGh64doMq8Jx28fp4x9GbaP2J4u2MCjrRdAwo0QQhR3JoebP//8k86dO+Pg4MBrr73Ga6+9hr29PZ06dWLJkiX5UaMQGfrn7D+0X9Se8NhwGpRvQMDzAbTzbpfhuep4GysrK6ytrQuwSiGEEAVNpyiKYsoFderUYcKECbzxxhtGx2fMmMH8+fMJCgrK0wLzWkxMDK6urkRHR+Pi4mLuckQOzTw0k8lbJwPQt3Zf/uj3B042TpmeHxwcTI0aNXB2diYmJqagyhRCCJFHTHn/NrnlJjQ0lF69eqU73rt3by5fvmzq7YQwiUEx8OaWN7Vg82qzV1kxaEWWwQaQaeBCCFGCmBxuPD092bFjR7rj27dvx9PTM0+KEiIjiSmJDF85nBmHZwDwdeev+b7b91haWD7xWgk3QghRcpg8W+rNN9/ktddeIzAwkJYtWwJw4MABFi5cyPfff5/nBQoBEJccR6+lvdh5eSfWFtYs7LuQ4Q2GZ/t6WeNGCCFKDpPDzUsvvUSFChX47rvv+Oeff4DUcTjLli2jT58+eV6gEGmDjbONM2uGrqGjT0fT7iFr3AghRImRo3Vu+vXrR79+/fK6FiHSSUhJoO/ffbVgs3XEVp72eNrk+0i3lBBClBwmj7mpWrUq9+7dS3f8/v37VK1aNU+KEgJSx9j0W9aPbaHbcLR2ZNOzm3IUbEDCjRBClCQmh5srV66g1+vTHU9MTOTmzZt5UpQQSfokBi4fyObgzThYO7Dx2Y20qtIqx/eTcCOEECVHtrul1q1bp32+ZcsWXF1dta/1ej07duzA29s7T4sTJVOyPpnBywfz78V/sbey599h/9LWK3d7l6kDimXMjRBCFH/ZDjd9+/YFUveVGjVqlNFj1tbWeHt789133+VpcaLkSdYnM2zlMNZeWIudlR3rhq2jg0+HXN9XWm6EEKLkyHa4UTcd9PHxISAggLJly+ZbUaJkSjGk8Nzq51gZtBIbSxvWDFlD56qd8+TeEm6EEKLkMHm2lKxCLPKD3qBn5OqR/HP2H6wtrFk1eBX+1f3z7P4SboQQouTI9oDiQ4cO8e+//xodW7x4MT4+PpQvX54JEyaQmJiY5wWK4k9v0DNm7RiWnlmKlYUVKwav4Jmaz+Tpc8iYGyGEKDmyHW4+/vhjzp49q33933//MW7cODp37syUKVNYv349X3zxRb4UKYqvJH0SI1aP4I/Tf2Cps+Sfgf/Qu1bvPH8eabkRQoiSI9vhJjAwkE6dOmlf//333zRv3pz58+czefJkfvjhB23FYiGyIzYplj5/99FabP4e+Df96uTP4pASboQQouTI9pibqKgo3N3dta/37NlD9+7dta+bNm3K9evX87Y6UWw9SHxA97+6c+D6ARysHVg5eCXdqnfLt+eTcCOEECVHtltu3N3dtcHESUlJnDhxgqeffrRa7IMHD7C2ts77CkWx8yDxAd3+6saB6wdwtXVl24ht+RpsQMbcCCFESZLtcNOjRw+mTJnCvn37mDp1Kg4ODrRp00Z7/PTp01SrVi1fihTFx8Okh3T7qxsHrx+klF0pdozcQUvPlvn+vNJyI4QQJUe2u6U++eQT+vfvT7t27XBycmLRokXY2Nhojy9YsICuXbvmS5GieEgxpDBs5TAt2GwfsR2/Sn4F8twSboQQouTIdrgpW7Yse/fuJTo6GicnJywtLY0eX758OU5OTnleoCgeFEXh9U2v8+/Ff7GzsmPj8I0FFmxAwo0QQpQkJi/il3ZPqbTc3NxyXYwovn448gM/H/sZHTr+7PcnLTxbFOjzy5gbIYQoOUzeFVwIUx2+cZi3tr0FwDddvmFA3QEFXoO03AghRMkh4Ubkq3tx9xi8fDAphhSG1BvC5BaTzVKHhBshhCg5JNyIfGNQDIxaM4rrMdep4VaDeb3modPpCryO5ORkUlJSAAk3QghREki4Efnmu4PfseHSBmwtbfln0D+42LqYpQ611QZkzI0QQpQE2R5QvG7dumyd17t33u8LJIqeA9cOMHXHVAC+7/Y9DSs0NFst6mBinU6Hra2t2eoQQghRMLIdbvr27fvEc3Q6HXq9Pjf1iGIgIi6CoSuHolf0DKs/jAl+E8xaT9rxNuboFhNCCFGwsh1uDAZDftYhigmDYmDE6hHciLlBzTI1+aXnL2YPFDKYWAghShYZcyPy1Ff7v2Jz8GbsrOxYPmg5zrbO5i5JCzcy3kYIIUqGbLfc7N27N1vntW3bNsfFiKJt79W9TNs1DYCfuv/EU+5PmbmiVOqYG2m5EUKIkiHb4aZ9+/Za94KiKBmek9MxN7Nnz+abb74hLCwMX19ffvzxR5o1a/bE6/7++2+GDRtGnz59WLNmjcnPK/LOndg7DF0xFINiYKTvSMY2GmvukjTSLSWEECVLtrulSpcujaenJ++//z6XLl0iKioq3UdkZKTJBSxbtozJkyfzwQcfcOLECXx9ffH39+fOnTtZXnflyhXeeusto53JhXnoDXqeXfUstx/epm65uvzc42ezj7NJS8KNEEKULNkON7dv3+arr77i0KFDNGjQgHHjxnHw4EFcXFxwdXXVPkw1Y8YMnn/+ecaMGUPdunWZO3cuDg4OLFiwINNr9Ho9zz77LB999BFVq1Y1+TlF3vps32dsD92Og7UDywctx9HG0dwlGZExN0IIUbJkO9zY2NgwZMgQtmzZwvnz53nqqaeYOHEinp6evPfee9oKsKZISkri+PHjdO7c+VFBFhZ07tyZQ4cOZXrdxx9/TPny5Rk3bpzJzyny1voL6/lw94cAzHlmDnXL1TVvQRmQMTdCCFGy5Gi2VJUqVZg+fTrbt2+nZs2afPnll8TExJh8n4iICPR6Pe7u7kbH3d3dCQsLy/Ca/fv389tvvzF//vxsPUdiYiIxMTFGHyJvHL91nKErh6Kg8ILfC4z0HWnukjIk3VJCCFGymBxuEhMTWbJkCZ07d6Z+/fqULVuWDRs24Obmlh/1GXnw4AEjRoxg/vz5lC1bNlvXfPHFF0bdZp6envlcZclw9f5Vei7tSVxyHF2rdeXH7j+au6RMSbgRQoiSJduzpY4ePcrvv//O33//jbe3N2PGjOGff/7JVagpW7YslpaWhIeHGx0PDw+nQoUK6c4PCQnhypUr9OrVSzumLi5oZWXFhQsXqFatmtE1U6dOZfLkRztRx8TESMDJpRO3T9BzSU/CHoZRv3x9/hn4D9aW1uYuK1My5kYIIUqWbIebp59+mipVqvDaa6/h5+cHpHYRPc6UvaVsbGzw8/Njx44d2vYOBoOBHTt2MHHixHTn165dm//++8/o2LRp03jw4AHff/99hqHF1tZW9hPKQ/9e/JchK4YQlxxHvXL12Dh8I652pg8kL0jSciOEECVLtsMNwLVr1/jkk08yfTwn69xMnjyZUaNG0aRJE5o1a8asWbOIjY1lzJgxAIwcOZLKlSvzxRdfYGdnR/369Y2uL1WqFEC64yLvBUcGM2j5IBJSEuhStQvLBy0v9MEGZECxEEKUNGbfW2rIkCHcvXuX6dOnExYWRsOGDdm8ebM2yPjatWtYWMguEeZmUAyMXzeehJQEOvp0ZMPwDYW6KyqtBw8eABJuhBCipDCp5Sa/TJw4McNuKIDdu3dnee3ChQvzviCRzq8nfmXP1T04WDswv9f8IhNsAK5evQogY62EEKKEMLlJZPny5fTv35/69etTv359+vfvz4oVK/KjNlFI3Hpwi7e3vQ3Apx0+pWrporVwYnBwMADVq1c3cyVCCCEKQrbDjcFgYMiQIQwZMoRz585RvXp1qlevztmzZxkyZAhDhw7NdM8pUbR9vOdjYhJjaFqpKa81f83c5ZgkNjZWWzPp8Zl0Qgghiqdsd0t9//33bN++nXXr1tGzZ0+jx9atW8eYMWP4/vvvmTRpUl7XKMwoNCqU307+BsB3Xb/D0sLSzBWZJiQkBAA3NzdKly5t5mqEEEIUhGy33Pz+++9888036YINpE7//vrrr7PcD0oUTR/v+ZgUQwr+1fxp41X0NilVw4202gghRMmR7XBz6dIloz2gHte5c2cuXbqUJ0WJwiHobhB/nP4DgE86ZL4EQGEm422EEKLkyXa4sbe35/79+5k+HhMTg52dXV7UJAqJj/Z8hEEx0KdWH5pWbmrucnJEWm6EEKLkyXa4adGiBXPmzMn08dmzZ9OiRYs8KUqY34WIC/xz9h8APmr/kZmryTlpuRFCiJIn2wOK33vvPdq3b8+9e/d46623qF27NoqiEBQUxHfffcfatWvZtWtXftYqCtCXB75EQaF3rd74VvA1dzlPdPDgQXbu3Mm7776LtfWjNXik5UYIIUqebIebli1bsmzZMiZMmMDKlSuNHitdujRLly6lVatWeV6gKHhX7l/hj1OpY23ea/Oemat5MkVRGD58OFevXqV8+fJMmDABgKSkJK5duwZIy40QQpQkJq1Q3K9fP/z9/dmyZYs2eLhmzZp07dpVlrYvRr4+8DV6RU/nqp1pVrmZuct5oiNHjmirEC9atEgLN1euXMFgMODo6Kht5yGEEKL4M3n7BQcHB/r165cftYhC4Hr0dW1dm2ltppm5muxZtmyZ9vnBgwe5ePEiNWvW1MbbVKtWDZ1OZ67yhBBCFLBsDyjeuXMndevWJSYmJt1j0dHR1KtXj3379uVpcaLgvbfzPZL0SbTzakdbr7bmLueJDAYDy5cvB6Bs2bJAausNyHgbIYQoqbIdbmbNmsXzzz+Pi4tLusdcXV154YUXmDFjRp4WJwrWidsntHVtvu36bZFo7Th48CA3b97ExcWFmTNnArB48WL0er3MlBJCiBIq2+Hm1KlTdOvWLdPHu3btyvHjx/OkKFHwFEXhza1vAvBsg2dpUqmJmSvKHrVLqm/fvgwcOJBSpUpx48YNdu3aJS03QghRQmU73ISHhxtNsX2clZUVd+/ezZOiRMH79+K/7L6yG1tLWz7r+Jm5y8kWvV6v7Ug/ZMgQ7OzsGDZsGACDBw/Wukml5UYIIUqWbIebypUrc+bMmUwfP336NBUrVsyTokTBik+O5/XNrwMw6elJeJXyMnNF2XPmzBnCwsJwcXHRtgZ59913qVmzJlFRUdr4MGm5EUKIkiXb4aZHjx68//77JCQkpHssPj6eDz74IMNNNUXh98X+L7h8/zIeLh5Ma1s0ZkgBXL58GUhdjsDGxgYALy8vzp07x9q1a+nRowcvvPACXl5FI6wJIYTIG9meCj5t2jRWrVpFzZo1mThxIrVq1QLg/PnzzJ49G71ez3vvFf4F34SxS/cu8dWBrwCY5T8LJxsnM1eUferaNo+HF0tLS3r37k3v3r3NUZYQQggzy3a4cXd35+DBg7z00ktMnToVRVEA0Ol0+Pv7M3v2bFkorYhRFIWXN75Mkj6JbtW70b9Of3OXZBJ19WFpmRFCCJGWSYv4eXl5sXHjRqKioggODkZRFGrUqEHp0qXzqz6Rj+Yem8v20O3YWdnxY/cfi8TU77Qya7kRQghRsmV7zE1apUuXpmnTpjRr1kyCTREVHBnMW9veAuDLTl9S3a1gZhRFRUXRoUMHXn/9dWJjY3N1L7XlpkqVKnlRmhBCiGIiR+FGFG16g55Ra0YRlxxHB+8OvNr81QJ77hUrVrB7925++OEHGjdunKu1kaTlRgghREYk3JQwiqLw8oaXOXj9IM42zvze53csdAX3z2Dz5s0AWFhYcPHiRdq0aaOFFFPEx8dz584dQMKNEEIIYxJuSpjpu6Yz78Q8dOhY2Hdhga5pk5yczPbt2wHYsGEDjRo1Ij4+npUrV5p8r+vXrwPg6OgoXaNCCCGMSLgpAUKjQplxaAY9l/Tk032fAjDnmTkFPjvqyJEjxMTE4ObmRpcuXRg1ahQA69evN/leabukitpAaCGEEPnLpNlSouiJS46j8S+NiU6M1o593P5jXmjyQoHXonZJde3aFUtLS3r16sWkSZPYt28fUVFRJrXAyHgbIYQQmZGWm2Lu+K3jRCdGU8quFF93/poTE07wfrv3zVLLli1bALQNWKtWrUrdunXR6/Va8FFt27aNESNGEBUVleG9ZKaUEEKIzEi4KeYO3zgMQAfvDrzd6m0aVWxkljru3r2rzYzq2rWrdrxXr16AcddUSkoK48aN488//2TOnDkZ3k9aboQQQmRGwk0xd/hmarhp4dHCrHVs27YNRVHw9fU12mBVDTebNm0iOTkZgLVr12oDhjMbjyPhRgghRGYk3BRjiqJw6PohAJ72eNqstajdTmqXlOrpp5+mbNmy3L9/nwMHDgDwww8/aI8fOXJEm/KdlnRLCSGEyIyEm2Lsesx1bj+8jaXOEr9Kfmarw2AwaONt/P39jR6ztLSkR48eAHzwwQfs27ePvXv3YmlpSdWqVVEUhY0bNxpdo9frtZYdabkRQgjxOAk3xZg63sa3gi8O1g5mq+PUqVPcuXMHR0dHWrVqle7x1157DUdHR/bu3UvHjh0B6N+/PyNGjADSd02FhYWRkpKCpaUllSpVyv8XIIQQokiRcFOMqeHG3ONt1C6pTp06YWNjk+5xPz8/9u7dS4UKFUhJSQHg1Vdf1cbjbN26lcTERO18dbyNh4cHlpaW+V2+EEKIIkbCTTGmhhtzj7fJrEsqrcaNG3P48GHatGnD8OHDad26NY0bN6ZSpUo8fPiQ3bt3a+fKYGIhhBBZkUX8iqnElERO3D4BmDfcxMTEaAOFHx9M/DgvLy/27t1rdKxnz57MmzePt99+m507d1KqVCm2bt2qnS+EEEI8TsJNMXUq/BSJ+kTKOpSlWulqZqtj586dpKSkUKNGDapWrWry9YMHD2bevHn8999//Pfff0aP1atXL6/KFEIIUYxIuCmmDlxLbS1pXrm5Wfdeyk6XVFY6derEkSNHCAgI4Ny5c8TGxuLh4UG1atUYOnRoXpYqhBCimJBwU0xtv5y6+3Z77/Zmq0FRlEzXtzFFs2bNaNasWV6VJYQQopiTAcXFUJI+iT1X9gDQpWoXs9URHR3NlStXAGjbtq3Z6hBCCFGySLgphg5dP0RscizlHcvTwL2B2epQVxZ2cXHB2dnZbHUIIYQoWSTcFEPbQ1O7pDpX7YyFznw/4vDwcADKly9vthqEEEKUPBJuiqFtodsA6OzT2ax1qC03Em6EEEIUJAk3xUxUfBQBtwIA6FLNfONt4FHLjbu7u1nrEEIIUbJIuClmdl3ZhUExULtsbTxcPMxai7TcCCGEMAcJN8XMtpDC0SUF0nIjhBDCPCTcFCOKorApeBNg/i4pkJYbIYQQ5iHhphgJuBXA1eirOFo70rmqtNwIIYQomSTcFCP/nP0HgF61euFg7WDmaqTlRgghhHlIuCkmFEVh+bnlAAyuO9jM1aSScCOEEMIcJNwUE0dvHuVa9DWcbJzoVt14H6c1a9awdu3aAq0nISGB6OhoQLqlhBBCFCzZOLOY0LqkavbC3tpeOx4REcHAgQNRFIWrV6/i4VEw08Pv3r0LgLW1NaVKlSqQ5xRCCCFAWm6KBaMuqXrGXVIBAQHo9XoMBgNr1qwpsJrSbr2g0+kK7HmFEEIICTfFwMLAhVyPuZ5hl9SxY8e0z1etWlVgNcl4GyGEEOYi4aaIO3PnDK9sfAWAqa2nYmdlZ/R4QECA9vmePXu07qL8JtPAhRBCmIuEmyLsYdJDBi0fRHxKPP7V/JnSeorR44qiaOHGyckJg8HAunXrsn1/RVFISUnJUW3SciOEEMJcJNwUYe9ue5fzEeep7FyZP/r9gYXO+Md58+ZNwsLCsLS05LXXXgNSu6YMBgN79+4lLCwsy/u/9dZbODo6cvr0aZNrSzvmRgghhChIhSLczJ49G29vb+zs7GjevDlHjx7N9Nz58+fTpk0bSpcuTenSpencuXOW5xdXp8JOMff4XAAW91tMOcdy6c5Rx9vUr1+f5557DoBt27bh6+tLu3btqFmzJvPmzUNRlHTX3r17l59++omkpCRWr15tcn1qy410SwkhhChoZg83y5YtY/LkyXzwwQecOHECX19f/P39tTfHx+3evZthw4axa9cuDh06hKenJ127duXmzZsFXLn5KIrCpC2TMCgGBtUdREefjhmep3ZJNWnShDp16lC7dm2Sk5M5c+YMFhYWPHjwgBdeeIFu3bqRkJBgdO3ChQtJSkoC4PDhwybXKN1SQgghzMXs4WbGjBk8//zzjBkzhrp16zJ37lwcHBxYsGBBhuf/9ddfvPzyyzRs2JDatWvz66+/YjAY2LFjRwFXnr/mBMxhdVDGLSYrg1ay+8pu7Kzs+KbLN5neQw03TZs2BeCjjz6ifv36fPTRR9y5c4eZM2dib2/P1q1bmT9/vnadwWDgl19+0b4+evRohq07WZEBxUIIIczFrOEmKSmJ48eP07nzo00eLSws6Ny5M4cOHcrWPeLi4khOTsbNzS2/yixw16Ov8/LGlxm8YjA3Y4xbpGKTYnlr61sAvNPyHbxKeWV4D0VRtG6pJk2aADB48GD+++8/pk+fTpkyZZg0aRLfffcdAF9++aXWerN9+3ZCQkJwcXHB1taWyMhIgoODTXoN0nIjhBDCXMwabiIiItDr9en+und3d3/iYFfVu+++S6VKlYwCUlqJiYnExMQYfRR29+LvAZBiSOHngJ+NHpu+azpXo69SxbUK77R6J9N7hISEEBUVhY2NDQ0aNMj0vLFjx+Lh4cGtW7f47bffAJg7N3Usz8iRI2ncuDEAR44cyXb9BoNBm3IuLTdCCCEKmtm7pXLjyy+/5O+//2b16tXY2dlleM4XX3yBq6ur9uHp6VnAVZouNilW+/yX478QnxwPwLFbx5h1ZBYAc5+Zi6ONY6b3UFttGjZsiI2NTabn2draMmVK6hTyL774gtGjR2srGb/wwgs0b94cMC3cREZGotfrAShbtmy2rxNCCCHyglnDTdmyZbG0tNTGZ6jCw8OpUKFCltd+++23fPnll2zdupWnnnoq0/OmTp1KdHS09nH9+vU8qT0/xSY/Cjf34u+x5L8lJKQk8Pz65zEoBobVH0b3Gt2zvMfZs2cB8PX1feLzjRs3jkqVKnHz5k0WLVqEoii8/vrr1K9f36Rws2nTJl599VXtuUuXLp1lsBJCCCHyg1nDjY2NDX5+fkaDgdXBwS1atMj0uq+//ppPPvmEzZs3a+NJMmNra4uLi4vRR2GXtuUG4OO9H1Pzx5oEhgXiZu/GrG6znngPdYxMzZo1n3iunZ0dX375JQBt27bl8OHDzJqV+hxquAkMDEw3o+pxr776Kj/99BO9evUCpEtKCCGEeZi9W2ry5MnMnz+fRYsWERQUxEsvvURsbCxjxowBUsd9TJ06VTv/q6++4v3332fBggV4e3sTFhZGWFgYDx8+NNdLyHMPk1JfS9NKTXG0duRa9DWux1ynsnNllg5YSnnHJw/SvXTpEgDVq1fP1nOOGDGChw8fsnv3bi3QAHh7e1OuXDmSk5M5efJkptdHREQQEhICwIMHDwAZTCyEEMI8zB5uhgwZwrfffsv06dNp2LAhgYGBbN68Wfur/9q1a9y+fVs7f86cOSQlJTFw4EAqVqyofXz77bfmegl5Tu2WquxSmc87fU7dcnWZ0XUGwa8F07Va1yderyiKFm5q1KiR7ed1dHRMt4O3Tqfj6aefBrLumlIXUvTy8sLPzw+AqlWrZvu5hRBCiLxiZe4CACZOnMjEiRMzfGz37t1GX1+5ciX/CzIztVvKycaJ15q/xmvNXzPp+oiICGJiYtDpdFSrVi3X9TRv3pz169ezYsUKXnjhBezt7dOdo4abdu3a8fPPP7N8+XL8/f1z/dxCCCGEqczeciPSU1tuHK0znw2VFbXVxsPDI9NZZKbo168fNjY2HDhwgE6dOmW4s7jaqtOsWTMcHR0ZPXo0FStWzPVzCyGEEKaScFMIqWNuchtuTOmSykrdunXZvn07pUuX5tChQ7Rr147ExETtcUVRtJabtON1hBBCCHOQcFMIqd1SWa1jkxV1plRehRuANm3acPDgQcqUKUNQUBB79+7VHgsJCSEyMhJbW9ssp+ULIYQQBUHCTSGkdks52Tjl6Pq8brlR1a5dm549ewIYTd9XW20aNWok69oIIYQwOwk3hVBux9yoLTfZnQZuik6dOgHG4SbteBshhBDC3CTcFEK56ZbK6TTw7FLDzYkTJ4iKigKQ8TZCCCEKFQk3hVBuBhTfvXtXmwaeH+vMVKpUidq1a2MwGNizZw9JSUna4n7SciOEEKIwKBTr3AhjmY25URSF0NBQjhw5QqVKlWjfvn26a9UuKU9PzzyZBp6RTp06cf78eXbs2EFMTAyJiYmUKVMmT9bUEUIIIXJLwk0hlFG3VEhICB07duTatWsAWFlZcfnyZTw8PIyuzc8uKVWnTp2YPXs269ev56+//gLgzTffTLe6sRBCCGEO0i1VCGU0oHjDhg1cu3YNGxsbHBwcSElJMZqOrcqPaeCPa9++PRYWFly9epWoqCgaNWrEW2+9lW/PJ4QQQphCwk0hpI25SdNyo7bITJo0iQkTJgCwf/9+7fHExEQuXrxIQEAAkD8zpVSlS5emcePGQGoL0oIFC7C2ts635xNCCCFMIeGmEEq7t5QqbYtM69atgUfhJiwsDA8PD2rVqsWWLVsAqFmzZr7WOGjQIABtw1MhhBCisJAxN4VMsj6ZZEMyYNwtlXbtmjp16gBw5swZoqKi+PPPP4mIiMDW1hYfHx8aNmxI586d87XON998kwEDBsggYiGEEIWOtNwUMup4G3jULZWcnMzly5eB1JYbd3d3atSogaIoHDp0iCVLlgDw/fffExQUxNKlSzPcuTsvWVpaSrARQghRKEm4KWTU8TZWFlbYWKZuZXD16lX0ej329vbaTttq19T8+fM5efIkVlZWDBw40DxFCyGEEIWIhJtCJqvxNtWqVcPCIvVHpoabNWvWANC9e3fKlClTgJUKIYQQhZOEm0Imo2ngGa1do4Yb1fDhwwugOiGEEKLwk3BTyGS0gF9GG2HWqFGDcuXKpZ7r6EivXr0KsEohhBCi8JJwU8hktK9URuFGp9NprTd9+/bF0TFnO4gLIYQQxY1MBc8jR4KO8PHqj3GwdmD528tzfB+tWyqDBfweX3V42rRpAHz44Yc5fj4hhBCiuJFwk0cCLweyMXkjVpG5+5Y+PqA4JSVFmwb++KrDjRs3ZtWqVbl6PiGEEKK4kW6pPOJZ1hMAvbU+V/d5fEDx1atXSUlJwc7OjsqVK+euSCGEEKIEkHCTR7zKewGg2CkkJSfl+D6PDyjOaBq4EEIIITIn75Z5xKeCj/b51fCrOb7P4wOKMxpMLIQQQojMyZibPOJg5wCJgC1cCb9CDY8aT7wmI2q3lDrmRh1MLOFG5CW9Xk9ycrK5yxBCCCM2NjZ50ksh4SYPWSZZorfVcy3iWo7voXVLPdZy8/hMKSFyQlEUwsLCuH//vrlLEUKIdCwsLPDx8cHGxiZX95Fwk4ds9DbEE8/NyJs5vsfjU8HVmVI+Pj6ZXiNEdqnBpnz58jg4OKDT6cxdkhBCAGAwGLh16xa3b9+mSpUqufr9JOEmD9kr9sQTT1h0WI7vkXbMjaIoXL2aOn7H29s7L0oUJZher9eCjexDJoQojMqVK8etW7dISUnB2to6x/eRAcV5yNEitbXlzoM7Ob5H2jE3kZGRxMamfl2lSpXcFyhKNHWMjYODg5krEUKIjKndUXp97pZVkXCTh5ytnQGIiI3I8T3STgW/cuUKAO7u7tjZ2eW6PiEA6YoSQhRaefX7ScJNHiplWwqAqISoHN8j7SJ+0iUlRPH24Ycf0rBhQ5Ouad++PZMmTTJ7HQXF29ubWbNmFchz5cf3VpiHhJs85GbvBkBMckyO76GNubF5FG68vLxyX5wQRVhYWBivvvoqVatWxdbWFk9PT3r16sWOHTuMzjt48CA9evSgdOnS2NnZ0aBBA2bMmJGuiVun06HT6Th8+LDR8cTERMqUKYNOp2P37t1G569ZsybPX9dbb72V7jU8yapVq/jkk0/yvJYnWb16NU8//TSurq44OztTr149oyBQmANSdpnreyvynoSbPFTOqRwAsYbYHN8j7d5SEm6EgCtXruDn58fOnTv55ptv+O+//9i8eTMdOnTglVde0c5bvXo17dq1w8PDg127dnH+/Hlef/11Pv30U4YOHYqiKEb39fT05Pfffzc6tnr1apycnPL9NSmKQkpKCk5OTiYP7nZzc8PZ2TmfKsvYjh07GDJkCAMGDODo0aMcP36czz77rNislZSUlLqqvDm+tyJ/SLjJQxVcKwAQR1yO75G2W0odcyPdUqIke/nll9HpdBw9epQBAwZQs2ZN6tWrx+TJk7WWl9jYWJ5//nl69+7NvHnzaNiwId7e3owfP55FixaxYsUK/vnnH6P7jho1ir///pv4+Hjt2IIFCxg1apTJNSYmJvLaa69Rvnx57OzsaN26NQEBAdrju3fvRqfTsWnTJvz8/LC1tWX//v3pWjtSUlJ47bXXKFWqFGXKlOHdd99l1KhR9O3bVzvn8a4Tb29vPv/8c8aOHYuzszNVqlRh3rx5RvW9++671KxZEwcHB6pWrcr7779vUjBZv349rVq14u2336ZWrVrUrFmTvn37Mnv2bAAWLlzIRx99xKlTp7RWsYULFwJw7do1+vTpg5OTEy4uLgwePJjw8PB092/atCl2dnaULVuWfv36ZVrLr7/+SqlSpTJt8Vq4cCGlSpVizZo11KhRAzs7O/z9/bl+/bp2jvp9//XXX/Hx8dHGND7+vU1MTOTdd9/F09MTW1tbqlevzm+//aY9fubMGbp3746TkxPu7u6MGDGCiIhHYy5XrFhBgwYNsLe3p0yZMnTu3FmbJCLyl4SbPOTh5gFAkkXO9pZSFMVoQLG03Ij8pigKsbGxBf7xeCtKZiIjI9m8eTOvvPIKjo6O6R4vVaoUAFu3buXevXu89dZb6c7p1asXNWvWZOnSpUbH/fz88Pb2ZuXKlUDqm/DevXsZMWKEid9FeOedd1i5ciWLFi3ixIkTVK9eHX9/fyIjI43OmzJlCl9++SVBQUE89dRT6e7z1Vdf8ddff/H7779z4MABYmJistUd9t1339GkSRNOnjzJyy+/zEsvvcSFCxe0x52dnVm4cCHnzp3j+++/Z/78+cycOTPbr69ChQqcPXuWM2fOZPj4kCFDePPNN6lXrx63b9/m9u3bDBkyBIPBQJ8+fYiMjGTPnj1s27aN0NBQhgwZol27YcMG+vXrR48ePTh58iQ7duygWbNmGT7P119/zZQpU9i6dSudOnXKtN64uDg+++wzFi9ezIEDB7h//z5Dhw41Oic4OJiVK1eyatUqAgMDM7zPyJEjWbp0KT/88ANBQUH88ssvWsve/fv36dixI40aNeLYsWNs3ryZ8PBwBg8eDMDt27cZNmwYY8eOJSgoiN27d9O/f/9s/9sXuaSUMNHR0QqgREdH5/m91x5aq/Ahiu5dXY6uT0hOUPgQhQ9R7sffV0qXLq0Ayn///ZfHlYqSKD4+Xjl37pwSHx+vHXv48KECFPjHw4cPs1XzkSNHFEBZtWpVlud9+eWXCqBERUVl+Hjv3r2VOnXqaF8DyurVq5VZs2YpHTp0UBRFUT766COlX79+SlRUlAIou3btSnd+Rh4+fKhYW1srf/31l3YsKSlJqVSpkvL1118riqIou3btUgBlzZo1Rtd+8MEHiq+vr/a1u7u78s0332hfp6SkKFWqVFH69OmjHWvXrp3y+uuva197eXkpzz33nPa1wWBQypcvr8yZMyfDehVFUb755hvFz88v0zoyeo09evRQAMXLy0sZMmSI8ttvvykJCQlZ3mPr1q2KpaWlcu3aNe3Y2bNnFUA5evSooiiK0qJFC+XZZ5/N9Lm9vLyUmTNnKu+8845SsWJF5cyZM5meqyiK8vvvvyuAcvjwYe1YUFCQAihHjhzRarW2tlbu3LljdG3a7+2FCxcUQNm2bVuGz/PJJ58oXbt2NTp2/fp1BVAuXLigHD9+XAGUK1euZFmvMJbR7ymVKe/f0nKTh7zLewOg2Cqk6FNMvl4dTAygT9ATFZU660pabkRJpZj4V66p5z/33HMcOnSI0NBQFi5cyNixY026HiAkJITk5GRatWqlHbO2tqZZs2YEBQUZndukSZNM7xMdHU14eLhRq4WlpSV+fn5PrCFtK5BOp6NChQrcufNova1ly5bRqlUrKlSogJOTE9OmTePatexvE+Po6MiGDRsIDg5m2rRpODk58eabb9KsWTPi4jLvhg8KCsLT0xNPT0/tWN26dSlVqpT2vQkMDMyyFQZSW6bmz5/P/v37qVev3hPrtbKyomnTptrXtWvXNnpOSP29Wq5cuUzvERgYiKWlJe3atcvw8VOnTrFr1y6cnJy0j9q1awOp/yZ8fX3p1KkTDRo0YNCgQcyfP1/7nS7yn4SbPOTt7p36iQXcjDB9CwZ1vI2tpS03r6deLwPcRH5ycHDg4cOHBf6R3YUEa9SogU6n4/z581meV7NmTYB0YUIVFBSknZNWmTJl6NmzJ+PGjSMhIYHu3btnq66cyqhrLS88vpKrTqfDYDAAcOjQIZ599ll69OjBv//+y8mTJ3nvvfe0QbSmqFatGuPHj+fXX3/lxIkTnDt3jmXLluWqdnt7+yee06ZNG/R6fbpxU7nxpJ/Fk+p6+PAhvXr1IjAw0Ojj0qVLtG3bFktLS7Zt28amTZuoW7cuP/74I7Vq1dK21BH5S8JNHnJxdIH//30RcjvE5OtlvI0oaDqdDkdHxwL/yO5CXW5ubvj7+zN79uwMB2KqG4B27doVNzc3vvvuu3TnrFu3jkuXLjFs2LAMn2Ps2LHs3r2bkSNHYmlpmf1v3v+rVq0aNjY2HDhwQDuWnJxMQEAAdevWzfZ9XF1dcXd3NxqIrNfrOXHihMk1pXXw4EG8vLx47733aNKkCTVq1NB+v+SGt7c3Dg7/196dR0VxrH8D/w7CsM0AArIpi4C4RNCgQohxiyiocYkG1+seNArGuCAx6gXNjeCKy1Xxl6gY1xuvghE1BhcMAlFAMRp1BIJiAqhREZGded4/eOmbkQFFlgnj8zlnzqGrqruf6uqBorq6W09oF7FYXO2W+44dO+LevXsKk3lv3LiBvLw84di4uLi89HZ4Nzc3nDx5EitXrsTatWtfGlt5eTmSk5OFZZlMhry8PHTs2PGV6+fs7Ay5XI7z588rzXd1dcWvv/4KOzs7ODo6KnyqOk4ikQg9e/bE8uXLceXKFYjFYkRGRr5yDOz18bulGliL0haoEFfg3sN7Ly/8An6AH2PVbdmyBT179oSbmxtWrFgBFxcXlJeXIyYmBtu2bcPNmzehr6+P7du3Y+zYsZgxYwb8/f1hYGCAM2fOICAgAB999JEw0fNF3t7eePjwIQwMDF4rPn19fcyaNQsBAQEwNjaGjY0NVq9ejcLCQkyfPr1O25ozZw5CQkLg6OiIDh06YPPmzXjy5Em9ntrarl07ZGVl4eDBg+jRoweOHz9e5z+wwcHBKCwsxODBg2Fra4u8vDxs2rQJZWVlGDBgAIDK31WZmZlITU1FmzZtIJVK4enpCWdnZ0yYMAEbNmxAeXk5Zs+ejT59+giX6IKCgtC/f384ODhg7NixKC8vx4kTJxAYGKgQw7vvvosTJ05g0KBB0NTUrPVhe1paWpgzZw42bdoETU1N+Pv745133qlxorIydnZ2mDx5MqZNm4ZNmzahS5cuuHv3Lh48eIDRo0fDz88PX3/9NcaNG4dFixbB2NgY6enpOHjwIL755hskJyfjzJkzGDhwIMzMzHDx4kU8fPiwTh0s9vp45KaBaZVXDg///vh3pflyuRyFxcqvUVfNueFn3DD2P/b29rh8+TL69euHBQsWoHPnzhgwYADOnDmDbdu2CeU++ugjnDt3DllZWejVqxfat2+PsLAwLFmyBAcPHqyxgyASiWBqaiq80+Z1hIaGYtSoUZg4cSJcXV2Rnp6OU6dOoWXLlnXaTmBgIMaNG4dJkybBw8MDEokEXl5e9Xr9yrBhwzBv3jz4+/uja9euSEhIwLJly+q0jT59+uC3337DpEmT0KFDBwwaNAi5ubn48ccf0b59ewDAqFGj4O3tjX79+qFVq1Y4cOAARCIRjh49ipYtW6J3797w9PSEvb29wqWsvn374tChQ/j+++/RtWtXvP/++7h06ZLSON577z0cP34cS5cuxebNm2uMV09PD4GBgRg/fjx69uwJiUTyWpfPtm3bho8++gizZ89Ghw4d4OvrK4xUWVlZIT4+HhUVFRg4cCCcnZ3x2WefwcjICBoaGjAwMMBPP/2EwYMHw8nJCUuXLsW6desa/dInqySius7Aa+by8/NhaGiIp0+fvvZ/arVp+VlL5LXMg7+FPzbPrP7l8/qXF34s+xHh7uGYOXimQt7x28fxwYEP0N2qO9rGtMWhQ4cQFhbGjwNnDaK4uBiZmZkKz/Vgf29yuRwdO3bE6NGj+cm5rygiIgKfffaZcMmSNS+1/Z6qy99vHrlpYFVvBr//7L7S/LhHcYAGsOWnLdXylF2W4pEbxt4cd+/exddff43bt2/j2rVrmDVrFjIzMzF+/HhVh8ZYs8KdmwYm1ay8s+lR4aNqeQVFBSiSVD4NNb0kvVq+sgnFPOeGsTeHhoYGIiIi0KNHD/Ts2RPXrl3D6dOneZ4GY3XEE4obmPBm8KLqzzP4IfkH4YgXGRQh+1E2rEyshPyqOTdapCU8npxHbhh7c1hbWyvcdcXqbsqUKZgyZYqqw2AqxiM3DazqzeBPy55Wy/vxlx//t6AB7D23VyE/v7jybeInj56s3JaxcZ0nJDLGGGNvOu7cNLCqN4MXVBRUy7v8h+LzKk5cPyH8XFpWis3HKicglz4rxVtvvYX//ve/9boFlDHGGHsTceemgZkbmAMACqn67d6/Ff4GANDPq5x0fC3vGoDKOyK6LumK+9L7QDnw+Qef4+rVq+jXr18TRc0YY4ypD+7cNDCrlpVzaEpbKD7aXC6XI08nDwAw3rHyzofH+o9RXFqMvsv74qb+TYCA+XbzEeIX8lpPSmWMMcYYd24aXBuTNgCAMs0yhfQkWRJIl4AKIHRiKFAMQAy8F/we4jTiAADjDcdj3fTqj49njDHG2Kvjzk0Da2veFgBAOiS8uA4AopOjAQA6BTowNjCGabEpACBFOwUA8E75O9g3b18TR8sYY4ypH+7cNLC/vhk8+1G2kJ6QmQAAsNKovGzV1birkGeZZ4m44LimCpExVoMpU6ZgxIgRwnLfvn1V8oTw2NhYiEQitX7KbkREBIyMjBpse3Z2dtiwYUODbe/v5sVzszEFBweja9euTbKvxsKdmwZmbGAM/P8rUnfu3xHSb+XdAgB0Nu0MAPi498cAAbp5uri87DI0W/AjhxhTZsqUKRCJRBCJRBCLxXB0dMSKFStQXl7e6Ps+cuTIK7/2QBUdkitXrsDHxwfm5ubQ0dFBu3bt4Ovri9u3byuU2717N3r06AE9PT1IpVL06dMH0dHRSuNv2bIliouLFfKSkpKENnix/N+lA5aUlIQZM2Y0+n6uXr2KYcOGwczMDDo6OrCzs8OYMWPw4MEDAH+/4/I6Fi5c+NI3tf/dceemEWiUVB7Wuw/uCmkPNCpP/N5OvQEAY/qMwfmR55H7r1xYGFs0fZCMNSPe3t7IyclBWloaFixYgODgYKxZs0Zp2dLSUqXpr8PY2BhSqbTBtteQoqOj8c4776CkpAT79u3DzZs3sXfvXhgaGiq8GHPhwoWYOXMmxowZg19++QWXLl3Ce++9h+HDh+Pf//53te1KpdJqbw3fsWMHbGxsGr1O9dGqVSvo6ek16j4ePnyI/v37w9jYGKdOncLNmzexa9cuWFlZCS/UbM6ICOXl5ZBIJDAxMVF1OPVDb5inT58SAHr69Gmj7UP/M31CMGhi2EQiIrqacZUQDEIw6Pa92422X8ZqU1RURDdu3KCioiJVh1InkydPpuHDhyukDRgwgN555x2F/H/9619kaWlJdnZ2RESUlZVFPj4+ZGhoSC1btqRhw4ZRZmamsI3y8nKaN28eGRoakrGxMQUEBNCkSZMU9tWnTx+aO3eusFxcXEyLFi2iNm3akFgsJgcHB/rmm28oMzOTACh8Jk+eTEREFRUVtHLlSrKzsyMdHR1ycXGhQ4cOKdTn+PHj1K5dO9LR0aG+ffvSrl27CAA9efJE6TF5/vw5mZqa0ogRI5TmV62XmJhIAGjTpk3VysyfP5+0tLQoKyuLiIjOnTtHAGjp0qXk6ekplCssLCRDQ0NatmwZ/fVPRlX5mmKsimPGjBlkZmZG2tra9NZbb9GxY8eIiGjXrl1kaGioUH7r1q1kb29PWlpa5OTkRN9++62QJ5fLKSgoiKytrUksFpOlpSXNmTNHyLe1taWwsDBhGQB9/fXXNGLECNLV1SVHR0c6evSowv6OHj1Kjo6OpK2tTX379qWIiIha6xQZGUmamppUVlamNL+286C4uJjmzJlDrVq1Im1tberZsyddunRJYf3r16/TkCFDSCqVkkQioffee4/S09OJqPr34NKlS2RqakqhoaG1xnLgwAHy8PAQjn9sbKxQpqoNT5w4Qa6urqSlpUXnzp2joKAg6tKli8L2duzYQZ06dSKxWEwWFhbk5+cn5D158oSmT59OpqamJJVKqV+/fpSamirkp6amUt++fUkikZBUKiVXV1dKSkpSGndtv6fq8vebR24aQW/TytGZ7+98DwD44j9fAKh8vk27Nu1UFhdjLyIiPC993uQfIqpX3Lq6ugojNGfOnIFMJkNMTAyio6NRVlYGLy8vSKVSxMXFIT4+HhKJBN7e3sJ669atQ0REBHbu3IkLFy7g8ePH1UYsXjRp0iQcOHAAmzZtws2bN7F9+3ZIJBJYW1vj8OHDAACZTIacnBxs3LgRABASEoJvv/0W4eHh+PXXXzFv3jz84x//wPnz5wEA9+7dw8iRIzF06FCkpqbi448/xueff15rHKdOncKff/6JRYsWKc2vmsty4MABSCQSzJw5s1qZBQsWoKysTIi7ysSJExEXF4esrCwAwOHDh2FnZwdXV9daY3qRXC7HoEGDEB8fj7179+LGjRsIDQ2t8TEXkZGRmDt3LhYsWIDr169j5syZmDp1Ks6dOyfEERYWhu3btyMtLQ1RUVFwdnauNYbly5dj9OjR+OWXXzB48GBMmDABjx8/BgBkZmbio48+wogRI3D16lXMnDkTS5YsqXV7FhYWKC8vR2RkpNJzuLbzYNGiRTh8+DB2796Ny5cvw9HREV5eXkI8f/zxB3r37g1tbW2cPXsWKSkpmDZtmtLLr2fPnsWAAQPw1VdfITAwsNaYAwICsGDBAly5cgUeHh4YOnQoHj1SfPfh559/jtDQUNy8eRMuLi7VtrFt2zb4+flhxowZuHbtGr7//ns4OjoK+T4+Pnjw4AFOnjyJlJQUuLq6on///kLdJkyYgDZt2iApKQkpKSn4/PPPoaWlVWvc9fbS7o+aaYqRm59v/EwIqhypSfg1gcTzxAojOYypgrL/iApKCoRRxab8FJQUvHLcf/2PVS6XU0xMDGlra9PChQuFfHNzcyopKRHW2bNnD7Vv357kcrmQVlJSQrq6unTq1CkiIrK0tKTVq1cL+WVlZdSmTZsaR25kMhkBoJiYGKVxKhvJKC4uJj09PUpISFAoO336dBo3bhwRES1evJg6deqkkB8YGFjrCMKqVasIAD1+/FhpfhVvb+9q/4H/lYGBAc2aNata/CNGjKDly5cTEVG/fv1o48aNFBkZWaeRm1OnTpGGhgbJZDKl+S+O3Lz77rvk6+urUMbHx4cGDx5MRETr1q0jJycnKi0tVbo9ZSM3S5cuFZYLCgoIAJ08eZKIKo9x586dFbaxZMmSl45GffHFF6SpqUnGxsbk7e1Nq1evptzcXCFf2XEpKCggLS0t2rdvn5BWWlpKVlZWwjm4ePFiatu2bY31q/oeHDlyhCQSCR08eLDGGIn+N3Lz15GdqnN81apVCrFGRUUprPviyI2VlRUtWbJE6X7i4uLIwMCAiouLFdIdHBxo+/btREQklUopIiKi1nirqNXIzZYtW2BnZwcdHR24u7vj0qVLtZY/dOgQOnToAB0dHTg7O+PEiRO1lm9q7h3dYZRnBAAY9fUolBqWAmXAygkrVRsYY81UdHQ0JBIJdHR0MGjQIIwZMwbBwcFCvrOzM8RisbB89epVpKenQyqVQiKRQCKRwNjYGMXFxcjIyMDTp0+Rk5MDd3d3YR1NTU107969xhhSU1PRokUL9OnT55XjTk9PR2FhIQYMGCDEIZFI8O233yIjIwMAcPPmTYU4AMDDw6PW7VIdRr7qUrbKtGnTEBERgd9++w2JiYmYMGFCnbeRmpqKNm3awMnJ6ZXK37x5Ez179lRI69mzJ27evAmgcnSgqKgI9vb28PX1RWRk5Esnlf91FEJfXx8GBgbCxF+ZTIYePXoolHdzc3tpnF999RVyc3MRHh6Ot956C+Hh4ejQoQOuXbtW4zoZGRkoKytTqJ+Wlhbc3NyE+qWmpqJXr161jmhcvHgRPj4+2LNnD8aMGfPSWAHFc6nqHK/aZ5XazvsHDx4gOzsb/fv3V5p/9epVFBQUwMTEROEcz8zMFM7x+fPn4+OPP4anpydCQ0OF9Mak8lt0/vOf/2D+/PkIDw+Hu7s7NmzYAC8vL8hkMpiZmVUrn5CQgHHjxiEkJAQffPAB9u/fjxEjRuDy5cvo3LmzCmqg3Aj7EYh4EoEcoxwAgH2xPdq0aqPiqBhTpKelh4LF1d+D1hT7rYt+/fph27ZtEIvFsLKygqam4q8ufX19heWCggJ069YN+/ZVf3ZUq1at6h4wKi+F1VVBQeWxPX78OFq3bq2Qp62t/VpxABA6DLdu3aq1I+Tk5IQLFy6gtLRUofMHANnZ2cjPz1fa+Rg0aBBmzJiB6dOnY+jQoa81ufR1jldtrK2tIZPJcPr0acTExGD27NlYs2YNzp8/X2OH4MV0kUik8Pyx12ViYgIfHx/4+Phg5cqVePvtt7F27Vrs3r37tbf5KsfLwcEBJiYm2LlzJ4YMGdJgl3Ze/P7UJa6CggJYWloiNja2Wl7V5dHg4GCMHz8ex48fx8mTJxEUFISDBw/iww8/rE/YtVL5yM369evh6+uLqVOnolOnTggPD4eenh527typtPzGjRvh7e2NgIAAdOzYEV9++SVcXV2VzvpXpeVjlwN/+adizntzVBcMYzUQiUTQF+s3+aeuL4TV19eHo6MjbGxsqnVslHF1dUVaWhrMzMzg6Oio8DE0NIShoSEsLS1x8eJFYZ3y8nKkpKTUuE1nZ2fI5XJhrsyLqjoPFRUVQlqnTp2gra2NrKysanFYW1sDADp27FhttPrnn3+utX4DBw6EqakpVq9erTS/6jbksWPHoqCgANu3b69WZu3atdDS0sKoUaOq5WlqamLSpEmIjY3FtGnTao2lJi4uLvj999+r3ZZek44dOyI+Pl4hLT4+Hp06dRKWdXV1MXToUGzatAmxsbFITEysdcSkNu3bt0dycrJCWlJSUp23IxaL4eDgINwtpew8cHBwgFgsVqhfWVkZkpKShPq5uLggLi4OZWWKT7f/K1NTU5w9exbp6ekYPXp0rWWr/PVcqjrHO3bs+Mr1k0qlsLOzq/HWcFdXV+Tm5kJTU7PaOW5qaiqUc3Jywrx58/Djjz9i5MiR2LVr1yvH8DpU2rkpLS1FSkoKPD09hTQNDQ14enoiMTFR6TqJiYkK5QHAy8urxvIlJSXIz89X+DQFGzMbtH5e+Z+a5jNN+A/1b5L9MsYqJzCamppi+PDhiIuLQ2ZmJmJjY/Hpp5/i999/BwDMnTsXoaGhiIqKwq1btzB79uxan01iZ2eHyZMnY9q0aYiKihK2+d133wEAbG1tIRKJEB0djYcPH6KgoABSqRQLFy7EvHnzsHv3bmRkZODy5cvYvHmz8F/+J598grS0NAQEBEAmk2H//v2IiIiotX76+vr45ptvcPz4cQwbNgynT5/GnTt3kJycjEWLFuGTTz4BUHlJYu7cuQgICMC6deuQkZGBW7duYenSpdi4cSPWrVsndLJe9OWXX+Lhw4fw8vKq49Gv1KdPH/Tu3RujRo1CTEwMMjMzcfLkSfzwww9KywcEBCAiIgLbtm1DWloa1q9fjyNHjmDhwoUAKh/6t2PHDly/fh2//fYb9u7dC11dXdja2r5WfDNnzsStW7cQGBiI27dv47vvvhOOe02d7+joaPzjH/9AdHQ0bt++DZlMhrVr1+LEiRMYPnw4AOXngb6+PmbNmoWAgAD88MMPuHHjBnx9fVFYWIjp06cDAPz9/ZGfn4+xY8ciOTkZaWlp2LNnD2QymUIMZmZmOHv2LG7duoVx48a99NLcli1bEBkZiVu3bsHPzw9Pnjypc4c1ODgY69atw6ZNm5CWliacwwDg6ekJDw8PjBgxAj/++CPu3LmDhIQELFmyBMnJySgqKoK/vz9iY2Nx9+5dxMfHIykpqU4drNfySjN8Gskff/xBAKpNtgsICCA3Nzel62hpadH+/fsV0rZs2UJmZmZKywcFBVW7NQ+NPKG4yp7Te0hzgSb5h/s3+r4Yexl1uhX8VfJzcnJo0qRJZGpqStra2mRvb0++vr7Cd7+srIzmzp1LBgYGZGRkRPPnz3/preBFRUU0b948srS0JLFYTI6OjrRz504hf8WKFWRhYUEikUi4BVgul9OGDRuoffv2pKWlRa1atSIvLy86f/68sN6xY8eEW5J79epFO3fufOnEViKipKQkGjlypHB7saOjI82YMYPS0tIUyu3YsYO6detGOjo6pK+vT7169aLvv/9eoczLJgjXdUIxEdGjR49o6tSpZGJiQjo6OtS5c2eKjo4morrfCh4ZGUnu7u5kYGBA+vr69M4779Dp06eFfGUTiiMjIxW2b2hoSLt27RKWX7wVfNu2bQSgxu9IRkYG+fr6kpOTE+nq6pKRkRH16NFDYZtEys+DoqIimjNnjnA+KrsV/OrVqzRw4EDS09MjqVRKvXr1ooyMDCKqfp5nZ2eTk5MTjR49msrLy6vFWjWheP/+/eTm5kZisZg6depEZ8+eFcrU1IbKbgUPDw8XzuEXb8PPz8+nOXPmkJWVFWlpaZG1tTVNmDCBsrKyqKSkhMaOHSvcwm9lZUX+/v41HuOGmlAsIqrnPZn1kJ2djdatWyMhIUHhuvGiRYtw/vx5hSHjKmKxGLt378a4ceOEtK1bt2L58uW4f/9+tfIlJSUoKSkRlvPz82FtbY2nT5/CwMCggWvE2N9XcXExMjMz0bZtW+jo6Kg6HMb+dr766iuEh4fj3r17qg6l3u7cuYO2bdviypUrzepVCrX9nsrPz4ehoeEr/f1W6YRiU1NTtGjRolqn5P79+7CwUP7UXgsLizqV19bWrtfEPcYYY+pp69at6NGjB0xMTBAfH481a9bA35+nEKgDlc65EYvF6Natm8JEJblcjjNnztR4B4CHh0e1iU0xMTEvvXWSMcYY+6u0tDQMHz4cnTp1wpdffim82oM1fyq/FXz+/PmYPHkyunfvDjc3N2zYsAHPnz/H1KlTAVQ+EbR169YICQkBUDkJsE+fPli3bh2GDBmCgwcPIjk5Gf/3f/+nymowxhhrZsLCwhAWFqbqMBqFnZ1dvZ8E3pypvHMzZswYPHz4EP/85z+Rm5uLrl274ocffoC5uTkAICsrCxoa/xtgevfdd7F//34sXboUX3zxBdq1a4eoqKi/1TNuGGOMMaY6Kp1QrAp1mZDEmDrhCcWMsb+7hppQrPKH+DHGmtYb9v8MY6wZaajfT9y5YewNUfWo9sLCQhVHwhhjypWWlgJAjW+Pf1Uqn3PDGGsaLVq0gJGRkfDiQD09vTq/BoExxhqLXC7Hw4cPoaen90qvWakNd24Ye4NUPQ+qqoPDGGN/JxoaGrCxsan3P17cuWHsDSISiWBpaQkzM7NXeukeY4w1JbFYrHCH9Ovizg1jb6AWLVrU+5o2Y4z9XfGEYsYYY4ypFe7cMMYYY0ytcOeGMcYYY2rljZtzU/WAoPz8fBVHwhhjjLFXVfV3+1Ue9PfGdW6ePXsGALC2tlZxJIwxxhirq2fPnsHQ0LDWMm/cu6Xkcjmys7MhlUob/AFm+fn5sLa2xr1799T+vVVvUl0Brq86e5PqCnB91Zm615WI8OzZM1hZWb30dvE3buRGQ0MDbdq0adR9GBgYqOWJpcybVFeA66vO3qS6AlxfdabOdX3ZiE0VnlDMGGOMMbXCnRvGGGOMqRXu3DQgbW1tBAUFQVtbW9WhNLo3qa4A11edvUl1Bbi+6uxNquvLvHETihljjDGm3njkhjHGGGNqhTs3jDHGGFMr3LlhjDHGmFrhzg1jjDHG1Ap3bhrIli1bYGdnBx0dHbi7u+PSpUuqDqlBhISEoEePHpBKpTAzM8OIESMgk8kUyvTt2xcikUjh88knn6go4tcXHBxcrR4dOnQQ8ouLi+Hn5wcTExNIJBKMGjUK9+/fV2HE9WNnZ1etviKRCH5+fgCaf7v+9NNPGDp0KKysrCASiRAVFaWQT0T45z//CUtLS+jq6sLT0xNpaWkKZR4/fowJEybAwMAARkZGmD59OgoKCpqwFq+mtrqWlZUhMDAQzs7O0NfXh5WVFSZNmoTs7GyFbSg7H0JDQ5u4Jq/mZW07ZcqUanXx9vZWKNNc2hZ4eX2VfY9FIhHWrFkjlGlO7dsQuHPTAP7zn/9g/vz5CAoKwuXLl9GlSxd4eXnhwYMHqg6t3s6fPw8/Pz/8/PPPiImJQVlZGQYOHIjnz58rlPP19UVOTo7wWb16tYoirp+33npLoR4XLlwQ8ubNm4djx47h0KFDOH/+PLKzszFy5EgVRls/SUlJCnWNiYkBAPj4+AhlmnO7Pn/+HF26dMGWLVuU5q9evRqbNm1CeHg4Ll68CH19fXh5eaG4uFgoM2HCBPz666+IiYlBdHQ0fvrpJ8yYMaOpqvDKaqtrYWEhLl++jGXLluHy5cs4cuQIZDIZhg0bVq3sihUrFNp7zpw5TRF+nb2sbQHA29tboS4HDhxQyG8ubQu8vL5/rWdOTg527twJkUiEUaNGKZRrLu3bIIjVm5ubG/n5+QnLFRUVZGVlRSEhISqMqnE8ePCAAND58+eFtD59+tDcuXNVF1QDCQoKoi5duijNy8vLIy0tLTp06JCQdvPmTQJAiYmJTRRh45o7dy45ODiQXC4nIvVpVyIiABQZGSksy+VysrCwoDVr1ghpeXl5pK2tTQcOHCAiohs3bhAASkpKEsqcPHmSRCIR/fHHH00We129WFdlLl26RADo7t27QpqtrS2FhYU1bnCNQFl9J0+eTMOHD69xnebatkSv1r7Dhw+n999/XyGtubbv6+KRm3oqLS1FSkoKPD09hTQNDQ14enoiMTFRhZE1jqdPnwIAjI2NFdL37dsHU1NTdO7cGYsXL0ZhYaEqwqu3tLQ0WFlZwd7eHhMmTEBWVhYAICUlBWVlZQrt3KFDB9jY2KhFO5eWlmLv3r2YNm2awgtl1aVdX5SZmYnc3FyF9jQ0NIS7u7vQnomJiTAyMkL37t2FMp6entDQ0MDFixebPOaG9PTpU4hEIhgZGSmkh4aGwsTEBG+//TbWrFmD8vJy1QTYAGJjY2FmZob27dtj1qxZePTokZCnzm17//59HD9+HNOnT6+Wp07t+zJv3IszG9qff/6JiooKmJubK6Sbm5vj1q1bKoqqccjlcnz22Wfo2bMnOnfuLKSPHz8etra2sLKywi+//ILAwEDIZDIcOXJEhdHWnbu7OyIiItC+fXvk5ORg+fLl6NWrF65fv47c3FyIxeJqfwzMzc2Rm5urmoAbUFRUFPLy8jBlyhQhTV3aVZmqNlP2va3Ky83NhZmZmUK+pqYmjI2Nm3WbFxcXIzAwEOPGjVN4ueKnn34KV1dXGBsbIyEhAYsXL0ZOTg7Wr1+vwmhfj7e3N0aOHIm2bdsiIyMDX3zxBQYNGoTExES0aNFCbdsWAHbv3g2pVFrtkrk6te+r4M4Ne2V+fn64fv26wjwUAArXqZ2dnWFpaYn+/fsjIyMDDg4OTR3maxs0aJDws4uLC9zd3WFra4vvvvsOurq6Koys8e3YsQODBg2ClZWVkKYu7cr+p6ysDKNHjwYRYdu2bQp58+fPF352cXGBWCzGzJkzERIS0uwe5z927FjhZ2dnZ7i4uMDBwQGxsbHo37+/CiNrfDt37sSECROgo6OjkK5O7fsq+LJUPZmamqJFixbV7pq5f/8+LCwsVBRVw/P390d0dDTOnTuHNm3a1FrW3d0dAJCent4UoTUaIyMjODk5IT09HRYWFigtLUVeXp5CGXVo57t37+L06dP4+OOPay2nLu0KQGiz2r63FhYW1W4KKC8vx+PHj5tlm1d1bO7evYuYmBiFURtl3N3dUV5ejjt37jRNgI3I3t4epqamwrmrbm1bJS4uDjKZ7KXfZUC92lcZ7tzUk1gsRrdu3XDmzBkhTS6X48yZM/Dw8FBhZA2DiODv74/IyEicPXsWbdu2fek6qampAABLS8tGjq5xFRQUICMjA5aWlujWrRu0tLQU2lkmkyErK6vZt/OuXbtgZmaGIUOG1FpOXdoVANq2bQsLCwuF9szPz8fFixeF9vTw8EBeXh5SUlKEMmfPnoVcLhc6es1FVccmLS0Np0+fhomJyUvXSU1NhYaGRrXLN83R77//jkePHgnnrjq17V/t2LED3bp1Q5cuXV5aVp3aVylVz2hWBwcPHiRtbW2KiIigGzdu0IwZM8jIyIhyc3NVHVq9zZo1iwwNDSk2NpZycnKET2FhIRERpaen04oVKyg5OZkyMzPp6NGjZG9vT71791Zx5HW3YMECio2NpczMTIqPjydPT08yNTWlBw8eEBHRJ598QjY2NnT27FlKTk4mDw8P8vDwUHHU9VNRUUE2NjYUGBiokK4O7frs2TO6cuUKXblyhQDQ+vXr6cqVK8IdQqGhoWRkZERHjx6lX375hYYPH05t27aloqIiYRve3t709ttv08WLF+nChQvUrl07GjdunKqqVKPa6lpaWkrDhg2jNm3aUGpqqsL3uKSkhIiIEhISKCwsjFJTUykjI4P27t1LrVq1okmTJqm4ZsrVVt9nz57RwoULKTExkTIzM+n06dPk6upK7dq1o+LiYmEbzaVtiV5+LhMRPX36lPT09Gjbtm3V1m9u7dsQuHPTQDZv3kw2NjYkFovJzc2Nfv75Z1WH1CAAKP3s2rWLiIiysrKod+/eZGxsTNra2uTo6EgBAQH09OlT1Qb+GsaMGUOWlpYkFoupdevWNGbMGEpPTxfyi4qKaPbs2dSyZUvS09OjDz/8kHJyclQYcf2dOnWKAJBMJlNIV4d2PXfunNJzd/LkyURUeTv4smXLyNzcnLS1tal///7VjsOjR49o3LhxJJFIyMDAgKZOnUrPnj1TQW1qV1tdMzMza/wenzt3joiIUlJSyN3dnQwNDUlHR4c6duxIK1euVOgM/J3UVt/CwkIaOHAgtWrVirS0tMjW1pZ8fX2r/bPZXNqW6OXnMhHR9u3bSVdXl/Ly8qqt39zatyGIiIgadWiIMcYYY6wJ8ZwbxhhjjKkV7twwxhhjTK1w54YxxhhjaoU7N4wxxhhTK9y5YYwxxpha4c4NY4wxxtQKd24YY4wxpla4c8MYY4wxtcKdG8ZYo3j48CFmzZoFGxsbaGtrw8LCAl5eXoiPj1d1aIwxNaep6gAYY+pp1KhRKC0txe7du2Fvb4/79+/jzJkzePTokapDY4ypOR65YYw1uLy8PMTFxWHVqlXo168fbG1t4ebmhsWLF2PYsGFCmY8//hitWrWCgYEB3n//fVy9elXYRnBwMLp27YqdO3fCxsYGEokEs2fPRkVFBVavXg0LCwuYmZnhq6++Utj3+vXr4ezsDH19fVhbW2P27NkoKCgQ8iMiImBkZIRTp06hY8eOkEgk8Pb2Rk5OjlAmKSkJAwYMgKmpKQwNDdGnTx9cvnxZyCciBAcHC6NSVlZW+PTTTxvrcDLG6og7N4yxBieRSCCRSBAVFYWSkhKlZXx8fPDgwQOcPHkSKSkpcHV1Rf/+/fH48WOhTEZGBk6ePIkffvgBBw4cwI4dOzBkyBD8/vvvOH/+PFatWoWlS5fi4sWLwjoaGhrYtGkTfv31V+zevRtnz57FokWLFPZdWFiItWvXYs+ePfjpp5+QlZWFhQsXCvnPnj3D5MmTceHCBfz8889o164dBg8ejGfPngEADh8+jLCwMGzfvh1paWmIioqCs7NzQx5Cxlh9qPjFnYwxNfXf//6XWrZsSTo6OvTuu+/S4sWL6erVq0REFBcXRwYGBtXeSuzg4EDbt28nIqKgoCDS09Oj/Px8Id/Ly4vs7OyooqJCSGvfvj2FhITUGMehQ4fIxMREWN61axcBUHjj+5YtW8jc3LzGbVRUVJBUKqVjx44REdG6devIycmJSktLX+VQMMaaGI/cMMYaxahRo5CdnY3vv/8e3t7eiI2NhaurKyIiInD16lUUFBTAxMREGOWRSCTIzMxERkaGsA07OztIpVJh2dzcHJ06dYKGhoZC2oMHD4Tl06dPo3///mjdujWkUikmTpyIR48eobCwUCijp6cHBwcHYdnS0lJhG/fv34evry/atWsHQ0NDGBgYoKCgAFlZWQAqR52Kiopgb28PX19fREZGory8vGEPIGPstXHnhjHWaHR0dDBgwAAsW7YMCQkJmDJlCoKCglBQUABLS0ukpqYqfGQyGQICAoT1tbS0FLYnEomUpsnlcgDAnTt38MEHH8DFxQWHDx9GSkoKtmzZAgAoLS2tdbtEJCxPnjwZqamp2LhxIxISEpCamgoTExNhG9bW1pDJZNi6dSt0dXUxe/Zs9O7dG2VlZQ1w1Bhj9cV3SzHGmkynTp0QFRUFV1dX5ObmQlNTE3Z2dg22/ZSUFMjlcqxbt04Y3fnuu+/qvJ34+Hhs3boVgwcPBgDcu3cPf/75p0IZXV1dDB06FEOHDoWfnx86dOiAa9euwdXVtf4VYYzVC3duGGMN7tGjR/Dx8cG0adPg4uICqVSK5ORkrF69GsOHD4enpyc8PDwwYsQIrF69Gk5OTsjOzsbx48fx4Ycfonv37q+1X0dHR5SVlWHz5s0YOnQo4uPjER4eXufttGvXDnv27EH37t2Rn5+PgIAA6OrqCvkRERGoqKiAu7s79PT0sHfvXujq6sLW1va14maMNSy+LMUYa3ASiQTu7u4ICwtD79690blzZyxbtgy+vr7497//DZFIhBMnTqB3796YOnUqnJycMHbsWNy9exfm5uavvd8uXbpg/fr1WLVqFTp37ox9+/YhJCSkztvZsWMHnjx5AldXV0ycOBGffvopzMzMhHwjIyN8/fXX6NmzJ1xcXHD69GkcO3YMJiYmrx07Y6zhiOivF5oZY4wxxpo5HrlhjDHGmFrhzg1jjDHG1Ap3bhhjjDGmVrhzwxhjjDG1wp0bxhhjjKkV7twwxhhjTK1w54YxxhhjaoU7N4wxxhhTK9y5YYwxxpha4c4NY4wxxtQKd24YY4wxpla4c8MYY4wxtfL/AN08uZgyWJdRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predice el conjunto de entrenamiento usando la prediccion predictiva a partir de los primeros (usando los datos que predice)\n",
    "red_ap_X_entrenamiento_n = c_entrenamiento_n[:time_steps].reshape(8)\n",
    "red_ap_precios_predichos_n = utls.genera_prediccion_predictiva(red_ap_X_entrenamiento_n,8,182,red)\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(c_entrenamiento_n, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(red_ap_precios_predichos_n, color = 'green', label = 'Predicted COMI closing Stock prices') #ts_cierre_s_pred[:,0]\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Semanas')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ahora, el modelo ha sido entrenado de manera iterativa\n",
    "\n",
    "red_ap_X_prueba_n = np.reshape(X_prueba_n[0,:], (1, X_prueba_n[0,:].shape[0], 1))\n",
    "red_ap_precios_predichos = red.predict(red_ap_X_prueba_n)\n",
    "f_predicted_sp_cierre = m_m_s.inverse_transform(red_ap_precios_predichos)\n",
    "\n",
    "# Predice el conjunto de prueba usando la prediccion predictiva (ñps datos que va prediciendo)\n",
    "\n",
    "red_ap_precios_predichos = utls.genera_prediccion_predictiva(red_ap_X_prueba_n.reshape(8),8,78,red)\n",
    "temp = red_ap_precios_predichos\n",
    "red_ap_precios_predichos = m_m_s_prueba.inverse_transform(red_ap_precios_predichos.reshape(86,1))\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(m_m_s_prueba.inverse_transform(c_prueba_n), color = 'black', label = 'COMI original Stock prices') #c_prueba_n\n",
    "plt.plot(red_ap_precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Semanas')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'weight_decay': None,\n",
       " 'clipnorm': None,\n",
       " 'global_clipnorm': None,\n",
       " 'clipvalue': None,\n",
       " 'use_ema': False,\n",
       " 'ema_momentum': 0.99,\n",
       " 'ema_overwrite_frequency': None,\n",
       " 'jit_compile': False,\n",
       " 'is_legacy_optimizer': False,\n",
       " 'learning_rate': 0.01,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.optimizer.get_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
