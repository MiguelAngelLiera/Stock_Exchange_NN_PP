{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import src.utilerias.reader as rd\n",
    "import src.utilerias.utilerias as utls\n",
    "\n",
    "# Llamamos a la función antes de ejecutar el script\n",
    "logs_dir = 'logs/NARNN/estandar'\n",
    "logs_dir_auto_pred = 'logs/NARNN/auto_predictiva'\n",
    "utls.eliminar_archivos_registro(logs_dir)\n",
    "utls.eliminar_archivos_registro(logs_dir_auto_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS = 'cierre.csv'#Grupo Financiero Inbursa\n",
    "# DATOS = 'Datos históricos COMI 03012016_27122020.csv' #Datos originales\n",
    "DATOS = 'datos/Datos históricos COMI 3ene16-31dic2020 semanal.csv' #Datos semanales\n",
    "# DATOS = 'Datos históricos COMI_prueba 30jun19-31dic2020.csv' #Datos semanales de prueba\n",
    "# DATOS = 'Datos históricos COMI3ene2016_27dic2020_diario.csv' #Datos originales diarios de prueba\n",
    "# DATOS = 'Datos históricos COMI_prueba 30jun19-31dic2020_DIARIO.csv' #Datos diarios de prueba\n",
    "\n",
    "cierre = rd.leer_archivo(DATOS).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crean los conjuntos de entradas y salidas para la red, que funcionaran para predecir y comparar con las salidas esperadas a la hora de realizar el entrenamiento\n",
    "time_steps = 8 # la cantidad de semanas anteriores a partir de las cuales se va a predecir la novena semana\n",
    "\n",
    "#Obtenemos el conjunto de entrenamiento\n",
    "c_entrenamiento = np.array(cierre[:int(len(cierre) * 0.7)])\n",
    "\n",
    "precios_reales = cierre[int(len(cierre) * 0.7):] #verdaderos valores del conjunto de prueba\n",
    "\n",
    "#Se concatenan los ultimo 8 elementos del conjunto de entrenamiento para predecir el primero del conjunto de prueba\n",
    "# ahora cada uno de los arreglos dentro de components_p y components_p_n tiene forma (84,)\n",
    "c_prueba = cierre[len(cierre) - len(precios_reales) - time_steps:]\n",
    "\n",
    "#Se normalizan cada uno de los elementos de los vectores contenidos en las descomposicion de la serie de tiempo original\n",
    "c_entrenamiento_n = utls.normalizar(c_entrenamiento) # componentes de entrenamiento normalizados\n",
    "c_prueba_n = utls.normalizar(c_prueba) # componentes de prueba normalizados len 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---INICIO DE ENTRENAMIENTO: entrena_LM---\n",
      "---Inicio de epoca: 0--\n",
      "-----> Predicción pre entreno: tensor([-0.1284], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([-0.1268], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([-0.1274], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([-0.1252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([-0.1244], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([-0.1217], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([-0.1218], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([-0.1192], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([-0.1197], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([-0.1174], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([-0.1174], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([-0.1149], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([-0.1159], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([-0.1134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([-0.1137], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([-0.1107], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([-0.1098], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([-0.1066], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([-0.1056], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([-0.1026], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([-0.1032], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([-0.1002], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([-0.1006], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([-0.0976], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([-0.0982], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([-0.0955], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([-0.0956], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([-0.0928], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([-0.0916], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([-0.0887], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([-0.0886], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([-0.0860], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([-0.0860], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([-0.0835], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([-0.0834], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([-0.0812], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([-0.0813], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([-0.0791], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([-0.0795], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([-0.0769], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([-0.0762], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([-0.0737], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([-0.0736], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([-0.0704], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([-0.0707], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([-0.0672], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([-0.0677], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([-0.0641], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([-0.0650], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([-0.0614], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([-0.0611], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([-0.0578], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([-0.0588], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([-0.0556], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([-0.0554], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([-0.0521], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([-0.0514], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([-0.0483], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([-0.0475], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([-0.0445], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([-0.0439], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([-0.0409], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([-0.0410], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([-0.0374], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([-0.0381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([-0.0344], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([-0.0339], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([-0.0304], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([-0.0305], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([-0.0270], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([-0.0274], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([-0.0235], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([-0.0247], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([-0.0190], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([-0.0193], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([-0.0134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([-0.0122], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([-0.0067], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([-0.0070], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([-0.0011], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([-0.0027], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.0029], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.0003], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.0057], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.0074], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.0134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.0158], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.0220], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.0217], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.0280], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.0282], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.0347], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.0348], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.0412], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.0396], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.0462], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.0461], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.0526], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.0534], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.0602], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.0597], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.0661], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.0668], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.0726], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.0726], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.0783], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.0785], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.0845], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.0840], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.0903], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.0915], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.0975], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.0985], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.1043], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.1031], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.1092], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.1078], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.1136], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.1137], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.1195], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.1205], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.1258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.1264], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.1319], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.1307], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.1363], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.1367], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.1423], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.1427], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.1485], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.1488], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.1553], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.1543], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.1608], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.1601], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.1662], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.1666], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.1725], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.1720], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.1777], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.1770], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.1828], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.1836], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.1902], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.1916], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.1981], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.1982], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.2044], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.2039], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.2098], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.2092], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.2151], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.2135], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.2190], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.2203], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.2257], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.2271], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.2329], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.2331], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.2386], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.2381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.2435], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.2437], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.2491], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.2487], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.2539], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.2528], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.2577], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.2585], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.2631], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.2636], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.2679], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.2676], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.2719], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.2719], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.2764], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.2768], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.2812], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.2813], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.2850], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.2849], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.2886], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.2879], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.2918], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.2911], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.2946], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.2952], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.2988], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.3000], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.3036], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.3030], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.3070], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.3057], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.3094], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.3105], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.3148], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.3140], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.3182], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.3182], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.3223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.3216], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.3257], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.3264], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.3301], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.3296], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.3330], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.3335], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.3375], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.3381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.3417], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.3418], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.3466], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.3466], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.3519], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.3520], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.3570], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.3554], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.3607], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.3611], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.3661], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.3646], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.3694], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.3694], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.3746], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.3766], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.3825], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.3825], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.3881], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.3887], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.3934], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.3938], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.3984], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.3973], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.4016], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.4007], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.4048], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.4066], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.4109], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.4128], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.4172], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.4165], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.4206], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.4202], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.4243], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.4239], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.4279], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.4271], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.4309], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.4307], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.4340], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.4348], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.4381], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.4382], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.4422], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.4419], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.4459], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.4463], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.4500], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.4504], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.4540], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.4530], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.4572], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.4553], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.4592], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.4603], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.4639], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.4649], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.4679], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.4680], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.4714], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.4700], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.4731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.4742], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.4770], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.4777], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.4819], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.4822], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.4849], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.4839], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.4866], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.4867], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.4896], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.4902], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.4931], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.4921], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.4946], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.4950], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.4967], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.4972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.4984], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.4980], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.4996], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.4999], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.5019], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.5028], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.5043], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.5053], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.5072], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.5070], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.5086], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.5065], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.5089], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.5075], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.5103], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.5120], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.5149], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.5141], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.5178], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.5176], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.5218], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.5206], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.5248], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.5242], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.5276], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.5288], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.5323], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.5312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.5344], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.5347], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.5377], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.5393], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.5422], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.5440], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.5480], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.5469], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.5509], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.5505], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.5543], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.5543], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.5583], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.5576], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.5618], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.5598], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.5636], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.5646], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.5677], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.5695], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.5724], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.5718], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.5751], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.5748], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.5780], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.5795], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.5831], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.5835], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.5872], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.5864], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.5899], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 1--\n",
      "-----> Predicción pre entreno: tensor([0.5916], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.5864], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.5859], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.5813], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.5821], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.5781], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.5780], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.5740], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.5736], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.5693], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.5694], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.5654], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.5644], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.5604], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.5602], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.5568], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.5577], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.5546], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.5555], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.5523], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.5517], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.5485], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.5481], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.5449], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.5444], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.5411], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.5411], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.5378], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.5390], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.5359], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.5360], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.5327], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.5327], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.5293], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.5295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.5259], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.5258], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.5223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.5219], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.5188], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.5194], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.5163], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.5164], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.5141], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.5136], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.5116], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.5112], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.5095], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.5085], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.5068], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.5072], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.5043], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.5023], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.5024], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.5005], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.5012], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.4992], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.4999], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.4978], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.4983], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.4962], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.4961], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.4947], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.4939], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.4904], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.4909], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.4898], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.4898], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.4886], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.4882], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.4871], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.4860], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.4868], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.4864], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.4876], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.4889], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.4897], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.4895], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.4912], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.4897], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.4907], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.4884], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.4925], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.4942], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.4955], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.4977], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.4993], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.4989], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.5006], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.5007], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.5027], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.5028], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.5047], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.5033], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.5054], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.5054], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.5074], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.5082], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.5107], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.5102], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.5122], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.5130], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.5144], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.5145], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.5159], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.5160], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.5179], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.5174], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.5196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.5206], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.5225], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.5235], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.5251], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.5240], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.5260], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.5247], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.5266], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.5267], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.5285], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.5295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.5308], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.5314], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.5329], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.5318], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.5335], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.5339], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.5357], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.5361], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.5381], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.5383], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.5411], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.5401], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.5429], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.5423], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.5447], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.5451], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.5474], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.5470], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.5491], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.5484], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.5507], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.5514], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.5545], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.5557], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.5588], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.5588], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.5616], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.5611], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.5635], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.5630], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.5655], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.5641], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.5662], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.5675], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.5696], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.5709], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.5734], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.5734], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.5757], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.5753], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.5774], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.5776], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.5798], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.5794], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.5815], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.5805], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.5822], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.5831], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.5844], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.5850], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.5859], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.5857], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.5867], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.5868], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.5882], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.5886], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.5899], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.5900], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.5908], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.5908], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.5916], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.5910], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.5921], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.5915], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.5922], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.5928], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.5937], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.5947], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.5955], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.5950], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.5962], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.5948], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.5960], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.5971], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.5987], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.5979], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.5993], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.5992], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6005], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.5999], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6013], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6020], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6032], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6028], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6037], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6041], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6055], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6060], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6086], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6086], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6109], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6107], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6135], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6135], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6161], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6145], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6173], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6176], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6202], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6189], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6213], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6211], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6239], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6258], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6294], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6292], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.6324], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.6328], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.6352], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.6355], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.6378], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.6368], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.6388], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.6381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.6399], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.6416], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.6455], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.6476], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.6468], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.6488], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.6483], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.6502], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.6501], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.6519], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.6512], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.6528], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.6526], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.6534], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.6543], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.6554], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.6555], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.6574], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.6571], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.6590], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.6593], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.6610], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.6613], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.6628], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.6620], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.6641], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.6624], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.6643], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.6654], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.6670], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.6679], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.6765], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.6765], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.6778], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.6766], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.6783], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.6794], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.6803], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.6810], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.6823], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.6825], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.6834], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.6825], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.6834], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.6834], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.6851], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.6856], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.6868], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.6859], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.6867], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.6869], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.6869], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.6873], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.6864], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.6861], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.6858], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.6861], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.6863], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.6872], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.6870], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.6878], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.6881], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.6879], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.6877], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.6858], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.6866], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.6852], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.6935], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.6952], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.6957], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.6951], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.6970], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.6968], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.6993], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.6982], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7007], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7002], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7020], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7032], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7050], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7039], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7055], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7057], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7071], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7086], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7099], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7116], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7129], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7153], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7150], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7171], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7173], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7197], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7190], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7216], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7197], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7230], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7246], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7263], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7277], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7270], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7288], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7285], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7303], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7317], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7339], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7343], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7365], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7357], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7378], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 2--\n",
      "-----> Predicción pre entreno: tensor([0.7384], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7318], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7313], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7254], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7262], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7207], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7207], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7153], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7149], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7094], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7095], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7041], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7031], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.6978], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.6977], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.6929], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.6938], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.6894], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.6904], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.6858], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6853], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6809], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6805], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6760], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6755], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6709], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6709], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6664], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6676], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6634], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6588], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6588], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6542], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6544], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6496], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6495], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6448], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6444], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6401], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6407], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6364], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6366], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6331], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6326], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6294], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6290], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6261], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6228], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6197], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6188], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6156], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6157], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6128], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6135], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6103], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6110], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6078], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6084], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6052], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6050], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6025], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6017], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.5994], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.5999], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.5975], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.5976], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.5951], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.5946], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.5927], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.5916], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.5914], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.5910], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.5910], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.5924], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.5922], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.5921], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.5923], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.5908], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.5907], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.5885], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.5883], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.5901], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.5907], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.5929], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.5935], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.5931], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.5940], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.5942], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.5962], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.5964], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.5975], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.5961], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.5972], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.5972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.5982], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.5990], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6006], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6001], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6010], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6017], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6024], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6025], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6032], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6032], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6046], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6041], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6054], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6064], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6096], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6106], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6115], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6104], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6114], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6102], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6115], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6117], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6129], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6138], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6144], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6150], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6158], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6147], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6159], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6163], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6174], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6178], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6190], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6192], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6212], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6202], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6217], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6233], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6237], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6248], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6261], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6255], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6269], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6277], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6301], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6335], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6335], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6356], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6351], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6368], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6363], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6381], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6368], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6381], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6393], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6407], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6420], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6438], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6438], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6454], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6450], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6464], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6467], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6481], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6478], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6491], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6482], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6497], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6505], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6514], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6519], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6525], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6523], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6529], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6530], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6539], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6543], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6551], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6552], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6553], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6553], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6554], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6548], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6553], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6547], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6547], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6553], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6555], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6566], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6567], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6562], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6569], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6557], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6562], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6572], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6585], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6577], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6587], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6586], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6595], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6590], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6599], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6605], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6610], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6606], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6609], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6613], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6622], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6628], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6634], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6634], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6651], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6650], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6673], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6673], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6693], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6678], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6700], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6704], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6724], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6712], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6729], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6752], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6771], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6802], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6800], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.6827], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.6831], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.6851], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.6854], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.6872], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.6862], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.6877], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.6870], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.6884], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.6900], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.6915], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.6932], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.6949], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.6942], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.6957], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.6953], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.6967], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.6965], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.6978], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.6972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.6982], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.6981], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.6988], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.6996], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7005], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7006], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7020], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7017], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7031], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7035], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7047], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7050], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7060], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7052], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7069], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7052], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7066], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7077], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7088], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7097], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7105], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7105], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7117], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7106], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7114], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7124], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7130], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7137], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7145], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7146], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7152], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7143], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7149], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7149], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7158], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7162], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7170], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7161], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7166], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7169], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7166], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7169], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7157], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7153], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7148], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7150], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7149], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7158], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7153], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7162], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7161], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7159], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7155], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7136], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7141], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7128], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7137], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7152], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7163], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7157], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7175], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7173], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7185], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7209], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7204], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7220], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7231], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7247], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7237], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7251], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7263], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7278], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7287], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7302], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7324], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7314], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7337], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7334], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7353], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7355], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7377], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7371], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7395], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7378], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7398], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7408], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7422], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7438], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7450], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7444], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7460], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7457], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7473], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7486], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7506], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7510], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7531], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7523], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7543], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 3--\n",
      "-----> Predicción pre entreno: tensor([0.7544], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7477], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7472], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7411], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7418], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7362], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7362], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7307], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7304], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7246], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7248], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7193], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7183], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.7129], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.7127], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.7078], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.7087], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.7041], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.7050], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.7003], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6999], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6953], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6949], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6903], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6899], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6852], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6851], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6805], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6816], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6771], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6772], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6725], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6725], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6678], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6680], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6630], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6629], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6582], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6577], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6533], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6539], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6495], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6496], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6460], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6456], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6422], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6419], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6388], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6350], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6354], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6322], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6314], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6281], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6282], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6251], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6258], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6225], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6231], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6199], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6203], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6171], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6169], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6143], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6135], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6111], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6116], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6090], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6091], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6065], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6061], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6041], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6030], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.6027], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.6022], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.6022], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6035], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6032], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6032], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6032], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6018], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6017], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.5996], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.5993], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6010], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6014], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6034], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6040], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6037], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6065], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6067], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6078], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6079], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6103], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6090], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6201], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6202], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6213], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6221], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6234], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6229], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6240], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6248], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6259], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6268], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6263], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6286], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6305], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6313], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6319], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6310], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6321], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6310], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6319], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6321], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6330], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6338], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6342], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6348], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6355], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6344], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6353], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6356], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6365], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6368], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6408], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6410], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6427], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6418], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6431], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6445], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6449], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6461], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6458], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6460], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6455], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6467], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6474], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6496], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6506], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6527], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6527], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6545], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6541], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6556], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6553], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6569], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6556], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6567], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6579], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6590], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6601], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6617], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6617], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6631], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6626], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6639], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6641], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6653], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6650], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6660], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6652], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6661], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6670], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6676], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6681], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6685], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6683], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6687], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6688], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6695], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6698], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6706], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6706], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6706], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6706], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6706], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6700], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6703], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6698], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6696], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6702], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6703], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6712], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6712], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6707], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6713], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6700], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6703], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6714], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6724], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6715], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6724], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6724], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6726], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6734], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6741], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6744], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6741], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6743], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6747], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6755], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6759], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6764], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6763], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6779], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6777], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6799], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6798], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6817], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6803], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6825], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6829], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6849], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6838], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6855], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6855], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6877], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6894], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6924], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6921], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.6947], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.6951], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.6969], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.6973], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.6990], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.6982], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.6989], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.7001], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.7016], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7030], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7046], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7061], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7053], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7066], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7062], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7075], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7074], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7085], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7079], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7099], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7098], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7105], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7113], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7120], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7120], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7130], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7142], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7145], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7152], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7155], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7172], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7165], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7181], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7165], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7178], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7189], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7194], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7202], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7208], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7209], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7208], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7215], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7226], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7229], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7236], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7242], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7248], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7239], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7244], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7244], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7256], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7262], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7254], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7261], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7257], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7261], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7246], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7237], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7238], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7237], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7244], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7238], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7246], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7245], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7242], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7237], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7219], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7211], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7234], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7244], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7237], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7254], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7275], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7265], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7287], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7284], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7298], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7311], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7325], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7316], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7329], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7332], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7336], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7351], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7377], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7392], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7413], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7402], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7423], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7420], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7439], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7441], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7462], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7456], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7480], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7463], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7482], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7493], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7506], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7522], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7533], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7527], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7542], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7539], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7554], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7566], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7586], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7589], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7608], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7601], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7619], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 4--\n",
      "-----> Predicción pre entreno: tensor([0.7612], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7544], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7539], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7478], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7484], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7428], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7427], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7372], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7368], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7310], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7257], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7248], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.7193], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.7192], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.7143], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.7151], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.7105], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.7113], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.7065], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.7061], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.7014], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.7012], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6965], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6961], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6913], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6913], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6866], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6877], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6832], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6832], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6785], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6785], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6737], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6739], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6689], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6688], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6639], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6635], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6590], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6596], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6551], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6552], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6515], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6511], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6477], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6473], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6442], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6435], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6404], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6409], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6376], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6368], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6335], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6337], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6306], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6278], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6285], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6251], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6256], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6221], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6194], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6186], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6162], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6166], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6141], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6114], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6111], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6090], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6080], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.6076], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.6071], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.6070], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6083], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6080], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6079], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6079], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6067], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6065], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6047], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6043], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6060], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6064], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6083], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6088], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6085], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6091], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6094], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6104], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6105], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6115], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6103], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6123], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6123], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6136], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6144], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6158], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6153], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6166], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6173], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6179], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6180], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6185], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6186], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6191], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6199], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6209], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6228], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6235], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6226], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6242], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6231], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6241], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6253], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6261], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6266], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6271], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6278], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6268], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6277], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6281], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6290], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6293], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6303], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6304], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6323], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6313], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6333], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6328], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6343], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6348], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6361], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6358], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6369], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6364], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6378], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6385], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6408], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6417], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6439], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6439], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6458], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6454], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6471], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6467], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6484], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6472], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6484], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6496], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6508], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6519], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6536], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6536], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6550], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6546], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6560], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6562], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6575], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6572], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6584], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6576], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6587], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6595], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6603], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6607], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6612], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6610], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6615], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6615], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6623], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6626], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6634], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6634], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6634], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6635], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6629], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6627], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6626], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6632], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6634], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6642], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6644], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6638], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6645], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6633], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6637], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6647], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6657], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6650], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6659], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6659], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6667], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6662], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6671], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6677], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6681], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6678], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6680], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6684], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6693], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6697], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6702], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6702], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6719], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6717], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6739], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6738], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6758], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6745], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6767], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6771], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6791], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6780], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6799], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6799], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6821], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6838], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6868], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6865], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.6892], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.6896], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.6915], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.6919], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.6936], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.6928], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.6942], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.6936], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.6948], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.6964], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.6978], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.6993], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7009], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7001], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7015], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7011], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7025], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7023], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7036], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7030], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7036], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7035], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7042], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7050], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7058], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7058], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7072], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7069], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7082], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7085], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7096], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7099], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7106], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7098], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7115], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7099], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7113], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7123], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7143], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7150], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7150], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7161], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7150], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7158], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7168], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7172], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7179], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7186], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7187], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7192], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7183], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7188], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7189], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7197], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7201], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7208], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7200], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7204], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7207], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7204], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7208], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7195], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7191], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7186], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7187], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7186], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7192], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7186], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7195], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7194], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7191], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7187], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7168], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7173], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7161], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7170], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7185], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7195], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7189], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7206], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7205], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7228], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7218], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7241], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7239], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7254], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7266], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7282], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7273], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7287], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7289], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7299], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7313], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7318], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7333], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7354], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7343], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7365], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7362], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7381], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7384], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7406], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7400], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7424], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7407], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7427], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7438], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7452], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7468], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7480], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7474], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7490], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7486], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7502], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7514], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7534], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7537], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7557], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7550], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7569], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 5--\n",
      "-----> Predicción pre entreno: tensor([0.7543], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7476], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7472], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7411], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7417], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7362], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7361], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7306], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7304], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7246], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7249], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7194], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7185], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.7131], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.7130], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.7081], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.7089], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.7044], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.7053], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.7006], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.7002], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6956], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6954], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6907], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6903], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6856], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6857], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6810], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6821], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6777], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6777], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6730], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6730], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6683], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6684], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6635], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6634], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6586], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6581], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6537], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6542], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6498], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6499], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6463], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6458], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6425], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6422], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6391], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6385], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6354], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6359], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6327], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6320], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6287], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6289], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6265], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6231], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6238], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6205], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6210], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6177], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6175], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6149], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6141], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6117], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6121], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6096], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6097], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6071], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6068], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6047], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6037], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.6034], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.6029], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.6028], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6042], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6039], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6041], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6041], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6029], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6027], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6009], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6006], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6024], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6028], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6047], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6053], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6050], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6057], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6060], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6071], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6072], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6082], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6070], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6075], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6077], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6093], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6101], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6116], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6111], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6126], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6134], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6141], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6147], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6148], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6158], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6152], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6163], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6173], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6184], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6193], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6200], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6191], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6283], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6269], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6279], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6282], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6291], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6302], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6306], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6319], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6306], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6315], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6317], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6326], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6330], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6339], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6341], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6359], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6347], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6367], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6364], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6379], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6388], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6401], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6399], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6410], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6405], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6418], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6427], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6449], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6458], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6480], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6481], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6500], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6499], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6514], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6511], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6527], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6513], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6525], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6541], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6553], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6565], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6582], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6579], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6593], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6589], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6602], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6605], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6618], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6613], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6625], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6616], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6626], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6636], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6643], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6647], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6652], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6648], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6652], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6651], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6659], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6660], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6667], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6667], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6667], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6668], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6668], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6660], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6663], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6654], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6653], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6661], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6662], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6671], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6671], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6663], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6670], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6656], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6659], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6672], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6682], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6673], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6681], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6682], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6690], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6687], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6694], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6702], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6706], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6704], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6706], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6711], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6718], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6720], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6725], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6726], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6742], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6739], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6761], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6760], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6780], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6770], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6792], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6800], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6809], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6827], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6831], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6853], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6872], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6902], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6899], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.6925], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.6933], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.6951], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.6959], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.6976], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.6965], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.6980], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.6972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.6984], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.7002], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7016], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7030], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7047], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7035], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7049], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7045], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7058], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7056], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7068], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7061], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7080], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7080], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7086], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7095], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7103], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7101], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7115], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7108], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7122], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7126], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7136], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7141], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7158], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7149], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7165], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7148], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7161], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7174], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7184], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7195], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7202], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7202], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7212], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7199], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7206], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7217], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7221], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7228], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7235], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7233], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7238], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7227], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7232], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7233], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7240], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7249], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7240], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7244], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7249], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7245], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7249], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7236], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7231], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7225], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7222], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7221], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7225], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7230], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7229], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7223], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7197], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7201], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7188], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7197], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7213], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7219], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7237], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7237], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7259], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7250], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7272], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7275], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7290], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7308], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7323], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7315], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7328], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7332], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7339], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7356], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7368], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7383], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7404], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7388], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7410], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7407], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7426], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7432], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7453], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7446], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7470], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7453], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7472], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7489], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7502], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7521], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7532], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7524], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7540], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7534], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7549], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7562], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7582], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7584], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7604], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7595], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7614], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 6--\n",
      "-----> Predicción pre entreno: tensor([0.7492], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7425], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7420], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7359], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7367], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7259], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7202], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7209], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7154], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7144], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.7091], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.7092], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.7043], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.7054], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.7009], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.7021], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.6974], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6974], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6928], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6926], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6880], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6876], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6829], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6832], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6786], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6798], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6754], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6754], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6707], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6709], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6662], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6663], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6614], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6611], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6564], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6557], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6513], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6517], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6473], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6475], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6439], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6433], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6400], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6397], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6367], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6363], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6333], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6342], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6309], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6305], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6272], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6277], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6246], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6220], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6230], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6197], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6203], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6170], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6166], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6130], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6106], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6112], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6086], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6090], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6065], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6062], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6041], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6029], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.6026], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.6020], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.6019], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6041], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6039], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6048], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6048], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6037], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6036], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6020], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6017], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6043], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6047], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6068], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6073], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6072], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6079], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6085], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6095], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6097], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6106], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6095], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6108], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6112], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6123], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6134], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6148], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6145], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6156], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6167], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6173], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6176], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6182], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6181], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6190], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6183], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6192], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6203], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6214], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6224], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6231], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6221], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6233], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6219], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6232], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6242], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6264], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6271], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6258], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6267], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6269], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6279], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6283], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6293], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6314], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6302], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6322], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6320], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6335], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6345], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6359], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6357], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6369], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6364], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6377], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6386], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6409], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6418], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6440], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6441], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6461], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6460], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6476], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6473], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6489], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6476], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6489], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6504], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6516], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6528], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6545], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6542], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6557], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6552], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6566], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6569], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6582], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6577], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6590], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6581], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6591], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6601], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6621], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6625], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6630], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6625], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6630], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6628], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6636], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6636], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6644], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6643], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6643], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6645], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6645], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6636], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6639], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6630], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6629], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6637], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6638], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6647], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6648], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6639], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6646], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6631], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6635], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6648], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6659], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6650], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6659], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6660], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6668], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6665], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6676], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6684], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6688], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6686], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6688], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6694], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6704], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6705], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6710], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6711], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6728], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6724], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6746], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6745], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6765], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6757], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6779], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6788], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6808], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6798], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6816], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6822], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6843], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6863], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6893], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6890], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.6916], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.6925], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.6943], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.6952], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.6969], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.6958], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.6973], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.6965], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.6977], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.6995], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7009], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7022], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7039], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7026], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7040], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7036], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7049], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7047], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7059], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7052], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7064], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7063], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7070], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7079], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7087], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7085], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7099], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7091], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7104], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7108], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7118], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7123], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7135], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7126], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7143], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7125], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7139], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7154], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7162], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7174], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7181], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7182], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7192], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7176], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7184], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7195], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7199], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7206], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7213], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7210], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7215], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7203], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7208], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7208], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7216], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7218], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7225], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7216], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7225], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7221], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7226], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7213], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7208], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7203], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7196], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7195], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7198], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7193], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7203], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7202], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7194], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7190], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7168], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7172], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7158], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7167], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7185], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7194], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7192], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7210], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7211], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7234], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7226], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7249], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7256], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7271], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7293], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7309], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7301], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7315], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7320], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7332], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7350], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7361], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7375], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7397], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7378], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7400], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7398], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7417], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7423], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7445], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7438], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7463], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7445], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7465], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7483], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7497], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7516], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7528], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7519], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7535], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7528], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7544], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7556], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7576], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7577], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7597], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7588], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7607], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 7--\n",
      "-----> Predicción pre entreno: tensor([0.7430], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7364], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7358], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7298], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7306], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7199], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7202], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7146], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7154], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7100], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7091], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.7038], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.7040], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.6992], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.7004], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.6959], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.6972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.6926], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6927], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6881], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6881], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6835], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6831], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6785], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6789], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6743], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6756], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6712], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6712], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6665], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6668], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6621], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6622], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6573], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6570], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6523], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6516], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6472], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6475], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6432], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6434], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6398], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6391], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6358], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6356], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6326], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6324], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6294], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6306], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6273], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6270], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6238], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6244], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6214], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6222], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6189], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6200], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6167], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6172], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6136], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6110], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6099], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6075], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6082], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6056], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6061], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6036], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6033], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6013], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6001], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.5998], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.5992], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.5992], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6018], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6015], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6028], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6028], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6019], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6018], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6005], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6001], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6031], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6035], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6057], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6063], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6063], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6069], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6077], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6087], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6089], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6098], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6088], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6099], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6104], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6115], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6126], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6141], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6138], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6155], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6167], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6173], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6177], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6182], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6181], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6191], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6182], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6207], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6217], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6227], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6235], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6225], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6236], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6221], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6231], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6235], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6244], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6255], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6260], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6266], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6274], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6260], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6269], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6271], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6280], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6284], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6908], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6910], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6923], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6908], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6922], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6927], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6936], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6956], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6964], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6967], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6974], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6980], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6992], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.7009], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.7019], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.7035], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.7041], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.7055], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.7058], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.7069], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.7067], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.7080], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.7066], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.7074], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.7095], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.7103], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.7115], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.7126], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.7119], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.7127], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.7121], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.7129], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.7132], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.7141], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.7132], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.7140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.7129], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.7134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.7146], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.7148], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.7151], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.7150], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.7142], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.7142], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.7135], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.7137], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.7132], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.7135], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.7131], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.7126], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.7127], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.7123], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.7106], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.7105], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.7089], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.7084], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.7093], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.7090], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.7096], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.7093], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.7079], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.7081], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.7062], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.7062], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.7079], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.7085], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.7074], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.7079], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.7086], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.7090], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.7091], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.7095], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.7109], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.7109], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.7109], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.7107], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.7116], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.7120], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.7117], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.7118], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.7121], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.7134], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.7126], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.7145], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.7147], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.7162], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.7163], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.7181], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.7199], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.7215], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.7211], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.7226], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.7261], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.7287], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.7313], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.7312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.7335], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.7352], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.7366], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.7381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.7394], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.7381], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.7392], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.7382], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.7393], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.7413], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7425], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7435], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7447], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7427], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7438], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7430], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7440], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7434], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7442], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7432], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7442], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7441], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7444], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7454], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7457], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7451], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7463], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7449], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7460], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7465], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7473], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7480], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7488], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7477], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7490], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7469], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7484], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7505], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7536], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7553], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7555], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7557], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7563], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7543], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7547], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7558], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7559], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7565], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7568], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7560], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7561], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7544], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7546], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7545], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7549], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7547], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7551], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7541], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7542], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7549], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7542], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7546], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7536], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7528], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7519], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7503], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7499], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7496], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7487], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7496], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7493], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7478], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7471], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7444], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7445], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7429], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7435], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7459], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7466], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7472], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7487], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7494], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7514], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7513], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7534], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7555], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7568], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7604], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7616], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7614], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7625], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7636], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7644], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7666], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7690], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7704], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7722], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7696], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7716], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7715], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7741], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7759], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7753], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7774], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7759], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7776], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7804], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7815], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7839], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7849], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7839], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7851], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7841], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7853], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7865], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7882], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7880], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7898], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7887], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7903], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 8--\n",
      "-----> Predicción pre entreno: tensor([0.7426], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7360], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7352], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7292], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7302], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7248], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7199], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7213], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7157], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7173], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7118], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7112], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.7058], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.7067], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.7019], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.7038], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.6993], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.7014], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.6967], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6976], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6930], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6932], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6887], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6885], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6838], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6847], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6801], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6817], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6773], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6773], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6726], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6731], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6684], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6682], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6632], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6627], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6579], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6567], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6524], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6524], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6480], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6483], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6447], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6437], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6404], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6405], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6375], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6380], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6350], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6371], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6338], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6343], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6309], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6324], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6292], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6304], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6271], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6288], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6255], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6260], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6227], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6220], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6193], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6178], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6154], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6164], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6138], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6147], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6121], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6121], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6100], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6087], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.6083], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.6080], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.6079], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6124], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6121], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6152], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6151], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6151], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6148], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6146], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6141], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6188], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6190], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6221], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6225], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6233], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6238], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6251], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6260], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6264], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6272], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6267], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6277], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6289], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6311], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6329], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6342], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6343], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6352], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6373], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6376], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6384], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6387], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6385], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6392], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6380], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6389], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6402], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6411], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6422], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6427], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6415], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6426], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6407], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6414], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6421], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6429], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6444], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6447], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6455], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6460], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6442], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6450], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6450], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6459], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6463], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6474], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6476], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6493], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6479], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6498], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6503], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6517], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6537], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6549], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6552], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6565], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6563], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6575], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6587], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6608], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6617], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6638], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6643], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6661], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6664], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6679], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6676], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6692], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6679], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6690], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6711], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6722], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6734], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6749], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6742], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6755], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6748], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6760], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6763], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6774], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6765], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6777], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6767], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6775], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6787], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6792], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6794], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6797], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6789], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6792], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6784], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6790], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6785], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6791], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6787], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6786], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6786], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6785], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6769], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6771], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6756], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6754], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6762], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6763], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6768], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6768], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6754], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6760], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6742], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6745], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6761], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6770], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6760], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6773], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6781], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6787], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6789], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6797], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6810], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6813], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6813], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6814], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6823], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6830], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6827], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6830], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6834], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6849], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6842], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6863], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6865], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6884], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6886], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6907], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6925], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6946], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6943], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6961], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6979], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6999], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.7025], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.7053], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.7053], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.7078], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.7096], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.7113], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.7127], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.7142], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.7130], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.7143], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.7134], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.7160], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.7178], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7191], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7199], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7214], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7193], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7209], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7200], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7213], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7206], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7218], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7208], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7218], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7223], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7232], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7238], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7231], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7243], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7229], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7241], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7245], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7256], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7262], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7273], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7262], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7277], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7257], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7271], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7294], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7303], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7320], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7325], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7327], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7335], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7315], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7320], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7332], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7334], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7339], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7345], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7335], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7339], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7322], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7325], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7324], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7330], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7327], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7333], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7324], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7326], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7333], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7329], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7332], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7319], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7309], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7303], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7285], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7283], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7278], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7272], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7280], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7279], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7262], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7257], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7229], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7233], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7217], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7225], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7250], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7259], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7267], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7284], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7293], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7315], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7316], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7338], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7364], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7378], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7417], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7431], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7432], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7445], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7457], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7468], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7490], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7500], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7514], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7591], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7566], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7586], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7585], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7603], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7612], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7632], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7626], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7648], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7634], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7652], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7679], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7691], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7714], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7723], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7713], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7727], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7717], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7742], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7760], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7759], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7777], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7766], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7784], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 9--\n",
      "-----> Predicción pre entreno: tensor([0.7316], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7251], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7184], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7194], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7140], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7146], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.7093], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.7107], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.7051], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.7067], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.7014], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.7007], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.6955], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.6963], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.6916], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.6934], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.6890], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.6911], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.6865], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6874], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6829], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6832], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6787], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6784], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6738], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6748], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6702], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6718], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6675], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6675], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6629], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6633], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6587], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6585], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6537], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6531], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6485], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6473], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6430], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6431], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6388], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6390], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6355], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6346], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6314], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6315], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6285], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6291], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6261], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6282], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6250], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6255], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6222], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6236], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6205], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6217], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6184], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6201], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6169], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6174], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6142], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6135], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6109], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6094], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.6071], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.6080], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.6055], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.6065], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.6039], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.6039], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.6019], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.6006], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.6003], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.6000], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.6000], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.6044], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.6041], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6073], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6073], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6072], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6070], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6069], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6065], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6110], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6113], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6142], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6147], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6155], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6161], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6174], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6183], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6188], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6191], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6202], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6214], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6224], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6241], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6255], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6256], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6266], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6286], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6290], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6297], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6302], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6299], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6307], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6305], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6317], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6326], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6337], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6344], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6332], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6343], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6324], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6333], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6339], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6347], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6362], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6366], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6373], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6379], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6362], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6370], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6370], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6378], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6383], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6394], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6396], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6414], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6401], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6420], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6425], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6440], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6460], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6473], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6475], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6488], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6486], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6499], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6511], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6533], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6541], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6562], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6568], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6586], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6590], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6605], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6603], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6619], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6606], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6617], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6638], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6649], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6660], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6676], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6668], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6682], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6676], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6688], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6691], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6704], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6695], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6713], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6704], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6713], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6724], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6730], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6732], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6735], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6727], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6723], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6730], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6725], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6727], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6727], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6727], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6727], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6711], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6714], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6698], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6697], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6706], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6706], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6712], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6712], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6699], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6705], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6688], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6691], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6706], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6717], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6708], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6716], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6722], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6730], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6732], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6740], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6753], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6756], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6757], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6758], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6767], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6774], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6771], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6775], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6778], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6794], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6788], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6810], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6811], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6830], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6833], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6854], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6872], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6891], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6889], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6906], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6924], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6945], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6969], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.6998], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.6998], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.7024], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.7040], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.7057], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.7071], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.7088], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.7076], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.7089], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.7080], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.7092], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.7109], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7124], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7131], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7147], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7128], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7188], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7179], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7191], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7185], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7186], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7196], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7195], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7200], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7210], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7216], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7208], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7221], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7206], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7219], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7224], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7237], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7254], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7259], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7239], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7274], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7287], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7304], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7309], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7310], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7319], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7299], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7305], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7315], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7318], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7323], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7329], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7319], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7323], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7306], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7310], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7308], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7315], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7312], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7318], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7309], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7319], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7314], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7318], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7305], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7289], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7271], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7269], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7264], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7267], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7265], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7249], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7245], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7217], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7221], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7206], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7214], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7238], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7247], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7255], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7274], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7283], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7305], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7306], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7328], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7353], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7368], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7405], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7420], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7420], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7433], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7444], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7476], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7486], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7500], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7520], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7494], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7514], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7513], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7531], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7542], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7563], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7557], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7580], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7566], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7585], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7613], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7626], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7650], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7661], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7651], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7665], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7654], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7669], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7679], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7698], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7696], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7715], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7704], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7722], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---Inicio de epoca: 10--\n",
      "-----> Predicción pre entreno: tensor([0.7171], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1201, 0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422])\n",
      "----->Salida de la red: tensor([0.7108], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.0461])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 1\n",
      "-----> Predicción pre entreno: tensor([0.7099], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0198, 0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461])\n",
      "----->Salida de la red: tensor([0.7042], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1042])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 2\n",
      "-----> Predicción pre entreno: tensor([0.7053], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0000, 0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042])\n",
      "----->Salida de la red: tensor([0.7000], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1542])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 3\n",
      "-----> Predicción pre entreno: tensor([0.7008], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0186, 0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542])\n",
      "----->Salida de la red: tensor([0.6956], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1558])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 4\n",
      "-----> Predicción pre entreno: tensor([0.6972], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0566, 0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558])\n",
      "----->Salida de la red: tensor([0.6918], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1255])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 5\n",
      "-----> Predicción pre entreno: tensor([0.6936], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0260, 0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255])\n",
      "----->Salida de la red: tensor([0.6884], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1457])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 6\n",
      "-----> Predicción pre entreno: tensor([0.6879], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0345, 0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457])\n",
      "----->Salida de la red: tensor([0.6827], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1465])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 7\n",
      "-----> Predicción pre entreno: tensor([0.6837], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0422, 0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465])\n",
      "----->Salida de la red: tensor([0.6791], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1960])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 8\n",
      "-----> Predicción pre entreno: tensor([0.6811], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.0461, 0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960])\n",
      "----->Salida de la red: tensor([0.6769], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2305])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 9\n",
      "-----> Predicción pre entreno: tensor([0.6792], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1042, 0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305])\n",
      "----->Salida de la red: tensor([0.6747], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2084])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 10\n",
      "-----> Predicción pre entreno: tensor([0.6757], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1542, 0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084])\n",
      "----->Salida de la red: tensor([0.6713], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2119])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 11\n",
      "-----> Predicción pre entreno: tensor([0.6717], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1558, 0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119])\n",
      "----->Salida de la red: tensor([0.6673], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2073])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 12\n",
      "-----> Predicción pre entreno: tensor([0.6672], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1255, 0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073])\n",
      "----->Salida de la red: tensor([0.6627], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1929])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 13\n",
      "-----> Predicción pre entreno: tensor([0.6637], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1457, 0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929])\n",
      "----->Salida de la red: tensor([0.6593], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1968])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 14\n",
      "-----> Predicción pre entreno: tensor([0.6610], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1465, 0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968])\n",
      "----->Salida de la red: tensor([0.6568], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2143])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 15\n",
      "-----> Predicción pre entreno: tensor([0.6568], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1960, 0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143])\n",
      "----->Salida de la red: tensor([0.6523], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1813])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 16\n",
      "-----> Predicción pre entreno: tensor([0.6527], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2305, 0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813])\n",
      "----->Salida de la red: tensor([0.6482], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1751])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 17\n",
      "-----> Predicción pre entreno: tensor([0.6480], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2084, 0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751])\n",
      "----->Salida de la red: tensor([0.6433], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1480])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 18\n",
      "-----> Predicción pre entreno: tensor([0.6426], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2119, 0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480])\n",
      "----->Salida de la red: tensor([0.6380], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1589])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 19\n",
      "-----> Predicción pre entreno: tensor([0.6368], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2073, 0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589])\n",
      "----->Salida de la red: tensor([0.6326], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1922])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 20\n",
      "-----> Predicción pre entreno: tensor([0.6326], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1929, 0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922])\n",
      "----->Salida de la red: tensor([0.6284], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.1860])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 21\n",
      "-----> Predicción pre entreno: tensor([0.6286], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1968, 0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860])\n",
      "----->Salida de la red: tensor([0.6252], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2670])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 22\n",
      "-----> Predicción pre entreno: tensor([0.6243], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2143, 0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670])\n",
      "----->Salida de la red: tensor([0.6212], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2925])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 23\n",
      "-----> Predicción pre entreno: tensor([0.6214], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1813, 0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925])\n",
      "----->Salida de la red: tensor([0.6185], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3177])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 24\n",
      "-----> Predicción pre entreno: tensor([0.6193], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1751, 0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177])\n",
      "----->Salida de la red: tensor([0.6164], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3127])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 25\n",
      "-----> Predicción pre entreno: tensor([0.6187], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1480, 0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127])\n",
      "----->Salida de la red: tensor([0.6156], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2890])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 26\n",
      "-----> Predicción pre entreno: tensor([0.6163], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1589, 0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890])\n",
      "----->Salida de la red: tensor([0.6132], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2828])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 27\n",
      "-----> Predicción pre entreno: tensor([0.6147], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1922, 0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828])\n",
      "----->Salida de la red: tensor([0.6118], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2995])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 28\n",
      "-----> Predicción pre entreno: tensor([0.6131], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.1860, 0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995])\n",
      "----->Salida de la red: tensor([0.6099], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2759])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 29\n",
      "-----> Predicción pre entreno: tensor([0.6117], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2670, 0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759])\n",
      "----->Salida de la red: tensor([0.6085], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2747])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 30\n",
      "-----> Predicción pre entreno: tensor([0.6090], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2925, 0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747])\n",
      "----->Salida de la red: tensor([0.6059], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.2755])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 31\n",
      "-----> Predicción pre entreno: tensor([0.6051], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3177, 0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755])\n",
      "----->Salida de la red: tensor([0.6026], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3348])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 32\n",
      "-----> Predicción pre entreno: tensor([0.6011], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3127, 0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348])\n",
      "----->Salida de la red: tensor([0.5988], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3557])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 33\n",
      "-----> Predicción pre entreno: tensor([0.5998], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2890, 0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557])\n",
      "----->Salida de la red: tensor([0.5974], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3367])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 34\n",
      "-----> Predicción pre entreno: tensor([0.5985], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2828, 0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367])\n",
      "----->Salida de la red: tensor([0.5960], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3336])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 35\n",
      "-----> Predicción pre entreno: tensor([0.5961], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2995, 0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336])\n",
      "----->Salida de la red: tensor([0.5941], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.3847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 36\n",
      "-----> Predicción pre entreno: tensor([0.5929], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2759, 0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847])\n",
      "----->Salida de la red: tensor([0.5927], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 37\n",
      "-----> Predicción pre entreno: tensor([0.5925], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2747, 0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711])\n",
      "----->Salida de la red: tensor([0.5926], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5963])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 38\n",
      "-----> Predicción pre entreno: tensor([0.5975], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.2755, 0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963])\n",
      "----->Salida de la red: tensor([0.5973], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5746])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 39\n",
      "-----> Predicción pre entreno: tensor([0.6008], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3348, 0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746])\n",
      "----->Salida de la red: tensor([0.6009], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6064])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 40\n",
      "-----> Predicción pre entreno: tensor([0.6011], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3557, 0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064])\n",
      "----->Salida de la red: tensor([0.6010], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5847])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 41\n",
      "-----> Predicción pre entreno: tensor([0.6011], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3367, 0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847])\n",
      "----->Salida de la red: tensor([0.6008], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.5688])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 42\n",
      "-----> Predicción pre entreno: tensor([0.6057], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3336, 0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688])\n",
      "----->Salida de la red: tensor([0.6061], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6428])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 43\n",
      "-----> Predicción pre entreno: tensor([0.6093], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.3847, 0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428])\n",
      "----->Salida de la red: tensor([0.6098], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6618])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 44\n",
      "-----> Predicción pre entreno: tensor([0.6108], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5711, 0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618])\n",
      "----->Salida de la red: tensor([0.6114], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6730])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 45\n",
      "-----> Predicción pre entreno: tensor([0.6128], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5963, 0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730])\n",
      "----->Salida de la red: tensor([0.6138], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7106])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 46\n",
      "-----> Predicción pre entreno: tensor([0.6144], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5746, 0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106])\n",
      "----->Salida de la red: tensor([0.6155], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7040])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 47\n",
      "-----> Predicción pre entreno: tensor([0.6151], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6064, 0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040])\n",
      "----->Salida de la red: tensor([0.6163], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7272])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 48\n",
      "-----> Predicción pre entreno: tensor([0.6176], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5847, 0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272])\n",
      "----->Salida de la red: tensor([0.6186], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 49\n",
      "-----> Predicción pre entreno: tensor([0.6205], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.5688, 0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226])\n",
      "----->Salida de la red: tensor([0.6220], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7718])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 50\n",
      "-----> Predicción pre entreno: tensor([0.6222], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6428, 0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718])\n",
      "----->Salida de la red: tensor([0.6232], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7245])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 51\n",
      "-----> Predicción pre entreno: tensor([0.6253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6618, 0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245])\n",
      "----->Salida de la red: tensor([0.6258], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6711])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 52\n",
      "-----> Predicción pre entreno: tensor([0.6266], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6730, 0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711])\n",
      "----->Salida de la red: tensor([0.6270], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6738])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 53\n",
      "-----> Predicción pre entreno: tensor([0.6267], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7106, 0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738])\n",
      "----->Salida de la red: tensor([0.6317], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7145])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 54\n",
      "-----> Predicción pre entreno: tensor([0.6305], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7040, 0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145])\n",
      "----->Salida de la red: tensor([0.6318], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7439])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 55\n",
      "-----> Predicción pre entreno: tensor([0.6329], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7272, 0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439])\n",
      "----->Salida de la red: tensor([0.6338], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 56\n",
      "-----> Predicción pre entreno: tensor([0.6348], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226])\n",
      "----->Salida de la red: tensor([0.6354], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6993])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 57\n",
      "-----> Predicción pre entreno: tensor([0.6343], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7718, 0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993])\n",
      "----->Salida de la red: tensor([0.6353], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7373])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 58\n",
      "-----> Predicción pre entreno: tensor([0.6336], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7245, 0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373])\n",
      "----->Salida de la red: tensor([0.6344], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7214])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 59\n",
      "-----> Predicción pre entreno: tensor([0.6351], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6711, 0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214])\n",
      "----->Salida de la red: tensor([0.6359], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7187])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 60\n",
      "-----> Predicción pre entreno: tensor([0.6373], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6738, 0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187])\n",
      "----->Salida de la red: tensor([0.6377], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6742])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 61\n",
      "-----> Predicción pre entreno: tensor([0.6384], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7145, 0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742])\n",
      "----->Salida de la red: tensor([0.6390], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6986])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 62\n",
      "-----> Predicción pre entreno: tensor([0.6372], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7439, 0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986])\n",
      "----->Salida de la red: tensor([0.6380], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7210])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 63\n",
      "-----> Predicción pre entreno: tensor([0.6380], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210])\n",
      "----->Salida de la red: tensor([0.6388], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7226])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 64\n",
      "-----> Predicción pre entreno: tensor([0.6392], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6993, 0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226])\n",
      "----->Salida de la red: tensor([0.6403], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7563])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 65\n",
      "-----> Predicción pre entreno: tensor([0.6405], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7373, 0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563])\n",
      "----->Salida de la red: tensor([0.6423], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8276])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 66\n",
      "-----> Predicción pre entreno: tensor([0.6411], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7214, 0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276])\n",
      "----->Salida de la red: tensor([0.6430], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8388])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 67\n",
      "-----> Predicción pre entreno: tensor([0.6437], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7187, 0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388])\n",
      "----->Salida de la red: tensor([0.6451], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7943])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 68\n",
      "-----> Predicción pre entreno: tensor([0.6472], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6742, 0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943])\n",
      "----->Salida de la red: tensor([0.6485], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 69\n",
      "-----> Predicción pre entreno: tensor([0.6489], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6986, 0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838])\n",
      "----->Salida de la red: tensor([0.6500], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7679])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 70\n",
      "-----> Predicción pre entreno: tensor([0.6500], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7210, 0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679])\n",
      "----->Salida de la red: tensor([0.6513], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7846])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 71\n",
      "-----> Predicción pre entreno: tensor([0.6524], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7226, 0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846])\n",
      "----->Salida de la red: tensor([0.6546], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8787])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 72\n",
      "-----> Predicción pre entreno: tensor([0.6554], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7563, 0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787])\n",
      "----->Salida de la red: tensor([0.6575], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8756])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 73\n",
      "-----> Predicción pre entreno: tensor([0.6582], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8276, 0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756])\n",
      "----->Salida de la red: tensor([0.6600], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 74\n",
      "-----> Predicción pre entreno: tensor([0.6605], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8388, 0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489])\n",
      "----->Salida de la red: tensor([0.6620], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 75\n",
      "-----> Predicción pre entreno: tensor([0.6618], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7943, 0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183])\n",
      "----->Salida de la red: tensor([0.6634], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8268])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 76\n",
      "-----> Predicción pre entreno: tensor([0.6622], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268])\n",
      "----->Salida de la red: tensor([0.6635], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 77\n",
      "-----> Predicción pre entreno: tensor([0.6655], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7679, 0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854])\n",
      "----->Salida de la red: tensor([0.6670], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7892])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 78\n",
      "-----> Predicción pre entreno: tensor([0.6680], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7846, 0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892])\n",
      "----->Salida de la red: tensor([0.6696], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 79\n",
      "-----> Predicción pre entreno: tensor([0.6688], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8787, 0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342])\n",
      "----->Salida de la red: tensor([0.6701], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8125])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 80\n",
      "-----> Predicción pre entreno: tensor([0.6695], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8756, 0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125])\n",
      "----->Salida de la red: tensor([0.6707], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8012])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 81\n",
      "-----> Predicción pre entreno: tensor([0.6709], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012])\n",
      "----->Salida de la red: tensor([0.6721], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8032])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 82\n",
      "-----> Predicción pre entreno: tensor([0.6713], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032])\n",
      "----->Salida de la red: tensor([0.6731], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7935])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 83\n",
      "-----> Predicción pre entreno: tensor([0.6722], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8268, 0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935])\n",
      "----->Salida de la red: tensor([0.6730], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 84\n",
      "-----> Predicción pre entreno: tensor([0.6741], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7854, 0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602])\n",
      "----->Salida de la red: tensor([0.6747], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7354])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 85\n",
      "-----> Predicción pre entreno: tensor([0.6748], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7892, 0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354])\n",
      "----->Salida de la red: tensor([0.6752], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7102])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 86\n",
      "-----> Predicción pre entreno: tensor([0.6743], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102])\n",
      "----->Salida de la red: tensor([0.6746], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7121])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 87\n",
      "-----> Predicción pre entreno: tensor([0.6737], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8125, 0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121])\n",
      "----->Salida de la red: tensor([0.6743], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 88\n",
      "-----> Predicción pre entreno: tensor([0.6737], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8012, 0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396])\n",
      "----->Salida de la red: tensor([0.6743], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7361])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 89\n",
      "-----> Predicción pre entreno: tensor([0.6738], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8032, 0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361])\n",
      "----->Salida de la red: tensor([0.6737], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6676])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 90\n",
      "-----> Predicción pre entreno: tensor([0.6736], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7935, 0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676])\n",
      "----->Salida de la red: tensor([0.6736], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6699])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 91\n",
      "-----> Predicción pre entreno: tensor([0.6719], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699])\n",
      "----->Salida de la red: tensor([0.6721], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6966])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 92\n",
      "-----> Predicción pre entreno: tensor([0.6705], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7354, 0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966])\n",
      "----->Salida de la red: tensor([0.6704], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6559])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 93\n",
      "-----> Predicción pre entreno: tensor([0.6712], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7102, 0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559])\n",
      "----->Salida de la red: tensor([0.6712], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6788])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 94\n",
      "-----> Predicción pre entreno: tensor([0.6716], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7121, 0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788])\n",
      "----->Salida de la red: tensor([0.6717], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6761])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 95\n",
      "-----> Predicción pre entreno: tensor([0.6703], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7396, 0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761])\n",
      "----->Salida de la red: tensor([0.6709], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7296])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 96\n",
      "-----> Predicción pre entreno: tensor([0.6691], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7361, 0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296])\n",
      "----->Salida de la red: tensor([0.6694], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7013])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 97\n",
      "-----> Predicción pre entreno: tensor([0.6710], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6676, 0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013])\n",
      "----->Salida de la red: tensor([0.6720], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7675])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 98\n",
      "-----> Predicción pre entreno: tensor([0.6711], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6699, 0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675])\n",
      "----->Salida de la red: tensor([0.6719], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 99\n",
      "-----> Predicción pre entreno: tensor([0.6728], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6966, 0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551])\n",
      "----->Salida de la red: tensor([0.6735], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7451])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 100\n",
      "-----> Predicción pre entreno: tensor([0.6739], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6559, 0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451])\n",
      "----->Salida de la red: tensor([0.6747], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7520])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 101\n",
      "-----> Predicción pre entreno: tensor([0.6761], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6788, 0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520])\n",
      "----->Salida de la red: tensor([0.6764], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7098])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 102\n",
      "-----> Predicción pre entreno: tensor([0.6766], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6761, 0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098])\n",
      "----->Salida de la red: tensor([0.6767], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6904])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 103\n",
      "-----> Predicción pre entreno: tensor([0.6776], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7296, 0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904])\n",
      "----->Salida de la red: tensor([0.6783], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7544])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 104\n",
      "-----> Predicción pre entreno: tensor([0.6779], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7013, 0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544])\n",
      "----->Salida de la red: tensor([0.6783], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7222])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 105\n",
      "-----> Predicción pre entreno: tensor([0.6787], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7675, 0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222])\n",
      "----->Salida de la red: tensor([0.6803], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8485])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 106\n",
      "-----> Predicción pre entreno: tensor([0.6795], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7551, 0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485])\n",
      "----->Salida de la red: tensor([0.6817], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9055])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 107\n",
      "-----> Predicción pre entreno: tensor([0.6820], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7451, 0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055])\n",
      "----->Salida de la red: tensor([0.6839], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8822])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 108\n",
      "-----> Predicción pre entreno: tensor([0.6844], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7520, 0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822])\n",
      "----->Salida de la red: tensor([0.6865], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9078])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 109\n",
      "-----> Predicción pre entreno: tensor([0.6886], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7098, 0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078])\n",
      "----->Salida de la red: tensor([0.6905], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8896])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 110\n",
      "-----> Predicción pre entreno: tensor([0.6906], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6904, 0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896])\n",
      "----->Salida de la red: tensor([0.6923], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8749])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 111\n",
      "-----> Predicción pre entreno: tensor([0.6944], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7544, 0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749])\n",
      "----->Salida de la red: tensor([0.6964], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9132])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 112\n",
      "-----> Predicción pre entreno: tensor([0.6990], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7222, 0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132])\n",
      "----->Salida de la red: tensor([0.7019], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([1.])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 113\n",
      "-----> Predicción pre entreno: tensor([0.7020], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8485, 0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000])\n",
      "----->Salida de la red: tensor([0.7046], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9706])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 114\n",
      "-----> Predicción pre entreno: tensor([0.7064], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9055, 0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706])\n",
      "----->Salida de la red: tensor([0.7082], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8888])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 115\n",
      "-----> Predicción pre entreno: tensor([0.7096], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8822, 0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888])\n",
      "----->Salida de la red: tensor([0.7112], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8780])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 116\n",
      "-----> Predicción pre entreno: tensor([0.7101], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9078, 0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780])\n",
      "----->Salida de la red: tensor([0.7114], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 117\n",
      "-----> Predicción pre entreno: tensor([0.7105], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8896, 0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489])\n",
      "----->Salida de la red: tensor([0.7116], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8342])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 118\n",
      "-----> Predicción pre entreno: tensor([0.7133], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8749, 0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342])\n",
      "----->Salida de la red: tensor([0.7146], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8551])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 119\n",
      "-----> Predicción pre entreno: tensor([0.7152], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9132, 1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551])\n",
      "----->Salida de la red: tensor([0.7167], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 120\n",
      "-----> Predicción pre entreno: tensor([0.7147], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([1.0000, 0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752])\n",
      "----->Salida de la red: tensor([0.7160], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8570])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 121\n",
      "-----> Predicción pre entreno: tensor([0.7151], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9706, 0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570])\n",
      "----->Salida de la red: tensor([0.7164], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8501])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 122\n",
      "-----> Predicción pre entreno: tensor([0.7156], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8888, 0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501])\n",
      "----->Salida de la red: tensor([0.7168], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8427])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 123\n",
      "-----> Predicción pre entreno: tensor([0.7159], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8780, 0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427])\n",
      "----->Salida de la red: tensor([0.7247], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8229])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 124\n",
      "-----> Predicción pre entreno: tensor([0.7245], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229])\n",
      "----->Salida de la red: tensor([0.7250], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7745])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 125\n",
      "-----> Predicción pre entreno: tensor([0.7259], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8342, 0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745])\n",
      "----->Salida de la red: tensor([0.7265], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7842])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 126\n",
      "-----> Predicción pre entreno: tensor([0.7256], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8551, 0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842])\n",
      "----->Salida de la red: tensor([0.7269], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 127\n",
      "-----> Predicción pre entreno: tensor([0.7253], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597])\n",
      "----->Salida de la red: tensor([0.7266], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8543])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 128\n",
      "-----> Predicción pre entreno: tensor([0.7271], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8570, 0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543])\n",
      "----->Salida de la red: tensor([0.7282], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8369])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 129\n",
      "-----> Predicción pre entreno: tensor([0.7289], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8501, 0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369])\n",
      "----->Salida de la red: tensor([0.7299], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8299])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 130\n",
      "-----> Predicción pre entreno: tensor([0.7288], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8427, 0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299])\n",
      "----->Salida de la red: tensor([0.7303], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8873])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 131\n",
      "-----> Predicción pre entreno: tensor([0.7283], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8229, 0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873])\n",
      "----->Salida de la red: tensor([0.7296], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 132\n",
      "-----> Predicción pre entreno: tensor([0.7319], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7745, 0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597])\n",
      "----->Salida de la red: tensor([0.7330], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8396])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 133\n",
      "-----> Predicción pre entreno: tensor([0.7347], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7842, 0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396])\n",
      "----->Salida de la red: tensor([0.7352], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7838])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 134\n",
      "-----> Predicción pre entreno: tensor([0.7354], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838])\n",
      "----->Salida de la red: tensor([0.7363], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8183])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 135\n",
      "-----> Predicción pre entreno: tensor([0.7341], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8543, 0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183])\n",
      "----->Salida de la red: tensor([0.7347], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7912])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 136\n",
      "-----> Predicción pre entreno: tensor([0.7357], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8369, 0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912])\n",
      "----->Salida de la red: tensor([0.7360], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7606])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 137\n",
      "-----> Predicción pre entreno: tensor([0.7364], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8299, 0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606])\n",
      "----->Salida de la red: tensor([0.7369], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7916])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 138\n",
      "-----> Predicción pre entreno: tensor([0.7359], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8873, 0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916])\n",
      "----->Salida de la red: tensor([0.7362], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 139\n",
      "-----> Predicción pre entreno: tensor([0.7344], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8597, 0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687])\n",
      "----->Salida de la red: tensor([0.7348], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7687])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 140\n",
      "-----> Predicción pre entreno: tensor([0.7345], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8396, 0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687])\n",
      "----->Salida de la red: tensor([0.7352], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7989])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 141\n",
      "-----> Predicción pre entreno: tensor([0.7348], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7838, 0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989])\n",
      "----->Salida de la red: tensor([0.7353], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7900])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 142\n",
      "-----> Predicción pre entreno: tensor([0.7345], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8183, 0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900])\n",
      "----->Salida de la red: tensor([0.7347], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7602])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 143\n",
      "-----> Predicción pre entreno: tensor([0.7354], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7912, 0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602])\n",
      "----->Salida de la red: tensor([0.7349], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6854])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 144\n",
      "-----> Predicción pre entreno: tensor([0.7353], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7606, 0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854])\n",
      "----->Salida de la red: tensor([0.7339], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6052])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 145\n",
      "-----> Predicción pre entreno: tensor([0.7329], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7916, 0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052])\n",
      "----->Salida de la red: tensor([0.7323], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 146\n",
      "-----> Predicción pre entreno: tensor([0.7302], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649])\n",
      "----->Salida de la red: tensor([0.7300], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7079])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 147\n",
      "-----> Predicción pre entreno: tensor([0.7293], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7687, 0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079])\n",
      "----->Salida de la red: tensor([0.7287], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6649])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 148\n",
      "-----> Predicción pre entreno: tensor([0.7295], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7989, 0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649])\n",
      "----->Salida de la red: tensor([0.7293], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7114])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 149\n",
      "-----> Predicción pre entreno: tensor([0.7276], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7900, 0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114])\n",
      "----->Salida de la red: tensor([0.7271], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.6773])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 150\n",
      "-----> Predicción pre entreno: tensor([0.7244], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7602, 0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773])\n",
      "----->Salida de la red: tensor([0.7247], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.7621])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 151\n",
      "-----> Predicción pre entreno: tensor([0.7230], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6854, 0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621])\n",
      "----->Salida de la red: tensor([0.7239], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8071])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 152\n",
      "-----> Predicción pre entreno: tensor([0.7264], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6052, 0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071])\n",
      "----->Salida de la red: tensor([0.7272], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8152])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 153\n",
      "-----> Predicción pre entreno: tensor([0.7283], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152])\n",
      "----->Salida de la red: tensor([0.7300], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9062])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 154\n",
      "-----> Predicción pre entreno: tensor([0.7310], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7079, 0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062])\n",
      "----->Salida de la red: tensor([0.7332], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9597])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 155\n",
      "-----> Predicción pre entreno: tensor([0.7336], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6649, 0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597])\n",
      "----->Salida de la red: tensor([0.7358], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9644])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 156\n",
      "-----> Predicción pre entreno: tensor([0.7386], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7114, 0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644])\n",
      "----->Salida de la red: tensor([0.7400], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8880])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 157\n",
      "-----> Predicción pre entreno: tensor([0.7441], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.6773, 0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880])\n",
      "----->Salida de la red: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8927])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 158\n",
      "-----> Predicción pre entreno: tensor([0.7457], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.7621, 0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927])\n",
      "----->Salida de la red: tensor([0.7470], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8752])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 159\n",
      "-----> Predicción pre entreno: tensor([0.7482], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8071, 0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752])\n",
      "----->Salida de la red: tensor([0.7492], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8508])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 160\n",
      "-----> Predicción pre entreno: tensor([0.7514], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8152, 0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508])\n",
      "----->Salida de la red: tensor([0.7523], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8489])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 161\n",
      "-----> Predicción pre entreno: tensor([0.7537], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9062, 0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489])\n",
      "----->Salida de la red: tensor([0.7557], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9624])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 162\n",
      "-----> Predicción pre entreno: tensor([0.7529], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9597, 0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624])\n",
      "----->Salida de la red: tensor([0.7550], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9678])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 163\n",
      "-----> Predicción pre entreno: tensor([0.7550], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9644, 0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678])\n",
      "----->Salida de la red: tensor([0.7567], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9407])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 164\n",
      "-----> Predicción pre entreno: tensor([0.7578], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8880, 0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407])\n",
      "----->Salida de la red: tensor([0.7598], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9725])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 165\n",
      "-----> Predicción pre entreno: tensor([0.7594], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8927, 0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725])\n",
      "----->Salida de la red: tensor([0.7616], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9969])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 166\n",
      "-----> Predicción pre entreno: tensor([0.7603], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8752, 0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969])\n",
      "----->Salida de la red: tensor([0.7622], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9512])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 167\n",
      "-----> Predicción pre entreno: tensor([0.7652], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8508, 0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512])\n",
      "----->Salida de la red: tensor([0.7665], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8958])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 168\n",
      "-----> Predicción pre entreno: tensor([0.7689], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.8489, 0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958])\n",
      "----->Salida de la red: tensor([0.7701], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.8814])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 169\n",
      "-----> Predicción pre entreno: tensor([0.7692], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9624, 0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814])\n",
      "----->Salida de la red: tensor([0.7705], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9171])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 170\n",
      "-----> Predicción pre entreno: tensor([0.7693], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9678, 0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171])\n",
      "----->Salida de la red: tensor([0.7707], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9198])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 171\n",
      "-----> Predicción pre entreno: tensor([0.7717], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9407, 0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198])\n",
      "----->Salida de la red: tensor([0.7736], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9616])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 172\n",
      "-----> Predicción pre entreno: tensor([0.7734], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9725, 0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616])\n",
      "----->Salida de la red: tensor([0.7752], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9682])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 173\n",
      "-----> Predicción pre entreno: tensor([0.7742], grad_fn=<ViewBackward0>) \n",
      ">>Paso...<<\n",
      ">>Fin de paso<<\n",
      ">>Se calcula perdida despues del paso...\n",
      "entrada: tensor([0.9969, 0.9512, 0.8958, 0.8814, 0.9171, 0.9198, 0.9616, 0.9682])\n",
      "----->Salida de la red: tensor([0.7759], grad_fn=<ViewBackward0>)\n",
      "----->Salida esperada: tensor([0.9578])\n",
      "Lambda: 0.05\n",
      "lr: 0.01, batch: 174\n",
      "Se resetea\n",
      "---FIN DE ENTRENAMIENTO: entrena_LM---\n"
     ]
    }
   ],
   "source": [
    "from src.modelos.auto_regresivo.NARNN.NARNN import NARNN\n",
    "from src.modelos.auto_regresivo.entrenamientos.entrenamiento import Entrenamiento as entr\n",
    "\n",
    "red = NARNN(input_dim=8, hidden_dim=0, num_layers= 0, output_dim=1, nombre=\"NARNN\")\n",
    "#red.load_state_dict(torch.load('redes/NARNN/estandar/red.pth'))\n",
    "#red.eval()\n",
    "\n",
    "entrenamiento_8_1 = [[]]\n",
    "prueba_8_1 = [[]]\n",
    "\n",
    "# A cada uno de los conjuntos de entrenamiento se les da una forma de entrada en especifico,\n",
    "# que es un arreglo de 8 y uno de un solo elemento para representar la salida\n",
    "\n",
    "entrenamiento_8_1[0] = utls.corrimiento_t_1(c_entrenamiento_n,9) # list(tensor[()]*) una lista de 174 tensores con 9 elementos cada uno\n",
    "prueba_8_1[0] = utls.corrimiento_t_1(c_prueba_n,9) # list(tensor[()]*) una lista de 78 tensores con 9 elementos cada uno\n",
    "\n",
    "# Se realiza el entrenamiento de cada una de las redes y se guarda el modelo ya entrenado\n",
    "\n",
    "entr_red = entr(red,0,writer_dir=logs_dir)\n",
    "entr_red.entrena_lm(entrenamiento_8_1[0],epocas=5,lr=0.01,λ=0.1,e_predictivo=False)\n",
    "torch.save(red.state_dict(), 'redes/NARNN/red_NARNN.pth') #Salvamos el estado actual del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción del conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdida: 29.140090174497164\n"
     ]
    }
   ],
   "source": [
    "#Se grafica el conjunto de entrenamiento\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "prediccion = utls.genera_prediccion_1(prueba_8_1[0],red,8)\n",
    "precios_predichos = utls.desnormalizar(prediccion,np.max(c_prueba),np.min(c_prueba)).detach().numpy()\n",
    "plt.plot(c_prueba, color = '#451952', label = 'Precios originales') \n",
    "plt.plot(precios_predichos, label = 'Precios predichos')\n",
    "plt.title('Conjunto de Prueba')\n",
    "plt.xlabel('Semanas')\n",
    "plt.ylabel('Precio')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Perdida: {float(criterion(torch.tensor(precios_predichos), torch.tensor(c_prueba)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          RMSE    MAPE       DS\n",
      "Precicción de c_prueba  5.3982  13.111  46.5116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "r_c_prueba_txt = 'Precicción de c_prueba'\n",
    "# Supongamos que tenemos una lista de errores de predicción para cada red neuronal\n",
    "rmse = {\n",
    "    r_c_prueba_txt: utls.rmse(c_prueba,precios_predichos)\n",
    "}\n",
    "mape = {\n",
    "    r_c_prueba_txt: utls.mape(c_prueba,precios_predichos)\n",
    "}\n",
    "ds = {\n",
    "    r_c_prueba_txt: utls.directional_symmetry(c_prueba,precios_predichos)\n",
    "}\n",
    "\n",
    "# Creamos un DataFrame de Pandas a partir del diccionario de errores\n",
    "df_errores = pd.DataFrame({\n",
    "    'RMSE': pd.Series(rmse),\n",
    "    'MAPE': pd.Series(mape),\n",
    "    'DS': pd.Series(ds)\n",
    "})\n",
    "\n",
    "# Mostramos el DataFrame con los errores\n",
    "print(df_errores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos el entrenamiento predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el número de epocas\n",
    "EPOCAS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.24802819]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037179067730903625, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24802819]] | y: 0.10422316931421921 | Predicción actual: [[0.23225437]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01266101561486721, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24802819]\n",
      " [0.23225437]] | y: 0.15420379697791559 | Predicción actual: [[0.23611084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00687388563528657, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24802819]\n",
      " [0.23225437]\n",
      " [0.23611084]] | y: 0.1557535838822161 | Predicción actual: [[0.24782157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010962770320475101, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24802819]\n",
      " [0.23225437]\n",
      " [0.23611084]\n",
      " [0.24782157]] | y: 0.12553273924835334 | Predicción actual: [[0.26164153]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018370745703577995, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24802819]\n",
      " [0.23225437]\n",
      " [0.23611084]\n",
      " [0.24782157]\n",
      " [0.26164153]] | y: 0.1456799690042619 | Predicción actual: [[0.2741652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010779556818306446, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.24802819]\n",
      " [0.23225437]\n",
      " [0.23611084]\n",
      " [0.24782157]\n",
      " [0.26164153]\n",
      " [0.27416521]] | y: 0.1464548624564122 | Predicción actual: [[0.29914078]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030998666770756245, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.24802819]\n",
      " [0.23225437]\n",
      " [0.23611084]\n",
      " [0.24782157]\n",
      " [0.26164153]\n",
      " [0.27416521]\n",
      " [0.29914078]] | y: 0.1960480433940332 | Predicción actual: [[0.33049366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03480622172355652, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24802819]\n",
      " [0.23225437]\n",
      " [0.23611084]\n",
      " [0.24782157]\n",
      " [0.26164153]\n",
      " [0.27416521]\n",
      " [0.29914078]\n",
      " [0.33049366]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021915797144174576, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23225437]\n",
      " [0.23611084]\n",
      " [0.24782157]\n",
      " [0.26164153]\n",
      " [0.27416521]\n",
      " [0.29914078]\n",
      " [0.33049366]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.36993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0076552159152925014, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23611084]\n",
      " [0.24782157]\n",
      " [0.26164153]\n",
      " [0.27416521]\n",
      " [0.29914078]\n",
      " [0.33049366]\n",
      " [0.2305308 ]\n",
      " [0.36993   ]] | y: 0.211933359163115 | Predicción actual: [[0.37613237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03886333107948303, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24782157]\n",
      " [0.26164153]\n",
      " [0.27416521]\n",
      " [0.29914078]\n",
      " [0.33049366]\n",
      " [0.2305308 ]\n",
      " [0.36993   ]\n",
      " [0.37613237]] | y: 0.2072839984502131 | Predicción actual: [[0.38416544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023776927962899208, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26164153]\n",
      " [0.27416521]\n",
      " [0.29914078]\n",
      " [0.33049366]\n",
      " [0.2305308 ]\n",
      " [0.36993   ]\n",
      " [0.37613237]\n",
      " [0.38416544]] | y: 0.19294846958543205 | Predicción actual: [[0.39285648]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0377703532576561, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27416521]\n",
      " [0.29914078]\n",
      " [0.33049366]\n",
      " [0.2305308 ]\n",
      " [0.36993   ]\n",
      " [0.37613237]\n",
      " [0.38416544]\n",
      " [0.39285648]] | y: 0.19682293684618352 | Predicción actual: [[0.4020017]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04227638244628906, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.29914078]\n",
      " [0.33049366]\n",
      " [0.2305308 ]\n",
      " [0.36993   ]\n",
      " [0.37613237]\n",
      " [0.38416544]\n",
      " [0.39285648]\n",
      " [0.40200171]] | y: 0.21425803951956607 | Predicción actual: [[0.41203547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017920978367328644, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33049366]\n",
      " [0.2305308 ]\n",
      " [0.36993   ]\n",
      " [0.37613237]\n",
      " [0.38416544]\n",
      " [0.39285648]\n",
      " [0.40200171]\n",
      " [0.41203547]] | y: 0.18132506780317698 | Predicción actual: [[0.42030758]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06490746885538101, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.36993   ]\n",
      " [0.37613237]\n",
      " [0.38416544]\n",
      " [0.39285648]\n",
      " [0.40200171]\n",
      " [0.41203547]\n",
      " [0.42030758]] | y: 0.17512592018597434 | Predicción actual: [[0.42500928]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0644264668226242, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36993   ]\n",
      " [0.37613237]\n",
      " [0.38416544]\n",
      " [0.39285648]\n",
      " [0.40200171]\n",
      " [0.41203547]\n",
      " [0.42030758]\n",
      " [0.42500928]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11137726902961731, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37613237]\n",
      " [0.38416544]\n",
      " [0.39285648]\n",
      " [0.40200171]\n",
      " [0.41203547]\n",
      " [0.42030758]\n",
      " [0.42500928]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.45820442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10425262898206711, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38416544]\n",
      " [0.39285648]\n",
      " [0.40200171]\n",
      " [0.41203547]\n",
      " [0.42030758]\n",
      " [0.42500928]\n",
      " [0.14800465]\n",
      " [0.45820442]] | y: 0.19217357613328173 | Predicción actual: [[0.45954219]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0777081623673439, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39285648]\n",
      " [0.40200171]\n",
      " [0.41203547]\n",
      " [0.42030758]\n",
      " [0.42500928]\n",
      " [0.14800465]\n",
      " [0.45820442]\n",
      " [0.45954219]] | y: 0.1859744285160791 | Predicción actual: [[0.45890638]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0662299245595932, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40200171]\n",
      " [0.41203547]\n",
      " [0.42030758]\n",
      " [0.42500928]\n",
      " [0.14800465]\n",
      " [0.45820442]\n",
      " [0.45954219]\n",
      " [0.45890638]] | y: 0.26695079426578844 | Predicción actual: [[0.45645478]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04673369973897934, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41203547]\n",
      " [0.42030758]\n",
      " [0.42500928]\n",
      " [0.14800465]\n",
      " [0.45820442]\n",
      " [0.45954219]\n",
      " [0.45890638]\n",
      " [0.45645478]] | y: 0.2925222781867493 | Predicción actual: [[0.45252833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04449775815010071, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42030758]\n",
      " [0.42500928]\n",
      " [0.14800465]\n",
      " [0.45820442]\n",
      " [0.45954219]\n",
      " [0.45890638]\n",
      " [0.45645478]\n",
      " [0.45252833]] | y: 0.3177063153816349 | Predicción actual: [[0.44738036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011855999939143658, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42500928]\n",
      " [0.14800465]\n",
      " [0.45820442]\n",
      " [0.45954219]\n",
      " [0.45890638]\n",
      " [0.45645478]\n",
      " [0.45252833]\n",
      " [0.44738036]] | y: 0.31266950794265785 | Predicción actual: [[0.44182783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02108057774603367, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.45820442]\n",
      " [0.45954219]\n",
      " [0.45890638]\n",
      " [0.45645478]\n",
      " [0.45252833]\n",
      " [0.44738036]\n",
      " [0.44182783]] | y: 0.2890352576520729 | Predicción actual: [[0.43691283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02982860989868641, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45820442]\n",
      " [0.45954219]\n",
      " [0.45890638]\n",
      " [0.45645478]\n",
      " [0.45252833]\n",
      " [0.44738036]\n",
      " [0.44182783]\n",
      " [0.43691283]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05465063452720642, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45954219]\n",
      " [0.45890638]\n",
      " [0.45645478]\n",
      " [0.45252833]\n",
      " [0.44738036]\n",
      " [0.44182783]\n",
      " [0.43691283]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.49244958]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0516829676926136, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45890638]\n",
      " [0.45645478]\n",
      " [0.45252833]\n",
      " [0.44738036]\n",
      " [0.44182783]\n",
      " [0.43691283]\n",
      " [0.28283611]\n",
      " [0.49244958]] | y: 0.2758620689655173 | Predicción actual: [[0.48730356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020409829914569855, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45645478]\n",
      " [0.45252833]\n",
      " [0.44738036]\n",
      " [0.44182783]\n",
      " [0.43691283]\n",
      " [0.28283611]\n",
      " [0.49244958]\n",
      " [0.48730356]] | y: 0.2746997287872917 | Predicción actual: [[0.48115262]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03936291113495827, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45252833]\n",
      " [0.44738036]\n",
      " [0.44182783]\n",
      " [0.43691283]\n",
      " [0.28283611]\n",
      " [0.49244958]\n",
      " [0.48730356]\n",
      " [0.48115262]] | y: 0.275474622239442 | Predicción actual: [[0.47487384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03633008897304535, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44738036]\n",
      " [0.44182783]\n",
      " [0.43691283]\n",
      " [0.28283611]\n",
      " [0.49244958]\n",
      " [0.48730356]\n",
      " [0.48115262]\n",
      " [0.47487384]] | y: 0.3347539713289423 | Predicción actual: [[0.46941984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025505272671580315, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44182783]\n",
      " [0.43691283]\n",
      " [0.28283611]\n",
      " [0.49244958]\n",
      " [0.48730356]\n",
      " [0.48115262]\n",
      " [0.47487384]\n",
      " [0.46941984]] | y: 0.35567609453700116 | Predicción actual: [[0.46565896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010601477697491646, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43691283]\n",
      " [0.28283611]\n",
      " [0.49244958]\n",
      " [0.48730356]\n",
      " [0.48115262]\n",
      " [0.47487384]\n",
      " [0.46941984]\n",
      " [0.46565896]] | y: 0.3366912049593181 | Predicción actual: [[0.46420202]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012490511871874332, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.49244958]\n",
      " [0.48730356]\n",
      " [0.48115262]\n",
      " [0.47487384]\n",
      " [0.46941984]\n",
      " [0.46565896]\n",
      " [0.46420202]] | y: 0.3335916311507167 | Predicción actual: [[0.46529377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01210822630673647, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49244958]\n",
      " [0.48730356]\n",
      " [0.48115262]\n",
      " [0.47487384]\n",
      " [0.46941984]\n",
      " [0.46565896]\n",
      " [0.46420202]\n",
      " [0.46529377]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004693656228482723, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48730356]\n",
      " [0.48115262]\n",
      " [0.47487384]\n",
      " [0.46941984]\n",
      " [0.46565896]\n",
      " [0.46420202]\n",
      " [0.46529377]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.49707887]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011548412032425404, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48115262]\n",
      " [0.47487384]\n",
      " [0.46941984]\n",
      " [0.46565896]\n",
      " [0.46420202]\n",
      " [0.46529377]\n",
      " [0.3847346 ]\n",
      " [0.49707887]] | y: 0.5962805114296785 | Predicción actual: [[0.49194488]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003919612616300583, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47487384]\n",
      " [0.46941984]\n",
      " [0.46565896]\n",
      " [0.46420202]\n",
      " [0.46529377]\n",
      " [0.3847346 ]\n",
      " [0.49707887]\n",
      " [0.49194488]] | y: 0.574583494769469 | Predicción actual: [[0.48741263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00515755033120513, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46941984]\n",
      " [0.46565896]\n",
      " [0.46420202]\n",
      " [0.46529377]\n",
      " [0.3847346 ]\n",
      " [0.49707887]\n",
      " [0.49194488]\n",
      " [0.48741263]] | y: 0.6063541263076326 | Predicción actual: [[0.48395807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011119244620203972, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46565896]\n",
      " [0.46420202]\n",
      " [0.46529377]\n",
      " [0.3847346 ]\n",
      " [0.49707887]\n",
      " [0.49194488]\n",
      " [0.48741263]\n",
      " [0.48395807]] | y: 0.5846571096474236 | Predicción actual: [[0.481875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.2747172206672985e-07, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46420202]\n",
      " [0.46529377]\n",
      " [0.3847346 ]\n",
      " [0.49707887]\n",
      " [0.49194488]\n",
      " [0.48741263]\n",
      " [0.48395807]\n",
      " [0.481875  ]] | y: 0.5687717938783416 | Predicción actual: [[0.4810714]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0189068540930748, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46529377]\n",
      " [0.3847346 ]\n",
      " [0.49707887]\n",
      " [0.49194488]\n",
      " [0.48741263]\n",
      " [0.48395807]\n",
      " [0.481875  ]\n",
      " [0.48107141]] | y: 0.6427741185586981 | Predicción actual: [[0.48141024]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05942574515938759, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.49707887]\n",
      " [0.49194488]\n",
      " [0.48741263]\n",
      " [0.48395807]\n",
      " [0.481875  ]\n",
      " [0.48107141]\n",
      " [0.48141024]] | y: 0.6617590081363811 | Predicción actual: [[0.48252207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0344911627471447, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49707887]\n",
      " [0.49194488]\n",
      " [0.48741263]\n",
      " [0.48395807]\n",
      " [0.481875  ]\n",
      " [0.48107141]\n",
      " [0.48141024]\n",
      " [0.48252207]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04569755122065544, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49194488]\n",
      " [0.48741263]\n",
      " [0.48395807]\n",
      " [0.481875  ]\n",
      " [0.48107141]\n",
      " [0.48141024]\n",
      " [0.48252207]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.50134903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025075305253267288, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48741263]\n",
      " [0.48395807]\n",
      " [0.481875  ]\n",
      " [0.48107141]\n",
      " [0.48141024]\n",
      " [0.48252207]\n",
      " [0.67299496]\n",
      " [0.50134903]] | y: 0.703990701278574 | Predicción actual: [[0.5024355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050710782408714294, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48395807]\n",
      " [0.481875  ]\n",
      " [0.48107141]\n",
      " [0.48141024]\n",
      " [0.48252207]\n",
      " [0.67299496]\n",
      " [0.50134903]\n",
      " [0.50243551]] | y: 0.7272375048430839 | Predicción actual: [[0.5060945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02894529700279236, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.481875  ]\n",
      " [0.48107141]\n",
      " [0.48141024]\n",
      " [0.48252207]\n",
      " [0.67299496]\n",
      " [0.50134903]\n",
      " [0.50243551]\n",
      " [0.50609452]] | y: 0.722588144130182 | Predicción actual: [[0.5122039]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049042124301195145, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48107141]\n",
      " [0.48141024]\n",
      " [0.48252207]\n",
      " [0.67299496]\n",
      " [0.50134903]\n",
      " [0.50243551]\n",
      " [0.50609452]\n",
      " [0.51220387]] | y: 0.771793878341728 | Predicción actual: [[0.52045125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03692801296710968, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48141024]\n",
      " [0.48252207]\n",
      " [0.67299496]\n",
      " [0.50134903]\n",
      " [0.50243551]\n",
      " [0.50609452]\n",
      " [0.51220387]\n",
      " [0.52045125]] | y: 0.7245253777605578 | Predicción actual: [[0.5304096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02388867363333702, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48252207]\n",
      " [0.67299496]\n",
      " [0.50134903]\n",
      " [0.50243551]\n",
      " [0.50609452]\n",
      " [0.51220387]\n",
      " [0.52045125]\n",
      " [0.53040957]] | y: 0.6710577295621851 | Predicción actual: [[0.5415991]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031442625913769007, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.50134903]\n",
      " [0.50243551]\n",
      " [0.50609452]\n",
      " [0.51220387]\n",
      " [0.52045125]\n",
      " [0.53040957]\n",
      " [0.54159909]] | y: 0.6737698566447115 | Predicción actual: [[0.55357486]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008785832673311234, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50134903]\n",
      " [0.50243551]\n",
      " [0.50609452]\n",
      " [0.51220387]\n",
      " [0.52045125]\n",
      " [0.53040957]\n",
      " [0.54159909]\n",
      " [0.55357486]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044636186212301254, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50243551]\n",
      " [0.50609452]\n",
      " [0.51220387]\n",
      " [0.52045125]\n",
      " [0.53040957]\n",
      " [0.54159909]\n",
      " [0.55357486]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5278026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10893150418996811, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50609452]\n",
      " [0.51220387]\n",
      " [0.52045125]\n",
      " [0.53040957]\n",
      " [0.54159909]\n",
      " [0.55357486]\n",
      " [0.71445176]\n",
      " [0.52780259]] | y: 0.722588144130182 | Predicción actual: [[0.5359601]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03863811492919922, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51220387]\n",
      " [0.52045125]\n",
      " [0.53040957]\n",
      " [0.54159909]\n",
      " [0.55357486]\n",
      " [0.71445176]\n",
      " [0.52780259]\n",
      " [0.53596008]] | y: 0.6993413405656723 | Predicción actual: [[0.5460289]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02392931841313839, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52045125]\n",
      " [0.53040957]\n",
      " [0.54159909]\n",
      " [0.55357486]\n",
      " [0.71445176]\n",
      " [0.52780259]\n",
      " [0.53596008]\n",
      " [0.54602891]] | y: 0.7373111197210385 | Predicción actual: [[0.55713475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0514339804649353, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53040957]\n",
      " [0.54159909]\n",
      " [0.55357486]\n",
      " [0.71445176]\n",
      " [0.52780259]\n",
      " [0.53596008]\n",
      " [0.54602891]\n",
      " [0.55713475]] | y: 0.7214258039519565 | Predicción actual: [[0.5683496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018617266789078712, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54159909]\n",
      " [0.55357486]\n",
      " [0.71445176]\n",
      " [0.52780259]\n",
      " [0.53596008]\n",
      " [0.54602891]\n",
      " [0.55713475]\n",
      " [0.5683496 ]] | y: 0.7187136768694304 | Predicción actual: [[0.5786544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05150221288204193, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55357486]\n",
      " [0.71445176]\n",
      " [0.52780259]\n",
      " [0.53596008]\n",
      " [0.54602891]\n",
      " [0.55713475]\n",
      " [0.5683496 ]\n",
      " [0.57865441]] | y: 0.6741573033707864 | Predicción actual: [[0.587251]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006922117434442043, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.52780259]\n",
      " [0.53596008]\n",
      " [0.54602891]\n",
      " [0.55713475]\n",
      " [0.5683496 ]\n",
      " [0.57865441]\n",
      " [0.58725101]] | y: 0.698566447113522 | Predicción actual: [[0.5933759]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011922596022486687, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52780259]\n",
      " [0.53596008]\n",
      " [0.54602891]\n",
      " [0.55713475]\n",
      " [0.5683496 ]\n",
      " [0.57865441]\n",
      " [0.58725101]\n",
      " [0.59337592]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021701310761272907, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53596008]\n",
      " [0.54602891]\n",
      " [0.55713475]\n",
      " [0.5683496 ]\n",
      " [0.57865441]\n",
      " [0.58725101]\n",
      " [0.59337592]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.57006025]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015568709932267666, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54602891]\n",
      " [0.55713475]\n",
      " [0.5683496 ]\n",
      " [0.57865441]\n",
      " [0.58725101]\n",
      " [0.59337592]\n",
      " [0.72103836]\n",
      " [0.57006025]] | y: 0.7562960092987214 | Predicción actual: [[0.5805557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05402383580803871, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55713475]\n",
      " [0.5683496 ]\n",
      " [0.57865441]\n",
      " [0.58725101]\n",
      " [0.59337592]\n",
      " [0.72103836]\n",
      " [0.57006025]\n",
      " [0.58055568]] | y: 0.8275862068965516 | Predicción actual: [[0.591537]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055946219712495804, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5683496 ]\n",
      " [0.57865441]\n",
      " [0.58725101]\n",
      " [0.59337592]\n",
      " [0.72103836]\n",
      " [0.57006025]\n",
      " [0.58055568]\n",
      " [0.591537  ]] | y: 0.8388221619527314 | Predicción actual: [[0.6022772]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04354586452245712, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57865441]\n",
      " [0.58725101]\n",
      " [0.59337592]\n",
      " [0.72103836]\n",
      " [0.57006025]\n",
      " [0.58055568]\n",
      " [0.591537  ]\n",
      " [0.60227722]] | y: 0.7942657884540876 | Predicción actual: [[0.61213696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036347825080156326, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58725101]\n",
      " [0.59337592]\n",
      " [0.72103836]\n",
      " [0.57006025]\n",
      " [0.58055568]\n",
      " [0.591537  ]\n",
      " [0.60227722]\n",
      " [0.61213696]] | y: 0.7838047268500579 | Predicción actual: [[0.62073386]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041941359639167786, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59337592]\n",
      " [0.72103836]\n",
      " [0.57006025]\n",
      " [0.58055568]\n",
      " [0.591537  ]\n",
      " [0.60227722]\n",
      " [0.61213696]\n",
      " [0.62073386]] | y: 0.7679194110809764 | Predicción actual: [[0.6280295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015146738849580288, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.57006025]\n",
      " [0.58055568]\n",
      " [0.591537  ]\n",
      " [0.60227722]\n",
      " [0.61213696]\n",
      " [0.62073386]\n",
      " [0.62802953]] | y: 0.7845796203022084 | Predicción actual: [[0.63427216]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012592523358762264, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57006025]\n",
      " [0.58055568]\n",
      " [0.591537  ]\n",
      " [0.60227722]\n",
      " [0.61213696]\n",
      " [0.62073386]\n",
      " [0.62802953]\n",
      " [0.63427216]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08987688273191452, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58055568]\n",
      " [0.591537  ]\n",
      " [0.60227722]\n",
      " [0.61213696]\n",
      " [0.62073386]\n",
      " [0.62802953]\n",
      " [0.63427216]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.61986506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06686227768659592, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.591537  ]\n",
      " [0.60227722]\n",
      " [0.61213696]\n",
      " [0.62073386]\n",
      " [0.62802953]\n",
      " [0.63427216]\n",
      " [0.87872917]\n",
      " [0.61986506]] | y: 0.8488957768306855 | Predicción actual: [[0.6327704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04006549343466759, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60227722]\n",
      " [0.61213696]\n",
      " [0.62073386]\n",
      " [0.62802953]\n",
      " [0.63427216]\n",
      " [0.87872917]\n",
      " [0.61986506]\n",
      " [0.63277042]] | y: 0.8182874854707476 | Predicción actual: [[0.6469527]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007172351237386465, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61213696]\n",
      " [0.62073386]\n",
      " [0.62802953]\n",
      " [0.63427216]\n",
      " [0.87872917]\n",
      " [0.61986506]\n",
      " [0.63277042]\n",
      " [0.64695269]] | y: 0.8268113134444013 | Predicción actual: [[0.66185325]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0791260376572609, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62073386]\n",
      " [0.62802953]\n",
      " [0.63427216]\n",
      " [0.87872917]\n",
      " [0.61986506]\n",
      " [0.63277042]\n",
      " [0.64695269]\n",
      " [0.66185325]] | y: 0.7853545137543589 | Predicción actual: [[0.67718863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01067933440208435, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62802953]\n",
      " [0.63427216]\n",
      " [0.87872917]\n",
      " [0.61986506]\n",
      " [0.63277042]\n",
      " [0.64695269]\n",
      " [0.66185325]\n",
      " [0.67718863]] | y: 0.7892289810151103 | Predicción actual: [[0.69248223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002314372221007943, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63427216]\n",
      " [0.87872917]\n",
      " [0.61986506]\n",
      " [0.63277042]\n",
      " [0.64695269]\n",
      " [0.66185325]\n",
      " [0.67718863]\n",
      " [0.69248223]] | y: 0.8341728012398295 | Predicción actual: [[0.707447]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02253670059144497, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.61986506]\n",
      " [0.63277042]\n",
      " [0.64695269]\n",
      " [0.66185325]\n",
      " [0.67718863]\n",
      " [0.69248223]\n",
      " [0.70744699]] | y: 0.8124757845796202 | Predicción actual: [[0.7220925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00013238440442364663, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61986506]\n",
      " [0.63277042]\n",
      " [0.64695269]\n",
      " [0.66185325]\n",
      " [0.67718863]\n",
      " [0.69248223]\n",
      " [0.70744699]\n",
      " [0.72209251]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04543105140328407, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63277042]\n",
      " [0.64695269]\n",
      " [0.66185325]\n",
      " [0.67718863]\n",
      " [0.69248223]\n",
      " [0.70744699]\n",
      " [0.72209251]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.6860552]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014066513627767563, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64695269]\n",
      " [0.66185325]\n",
      " [0.67718863]\n",
      " [0.69248223]\n",
      " [0.70744699]\n",
      " [0.72209251]\n",
      " [0.80123983]\n",
      " [0.68605518]] | y: 0.793490895001937 | Predicción actual: [[0.7010812]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001316215202677995, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66185325]\n",
      " [0.67718863]\n",
      " [0.69248223]\n",
      " [0.70744699]\n",
      " [0.72209251]\n",
      " [0.80123983]\n",
      " [0.68605518]\n",
      " [0.70108122]] | y: 0.760170476559473 | Predicción actual: [[0.71591985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012577571906149387, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67718863]\n",
      " [0.69248223]\n",
      " [0.70744699]\n",
      " [0.72209251]\n",
      " [0.80123983]\n",
      " [0.68605518]\n",
      " [0.70108122]\n",
      " [0.71591985]] | y: 0.7353738860906625 | Predicción actual: [[0.72986674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.720388460555114e-05, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69248223]\n",
      " [0.70744699]\n",
      " [0.72209251]\n",
      " [0.80123983]\n",
      " [0.68605518]\n",
      " [0.70108122]\n",
      " [0.71591985]\n",
      " [0.72986674]] | y: 0.7101898488957767 | Predicción actual: [[0.74193996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006828432437032461, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70744699]\n",
      " [0.72209251]\n",
      " [0.80123983]\n",
      " [0.68605518]\n",
      " [0.70108122]\n",
      " [0.71591985]\n",
      " [0.72986674]\n",
      " [0.74193996]] | y: 0.7121270825261525 | Predicción actual: [[0.75158507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005638847127556801, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72209251]\n",
      " [0.80123983]\n",
      " [0.68605518]\n",
      " [0.70108122]\n",
      " [0.71591985]\n",
      " [0.72986674]\n",
      " [0.74193996]\n",
      " [0.75158507]] | y: 0.7396358000774894 | Predicción actual: [[0.75806147]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010123529937118292, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.68605518]\n",
      " [0.70108122]\n",
      " [0.71591985]\n",
      " [0.72986674]\n",
      " [0.74193996]\n",
      " [0.75158507]\n",
      " [0.75806147]] | y: 0.7361487795428128 | Predicción actual: [[0.7611607]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022659616079181433, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68605518]\n",
      " [0.70108122]\n",
      " [0.71591985]\n",
      " [0.72986674]\n",
      " [0.74193996]\n",
      " [0.75158507]\n",
      " [0.75806147]\n",
      " [0.76116067]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.413099668454379e-05, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70108122]\n",
      " [0.71591985]\n",
      " [0.72986674]\n",
      " [0.74193996]\n",
      " [0.75158507]\n",
      " [0.75806147]\n",
      " [0.76116067]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.75438535]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.981392940972e-05, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71591985]\n",
      " [0.72986674]\n",
      " [0.74193996]\n",
      " [0.75158507]\n",
      " [0.75806147]\n",
      " [0.76116067]\n",
      " [0.66757071]\n",
      " [0.75438535]] | y: 0.696629213483146 | Predicción actual: [[0.7639802]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020350045815575868, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72986674]\n",
      " [0.74193996]\n",
      " [0.75158507]\n",
      " [0.75806147]\n",
      " [0.76116067]\n",
      " [0.66757071]\n",
      " [0.75438535]\n",
      " [0.76398021]] | y: 0.6559473072452537 | Predicción actual: [[0.77080125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011597387492656708, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74193996]\n",
      " [0.75158507]\n",
      " [0.75806147]\n",
      " [0.76116067]\n",
      " [0.66757071]\n",
      " [0.75438535]\n",
      " [0.76398021]\n",
      " [0.77080125]] | y: 0.6788066640836885 | Predicción actual: [[0.77444166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003782361513003707, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75158507]\n",
      " [0.75806147]\n",
      " [0.76116067]\n",
      " [0.66757071]\n",
      " [0.75438535]\n",
      " [0.76398021]\n",
      " [0.77080125]\n",
      " [0.77444166]] | y: 0.6760945370011622 | Predicción actual: [[0.77527666]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017063921317458153, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75806147]\n",
      " [0.76116067]\n",
      " [0.66757071]\n",
      " [0.75438535]\n",
      " [0.76398021]\n",
      " [0.77080125]\n",
      " [0.77444166]\n",
      " [0.77527666]] | y: 0.7295621851995349 | Predicción actual: [[0.77377063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002346512395888567, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76116067]\n",
      " [0.66757071]\n",
      " [0.75438535]\n",
      " [0.76398021]\n",
      " [0.77080125]\n",
      " [0.77444166]\n",
      " [0.77527666]\n",
      " [0.77377063]] | y: 0.7012785741960481 | Predicción actual: [[0.7710805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04863302409648895, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.75438535]\n",
      " [0.76398021]\n",
      " [0.77080125]\n",
      " [0.77444166]\n",
      " [0.77527666]\n",
      " [0.77377063]\n",
      " [0.77108049]] | y: 0.767531964354901 | Predicción actual: [[0.76793337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006945931352674961, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75438535]\n",
      " [0.76398021]\n",
      " [0.77080125]\n",
      " [0.77444166]\n",
      " [0.77527666]\n",
      " [0.77377063]\n",
      " [0.77108049]\n",
      " [0.76793337]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011184806935489178, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76398021]\n",
      " [0.77080125]\n",
      " [0.77444166]\n",
      " [0.77527666]\n",
      " [0.77377063]\n",
      " [0.77108049]\n",
      " [0.76793337]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.7953545]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007350984960794449, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77080125]\n",
      " [0.77444166]\n",
      " [0.77527666]\n",
      " [0.77377063]\n",
      " [0.77108049]\n",
      " [0.76793337]\n",
      " [0.75513367]\n",
      " [0.79535449]] | y: 0.7520340953118947 | Predicción actual: [[0.79637635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01690988801419735, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77444166]\n",
      " [0.77527666]\n",
      " [0.77377063]\n",
      " [0.77108049]\n",
      " [0.76793337]\n",
      " [0.75513367]\n",
      " [0.79535449]\n",
      " [0.79637635]] | y: 0.7098024021697016 | Predicción actual: [[0.795722]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02913936972618103, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77527666]\n",
      " [0.77377063]\n",
      " [0.77108049]\n",
      " [0.76793337]\n",
      " [0.75513367]\n",
      " [0.79535449]\n",
      " [0.79637635]\n",
      " [0.79572201]] | y: 0.6904300658659435 | Predicción actual: [[0.79422355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05963299423456192, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77377063]\n",
      " [0.77108049]\n",
      " [0.76793337]\n",
      " [0.75513367]\n",
      " [0.79535449]\n",
      " [0.79637635]\n",
      " [0.79572201]\n",
      " [0.79422355]] | y: 0.7543587756683454 | Predicción actual: [[0.792677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017654820112511516, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77108049]\n",
      " [0.76793337]\n",
      " [0.75513367]\n",
      " [0.79535449]\n",
      " [0.79637635]\n",
      " [0.79572201]\n",
      " [0.79422355]\n",
      " [0.79267699]] | y: 0.7222006974041069 | Predicción actual: [[0.79253376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018278429051861167, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76793337]\n",
      " [0.75513367]\n",
      " [0.79535449]\n",
      " [0.79637635]\n",
      " [0.79572201]\n",
      " [0.79422355]\n",
      " [0.79267699]\n",
      " [0.79253376]] | y: 0.8485083301046106 | Predicción actual: [[0.79413676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008934351615607738, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.79535449]\n",
      " [0.79637635]\n",
      " [0.79572201]\n",
      " [0.79422355]\n",
      " [0.79267699]\n",
      " [0.79253376]\n",
      " [0.79413676]] | y: 0.9054629988376597 | Predicción actual: [[0.7980054]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028975239023566246, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79535449]\n",
      " [0.79637635]\n",
      " [0.79572201]\n",
      " [0.79422355]\n",
      " [0.79267699]\n",
      " [0.79253376]\n",
      " [0.79413676]\n",
      " [0.7980054 ]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001978300279006362, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79637635]\n",
      " [0.79572201]\n",
      " [0.79422355]\n",
      " [0.79267699]\n",
      " [0.79253376]\n",
      " [0.79413676]\n",
      " [0.7980054 ]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8067028]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01819198951125145, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79572201]\n",
      " [0.79422355]\n",
      " [0.79267699]\n",
      " [0.79253376]\n",
      " [0.79413676]\n",
      " [0.7980054 ]\n",
      " [0.8822162 ]\n",
      " [0.80670279]] | y: 0.889577683068578 | Predicción actual: [[0.80721533]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005373380146920681, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79422355]\n",
      " [0.79267699]\n",
      " [0.79253376]\n",
      " [0.79413676]\n",
      " [0.7980054 ]\n",
      " [0.8822162 ]\n",
      " [0.80670279]\n",
      " [0.80721533]] | y: 0.8748547074777218 | Predicción actual: [[0.80873966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00908730924129486, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79267699]\n",
      " [0.79253376]\n",
      " [0.79413676]\n",
      " [0.7980054 ]\n",
      " [0.8822162 ]\n",
      " [0.80670279]\n",
      " [0.80721533]\n",
      " [0.80873966]] | y: 0.9132119333591631 | Predicción actual: [[0.8119877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013383730547502637, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79253376]\n",
      " [0.79413676]\n",
      " [0.7980054 ]\n",
      " [0.8822162 ]\n",
      " [0.80670279]\n",
      " [0.80721533]\n",
      " [0.80873966]\n",
      " [0.8119877 ]] | y: 1.0 | Predicción actual: [[0.8168603]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05162589251995087, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79413676]\n",
      " [0.7980054 ]\n",
      " [0.8822162 ]\n",
      " [0.80670279]\n",
      " [0.80721533]\n",
      " [0.80873966]\n",
      " [0.8119877 ]\n",
      " [0.81686032]] | y: 0.9705540488182873 | Predicción actual: [[0.823263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019517281325533986, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7980054 ]\n",
      " [0.8822162 ]\n",
      " [0.80670279]\n",
      " [0.80721533]\n",
      " [0.80873966]\n",
      " [0.8119877 ]\n",
      " [0.81686032]\n",
      " [0.82326299]] | y: 0.8888027896164277 | Predicción actual: [[0.83019596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014120773412287235, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.80670279]\n",
      " [0.80721533]\n",
      " [0.80873966]\n",
      " [0.8119877 ]\n",
      " [0.81686032]\n",
      " [0.82326299]\n",
      " [0.83019596]] | y: 0.877954281286323 | Predicción actual: [[0.8369623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009744605980813503, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80670279]\n",
      " [0.80721533]\n",
      " [0.80873966]\n",
      " [0.8119877 ]\n",
      " [0.81686032]\n",
      " [0.82326299]\n",
      " [0.83019596]\n",
      " [0.83696228]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032053086906671524, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80721533]\n",
      " [0.80873966]\n",
      " [0.8119877 ]\n",
      " [0.81686032]\n",
      " [0.82326299]\n",
      " [0.83019596]\n",
      " [0.83696228]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.82403743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00030308665009215474, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80873966]\n",
      " [0.8119877 ]\n",
      " [0.81686032]\n",
      " [0.82326299]\n",
      " [0.83019596]\n",
      " [0.83696228]\n",
      " [0.84889578]\n",
      " [0.82403743]] | y: 0.8550949244478885 | Predicción actual: [[0.8284272]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005937175010330975, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8119877 ]\n",
      " [0.81686032]\n",
      " [0.82326299]\n",
      " [0.83019596]\n",
      " [0.83696228]\n",
      " [0.84889578]\n",
      " [0.82403743]\n",
      " [0.8284272 ]] | y: 0.8752421542037967 | Predicción actual: [[0.8333977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016268577426671982, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81686032]\n",
      " [0.82326299]\n",
      " [0.83019596]\n",
      " [0.83696228]\n",
      " [0.84889578]\n",
      " [0.82403743]\n",
      " [0.8284272 ]\n",
      " [0.83339769]] | y: 0.857032158078264 | Predicción actual: [[0.8386995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.347693538875319e-05, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82326299]\n",
      " [0.83019596]\n",
      " [0.83696228]\n",
      " [0.84889578]\n",
      " [0.82403743]\n",
      " [0.8284272 ]\n",
      " [0.83339769]\n",
      " [0.83869952]] | y: 0.8500581170089112 | Predicción actual: [[0.84343445]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02051016129553318, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83019596]\n",
      " [0.83696228]\n",
      " [0.84889578]\n",
      " [0.82403743]\n",
      " [0.8284272 ]\n",
      " [0.83339769]\n",
      " [0.83869952]\n",
      " [0.84343445]] | y: 0.8426966292134832 | Predicción actual: [[0.8466028]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002985431347042322, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83696228]\n",
      " [0.84889578]\n",
      " [0.82403743]\n",
      " [0.8284272 ]\n",
      " [0.83339769]\n",
      " [0.83869952]\n",
      " [0.84343445]\n",
      " [0.8466028 ]] | y: 0.8229368461836497 | Predicción actual: [[0.8481518]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011840029619634151, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.82403743]\n",
      " [0.8284272 ]\n",
      " [0.83339769]\n",
      " [0.83869952]\n",
      " [0.84343445]\n",
      " [0.8466028 ]\n",
      " [0.8481518 ]] | y: 0.7745060054242543 | Predicción actual: [[0.8481921]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005092467763461173, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82403743]\n",
      " [0.8284272 ]\n",
      " [0.83339769]\n",
      " [0.83869952]\n",
      " [0.84343445]\n",
      " [0.8466028 ]\n",
      " [0.8481518 ]\n",
      " [0.8481921 ]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0807255432009697, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8284272 ]\n",
      " [0.83339769]\n",
      " [0.83869952]\n",
      " [0.84343445]\n",
      " [0.8466028 ]\n",
      " [0.8481518 ]\n",
      " [0.8481921 ]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8480634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00924830324947834, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83339769]\n",
      " [0.83869952]\n",
      " [0.84343445]\n",
      " [0.8466028 ]\n",
      " [0.8481518 ]\n",
      " [0.8481921 ]\n",
      " [0.78419217]\n",
      " [0.84806341]] | y: 0.854320030995738 | Predicción actual: [[0.85041314]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003487923531793058, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83869952]\n",
      " [0.84343445]\n",
      " [0.8466028 ]\n",
      " [0.8481518 ]\n",
      " [0.8481921 ]\n",
      " [0.78419217]\n",
      " [0.84806341]\n",
      " [0.85041314]] | y: 0.8368849283223556 | Predicción actual: [[0.85153437]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028586345724761486, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84343445]\n",
      " [0.8466028 ]\n",
      " [0.8481518 ]\n",
      " [0.8481921 ]\n",
      " [0.78419217]\n",
      " [0.84806341]\n",
      " [0.85041314]\n",
      " [0.85153437]] | y: 0.8299108872530028 | Predicción actual: [[0.8513436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03354603797197342, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8466028 ]\n",
      " [0.8481518 ]\n",
      " [0.8481921 ]\n",
      " [0.78419217]\n",
      " [0.84806341]\n",
      " [0.85041314]\n",
      " [0.85153437]\n",
      " [0.85134357]] | y: 0.887253002712127 | Predicción actual: [[0.8493562]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032185872551053762, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8481518 ]\n",
      " [0.8481921 ]\n",
      " [0.78419217]\n",
      " [0.84806341]\n",
      " [0.85041314]\n",
      " [0.85153437]\n",
      " [0.85134357]\n",
      " [0.84935617]] | y: 0.8597442851607902 | Predicción actual: [[0.84641165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01715359464287758, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8481921 ]\n",
      " [0.78419217]\n",
      " [0.84806341]\n",
      " [0.85041314]\n",
      " [0.85153437]\n",
      " [0.85134357]\n",
      " [0.84935617]\n",
      " [0.84641165]] | y: 0.8395970554048819 | Predicción actual: [[0.84345126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028792971279472113, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.84806341]\n",
      " [0.85041314]\n",
      " [0.85153437]\n",
      " [0.85134357]\n",
      " [0.84935617]\n",
      " [0.84641165]\n",
      " [0.84345126]] | y: 0.7838047268500579 | Predicción actual: [[0.8408713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.819452220137464e-06, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84806341]\n",
      " [0.85041314]\n",
      " [0.85153437]\n",
      " [0.85134357]\n",
      " [0.84935617]\n",
      " [0.84641165]\n",
      " [0.84345126]\n",
      " [0.84087127]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01639128476381302, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85041314]\n",
      " [0.85153437]\n",
      " [0.85134357]\n",
      " [0.84935617]\n",
      " [0.84641165]\n",
      " [0.84345126]\n",
      " [0.84087127]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8569239]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000751061481423676, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85153437]\n",
      " [0.85134357]\n",
      " [0.84935617]\n",
      " [0.84641165]\n",
      " [0.84345126]\n",
      " [0.84087127]\n",
      " [0.81828749]\n",
      " [0.85692388]] | y: 0.7605579232855482 | Predicción actual: [[0.85584337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036677720490843058, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85134357]\n",
      " [0.84935617]\n",
      " [0.84641165]\n",
      " [0.84345126]\n",
      " [0.84087127]\n",
      " [0.81828749]\n",
      " [0.85692388]\n",
      " [0.85584337]] | y: 0.7915536613715615 | Predicción actual: [[0.8539449]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010488849511602893, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84935617]\n",
      " [0.84641165]\n",
      " [0.84345126]\n",
      " [0.84087127]\n",
      " [0.81828749]\n",
      " [0.85692388]\n",
      " [0.85584337]\n",
      " [0.8539449 ]] | y: 0.7686943045331267 | Predicción actual: [[0.8518533]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023765036836266518, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84641165]\n",
      " [0.84345126]\n",
      " [0.84087127]\n",
      " [0.81828749]\n",
      " [0.85692388]\n",
      " [0.85584337]\n",
      " [0.8539449 ]\n",
      " [0.85185331]] | y: 0.7686943045331267 | Predicción actual: [[0.8498605]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007599706877954304, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84345126]\n",
      " [0.84087127]\n",
      " [0.81828749]\n",
      " [0.85692388]\n",
      " [0.85584337]\n",
      " [0.8539449 ]\n",
      " [0.85185331]\n",
      " [0.84986049]] | y: 0.7989151491669895 | Predicción actual: [[0.8489043]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00099176075309515, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84087127]\n",
      " [0.81828749]\n",
      " [0.85692388]\n",
      " [0.85584337]\n",
      " [0.8539449 ]\n",
      " [0.85185331]\n",
      " [0.84986049]\n",
      " [0.84890431]] | y: 0.7900038744672608 | Predicción actual: [[0.8490585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024432376958429813, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.85692388]\n",
      " [0.85584337]\n",
      " [0.8539449 ]\n",
      " [0.85185331]\n",
      " [0.84986049]\n",
      " [0.84890431]\n",
      " [0.84905851]] | y: 0.760170476559473 | Predicción actual: [[0.8505214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040317386388778687, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85692388]\n",
      " [0.85584337]\n",
      " [0.8539449 ]\n",
      " [0.85185331]\n",
      " [0.84986049]\n",
      " [0.84890431]\n",
      " [0.84905851]\n",
      " [0.85052139]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007721819565631449, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85584337]\n",
      " [0.8539449 ]\n",
      " [0.85185331]\n",
      " [0.84986049]\n",
      " [0.84890431]\n",
      " [0.84905851]\n",
      " [0.85052139]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.85540557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07081783562898636, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8539449 ]\n",
      " [0.85185331]\n",
      " [0.84986049]\n",
      " [0.84890431]\n",
      " [0.84905851]\n",
      " [0.85052139]\n",
      " [0.68539326]\n",
      " [0.85540557]] | y: 0.6648585819449826 | Predicción actual: [[0.85043913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.056018341332674026, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85185331]\n",
      " [0.84986049]\n",
      " [0.84890431]\n",
      " [0.84905851]\n",
      " [0.85052139]\n",
      " [0.68539326]\n",
      " [0.85540557]\n",
      " [0.85043913]] | y: 0.7078651685393258 | Predicción actual: [[0.84387904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09595844149589539, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84986049]\n",
      " [0.84890431]\n",
      " [0.84905851]\n",
      " [0.85052139]\n",
      " [0.68539326]\n",
      " [0.85540557]\n",
      " [0.85043913]\n",
      " [0.84387904]] | y: 0.6648585819449826 | Predicción actual: [[0.83585274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.13989487290382385, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84890431]\n",
      " [0.84905851]\n",
      " [0.85052139]\n",
      " [0.68539326]\n",
      " [0.85540557]\n",
      " [0.85043913]\n",
      " [0.84387904]\n",
      " [0.83585274]] | y: 0.7113521890740022 | Predicción actual: [[0.8266515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02118954248726368, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84905851]\n",
      " [0.85052139]\n",
      " [0.68539326]\n",
      " [0.85540557]\n",
      " [0.85043913]\n",
      " [0.84387904]\n",
      " [0.83585274]\n",
      " [0.82665151]] | y: 0.6772568771793879 | Predicción actual: [[0.8169181]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003089271020144224, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85052139]\n",
      " [0.68539326]\n",
      " [0.85540557]\n",
      " [0.85043913]\n",
      " [0.84387904]\n",
      " [0.83585274]\n",
      " [0.82665151]\n",
      " [0.81691808]] | y: 0.7621077101898488 | Predicción actual: [[0.8068243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044133368879556656, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.85540557]\n",
      " [0.85043913]\n",
      " [0.84387904]\n",
      " [0.83585274]\n",
      " [0.82665151]\n",
      " [0.81691808]\n",
      " [0.80682433]] | y: 0.8070515304145678 | Predicción actual: [[0.79589766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014447690919041634, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85540557]\n",
      " [0.85043913]\n",
      " [0.84387904]\n",
      " [0.83585274]\n",
      " [0.82665151]\n",
      " [0.81691808]\n",
      " [0.80682433]\n",
      " [0.79589766]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03500023111701012, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85043913]\n",
      " [0.84387904]\n",
      " [0.83585274]\n",
      " [0.82665151]\n",
      " [0.81691808]\n",
      " [0.80682433]\n",
      " [0.79589766]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8210875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001297531562158838, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84387904]\n",
      " [0.83585274]\n",
      " [0.82665151]\n",
      " [0.81691808]\n",
      " [0.80682433]\n",
      " [0.79589766]\n",
      " [0.81518791]\n",
      " [0.82108748]] | y: 0.9597055404881829 | Predicción actual: [[0.81203735]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026912866160273552, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83585274]\n",
      " [0.82665151]\n",
      " [0.81691808]\n",
      " [0.80682433]\n",
      " [0.79589766]\n",
      " [0.81518791]\n",
      " [0.82108748]\n",
      " [0.81203735]] | y: 0.9643549012010848 | Predicción actual: [[0.8037743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03482731431722641, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82665151]\n",
      " [0.81691808]\n",
      " [0.80682433]\n",
      " [0.79589766]\n",
      " [0.81518791]\n",
      " [0.82108748]\n",
      " [0.81203735]\n",
      " [0.8037743 ]] | y: 0.8880278961642774 | Predicción actual: [[0.7969328]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004545570118352771, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81691808]\n",
      " [0.80682433]\n",
      " [0.79589766]\n",
      " [0.81518791]\n",
      " [0.82108748]\n",
      " [0.81203735]\n",
      " [0.8037743 ]\n",
      " [0.79693282]] | y: 0.8926772568771792 | Predicción actual: [[0.7916945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004303368623368442, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80682433]\n",
      " [0.79589766]\n",
      " [0.81518791]\n",
      " [0.82108748]\n",
      " [0.81203735]\n",
      " [0.8037743 ]\n",
      " [0.79693282]\n",
      " [0.79169452]] | y: 0.8752421542037967 | Predicción actual: [[0.7884316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08379796147346497, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79589766]\n",
      " [0.81518791]\n",
      " [0.82108748]\n",
      " [0.81203735]\n",
      " [0.8037743 ]\n",
      " [0.79693282]\n",
      " [0.79169452]\n",
      " [0.78843158]] | y: 0.8508330104610615 | Predicción actual: [[0.7877929]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004417524905875325, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.82108748]\n",
      " [0.81203735]\n",
      " [0.8037743 ]\n",
      " [0.79693282]\n",
      " [0.79169452]\n",
      " [0.78843158]\n",
      " [0.78779292]] | y: 0.8488957768306855 | Predicción actual: [[0.78967506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00021590941469185054, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82108748]\n",
      " [0.81203735]\n",
      " [0.8037743 ]\n",
      " [0.79693282]\n",
      " [0.79169452]\n",
      " [0.78843158]\n",
      " [0.78779292]\n",
      " [0.78967506]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030793212354183197, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81203735]\n",
      " [0.8037743 ]\n",
      " [0.79693282]\n",
      " [0.79169452]\n",
      " [0.78843158]\n",
      " [0.78779292]\n",
      " [0.78967506]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.781252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00816313922405243, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8037743 ]\n",
      " [0.79693282]\n",
      " [0.79169452]\n",
      " [0.78843158]\n",
      " [0.78779292]\n",
      " [0.78967506]\n",
      " [0.96241767]\n",
      " [0.78125203]] | y: 0.9407206509104997 | Predicción actual: [[0.7792198]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06372350454330444, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79693282]\n",
      " [0.79169452]\n",
      " [0.78843158]\n",
      " [0.78779292]\n",
      " [0.78967506]\n",
      " [0.96241767]\n",
      " [0.78125203]\n",
      " [0.77921981]] | y: 0.9724912824486633 | Predicción actual: [[0.78033555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11057038605213165, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79169452]\n",
      " [0.78843158]\n",
      " [0.78779292]\n",
      " [0.78967506]\n",
      " [0.96241767]\n",
      " [0.78125203]\n",
      " [0.77921981]\n",
      " [0.78033555]] | y: 0.9969004261913985 | Predicción actual: [[0.7843671]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014861548319458961, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78843158]\n",
      " [0.78779292]\n",
      " [0.78967506]\n",
      " [0.96241767]\n",
      " [0.78125203]\n",
      " [0.77921981]\n",
      " [0.78033555]\n",
      " [0.78436708]] | y: 0.951181712514529 | Predicción actual: [[0.7905253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002506645629182458, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78779292]\n",
      " [0.78967506]\n",
      " [0.96241767]\n",
      " [0.78125203]\n",
      " [0.77921981]\n",
      " [0.78033555]\n",
      " [0.78436708]\n",
      " [0.79052532]] | y: 0.8957768306857805 | Predicción actual: [[0.7978756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010579184163361788, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78967506]\n",
      " [0.96241767]\n",
      " [0.78125203]\n",
      " [0.77921981]\n",
      " [0.78033555]\n",
      " [0.78436708]\n",
      " [0.79052532]\n",
      " [0.79787558]] | y: 0.8814413018209997 | Predicción actual: [[0.8053414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04191597178578377, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.78125203]\n",
      " [0.77921981]\n",
      " [0.78033555]\n",
      " [0.78436708]\n",
      " [0.79052532]\n",
      " [0.79787558]\n",
      " [0.80534142]] | y: 0.9170864006199149 | Predicción actual: [[0.812105]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014534955844283104, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78125203]\n",
      " [0.77921981]\n",
      " [0.78033555]\n",
      " [0.78436708]\n",
      " [0.79052532]\n",
      " [0.79787558]\n",
      " [0.80534142]\n",
      " [0.812105  ]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016651906073093414, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77921981]\n",
      " [0.78033555]\n",
      " [0.78436708]\n",
      " [0.79052532]\n",
      " [0.79787558]\n",
      " [0.80534142]\n",
      " [0.812105  ]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7752543]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004107537679374218, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78033555]\n",
      " [0.78436708]\n",
      " [0.79052532]\n",
      " [0.79787558]\n",
      " [0.80534142]\n",
      " [0.812105  ]\n",
      " [0.91979853]\n",
      " [0.77525431]] | y: 0.9682293684618366 | Predicción actual: [[0.78154147]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026998376473784447, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78436708]\n",
      " [0.79052532]\n",
      " [0.79787558]\n",
      " [0.80534142]\n",
      " [0.812105  ]\n",
      " [0.91979853]\n",
      " [0.77525431]\n",
      " [0.78154147]] | y: 0.9577683068578069 | Predicción actual: [[0.7894496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07486637681722641, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.23889455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031657736748456955, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23889455]] | y: 0.10422316931421921 | Predicción actual: [[0.22457044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013883954845368862, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23889455]\n",
      " [0.22457044]] | y: 0.15420379697791559 | Predicción actual: [[0.22906168]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006660431972704828, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23889455]\n",
      " [0.22457044]\n",
      " [0.22906168]] | y: 0.1557535838822161 | Predicción actual: [[0.24107805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01090166438370943, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23889455]\n",
      " [0.22457044]\n",
      " [0.22906168]\n",
      " [0.24107805]] | y: 0.12553273924835334 | Predicción actual: [[0.2550107]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018784688785672188, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23889455]\n",
      " [0.22457044]\n",
      " [0.22906168]\n",
      " [0.24107805]\n",
      " [0.25501069]] | y: 0.1456799690042619 | Predicción actual: [[0.26749676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011472189798951149, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23889455]\n",
      " [0.22457044]\n",
      " [0.22906168]\n",
      " [0.24107805]\n",
      " [0.25501069]\n",
      " [0.26749676]] | y: 0.1464548624564122 | Predicción actual: [[0.29202682]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01859428733587265, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.23889455]\n",
      " [0.22457044]\n",
      " [0.22906168]\n",
      " [0.24107805]\n",
      " [0.25501069]\n",
      " [0.26749676]\n",
      " [0.29202682]] | y: 0.1960480433940332 | Predicción actual: [[0.32262677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03474307432770729, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23889455]\n",
      " [0.22457044]\n",
      " [0.22906168]\n",
      " [0.24107805]\n",
      " [0.25501069]\n",
      " [0.26749676]\n",
      " [0.29202682]\n",
      " [0.32262677]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0237217228859663, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22457044]\n",
      " [0.22906168]\n",
      " [0.24107805]\n",
      " [0.25501069]\n",
      " [0.26749676]\n",
      " [0.29202682]\n",
      " [0.32262677]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.36233386]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03737305849790573, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22906168]\n",
      " [0.24107805]\n",
      " [0.25501069]\n",
      " [0.26749676]\n",
      " [0.29202682]\n",
      " [0.32262677]\n",
      " [0.2305308 ]\n",
      " [0.36233386]] | y: 0.211933359163115 | Predicción actual: [[0.3694868]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01523111667484045, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24107805]\n",
      " [0.25501069]\n",
      " [0.26749676]\n",
      " [0.29202682]\n",
      " [0.32262677]\n",
      " [0.2305308 ]\n",
      " [0.36233386]\n",
      " [0.36948681]] | y: 0.2072839984502131 | Predicción actual: [[0.37842456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02097930759191513, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25501069]\n",
      " [0.26749676]\n",
      " [0.29202682]\n",
      " [0.32262677]\n",
      " [0.2305308 ]\n",
      " [0.36233386]\n",
      " [0.36948681]\n",
      " [0.37842456]] | y: 0.19294846958543205 | Predicción actual: [[0.38801566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03700355067849159, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26749676]\n",
      " [0.29202682]\n",
      " [0.32262677]\n",
      " [0.2305308 ]\n",
      " [0.36233386]\n",
      " [0.36948681]\n",
      " [0.37842456]\n",
      " [0.38801566]] | y: 0.19682293684618352 | Predicción actual: [[0.39808413]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023635948076844215, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.29202682]\n",
      " [0.32262677]\n",
      " [0.2305308 ]\n",
      " [0.36233386]\n",
      " [0.36948681]\n",
      " [0.37842456]\n",
      " [0.38801566]\n",
      " [0.39808413]] | y: 0.21425803951956607 | Predicción actual: [[0.40913913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028809793293476105, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32262677]\n",
      " [0.2305308 ]\n",
      " [0.36233386]\n",
      " [0.36948681]\n",
      " [0.37842456]\n",
      " [0.38801566]\n",
      " [0.39808413]\n",
      " [0.40913913]] | y: 0.18132506780317698 | Predicción actual: [[0.41857937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07740650326013565, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.36233386]\n",
      " [0.36948681]\n",
      " [0.37842456]\n",
      " [0.38801566]\n",
      " [0.39808413]\n",
      " [0.40913913]\n",
      " [0.41857937]] | y: 0.17512592018597434 | Predicción actual: [[0.42464495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06375356763601303, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36233386]\n",
      " [0.36948681]\n",
      " [0.37842456]\n",
      " [0.38801566]\n",
      " [0.39808413]\n",
      " [0.40913913]\n",
      " [0.41857937]\n",
      " [0.42464495]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12213212996721268, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36948681]\n",
      " [0.37842456]\n",
      " [0.38801566]\n",
      " [0.39808413]\n",
      " [0.40913913]\n",
      " [0.41857937]\n",
      " [0.42464495]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.45920223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08854222297668457, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37842456]\n",
      " [0.38801566]\n",
      " [0.39808413]\n",
      " [0.40913913]\n",
      " [0.41857937]\n",
      " [0.42464495]\n",
      " [0.14800465]\n",
      " [0.45920223]] | y: 0.19217357613328173 | Predicción actual: [[0.46181515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0628717690706253, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38801566]\n",
      " [0.39808413]\n",
      " [0.40913913]\n",
      " [0.41857937]\n",
      " [0.42464495]\n",
      " [0.14800465]\n",
      " [0.45920223]\n",
      " [0.46181515]] | y: 0.1859744285160791 | Predicción actual: [[0.46241155]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061177417635917664, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39808413]\n",
      " [0.40913913]\n",
      " [0.41857937]\n",
      " [0.42464495]\n",
      " [0.14800465]\n",
      " [0.45920223]\n",
      " [0.46181515]\n",
      " [0.46241155]] | y: 0.26695079426578844 | Predicción actual: [[0.4611394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028656261041760445, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40913913]\n",
      " [0.41857937]\n",
      " [0.42464495]\n",
      " [0.14800465]\n",
      " [0.45920223]\n",
      " [0.46181515]\n",
      " [0.46241155]\n",
      " [0.46113941]] | y: 0.2925222781867493 | Predicción actual: [[0.45836583]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02921087108552456, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41857937]\n",
      " [0.42464495]\n",
      " [0.14800465]\n",
      " [0.45920223]\n",
      " [0.46181515]\n",
      " [0.46241155]\n",
      " [0.46113941]\n",
      " [0.45836583]] | y: 0.3177063153816349 | Predicción actual: [[0.4543166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03471315652132034, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42464495]\n",
      " [0.14800465]\n",
      " [0.45920223]\n",
      " [0.46181515]\n",
      " [0.46241155]\n",
      " [0.46113941]\n",
      " [0.45836583]\n",
      " [0.45431659]] | y: 0.31266950794265785 | Predicción actual: [[0.4497194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012869724072515965, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.45920223]\n",
      " [0.46181515]\n",
      " [0.46241155]\n",
      " [0.46113941]\n",
      " [0.45836583]\n",
      " [0.45431659]\n",
      " [0.4497194 ]] | y: 0.2890352576520729 | Predicción actual: [[0.44568813]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007138469722121954, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45920223]\n",
      " [0.46181515]\n",
      " [0.46241155]\n",
      " [0.46113941]\n",
      " [0.45836583]\n",
      " [0.45431659]\n",
      " [0.4497194 ]\n",
      " [0.44568813]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03541861101984978, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46181515]\n",
      " [0.46241155]\n",
      " [0.46113941]\n",
      " [0.45836583]\n",
      " [0.45431659]\n",
      " [0.4497194 ]\n",
      " [0.44568813]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.50564945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032087743282318115, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46241155]\n",
      " [0.46113941]\n",
      " [0.45836583]\n",
      " [0.45431659]\n",
      " [0.4497194 ]\n",
      " [0.44568813]\n",
      " [0.28283611]\n",
      " [0.50564945]] | y: 0.2758620689655173 | Predicción actual: [[0.5015687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007852845825254917, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46113941]\n",
      " [0.45836583]\n",
      " [0.45431659]\n",
      " [0.4497194 ]\n",
      " [0.44568813]\n",
      " [0.28283611]\n",
      " [0.50564945]\n",
      " [0.50156868]] | y: 0.2746997287872917 | Predicción actual: [[0.49634555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06520908325910568, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45836583]\n",
      " [0.45431659]\n",
      " [0.4497194 ]\n",
      " [0.44568813]\n",
      " [0.28283611]\n",
      " [0.50564945]\n",
      " [0.50156868]\n",
      " [0.49634555]] | y: 0.275474622239442 | Predicción actual: [[0.49083045]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05517887696623802, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45431659]\n",
      " [0.4497194 ]\n",
      " [0.44568813]\n",
      " [0.28283611]\n",
      " [0.50564945]\n",
      " [0.50156868]\n",
      " [0.49634555]\n",
      " [0.49083045]] | y: 0.3347539713289423 | Predicción actual: [[0.48606843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013619082979857922, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4497194 ]\n",
      " [0.44568813]\n",
      " [0.28283611]\n",
      " [0.50564945]\n",
      " [0.50156868]\n",
      " [0.49634555]\n",
      " [0.49083045]\n",
      " [0.48606843]] | y: 0.35567609453700116 | Predicción actual: [[0.48309055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03285091742873192, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44568813]\n",
      " [0.28283611]\n",
      " [0.50564945]\n",
      " [0.50156868]\n",
      " [0.49634555]\n",
      " [0.49083045]\n",
      " [0.48606843]\n",
      " [0.48309055]] | y: 0.3366912049593181 | Predicción actual: [[0.4825116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021794777363538742, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.50564945]\n",
      " [0.50156868]\n",
      " [0.49634555]\n",
      " [0.49083045]\n",
      " [0.48606843]\n",
      " [0.48309055]\n",
      " [0.48251161]] | y: 0.3335916311507167 | Predicción actual: [[0.48463145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025419872254133224, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50564945]\n",
      " [0.50156868]\n",
      " [0.49634555]\n",
      " [0.49083045]\n",
      " [0.48606843]\n",
      " [0.48309055]\n",
      " [0.48251161]\n",
      " [0.48463145]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025090286508202553, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50156868]\n",
      " [0.49634555]\n",
      " [0.49083045]\n",
      " [0.48606843]\n",
      " [0.48309055]\n",
      " [0.48251161]\n",
      " [0.48463145]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.52203417]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.682951475842856e-05, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49634555]\n",
      " [0.49083045]\n",
      " [0.48606843]\n",
      " [0.48309055]\n",
      " [0.48251161]\n",
      " [0.48463145]\n",
      " [0.3847346 ]\n",
      " [0.52203417]] | y: 0.5962805114296785 | Predicción actual: [[0.5170419]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01345042698085308, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49083045]\n",
      " [0.48606843]\n",
      " [0.48309055]\n",
      " [0.48251161]\n",
      " [0.48463145]\n",
      " [0.3847346 ]\n",
      " [0.52203417]\n",
      " [0.51704192]] | y: 0.574583494769469 | Predicción actual: [[0.5125592]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010125488042831421, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48606843]\n",
      " [0.48309055]\n",
      " [0.48251161]\n",
      " [0.48463145]\n",
      " [0.3847346 ]\n",
      " [0.52203417]\n",
      " [0.51704192]\n",
      " [0.51255918]] | y: 0.6063541263076326 | Predicción actual: [[0.5091465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002495074411854148, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48309055]\n",
      " [0.48251161]\n",
      " [0.48463145]\n",
      " [0.3847346 ]\n",
      " [0.52203417]\n",
      " [0.51704192]\n",
      " [0.51255918]\n",
      " [0.50914651]] | y: 0.5846571096474236 | Predicción actual: [[0.50712883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006043064873665571, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48251161]\n",
      " [0.48463145]\n",
      " [0.3847346 ]\n",
      " [0.52203417]\n",
      " [0.51704192]\n",
      " [0.51255918]\n",
      " [0.50914651]\n",
      " [0.50712883]] | y: 0.5687717938783416 | Predicción actual: [[0.50655895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.611394489184022e-05, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48463145]\n",
      " [0.3847346 ]\n",
      " [0.52203417]\n",
      " [0.51704192]\n",
      " [0.51255918]\n",
      " [0.50914651]\n",
      " [0.50712883]\n",
      " [0.50655895]] | y: 0.6427741185586981 | Predicción actual: [[0.50713855]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034972190856933594, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.52203417]\n",
      " [0.51704192]\n",
      " [0.51255918]\n",
      " [0.50914651]\n",
      " [0.50712883]\n",
      " [0.50655895]\n",
      " [0.50713855]] | y: 0.6617590081363811 | Predicción actual: [[0.5085347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011630854569375515, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52203417]\n",
      " [0.51704192]\n",
      " [0.51255918]\n",
      " [0.50914651]\n",
      " [0.50712883]\n",
      " [0.50655895]\n",
      " [0.50713855]\n",
      " [0.50853473]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005707679316401482, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51704192]\n",
      " [0.51255918]\n",
      " [0.50914651]\n",
      " [0.50712883]\n",
      " [0.50655895]\n",
      " [0.50713855]\n",
      " [0.50853473]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.53305435]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03519991785287857, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51255918]\n",
      " [0.50914651]\n",
      " [0.50712883]\n",
      " [0.50655895]\n",
      " [0.50713855]\n",
      " [0.50853473]\n",
      " [0.67299496]\n",
      " [0.53305435]] | y: 0.703990701278574 | Predicción actual: [[0.5336759]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028300007805228233, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50914651]\n",
      " [0.50712883]\n",
      " [0.50655895]\n",
      " [0.50713855]\n",
      " [0.50853473]\n",
      " [0.67299496]\n",
      " [0.53305435]\n",
      " [0.53367591]] | y: 0.7272375048430839 | Predicción actual: [[0.53685015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023089800029993057, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50712883]\n",
      " [0.50655895]\n",
      " [0.50713855]\n",
      " [0.50853473]\n",
      " [0.67299496]\n",
      " [0.53305435]\n",
      " [0.53367591]\n",
      " [0.53685015]] | y: 0.722588144130182 | Predicción actual: [[0.5425418]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0611610934138298, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50655895]\n",
      " [0.50713855]\n",
      " [0.50853473]\n",
      " [0.67299496]\n",
      " [0.53305435]\n",
      " [0.53367591]\n",
      " [0.53685015]\n",
      " [0.5425418 ]] | y: 0.771793878341728 | Predicción actual: [[0.55051196]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.056349221616983414, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50713855]\n",
      " [0.50853473]\n",
      " [0.67299496]\n",
      " [0.53305435]\n",
      " [0.53367591]\n",
      " [0.53685015]\n",
      " [0.5425418 ]\n",
      " [0.55051196]] | y: 0.7245253777605578 | Predicción actual: [[0.5603524]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044437289237976074, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50853473]\n",
      " [0.67299496]\n",
      " [0.53305435]\n",
      " [0.53367591]\n",
      " [0.53685015]\n",
      " [0.5425418 ]\n",
      " [0.55051196]\n",
      " [0.56035239]] | y: 0.6710577295621851 | Predicción actual: [[0.5716225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0073614236898720264, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.53305435]\n",
      " [0.53367591]\n",
      " [0.53685015]\n",
      " [0.5425418 ]\n",
      " [0.55051196]\n",
      " [0.56035239]\n",
      " [0.57162249]] | y: 0.6737698566447115 | Predicción actual: [[0.5838863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010688317008316517, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53305435]\n",
      " [0.53367591]\n",
      " [0.53685015]\n",
      " [0.5425418 ]\n",
      " [0.55051196]\n",
      " [0.56035239]\n",
      " [0.57162249]\n",
      " [0.58388633]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018088124692440033, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53367591]\n",
      " [0.53685015]\n",
      " [0.5425418 ]\n",
      " [0.55051196]\n",
      " [0.56035239]\n",
      " [0.57162249]\n",
      " [0.58388633]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.56233895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013308498077094555, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53685015]\n",
      " [0.5425418 ]\n",
      " [0.55051196]\n",
      " [0.56035239]\n",
      " [0.57162249]\n",
      " [0.58388633]\n",
      " [0.71445176]\n",
      " [0.56233895]] | y: 0.722588144130182 | Predicción actual: [[0.569913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03568663075566292, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5425418 ]\n",
      " [0.55051196]\n",
      " [0.56035239]\n",
      " [0.57162249]\n",
      " [0.58388633]\n",
      " [0.71445176]\n",
      " [0.56233895]\n",
      " [0.56991303]] | y: 0.6993413405656723 | Predicción actual: [[0.5793689]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032627616077661514, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55051196]\n",
      " [0.56035239]\n",
      " [0.57162249]\n",
      " [0.58388633]\n",
      " [0.71445176]\n",
      " [0.56233895]\n",
      " [0.56991303]\n",
      " [0.57936889]] | y: 0.7373111197210385 | Predicción actual: [[0.5898665]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03045865148305893, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56035239]\n",
      " [0.57162249]\n",
      " [0.58388633]\n",
      " [0.71445176]\n",
      " [0.56233895]\n",
      " [0.56991303]\n",
      " [0.57936889]\n",
      " [0.58986652]] | y: 0.7214258039519565 | Predicción actual: [[0.6004481]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029602862894535065, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57162249]\n",
      " [0.58388633]\n",
      " [0.71445176]\n",
      " [0.56233895]\n",
      " [0.56991303]\n",
      " [0.57936889]\n",
      " [0.58986652]\n",
      " [0.60044807]] | y: 0.7187136768694304 | Predicción actual: [[0.6101421]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011994399130344391, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58388633]\n",
      " [0.71445176]\n",
      " [0.56233895]\n",
      " [0.56991303]\n",
      " [0.57936889]\n",
      " [0.58986652]\n",
      " [0.60044807]\n",
      " [0.61014211]] | y: 0.6741573033707864 | Predicción actual: [[0.6180516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0064195627346634865, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56233895]\n",
      " [0.56991303]\n",
      " [0.57936889]\n",
      " [0.58986652]\n",
      " [0.60044807]\n",
      " [0.61014211]\n",
      " [0.61805159]] | y: 0.698566447113522 | Predicción actual: [[0.6234545]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004874514415860176, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56233895]\n",
      " [0.56991303]\n",
      " [0.57936889]\n",
      " [0.58986652]\n",
      " [0.60044807]\n",
      " [0.61014211]\n",
      " [0.61805159]\n",
      " [0.62345451]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03158726170659065, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56991303]\n",
      " [0.57936889]\n",
      " [0.58986652]\n",
      " [0.60044807]\n",
      " [0.61014211]\n",
      " [0.61805159]\n",
      " [0.62345451]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.605021]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007209299132227898, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57936889]\n",
      " [0.58986652]\n",
      " [0.60044807]\n",
      " [0.61014211]\n",
      " [0.61805159]\n",
      " [0.62345451]\n",
      " [0.72103836]\n",
      " [0.605021  ]] | y: 0.7562960092987214 | Predicción actual: [[0.6147567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021662520244717598, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58986652]\n",
      " [0.60044807]\n",
      " [0.61014211]\n",
      " [0.61805159]\n",
      " [0.62345451]\n",
      " [0.72103836]\n",
      " [0.605021  ]\n",
      " [0.6147567 ]] | y: 0.8275862068965516 | Predicción actual: [[0.62475294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020904239267110825, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60044807]\n",
      " [0.61014211]\n",
      " [0.61805159]\n",
      " [0.62345451]\n",
      " [0.72103836]\n",
      " [0.605021  ]\n",
      " [0.6147567 ]\n",
      " [0.62475294]] | y: 0.8388221619527314 | Predicción actual: [[0.6343175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10254309326410294, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61014211]\n",
      " [0.61805159]\n",
      " [0.62345451]\n",
      " [0.72103836]\n",
      " [0.605021  ]\n",
      " [0.6147567 ]\n",
      " [0.62475294]\n",
      " [0.63431752]] | y: 0.7942657884540876 | Predicción actual: [[0.64301425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01790190488100052, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61805159]\n",
      " [0.62345451]\n",
      " [0.72103836]\n",
      " [0.605021  ]\n",
      " [0.6147567 ]\n",
      " [0.62475294]\n",
      " [0.63431752]\n",
      " [0.64301425]] | y: 0.7838047268500579 | Predicción actual: [[0.6504446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023200973868370056, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62345451]\n",
      " [0.72103836]\n",
      " [0.605021  ]\n",
      " [0.6147567 ]\n",
      " [0.62475294]\n",
      " [0.63431752]\n",
      " [0.64301425]\n",
      " [0.65044463]] | y: 0.7679194110809764 | Predicción actual: [[0.6566873]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006796612404286861, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.605021  ]\n",
      " [0.6147567 ]\n",
      " [0.62475294]\n",
      " [0.63431752]\n",
      " [0.64301425]\n",
      " [0.65044463]\n",
      " [0.65668732]] | y: 0.7845796203022084 | Predicción actual: [[0.6620831]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007693884428590536, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.605021  ]\n",
      " [0.6147567 ]\n",
      " [0.62475294]\n",
      " [0.63431752]\n",
      " [0.64301425]\n",
      " [0.65044463]\n",
      " [0.65668732]\n",
      " [0.66208309]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04788781702518463, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6147567 ]\n",
      " [0.62475294]\n",
      " [0.63431752]\n",
      " [0.64301425]\n",
      " [0.65044463]\n",
      " [0.65668732]\n",
      " [0.66208309]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6527043]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04422755539417267, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62475294]\n",
      " [0.63431752]\n",
      " [0.64301425]\n",
      " [0.65044463]\n",
      " [0.65668732]\n",
      " [0.66208309]\n",
      " [0.87872917]\n",
      " [0.6527043 ]] | y: 0.8488957768306855 | Predicción actual: [[0.66431546]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040565650910139084, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63431752]\n",
      " [0.64301425]\n",
      " [0.65044463]\n",
      " [0.65668732]\n",
      " [0.66208309]\n",
      " [0.87872917]\n",
      " [0.6527043 ]\n",
      " [0.66431546]] | y: 0.8182874854707476 | Predicción actual: [[0.6770752]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02163906767964363, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64301425]\n",
      " [0.65044463]\n",
      " [0.65668732]\n",
      " [0.66208309]\n",
      " [0.87872917]\n",
      " [0.6527043 ]\n",
      " [0.66431546]\n",
      " [0.67707521]] | y: 0.8268113134444013 | Predicción actual: [[0.69059664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007234869059175253, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65044463]\n",
      " [0.65668732]\n",
      " [0.66208309]\n",
      " [0.87872917]\n",
      " [0.6527043 ]\n",
      " [0.66431546]\n",
      " [0.67707521]\n",
      " [0.69059664]] | y: 0.7853545137543589 | Predicción actual: [[0.7044725]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001369158853776753, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65668732]\n",
      " [0.66208309]\n",
      " [0.87872917]\n",
      " [0.6527043 ]\n",
      " [0.66431546]\n",
      " [0.67707521]\n",
      " [0.69059664]\n",
      " [0.70447248]] | y: 0.7892289810151103 | Predicción actual: [[0.7184033]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006585786119103432, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66208309]\n",
      " [0.87872917]\n",
      " [0.6527043 ]\n",
      " [0.66431546]\n",
      " [0.67707521]\n",
      " [0.69059664]\n",
      " [0.70447248]\n",
      " [0.71840328]] | y: 0.8341728012398295 | Predicción actual: [[0.73228484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05025198683142662, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.6527043 ]\n",
      " [0.66431546]\n",
      " [0.67707521]\n",
      " [0.69059664]\n",
      " [0.70447248]\n",
      " [0.71840328]\n",
      " [0.73228484]] | y: 0.8124757845796202 | Predicción actual: [[0.74615145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011011314578354359, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6527043 ]\n",
      " [0.66431546]\n",
      " [0.67707521]\n",
      " [0.69059664]\n",
      " [0.70447248]\n",
      " [0.71840328]\n",
      " [0.73228484]\n",
      " [0.74615145]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012503068894147873, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66431546]\n",
      " [0.67707521]\n",
      " [0.69059664]\n",
      " [0.70447248]\n",
      " [0.71840328]\n",
      " [0.73228484]\n",
      " [0.74615145]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.71448576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02735825441777706, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67707521]\n",
      " [0.69059664]\n",
      " [0.70447248]\n",
      " [0.71840328]\n",
      " [0.73228484]\n",
      " [0.74615145]\n",
      " [0.80123983]\n",
      " [0.71448576]] | y: 0.793490895001937 | Predicción actual: [[0.72811675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03961889073252678, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69059664]\n",
      " [0.70447248]\n",
      " [0.71840328]\n",
      " [0.73228484]\n",
      " [0.74615145]\n",
      " [0.80123983]\n",
      " [0.71448576]\n",
      " [0.72811675]] | y: 0.760170476559473 | Predicción actual: [[0.741681]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001213504932820797, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70447248]\n",
      " [0.71840328]\n",
      " [0.73228484]\n",
      " [0.74615145]\n",
      " [0.80123983]\n",
      " [0.71448576]\n",
      " [0.72811675]\n",
      " [0.74168098]] | y: 0.7353738860906625 | Predicción actual: [[0.75421524]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004709313157945871, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71840328]\n",
      " [0.73228484]\n",
      " [0.74615145]\n",
      " [0.80123983]\n",
      " [0.71448576]\n",
      " [0.72811675]\n",
      " [0.74168098]\n",
      " [0.75421524]] | y: 0.7101898488957767 | Predicción actual: [[0.7650538]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00991484522819519, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73228484]\n",
      " [0.74615145]\n",
      " [0.80123983]\n",
      " [0.71448576]\n",
      " [0.72811675]\n",
      " [0.74168098]\n",
      " [0.75421524]\n",
      " [0.76505381]] | y: 0.7121270825261525 | Predicción actual: [[0.77334523]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027997992001473904, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74615145]\n",
      " [0.80123983]\n",
      " [0.71448576]\n",
      " [0.72811675]\n",
      " [0.74168098]\n",
      " [0.75421524]\n",
      " [0.76505381]\n",
      " [0.77334523]] | y: 0.7396358000774894 | Predicción actual: [[0.77890414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027079058811068535, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.71448576]\n",
      " [0.72811675]\n",
      " [0.74168098]\n",
      " [0.75421524]\n",
      " [0.76505381]\n",
      " [0.77334523]\n",
      " [0.77890414]] | y: 0.7361487795428128 | Predicción actual: [[0.7810052]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009138678200542927, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71448576]\n",
      " [0.72811675]\n",
      " [0.74168098]\n",
      " [0.75421524]\n",
      " [0.76505381]\n",
      " [0.77334523]\n",
      " [0.77890414]\n",
      " [0.7810052 ]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.963322119991062e-06, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72811675]\n",
      " [0.74168098]\n",
      " [0.75421524]\n",
      " [0.76505381]\n",
      " [0.77334523]\n",
      " [0.77890414]\n",
      " [0.7810052 ]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.77828014]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006970980670303106, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74168098]\n",
      " [0.75421524]\n",
      " [0.76505381]\n",
      " [0.77334523]\n",
      " [0.77890414]\n",
      " [0.7810052 ]\n",
      " [0.66757071]\n",
      " [0.77828014]] | y: 0.696629213483146 | Predicción actual: [[0.78643745]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005713174585253, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75421524]\n",
      " [0.76505381]\n",
      " [0.77334523]\n",
      " [0.77890414]\n",
      " [0.7810052 ]\n",
      " [0.66757071]\n",
      " [0.77828014]\n",
      " [0.78643745]] | y: 0.6559473072452537 | Predicción actual: [[0.7916213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02218233235180378, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76505381]\n",
      " [0.77334523]\n",
      " [0.77890414]\n",
      " [0.7810052 ]\n",
      " [0.66757071]\n",
      " [0.77828014]\n",
      " [0.78643745]\n",
      " [0.79162133]] | y: 0.6788066640836885 | Predicción actual: [[0.7936191]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007825518841855228, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77334523]\n",
      " [0.77890414]\n",
      " [0.7810052 ]\n",
      " [0.66757071]\n",
      " [0.77828014]\n",
      " [0.78643745]\n",
      " [0.79162133]\n",
      " [0.7936191 ]] | y: 0.6760945370011622 | Predicción actual: [[0.7929728]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028923701494932175, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77890414]\n",
      " [0.7810052 ]\n",
      " [0.66757071]\n",
      " [0.77828014]\n",
      " [0.78643745]\n",
      " [0.79162133]\n",
      " [0.7936191 ]\n",
      " [0.7929728 ]] | y: 0.7295621851995349 | Predicción actual: [[0.79015124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030418427661061287, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7810052 ]\n",
      " [0.66757071]\n",
      " [0.77828014]\n",
      " [0.78643745]\n",
      " [0.79162133]\n",
      " [0.7936191 ]\n",
      " [0.7929728 ]\n",
      " [0.79015124]] | y: 0.7012785741960481 | Predicción actual: [[0.7860957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022968413308262825, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.77828014]\n",
      " [0.78643745]\n",
      " [0.79162133]\n",
      " [0.7936191 ]\n",
      " [0.7929728 ]\n",
      " [0.79015124]\n",
      " [0.78609568]] | y: 0.767531964354901 | Predicción actual: [[0.7821066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.739199195886613e-07, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77828014]\n",
      " [0.78643745]\n",
      " [0.79162133]\n",
      " [0.7936191 ]\n",
      " [0.7929728 ]\n",
      " [0.79015124]\n",
      " [0.78609568]\n",
      " [0.78210658]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038388799875974655, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78643745]\n",
      " [0.79162133]\n",
      " [0.7936191 ]\n",
      " [0.7929728 ]\n",
      " [0.79015124]\n",
      " [0.78609568]\n",
      " [0.78210658]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.81324697]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0554390428296756e-06, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79162133]\n",
      " [0.7936191 ]\n",
      " [0.7929728 ]\n",
      " [0.79015124]\n",
      " [0.78609568]\n",
      " [0.78210658]\n",
      " [0.75513367]\n",
      " [0.81324697]] | y: 0.7520340953118947 | Predicción actual: [[0.81282794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029016388580203056, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7936191 ]\n",
      " [0.7929728 ]\n",
      " [0.79015124]\n",
      " [0.78609568]\n",
      " [0.78210658]\n",
      " [0.75513367]\n",
      " [0.81324697]\n",
      " [0.81282794]] | y: 0.7098024021697016 | Predicción actual: [[0.8111296]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014102830551564693, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7929728 ]\n",
      " [0.79015124]\n",
      " [0.78609568]\n",
      " [0.78210658]\n",
      " [0.75513367]\n",
      " [0.81324697]\n",
      " [0.81282794]\n",
      " [0.81112963]] | y: 0.6904300658659435 | Predicción actual: [[0.80882365]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04367950186133385, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79015124]\n",
      " [0.78609568]\n",
      " [0.78210658]\n",
      " [0.75513367]\n",
      " [0.81324697]\n",
      " [0.81282794]\n",
      " [0.81112963]\n",
      " [0.80882365]] | y: 0.7543587756683454 | Predicción actual: [[0.8067113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05860297381877899, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78609568]\n",
      " [0.78210658]\n",
      " [0.75513367]\n",
      " [0.81324697]\n",
      " [0.81282794]\n",
      " [0.81112963]\n",
      " [0.80882365]\n",
      " [0.80671132]] | y: 0.7222006974041069 | Predicción actual: [[0.8056275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019231129437685013, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78210658]\n",
      " [0.75513367]\n",
      " [0.81324697]\n",
      " [0.81282794]\n",
      " [0.81112963]\n",
      " [0.80882365]\n",
      " [0.80671132]\n",
      " [0.80562752]] | y: 0.8485083301046106 | Predicción actual: [[0.80647975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00311132799834013, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.81324697]\n",
      " [0.81282794]\n",
      " [0.81112963]\n",
      " [0.80882365]\n",
      " [0.80671132]\n",
      " [0.80562752]\n",
      " [0.80647975]] | y: 0.9054629988376597 | Predicción actual: [[0.8096087]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015437779075000435, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81324697]\n",
      " [0.81282794]\n",
      " [0.81112963]\n",
      " [0.80882365]\n",
      " [0.80671132]\n",
      " [0.80562752]\n",
      " [0.80647975]\n",
      " [0.8096087 ]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009495425038039684, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81282794]\n",
      " [0.81112963]\n",
      " [0.80882365]\n",
      " [0.80671132]\n",
      " [0.80562752]\n",
      " [0.80647975]\n",
      " [0.8096087 ]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.81962985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005585948820225894, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81112963]\n",
      " [0.80882365]\n",
      " [0.80671132]\n",
      " [0.80562752]\n",
      " [0.80647975]\n",
      " [0.8096087 ]\n",
      " [0.8822162 ]\n",
      " [0.81962985]] | y: 0.889577683068578 | Predicción actual: [[0.8182566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023892992176115513, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80882365]\n",
      " [0.80671132]\n",
      " [0.80562752]\n",
      " [0.80647975]\n",
      " [0.8096087 ]\n",
      " [0.8822162 ]\n",
      " [0.81962985]\n",
      " [0.81825662]] | y: 0.8748547074777218 | Predicción actual: [[0.81827426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038746427744627, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80671132]\n",
      " [0.80562752]\n",
      " [0.80647975]\n",
      " [0.8096087 ]\n",
      " [0.8822162 ]\n",
      " [0.81962985]\n",
      " [0.81825662]\n",
      " [0.81827426]] | y: 0.9132119333591631 | Predicción actual: [[0.8201577]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015513470396399498, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80562752]\n",
      " [0.80647975]\n",
      " [0.8096087 ]\n",
      " [0.8822162 ]\n",
      " [0.81962985]\n",
      " [0.81825662]\n",
      " [0.81827426]\n",
      " [0.82015771]] | y: 1.0 | Predicción actual: [[0.82378155]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.056552186608314514, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80647975]\n",
      " [0.8096087 ]\n",
      " [0.8822162 ]\n",
      " [0.81962985]\n",
      " [0.81825662]\n",
      " [0.81827426]\n",
      " [0.82015771]\n",
      " [0.82378155]] | y: 0.9705540488182873 | Predicción actual: [[0.82897776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10058975219726562, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8096087 ]\n",
      " [0.8822162 ]\n",
      " [0.81962985]\n",
      " [0.81825662]\n",
      " [0.81827426]\n",
      " [0.82015771]\n",
      " [0.82378155]\n",
      " [0.82897776]] | y: 0.8888027896164277 | Predicción actual: [[0.835108]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04675367474555969, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.81962985]\n",
      " [0.81825662]\n",
      " [0.81827426]\n",
      " [0.82015771]\n",
      " [0.82378155]\n",
      " [0.82897776]\n",
      " [0.83510798]] | y: 0.877954281286323 | Predicción actual: [[0.84118485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027573497965931892, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81962985]\n",
      " [0.81825662]\n",
      " [0.81827426]\n",
      " [0.82015771]\n",
      " [0.82378155]\n",
      " [0.82897776]\n",
      " [0.83510798]\n",
      " [0.84118485]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002550331875681877, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81825662]\n",
      " [0.81827426]\n",
      " [0.82015771]\n",
      " [0.82378155]\n",
      " [0.82897776]\n",
      " [0.83510798]\n",
      " [0.84118485]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.82935125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007157296407967806, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81827426]\n",
      " [0.82015771]\n",
      " [0.82378155]\n",
      " [0.82897776]\n",
      " [0.83510798]\n",
      " [0.84118485]\n",
      " [0.84889578]\n",
      " [0.82935125]] | y: 0.8550949244478885 | Predicción actual: [[0.83244205]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009541028179228306, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82015771]\n",
      " [0.82378155]\n",
      " [0.82897776]\n",
      " [0.83510798]\n",
      " [0.84118485]\n",
      " [0.84889578]\n",
      " [0.82935125]\n",
      " [0.83244205]] | y: 0.8752421542037967 | Predicción actual: [[0.836094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007448299787938595, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82378155]\n",
      " [0.82897776]\n",
      " [0.83510798]\n",
      " [0.84118485]\n",
      " [0.84889578]\n",
      " [0.82935125]\n",
      " [0.83244205]\n",
      " [0.83609402]] | y: 0.857032158078264 | Predicción actual: [[0.8397971]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004637265577912331, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82897776]\n",
      " [0.83510798]\n",
      " [0.84118485]\n",
      " [0.84889578]\n",
      " [0.82935125]\n",
      " [0.83244205]\n",
      " [0.83609402]\n",
      " [0.83979708]] | y: 0.8500581170089112 | Predicción actual: [[0.8432718]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000945539097301662, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83510798]\n",
      " [0.84118485]\n",
      " [0.84889578]\n",
      " [0.82935125]\n",
      " [0.83244205]\n",
      " [0.83609402]\n",
      " [0.83979708]\n",
      " [0.84327179]] | y: 0.8426966292134832 | Predicción actual: [[0.84582645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004544789902865887, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84118485]\n",
      " [0.84889578]\n",
      " [0.82935125]\n",
      " [0.83244205]\n",
      " [0.83609402]\n",
      " [0.83979708]\n",
      " [0.84327179]\n",
      " [0.84582645]] | y: 0.8229368461836497 | Predicción actual: [[0.84707296]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00571037270128727, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.82935125]\n",
      " [0.83244205]\n",
      " [0.83609402]\n",
      " [0.83979708]\n",
      " [0.84327179]\n",
      " [0.84582645]\n",
      " [0.84707296]] | y: 0.7745060054242543 | Predicción actual: [[0.84686977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012631548568606377, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82935125]\n",
      " [0.83244205]\n",
      " [0.83609402]\n",
      " [0.83979708]\n",
      " [0.84327179]\n",
      " [0.84582645]\n",
      " [0.84707296]\n",
      " [0.84686977]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009007924236357212, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83244205]\n",
      " [0.83609402]\n",
      " [0.83979708]\n",
      " [0.84327179]\n",
      " [0.84582645]\n",
      " [0.84707296]\n",
      " [0.84686977]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8470602]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005302275996655226, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83609402]\n",
      " [0.83979708]\n",
      " [0.84327179]\n",
      " [0.84582645]\n",
      " [0.84707296]\n",
      " [0.84686977]\n",
      " [0.78419217]\n",
      " [0.8470602 ]] | y: 0.854320030995738 | Predicción actual: [[0.8492162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025458013638854027, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83979708]\n",
      " [0.84327179]\n",
      " [0.84582645]\n",
      " [0.84707296]\n",
      " [0.84686977]\n",
      " [0.78419217]\n",
      " [0.8470602 ]\n",
      " [0.84921622]] | y: 0.8368849283223556 | Predicción actual: [[0.8499211]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029019792564213276, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84327179]\n",
      " [0.84582645]\n",
      " [0.84707296]\n",
      " [0.84686977]\n",
      " [0.78419217]\n",
      " [0.8470602 ]\n",
      " [0.84921622]\n",
      " [0.84992111]] | y: 0.8299108872530028 | Predicción actual: [[0.84957784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009747135452926159, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84582645]\n",
      " [0.84707296]\n",
      " [0.84686977]\n",
      " [0.78419217]\n",
      " [0.8470602 ]\n",
      " [0.84921622]\n",
      " [0.84992111]\n",
      " [0.84957784]] | y: 0.887253002712127 | Predicción actual: [[0.84831065]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004705199506133795, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84707296]\n",
      " [0.84686977]\n",
      " [0.78419217]\n",
      " [0.8470602 ]\n",
      " [0.84921622]\n",
      " [0.84992111]\n",
      " [0.84957784]\n",
      " [0.84831065]] | y: 0.8597442851607902 | Predicción actual: [[0.84610814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008920088293962181, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84686977]\n",
      " [0.78419217]\n",
      " [0.8470602 ]\n",
      " [0.84921622]\n",
      " [0.84992111]\n",
      " [0.84957784]\n",
      " [0.84831065]\n",
      " [0.84610814]] | y: 0.8395970554048819 | Predicción actual: [[0.84369296]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005374743137508631, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.8470602 ]\n",
      " [0.84921622]\n",
      " [0.84992111]\n",
      " [0.84957784]\n",
      " [0.84831065]\n",
      " [0.84610814]\n",
      " [0.84369296]] | y: 0.7838047268500579 | Predicción actual: [[0.8416949]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012071969686076045, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8470602 ]\n",
      " [0.84921622]\n",
      " [0.84992111]\n",
      " [0.84957784]\n",
      " [0.84831065]\n",
      " [0.84610814]\n",
      " [0.84369296]\n",
      " [0.84169489]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015907720080576837, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84921622]\n",
      " [0.84992111]\n",
      " [0.84957784]\n",
      " [0.84831065]\n",
      " [0.84610814]\n",
      " [0.84369296]\n",
      " [0.84169489]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8581505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007281820755451918, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84992111]\n",
      " [0.84957784]\n",
      " [0.84831065]\n",
      " [0.84610814]\n",
      " [0.84369296]\n",
      " [0.84169489]\n",
      " [0.81828749]\n",
      " [0.85815048]] | y: 0.7605579232855482 | Predicción actual: [[0.8572234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015138494782149792, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84957784]\n",
      " [0.84831065]\n",
      " [0.84610814]\n",
      " [0.84369296]\n",
      " [0.84169489]\n",
      " [0.81828749]\n",
      " [0.85815048]\n",
      " [0.85722339]] | y: 0.7915536613715615 | Predicción actual: [[0.855984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012348922900855541, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84831065]\n",
      " [0.84610814]\n",
      " [0.84369296]\n",
      " [0.84169489]\n",
      " [0.81828749]\n",
      " [0.85815048]\n",
      " [0.85722339]\n",
      " [0.85598397]] | y: 0.7686943045331267 | Predicción actual: [[0.85442007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04724646732211113, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84610814]\n",
      " [0.84369296]\n",
      " [0.84169489]\n",
      " [0.81828749]\n",
      " [0.85815048]\n",
      " [0.85722339]\n",
      " [0.85598397]\n",
      " [0.85442007]] | y: 0.7686943045331267 | Predicción actual: [[0.8527367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.067023366689682, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84369296]\n",
      " [0.84169489]\n",
      " [0.81828749]\n",
      " [0.85815048]\n",
      " [0.85722339]\n",
      " [0.85598397]\n",
      " [0.85442007]\n",
      " [0.85273671]] | y: 0.7989151491669895 | Predicción actual: [[0.8513611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011214593541808426, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84169489]\n",
      " [0.81828749]\n",
      " [0.85815048]\n",
      " [0.85722339]\n",
      " [0.85598397]\n",
      " [0.85442007]\n",
      " [0.85273671]\n",
      " [0.8513611 ]] | y: 0.7900038744672608 | Predicción actual: [[0.8511735]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004581171553581953, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.85815048]\n",
      " [0.85722339]\n",
      " [0.85598397]\n",
      " [0.85442007]\n",
      " [0.85273671]\n",
      " [0.8513611 ]\n",
      " [0.85117352]] | y: 0.760170476559473 | Predicción actual: [[0.8520592]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03575573116540909, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85815048]\n",
      " [0.85722339]\n",
      " [0.85598397]\n",
      " [0.85442007]\n",
      " [0.85273671]\n",
      " [0.8513611 ]\n",
      " [0.85117352]\n",
      " [0.85205919]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.090908482670784, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85722339]\n",
      " [0.85598397]\n",
      " [0.85442007]\n",
      " [0.85273671]\n",
      " [0.8513611 ]\n",
      " [0.85117352]\n",
      " [0.85205919]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.85587275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026284512132406235, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85598397]\n",
      " [0.85442007]\n",
      " [0.85273671]\n",
      " [0.8513611 ]\n",
      " [0.85117352]\n",
      " [0.85205919]\n",
      " [0.68539326]\n",
      " [0.85587275]] | y: 0.6648585819449826 | Predicción actual: [[0.8503085]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015156981535255909, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85442007]\n",
      " [0.85273671]\n",
      " [0.8513611 ]\n",
      " [0.85117352]\n",
      " [0.85205919]\n",
      " [0.68539326]\n",
      " [0.85587275]\n",
      " [0.85030848]] | y: 0.7078651685393258 | Predicción actual: [[0.84331185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006815012544393539, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85273671]\n",
      " [0.8513611 ]\n",
      " [0.85117352]\n",
      " [0.85205919]\n",
      " [0.68539326]\n",
      " [0.85587275]\n",
      " [0.85030848]\n",
      " [0.84331185]] | y: 0.6648585819449826 | Predicción actual: [[0.83519685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04194621741771698, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8513611 ]\n",
      " [0.85117352]\n",
      " [0.85205919]\n",
      " [0.68539326]\n",
      " [0.85587275]\n",
      " [0.85030848]\n",
      " [0.84331185]\n",
      " [0.83519685]] | y: 0.7113521890740022 | Predicción actual: [[0.82605314]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05067432299256325, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85117352]\n",
      " [0.85205919]\n",
      " [0.68539326]\n",
      " [0.85587275]\n",
      " [0.85030848]\n",
      " [0.84331185]\n",
      " [0.83519685]\n",
      " [0.82605314]] | y: 0.6772568771793879 | Predicción actual: [[0.8161175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018557636067271233, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85205919]\n",
      " [0.68539326]\n",
      " [0.85587275]\n",
      " [0.85030848]\n",
      " [0.84331185]\n",
      " [0.83519685]\n",
      " [0.82605314]\n",
      " [0.81611753]] | y: 0.7621077101898488 | Predicción actual: [[0.8056312]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00936226174235344, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.85587275]\n",
      " [0.85030848]\n",
      " [0.84331185]\n",
      " [0.83519685]\n",
      " [0.82605314]\n",
      " [0.81611753]\n",
      " [0.80563122]] | y: 0.8070515304145678 | Predicción actual: [[0.79488814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008438362856395543, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85587275]\n",
      " [0.85030848]\n",
      " [0.84331185]\n",
      " [0.83519685]\n",
      " [0.82605314]\n",
      " [0.81611753]\n",
      " [0.80563122]\n",
      " [0.79488814]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012059505097568035, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85030848]\n",
      " [0.84331185]\n",
      " [0.83519685]\n",
      " [0.82605314]\n",
      " [0.81611753]\n",
      " [0.80563122]\n",
      " [0.79488814]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8214446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039575763046741486, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84331185]\n",
      " [0.83519685]\n",
      " [0.82605314]\n",
      " [0.81611753]\n",
      " [0.80563122]\n",
      " [0.79488814]\n",
      " [0.81518791]\n",
      " [0.82144457]] | y: 0.9597055404881829 | Predicción actual: [[0.8132851]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00034466583747416735, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83519685]\n",
      " [0.82605314]\n",
      " [0.81611753]\n",
      " [0.80563122]\n",
      " [0.79488814]\n",
      " [0.81518791]\n",
      " [0.82144457]\n",
      " [0.81328511]] | y: 0.9643549012010848 | Predicción actual: [[0.8056626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051614031195640564, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82605314]\n",
      " [0.81611753]\n",
      " [0.80563122]\n",
      " [0.79488814]\n",
      " [0.81518791]\n",
      " [0.82144457]\n",
      " [0.81328511]\n",
      " [0.80566257]] | y: 0.8880278961642774 | Predicción actual: [[0.7994984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009010492824018002, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81611753]\n",
      " [0.80563122]\n",
      " [0.79488814]\n",
      " [0.81518791]\n",
      " [0.82144457]\n",
      " [0.81328511]\n",
      " [0.80566257]\n",
      " [0.79949838]] | y: 0.8926772568771792 | Predicción actual: [[0.7947736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016301697120070457, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80563122]\n",
      " [0.79488814]\n",
      " [0.81518791]\n",
      " [0.82144457]\n",
      " [0.81328511]\n",
      " [0.80566257]\n",
      " [0.79949838]\n",
      " [0.79477358]] | y: 0.8752421542037967 | Predicción actual: [[0.79238975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005954615771770477, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79488814]\n",
      " [0.81518791]\n",
      " [0.82144457]\n",
      " [0.81328511]\n",
      " [0.80566257]\n",
      " [0.79949838]\n",
      " [0.79477358]\n",
      " [0.79238975]] | y: 0.8508330104610615 | Predicción actual: [[0.7925215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013337765820324421, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.82144457]\n",
      " [0.81328511]\n",
      " [0.80566257]\n",
      " [0.79949838]\n",
      " [0.79477358]\n",
      " [0.79238975]\n",
      " [0.79252148]] | y: 0.8488957768306855 | Predicción actual: [[0.79552037]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00031175639014691114, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82144457]\n",
      " [0.81328511]\n",
      " [0.80566257]\n",
      " [0.79949838]\n",
      " [0.79477358]\n",
      " [0.79238975]\n",
      " [0.79252148]\n",
      " [0.79552037]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014221173711121082, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81328511]\n",
      " [0.80566257]\n",
      " [0.79949838]\n",
      " [0.79477358]\n",
      " [0.79238975]\n",
      " [0.79252148]\n",
      " [0.79552037]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7887375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01015944592654705, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80566257]\n",
      " [0.79949838]\n",
      " [0.79477358]\n",
      " [0.79238975]\n",
      " [0.79252148]\n",
      " [0.79552037]\n",
      " [0.96241767]\n",
      " [0.78873748]] | y: 0.9407206509104997 | Predicción actual: [[0.7874125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09813015908002853, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79949838]\n",
      " [0.79477358]\n",
      " [0.79238975]\n",
      " [0.79252148]\n",
      " [0.79552037]\n",
      " [0.96241767]\n",
      " [0.78873748]\n",
      " [0.78741252]] | y: 0.9724912824486633 | Predicción actual: [[0.78927875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028147561475634575, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79477358]\n",
      " [0.79238975]\n",
      " [0.79252148]\n",
      " [0.79552037]\n",
      " [0.96241767]\n",
      " [0.78873748]\n",
      " [0.78741252]\n",
      " [0.78927875]] | y: 0.9969004261913985 | Predicción actual: [[0.79390925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03937193378806114, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79238975]\n",
      " [0.79252148]\n",
      " [0.79552037]\n",
      " [0.96241767]\n",
      " [0.78873748]\n",
      " [0.78741252]\n",
      " [0.78927875]\n",
      " [0.79390925]] | y: 0.951181712514529 | Predicción actual: [[0.80084145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011912159621715546, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79252148]\n",
      " [0.79552037]\n",
      " [0.96241767]\n",
      " [0.78873748]\n",
      " [0.78741252]\n",
      " [0.78927875]\n",
      " [0.79390925]\n",
      " [0.80084145]] | y: 0.8957768306857805 | Predicción actual: [[0.8090419]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04034838825464249, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79552037]\n",
      " [0.96241767]\n",
      " [0.78873748]\n",
      " [0.78741252]\n",
      " [0.78927875]\n",
      " [0.79390925]\n",
      " [0.80084145]\n",
      " [0.80904192]] | y: 0.8814413018209997 | Predicción actual: [[0.8175868]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007803742308169603, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.78873748]\n",
      " [0.78741252]\n",
      " [0.78927875]\n",
      " [0.79390925]\n",
      " [0.80084145]\n",
      " [0.80904192]\n",
      " [0.81758678]] | y: 0.9170864006199149 | Predicción actual: [[0.8248376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003133202902972698, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78873748]\n",
      " [0.78741252]\n",
      " [0.78927875]\n",
      " [0.79390925]\n",
      " [0.80084145]\n",
      " [0.80904192]\n",
      " [0.81758678]\n",
      " [0.82483763]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07746714353561401, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78741252]\n",
      " [0.78927875]\n",
      " [0.79390925]\n",
      " [0.80084145]\n",
      " [0.80904192]\n",
      " [0.81758678]\n",
      " [0.82483763]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.789679]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0365455262362957, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78927875]\n",
      " [0.79390925]\n",
      " [0.80084145]\n",
      " [0.80904192]\n",
      " [0.81758678]\n",
      " [0.82483763]\n",
      " [0.91979853]\n",
      " [0.78967899]] | y: 0.9682293684618366 | Predicción actual: [[0.79656005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1858222931623459, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79390925]\n",
      " [0.80084145]\n",
      " [0.80904192]\n",
      " [0.81758678]\n",
      " [0.82483763]\n",
      " [0.91979853]\n",
      " [0.78967899]\n",
      " [0.79656005]] | y: 0.9577683068578069 | Predicción actual: [[0.8051632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023647623136639595, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.23859632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034934207797050476, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23859632]] | y: 0.10422316931421921 | Predicción actual: [[0.22411689]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01415675412863493, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23859632]\n",
      " [0.22411689]] | y: 0.15420379697791559 | Predicción actual: [[0.22866397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01183595322072506, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23859632]\n",
      " [0.22411689]\n",
      " [0.22866397]] | y: 0.1557535838822161 | Predicción actual: [[0.24078836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003579935058951378, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23859632]\n",
      " [0.22411689]\n",
      " [0.22866397]\n",
      " [0.24078836]] | y: 0.12553273924835334 | Predicción actual: [[0.25485763]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017173966392874718, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23859632]\n",
      " [0.22411689]\n",
      " [0.22866397]\n",
      " [0.24078836]\n",
      " [0.25485763]] | y: 0.1456799690042619 | Predicción actual: [[0.267453]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00847272016108036, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23859632]\n",
      " [0.22411689]\n",
      " [0.22866397]\n",
      " [0.24078836]\n",
      " [0.25485763]\n",
      " [0.26745301]] | y: 0.1464548624564122 | Predicción actual: [[0.29224116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03180695325136185, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.23859632]\n",
      " [0.22411689]\n",
      " [0.22866397]\n",
      " [0.24078836]\n",
      " [0.25485763]\n",
      " [0.26745301]\n",
      " [0.29224116]] | y: 0.1960480433940332 | Predicción actual: [[0.3231595]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039707865566015244, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23859632]\n",
      " [0.22411689]\n",
      " [0.22866397]\n",
      " [0.24078836]\n",
      " [0.25485763]\n",
      " [0.26745301]\n",
      " [0.29224116]\n",
      " [0.32315949]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00022013028501532972, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22411689]\n",
      " [0.22866397]\n",
      " [0.24078836]\n",
      " [0.25485763]\n",
      " [0.26745301]\n",
      " [0.29224116]\n",
      " [0.32315949]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.36337224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03851889446377754, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22866397]\n",
      " [0.24078836]\n",
      " [0.25485763]\n",
      " [0.26745301]\n",
      " [0.29224116]\n",
      " [0.32315949]\n",
      " [0.2305308 ]\n",
      " [0.36337224]] | y: 0.211933359163115 | Predicción actual: [[0.37073013]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02099038101732731, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24078836]\n",
      " [0.25485763]\n",
      " [0.26745301]\n",
      " [0.29224116]\n",
      " [0.32315949]\n",
      " [0.2305308 ]\n",
      " [0.36337224]\n",
      " [0.37073013]] | y: 0.2072839984502131 | Predicción actual: [[0.37990475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030217086896300316, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25485763]\n",
      " [0.26745301]\n",
      " [0.29224116]\n",
      " [0.32315949]\n",
      " [0.2305308 ]\n",
      " [0.36337224]\n",
      " [0.37073013]\n",
      " [0.37990475]] | y: 0.19294846958543205 | Predicción actual: [[0.38974166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06085186451673508, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26745301]\n",
      " [0.29224116]\n",
      " [0.32315949]\n",
      " [0.2305308 ]\n",
      " [0.36337224]\n",
      " [0.37073013]\n",
      " [0.37990475]\n",
      " [0.38974166]] | y: 0.19682293684618352 | Predicción actual: [[0.40004474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05320025235414505, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.29224116]\n",
      " [0.32315949]\n",
      " [0.2305308 ]\n",
      " [0.36337224]\n",
      " [0.37073013]\n",
      " [0.37990475]\n",
      " [0.38974166]\n",
      " [0.40004474]] | y: 0.21425803951956607 | Predicción actual: [[0.4113311]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04512358084321022, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32315949]\n",
      " [0.2305308 ]\n",
      " [0.36337224]\n",
      " [0.37073013]\n",
      " [0.37990475]\n",
      " [0.38974166]\n",
      " [0.40004474]\n",
      " [0.41133109]] | y: 0.18132506780317698 | Predicción actual: [[0.42095926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052644774317741394, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.36337224]\n",
      " [0.37073013]\n",
      " [0.37990475]\n",
      " [0.38974166]\n",
      " [0.40004474]\n",
      " [0.41133109]\n",
      " [0.42095926]] | y: 0.17512592018597434 | Predicción actual: [[0.42719507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061549801379442215, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36337224]\n",
      " [0.37073013]\n",
      " [0.37990475]\n",
      " [0.38974166]\n",
      " [0.40004474]\n",
      " [0.41133109]\n",
      " [0.42095926]\n",
      " [0.42719507]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10289579629898071, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37073013]\n",
      " [0.37990475]\n",
      " [0.38974166]\n",
      " [0.40004474]\n",
      " [0.41133109]\n",
      " [0.42095926]\n",
      " [0.42719507]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.46265534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09007616341114044, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37990475]\n",
      " [0.38974166]\n",
      " [0.40004474]\n",
      " [0.41133109]\n",
      " [0.42095926]\n",
      " [0.42719507]\n",
      " [0.14800465]\n",
      " [0.46265534]] | y: 0.19217357613328173 | Predicción actual: [[0.46542788]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028745252639055252, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38974166]\n",
      " [0.40004474]\n",
      " [0.41133109]\n",
      " [0.42095926]\n",
      " [0.42719507]\n",
      " [0.14800465]\n",
      " [0.46265534]\n",
      " [0.46542788]] | y: 0.1859744285160791 | Predicción actual: [[0.46619642]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09629962593317032, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40004474]\n",
      " [0.41133109]\n",
      " [0.42095926]\n",
      " [0.42719507]\n",
      " [0.14800465]\n",
      " [0.46265534]\n",
      " [0.46542788]\n",
      " [0.46619642]] | y: 0.26695079426578844 | Predicción actual: [[0.46498707]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02274276688694954, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41133109]\n",
      " [0.42095926]\n",
      " [0.42719507]\n",
      " [0.14800465]\n",
      " [0.46265534]\n",
      " [0.46542788]\n",
      " [0.46619642]\n",
      " [0.46498707]] | y: 0.2925222781867493 | Predicción actual: [[0.4622551]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04662610590457916, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42095926]\n",
      " [0.42719507]\n",
      " [0.14800465]\n",
      " [0.46265534]\n",
      " [0.46542788]\n",
      " [0.46619642]\n",
      " [0.46498707]\n",
      " [0.46225509]] | y: 0.3177063153816349 | Predicción actual: [[0.45818323]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04182412102818489, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42719507]\n",
      " [0.14800465]\n",
      " [0.46265534]\n",
      " [0.46542788]\n",
      " [0.46619642]\n",
      " [0.46498707]\n",
      " [0.46225509]\n",
      " [0.45818323]] | y: 0.31266950794265785 | Predicción actual: [[0.4535516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05002917721867561, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.46265534]\n",
      " [0.46542788]\n",
      " [0.46619642]\n",
      " [0.46498707]\n",
      " [0.46225509]\n",
      " [0.45818323]\n",
      " [0.45355159]] | y: 0.2890352576520729 | Predicción actual: [[0.44943607]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028362832963466644, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46265534]\n",
      " [0.46542788]\n",
      " [0.46619642]\n",
      " [0.46498707]\n",
      " [0.46225509]\n",
      " [0.45818323]\n",
      " [0.45355159]\n",
      " [0.44943607]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039824534207582474, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46542788]\n",
      " [0.46619642]\n",
      " [0.46498707]\n",
      " [0.46225509]\n",
      " [0.45818323]\n",
      " [0.45355159]\n",
      " [0.44943607]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.5107471]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007185062859207392, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46619642]\n",
      " [0.46498707]\n",
      " [0.46225509]\n",
      " [0.45818323]\n",
      " [0.45355159]\n",
      " [0.44943607]\n",
      " [0.28283611]\n",
      " [0.51074708]] | y: 0.2758620689655173 | Predicción actual: [[0.5065295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047389738261699677, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46498707]\n",
      " [0.46225509]\n",
      " [0.45818323]\n",
      " [0.45355159]\n",
      " [0.44943607]\n",
      " [0.28283611]\n",
      " [0.51074708]\n",
      " [0.50652951]] | y: 0.2746997287872917 | Predicción actual: [[0.5010183]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061357151716947556, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46225509]\n",
      " [0.45818323]\n",
      " [0.45355159]\n",
      " [0.44943607]\n",
      " [0.28283611]\n",
      " [0.51074708]\n",
      " [0.50652951]\n",
      " [0.50101829]] | y: 0.275474622239442 | Predicción actual: [[0.4952174]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06913681328296661, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45818323]\n",
      " [0.45355159]\n",
      " [0.44943607]\n",
      " [0.28283611]\n",
      " [0.51074708]\n",
      " [0.50652951]\n",
      " [0.50101829]\n",
      " [0.49521741]] | y: 0.3347539713289423 | Predicción actual: [[0.4901645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02765793912112713, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45355159]\n",
      " [0.44943607]\n",
      " [0.28283611]\n",
      " [0.51074708]\n",
      " [0.50652951]\n",
      " [0.50101829]\n",
      " [0.49521741]\n",
      " [0.49016449]] | y: 0.35567609453700116 | Predicción actual: [[0.48691982]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04303750768303871, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44943607]\n",
      " [0.28283611]\n",
      " [0.51074708]\n",
      " [0.50652951]\n",
      " [0.50101829]\n",
      " [0.49521741]\n",
      " [0.49016449]\n",
      " [0.48691982]] | y: 0.3366912049593181 | Predicción actual: [[0.48613194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018974553793668747, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.51074708]\n",
      " [0.50652951]\n",
      " [0.50101829]\n",
      " [0.49521741]\n",
      " [0.49016449]\n",
      " [0.48691982]\n",
      " [0.48613194]] | y: 0.3335916311507167 | Predicción actual: [[0.48814583]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011454541236162186, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51074708]\n",
      " [0.50652951]\n",
      " [0.50101829]\n",
      " [0.49521741]\n",
      " [0.49016449]\n",
      " [0.48691982]\n",
      " [0.48613194]\n",
      " [0.48814583]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016900038346648216, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50652951]\n",
      " [0.50101829]\n",
      " [0.49521741]\n",
      " [0.49016449]\n",
      " [0.48691982]\n",
      " [0.48613194]\n",
      " [0.48814583]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.52657527]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003420854452997446, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50101829]\n",
      " [0.49521741]\n",
      " [0.49016449]\n",
      " [0.48691982]\n",
      " [0.48613194]\n",
      " [0.48814583]\n",
      " [0.3847346 ]\n",
      " [0.52657527]] | y: 0.5962805114296785 | Predicción actual: [[0.5212605]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012033075094223022, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49521741]\n",
      " [0.49016449]\n",
      " [0.48691982]\n",
      " [0.48613194]\n",
      " [0.48814583]\n",
      " [0.3847346 ]\n",
      " [0.52657527]\n",
      " [0.5212605 ]] | y: 0.574583494769469 | Predicción actual: [[0.516466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004487015772610903, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49016449]\n",
      " [0.48691982]\n",
      " [0.48613194]\n",
      " [0.48814583]\n",
      " [0.3847346 ]\n",
      " [0.52657527]\n",
      " [0.5212605 ]\n",
      " [0.51646602]] | y: 0.6063541263076326 | Predicción actual: [[0.51275957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024816233199089766, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48691982]\n",
      " [0.48613194]\n",
      " [0.48814583]\n",
      " [0.3847346 ]\n",
      " [0.52657527]\n",
      " [0.5212605 ]\n",
      " [0.51646602]\n",
      " [0.51275957]] | y: 0.5846571096474236 | Predicción actual: [[0.5105061]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016885798424482346, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48613194]\n",
      " [0.48814583]\n",
      " [0.3847346 ]\n",
      " [0.52657527]\n",
      " [0.5212605 ]\n",
      " [0.51646602]\n",
      " [0.51275957]\n",
      " [0.51050609]] | y: 0.5687717938783416 | Predicción actual: [[0.509795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007302098907530308, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48814583]\n",
      " [0.3847346 ]\n",
      " [0.52657527]\n",
      " [0.5212605 ]\n",
      " [0.51646602]\n",
      " [0.51275957]\n",
      " [0.51050609]\n",
      " [0.50979501]] | y: 0.6427741185586981 | Predicción actual: [[0.51035655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022972378879785538, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.52657527]\n",
      " [0.5212605 ]\n",
      " [0.51646602]\n",
      " [0.51275957]\n",
      " [0.51050609]\n",
      " [0.50979501]\n",
      " [0.51035655]] | y: 0.6617590081363811 | Predicción actual: [[0.5117538]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009314317256212234, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52657527]\n",
      " [0.5212605 ]\n",
      " [0.51646602]\n",
      " [0.51275957]\n",
      " [0.51050609]\n",
      " [0.50979501]\n",
      " [0.51035655]\n",
      " [0.5117538 ]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024923913180828094, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5212605 ]\n",
      " [0.51646602]\n",
      " [0.51275957]\n",
      " [0.51050609]\n",
      " [0.50979501]\n",
      " [0.51035655]\n",
      " [0.5117538 ]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5372384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016626441851258278, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51646602]\n",
      " [0.51275957]\n",
      " [0.51050609]\n",
      " [0.50979501]\n",
      " [0.51035655]\n",
      " [0.5117538 ]\n",
      " [0.67299496]\n",
      " [0.53723842]] | y: 0.703990701278574 | Predicción actual: [[0.537689]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05888247862458229, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51275957]\n",
      " [0.51050609]\n",
      " [0.50979501]\n",
      " [0.51035655]\n",
      " [0.5117538 ]\n",
      " [0.67299496]\n",
      " [0.53723842]\n",
      " [0.53768897]] | y: 0.7272375048430839 | Predicción actual: [[0.5407747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11566449701786041, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51050609]\n",
      " [0.50979501]\n",
      " [0.51035655]\n",
      " [0.5117538 ]\n",
      " [0.67299496]\n",
      " [0.53723842]\n",
      " [0.53768897]\n",
      " [0.5407747 ]] | y: 0.722588144130182 | Predicción actual: [[0.5465038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09178216755390167, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50979501]\n",
      " [0.51035655]\n",
      " [0.5117538 ]\n",
      " [0.67299496]\n",
      " [0.53723842]\n",
      " [0.53768897]\n",
      " [0.5407747 ]\n",
      " [0.54650378]] | y: 0.771793878341728 | Predicción actual: [[0.55459136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06165046989917755, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51035655]\n",
      " [0.5117538 ]\n",
      " [0.67299496]\n",
      " [0.53723842]\n",
      " [0.53768897]\n",
      " [0.5407747 ]\n",
      " [0.54650378]\n",
      " [0.55459136]] | y: 0.7245253777605578 | Predicción actual: [[0.56461746]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032675500959157944, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5117538 ]\n",
      " [0.67299496]\n",
      " [0.53723842]\n",
      " [0.53768897]\n",
      " [0.5407747 ]\n",
      " [0.54650378]\n",
      " [0.55459136]\n",
      " [0.56461746]] | y: 0.6710577295621851 | Predicción actual: [[0.576101]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006148992571979761, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.53723842]\n",
      " [0.53768897]\n",
      " [0.5407747 ]\n",
      " [0.54650378]\n",
      " [0.55459136]\n",
      " [0.56461746]\n",
      " [0.57610101]] | y: 0.6737698566447115 | Predicción actual: [[0.5886223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004659633152186871, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53723842]\n",
      " [0.53768897]\n",
      " [0.5407747 ]\n",
      " [0.54650378]\n",
      " [0.55459136]\n",
      " [0.56461746]\n",
      " [0.57610101]\n",
      " [0.58862227]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000459728529676795, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53768897]\n",
      " [0.5407747 ]\n",
      " [0.54650378]\n",
      " [0.55459136]\n",
      " [0.56461746]\n",
      " [0.57610101]\n",
      " [0.58862227]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5675909]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03844985365867615, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5407747 ]\n",
      " [0.54650378]\n",
      " [0.55459136]\n",
      " [0.56461746]\n",
      " [0.57610101]\n",
      " [0.58862227]\n",
      " [0.71445176]\n",
      " [0.56759089]] | y: 0.722588144130182 | Predicción actual: [[0.575232]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007061466458253562, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54650378]\n",
      " [0.55459136]\n",
      " [0.56461746]\n",
      " [0.57610101]\n",
      " [0.58862227]\n",
      " [0.71445176]\n",
      " [0.56759089]\n",
      " [0.57523203]] | y: 0.6993413405656723 | Predicción actual: [[0.5846719]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006088837515562773, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55459136]\n",
      " [0.56461746]\n",
      " [0.57610101]\n",
      " [0.58862227]\n",
      " [0.71445176]\n",
      " [0.56759089]\n",
      " [0.57523203]\n",
      " [0.58467191]] | y: 0.7373111197210385 | Predicción actual: [[0.5951044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004232076928019524, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56461746]\n",
      " [0.57610101]\n",
      " [0.58862227]\n",
      " [0.71445176]\n",
      " [0.56759089]\n",
      " [0.57523203]\n",
      " [0.58467191]\n",
      " [0.5951044 ]] | y: 0.7214258039519565 | Predicción actual: [[0.6055348]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01336474996060133, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57610101]\n",
      " [0.58862227]\n",
      " [0.71445176]\n",
      " [0.56759089]\n",
      " [0.57523203]\n",
      " [0.58467191]\n",
      " [0.5951044 ]\n",
      " [0.60553479]] | y: 0.7187136768694304 | Predicción actual: [[0.6150254]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.380014383466914e-05, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58862227]\n",
      " [0.71445176]\n",
      " [0.56759089]\n",
      " [0.57523203]\n",
      " [0.58467191]\n",
      " [0.5951044 ]\n",
      " [0.60553479]\n",
      " [0.6150254 ]] | y: 0.6741573033707864 | Predicción actual: [[0.62258685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008126603439450264, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56759089]\n",
      " [0.57523203]\n",
      " [0.58467191]\n",
      " [0.5951044 ]\n",
      " [0.60553479]\n",
      " [0.6150254 ]\n",
      " [0.62258685]] | y: 0.698566447113522 | Predicción actual: [[0.6276155]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021014900878071785, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56759089]\n",
      " [0.57523203]\n",
      " [0.58467191]\n",
      " [0.5951044 ]\n",
      " [0.60553479]\n",
      " [0.6150254 ]\n",
      " [0.62258685]\n",
      " [0.62761551]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007877875119447708, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57523203]\n",
      " [0.58467191]\n",
      " [0.5951044 ]\n",
      " [0.60553479]\n",
      " [0.6150254 ]\n",
      " [0.62258685]\n",
      " [0.62761551]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.60953534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01516471616923809, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58467191]\n",
      " [0.5951044 ]\n",
      " [0.60553479]\n",
      " [0.6150254 ]\n",
      " [0.62258685]\n",
      " [0.62761551]\n",
      " [0.72103836]\n",
      " [0.60953534]] | y: 0.7562960092987214 | Predicción actual: [[0.61897635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00534020783379674, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5951044 ]\n",
      " [0.60553479]\n",
      " [0.6150254 ]\n",
      " [0.62258685]\n",
      " [0.62761551]\n",
      " [0.72103836]\n",
      " [0.60953534]\n",
      " [0.61897635]] | y: 0.8275862068965516 | Predicción actual: [[0.6285566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019760223105549812, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60553479]\n",
      " [0.6150254 ]\n",
      " [0.62258685]\n",
      " [0.62761551]\n",
      " [0.72103836]\n",
      " [0.60953534]\n",
      " [0.61897635]\n",
      " [0.62855661]] | y: 0.8388221619527314 | Predicción actual: [[0.6376557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08421260863542557, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6150254 ]\n",
      " [0.62258685]\n",
      " [0.62761551]\n",
      " [0.72103836]\n",
      " [0.60953534]\n",
      " [0.61897635]\n",
      " [0.62855661]\n",
      " [0.63765568]] | y: 0.7942657884540876 | Predicción actual: [[0.64585507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020965177565813065, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62258685]\n",
      " [0.62761551]\n",
      " [0.72103836]\n",
      " [0.60953534]\n",
      " [0.61897635]\n",
      " [0.62855661]\n",
      " [0.63765568]\n",
      " [0.64585507]] | y: 0.7838047268500579 | Predicción actual: [[0.6527872]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025530684739351273, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62761551]\n",
      " [0.72103836]\n",
      " [0.60953534]\n",
      " [0.61897635]\n",
      " [0.62855661]\n",
      " [0.63765568]\n",
      " [0.64585507]\n",
      " [0.65278721]] | y: 0.7679194110809764 | Predicción actual: [[0.6585761]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012544624507427216, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.60953534]\n",
      " [0.61897635]\n",
      " [0.62855661]\n",
      " [0.63765568]\n",
      " [0.64585507]\n",
      " [0.65278721]\n",
      " [0.65857607]] | y: 0.7845796203022084 | Predicción actual: [[0.6635985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007062689401209354, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60953534]\n",
      " [0.61897635]\n",
      " [0.62855661]\n",
      " [0.63765568]\n",
      " [0.64585507]\n",
      " [0.65278721]\n",
      " [0.65857607]\n",
      " [0.66359848]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03748737648129463, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61897635]\n",
      " [0.62855661]\n",
      " [0.63765568]\n",
      " [0.64585507]\n",
      " [0.65278721]\n",
      " [0.65857607]\n",
      " [0.66359848]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6538941]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032886069267988205, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62855661]\n",
      " [0.63765568]\n",
      " [0.64585507]\n",
      " [0.65278721]\n",
      " [0.65857607]\n",
      " [0.66359848]\n",
      " [0.87872917]\n",
      " [0.65389413]] | y: 0.8488957768306855 | Predicción actual: [[0.6648261]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02955806441605091, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63765568]\n",
      " [0.64585507]\n",
      " [0.65278721]\n",
      " [0.65857607]\n",
      " [0.66359848]\n",
      " [0.87872917]\n",
      " [0.65389413]\n",
      " [0.6648261 ]] | y: 0.8182874854707476 | Predicción actual: [[0.676891]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0474216602742672, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64585507]\n",
      " [0.65278721]\n",
      " [0.65857607]\n",
      " [0.66359848]\n",
      " [0.87872917]\n",
      " [0.65389413]\n",
      " [0.6648261 ]\n",
      " [0.67689103]] | y: 0.8268113134444013 | Predicción actual: [[0.6897878]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018439343199133873, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65278721]\n",
      " [0.65857607]\n",
      " [0.66359848]\n",
      " [0.87872917]\n",
      " [0.65389413]\n",
      " [0.6648261 ]\n",
      " [0.67689103]\n",
      " [0.68978781]] | y: 0.7853545137543589 | Predicción actual: [[0.7031126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02648971788585186, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65857607]\n",
      " [0.66359848]\n",
      " [0.87872917]\n",
      " [0.65389413]\n",
      " [0.6648261 ]\n",
      " [0.67689103]\n",
      " [0.68978781]\n",
      " [0.7031126 ]] | y: 0.7892289810151103 | Predicción actual: [[0.7166453]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005689519457519054, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66359848]\n",
      " [0.87872917]\n",
      " [0.65389413]\n",
      " [0.6648261 ]\n",
      " [0.67689103]\n",
      " [0.68978781]\n",
      " [0.7031126 ]\n",
      " [0.7166453 ]] | y: 0.8341728012398295 | Predicción actual: [[0.730118]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027615169528871775, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.65389413]\n",
      " [0.6648261 ]\n",
      " [0.67689103]\n",
      " [0.68978781]\n",
      " [0.7031126 ]\n",
      " [0.7166453 ]\n",
      " [0.73011798]] | y: 0.8124757845796202 | Predicción actual: [[0.7433632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006220899522304535, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65389413]\n",
      " [0.6648261 ]\n",
      " [0.67689103]\n",
      " [0.68978781]\n",
      " [0.7031126 ]\n",
      " [0.7166453 ]\n",
      " [0.73011798]\n",
      " [0.7433632 ]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005301772616803646, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6648261 ]\n",
      " [0.67689103]\n",
      " [0.68978781]\n",
      " [0.7031126 ]\n",
      " [0.7166453 ]\n",
      " [0.73011798]\n",
      " [0.7433632 ]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7105434]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028577089309692383, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67689103]\n",
      " [0.68978781]\n",
      " [0.7031126 ]\n",
      " [0.7166453 ]\n",
      " [0.73011798]\n",
      " [0.7433632 ]\n",
      " [0.80123983]\n",
      " [0.71054339]] | y: 0.793490895001937 | Predicción actual: [[0.7234871]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013159209629520774, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68978781]\n",
      " [0.7031126 ]\n",
      " [0.7166453 ]\n",
      " [0.73011798]\n",
      " [0.7433632 ]\n",
      " [0.80123983]\n",
      " [0.71054339]\n",
      " [0.72348708]] | y: 0.760170476559473 | Predicción actual: [[0.73626536]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015160445123910904, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7031126 ]\n",
      " [0.7166453 ]\n",
      " [0.73011798]\n",
      " [0.7433632 ]\n",
      " [0.80123983]\n",
      " [0.71054339]\n",
      " [0.72348708]\n",
      " [0.73626536]] | y: 0.7353738860906625 | Predicción actual: [[0.74818945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020641418173909187, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7166453 ]\n",
      " [0.73011798]\n",
      " [0.7433632 ]\n",
      " [0.80123983]\n",
      " [0.71054339]\n",
      " [0.72348708]\n",
      " [0.73626536]\n",
      " [0.74818945]] | y: 0.7101898488957767 | Predicción actual: [[0.7580988]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008988677524030209, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73011798]\n",
      " [0.7433632 ]\n",
      " [0.80123983]\n",
      " [0.71054339]\n",
      " [0.72348708]\n",
      " [0.73626536]\n",
      " [0.74818945]\n",
      " [0.75809878]] | y: 0.7121270825261525 | Predicción actual: [[0.7654785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03626816347241402, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7433632 ]\n",
      " [0.80123983]\n",
      " [0.71054339]\n",
      " [0.72348708]\n",
      " [0.73626536]\n",
      " [0.74818945]\n",
      " [0.75809878]\n",
      " [0.76547849]] | y: 0.7396358000774894 | Predicción actual: [[0.7696861]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013018247671425343, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.71054339]\n",
      " [0.72348708]\n",
      " [0.73626536]\n",
      " [0.74818945]\n",
      " [0.75809878]\n",
      " [0.76547849]\n",
      " [0.7696861 ]] | y: 0.7361487795428128 | Predicción actual: [[0.7706206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017772387713193893, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71054339]\n",
      " [0.72348708]\n",
      " [0.73626536]\n",
      " [0.74818945]\n",
      " [0.75809878]\n",
      " [0.76547849]\n",
      " [0.7696861 ]\n",
      " [0.77062058]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006318120751529932, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72348708]\n",
      " [0.73626536]\n",
      " [0.74818945]\n",
      " [0.75809878]\n",
      " [0.76547849]\n",
      " [0.7696861 ]\n",
      " [0.77062058]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.7643618]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006191392429172993, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73626536]\n",
      " [0.74818945]\n",
      " [0.75809878]\n",
      " [0.76547849]\n",
      " [0.7696861 ]\n",
      " [0.77062058]\n",
      " [0.66757071]\n",
      " [0.7643618 ]] | y: 0.696629213483146 | Predicción actual: [[0.77092606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036329340655356646, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74818945]\n",
      " [0.75809878]\n",
      " [0.76547849]\n",
      " [0.7696861 ]\n",
      " [0.77062058]\n",
      " [0.66757071]\n",
      " [0.7643618 ]\n",
      " [0.77092606]] | y: 0.6559473072452537 | Predicción actual: [[0.77467984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00037118600448593497, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75809878]\n",
      " [0.76547849]\n",
      " [0.7696861 ]\n",
      " [0.77062058]\n",
      " [0.66757071]\n",
      " [0.7643618 ]\n",
      " [0.77092606]\n",
      " [0.77467984]] | y: 0.6788066640836885 | Predicción actual: [[0.7755175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015380172058939934, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76547849]\n",
      " [0.7696861 ]\n",
      " [0.77062058]\n",
      " [0.66757071]\n",
      " [0.7643618 ]\n",
      " [0.77092606]\n",
      " [0.77467984]\n",
      " [0.77551752]] | y: 0.6760945370011622 | Predicción actual: [[0.7736018]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06393411755561829, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7696861 ]\n",
      " [0.77062058]\n",
      " [0.66757071]\n",
      " [0.7643618 ]\n",
      " [0.77092606]\n",
      " [0.77467984]\n",
      " [0.77551752]\n",
      " [0.77360177]] | y: 0.7295621851995349 | Predicción actual: [[0.7693498]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012068237992934883, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77062058]\n",
      " [0.66757071]\n",
      " [0.7643618 ]\n",
      " [0.77092606]\n",
      " [0.77467984]\n",
      " [0.77551752]\n",
      " [0.77360177]\n",
      " [0.76934981]] | y: 0.7012785741960481 | Predicción actual: [[0.7642531]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007144642877392471, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.7643618 ]\n",
      " [0.77092606]\n",
      " [0.77467984]\n",
      " [0.77551752]\n",
      " [0.77360177]\n",
      " [0.76934981]\n",
      " [0.76425308]] | y: 0.767531964354901 | Predicción actual: [[0.7593708]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003998670727014542, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7643618 ]\n",
      " [0.77092606]\n",
      " [0.77467984]\n",
      " [0.77551752]\n",
      " [0.77360177]\n",
      " [0.76934981]\n",
      " [0.76425308]\n",
      " [0.7593708 ]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014382497407495975, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77092606]\n",
      " [0.77467984]\n",
      " [0.77551752]\n",
      " [0.77360177]\n",
      " [0.76934981]\n",
      " [0.76425308]\n",
      " [0.7593708 ]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.7852346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008841017261147499, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77467984]\n",
      " [0.77551752]\n",
      " [0.77360177]\n",
      " [0.76934981]\n",
      " [0.76425308]\n",
      " [0.7593708 ]\n",
      " [0.75513367]\n",
      " [0.78523457]] | y: 0.7520340953118947 | Predicción actual: [[0.78441393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007795046083629131, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77551752]\n",
      " [0.77360177]\n",
      " [0.76934981]\n",
      " [0.76425308]\n",
      " [0.7593708 ]\n",
      " [0.75513367]\n",
      " [0.78523457]\n",
      " [0.78441393]] | y: 0.7098024021697016 | Predicción actual: [[0.7825932]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00963609293103218, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77360177]\n",
      " [0.76934981]\n",
      " [0.76425308]\n",
      " [0.7593708 ]\n",
      " [0.75513367]\n",
      " [0.78523457]\n",
      " [0.78441393]\n",
      " [0.78259319]] | y: 0.6904300658659435 | Predicción actual: [[0.7803395]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027766203857026994, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76934981]\n",
      " [0.76425308]\n",
      " [0.7593708 ]\n",
      " [0.75513367]\n",
      " [0.78523457]\n",
      " [0.78441393]\n",
      " [0.78259319]\n",
      " [0.78033948]] | y: 0.7543587756683454 | Predicción actual: [[0.7787527]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.486095738480799e-05, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76425308]\n",
      " [0.7593708 ]\n",
      " [0.75513367]\n",
      " [0.78523457]\n",
      " [0.78441393]\n",
      " [0.78259319]\n",
      " [0.78033948]\n",
      " [0.77875268]] | y: 0.7222006974041069 | Predicción actual: [[0.77874947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037366640754044056, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7593708 ]\n",
      " [0.75513367]\n",
      " [0.78523457]\n",
      " [0.78441393]\n",
      " [0.78259319]\n",
      " [0.78033948]\n",
      " [0.77875268]\n",
      " [0.77874947]] | y: 0.8485083301046106 | Predicción actual: [[0.78069127]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010248254053294659, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.78523457]\n",
      " [0.78441393]\n",
      " [0.78259319]\n",
      " [0.78033948]\n",
      " [0.77875268]\n",
      " [0.77874947]\n",
      " [0.78069127]] | y: 0.9054629988376597 | Predicción actual: [[0.7849715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016559092327952385, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78523457]\n",
      " [0.78441393]\n",
      " [0.78259319]\n",
      " [0.78033948]\n",
      " [0.77875268]\n",
      " [0.77874947]\n",
      " [0.78069127]\n",
      " [0.78497148]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001198601326905191, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78441393]\n",
      " [0.78259319]\n",
      " [0.78033948]\n",
      " [0.77875268]\n",
      " [0.77874947]\n",
      " [0.78069127]\n",
      " [0.78497148]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.7911236]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015109130181372166, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78259319]\n",
      " [0.78033948]\n",
      " [0.77875268]\n",
      " [0.77874947]\n",
      " [0.78069127]\n",
      " [0.78497148]\n",
      " [0.8822162 ]\n",
      " [0.79112363]] | y: 0.889577683068578 | Predicción actual: [[0.7919266]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019328829366713762, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78033948]\n",
      " [0.77875268]\n",
      " [0.77874947]\n",
      " [0.78069127]\n",
      " [0.78497148]\n",
      " [0.8822162 ]\n",
      " [0.79112363]\n",
      " [0.79192662]] | y: 0.8748547074777218 | Predicción actual: [[0.7943308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013063034974038601, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77875268]\n",
      " [0.77874947]\n",
      " [0.78069127]\n",
      " [0.78497148]\n",
      " [0.8822162 ]\n",
      " [0.79112363]\n",
      " [0.79192662]\n",
      " [0.79433078]] | y: 0.9132119333591631 | Predicción actual: [[0.7986807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08480732142925262, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77874947]\n",
      " [0.78069127]\n",
      " [0.78497148]\n",
      " [0.8822162 ]\n",
      " [0.79112363]\n",
      " [0.79192662]\n",
      " [0.79433078]\n",
      " [0.79868072]] | y: 1.0 | Predicción actual: [[0.80499476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09714915603399277, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78069127]\n",
      " [0.78497148]\n",
      " [0.8822162 ]\n",
      " [0.79112363]\n",
      " [0.79192662]\n",
      " [0.79433078]\n",
      " [0.79868072]\n",
      " [0.80499476]] | y: 0.9705540488182873 | Predicción actual: [[0.8127984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021087180823087692, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78497148]\n",
      " [0.8822162 ]\n",
      " [0.79112363]\n",
      " [0.79192662]\n",
      " [0.79433078]\n",
      " [0.79868072]\n",
      " [0.80499476]\n",
      " [0.81279838]] | y: 0.8888027896164277 | Predicción actual: [[0.8211521]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0148086529225111, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.79112363]\n",
      " [0.79192662]\n",
      " [0.79433078]\n",
      " [0.79868072]\n",
      " [0.80499476]\n",
      " [0.81279838]\n",
      " [0.82115209]] | y: 0.877954281286323 | Predicción actual: [[0.8291359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003006232436746359, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79112363]\n",
      " [0.79192662]\n",
      " [0.79433078]\n",
      " [0.79868072]\n",
      " [0.80499476]\n",
      " [0.81279838]\n",
      " [0.82115209]\n",
      " [0.82913589]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039841651916503906, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79192662]\n",
      " [0.79433078]\n",
      " [0.79868072]\n",
      " [0.80499476]\n",
      " [0.81279838]\n",
      " [0.82115209]\n",
      " [0.82913589]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8143534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006358133163303137, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79433078]\n",
      " [0.79868072]\n",
      " [0.80499476]\n",
      " [0.81279838]\n",
      " [0.82115209]\n",
      " [0.82913589]\n",
      " [0.84889578]\n",
      " [0.81435341]] | y: 0.8550949244478885 | Predicción actual: [[0.8201082]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014151345007121563, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79868072]\n",
      " [0.80499476]\n",
      " [0.81279838]\n",
      " [0.82115209]\n",
      " [0.82913589]\n",
      " [0.84889578]\n",
      " [0.81435341]\n",
      " [0.82010818]] | y: 0.8752421542037967 | Predicción actual: [[0.82679677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007366180419921875, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80499476]\n",
      " [0.81279838]\n",
      " [0.82115209]\n",
      " [0.82913589]\n",
      " [0.84889578]\n",
      " [0.81435341]\n",
      " [0.82010818]\n",
      " [0.82679677]] | y: 0.857032158078264 | Predicción actual: [[0.83370435]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031439485028386116, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81279838]\n",
      " [0.82115209]\n",
      " [0.82913589]\n",
      " [0.84889578]\n",
      " [0.81435341]\n",
      " [0.82010818]\n",
      " [0.82679677]\n",
      " [0.83370435]] | y: 0.8500581170089112 | Predicción actual: [[0.8397898]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.458688610815443e-05, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82115209]\n",
      " [0.82913589]\n",
      " [0.84889578]\n",
      " [0.81435341]\n",
      " [0.82010818]\n",
      " [0.82679677]\n",
      " [0.83370435]\n",
      " [0.83978981]] | y: 0.8426966292134832 | Predicción actual: [[0.8445245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00024960419978015125, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82913589]\n",
      " [0.84889578]\n",
      " [0.81435341]\n",
      " [0.82010818]\n",
      " [0.82679677]\n",
      " [0.83370435]\n",
      " [0.83978981]\n",
      " [0.8445245 ]] | y: 0.8229368461836497 | Predicción actual: [[0.8474675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005484445486217737, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.81435341]\n",
      " [0.82010818]\n",
      " [0.82679677]\n",
      " [0.83370435]\n",
      " [0.83978981]\n",
      " [0.8445245 ]\n",
      " [0.84746748]] | y: 0.7745060054242543 | Predicción actual: [[0.84843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03026852197945118, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81435341]\n",
      " [0.82010818]\n",
      " [0.82679677]\n",
      " [0.83370435]\n",
      " [0.83978981]\n",
      " [0.8445245 ]\n",
      " [0.84746748]\n",
      " [0.84842998]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008311405777931213, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82010818]\n",
      " [0.82679677]\n",
      " [0.83370435]\n",
      " [0.83978981]\n",
      " [0.8445245 ]\n",
      " [0.84746748]\n",
      " [0.84842998]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.84851354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007818101905286312, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82679677]\n",
      " [0.83370435]\n",
      " [0.83978981]\n",
      " [0.8445245 ]\n",
      " [0.84746748]\n",
      " [0.84842998]\n",
      " [0.78419217]\n",
      " [0.84851354]] | y: 0.854320030995738 | Predicción actual: [[0.8526599]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013002460822463036, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83370435]\n",
      " [0.83978981]\n",
      " [0.8445245 ]\n",
      " [0.84746748]\n",
      " [0.84842998]\n",
      " [0.78419217]\n",
      " [0.84851354]\n",
      " [0.85265988]] | y: 0.8368849283223556 | Predicción actual: [[0.85562193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011936202645301819, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83978981]\n",
      " [0.8445245 ]\n",
      " [0.84746748]\n",
      " [0.84842998]\n",
      " [0.78419217]\n",
      " [0.84851354]\n",
      " [0.85265988]\n",
      " [0.85562193]] | y: 0.8299108872530028 | Predicción actual: [[0.85692114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013952309265732765, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8445245 ]\n",
      " [0.84746748]\n",
      " [0.84842998]\n",
      " [0.78419217]\n",
      " [0.84851354]\n",
      " [0.85265988]\n",
      " [0.85562193]\n",
      " [0.85692114]] | y: 0.887253002712127 | Predicción actual: [[0.8569292]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014755142852663994, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84746748]\n",
      " [0.84842998]\n",
      " [0.78419217]\n",
      " [0.84851354]\n",
      " [0.85265988]\n",
      " [0.85562193]\n",
      " [0.85692114]\n",
      " [0.85692918]] | y: 0.8597442851607902 | Predicción actual: [[0.8555527]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024689538404345512, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84842998]\n",
      " [0.78419217]\n",
      " [0.84851354]\n",
      " [0.85265988]\n",
      " [0.85562193]\n",
      " [0.85692114]\n",
      " [0.85692918]\n",
      " [0.85555267]] | y: 0.8395970554048819 | Predicción actual: [[0.85336685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000151349013322033, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.84851354]\n",
      " [0.85265988]\n",
      " [0.85562193]\n",
      " [0.85692114]\n",
      " [0.85692918]\n",
      " [0.85555267]\n",
      " [0.85336685]] | y: 0.7838047268500579 | Predicción actual: [[0.8515347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00631288206204772, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84851354]\n",
      " [0.85265988]\n",
      " [0.85562193]\n",
      " [0.85692114]\n",
      " [0.85692918]\n",
      " [0.85555267]\n",
      " [0.85336685]\n",
      " [0.85153472]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006374407093971968, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85265988]\n",
      " [0.85562193]\n",
      " [0.85692114]\n",
      " [0.85692918]\n",
      " [0.85555267]\n",
      " [0.85336685]\n",
      " [0.85153472]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.86993945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.463370714802295e-05, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85562193]\n",
      " [0.85692114]\n",
      " [0.85692918]\n",
      " [0.85555267]\n",
      " [0.85336685]\n",
      " [0.85153472]\n",
      " [0.81828749]\n",
      " [0.86993945]] | y: 0.7605579232855482 | Predicción actual: [[0.86967534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01999695412814617, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85692114]\n",
      " [0.85692918]\n",
      " [0.85555267]\n",
      " [0.85336685]\n",
      " [0.85153472]\n",
      " [0.81828749]\n",
      " [0.86993945]\n",
      " [0.86967534]] | y: 0.7915536613715615 | Predicción actual: [[0.86818814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012855703942477703, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85692918]\n",
      " [0.85555267]\n",
      " [0.85336685]\n",
      " [0.85153472]\n",
      " [0.81828749]\n",
      " [0.86993945]\n",
      " [0.86967534]\n",
      " [0.86818814]] | y: 0.7686943045331267 | Predicción actual: [[0.8661146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01926678791642189, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85555267]\n",
      " [0.85336685]\n",
      " [0.85153472]\n",
      " [0.81828749]\n",
      " [0.86993945]\n",
      " [0.86967534]\n",
      " [0.86818814]\n",
      " [0.86611462]] | y: 0.7686943045331267 | Predicción actual: [[0.8639505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013009612448513508, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85336685]\n",
      " [0.85153472]\n",
      " [0.81828749]\n",
      " [0.86993945]\n",
      " [0.86967534]\n",
      " [0.86818814]\n",
      " [0.86611462]\n",
      " [0.86395049]] | y: 0.7989151491669895 | Predicción actual: [[0.8623743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012297048233449459, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85153472]\n",
      " [0.81828749]\n",
      " [0.86993945]\n",
      " [0.86967534]\n",
      " [0.86818814]\n",
      " [0.86611462]\n",
      " [0.86395049]\n",
      " [0.86237431]] | y: 0.7900038744672608 | Predicción actual: [[0.86182463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013918282464146614, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.86993945]\n",
      " [0.86967534]\n",
      " [0.86818814]\n",
      " [0.86611462]\n",
      " [0.86395049]\n",
      " [0.86237431]\n",
      " [0.86182463]] | y: 0.760170476559473 | Predicción actual: [[0.862339]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043047115206718445, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86993945]\n",
      " [0.86967534]\n",
      " [0.86818814]\n",
      " [0.86611462]\n",
      " [0.86395049]\n",
      " [0.86237431]\n",
      " [0.86182463]\n",
      " [0.86233902]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06226951256394386, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86967534]\n",
      " [0.86818814]\n",
      " [0.86611462]\n",
      " [0.86395049]\n",
      " [0.86237431]\n",
      " [0.86182463]\n",
      " [0.86233902]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8683989]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09484386444091797, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86818814]\n",
      " [0.86611462]\n",
      " [0.86395049]\n",
      " [0.86237431]\n",
      " [0.86182463]\n",
      " [0.86233902]\n",
      " [0.68539326]\n",
      " [0.8683989 ]] | y: 0.6648585819449826 | Predicción actual: [[0.8617514]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024159453809261322, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86611462]\n",
      " [0.86395049]\n",
      " [0.86237431]\n",
      " [0.86182463]\n",
      " [0.86233902]\n",
      " [0.68539326]\n",
      " [0.8683989 ]\n",
      " [0.86175138]] | y: 0.7078651685393258 | Predicción actual: [[0.85355914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06285583972930908, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86395049]\n",
      " [0.86237431]\n",
      " [0.86182463]\n",
      " [0.86233902]\n",
      " [0.68539326]\n",
      " [0.8683989 ]\n",
      " [0.86175138]\n",
      " [0.85355914]] | y: 0.6648585819449826 | Predicción actual: [[0.843934]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018823486752808094, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86237431]\n",
      " [0.86182463]\n",
      " [0.86233902]\n",
      " [0.68539326]\n",
      " [0.8683989 ]\n",
      " [0.86175138]\n",
      " [0.85355914]\n",
      " [0.843934  ]] | y: 0.7113521890740022 | Predicción actual: [[0.83373606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018061300506815314, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86182463]\n",
      " [0.86233902]\n",
      " [0.68539326]\n",
      " [0.8683989 ]\n",
      " [0.86175138]\n",
      " [0.85355914]\n",
      " [0.843934  ]\n",
      " [0.83373606]] | y: 0.6772568771793879 | Predicción actual: [[0.8231575]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012575406581163406, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86233902]\n",
      " [0.68539326]\n",
      " [0.8683989 ]\n",
      " [0.86175138]\n",
      " [0.85355914]\n",
      " [0.843934  ]\n",
      " [0.83373606]\n",
      " [0.82315749]] | y: 0.7621077101898488 | Predicción actual: [[0.81210715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03128788620233536, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.8683989 ]\n",
      " [0.86175138]\n",
      " [0.85355914]\n",
      " [0.843934  ]\n",
      " [0.83373606]\n",
      " [0.82315749]\n",
      " [0.81210715]] | y: 0.8070515304145678 | Predicción actual: [[0.8003698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014141774736344814, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8683989 ]\n",
      " [0.86175138]\n",
      " [0.85355914]\n",
      " [0.843934  ]\n",
      " [0.83373606]\n",
      " [0.82315749]\n",
      " [0.81210715]\n",
      " [0.8003698 ]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013306916691362858, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86175138]\n",
      " [0.85355914]\n",
      " [0.843934  ]\n",
      " [0.83373606]\n",
      " [0.82315749]\n",
      " [0.81210715]\n",
      " [0.8003698 ]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8272022]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002963977458421141, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85355914]\n",
      " [0.843934  ]\n",
      " [0.83373606]\n",
      " [0.82315749]\n",
      " [0.81210715]\n",
      " [0.8003698 ]\n",
      " [0.81518791]\n",
      " [0.8272022 ]] | y: 0.9597055404881829 | Predicción actual: [[0.8171214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02978186123073101, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.843934  ]\n",
      " [0.83373606]\n",
      " [0.82315749]\n",
      " [0.81210715]\n",
      " [0.8003698 ]\n",
      " [0.81518791]\n",
      " [0.8272022 ]\n",
      " [0.81712139]] | y: 0.9643549012010848 | Predicción actual: [[0.8079956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07159192860126495, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83373606]\n",
      " [0.82315749]\n",
      " [0.81210715]\n",
      " [0.8003698 ]\n",
      " [0.81518791]\n",
      " [0.8272022 ]\n",
      " [0.81712139]\n",
      " [0.80799562]] | y: 0.8880278961642774 | Predicción actual: [[0.8005936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04186834767460823, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82315749]\n",
      " [0.81210715]\n",
      " [0.8003698 ]\n",
      " [0.81518791]\n",
      " [0.8272022 ]\n",
      " [0.81712139]\n",
      " [0.80799562]\n",
      " [0.80059361]] | y: 0.8926772568771792 | Predicción actual: [[0.7952374]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.549828635295853e-05, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81210715]\n",
      " [0.8003698 ]\n",
      " [0.81518791]\n",
      " [0.8272022 ]\n",
      " [0.81712139]\n",
      " [0.80799562]\n",
      " [0.80059361]\n",
      " [0.79523742]] | y: 0.8752421542037967 | Predicción actual: [[0.79199255]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001339297741651535, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8003698 ]\n",
      " [0.81518791]\n",
      " [0.8272022 ]\n",
      " [0.81712139]\n",
      " [0.80799562]\n",
      " [0.80059361]\n",
      " [0.79523742]\n",
      " [0.79199255]] | y: 0.8508330104610615 | Predicción actual: [[0.79123604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010105064138770103, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.8272022 ]\n",
      " [0.81712139]\n",
      " [0.80799562]\n",
      " [0.80059361]\n",
      " [0.79523742]\n",
      " [0.79199255]\n",
      " [0.79123604]] | y: 0.8488957768306855 | Predicción actual: [[0.79338616]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0064704567193984985, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8272022 ]\n",
      " [0.81712139]\n",
      " [0.80799562]\n",
      " [0.80059361]\n",
      " [0.79523742]\n",
      " [0.79199255]\n",
      " [0.79123604]\n",
      " [0.79338616]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009023861959576607, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81712139]\n",
      " [0.80799562]\n",
      " [0.80059361]\n",
      " [0.79523742]\n",
      " [0.79199255]\n",
      " [0.79123604]\n",
      " [0.79338616]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7861269]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02393427863717079, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80799562]\n",
      " [0.80059361]\n",
      " [0.79523742]\n",
      " [0.79199255]\n",
      " [0.79123604]\n",
      " [0.79338616]\n",
      " [0.96241767]\n",
      " [0.78612691]] | y: 0.9407206509104997 | Predicción actual: [[0.78405124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0408041775226593, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80059361]\n",
      " [0.79523742]\n",
      " [0.79199255]\n",
      " [0.79123604]\n",
      " [0.79338616]\n",
      " [0.96241767]\n",
      " [0.78612691]\n",
      " [0.78405124]] | y: 0.9724912824486633 | Predicción actual: [[0.78525734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03874518349766731, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79523742]\n",
      " [0.79199255]\n",
      " [0.79123604]\n",
      " [0.79338616]\n",
      " [0.96241767]\n",
      " [0.78612691]\n",
      " [0.78405124]\n",
      " [0.78525734]] | y: 0.9969004261913985 | Predicción actual: [[0.78941476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022925958037376404, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79199255]\n",
      " [0.79123604]\n",
      " [0.79338616]\n",
      " [0.96241767]\n",
      " [0.78612691]\n",
      " [0.78405124]\n",
      " [0.78525734]\n",
      " [0.78941476]] | y: 0.951181712514529 | Predicción actual: [[0.7958118]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000265051843598485, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79123604]\n",
      " [0.79338616]\n",
      " [0.96241767]\n",
      " [0.78612691]\n",
      " [0.78405124]\n",
      " [0.78525734]\n",
      " [0.78941476]\n",
      " [0.79581177]] | y: 0.8957768306857805 | Predicción actual: [[0.80331904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003077323781326413, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79338616]\n",
      " [0.96241767]\n",
      " [0.78612691]\n",
      " [0.78405124]\n",
      " [0.78525734]\n",
      " [0.78941476]\n",
      " [0.79581177]\n",
      " [0.80331904]] | y: 0.8814413018209997 | Predicción actual: [[0.81100965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001005314290523529, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.78612691]\n",
      " [0.78405124]\n",
      " [0.78525734]\n",
      " [0.78941476]\n",
      " [0.79581177]\n",
      " [0.80331904]\n",
      " [0.81100965]] | y: 0.9170864006199149 | Predicción actual: [[0.8177624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023848524317145348, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78612691]\n",
      " [0.78405124]\n",
      " [0.78525734]\n",
      " [0.78941476]\n",
      " [0.79581177]\n",
      " [0.80331904]\n",
      " [0.81100965]\n",
      " [0.81776237]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025207826867699623, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78405124]\n",
      " [0.78525734]\n",
      " [0.78941476]\n",
      " [0.79581177]\n",
      " [0.80331904]\n",
      " [0.81100965]\n",
      " [0.81776237]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.78138566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05031146481633186, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78525734]\n",
      " [0.78941476]\n",
      " [0.79581177]\n",
      " [0.80331904]\n",
      " [0.81100965]\n",
      " [0.81776237]\n",
      " [0.91979853]\n",
      " [0.78138566]] | y: 0.9682293684618366 | Predicción actual: [[0.7879422]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012069272808730602, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78941476]\n",
      " [0.79581177]\n",
      " [0.80331904]\n",
      " [0.81100965]\n",
      " [0.81776237]\n",
      " [0.91979853]\n",
      " [0.78138566]\n",
      " [0.78794217]] | y: 0.9577683068578069 | Predicción actual: [[0.79602665]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04014279320836067, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.2345531]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03625998646020889, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2345531 ]] | y: 0.10422316931421921 | Predicción actual: [[0.22006112]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02288988046348095, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2345531 ]\n",
      " [0.22006112]] | y: 0.15420379697791559 | Predicción actual: [[0.22450049]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011083818040788174, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2345531 ]\n",
      " [0.22006112]\n",
      " [0.22450049]] | y: 0.1557535838822161 | Predicción actual: [[0.23643407]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007667463272809982, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2345531 ]\n",
      " [0.22006112]\n",
      " [0.22450049]\n",
      " [0.23643407]] | y: 0.12553273924835334 | Predicción actual: [[0.2502039]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01620231382548809, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2345531 ]\n",
      " [0.22006112]\n",
      " [0.22450049]\n",
      " [0.23643407]\n",
      " [0.25020391]] | y: 0.1456799690042619 | Predicción actual: [[0.2623863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010869752615690231, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.2345531 ]\n",
      " [0.22006112]\n",
      " [0.22450049]\n",
      " [0.23643407]\n",
      " [0.25020391]\n",
      " [0.26238629]] | y: 0.1464548624564122 | Predicción actual: [[0.28656474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02500706911087036, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.2345531 ]\n",
      " [0.22006112]\n",
      " [0.22450049]\n",
      " [0.23643407]\n",
      " [0.25020391]\n",
      " [0.26238629]\n",
      " [0.28656474]] | y: 0.1960480433940332 | Predicción actual: [[0.31667867]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017648253589868546, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2345531 ]\n",
      " [0.22006112]\n",
      " [0.22450049]\n",
      " [0.23643407]\n",
      " [0.25020391]\n",
      " [0.26238629]\n",
      " [0.28656474]\n",
      " [0.31667867]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02020367793738842, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22006112]\n",
      " [0.22450049]\n",
      " [0.23643407]\n",
      " [0.25020391]\n",
      " [0.26238629]\n",
      " [0.28656474]\n",
      " [0.31667867]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.35572532]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025710176676511765, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22450049]\n",
      " [0.23643407]\n",
      " [0.25020391]\n",
      " [0.26238629]\n",
      " [0.28656474]\n",
      " [0.31667867]\n",
      " [0.2305308 ]\n",
      " [0.35572532]] | y: 0.211933359163115 | Predicción actual: [[0.3628991]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040381841361522675, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23643407]\n",
      " [0.25020391]\n",
      " [0.26238629]\n",
      " [0.28656474]\n",
      " [0.31667867]\n",
      " [0.2305308 ]\n",
      " [0.35572532]\n",
      " [0.36289909]] | y: 0.2072839984502131 | Predicción actual: [[0.37182984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03905663266777992, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25020391]\n",
      " [0.26238629]\n",
      " [0.28656474]\n",
      " [0.31667867]\n",
      " [0.2305308 ]\n",
      " [0.35572532]\n",
      " [0.36289909]\n",
      " [0.37182984]] | y: 0.19294846958543205 | Predicción actual: [[0.3813902]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00926954485476017, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26238629]\n",
      " [0.28656474]\n",
      " [0.31667867]\n",
      " [0.2305308 ]\n",
      " [0.35572532]\n",
      " [0.36289909]\n",
      " [0.37182984]\n",
      " [0.38139021]] | y: 0.19682293684618352 | Predicción actual: [[0.39149225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032276447862386703, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28656474]\n",
      " [0.31667867]\n",
      " [0.2305308 ]\n",
      " [0.35572532]\n",
      " [0.36289909]\n",
      " [0.37182984]\n",
      " [0.38139021]\n",
      " [0.39149225]] | y: 0.21425803951956607 | Predicción actual: [[0.4026013]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05162421613931656, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31667867]\n",
      " [0.2305308 ]\n",
      " [0.35572532]\n",
      " [0.36289909]\n",
      " [0.37182984]\n",
      " [0.38139021]\n",
      " [0.39149225]\n",
      " [0.4026013 ]] | y: 0.18132506780317698 | Predicción actual: [[0.41207987]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025236446410417557, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.35572532]\n",
      " [0.36289909]\n",
      " [0.37182984]\n",
      " [0.38139021]\n",
      " [0.39149225]\n",
      " [0.4026013 ]\n",
      " [0.41207987]] | y: 0.17512592018597434 | Predicción actual: [[0.4183063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06477756053209305, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35572532]\n",
      " [0.36289909]\n",
      " [0.37182984]\n",
      " [0.38139021]\n",
      " [0.39149225]\n",
      " [0.4026013 ]\n",
      " [0.41207987]\n",
      " [0.41830629]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08493611216545105, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36289909]\n",
      " [0.37182984]\n",
      " [0.38139021]\n",
      " [0.39149225]\n",
      " [0.4026013 ]\n",
      " [0.41207987]\n",
      " [0.41830629]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.4519559]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09598776698112488, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37182984]\n",
      " [0.38139021]\n",
      " [0.39149225]\n",
      " [0.4026013 ]\n",
      " [0.41207987]\n",
      " [0.41830629]\n",
      " [0.14800465]\n",
      " [0.45195591]] | y: 0.19217357613328173 | Predicción actual: [[0.4547315]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0652838721871376, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38139021]\n",
      " [0.39149225]\n",
      " [0.4026013 ]\n",
      " [0.41207987]\n",
      " [0.41830629]\n",
      " [0.14800465]\n",
      " [0.45195591]\n",
      " [0.45473149]] | y: 0.1859744285160791 | Predicción actual: [[0.45551226]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11321880668401718, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39149225]\n",
      " [0.4026013 ]\n",
      " [0.41207987]\n",
      " [0.41830629]\n",
      " [0.14800465]\n",
      " [0.45195591]\n",
      " [0.45473149]\n",
      " [0.45551226]] | y: 0.26695079426578844 | Predicción actual: [[0.4543616]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09218274056911469, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4026013 ]\n",
      " [0.41207987]\n",
      " [0.41830629]\n",
      " [0.14800465]\n",
      " [0.45195591]\n",
      " [0.45473149]\n",
      " [0.45551226]\n",
      " [0.45436159]] | y: 0.2925222781867493 | Predicción actual: [[0.45159656]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009871868416666985, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41207987]\n",
      " [0.41830629]\n",
      " [0.14800465]\n",
      " [0.45195591]\n",
      " [0.45473149]\n",
      " [0.45551226]\n",
      " [0.45436159]\n",
      " [0.45159656]] | y: 0.3177063153816349 | Predicción actual: [[0.44760048]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01551203802227974, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41830629]\n",
      " [0.14800465]\n",
      " [0.45195591]\n",
      " [0.45473149]\n",
      " [0.45551226]\n",
      " [0.45436159]\n",
      " [0.45159656]\n",
      " [0.44760048]] | y: 0.31266950794265785 | Predicción actual: [[0.4430853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006000802852213383, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.45195591]\n",
      " [0.45473149]\n",
      " [0.45551226]\n",
      " [0.45436159]\n",
      " [0.45159656]\n",
      " [0.44760048]\n",
      " [0.44308531]] | y: 0.2890352576520729 | Predicción actual: [[0.4391002]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010140626691281796, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45195591]\n",
      " [0.45473149]\n",
      " [0.45551226]\n",
      " [0.45436159]\n",
      " [0.45159656]\n",
      " [0.44760048]\n",
      " [0.44308531]\n",
      " [0.43910021]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048319362103939056, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45473149]\n",
      " [0.45551226]\n",
      " [0.45436159]\n",
      " [0.45159656]\n",
      " [0.44760048]\n",
      " [0.44308531]\n",
      " [0.43910021]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.49817914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03026817925274372, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45551226]\n",
      " [0.45436159]\n",
      " [0.45159656]\n",
      " [0.44760048]\n",
      " [0.44308531]\n",
      " [0.43910021]\n",
      " [0.28283611]\n",
      " [0.49817914]] | y: 0.2758620689655173 | Predicción actual: [[0.49418512]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06574729830026627, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45436159]\n",
      " [0.45159656]\n",
      " [0.44760048]\n",
      " [0.44308531]\n",
      " [0.43910021]\n",
      " [0.28283611]\n",
      " [0.49817914]\n",
      " [0.49418512]] | y: 0.2746997287872917 | Predicción actual: [[0.48892844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054773882031440735, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45159656]\n",
      " [0.44760048]\n",
      " [0.44308531]\n",
      " [0.43910021]\n",
      " [0.28283611]\n",
      " [0.49817914]\n",
      " [0.49418512]\n",
      " [0.48892844]] | y: 0.275474622239442 | Predicción actual: [[0.48342568]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02683010883629322, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44760048]\n",
      " [0.44308531]\n",
      " [0.43910021]\n",
      " [0.28283611]\n",
      " [0.49817914]\n",
      " [0.49418512]\n",
      " [0.48892844]\n",
      " [0.48342568]] | y: 0.3347539713289423 | Predicción actual: [[0.47876662]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007162254303693771, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44308531]\n",
      " [0.43910021]\n",
      " [0.28283611]\n",
      " [0.49817914]\n",
      " [0.49418512]\n",
      " [0.48892844]\n",
      " [0.48342568]\n",
      " [0.47876662]] | y: 0.35567609453700116 | Predicción actual: [[0.4759165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015158338472247124, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43910021]\n",
      " [0.28283611]\n",
      " [0.49817914]\n",
      " [0.49418512]\n",
      " [0.48892844]\n",
      " [0.48342568]\n",
      " [0.47876662]\n",
      " [0.4759165 ]] | y: 0.3366912049593181 | Predicción actual: [[0.47549042]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0437653474509716, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.49817914]\n",
      " [0.49418512]\n",
      " [0.48892844]\n",
      " [0.48342568]\n",
      " [0.47876662]\n",
      " [0.4759165 ]\n",
      " [0.47549042]] | y: 0.3335916311507167 | Predicción actual: [[0.4776781]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03014511987566948, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49817914]\n",
      " [0.49418512]\n",
      " [0.48892844]\n",
      " [0.48342568]\n",
      " [0.47876662]\n",
      " [0.4759165 ]\n",
      " [0.47549042]\n",
      " [0.47767809]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029539592564105988, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49418512]\n",
      " [0.48892844]\n",
      " [0.48342568]\n",
      " [0.47876662]\n",
      " [0.4759165 ]\n",
      " [0.47549042]\n",
      " [0.47767809]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.51383466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004369824018795043, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48892844]\n",
      " [0.48342568]\n",
      " [0.47876662]\n",
      " [0.4759165 ]\n",
      " [0.47549042]\n",
      " [0.47767809]\n",
      " [0.3847346 ]\n",
      " [0.51383466]] | y: 0.5962805114296785 | Predicción actual: [[0.5088971]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.323025106918067e-05, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48342568]\n",
      " [0.47876662]\n",
      " [0.4759165 ]\n",
      " [0.47549042]\n",
      " [0.47767809]\n",
      " [0.3847346 ]\n",
      " [0.51383466]\n",
      " [0.50889713]] | y: 0.574583494769469 | Predicción actual: [[0.5044692]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006822040770202875, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47876662]\n",
      " [0.4759165 ]\n",
      " [0.47549042]\n",
      " [0.47767809]\n",
      " [0.3847346 ]\n",
      " [0.51383466]\n",
      " [0.50889713]\n",
      " [0.50446922]] | y: 0.6063541263076326 | Predicción actual: [[0.5011562]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02170184813439846, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4759165 ]\n",
      " [0.47549042]\n",
      " [0.47767809]\n",
      " [0.3847346 ]\n",
      " [0.51383466]\n",
      " [0.50889713]\n",
      " [0.50446922]\n",
      " [0.50115621]] | y: 0.5846571096474236 | Predicción actual: [[0.4993042]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020496018696576357, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47549042]\n",
      " [0.47767809]\n",
      " [0.3847346 ]\n",
      " [0.51383466]\n",
      " [0.50889713]\n",
      " [0.50446922]\n",
      " [0.50115621]\n",
      " [0.49930421]] | y: 0.5687717938783416 | Predicción actual: [[0.49885607]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0051836478523910046, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47767809]\n",
      " [0.3847346 ]\n",
      " [0.51383466]\n",
      " [0.50889713]\n",
      " [0.50446922]\n",
      " [0.50115621]\n",
      " [0.49930421]\n",
      " [0.49885607]] | y: 0.6427741185586981 | Predicción actual: [[0.49956015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013016805984079838, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.51383466]\n",
      " [0.50889713]\n",
      " [0.50446922]\n",
      " [0.50115621]\n",
      " [0.49930421]\n",
      " [0.49885607]\n",
      " [0.49956015]] | y: 0.6617590081363811 | Predicción actual: [[0.50098747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002506186021491885, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51383466]\n",
      " [0.50889713]\n",
      " [0.50446922]\n",
      " [0.50115621]\n",
      " [0.49930421]\n",
      " [0.49885607]\n",
      " [0.49956015]\n",
      " [0.50098747]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018457913771271706, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50889713]\n",
      " [0.50446922]\n",
      " [0.50115621]\n",
      " [0.49930421]\n",
      " [0.49885607]\n",
      " [0.49956015]\n",
      " [0.50098747]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.52403885]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006691871210932732, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50446922]\n",
      " [0.50115621]\n",
      " [0.49930421]\n",
      " [0.49885607]\n",
      " [0.49956015]\n",
      " [0.50098747]\n",
      " [0.67299496]\n",
      " [0.52403885]] | y: 0.703990701278574 | Predicción actual: [[0.5247466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028824545443058014, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50115621]\n",
      " [0.49930421]\n",
      " [0.49885607]\n",
      " [0.49956015]\n",
      " [0.50098747]\n",
      " [0.67299496]\n",
      " [0.52403885]\n",
      " [0.5247466 ]] | y: 0.7272375048430839 | Predicción actual: [[0.5280799]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07844458520412445, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49930421]\n",
      " [0.49885607]\n",
      " [0.49956015]\n",
      " [0.50098747]\n",
      " [0.67299496]\n",
      " [0.52403885]\n",
      " [0.5247466 ]\n",
      " [0.52807993]] | y: 0.722588144130182 | Predicción actual: [[0.5340259]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08297376334667206, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49885607]\n",
      " [0.49956015]\n",
      " [0.50098747]\n",
      " [0.67299496]\n",
      " [0.52403885]\n",
      " [0.5247466 ]\n",
      " [0.52807993]\n",
      " [0.53402591]] | y: 0.771793878341728 | Predicción actual: [[0.54225165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043481357395648956, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49956015]\n",
      " [0.50098747]\n",
      " [0.67299496]\n",
      " [0.52403885]\n",
      " [0.5247466 ]\n",
      " [0.52807993]\n",
      " [0.53402591]\n",
      " [0.54225165]] | y: 0.7245253777605578 | Predicción actual: [[0.5523072]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008909647352993488, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50098747]\n",
      " [0.67299496]\n",
      " [0.52403885]\n",
      " [0.5247466 ]\n",
      " [0.52807993]\n",
      " [0.53402591]\n",
      " [0.54225165]\n",
      " [0.55230719]] | y: 0.6710577295621851 | Predicción actual: [[0.56366897]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04671778902411461, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.52403885]\n",
      " [0.5247466 ]\n",
      " [0.52807993]\n",
      " [0.53402591]\n",
      " [0.54225165]\n",
      " [0.55230719]\n",
      " [0.56366897]] | y: 0.6737698566447115 | Predicción actual: [[0.57605517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002133727539330721, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52403885]\n",
      " [0.5247466 ]\n",
      " [0.52807993]\n",
      " [0.53402591]\n",
      " [0.54225165]\n",
      " [0.55230719]\n",
      " [0.56366897]\n",
      " [0.57605517]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045853257179260254, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5247466 ]\n",
      " [0.52807993]\n",
      " [0.53402591]\n",
      " [0.54225165]\n",
      " [0.55230719]\n",
      " [0.56366897]\n",
      " [0.57605517]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5526277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013341675512492657, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52807993]\n",
      " [0.53402591]\n",
      " [0.54225165]\n",
      " [0.55230719]\n",
      " [0.56366897]\n",
      " [0.57605517]\n",
      " [0.71445176]\n",
      " [0.55262768]] | y: 0.722588144130182 | Predicción actual: [[0.56047064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03598539158701897, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53402591]\n",
      " [0.54225165]\n",
      " [0.55230719]\n",
      " [0.56366897]\n",
      " [0.57605517]\n",
      " [0.71445176]\n",
      " [0.55262768]\n",
      " [0.56047064]] | y: 0.6993413405656723 | Predicción actual: [[0.5702499]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01238797977566719, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54225165]\n",
      " [0.55230719]\n",
      " [0.56366897]\n",
      " [0.57605517]\n",
      " [0.71445176]\n",
      " [0.55262768]\n",
      " [0.56047064]\n",
      " [0.57024992]] | y: 0.7373111197210385 | Predicción actual: [[0.58102566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011670241132378578, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55230719]\n",
      " [0.56366897]\n",
      " [0.57605517]\n",
      " [0.71445176]\n",
      " [0.55262768]\n",
      " [0.56047064]\n",
      " [0.57024992]\n",
      " [0.58102566]] | y: 0.7214258039519565 | Predicción actual: [[0.5917985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012579604052007198, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56366897]\n",
      " [0.57605517]\n",
      " [0.71445176]\n",
      " [0.55262768]\n",
      " [0.56047064]\n",
      " [0.57024992]\n",
      " [0.58102566]\n",
      " [0.59179848]] | y: 0.7187136768694304 | Predicción actual: [[0.60158426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004871593322604895, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57605517]\n",
      " [0.71445176]\n",
      " [0.55262768]\n",
      " [0.56047064]\n",
      " [0.57024992]\n",
      " [0.58102566]\n",
      " [0.59179848]\n",
      " [0.60158426]] | y: 0.6741573033707864 | Predicción actual: [[0.6094897]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009812789037823677, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55262768]\n",
      " [0.56047064]\n",
      " [0.57024992]\n",
      " [0.58102566]\n",
      " [0.59179848]\n",
      " [0.60158426]\n",
      " [0.60948968]] | y: 0.698566447113522 | Predicción actual: [[0.6148201]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017097245901823044, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55262768]\n",
      " [0.56047064]\n",
      " [0.57024992]\n",
      " [0.58102566]\n",
      " [0.59179848]\n",
      " [0.60158426]\n",
      " [0.60948968]\n",
      " [0.61482012]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02210741862654686, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56047064]\n",
      " [0.57024992]\n",
      " [0.58102566]\n",
      " [0.59179848]\n",
      " [0.60158426]\n",
      " [0.60948968]\n",
      " [0.61482012]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.5943538]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018398329615592957, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57024992]\n",
      " [0.58102566]\n",
      " [0.59179848]\n",
      " [0.60158426]\n",
      " [0.60948968]\n",
      " [0.61482012]\n",
      " [0.72103836]\n",
      " [0.5943538 ]] | y: 0.7562960092987214 | Predicción actual: [[0.6043472]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044691357761621475, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58102566]\n",
      " [0.59179848]\n",
      " [0.60158426]\n",
      " [0.60948968]\n",
      " [0.61482012]\n",
      " [0.72103836]\n",
      " [0.5943538 ]\n",
      " [0.60434723]] | y: 0.8275862068965516 | Predicción actual: [[0.6146412]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11146198958158493, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59179848]\n",
      " [0.60158426]\n",
      " [0.60948968]\n",
      " [0.61482012]\n",
      " [0.72103836]\n",
      " [0.5943538 ]\n",
      " [0.60434723]\n",
      " [0.61464119]] | y: 0.8388221619527314 | Predicción actual: [[0.6245791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08109956234693527, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60158426]\n",
      " [0.60948968]\n",
      " [0.61482012]\n",
      " [0.72103836]\n",
      " [0.5943538 ]\n",
      " [0.60434723]\n",
      " [0.61464119]\n",
      " [0.62457907]] | y: 0.7942657884540876 | Predicción actual: [[0.63358176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021490443497896194, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60948968]\n",
      " [0.61482012]\n",
      " [0.72103836]\n",
      " [0.5943538 ]\n",
      " [0.60434723]\n",
      " [0.61464119]\n",
      " [0.62457907]\n",
      " [0.63358176]] | y: 0.7838047268500579 | Predicción actual: [[0.6412637]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009502698667347431, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61482012]\n",
      " [0.72103836]\n",
      " [0.5943538 ]\n",
      " [0.60434723]\n",
      " [0.61464119]\n",
      " [0.62457907]\n",
      " [0.63358176]\n",
      " [0.64126372]] | y: 0.7679194110809764 | Predicción actual: [[0.6476479]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009727138094604015, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.5943538 ]\n",
      " [0.60434723]\n",
      " [0.61464119]\n",
      " [0.62457907]\n",
      " [0.63358176]\n",
      " [0.64126372]\n",
      " [0.64764792]] | y: 0.7845796203022084 | Predicción actual: [[0.6531494]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06335549056529999, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5943538 ]\n",
      " [0.60434723]\n",
      " [0.61464119]\n",
      " [0.62457907]\n",
      " [0.63358176]\n",
      " [0.64126372]\n",
      " [0.64764792]\n",
      " [0.65314943]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07566413283348083, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60434723]\n",
      " [0.61464119]\n",
      " [0.62457907]\n",
      " [0.63358176]\n",
      " [0.64126372]\n",
      " [0.64764792]\n",
      " [0.65314943]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6420346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05801832675933838, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61464119]\n",
      " [0.62457907]\n",
      " [0.63358176]\n",
      " [0.64126372]\n",
      " [0.64764792]\n",
      " [0.65314943]\n",
      " [0.87872917]\n",
      " [0.64203459]] | y: 0.8488957768306855 | Predicción actual: [[0.65421516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08000936359167099, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62457907]\n",
      " [0.63358176]\n",
      " [0.64126372]\n",
      " [0.64764792]\n",
      " [0.65314943]\n",
      " [0.87872917]\n",
      " [0.64203459]\n",
      " [0.65421516]] | y: 0.8182874854707476 | Predicción actual: [[0.66762006]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04244013875722885, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63358176]\n",
      " [0.64126372]\n",
      " [0.64764792]\n",
      " [0.65314943]\n",
      " [0.87872917]\n",
      " [0.64203459]\n",
      " [0.65421516]\n",
      " [0.66762006]] | y: 0.8268113134444013 | Predicción actual: [[0.6818152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06221017986536026, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64126372]\n",
      " [0.64764792]\n",
      " [0.65314943]\n",
      " [0.87872917]\n",
      " [0.64203459]\n",
      " [0.65421516]\n",
      " [0.66762006]\n",
      " [0.68181521]] | y: 0.7853545137543589 | Predicción actual: [[0.69647324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.787090877769515e-05, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64764792]\n",
      " [0.65314943]\n",
      " [0.87872917]\n",
      " [0.64203459]\n",
      " [0.65421516]\n",
      " [0.66762006]\n",
      " [0.68181521]\n",
      " [0.69647324]] | y: 0.7892289810151103 | Predicción actual: [[0.71107316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01960800774395466, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65314943]\n",
      " [0.87872917]\n",
      " [0.64203459]\n",
      " [0.65421516]\n",
      " [0.66762006]\n",
      " [0.68181521]\n",
      " [0.69647324]\n",
      " [0.71107316]] | y: 0.8341728012398295 | Predicción actual: [[0.72564596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002381636993959546, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.64203459]\n",
      " [0.65421516]\n",
      " [0.66762006]\n",
      " [0.68181521]\n",
      " [0.69647324]\n",
      " [0.71107316]\n",
      " [0.72564596]] | y: 0.8124757845796202 | Predicción actual: [[0.7399803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025128505658358335, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64203459]\n",
      " [0.65421516]\n",
      " [0.66762006]\n",
      " [0.68181521]\n",
      " [0.69647324]\n",
      " [0.71107316]\n",
      " [0.72564596]\n",
      " [0.73998028]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03349306806921959, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65421516]\n",
      " [0.66762006]\n",
      " [0.68181521]\n",
      " [0.69647324]\n",
      " [0.71107316]\n",
      " [0.72564596]\n",
      " [0.73998028]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7064936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005781300133094192, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66762006]\n",
      " [0.68181521]\n",
      " [0.69647324]\n",
      " [0.71107316]\n",
      " [0.72564596]\n",
      " [0.73998028]\n",
      " [0.80123983]\n",
      " [0.70649362]] | y: 0.793490895001937 | Predicción actual: [[0.72068864]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005874093156307936, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68181521]\n",
      " [0.69647324]\n",
      " [0.71107316]\n",
      " [0.72564596]\n",
      " [0.73998028]\n",
      " [0.80123983]\n",
      " [0.70649362]\n",
      " [0.72068864]] | y: 0.760170476559473 | Predicción actual: [[0.7347185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019431713968515396, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69647324]\n",
      " [0.71107316]\n",
      " [0.72564596]\n",
      " [0.73998028]\n",
      " [0.80123983]\n",
      " [0.70649362]\n",
      " [0.72068864]\n",
      " [0.7347185 ]] | y: 0.7353738860906625 | Predicción actual: [[0.7478186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012526939390227199, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71107316]\n",
      " [0.72564596]\n",
      " [0.73998028]\n",
      " [0.80123983]\n",
      " [0.70649362]\n",
      " [0.72068864]\n",
      " [0.7347185 ]\n",
      " [0.74781859]] | y: 0.7101898488957767 | Predicción actual: [[0.7590697]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005876816343516111, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72564596]\n",
      " [0.73998028]\n",
      " [0.80123983]\n",
      " [0.70649362]\n",
      " [0.72068864]\n",
      " [0.7347185 ]\n",
      " [0.74781859]\n",
      " [0.75906968]] | y: 0.7121270825261525 | Predicción actual: [[0.76769495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009677644819021225, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73998028]\n",
      " [0.80123983]\n",
      " [0.70649362]\n",
      " [0.72068864]\n",
      " [0.7347185 ]\n",
      " [0.74781859]\n",
      " [0.75906968]\n",
      " [0.76769495]] | y: 0.7396358000774894 | Predicción actual: [[0.77317256]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029567841440439224, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.70649362]\n",
      " [0.72068864]\n",
      " [0.7347185 ]\n",
      " [0.74781859]\n",
      " [0.75906968]\n",
      " [0.76769495]\n",
      " [0.77317256]] | y: 0.7361487795428128 | Predicción actual: [[0.7750577]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019424123456701636, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70649362]\n",
      " [0.72068864]\n",
      " [0.7347185 ]\n",
      " [0.74781859]\n",
      " [0.75906968]\n",
      " [0.76769495]\n",
      " [0.77317256]\n",
      " [0.77505767]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011879602447152138, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72068864]\n",
      " [0.7347185 ]\n",
      " [0.74781859]\n",
      " [0.75906968]\n",
      " [0.76769495]\n",
      " [0.77317256]\n",
      " [0.77505767]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.770512]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019106052350252867, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7347185 ]\n",
      " [0.74781859]\n",
      " [0.75906968]\n",
      " [0.76769495]\n",
      " [0.77317256]\n",
      " [0.77505767]\n",
      " [0.66757071]\n",
      " [0.77051198]] | y: 0.696629213483146 | Predicción actual: [[0.7786336]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029047727584838867, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74781859]\n",
      " [0.75906968]\n",
      " [0.76769495]\n",
      " [0.77317256]\n",
      " [0.77505767]\n",
      " [0.66757071]\n",
      " [0.77051198]\n",
      " [0.77863359]] | y: 0.6559473072452537 | Predicción actual: [[0.7835841]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0391642190515995, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75906968]\n",
      " [0.76769495]\n",
      " [0.77317256]\n",
      " [0.77505767]\n",
      " [0.66757071]\n",
      " [0.77051198]\n",
      " [0.77863359]\n",
      " [0.78358412]] | y: 0.6788066640836885 | Predicción actual: [[0.785176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007479371502995491, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76769495]\n",
      " [0.77317256]\n",
      " [0.77505767]\n",
      " [0.66757071]\n",
      " [0.77051198]\n",
      " [0.77863359]\n",
      " [0.78358412]\n",
      " [0.78517598]] | y: 0.6760945370011622 | Predicción actual: [[0.7839536]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01163916103541851, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77317256]\n",
      " [0.77505767]\n",
      " [0.66757071]\n",
      " [0.77051198]\n",
      " [0.77863359]\n",
      " [0.78358412]\n",
      " [0.78517598]\n",
      " [0.78395361]] | y: 0.7295621851995349 | Predicción actual: [[0.7805995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027543972828425467, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77505767]\n",
      " [0.66757071]\n",
      " [0.77051198]\n",
      " [0.77863359]\n",
      " [0.78358412]\n",
      " [0.78517598]\n",
      " [0.78395361]\n",
      " [0.78059947]] | y: 0.7012785741960481 | Predicción actual: [[0.7763258]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02114769071340561, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.77051198]\n",
      " [0.77863359]\n",
      " [0.78358412]\n",
      " [0.78517598]\n",
      " [0.78395361]\n",
      " [0.78059947]\n",
      " [0.77632582]] | y: 0.767531964354901 | Predicción actual: [[0.77205825]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004338627681136131, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77051198]\n",
      " [0.77863359]\n",
      " [0.78358412]\n",
      " [0.78517598]\n",
      " [0.78395361]\n",
      " [0.78059947]\n",
      " [0.77632582]\n",
      " [0.77205825]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020459876395761967, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77863359]\n",
      " [0.78358412]\n",
      " [0.78517598]\n",
      " [0.78395361]\n",
      " [0.78059947]\n",
      " [0.77632582]\n",
      " [0.77205825]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8015337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006153620779514313, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78358412]\n",
      " [0.78517598]\n",
      " [0.78395361]\n",
      " [0.78059947]\n",
      " [0.77632582]\n",
      " [0.77205825]\n",
      " [0.75513367]\n",
      " [0.8015337 ]] | y: 0.7520340953118947 | Predicción actual: [[0.8012681]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016434459015727043, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78517598]\n",
      " [0.78395361]\n",
      " [0.78059947]\n",
      " [0.77632582]\n",
      " [0.77205825]\n",
      " [0.75513367]\n",
      " [0.8015337 ]\n",
      " [0.8012681 ]] | y: 0.7098024021697016 | Predicción actual: [[0.79940504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006269481964409351, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78395361]\n",
      " [0.78059947]\n",
      " [0.77632582]\n",
      " [0.77205825]\n",
      " [0.75513367]\n",
      " [0.8015337 ]\n",
      " [0.8012681 ]\n",
      " [0.79940504]] | y: 0.6904300658659435 | Predicción actual: [[0.7971011]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004273192957043648, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78059947]\n",
      " [0.77632582]\n",
      " [0.77205825]\n",
      " [0.75513367]\n",
      " [0.8015337 ]\n",
      " [0.8012681 ]\n",
      " [0.79940504]\n",
      " [0.79710108]] | y: 0.7543587756683454 | Predicción actual: [[0.795405]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006039747968316078, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77632582]\n",
      " [0.77205825]\n",
      " [0.75513367]\n",
      " [0.8015337 ]\n",
      " [0.8012681 ]\n",
      " [0.79940504]\n",
      " [0.79710108]\n",
      " [0.79540497]] | y: 0.7222006974041069 | Predicción actual: [[0.79516643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036378144286572933, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77205825]\n",
      " [0.75513367]\n",
      " [0.8015337 ]\n",
      " [0.8012681 ]\n",
      " [0.79940504]\n",
      " [0.79710108]\n",
      " [0.79540497]\n",
      " [0.79516643]] | y: 0.8485083301046106 | Predicción actual: [[0.79713416]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014544672332704067, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.8015337 ]\n",
      " [0.8012681 ]\n",
      " [0.79940504]\n",
      " [0.79710108]\n",
      " [0.79540497]\n",
      " [0.79516643]\n",
      " [0.79713416]] | y: 0.9054629988376597 | Predicción actual: [[0.80159765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006384443026036024, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8015337 ]\n",
      " [0.8012681 ]\n",
      " [0.79940504]\n",
      " [0.79710108]\n",
      " [0.79540497]\n",
      " [0.79516643]\n",
      " [0.79713416]\n",
      " [0.80159765]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007757748477160931, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8012681 ]\n",
      " [0.79940504]\n",
      " [0.79710108]\n",
      " [0.79540497]\n",
      " [0.79516643]\n",
      " [0.79713416]\n",
      " [0.80159765]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8108186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018036686815321445, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79940504]\n",
      " [0.79710108]\n",
      " [0.79540497]\n",
      " [0.79516643]\n",
      " [0.79713416]\n",
      " [0.80159765]\n",
      " [0.8822162 ]\n",
      " [0.81081861]] | y: 0.889577683068578 | Predicción actual: [[0.8106361]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010667149908840656, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79710108]\n",
      " [0.79540497]\n",
      " [0.79516643]\n",
      " [0.79713416]\n",
      " [0.80159765]\n",
      " [0.8822162 ]\n",
      " [0.81081861]\n",
      " [0.8106361 ]] | y: 0.8748547074777218 | Predicción actual: [[0.81200784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03164682537317276, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79540497]\n",
      " [0.79516643]\n",
      " [0.79713416]\n",
      " [0.80159765]\n",
      " [0.8822162 ]\n",
      " [0.81081861]\n",
      " [0.8106361 ]\n",
      " [0.81200784]] | y: 0.9132119333591631 | Predicción actual: [[0.8154083]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014055544510483742, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79516643]\n",
      " [0.79713416]\n",
      " [0.80159765]\n",
      " [0.8822162 ]\n",
      " [0.81081861]\n",
      " [0.8106361 ]\n",
      " [0.81200784]\n",
      " [0.81540829]] | y: 1.0 | Predicción actual: [[0.8206293]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03391575813293457, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79713416]\n",
      " [0.80159765]\n",
      " [0.8822162 ]\n",
      " [0.81081861]\n",
      " [0.8106361 ]\n",
      " [0.81200784]\n",
      " [0.81540829]\n",
      " [0.8206293 ]] | y: 0.9705540488182873 | Predicción actual: [[0.82732505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04753551259636879, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80159765]\n",
      " [0.8822162 ]\n",
      " [0.81081861]\n",
      " [0.8106361 ]\n",
      " [0.81200784]\n",
      " [0.81540829]\n",
      " [0.8206293 ]\n",
      " [0.82732505]] | y: 0.8888027896164277 | Predicción actual: [[0.8347453]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015163586474955082, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.81081861]\n",
      " [0.8106361 ]\n",
      " [0.81200784]\n",
      " [0.81540829]\n",
      " [0.8206293 ]\n",
      " [0.82732505]\n",
      " [0.83474529]] | y: 0.877954281286323 | Predicción actual: [[0.8418126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005224370863288641, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81081861]\n",
      " [0.8106361 ]\n",
      " [0.81200784]\n",
      " [0.81540829]\n",
      " [0.8206293 ]\n",
      " [0.82732505]\n",
      " [0.83474529]\n",
      " [0.84181261]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003251193091273308, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8106361 ]\n",
      " [0.81200784]\n",
      " [0.81540829]\n",
      " [0.8206293 ]\n",
      " [0.82732505]\n",
      " [0.83474529]\n",
      " [0.84181261]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8288896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011034494265913963, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81200784]\n",
      " [0.81540829]\n",
      " [0.8206293 ]\n",
      " [0.82732505]\n",
      " [0.83474529]\n",
      " [0.84181261]\n",
      " [0.84889578]\n",
      " [0.82888961]] | y: 0.8550949244478885 | Predicción actual: [[0.83318794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013586017303168774, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81540829]\n",
      " [0.8206293 ]\n",
      " [0.82732505]\n",
      " [0.83474529]\n",
      " [0.84181261]\n",
      " [0.84889578]\n",
      " [0.82888961]\n",
      " [0.83318794]] | y: 0.8752421542037967 | Predicción actual: [[0.83827925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.207606641808525e-05, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8206293 ]\n",
      " [0.82732505]\n",
      " [0.83474529]\n",
      " [0.84181261]\n",
      " [0.84889578]\n",
      " [0.82888961]\n",
      " [0.83318794]\n",
      " [0.83827925]] | y: 0.857032158078264 | Predicción actual: [[0.8434522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024718758650124073, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82732505]\n",
      " [0.83474529]\n",
      " [0.84181261]\n",
      " [0.84889578]\n",
      " [0.82888961]\n",
      " [0.83318794]\n",
      " [0.83827925]\n",
      " [0.84345222]] | y: 0.8500581170089112 | Predicción actual: [[0.8481058]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04282958805561066, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83474529]\n",
      " [0.84181261]\n",
      " [0.84889578]\n",
      " [0.82888961]\n",
      " [0.83318794]\n",
      " [0.83827925]\n",
      " [0.84345222]\n",
      " [0.84810579]] | y: 0.8426966292134832 | Predicción actual: [[0.8518295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000743982323911041, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84181261]\n",
      " [0.84889578]\n",
      " [0.82888961]\n",
      " [0.83318794]\n",
      " [0.83827925]\n",
      " [0.84345222]\n",
      " [0.84810579]\n",
      " [0.85182953]] | y: 0.8229368461836497 | Predicción actual: [[0.8539259]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008081352571025491, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.82888961]\n",
      " [0.83318794]\n",
      " [0.83827925]\n",
      " [0.84345222]\n",
      " [0.84810579]\n",
      " [0.85182953]\n",
      " [0.85392588]] | y: 0.7745060054242543 | Predicción actual: [[0.8542335]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012096833670511842, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82888961]\n",
      " [0.83318794]\n",
      " [0.83827925]\n",
      " [0.84345222]\n",
      " [0.84810579]\n",
      " [0.85182953]\n",
      " [0.85392588]\n",
      " [0.8542335 ]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011675340356305242, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83318794]\n",
      " [0.83827925]\n",
      " [0.84345222]\n",
      " [0.84810579]\n",
      " [0.85182953]\n",
      " [0.85392588]\n",
      " [0.8542335 ]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8568225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004791922983713448, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83827925]\n",
      " [0.84345222]\n",
      " [0.84810579]\n",
      " [0.85182953]\n",
      " [0.85392588]\n",
      " [0.8542335 ]\n",
      " [0.78419217]\n",
      " [0.85682249]] | y: 0.854320030995738 | Predicción actual: [[0.8600597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011515768710523844, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84345222]\n",
      " [0.84810579]\n",
      " [0.85182953]\n",
      " [0.85392588]\n",
      " [0.8542335 ]\n",
      " [0.78419217]\n",
      " [0.85682249]\n",
      " [0.86005968]] | y: 0.8368849283223556 | Predicción actual: [[0.86208]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.465092726808507e-06, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84810579]\n",
      " [0.85182953]\n",
      " [0.85392588]\n",
      " [0.8542335 ]\n",
      " [0.78419217]\n",
      " [0.85682249]\n",
      " [0.86005968]\n",
      " [0.86207998]] | y: 0.8299108872530028 | Predicción actual: [[0.8626856]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007015421986579895, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85182953]\n",
      " [0.85392588]\n",
      " [0.8542335 ]\n",
      " [0.78419217]\n",
      " [0.85682249]\n",
      " [0.86005968]\n",
      " [0.86207998]\n",
      " [0.86268562]] | y: 0.887253002712127 | Predicción actual: [[0.8618537]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009048418141901493, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85392588]\n",
      " [0.8542335 ]\n",
      " [0.78419217]\n",
      " [0.85682249]\n",
      " [0.86005968]\n",
      " [0.86207998]\n",
      " [0.86268562]\n",
      " [0.86185372]] | y: 0.8597442851607902 | Predicción actual: [[0.8603239]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004092522896826267, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8542335 ]\n",
      " [0.78419217]\n",
      " [0.85682249]\n",
      " [0.86005968]\n",
      " [0.86207998]\n",
      " [0.86268562]\n",
      " [0.86185372]\n",
      " [0.86032391]] | y: 0.8395970554048819 | Predicción actual: [[0.8586408]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006194084882736206, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.85682249]\n",
      " [0.86005968]\n",
      " [0.86207998]\n",
      " [0.86268562]\n",
      " [0.86185372]\n",
      " [0.86032391]\n",
      " [0.85864079]] | y: 0.7838047268500579 | Predicción actual: [[0.8575273]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009994377614930272, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85682249]\n",
      " [0.86005968]\n",
      " [0.86207998]\n",
      " [0.86268562]\n",
      " [0.86185372]\n",
      " [0.86032391]\n",
      " [0.85864079]\n",
      " [0.85752732]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009172133170068264, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86005968]\n",
      " [0.86207998]\n",
      " [0.86268562]\n",
      " [0.86185372]\n",
      " [0.86032391]\n",
      " [0.85864079]\n",
      " [0.85752732]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.87862235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04523328319191933, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86207998]\n",
      " [0.86268562]\n",
      " [0.86185372]\n",
      " [0.86032391]\n",
      " [0.85864079]\n",
      " [0.85752732]\n",
      " [0.81828749]\n",
      " [0.87862235]] | y: 0.7605579232855482 | Predicción actual: [[0.87791157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06504588574171066, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86268562]\n",
      " [0.86185372]\n",
      " [0.86032391]\n",
      " [0.85864079]\n",
      " [0.85752732]\n",
      " [0.81828749]\n",
      " [0.87862235]\n",
      " [0.87791157]] | y: 0.7915536613715615 | Predicción actual: [[0.87583745]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025231812614947557, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86185372]\n",
      " [0.86032391]\n",
      " [0.85864079]\n",
      " [0.85752732]\n",
      " [0.81828749]\n",
      " [0.87862235]\n",
      " [0.87791157]\n",
      " [0.87583745]] | y: 0.7686943045331267 | Predicción actual: [[0.87371904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.057240765541791916, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86032391]\n",
      " [0.85864079]\n",
      " [0.85752732]\n",
      " [0.81828749]\n",
      " [0.87862235]\n",
      " [0.87791157]\n",
      " [0.87583745]\n",
      " [0.87371904]] | y: 0.7686943045331267 | Predicción actual: [[0.87152696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006727727595716715, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85864079]\n",
      " [0.85752732]\n",
      " [0.81828749]\n",
      " [0.87862235]\n",
      " [0.87791157]\n",
      " [0.87583745]\n",
      " [0.87371904]\n",
      " [0.87152696]] | y: 0.7989151491669895 | Predicción actual: [[0.8701698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012019309360766783, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85752732]\n",
      " [0.81828749]\n",
      " [0.87862235]\n",
      " [0.87791157]\n",
      " [0.87583745]\n",
      " [0.87371904]\n",
      " [0.87152696]\n",
      " [0.87016982]] | y: 0.7900038744672608 | Predicción actual: [[0.87009823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019029531395062804, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.87862235]\n",
      " [0.87791157]\n",
      " [0.87583745]\n",
      " [0.87371904]\n",
      " [0.87152696]\n",
      " [0.87016982]\n",
      " [0.87009823]] | y: 0.760170476559473 | Predicción actual: [[0.87117064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01872079446911812, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87862235]\n",
      " [0.87791157]\n",
      " [0.87583745]\n",
      " [0.87371904]\n",
      " [0.87152696]\n",
      " [0.87016982]\n",
      " [0.87009823]\n",
      " [0.87117064]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024387086741626263, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87791157]\n",
      " [0.87583745]\n",
      " [0.87371904]\n",
      " [0.87152696]\n",
      " [0.87016982]\n",
      " [0.87009823]\n",
      " [0.87117064]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8805405]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08232637494802475, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87583745]\n",
      " [0.87371904]\n",
      " [0.87152696]\n",
      " [0.87016982]\n",
      " [0.87009823]\n",
      " [0.87117064]\n",
      " [0.68539326]\n",
      " [0.88054049]] | y: 0.6648585819449826 | Predicción actual: [[0.87449485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05940544977784157, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87371904]\n",
      " [0.87152696]\n",
      " [0.87016982]\n",
      " [0.87009823]\n",
      " [0.87117064]\n",
      " [0.68539326]\n",
      " [0.88054049]\n",
      " [0.87449485]] | y: 0.7078651685393258 | Predicción actual: [[0.8667189]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011248021386563778, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87152696]\n",
      " [0.87016982]\n",
      " [0.87009823]\n",
      " [0.87117064]\n",
      " [0.68539326]\n",
      " [0.88054049]\n",
      " [0.87449485]\n",
      " [0.86671889]] | y: 0.6648585819449826 | Predicción actual: [[0.8578377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04007524996995926, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87016982]\n",
      " [0.87009823]\n",
      " [0.87117064]\n",
      " [0.68539326]\n",
      " [0.88054049]\n",
      " [0.87449485]\n",
      " [0.86671889]\n",
      " [0.85783768]] | y: 0.7113521890740022 | Predicción actual: [[0.8480753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027105115354061127, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87009823]\n",
      " [0.87117064]\n",
      " [0.68539326]\n",
      " [0.88054049]\n",
      " [0.87449485]\n",
      " [0.86671889]\n",
      " [0.85783768]\n",
      " [0.84807527]] | y: 0.6772568771793879 | Predicción actual: [[0.8377476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009959633462131023, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87117064]\n",
      " [0.68539326]\n",
      " [0.88054049]\n",
      " [0.87449485]\n",
      " [0.86671889]\n",
      " [0.85783768]\n",
      " [0.84807527]\n",
      " [0.83774757]] | y: 0.7621077101898488 | Predicción actual: [[0.8270574]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05351455137133598, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.88054049]\n",
      " [0.87449485]\n",
      " [0.86671889]\n",
      " [0.85783768]\n",
      " [0.84807527]\n",
      " [0.83774757]\n",
      " [0.82705742]] | y: 0.8070515304145678 | Predicción actual: [[0.81563157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0048715099692344666, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88054049]\n",
      " [0.87449485]\n",
      " [0.86671889]\n",
      " [0.85783768]\n",
      " [0.84807527]\n",
      " [0.83774757]\n",
      " [0.82705742]\n",
      " [0.81563157]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009317676536738873, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87449485]\n",
      " [0.86671889]\n",
      " [0.85783768]\n",
      " [0.84807527]\n",
      " [0.83774757]\n",
      " [0.82705742]\n",
      " [0.81563157]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8476986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00145091547165066, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86671889]\n",
      " [0.85783768]\n",
      " [0.84807527]\n",
      " [0.83774757]\n",
      " [0.82705742]\n",
      " [0.81563157]\n",
      " [0.81518791]\n",
      " [0.84769863]] | y: 0.9597055404881829 | Predicción actual: [[0.8383416]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.7484405513387173e-05, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85783768]\n",
      " [0.84807527]\n",
      " [0.83774757]\n",
      " [0.82705742]\n",
      " [0.81563157]\n",
      " [0.81518791]\n",
      " [0.84769863]\n",
      " [0.83834159]] | y: 0.9643549012010848 | Predicción actual: [[0.8294989]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00029395640012808144, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84807527]\n",
      " [0.83774757]\n",
      " [0.82705742]\n",
      " [0.81563157]\n",
      " [0.81518791]\n",
      " [0.84769863]\n",
      " [0.83834159]\n",
      " [0.82949889]] | y: 0.8880278961642774 | Predicción actual: [[0.82188237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00200360594317317, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83774757]\n",
      " [0.82705742]\n",
      " [0.81563157]\n",
      " [0.81518791]\n",
      " [0.84769863]\n",
      " [0.83834159]\n",
      " [0.82949889]\n",
      " [0.82188237]] | y: 0.8926772568771792 | Predicción actual: [[0.8159981]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001532927853986621, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82705742]\n",
      " [0.81563157]\n",
      " [0.81518791]\n",
      " [0.84769863]\n",
      " [0.83834159]\n",
      " [0.82949889]\n",
      " [0.82188237]\n",
      " [0.81599808]] | y: 0.8752421542037967 | Predicción actual: [[0.812367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022681549191474915, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81563157]\n",
      " [0.81518791]\n",
      " [0.84769863]\n",
      " [0.83834159]\n",
      " [0.82949889]\n",
      " [0.82188237]\n",
      " [0.81599808]\n",
      " [0.81236702]] | y: 0.8508330104610615 | Predicción actual: [[0.8116737]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037949969992041588, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.84769863]\n",
      " [0.83834159]\n",
      " [0.82949889]\n",
      " [0.82188237]\n",
      " [0.81599808]\n",
      " [0.81236702]\n",
      " [0.8116737 ]] | y: 0.8488957768306855 | Predicción actual: [[0.8141377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008485002908855677, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84769863]\n",
      " [0.83834159]\n",
      " [0.82949889]\n",
      " [0.82188237]\n",
      " [0.81599808]\n",
      " [0.81236702]\n",
      " [0.8116737 ]\n",
      " [0.8141377 ]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008482513017952442, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83834159]\n",
      " [0.82949889]\n",
      " [0.82188237]\n",
      " [0.81599808]\n",
      " [0.81236702]\n",
      " [0.8116737 ]\n",
      " [0.8141377 ]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.8109606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04575676843523979, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82949889]\n",
      " [0.82188237]\n",
      " [0.81599808]\n",
      " [0.81236702]\n",
      " [0.8116737 ]\n",
      " [0.8141377 ]\n",
      " [0.96241767]\n",
      " [0.81096059]] | y: 0.9407206509104997 | Predicción actual: [[0.80817556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04486728459596634, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82188237]\n",
      " [0.81599808]\n",
      " [0.81236702]\n",
      " [0.8116737 ]\n",
      " [0.8141377 ]\n",
      " [0.96241767]\n",
      " [0.81096059]\n",
      " [0.80817556]] | y: 0.9724912824486633 | Predicción actual: [[0.8085481]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07264545559883118, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81599808]\n",
      " [0.81236702]\n",
      " [0.8116737 ]\n",
      " [0.8141377 ]\n",
      " [0.96241767]\n",
      " [0.81096059]\n",
      " [0.80817556]\n",
      " [0.80854809]] | y: 0.9969004261913985 | Predicción actual: [[0.8119835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0625535398721695, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81236702]\n",
      " [0.8116737 ]\n",
      " [0.8141377 ]\n",
      " [0.96241767]\n",
      " [0.81096059]\n",
      " [0.80817556]\n",
      " [0.80854809]\n",
      " [0.81198353]] | y: 0.951181712514529 | Predicción actual: [[0.81796086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016586225479841232, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8116737 ]\n",
      " [0.8141377 ]\n",
      " [0.96241767]\n",
      " [0.81096059]\n",
      " [0.80817556]\n",
      " [0.80854809]\n",
      " [0.81198353]\n",
      " [0.81796086]] | y: 0.8957768306857805 | Predicción actual: [[0.82548255]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009390045888721943, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8141377 ]\n",
      " [0.96241767]\n",
      " [0.81096059]\n",
      " [0.80817556]\n",
      " [0.80854809]\n",
      " [0.81198353]\n",
      " [0.81796086]\n",
      " [0.82548255]] | y: 0.8814413018209997 | Predicción actual: [[0.8333951]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005714508588425815, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.81096059]\n",
      " [0.80817556]\n",
      " [0.80854809]\n",
      " [0.81198353]\n",
      " [0.81796086]\n",
      " [0.82548255]\n",
      " [0.83339512]] | y: 0.9170864006199149 | Predicción actual: [[0.84027094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017062986444216222, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81096059]\n",
      " [0.80817556]\n",
      " [0.80854809]\n",
      " [0.81198353]\n",
      " [0.81796086]\n",
      " [0.82548255]\n",
      " [0.83339512]\n",
      " [0.84027094]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005301807541400194, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80817556]\n",
      " [0.80854809]\n",
      " [0.81198353]\n",
      " [0.81796086]\n",
      " [0.82548255]\n",
      " [0.83339512]\n",
      " [0.84027094]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.80810773]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00043282078695483506, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80854809]\n",
      " [0.81198353]\n",
      " [0.81796086]\n",
      " [0.82548255]\n",
      " [0.83339512]\n",
      " [0.84027094]\n",
      " [0.91979853]\n",
      " [0.80810773]] | y: 0.9682293684618366 | Predicción actual: [[0.8136861]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05854659900069237, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81198353]\n",
      " [0.81796086]\n",
      " [0.82548255]\n",
      " [0.83339512]\n",
      " [0.84027094]\n",
      " [0.91979853]\n",
      " [0.80810773]\n",
      " [0.81368607]] | y: 0.9577683068578069 | Predicción actual: [[0.82106084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021465741097927094, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.23346643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03307940065860748, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23346643]] | y: 0.10422316931421921 | Predicción actual: [[0.2187425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015258985571563244, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23346643]\n",
      " [0.2187425 ]] | y: 0.15420379697791559 | Predicción actual: [[0.22315711]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00199366407468915, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23346643]\n",
      " [0.2187425 ]\n",
      " [0.22315711]] | y: 0.1557535838822161 | Predicción actual: [[0.23514317]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003332015359774232, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23346643]\n",
      " [0.2187425 ]\n",
      " [0.22315711]\n",
      " [0.23514317]] | y: 0.12553273924835334 | Predicción actual: [[0.24896124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009319813922047615, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23346643]\n",
      " [0.2187425 ]\n",
      " [0.22315711]\n",
      " [0.23514317]\n",
      " [0.24896124]] | y: 0.1456799690042619 | Predicción actual: [[0.26114616]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023708097636699677, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23346643]\n",
      " [0.2187425 ]\n",
      " [0.22315711]\n",
      " [0.23514317]\n",
      " [0.24896124]\n",
      " [0.26114616]] | y: 0.1464548624564122 | Predicción actual: [[0.28538603]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0345226489007473, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.23346643]\n",
      " [0.2187425 ]\n",
      " [0.22315711]\n",
      " [0.23514317]\n",
      " [0.24896124]\n",
      " [0.26114616]\n",
      " [0.28538603]] | y: 0.1960480433940332 | Predicción actual: [[0.31556433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012096085585653782, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23346643]\n",
      " [0.2187425 ]\n",
      " [0.22315711]\n",
      " [0.23514317]\n",
      " [0.24896124]\n",
      " [0.26114616]\n",
      " [0.28538603]\n",
      " [0.31556433]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015823034569621086, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2187425 ]\n",
      " [0.22315711]\n",
      " [0.23514317]\n",
      " [0.24896124]\n",
      " [0.26114616]\n",
      " [0.28538603]\n",
      " [0.31556433]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3546854]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012539869174361229, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22315711]\n",
      " [0.23514317]\n",
      " [0.24896124]\n",
      " [0.26114616]\n",
      " [0.28538603]\n",
      " [0.31556433]\n",
      " [0.2305308 ]\n",
      " [0.3546854 ]] | y: 0.211933359163115 | Predicción actual: [[0.3619626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02722843550145626, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23514317]\n",
      " [0.24896124]\n",
      " [0.26114616]\n",
      " [0.28538603]\n",
      " [0.31556433]\n",
      " [0.2305308 ]\n",
      " [0.3546854 ]\n",
      " [0.36196259]] | y: 0.2072839984502131 | Predicción actual: [[0.37105733]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01866339147090912, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24896124]\n",
      " [0.26114616]\n",
      " [0.28538603]\n",
      " [0.31556433]\n",
      " [0.2305308 ]\n",
      " [0.3546854 ]\n",
      " [0.36196259]\n",
      " [0.37105733]] | y: 0.19294846958543205 | Predicción actual: [[0.3808288]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05789600685238838, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26114616]\n",
      " [0.28538603]\n",
      " [0.31556433]\n",
      " [0.2305308 ]\n",
      " [0.3546854 ]\n",
      " [0.36196259]\n",
      " [0.37105733]\n",
      " [0.3808288 ]] | y: 0.19682293684618352 | Predicción actual: [[0.39106587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03943701088428497, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28538603]\n",
      " [0.31556433]\n",
      " [0.2305308 ]\n",
      " [0.3546854 ]\n",
      " [0.36196259]\n",
      " [0.37105733]\n",
      " [0.3808288 ]\n",
      " [0.39106587]] | y: 0.21425803951956607 | Predicción actual: [[0.4023283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03723106533288956, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31556433]\n",
      " [0.2305308 ]\n",
      " [0.3546854 ]\n",
      " [0.36196259]\n",
      " [0.37105733]\n",
      " [0.3808288 ]\n",
      " [0.39106587]\n",
      " [0.40232831]] | y: 0.18132506780317698 | Predicción actual: [[0.41197857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0696176290512085, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.3546854 ]\n",
      " [0.36196259]\n",
      " [0.37105733]\n",
      " [0.3808288 ]\n",
      " [0.39106587]\n",
      " [0.40232831]\n",
      " [0.41197857]] | y: 0.17512592018597434 | Predicción actual: [[0.418278]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05338519811630249, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3546854 ]\n",
      " [0.36196259]\n",
      " [0.37105733]\n",
      " [0.3808288 ]\n",
      " [0.39106587]\n",
      " [0.40232831]\n",
      " [0.41197857]\n",
      " [0.41827801]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046903785318136215, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36196259]\n",
      " [0.37105733]\n",
      " [0.3808288 ]\n",
      " [0.39106587]\n",
      " [0.40232831]\n",
      " [0.41197857]\n",
      " [0.41827801]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.45219088]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11573564261198044, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37105733]\n",
      " [0.3808288 ]\n",
      " [0.39106587]\n",
      " [0.40232831]\n",
      " [0.41197857]\n",
      " [0.41827801]\n",
      " [0.14800465]\n",
      " [0.45219088]] | y: 0.19217357613328173 | Predicción actual: [[0.45508572]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06220267340540886, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3808288 ]\n",
      " [0.39106587]\n",
      " [0.40232831]\n",
      " [0.41197857]\n",
      " [0.41827801]\n",
      " [0.14800465]\n",
      " [0.45219088]\n",
      " [0.45508572]] | y: 0.1859744285160791 | Predicción actual: [[0.4559682]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.059272270649671555, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39106587]\n",
      " [0.40232831]\n",
      " [0.41197857]\n",
      " [0.41827801]\n",
      " [0.14800465]\n",
      " [0.45219088]\n",
      " [0.45508572]\n",
      " [0.4559682 ]] | y: 0.26695079426578844 | Predicción actual: [[0.45497105]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035094037652015686, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40232831]\n",
      " [0.41197857]\n",
      " [0.41827801]\n",
      " [0.14800465]\n",
      " [0.45219088]\n",
      " [0.45508572]\n",
      " [0.4559682 ]\n",
      " [0.45497105]] | y: 0.2925222781867493 | Predicción actual: [[0.45243517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008429856039583683, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41197857]\n",
      " [0.41827801]\n",
      " [0.14800465]\n",
      " [0.45219088]\n",
      " [0.45508572]\n",
      " [0.4559682 ]\n",
      " [0.45497105]\n",
      " [0.45243517]] | y: 0.3177063153816349 | Predicción actual: [[0.4486294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03306505084037781, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41827801]\n",
      " [0.14800465]\n",
      " [0.45219088]\n",
      " [0.45508572]\n",
      " [0.4559682 ]\n",
      " [0.45497105]\n",
      " [0.45243517]\n",
      " [0.44862941]] | y: 0.31266950794265785 | Predicción actual: [[0.44422472]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026970217004418373, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.45219088]\n",
      " [0.45508572]\n",
      " [0.4559682 ]\n",
      " [0.45497105]\n",
      " [0.45243517]\n",
      " [0.44862941]\n",
      " [0.44422472]] | y: 0.2890352576520729 | Predicción actual: [[0.4402989]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021775633096694946, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45219088]\n",
      " [0.45508572]\n",
      " [0.4559682 ]\n",
      " [0.45497105]\n",
      " [0.45243517]\n",
      " [0.44862941]\n",
      " [0.44422472]\n",
      " [0.44029889]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03578750044107437, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45508572]\n",
      " [0.4559682 ]\n",
      " [0.45497105]\n",
      " [0.45243517]\n",
      " [0.44862941]\n",
      " [0.44422472]\n",
      " [0.44029889]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.5003334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03323035687208176, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4559682 ]\n",
      " [0.45497105]\n",
      " [0.45243517]\n",
      " [0.44862941]\n",
      " [0.44422472]\n",
      " [0.44029889]\n",
      " [0.28283611]\n",
      " [0.50033343]] | y: 0.2758620689655173 | Predicción actual: [[0.49640393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05931362882256508, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45497105]\n",
      " [0.45243517]\n",
      " [0.44862941]\n",
      " [0.44422472]\n",
      " [0.44029889]\n",
      " [0.28283611]\n",
      " [0.50033343]\n",
      " [0.49640393]] | y: 0.2746997287872917 | Predicción actual: [[0.49121115]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06358345597982407, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45243517]\n",
      " [0.44862941]\n",
      " [0.44422472]\n",
      " [0.44029889]\n",
      " [0.28283611]\n",
      " [0.50033343]\n",
      " [0.49640393]\n",
      " [0.49121115]] | y: 0.275474622239442 | Predicción actual: [[0.48574474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04926283285021782, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44862941]\n",
      " [0.44422472]\n",
      " [0.44029889]\n",
      " [0.28283611]\n",
      " [0.50033343]\n",
      " [0.49640393]\n",
      " [0.49121115]\n",
      " [0.48574474]] | y: 0.3347539713289423 | Predicción actual: [[0.48107108]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021855870261788368, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44422472]\n",
      " [0.44029889]\n",
      " [0.28283611]\n",
      " [0.50033343]\n",
      " [0.49640393]\n",
      " [0.49121115]\n",
      " [0.48574474]\n",
      " [0.48107108]] | y: 0.35567609453700116 | Predicción actual: [[0.4781829]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032777171581983566, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44029889]\n",
      " [0.28283611]\n",
      " [0.50033343]\n",
      " [0.49640393]\n",
      " [0.49121115]\n",
      " [0.48574474]\n",
      " [0.48107108]\n",
      " [0.47818291]] | y: 0.3366912049593181 | Predicción actual: [[0.47772732]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012375511229038239, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.50033343]\n",
      " [0.49640393]\n",
      " [0.49121115]\n",
      " [0.48574474]\n",
      " [0.48107108]\n",
      " [0.47818291]\n",
      " [0.47772732]] | y: 0.3335916311507167 | Predicción actual: [[0.48003966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009364333003759384, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50033343]\n",
      " [0.49640393]\n",
      " [0.49121115]\n",
      " [0.48574474]\n",
      " [0.48107108]\n",
      " [0.47818291]\n",
      " [0.47772732]\n",
      " [0.48003966]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0052452608942985535, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49640393]\n",
      " [0.49121115]\n",
      " [0.48574474]\n",
      " [0.48107108]\n",
      " [0.47818291]\n",
      " [0.47772732]\n",
      " [0.48003966]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5172645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00540973199531436, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49121115]\n",
      " [0.48574474]\n",
      " [0.48107108]\n",
      " [0.47818291]\n",
      " [0.47772732]\n",
      " [0.48003966]\n",
      " [0.3847346 ]\n",
      " [0.51726449]] | y: 0.5962805114296785 | Predicción actual: [[0.51238865]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002119538839906454, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48574474]\n",
      " [0.48107108]\n",
      " [0.47818291]\n",
      " [0.47772732]\n",
      " [0.48003966]\n",
      " [0.3847346 ]\n",
      " [0.51726449]\n",
      " [0.51238865]] | y: 0.574583494769469 | Predicción actual: [[0.5080257]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031689165625721216, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48107108]\n",
      " [0.47818291]\n",
      " [0.47772732]\n",
      " [0.48003966]\n",
      " [0.3847346 ]\n",
      " [0.51726449]\n",
      " [0.51238865]\n",
      " [0.50802571]] | y: 0.6063541263076326 | Predicción actual: [[0.5047609]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023696336895227432, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47818291]\n",
      " [0.47772732]\n",
      " [0.48003966]\n",
      " [0.3847346 ]\n",
      " [0.51726449]\n",
      " [0.51238865]\n",
      " [0.50802571]\n",
      " [0.50476092]] | y: 0.5846571096474236 | Predicción actual: [[0.5029927]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015505669638514519, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47772732]\n",
      " [0.48003966]\n",
      " [0.3847346 ]\n",
      " [0.51726449]\n",
      " [0.51238865]\n",
      " [0.50802571]\n",
      " [0.50476092]\n",
      " [0.50299269]] | y: 0.5687717938783416 | Predicción actual: [[0.5027253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00442058639600873, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48003966]\n",
      " [0.3847346 ]\n",
      " [0.51726449]\n",
      " [0.51238865]\n",
      " [0.50802571]\n",
      " [0.50476092]\n",
      " [0.50299269]\n",
      " [0.5027253 ]] | y: 0.6427741185586981 | Predicción actual: [[0.50366485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024912556633353233, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.51726449]\n",
      " [0.51238865]\n",
      " [0.50802571]\n",
      " [0.50476092]\n",
      " [0.50299269]\n",
      " [0.5027253 ]\n",
      " [0.50366485]] | y: 0.6617590081363811 | Predicción actual: [[0.5053759]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009400653652846813, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51726449]\n",
      " [0.51238865]\n",
      " [0.50802571]\n",
      " [0.50476092]\n",
      " [0.50299269]\n",
      " [0.5027253 ]\n",
      " [0.50366485]\n",
      " [0.50537592]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007676181849092245, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51238865]\n",
      " [0.50802571]\n",
      " [0.50476092]\n",
      " [0.50299269]\n",
      " [0.5027253 ]\n",
      " [0.50366485]\n",
      " [0.50537592]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5298571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033877287060022354, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50802571]\n",
      " [0.50476092]\n",
      " [0.50299269]\n",
      " [0.5027253 ]\n",
      " [0.50366485]\n",
      " [0.50537592]\n",
      " [0.67299496]\n",
      " [0.5298571 ]] | y: 0.703990701278574 | Predicción actual: [[0.5307675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012942502275109291, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50476092]\n",
      " [0.50299269]\n",
      " [0.5027253 ]\n",
      " [0.50366485]\n",
      " [0.50537592]\n",
      " [0.67299496]\n",
      " [0.5298571 ]\n",
      " [0.5307675 ]] | y: 0.7272375048430839 | Predicción actual: [[0.5342941]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04065857455134392, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50299269]\n",
      " [0.5027253 ]\n",
      " [0.50366485]\n",
      " [0.50537592]\n",
      " [0.67299496]\n",
      " [0.5298571 ]\n",
      " [0.5307675 ]\n",
      " [0.53429413]] | y: 0.722588144130182 | Predicción actual: [[0.5404597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015598874539136887, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5027253 ]\n",
      " [0.50366485]\n",
      " [0.50537592]\n",
      " [0.67299496]\n",
      " [0.5298571 ]\n",
      " [0.5307675 ]\n",
      " [0.53429413]\n",
      " [0.54045969]] | y: 0.771793878341728 | Predicción actual: [[0.5489027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06487801671028137, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50366485]\n",
      " [0.50537592]\n",
      " [0.67299496]\n",
      " [0.5298571 ]\n",
      " [0.5307675 ]\n",
      " [0.53429413]\n",
      " [0.54045969]\n",
      " [0.54890269]] | y: 0.7245253777605578 | Predicción actual: [[0.55927086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02538588084280491, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50537592]\n",
      " [0.67299496]\n",
      " [0.5298571 ]\n",
      " [0.5307675 ]\n",
      " [0.53429413]\n",
      " [0.54045969]\n",
      " [0.54890269]\n",
      " [0.55927086]] | y: 0.6710577295621851 | Predicción actual: [[0.57105225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025306398048996925, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.5298571 ]\n",
      " [0.5307675 ]\n",
      " [0.53429413]\n",
      " [0.54045969]\n",
      " [0.54890269]\n",
      " [0.55927086]\n",
      " [0.57105225]] | y: 0.6737698566447115 | Predicción actual: [[0.583887]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015191548503935337, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5298571 ]\n",
      " [0.5307675 ]\n",
      " [0.53429413]\n",
      " [0.54045969]\n",
      " [0.54890269]\n",
      " [0.55927086]\n",
      " [0.57105225]\n",
      " [0.58388698]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04384728521108627, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5307675 ]\n",
      " [0.53429413]\n",
      " [0.54045969]\n",
      " [0.54890269]\n",
      " [0.55927086]\n",
      " [0.57105225]\n",
      " [0.58388698]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5617517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055182795971632004, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53429413]\n",
      " [0.54045969]\n",
      " [0.54890269]\n",
      " [0.55927086]\n",
      " [0.57105225]\n",
      " [0.58388698]\n",
      " [0.71445176]\n",
      " [0.56175172]] | y: 0.722588144130182 | Predicción actual: [[0.5699744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009768190793693066, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54045969]\n",
      " [0.54890269]\n",
      " [0.55927086]\n",
      " [0.57105225]\n",
      " [0.58388698]\n",
      " [0.71445176]\n",
      " [0.56175172]\n",
      " [0.56997442]] | y: 0.6993413405656723 | Predicción actual: [[0.58006954]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0064057111740112305, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54890269]\n",
      " [0.55927086]\n",
      " [0.57105225]\n",
      " [0.58388698]\n",
      " [0.71445176]\n",
      " [0.56175172]\n",
      " [0.56997442]\n",
      " [0.58006954]] | y: 0.7373111197210385 | Predicción actual: [[0.59113795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012127424590289593, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55927086]\n",
      " [0.57105225]\n",
      " [0.58388698]\n",
      " [0.71445176]\n",
      " [0.56175172]\n",
      " [0.56997442]\n",
      " [0.58006954]\n",
      " [0.59113795]] | y: 0.7214258039519565 | Predicción actual: [[0.60221356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011821076273918152, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57105225]\n",
      " [0.58388698]\n",
      " [0.71445176]\n",
      " [0.56175172]\n",
      " [0.56997442]\n",
      " [0.58006954]\n",
      " [0.59113795]\n",
      " [0.60221356]] | y: 0.7187136768694304 | Predicción actual: [[0.61229473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01138220727443695, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58388698]\n",
      " [0.71445176]\n",
      " [0.56175172]\n",
      " [0.56997442]\n",
      " [0.58006954]\n",
      " [0.59113795]\n",
      " [0.60221356]\n",
      " [0.61229473]] | y: 0.6741573033707864 | Predicción actual: [[0.62050134]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00797731801867485, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56175172]\n",
      " [0.56997442]\n",
      " [0.58006954]\n",
      " [0.59113795]\n",
      " [0.60221356]\n",
      " [0.61229473]\n",
      " [0.62050134]] | y: 0.698566447113522 | Predicción actual: [[0.6260872]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010062221437692642, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56175172]\n",
      " [0.56997442]\n",
      " [0.58006954]\n",
      " [0.59113795]\n",
      " [0.60221356]\n",
      " [0.61229473]\n",
      " [0.62050134]\n",
      " [0.62608719]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002005730289965868, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56997442]\n",
      " [0.58006954]\n",
      " [0.59113795]\n",
      " [0.60221356]\n",
      " [0.61229473]\n",
      " [0.62050134]\n",
      " [0.62608719]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6076276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016838468611240387, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58006954]\n",
      " [0.59113795]\n",
      " [0.60221356]\n",
      " [0.61229473]\n",
      " [0.62050134]\n",
      " [0.62608719]\n",
      " [0.72103836]\n",
      " [0.60762757]] | y: 0.7562960092987214 | Predicción actual: [[0.6178593]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00458386680111289, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59113795]\n",
      " [0.60221356]\n",
      " [0.61229473]\n",
      " [0.62050134]\n",
      " [0.62608719]\n",
      " [0.72103836]\n",
      " [0.60762757]\n",
      " [0.6178593 ]] | y: 0.8275862068965516 | Predicción actual: [[0.62820655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01565636694431305, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60221356]\n",
      " [0.61229473]\n",
      " [0.62050134]\n",
      " [0.62608719]\n",
      " [0.72103836]\n",
      " [0.60762757]\n",
      " [0.6178593 ]\n",
      " [0.62820655]] | y: 0.8388221619527314 | Predicción actual: [[0.63802135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03476271405816078, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61229473]\n",
      " [0.62050134]\n",
      " [0.62608719]\n",
      " [0.72103836]\n",
      " [0.60762757]\n",
      " [0.6178593 ]\n",
      " [0.62820655]\n",
      " [0.63802135]] | y: 0.7942657884540876 | Predicción actual: [[0.6468152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07574938237667084, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62050134]\n",
      " [0.62608719]\n",
      " [0.72103836]\n",
      " [0.60762757]\n",
      " [0.6178593 ]\n",
      " [0.62820655]\n",
      " [0.63802135]\n",
      " [0.64681518]] | y: 0.7838047268500579 | Predicción actual: [[0.65436834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.1310961528797634e-05, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62608719]\n",
      " [0.72103836]\n",
      " [0.60762757]\n",
      " [0.6178593 ]\n",
      " [0.62820655]\n",
      " [0.63802135]\n",
      " [0.64681518]\n",
      " [0.65436834]] | y: 0.7679194110809764 | Predicción actual: [[0.6605126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04780643433332443, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.60762757]\n",
      " [0.6178593 ]\n",
      " [0.62820655]\n",
      " [0.63802135]\n",
      " [0.64681518]\n",
      " [0.65436834]\n",
      " [0.66051263]] | y: 0.7845796203022084 | Predicción actual: [[0.6659298]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021503867581486702, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60762757]\n",
      " [0.6178593 ]\n",
      " [0.62820655]\n",
      " [0.63802135]\n",
      " [0.64681518]\n",
      " [0.65436834]\n",
      " [0.66051263]\n",
      " [0.66592979]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054616738110780716, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6178593 ]\n",
      " [0.62820655]\n",
      " [0.63802135]\n",
      " [0.64681518]\n",
      " [0.65436834]\n",
      " [0.66051263]\n",
      " [0.66592979]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6572175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03357331454753876, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62820655]\n",
      " [0.63802135]\n",
      " [0.64681518]\n",
      " [0.65436834]\n",
      " [0.66051263]\n",
      " [0.66592979]\n",
      " [0.87872917]\n",
      " [0.6572175 ]] | y: 0.8488957768306855 | Predicción actual: [[0.6691318]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02074521780014038, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63802135]\n",
      " [0.64681518]\n",
      " [0.65436834]\n",
      " [0.66051263]\n",
      " [0.66592979]\n",
      " [0.87872917]\n",
      " [0.6572175 ]\n",
      " [0.66913182]] | y: 0.8182874854707476 | Predicción actual: [[0.68208367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010597920045256615, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64681518]\n",
      " [0.65436834]\n",
      " [0.66051263]\n",
      " [0.66592979]\n",
      " [0.87872917]\n",
      " [0.6572175 ]\n",
      " [0.66913182]\n",
      " [0.68208367]] | y: 0.8268113134444013 | Predicción actual: [[0.69562507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013207830488681793, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65436834]\n",
      " [0.66051263]\n",
      " [0.66592979]\n",
      " [0.87872917]\n",
      " [0.6572175 ]\n",
      " [0.66913182]\n",
      " [0.68208367]\n",
      " [0.69562507]] | y: 0.7853545137543589 | Predicción actual: [[0.70956707]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046250391751527786, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66051263]\n",
      " [0.66592979]\n",
      " [0.87872917]\n",
      " [0.6572175 ]\n",
      " [0.66913182]\n",
      " [0.68208367]\n",
      " [0.69562507]\n",
      " [0.70956707]] | y: 0.7892289810151103 | Predicción actual: [[0.7237492]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005117877386510372, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66592979]\n",
      " [0.87872917]\n",
      " [0.6572175 ]\n",
      " [0.66913182]\n",
      " [0.68208367]\n",
      " [0.69562507]\n",
      " [0.70956707]\n",
      " [0.72374922]] | y: 0.8341728012398295 | Predicción actual: [[0.73793936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04358458146452904, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.6572175 ]\n",
      " [0.66913182]\n",
      " [0.68208367]\n",
      " [0.69562507]\n",
      " [0.70956707]\n",
      " [0.72374922]\n",
      " [0.73793936]] | y: 0.8124757845796202 | Predicción actual: [[0.75216687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01373309176415205, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6572175 ]\n",
      " [0.66913182]\n",
      " [0.68208367]\n",
      " [0.69562507]\n",
      " [0.70956707]\n",
      " [0.72374922]\n",
      " [0.73793936]\n",
      " [0.75216687]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003733239835128188, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66913182]\n",
      " [0.68208367]\n",
      " [0.69562507]\n",
      " [0.70956707]\n",
      " [0.72374922]\n",
      " [0.73793936]\n",
      " [0.75216687]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7210402]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005431341123767197, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68208367]\n",
      " [0.69562507]\n",
      " [0.70956707]\n",
      " [0.72374922]\n",
      " [0.73793936]\n",
      " [0.75216687]\n",
      " [0.80123983]\n",
      " [0.72104019]] | y: 0.793490895001937 | Predicción actual: [[0.7347903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01729900762438774, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69562507]\n",
      " [0.70956707]\n",
      " [0.72374922]\n",
      " [0.73793936]\n",
      " [0.75216687]\n",
      " [0.80123983]\n",
      " [0.72104019]\n",
      " [0.73479033]] | y: 0.760170476559473 | Predicción actual: [[0.7479482]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018508853390812874, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70956707]\n",
      " [0.72374922]\n",
      " [0.73793936]\n",
      " [0.75216687]\n",
      " [0.80123983]\n",
      " [0.72104019]\n",
      " [0.73479033]\n",
      " [0.74794823]] | y: 0.7353738860906625 | Predicción actual: [[0.7601075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012271587736904621, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72374922]\n",
      " [0.73793936]\n",
      " [0.75216687]\n",
      " [0.80123983]\n",
      " [0.72104019]\n",
      " [0.73479033]\n",
      " [0.74794823]\n",
      " [0.76010752]] | y: 0.7101898488957767 | Predicción actual: [[0.77061903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.842917860514717e-06, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73793936]\n",
      " [0.75216687]\n",
      " [0.80123983]\n",
      " [0.72104019]\n",
      " [0.73479033]\n",
      " [0.74794823]\n",
      " [0.76010752]\n",
      " [0.77061903]] | y: 0.7121270825261525 | Predicción actual: [[0.7786921]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012063916801707819, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75216687]\n",
      " [0.80123983]\n",
      " [0.72104019]\n",
      " [0.73479033]\n",
      " [0.74794823]\n",
      " [0.76010752]\n",
      " [0.77061903]\n",
      " [0.77869213]] | y: 0.7396358000774894 | Predicción actual: [[0.78387755]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002540592395234853, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.72104019]\n",
      " [0.73479033]\n",
      " [0.74794823]\n",
      " [0.76010752]\n",
      " [0.77061903]\n",
      " [0.77869213]\n",
      " [0.78387755]] | y: 0.7361487795428128 | Predicción actual: [[0.78578234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006063408800400794, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72104019]\n",
      " [0.73479033]\n",
      " [0.74794823]\n",
      " [0.76010752]\n",
      " [0.77061903]\n",
      " [0.77869213]\n",
      " [0.78387755]\n",
      " [0.78578234]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002735397429205477, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73479033]\n",
      " [0.74794823]\n",
      " [0.76010752]\n",
      " [0.77061903]\n",
      " [0.77869213]\n",
      " [0.78387755]\n",
      " [0.78578234]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.78450084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007858946919441223, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74794823]\n",
      " [0.76010752]\n",
      " [0.77061903]\n",
      " [0.77869213]\n",
      " [0.78387755]\n",
      " [0.78578234]\n",
      " [0.66757071]\n",
      " [0.78450084]] | y: 0.696629213483146 | Predicción actual: [[0.79227316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023137356620281935, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76010752]\n",
      " [0.77061903]\n",
      " [0.77869213]\n",
      " [0.78387755]\n",
      " [0.78578234]\n",
      " [0.66757071]\n",
      " [0.78450084]\n",
      " [0.79227316]] | y: 0.6559473072452537 | Predicción actual: [[0.79709095]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029688701033592224, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77061903]\n",
      " [0.77869213]\n",
      " [0.78387755]\n",
      " [0.78578234]\n",
      " [0.66757071]\n",
      " [0.78450084]\n",
      " [0.79227316]\n",
      " [0.79709095]] | y: 0.6788066640836885 | Predicción actual: [[0.79864657]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011339545017108321, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77869213]\n",
      " [0.78387755]\n",
      " [0.78578234]\n",
      " [0.66757071]\n",
      " [0.78450084]\n",
      " [0.79227316]\n",
      " [0.79709095]\n",
      " [0.79864657]] | y: 0.6760945370011622 | Predicción actual: [[0.7976605]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03647696599364281, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78387755]\n",
      " [0.78578234]\n",
      " [0.66757071]\n",
      " [0.78450084]\n",
      " [0.79227316]\n",
      " [0.79709095]\n",
      " [0.79864657]\n",
      " [0.79766053]] | y: 0.7295621851995349 | Predicción actual: [[0.7944594]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008214659988880157, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78578234]\n",
      " [0.66757071]\n",
      " [0.78450084]\n",
      " [0.79227316]\n",
      " [0.79709095]\n",
      " [0.79864657]\n",
      " [0.79766053]\n",
      " [0.7944594 ]] | y: 0.7012785741960481 | Predicción actual: [[0.79029614]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05777517333626747, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.78450084]\n",
      " [0.79227316]\n",
      " [0.79709095]\n",
      " [0.79864657]\n",
      " [0.79766053]\n",
      " [0.7944594 ]\n",
      " [0.79029614]] | y: 0.767531964354901 | Predicción actual: [[0.78605825]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024874499067664146, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78450084]\n",
      " [0.79227316]\n",
      " [0.79709095]\n",
      " [0.79864657]\n",
      " [0.79766053]\n",
      " [0.7944594 ]\n",
      " [0.79029614]\n",
      " [0.78605825]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004781438037753105, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79227316]\n",
      " [0.79709095]\n",
      " [0.79864657]\n",
      " [0.79766053]\n",
      " [0.7944594 ]\n",
      " [0.79029614]\n",
      " [0.78605825]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8182223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01336345449090004, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79709095]\n",
      " [0.79864657]\n",
      " [0.79766053]\n",
      " [0.7944594 ]\n",
      " [0.79029614]\n",
      " [0.78605825]\n",
      " [0.75513367]\n",
      " [0.81822228]] | y: 0.7520340953118947 | Predicción actual: [[0.81749904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030076485127210617, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79864657]\n",
      " [0.79766053]\n",
      " [0.7944594 ]\n",
      " [0.79029614]\n",
      " [0.78605825]\n",
      " [0.75513367]\n",
      " [0.81822228]\n",
      " [0.81749904]] | y: 0.7098024021697016 | Predicción actual: [[0.81502664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005973817780613899, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79766053]\n",
      " [0.7944594 ]\n",
      " [0.79029614]\n",
      " [0.78605825]\n",
      " [0.75513367]\n",
      " [0.81822228]\n",
      " [0.81749904]\n",
      " [0.81502664]] | y: 0.6904300658659435 | Predicción actual: [[0.8121067]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028991864528506994, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7944594 ]\n",
      " [0.79029614]\n",
      " [0.78605825]\n",
      " [0.75513367]\n",
      " [0.81822228]\n",
      " [0.81749904]\n",
      " [0.81502664]\n",
      " [0.81210673]] | y: 0.7543587756683454 | Predicción actual: [[0.80977905]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011502543929964304, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79029614]\n",
      " [0.78605825]\n",
      " [0.75513367]\n",
      " [0.81822228]\n",
      " [0.81749904]\n",
      " [0.81502664]\n",
      " [0.81210673]\n",
      " [0.80977905]] | y: 0.7222006974041069 | Predicción actual: [[0.8090171]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006666824920102954, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78605825]\n",
      " [0.75513367]\n",
      " [0.81822228]\n",
      " [0.81749904]\n",
      " [0.81502664]\n",
      " [0.81210673]\n",
      " [0.80977905]\n",
      " [0.80901712]] | y: 0.8485083301046106 | Predicción actual: [[0.8104019]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0508064366877079, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.81822228]\n",
      " [0.81749904]\n",
      " [0.81502664]\n",
      " [0.81210673]\n",
      " [0.80977905]\n",
      " [0.80901712]\n",
      " [0.81040192]] | y: 0.9054629988376597 | Predicción actual: [[0.8145342]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0202303659170866, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81822228]\n",
      " [0.81749904]\n",
      " [0.81502664]\n",
      " [0.81210673]\n",
      " [0.80977905]\n",
      " [0.80901712]\n",
      " [0.81040192]\n",
      " [0.81453419]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027703631203621626, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81749904]\n",
      " [0.81502664]\n",
      " [0.81210673]\n",
      " [0.80977905]\n",
      " [0.80901712]\n",
      " [0.81040192]\n",
      " [0.81453419]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8280304]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001880838768556714, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81502664]\n",
      " [0.81210673]\n",
      " [0.80977905]\n",
      " [0.80901712]\n",
      " [0.81040192]\n",
      " [0.81453419]\n",
      " [0.8822162 ]\n",
      " [0.82803041]] | y: 0.889577683068578 | Predicción actual: [[0.82765883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004313396289944649, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81210673]\n",
      " [0.80977905]\n",
      " [0.80901712]\n",
      " [0.81040192]\n",
      " [0.81453419]\n",
      " [0.8822162 ]\n",
      " [0.82803041]\n",
      " [0.82765883]] | y: 0.8748547074777218 | Predicción actual: [[0.82858473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023405165411531925, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80977905]\n",
      " [0.80901712]\n",
      " [0.81040192]\n",
      " [0.81453419]\n",
      " [0.8822162 ]\n",
      " [0.82803041]\n",
      " [0.82765883]\n",
      " [0.82858473]] | y: 0.9132119333591631 | Predicción actual: [[0.8314209]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010035882703959942, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80901712]\n",
      " [0.81040192]\n",
      " [0.81453419]\n",
      " [0.8822162 ]\n",
      " [0.82803041]\n",
      " [0.82765883]\n",
      " [0.82858473]\n",
      " [0.8314209 ]] | y: 1.0 | Predicción actual: [[0.8362191]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.14012208580970764, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81040192]\n",
      " [0.81453419]\n",
      " [0.8822162 ]\n",
      " [0.82803041]\n",
      " [0.82765883]\n",
      " [0.82858473]\n",
      " [0.8314209 ]\n",
      " [0.83621907]] | y: 0.9705540488182873 | Predicción actual: [[0.8428965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.505581015720963e-05, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81453419]\n",
      " [0.8822162 ]\n",
      " [0.82803041]\n",
      " [0.82765883]\n",
      " [0.82858473]\n",
      " [0.8314209 ]\n",
      " [0.83621907]\n",
      " [0.84289652]] | y: 0.8888027896164277 | Predicción actual: [[0.85021657]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009228653507307172, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.82803041]\n",
      " [0.82765883]\n",
      " [0.82858473]\n",
      " [0.8314209 ]\n",
      " [0.83621907]\n",
      " [0.84289652]\n",
      " [0.85021657]] | y: 0.877954281286323 | Predicción actual: [[0.8571634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008767182938754559, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82803041]\n",
      " [0.82765883]\n",
      " [0.82858473]\n",
      " [0.8314209 ]\n",
      " [0.83621907]\n",
      " [0.84289652]\n",
      " [0.85021657]\n",
      " [0.85716343]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00038514562766067684, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82765883]\n",
      " [0.82858473]\n",
      " [0.8314209 ]\n",
      " [0.83621907]\n",
      " [0.84289652]\n",
      " [0.85021657]\n",
      " [0.85716343]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.84788924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012004127725958824, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82858473]\n",
      " [0.8314209 ]\n",
      " [0.83621907]\n",
      " [0.84289652]\n",
      " [0.85021657]\n",
      " [0.85716343]\n",
      " [0.84889578]\n",
      " [0.84788924]] | y: 0.8550949244478885 | Predicción actual: [[0.85138303]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.495674900477752e-05, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8314209 ]\n",
      " [0.83621907]\n",
      " [0.84289652]\n",
      " [0.85021657]\n",
      " [0.85716343]\n",
      " [0.84889578]\n",
      " [0.84788924]\n",
      " [0.85138303]] | y: 0.8752421542037967 | Predicción actual: [[0.8556144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006425065454095602, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83621907]\n",
      " [0.84289652]\n",
      " [0.85021657]\n",
      " [0.85716343]\n",
      " [0.84889578]\n",
      " [0.84788924]\n",
      " [0.85138303]\n",
      " [0.85561442]] | y: 0.857032158078264 | Predicción actual: [[0.8601523]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006776293739676476, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84289652]\n",
      " [0.85021657]\n",
      " [0.85716343]\n",
      " [0.84889578]\n",
      " [0.84788924]\n",
      " [0.85138303]\n",
      " [0.85561442]\n",
      " [0.8601523 ]] | y: 0.8500581170089112 | Predicción actual: [[0.86421853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.4412171114818193e-05, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85021657]\n",
      " [0.85716343]\n",
      " [0.84889578]\n",
      " [0.84788924]\n",
      " [0.85138303]\n",
      " [0.85561442]\n",
      " [0.8601523 ]\n",
      " [0.86421853]] | y: 0.8426966292134832 | Predicción actual: [[0.8670736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018833473324775696, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85716343]\n",
      " [0.84889578]\n",
      " [0.84788924]\n",
      " [0.85138303]\n",
      " [0.85561442]\n",
      " [0.8601523 ]\n",
      " [0.86421853]\n",
      " [0.8670736 ]] | y: 0.8229368461836497 | Predicción actual: [[0.8680364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004039533901959658, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.84788924]\n",
      " [0.85138303]\n",
      " [0.85561442]\n",
      " [0.8601523 ]\n",
      " [0.86421853]\n",
      " [0.8670736 ]\n",
      " [0.86803639]] | y: 0.7745060054242543 | Predicción actual: [[0.86756194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009144855663180351, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84788924]\n",
      " [0.85138303]\n",
      " [0.85561442]\n",
      " [0.8601523 ]\n",
      " [0.86421853]\n",
      " [0.8670736 ]\n",
      " [0.86803639]\n",
      " [0.86756194]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005182656459510326, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85138303]\n",
      " [0.85561442]\n",
      " [0.8601523 ]\n",
      " [0.86421853]\n",
      " [0.8670736 ]\n",
      " [0.86803639]\n",
      " [0.86756194]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8723403]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009053742978721857, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85561442]\n",
      " [0.8601523 ]\n",
      " [0.86421853]\n",
      " [0.8670736 ]\n",
      " [0.86803639]\n",
      " [0.86756194]\n",
      " [0.78419217]\n",
      " [0.87234032]] | y: 0.854320030995738 | Predicción actual: [[0.87398076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038511473685503006, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8601523 ]\n",
      " [0.86421853]\n",
      " [0.8670736 ]\n",
      " [0.86803639]\n",
      " [0.86756194]\n",
      " [0.78419217]\n",
      " [0.87234032]\n",
      " [0.87398076]] | y: 0.8368849283223556 | Predicción actual: [[0.8738363]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005478037986904383, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86421853]\n",
      " [0.8670736 ]\n",
      " [0.86803639]\n",
      " [0.86756194]\n",
      " [0.78419217]\n",
      " [0.87234032]\n",
      " [0.87398076]\n",
      " [0.87383628]] | y: 0.8299108872530028 | Predicción actual: [[0.872135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.411287126364186e-05, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8670736 ]\n",
      " [0.86803639]\n",
      " [0.86756194]\n",
      " [0.78419217]\n",
      " [0.87234032]\n",
      " [0.87398076]\n",
      " [0.87383628]\n",
      " [0.87213498]] | y: 0.887253002712127 | Predicción actual: [[0.8692007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02508344128727913, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86803639]\n",
      " [0.86756194]\n",
      " [0.78419217]\n",
      " [0.87234032]\n",
      " [0.87398076]\n",
      " [0.87383628]\n",
      " [0.87213498]\n",
      " [0.86920071]] | y: 0.8597442851607902 | Predicción actual: [[0.8657931]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03935074433684349, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86756194]\n",
      " [0.78419217]\n",
      " [0.87234032]\n",
      " [0.87398076]\n",
      " [0.87383628]\n",
      " [0.87213498]\n",
      " [0.86920071]\n",
      " [0.86579311]] | y: 0.8395970554048819 | Predicción actual: [[0.86262226]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010753847163869068, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.87234032]\n",
      " [0.87398076]\n",
      " [0.87383628]\n",
      " [0.87213498]\n",
      " [0.86920071]\n",
      " [0.86579311]\n",
      " [0.86262226]] | y: 0.7838047268500579 | Predicción actual: [[0.8599319]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052789490669965744, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87234032]\n",
      " [0.87398076]\n",
      " [0.87383628]\n",
      " [0.87213498]\n",
      " [0.86920071]\n",
      " [0.86579311]\n",
      " [0.86262226]\n",
      " [0.85993189]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016517071053385735, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87398076]\n",
      " [0.87383628]\n",
      " [0.87213498]\n",
      " [0.86920071]\n",
      " [0.86579311]\n",
      " [0.86262226]\n",
      " [0.85993189]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8803297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029372000135481358, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87383628]\n",
      " [0.87213498]\n",
      " [0.86920071]\n",
      " [0.86579311]\n",
      " [0.86262226]\n",
      " [0.85993189]\n",
      " [0.81828749]\n",
      " [0.88032973]] | y: 0.7605579232855482 | Predicción actual: [[0.8776724]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003030264633707702, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87213498]\n",
      " [0.86920071]\n",
      " [0.86579311]\n",
      " [0.86262226]\n",
      " [0.85993189]\n",
      " [0.81828749]\n",
      " [0.88032973]\n",
      " [0.87767237]] | y: 0.7915536613715615 | Predicción actual: [[0.8743629]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039898112416267395, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86920071]\n",
      " [0.86579311]\n",
      " [0.86262226]\n",
      " [0.85993189]\n",
      " [0.81828749]\n",
      " [0.88032973]\n",
      " [0.87767237]\n",
      " [0.87436289]] | y: 0.7686943045331267 | Predicción actual: [[0.8706017]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09047997742891312, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86579311]\n",
      " [0.86262226]\n",
      " [0.85993189]\n",
      " [0.81828749]\n",
      " [0.88032973]\n",
      " [0.87767237]\n",
      " [0.87436289]\n",
      " [0.87060171]] | y: 0.7686943045331267 | Predicción actual: [[0.8667844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00032585900044068694, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86262226]\n",
      " [0.85993189]\n",
      " [0.81828749]\n",
      " [0.88032973]\n",
      " [0.87767237]\n",
      " [0.87436289]\n",
      " [0.87060171]\n",
      " [0.86678439]] | y: 0.7989151491669895 | Predicción actual: [[0.86413664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06750797480344772, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85993189]\n",
      " [0.81828749]\n",
      " [0.88032973]\n",
      " [0.87767237]\n",
      " [0.87436289]\n",
      " [0.87060171]\n",
      " [0.86678439]\n",
      " [0.86413664]] | y: 0.7900038744672608 | Predicción actual: [[0.86218333]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007787985727190971, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.88032973]\n",
      " [0.87767237]\n",
      " [0.87436289]\n",
      " [0.87060171]\n",
      " [0.86678439]\n",
      " [0.86413664]\n",
      " [0.86218333]] | y: 0.760170476559473 | Predicción actual: [[0.8614629]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011652166722342372, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88032973]\n",
      " [0.87767237]\n",
      " [0.87436289]\n",
      " [0.87060171]\n",
      " [0.86678439]\n",
      " [0.86413664]\n",
      " [0.86218333]\n",
      " [0.86146289]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01720365509390831, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87767237]\n",
      " [0.87436289]\n",
      " [0.87060171]\n",
      " [0.86678439]\n",
      " [0.86413664]\n",
      " [0.86218333]\n",
      " [0.86146289]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8676786]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03870847076177597, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87436289]\n",
      " [0.87060171]\n",
      " [0.86678439]\n",
      " [0.86413664]\n",
      " [0.86218333]\n",
      " [0.86146289]\n",
      " [0.68539326]\n",
      " [0.86767858]] | y: 0.6648585819449826 | Predicción actual: [[0.8601918]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.059101689606904984, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87060171]\n",
      " [0.86678439]\n",
      " [0.86413664]\n",
      " [0.86218333]\n",
      " [0.86146289]\n",
      " [0.68539326]\n",
      " [0.86767858]\n",
      " [0.86019182]] | y: 0.7078651685393258 | Predicción actual: [[0.8510592]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04319130629301071, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86678439]\n",
      " [0.86413664]\n",
      " [0.86218333]\n",
      " [0.86146289]\n",
      " [0.68539326]\n",
      " [0.86767858]\n",
      " [0.86019182]\n",
      " [0.8510592 ]] | y: 0.6648585819449826 | Predicción actual: [[0.8407489]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0314495712518692, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86413664]\n",
      " [0.86218333]\n",
      " [0.86146289]\n",
      " [0.68539326]\n",
      " [0.86767858]\n",
      " [0.86019182]\n",
      " [0.8510592 ]\n",
      " [0.84074891]] | y: 0.7113521890740022 | Predicción actual: [[0.8297844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013035554438829422, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86218333]\n",
      " [0.86146289]\n",
      " [0.68539326]\n",
      " [0.86767858]\n",
      " [0.86019182]\n",
      " [0.8510592 ]\n",
      " [0.84074891]\n",
      " [0.82978439]] | y: 0.6772568771793879 | Predicción actual: [[0.8184021]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012595667503774166, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86146289]\n",
      " [0.68539326]\n",
      " [0.86767858]\n",
      " [0.86019182]\n",
      " [0.8510592 ]\n",
      " [0.84074891]\n",
      " [0.82978439]\n",
      " [0.81840211]] | y: 0.7621077101898488 | Predicción actual: [[0.80676776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005828432040289044, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.86767858]\n",
      " [0.86019182]\n",
      " [0.8510592 ]\n",
      " [0.84074891]\n",
      " [0.82978439]\n",
      " [0.81840211]\n",
      " [0.80676776]] | y: 0.8070515304145678 | Predicción actual: [[0.79494447]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.2385868103592657e-05, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86767858]\n",
      " [0.86019182]\n",
      " [0.8510592 ]\n",
      " [0.84074891]\n",
      " [0.82978439]\n",
      " [0.81840211]\n",
      " [0.80676776]\n",
      " [0.79494447]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.255888001760468e-05, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86019182]\n",
      " [0.8510592 ]\n",
      " [0.84074891]\n",
      " [0.82978439]\n",
      " [0.81840211]\n",
      " [0.80676776]\n",
      " [0.79494447]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.82165575]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005868639796972275, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8510592 ]\n",
      " [0.84074891]\n",
      " [0.82978439]\n",
      " [0.81840211]\n",
      " [0.80676776]\n",
      " [0.79494447]\n",
      " [0.81518791]\n",
      " [0.82165575]] | y: 0.9597055404881829 | Predicción actual: [[0.81174475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00044037553016096354, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84074891]\n",
      " [0.82978439]\n",
      " [0.81840211]\n",
      " [0.80676776]\n",
      " [0.79494447]\n",
      " [0.81518791]\n",
      " [0.82165575]\n",
      " [0.81174475]] | y: 0.9643549012010848 | Predicción actual: [[0.80261]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00018745512352325022, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82978439]\n",
      " [0.81840211]\n",
      " [0.80676776]\n",
      " [0.79494447]\n",
      " [0.81518791]\n",
      " [0.82165575]\n",
      " [0.81174475]\n",
      " [0.80260998]] | y: 0.8880278961642774 | Predicción actual: [[0.79490757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011178668588399887, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81840211]\n",
      " [0.80676776]\n",
      " [0.79494447]\n",
      " [0.81518791]\n",
      " [0.82165575]\n",
      " [0.81174475]\n",
      " [0.80260998]\n",
      " [0.79490757]] | y: 0.8926772568771792 | Predicción actual: [[0.7893016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019757339730858803, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80676776]\n",
      " [0.79494447]\n",
      " [0.81518791]\n",
      " [0.82165575]\n",
      " [0.81174475]\n",
      " [0.80260998]\n",
      " [0.79490757]\n",
      " [0.78930157]] | y: 0.8752421542037967 | Predicción actual: [[0.7862158]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.523359767626971e-05, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79494447]\n",
      " [0.81518791]\n",
      " [0.82165575]\n",
      " [0.81174475]\n",
      " [0.80260998]\n",
      " [0.79490757]\n",
      " [0.78930157]\n",
      " [0.78621578]] | y: 0.8508330104610615 | Predicción actual: [[0.78566736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009596685878932476, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.82165575]\n",
      " [0.81174475]\n",
      " [0.80260998]\n",
      " [0.79490757]\n",
      " [0.78930157]\n",
      " [0.78621578]\n",
      " [0.78566736]] | y: 0.8488957768306855 | Predicción actual: [[0.7880309]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013325047679245472, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82165575]\n",
      " [0.81174475]\n",
      " [0.80260998]\n",
      " [0.79490757]\n",
      " [0.78930157]\n",
      " [0.78621578]\n",
      " [0.78566736]\n",
      " [0.78803092]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009374873712658882, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81174475]\n",
      " [0.80260998]\n",
      " [0.79490757]\n",
      " [0.78930157]\n",
      " [0.78621578]\n",
      " [0.78566736]\n",
      " [0.78803092]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.77953106]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08759775757789612, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80260998]\n",
      " [0.79490757]\n",
      " [0.78930157]\n",
      " [0.78621578]\n",
      " [0.78566736]\n",
      " [0.78803092]\n",
      " [0.96241767]\n",
      " [0.77953106]] | y: 0.9407206509104997 | Predicción actual: [[0.7776757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01635173335671425, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79490757]\n",
      " [0.78930157]\n",
      " [0.78621578]\n",
      " [0.78566736]\n",
      " [0.78803092]\n",
      " [0.96241767]\n",
      " [0.77953106]\n",
      " [0.77767569]] | y: 0.9724912824486633 | Predicción actual: [[0.77904284]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023919858038425446, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78930157]\n",
      " [0.78621578]\n",
      " [0.78566736]\n",
      " [0.78803092]\n",
      " [0.96241767]\n",
      " [0.77953106]\n",
      " [0.77767569]\n",
      " [0.77904284]] | y: 0.9969004261913985 | Predicción actual: [[0.78342396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07950272411108017, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78621578]\n",
      " [0.78566736]\n",
      " [0.78803092]\n",
      " [0.96241767]\n",
      " [0.77953106]\n",
      " [0.77767569]\n",
      " [0.77904284]\n",
      " [0.78342396]] | y: 0.951181712514529 | Predicción actual: [[0.79030186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006825398653745651, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78566736]\n",
      " [0.78803092]\n",
      " [0.96241767]\n",
      " [0.77953106]\n",
      " [0.77767569]\n",
      " [0.77904284]\n",
      " [0.78342396]\n",
      " [0.79030186]] | y: 0.8957768306857805 | Predicción actual: [[0.79843515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00014579715207219124, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78803092]\n",
      " [0.96241767]\n",
      " [0.77953106]\n",
      " [0.77767569]\n",
      " [0.77904284]\n",
      " [0.78342396]\n",
      " [0.79030186]\n",
      " [0.79843515]] | y: 0.8814413018209997 | Predicción actual: [[0.80660605]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08893220871686935, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.77953106]\n",
      " [0.77767569]\n",
      " [0.77904284]\n",
      " [0.78342396]\n",
      " [0.79030186]\n",
      " [0.79843515]\n",
      " [0.80660605]] | y: 0.9170864006199149 | Predicción actual: [[0.8140583]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00886521115899086, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77953106]\n",
      " [0.77767569]\n",
      " [0.77904284]\n",
      " [0.78342396]\n",
      " [0.79030186]\n",
      " [0.79843515]\n",
      " [0.80660605]\n",
      " [0.8140583 ]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013648411259055138, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77767569]\n",
      " [0.77904284]\n",
      " [0.78342396]\n",
      " [0.79030186]\n",
      " [0.79843515]\n",
      " [0.80660605]\n",
      " [0.8140583 ]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.77693903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06888481229543686, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77904284]\n",
      " [0.78342396]\n",
      " [0.79030186]\n",
      " [0.79843515]\n",
      " [0.80660605]\n",
      " [0.8140583 ]\n",
      " [0.91979853]\n",
      " [0.77693903]] | y: 0.9682293684618366 | Predicción actual: [[0.7842359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02990150824189186, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78342396]\n",
      " [0.79030186]\n",
      " [0.79843515]\n",
      " [0.80660605]\n",
      " [0.8140583 ]\n",
      " [0.91979853]\n",
      " [0.77693903]\n",
      " [0.78423589]] | y: 0.9577683068578069 | Predicción actual: [[0.7932306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10836857557296753, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.23022425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03833365812897682, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23022425]] | y: 0.10422316931421921 | Predicción actual: [[0.21567336]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02166871353983879, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23022425]\n",
      " [0.21567336]] | y: 0.15420379697791559 | Predicción actual: [[0.22017843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016960243228822947, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23022425]\n",
      " [0.21567336]\n",
      " [0.22017843]] | y: 0.1557535838822161 | Predicción actual: [[0.2321976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00391767080873251, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23022425]\n",
      " [0.21567336]\n",
      " [0.22017843]\n",
      " [0.2321976 ]] | y: 0.12553273924835334 | Predicción actual: [[0.2459749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022035585716366768, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23022425]\n",
      " [0.21567336]\n",
      " [0.22017843]\n",
      " [0.2321976 ]\n",
      " [0.2459749 ]] | y: 0.1456799690042619 | Predicción actual: [[0.2580062]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004168972373008728, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23022425]\n",
      " [0.21567336]\n",
      " [0.22017843]\n",
      " [0.2321976 ]\n",
      " [0.2459749 ]\n",
      " [0.25800619]] | y: 0.1464548624564122 | Predicción actual: [[0.28204423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01758388802409172, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.23022425]\n",
      " [0.21567336]\n",
      " [0.22017843]\n",
      " [0.2321976 ]\n",
      " [0.2459749 ]\n",
      " [0.25800619]\n",
      " [0.28204423]] | y: 0.1960480433940332 | Predicción actual: [[0.31195173]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02191389538347721, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23022425]\n",
      " [0.21567336]\n",
      " [0.22017843]\n",
      " [0.2321976 ]\n",
      " [0.2459749 ]\n",
      " [0.25800619]\n",
      " [0.28204423]\n",
      " [0.31195173]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032808516174554825, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21567336]\n",
      " [0.22017843]\n",
      " [0.2321976 ]\n",
      " [0.2459749 ]\n",
      " [0.25800619]\n",
      " [0.28204423]\n",
      " [0.31195173]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.35082185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03252260386943817, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22017843]\n",
      " [0.2321976 ]\n",
      " [0.2459749 ]\n",
      " [0.25800619]\n",
      " [0.28204423]\n",
      " [0.31195173]\n",
      " [0.2305308 ]\n",
      " [0.35082185]] | y: 0.211933359163115 | Predicción actual: [[0.3581811]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047687046229839325, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2321976 ]\n",
      " [0.2459749 ]\n",
      " [0.25800619]\n",
      " [0.28204423]\n",
      " [0.31195173]\n",
      " [0.2305308 ]\n",
      " [0.35082185]\n",
      " [0.35818109]] | y: 0.2072839984502131 | Predicción actual: [[0.36731473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032450199127197266, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2459749 ]\n",
      " [0.25800619]\n",
      " [0.28204423]\n",
      " [0.31195173]\n",
      " [0.2305308 ]\n",
      " [0.35082185]\n",
      " [0.35818109]\n",
      " [0.36731473]] | y: 0.19294846958543205 | Predicción actual: [[0.37709475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04133456572890282, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25800619]\n",
      " [0.28204423]\n",
      " [0.31195173]\n",
      " [0.2305308 ]\n",
      " [0.35082185]\n",
      " [0.35818109]\n",
      " [0.36731473]\n",
      " [0.37709475]] | y: 0.19682293684618352 | Predicción actual: [[0.38737056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05051855742931366, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28204423]\n",
      " [0.31195173]\n",
      " [0.2305308 ]\n",
      " [0.35082185]\n",
      " [0.35818109]\n",
      " [0.36731473]\n",
      " [0.37709475]\n",
      " [0.38737056]] | y: 0.21425803951956607 | Predicción actual: [[0.39867768]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03273286670446396, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31195173]\n",
      " [0.2305308 ]\n",
      " [0.35082185]\n",
      " [0.35818109]\n",
      " [0.36731473]\n",
      " [0.37709475]\n",
      " [0.38737056]\n",
      " [0.39867768]] | y: 0.18132506780317698 | Predicción actual: [[0.40840685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06038794666528702, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.35082185]\n",
      " [0.35818109]\n",
      " [0.36731473]\n",
      " [0.37709475]\n",
      " [0.38737056]\n",
      " [0.39867768]\n",
      " [0.40840685]] | y: 0.17512592018597434 | Predicción actual: [[0.4148373]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06063877046108246, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35082185]\n",
      " [0.35818109]\n",
      " [0.36731473]\n",
      " [0.37709475]\n",
      " [0.38737056]\n",
      " [0.39867768]\n",
      " [0.40840685]\n",
      " [0.4148373 ]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09320006519556046, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35818109]\n",
      " [0.36731473]\n",
      " [0.37709475]\n",
      " [0.38737056]\n",
      " [0.39867768]\n",
      " [0.40840685]\n",
      " [0.4148373 ]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.44809487]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05497989431023598, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36731473]\n",
      " [0.37709475]\n",
      " [0.38737056]\n",
      " [0.39867768]\n",
      " [0.40840685]\n",
      " [0.4148373 ]\n",
      " [0.14800465]\n",
      " [0.44809487]] | y: 0.19217357613328173 | Predicción actual: [[0.45111063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021435962989926338, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37709475]\n",
      " [0.38737056]\n",
      " [0.39867768]\n",
      " [0.40840685]\n",
      " [0.4148373 ]\n",
      " [0.14800465]\n",
      " [0.44809487]\n",
      " [0.45111063]] | y: 0.1859744285160791 | Predicción actual: [[0.45220098]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07646341621875763, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38737056]\n",
      " [0.39867768]\n",
      " [0.40840685]\n",
      " [0.4148373 ]\n",
      " [0.14800465]\n",
      " [0.44809487]\n",
      " [0.45111063]\n",
      " [0.45220098]] | y: 0.26695079426578844 | Predicción actual: [[0.45138606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046500034630298615, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39867768]\n",
      " [0.40840685]\n",
      " [0.4148373 ]\n",
      " [0.14800465]\n",
      " [0.44809487]\n",
      " [0.45111063]\n",
      " [0.45220098]\n",
      " [0.45138606]] | y: 0.2925222781867493 | Predicción actual: [[0.44900215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007080437615513802, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40840685]\n",
      " [0.4148373 ]\n",
      " [0.14800465]\n",
      " [0.44809487]\n",
      " [0.45111063]\n",
      " [0.45220098]\n",
      " [0.45138606]\n",
      " [0.44900215]] | y: 0.3177063153816349 | Predicción actual: [[0.4453378]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029812553897500038, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4148373 ]\n",
      " [0.14800465]\n",
      " [0.44809487]\n",
      " [0.45111063]\n",
      " [0.45220098]\n",
      " [0.45138606]\n",
      " [0.44900215]\n",
      " [0.4453378 ]] | y: 0.31266950794265785 | Predicción actual: [[0.4410506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026894642040133476, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.44809487]\n",
      " [0.45111063]\n",
      " [0.45220098]\n",
      " [0.45138606]\n",
      " [0.44900215]\n",
      " [0.4453378 ]\n",
      " [0.44105059]] | y: 0.2890352576520729 | Predicción actual: [[0.43719968]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009873058646917343, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44809487]\n",
      " [0.45111063]\n",
      " [0.45220098]\n",
      " [0.45138606]\n",
      " [0.44900215]\n",
      " [0.4453378 ]\n",
      " [0.44105059]\n",
      " [0.43719968]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04418899491429329, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45111063]\n",
      " [0.45220098]\n",
      " [0.45138606]\n",
      " [0.44900215]\n",
      " [0.4453378 ]\n",
      " [0.44105059]\n",
      " [0.43719968]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.49696618]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04313306882977486, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45220098]\n",
      " [0.45138606]\n",
      " [0.44900215]\n",
      " [0.4453378 ]\n",
      " [0.44105059]\n",
      " [0.43719968]\n",
      " [0.28283611]\n",
      " [0.49696618]] | y: 0.2758620689655173 | Predicción actual: [[0.49320757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0204706322401762, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45138606]\n",
      " [0.44900215]\n",
      " [0.4453378 ]\n",
      " [0.44105059]\n",
      " [0.43719968]\n",
      " [0.28283611]\n",
      " [0.49696618]\n",
      " [0.49320757]] | y: 0.2746997287872917 | Predicción actual: [[0.488264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02415473945438862, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44900215]\n",
      " [0.4453378 ]\n",
      " [0.44105059]\n",
      " [0.43719968]\n",
      " [0.28283611]\n",
      " [0.49696618]\n",
      " [0.49320757]\n",
      " [0.48826399]] | y: 0.275474622239442 | Predicción actual: [[0.48311415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05388834699988365, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4453378 ]\n",
      " [0.44105059]\n",
      " [0.43719968]\n",
      " [0.28283611]\n",
      " [0.49696618]\n",
      " [0.49320757]\n",
      " [0.48826399]\n",
      " [0.48311415]] | y: 0.3347539713289423 | Predicción actual: [[0.47872412]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02628609724342823, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44105059]\n",
      " [0.43719968]\n",
      " [0.28283611]\n",
      " [0.49696618]\n",
      " [0.49320757]\n",
      " [0.48826399]\n",
      " [0.48311415]\n",
      " [0.47872412]] | y: 0.35567609453700116 | Predicción actual: [[0.47608975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030330907553434372, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43719968]\n",
      " [0.28283611]\n",
      " [0.49696618]\n",
      " [0.49320757]\n",
      " [0.48826399]\n",
      " [0.48311415]\n",
      " [0.47872412]\n",
      " [0.47608975]] | y: 0.3366912049593181 | Predicción actual: [[0.47588435]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06392338871955872, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.49696618]\n",
      " [0.49320757]\n",
      " [0.48826399]\n",
      " [0.48311415]\n",
      " [0.47872412]\n",
      " [0.47608975]\n",
      " [0.47588435]] | y: 0.3335916311507167 | Predicción actual: [[0.4783277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02122117206454277, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49696618]\n",
      " [0.49320757]\n",
      " [0.48826399]\n",
      " [0.48311415]\n",
      " [0.47872412]\n",
      " [0.47608975]\n",
      " [0.47588435]\n",
      " [0.47832769]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025801309384405613, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49320757]\n",
      " [0.48826399]\n",
      " [0.48311415]\n",
      " [0.47872412]\n",
      " [0.47608975]\n",
      " [0.47588435]\n",
      " [0.47832769]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.51530397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004057369369547814, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48826399]\n",
      " [0.48311415]\n",
      " [0.47872412]\n",
      " [0.47608975]\n",
      " [0.47588435]\n",
      " [0.47832769]\n",
      " [0.3847346 ]\n",
      " [0.51530397]] | y: 0.5962805114296785 | Predicción actual: [[0.51052153]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014524975791573524, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48311415]\n",
      " [0.47872412]\n",
      " [0.47608975]\n",
      " [0.47588435]\n",
      " [0.47832769]\n",
      " [0.3847346 ]\n",
      " [0.51530397]\n",
      " [0.51052153]] | y: 0.574583494769469 | Predicción actual: [[0.5063095]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009364696219563484, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47872412]\n",
      " [0.47608975]\n",
      " [0.47588435]\n",
      " [0.47832769]\n",
      " [0.3847346 ]\n",
      " [0.51530397]\n",
      " [0.51052153]\n",
      " [0.50630951]] | y: 0.6063541263076326 | Predicción actual: [[0.50320214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024863351136446, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47608975]\n",
      " [0.47588435]\n",
      " [0.47832769]\n",
      " [0.3847346 ]\n",
      " [0.51530397]\n",
      " [0.51052153]\n",
      " [0.50630951]\n",
      " [0.50320214]] | y: 0.5846571096474236 | Predicción actual: [[0.5015694]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018648793920874596, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47588435]\n",
      " [0.47832769]\n",
      " [0.3847346 ]\n",
      " [0.51530397]\n",
      " [0.51052153]\n",
      " [0.50630951]\n",
      " [0.50320214]\n",
      " [0.50156939]] | y: 0.5687717938783416 | Predicción actual: [[0.5014168]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00028011068934574723, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47832769]\n",
      " [0.3847346 ]\n",
      " [0.51530397]\n",
      " [0.51052153]\n",
      " [0.50630951]\n",
      " [0.50320214]\n",
      " [0.50156939]\n",
      " [0.5014168 ]] | y: 0.6427741185586981 | Predicción actual: [[0.50240135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04062332957983017, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.51530397]\n",
      " [0.51052153]\n",
      " [0.50630951]\n",
      " [0.50320214]\n",
      " [0.50156939]\n",
      " [0.5014168 ]\n",
      " [0.50240135]] | y: 0.6617590081363811 | Predicción actual: [[0.5041618]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029450247064232826, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51530397]\n",
      " [0.51052153]\n",
      " [0.50630951]\n",
      " [0.50320214]\n",
      " [0.50156939]\n",
      " [0.5014168 ]\n",
      " [0.50240135]\n",
      " [0.50416178]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005565922241657972, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51052153]\n",
      " [0.50630951]\n",
      " [0.50320214]\n",
      " [0.50156939]\n",
      " [0.5014168 ]\n",
      " [0.50240135]\n",
      " [0.50416178]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5285742]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0065190973691642284, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50630951]\n",
      " [0.50320214]\n",
      " [0.50156939]\n",
      " [0.5014168 ]\n",
      " [0.50240135]\n",
      " [0.50416178]\n",
      " [0.67299496]\n",
      " [0.52857423]] | y: 0.703990701278574 | Predicción actual: [[0.52954394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05240714177489281, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50320214]\n",
      " [0.50156939]\n",
      " [0.5014168 ]\n",
      " [0.50240135]\n",
      " [0.50416178]\n",
      " [0.67299496]\n",
      " [0.52857423]\n",
      " [0.52954394]] | y: 0.7272375048430839 | Predicción actual: [[0.53320265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015532214194536209, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50156939]\n",
      " [0.5014168 ]\n",
      " [0.50240135]\n",
      " [0.50416178]\n",
      " [0.67299496]\n",
      " [0.52857423]\n",
      " [0.52954394]\n",
      " [0.53320265]] | y: 0.722588144130182 | Predicción actual: [[0.53945863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020165765658020973, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5014168 ]\n",
      " [0.50240135]\n",
      " [0.50416178]\n",
      " [0.67299496]\n",
      " [0.52857423]\n",
      " [0.52954394]\n",
      " [0.53320265]\n",
      " [0.53945863]] | y: 0.771793878341728 | Predicción actual: [[0.5480115]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11116830259561539, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50240135]\n",
      " [0.50416178]\n",
      " [0.67299496]\n",
      " [0.52857423]\n",
      " [0.52954394]\n",
      " [0.53320265]\n",
      " [0.53945863]\n",
      " [0.54801148]] | y: 0.7245253777605578 | Predicción actual: [[0.55850613]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04651552438735962, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50416178]\n",
      " [0.67299496]\n",
      " [0.52857423]\n",
      " [0.52954394]\n",
      " [0.53320265]\n",
      " [0.53945863]\n",
      " [0.54801148]\n",
      " [0.55850613]] | y: 0.6710577295621851 | Predicción actual: [[0.570458]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012954032979905605, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.52857423]\n",
      " [0.52954394]\n",
      " [0.53320265]\n",
      " [0.53945863]\n",
      " [0.54801148]\n",
      " [0.55850613]\n",
      " [0.57045799]] | y: 0.6737698566447115 | Predicción actual: [[0.5834441]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004231265338603407, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52857423]\n",
      " [0.52954394]\n",
      " [0.53320265]\n",
      " [0.53945863]\n",
      " [0.54801148]\n",
      " [0.55850613]\n",
      " [0.57045799]\n",
      " [0.58344412]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033078205306082964, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52954394]\n",
      " [0.53320265]\n",
      " [0.53945863]\n",
      " [0.54801148]\n",
      " [0.55850613]\n",
      " [0.57045799]\n",
      " [0.58344412]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.56076753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02687535062432289, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53320265]\n",
      " [0.53945863]\n",
      " [0.54801148]\n",
      " [0.55850613]\n",
      " [0.57045799]\n",
      " [0.58344412]\n",
      " [0.71445176]\n",
      " [0.56076753]] | y: 0.722588144130182 | Predicción actual: [[0.5689358]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020743638277053833, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53945863]\n",
      " [0.54801148]\n",
      " [0.55850613]\n",
      " [0.57045799]\n",
      " [0.58344412]\n",
      " [0.71445176]\n",
      " [0.56076753]\n",
      " [0.56893581]] | y: 0.6993413405656723 | Predicción actual: [[0.579027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039874400943517685, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54801148]\n",
      " [0.55850613]\n",
      " [0.57045799]\n",
      " [0.58344412]\n",
      " [0.71445176]\n",
      " [0.56076753]\n",
      " [0.56893581]\n",
      " [0.579027  ]] | y: 0.7373111197210385 | Predicción actual: [[0.5901787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02595592848956585, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55850613]\n",
      " [0.57045799]\n",
      " [0.58344412]\n",
      " [0.71445176]\n",
      " [0.56076753]\n",
      " [0.56893581]\n",
      " [0.579027  ]\n",
      " [0.59017873]] | y: 0.7214258039519565 | Predicción actual: [[0.601359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.898207397578517e-07, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57045799]\n",
      " [0.58344412]\n",
      " [0.71445176]\n",
      " [0.56076753]\n",
      " [0.56893581]\n",
      " [0.579027  ]\n",
      " [0.59017873]\n",
      " [0.60135901]] | y: 0.7187136768694304 | Predicción actual: [[0.61139804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021808233577758074, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58344412]\n",
      " [0.71445176]\n",
      " [0.56076753]\n",
      " [0.56893581]\n",
      " [0.579027  ]\n",
      " [0.59017873]\n",
      " [0.60135901]\n",
      " [0.61139804]] | y: 0.6741573033707864 | Predicción actual: [[0.6194508]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017480969429016113, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56076753]\n",
      " [0.56893581]\n",
      " [0.579027  ]\n",
      " [0.59017873]\n",
      " [0.60135901]\n",
      " [0.61139804]\n",
      " [0.61945081]] | y: 0.698566447113522 | Predicción actual: [[0.6248616]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013722527073696256, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56076753]\n",
      " [0.56893581]\n",
      " [0.579027  ]\n",
      " [0.59017873]\n",
      " [0.60135901]\n",
      " [0.61139804]\n",
      " [0.61945081]\n",
      " [0.6248616 ]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0193986427038908, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56893581]\n",
      " [0.579027  ]\n",
      " [0.59017873]\n",
      " [0.60135901]\n",
      " [0.61139804]\n",
      " [0.61945081]\n",
      " [0.6248616 ]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6058709]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021979920566082, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.579027  ]\n",
      " [0.59017873]\n",
      " [0.60135901]\n",
      " [0.61139804]\n",
      " [0.61945081]\n",
      " [0.6248616 ]\n",
      " [0.72103836]\n",
      " [0.6058709 ]] | y: 0.7562960092987214 | Predicción actual: [[0.61603016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008441435173153877, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59017873]\n",
      " [0.60135901]\n",
      " [0.61139804]\n",
      " [0.61945081]\n",
      " [0.6248616 ]\n",
      " [0.72103836]\n",
      " [0.6058709 ]\n",
      " [0.61603016]] | y: 0.8275862068965516 | Predicción actual: [[0.6263344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11521045863628387, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60135901]\n",
      " [0.61139804]\n",
      " [0.61945081]\n",
      " [0.6248616 ]\n",
      " [0.72103836]\n",
      " [0.6058709 ]\n",
      " [0.61603016]\n",
      " [0.62633443]] | y: 0.8388221619527314 | Predicción actual: [[0.63620913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03643924742937088, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61139804]\n",
      " [0.61945081]\n",
      " [0.6248616 ]\n",
      " [0.72103836]\n",
      " [0.6058709 ]\n",
      " [0.61603016]\n",
      " [0.62633443]\n",
      " [0.63620913]] | y: 0.7942657884540876 | Predicción actual: [[0.64500964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047171998769044876, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61945081]\n",
      " [0.6248616 ]\n",
      " [0.72103836]\n",
      " [0.6058709 ]\n",
      " [0.61603016]\n",
      " [0.62633443]\n",
      " [0.63620913]\n",
      " [0.64500964]] | y: 0.7838047268500579 | Predicción actual: [[0.65250486]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01183214783668518, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6248616 ]\n",
      " [0.72103836]\n",
      " [0.6058709 ]\n",
      " [0.61603016]\n",
      " [0.62633443]\n",
      " [0.63620913]\n",
      " [0.64500964]\n",
      " [0.65250486]] | y: 0.7679194110809764 | Predicción actual: [[0.65872514]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028406957164406776, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.6058709 ]\n",
      " [0.61603016]\n",
      " [0.62633443]\n",
      " [0.63620913]\n",
      " [0.64500964]\n",
      " [0.65250486]\n",
      " [0.65872514]] | y: 0.7845796203022084 | Predicción actual: [[0.6641832]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02287144400179386, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6058709 ]\n",
      " [0.61603016]\n",
      " [0.62633443]\n",
      " [0.63620913]\n",
      " [0.64500964]\n",
      " [0.65250486]\n",
      " [0.65872514]\n",
      " [0.6641832 ]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0461837574839592, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61603016]\n",
      " [0.62633443]\n",
      " [0.63620913]\n",
      " [0.64500964]\n",
      " [0.65250486]\n",
      " [0.65872514]\n",
      " [0.6641832 ]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.65513235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06251424551010132, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62633443]\n",
      " [0.63620913]\n",
      " [0.64500964]\n",
      " [0.65250486]\n",
      " [0.65872514]\n",
      " [0.6641832 ]\n",
      " [0.87872917]\n",
      " [0.65513235]] | y: 0.8488957768306855 | Predicción actual: [[0.6672215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050533320754766464, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63620913]\n",
      " [0.64500964]\n",
      " [0.65250486]\n",
      " [0.65872514]\n",
      " [0.6641832 ]\n",
      " [0.87872917]\n",
      " [0.65513235]\n",
      " [0.66722149]] | y: 0.8182874854707476 | Predicción actual: [[0.6804441]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.186819468392059e-05, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64500964]\n",
      " [0.65250486]\n",
      " [0.65872514]\n",
      " [0.6641832 ]\n",
      " [0.87872917]\n",
      " [0.65513235]\n",
      " [0.66722149]\n",
      " [0.68044412]] | y: 0.8268113134444013 | Predicción actual: [[0.69421667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01521008275449276, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65250486]\n",
      " [0.65872514]\n",
      " [0.6641832 ]\n",
      " [0.87872917]\n",
      " [0.65513235]\n",
      " [0.66722149]\n",
      " [0.68044412]\n",
      " [0.69421667]] | y: 0.7853545137543589 | Predicción actual: [[0.7084057]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012551235035061836, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65872514]\n",
      " [0.6641832 ]\n",
      " [0.87872917]\n",
      " [0.65513235]\n",
      " [0.66722149]\n",
      " [0.68044412]\n",
      " [0.69421667]\n",
      " [0.70840567]] | y: 0.7892289810151103 | Predicción actual: [[0.7227715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011623301543295383, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6641832 ]\n",
      " [0.87872917]\n",
      " [0.65513235]\n",
      " [0.66722149]\n",
      " [0.68044412]\n",
      " [0.69421667]\n",
      " [0.70840567]\n",
      " [0.72277153]] | y: 0.8341728012398295 | Predicción actual: [[0.73698467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010077018290758133, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.65513235]\n",
      " [0.66722149]\n",
      " [0.68044412]\n",
      " [0.69421667]\n",
      " [0.70840567]\n",
      " [0.72277153]\n",
      " [0.73698467]] | y: 0.8124757845796202 | Predicción actual: [[0.7511326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.950776878511533e-06, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65513235]\n",
      " [0.66722149]\n",
      " [0.68044412]\n",
      " [0.69421667]\n",
      " [0.70840567]\n",
      " [0.72277153]\n",
      " [0.73698467]\n",
      " [0.75113261]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031837576534599066, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66722149]\n",
      " [0.68044412]\n",
      " [0.69421667]\n",
      " [0.70840567]\n",
      " [0.72277153]\n",
      " [0.73698467]\n",
      " [0.75113261]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.71893114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017760766204446554, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68044412]\n",
      " [0.69421667]\n",
      " [0.70840567]\n",
      " [0.72277153]\n",
      " [0.73698467]\n",
      " [0.75113261]\n",
      " [0.80123983]\n",
      " [0.71893114]] | y: 0.793490895001937 | Predicción actual: [[0.732619]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.207501716446131e-05, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69421667]\n",
      " [0.70840567]\n",
      " [0.72277153]\n",
      " [0.73698467]\n",
      " [0.75113261]\n",
      " [0.80123983]\n",
      " [0.71893114]\n",
      " [0.73261899]] | y: 0.760170476559473 | Predicción actual: [[0.745948]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006676370394416153, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70840567]\n",
      " [0.72277153]\n",
      " [0.73698467]\n",
      " [0.75113261]\n",
      " [0.80123983]\n",
      " [0.71893114]\n",
      " [0.73261899]\n",
      " [0.74594802]] | y: 0.7353738860906625 | Predicción actual: [[0.7581124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030524324625730515, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72277153]\n",
      " [0.73698467]\n",
      " [0.75113261]\n",
      " [0.80123983]\n",
      " [0.71893114]\n",
      " [0.73261899]\n",
      " [0.74594802]\n",
      " [0.75811237]] | y: 0.7101898488957767 | Predicción actual: [[0.76807123]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003041591728106141, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73698467]\n",
      " [0.75113261]\n",
      " [0.80123983]\n",
      " [0.71893114]\n",
      " [0.73261899]\n",
      " [0.74594802]\n",
      " [0.75811237]\n",
      " [0.76807123]] | y: 0.7121270825261525 | Predicción actual: [[0.77561826]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015582605265080929, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75113261]\n",
      " [0.80123983]\n",
      " [0.71893114]\n",
      " [0.73261899]\n",
      " [0.74594802]\n",
      " [0.75811237]\n",
      " [0.76807123]\n",
      " [0.77561826]] | y: 0.7396358000774894 | Predicción actual: [[0.7800082]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.2774426068062894e-05, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.71893114]\n",
      " [0.73261899]\n",
      " [0.74594802]\n",
      " [0.75811237]\n",
      " [0.76807123]\n",
      " [0.77561826]\n",
      " [0.7800082 ]] | y: 0.7361487795428128 | Predicción actual: [[0.7811506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006857464089989662, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71893114]\n",
      " [0.73261899]\n",
      " [0.74594802]\n",
      " [0.75811237]\n",
      " [0.76807123]\n",
      " [0.77561826]\n",
      " [0.7800082 ]\n",
      " [0.78115058]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03016464225947857, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73261899]\n",
      " [0.74594802]\n",
      " [0.75811237]\n",
      " [0.76807123]\n",
      " [0.77561826]\n",
      " [0.7800082 ]\n",
      " [0.78115058]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.7782236]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03556443005800247, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74594802]\n",
      " [0.75811237]\n",
      " [0.76807123]\n",
      " [0.77561826]\n",
      " [0.7800082 ]\n",
      " [0.78115058]\n",
      " [0.66757071]\n",
      " [0.77822357]] | y: 0.696629213483146 | Predicción actual: [[0.78508896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005520859267562628, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75811237]\n",
      " [0.76807123]\n",
      " [0.77561826]\n",
      " [0.7800082 ]\n",
      " [0.78115058]\n",
      " [0.66757071]\n",
      " [0.77822357]\n",
      " [0.78508896]] | y: 0.6559473072452537 | Predicción actual: [[0.78897274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06007615476846695, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76807123]\n",
      " [0.77561826]\n",
      " [0.7800082 ]\n",
      " [0.78115058]\n",
      " [0.66757071]\n",
      " [0.77822357]\n",
      " [0.78508896]\n",
      " [0.78897274]] | y: 0.6788066640836885 | Predicción actual: [[0.7893654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014743098057806492, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77561826]\n",
      " [0.7800082 ]\n",
      " [0.78115058]\n",
      " [0.66757071]\n",
      " [0.77822357]\n",
      " [0.78508896]\n",
      " [0.78897274]\n",
      " [0.78936541]] | y: 0.6760945370011622 | Predicción actual: [[0.7870292]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00970888789743185, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7800082 ]\n",
      " [0.78115058]\n",
      " [0.66757071]\n",
      " [0.77822357]\n",
      " [0.78508896]\n",
      " [0.78897274]\n",
      " [0.78936541]\n",
      " [0.78702921]] | y: 0.7295621851995349 | Predicción actual: [[0.78272897]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028638888616114855, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78115058]\n",
      " [0.66757071]\n",
      " [0.77822357]\n",
      " [0.78508896]\n",
      " [0.78897274]\n",
      " [0.78936541]\n",
      " [0.78702921]\n",
      " [0.78272897]] | y: 0.7012785741960481 | Predicción actual: [[0.77759093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005388972931541502, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.77822357]\n",
      " [0.78508896]\n",
      " [0.78897274]\n",
      " [0.78936541]\n",
      " [0.78702921]\n",
      " [0.78272897]\n",
      " [0.77759093]] | y: 0.767531964354901 | Predicción actual: [[0.7728774]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012561120092868805, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77822357]\n",
      " [0.78508896]\n",
      " [0.78897274]\n",
      " [0.78936541]\n",
      " [0.78702921]\n",
      " [0.78272897]\n",
      " [0.77759093]\n",
      " [0.7728774 ]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.152798934839666e-05, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78508896]\n",
      " [0.78897274]\n",
      " [0.78936541]\n",
      " [0.78702921]\n",
      " [0.78272897]\n",
      " [0.77759093]\n",
      " [0.7728774 ]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8025455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01370490062981844, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78897274]\n",
      " [0.78936541]\n",
      " [0.78702921]\n",
      " [0.78272897]\n",
      " [0.77759093]\n",
      " [0.7728774 ]\n",
      " [0.75513367]\n",
      " [0.80254549]] | y: 0.7520340953118947 | Predicción actual: [[0.80113614]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00039947728510014713, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78936541]\n",
      " [0.78702921]\n",
      " [0.78272897]\n",
      " [0.77759093]\n",
      " [0.7728774 ]\n",
      " [0.75513367]\n",
      " [0.80254549]\n",
      " [0.80113614]] | y: 0.7098024021697016 | Predicción actual: [[0.79841834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05424477905035019, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78702921]\n",
      " [0.78272897]\n",
      " [0.77759093]\n",
      " [0.7728774 ]\n",
      " [0.75513367]\n",
      " [0.80254549]\n",
      " [0.80113614]\n",
      " [0.79841834]] | y: 0.6904300658659435 | Predicción actual: [[0.7950491]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029972461983561516, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78272897]\n",
      " [0.77759093]\n",
      " [0.7728774 ]\n",
      " [0.75513367]\n",
      " [0.80254549]\n",
      " [0.80113614]\n",
      " [0.79841834]\n",
      " [0.79504907]] | y: 0.7543587756683454 | Predicción actual: [[0.79225004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014991709031164646, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77759093]\n",
      " [0.7728774 ]\n",
      " [0.75513367]\n",
      " [0.80254549]\n",
      " [0.80113614]\n",
      " [0.79841834]\n",
      " [0.79504907]\n",
      " [0.79225004]] | y: 0.7222006974041069 | Predicción actual: [[0.7909822]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011066260747611523, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7728774 ]\n",
      " [0.75513367]\n",
      " [0.80254549]\n",
      " [0.80113614]\n",
      " [0.79841834]\n",
      " [0.79504907]\n",
      " [0.79225004]\n",
      " [0.79098219]] | y: 0.8485083301046106 | Predicción actual: [[0.79179335]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020151125267148018, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.80254549]\n",
      " [0.80113614]\n",
      " [0.79841834]\n",
      " [0.79504907]\n",
      " [0.79225004]\n",
      " [0.79098219]\n",
      " [0.79179335]] | y: 0.9054629988376597 | Predicción actual: [[0.7946271]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016002735123038292, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80254549]\n",
      " [0.80113614]\n",
      " [0.79841834]\n",
      " [0.79504907]\n",
      " [0.79225004]\n",
      " [0.79098219]\n",
      " [0.79179335]\n",
      " [0.79462707]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005242264596745372, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80113614]\n",
      " [0.79841834]\n",
      " [0.79504907]\n",
      " [0.79225004]\n",
      " [0.79098219]\n",
      " [0.79179335]\n",
      " [0.79462707]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.80143195]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.916132532642223e-07, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79841834]\n",
      " [0.79504907]\n",
      " [0.79225004]\n",
      " [0.79098219]\n",
      " [0.79179335]\n",
      " [0.79462707]\n",
      " [0.8822162 ]\n",
      " [0.80143195]] | y: 0.889577683068578 | Predicción actual: [[0.79999596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004094178322702646, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79504907]\n",
      " [0.79225004]\n",
      " [0.79098219]\n",
      " [0.79179335]\n",
      " [0.79462707]\n",
      " [0.8822162 ]\n",
      " [0.80143195]\n",
      " [0.79999596]] | y: 0.8748547074777218 | Predicción actual: [[0.80020833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016819979064166546, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79225004]\n",
      " [0.79098219]\n",
      " [0.79179335]\n",
      " [0.79462707]\n",
      " [0.8822162 ]\n",
      " [0.80143195]\n",
      " [0.79999596]\n",
      " [0.80020833]] | y: 0.9132119333591631 | Predicción actual: [[0.8023135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03669120371341705, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79098219]\n",
      " [0.79179335]\n",
      " [0.79462707]\n",
      " [0.8822162 ]\n",
      " [0.80143195]\n",
      " [0.79999596]\n",
      " [0.80020833]\n",
      " [0.80231351]] | y: 1.0 | Predicción actual: [[0.80638945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040960751473903656, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79179335]\n",
      " [0.79462707]\n",
      " [0.8822162 ]\n",
      " [0.80143195]\n",
      " [0.79999596]\n",
      " [0.80020833]\n",
      " [0.80231351]\n",
      " [0.80638945]] | y: 0.9705540488182873 | Predicción actual: [[0.81194746]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07432498782873154, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79462707]\n",
      " [0.8822162 ]\n",
      " [0.80143195]\n",
      " [0.79999596]\n",
      " [0.80020833]\n",
      " [0.80231351]\n",
      " [0.80638945]\n",
      " [0.81194746]] | y: 0.8888027896164277 | Predicción actual: [[0.8182639]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029561098664999008, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.80143195]\n",
      " [0.79999596]\n",
      " [0.80020833]\n",
      " [0.80231351]\n",
      " [0.80638945]\n",
      " [0.81194746]\n",
      " [0.81826389]] | y: 0.877954281286323 | Predicción actual: [[0.8243843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002116669638780877, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80143195]\n",
      " [0.79999596]\n",
      " [0.80020833]\n",
      " [0.80231351]\n",
      " [0.80638945]\n",
      " [0.81194746]\n",
      " [0.81826389]\n",
      " [0.82438427]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005942228715866804, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79999596]\n",
      " [0.80020833]\n",
      " [0.80231351]\n",
      " [0.80638945]\n",
      " [0.81194746]\n",
      " [0.81826389]\n",
      " [0.82438427]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.80769783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011318399338051677, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80020833]\n",
      " [0.80231351]\n",
      " [0.80638945]\n",
      " [0.81194746]\n",
      " [0.81826389]\n",
      " [0.82438427]\n",
      " [0.84889578]\n",
      " [0.80769783]] | y: 0.8550949244478885 | Predicción actual: [[0.811297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020523548126220703, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80231351]\n",
      " [0.80638945]\n",
      " [0.81194746]\n",
      " [0.81826389]\n",
      " [0.82438427]\n",
      " [0.84889578]\n",
      " [0.80769783]\n",
      " [0.811297  ]] | y: 0.8752421542037967 | Predicción actual: [[0.8159965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003343175631016493, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80638945]\n",
      " [0.81194746]\n",
      " [0.81826389]\n",
      " [0.82438427]\n",
      " [0.84889578]\n",
      " [0.80769783]\n",
      " [0.811297  ]\n",
      " [0.81599653]] | y: 0.857032158078264 | Predicción actual: [[0.8210318]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002003045752644539, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81194746]\n",
      " [0.81826389]\n",
      " [0.82438427]\n",
      " [0.84889578]\n",
      " [0.80769783]\n",
      " [0.811297  ]\n",
      " [0.81599653]\n",
      " [0.82103181]] | y: 0.8500581170089112 | Predicción actual: [[0.8256275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.4536594941746444e-05, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81826389]\n",
      " [0.82438427]\n",
      " [0.84889578]\n",
      " [0.80769783]\n",
      " [0.811297  ]\n",
      " [0.81599653]\n",
      " [0.82103181]\n",
      " [0.82562751]] | y: 0.8426966292134832 | Predicción actual: [[0.82904935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025678537786006927, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82438427]\n",
      " [0.84889578]\n",
      " [0.80769783]\n",
      " [0.811297  ]\n",
      " [0.81599653]\n",
      " [0.82103181]\n",
      " [0.82562751]\n",
      " [0.82904935]] | y: 0.8229368461836497 | Predicción actual: [[0.83046573]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027435166761279106, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.80769783]\n",
      " [0.811297  ]\n",
      " [0.81599653]\n",
      " [0.82103181]\n",
      " [0.82562751]\n",
      " [0.82904935]\n",
      " [0.83046573]] | y: 0.7745060054242543 | Predicción actual: [[0.8304076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00827464833855629, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80769783]\n",
      " [0.811297  ]\n",
      " [0.81599653]\n",
      " [0.82103181]\n",
      " [0.82562751]\n",
      " [0.82904935]\n",
      " [0.83046573]\n",
      " [0.83040762]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00991353951394558, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.811297  ]\n",
      " [0.81599653]\n",
      " [0.82103181]\n",
      " [0.82562751]\n",
      " [0.82904935]\n",
      " [0.83046573]\n",
      " [0.83040762]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8268124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006228583864867687, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81599653]\n",
      " [0.82103181]\n",
      " [0.82562751]\n",
      " [0.82904935]\n",
      " [0.83046573]\n",
      " [0.83040762]\n",
      " [0.78419217]\n",
      " [0.82681239]] | y: 0.854320030995738 | Predicción actual: [[0.83018667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018512854585424066, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82103181]\n",
      " [0.82562751]\n",
      " [0.82904935]\n",
      " [0.83046573]\n",
      " [0.83040762]\n",
      " [0.78419217]\n",
      " [0.82681239]\n",
      " [0.83018667]] | y: 0.8368849283223556 | Predicción actual: [[0.8325388]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013512122677639127, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82562751]\n",
      " [0.82904935]\n",
      " [0.83046573]\n",
      " [0.83040762]\n",
      " [0.78419217]\n",
      " [0.82681239]\n",
      " [0.83018667]\n",
      " [0.83253878]] | y: 0.8299108872530028 | Predicción actual: [[0.83359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008744720253162086, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82904935]\n",
      " [0.83046573]\n",
      " [0.83040762]\n",
      " [0.78419217]\n",
      " [0.82681239]\n",
      " [0.83018667]\n",
      " [0.83253878]\n",
      " [0.83358997]] | y: 0.887253002712127 | Predicción actual: [[0.8332438]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016524523962289095, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83046573]\n",
      " [0.83040762]\n",
      " [0.78419217]\n",
      " [0.82681239]\n",
      " [0.83018667]\n",
      " [0.83253878]\n",
      " [0.83358997]\n",
      " [0.83324379]] | y: 0.8597442851607902 | Predicción actual: [[0.8319751]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004414406605064869, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83040762]\n",
      " [0.78419217]\n",
      " [0.82681239]\n",
      " [0.83018667]\n",
      " [0.83253878]\n",
      " [0.83358997]\n",
      " [0.83324379]\n",
      " [0.8319751 ]] | y: 0.8395970554048819 | Predicción actual: [[0.8304693]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000640411046333611, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.82681239]\n",
      " [0.83018667]\n",
      " [0.83253878]\n",
      " [0.83358997]\n",
      " [0.83324379]\n",
      " [0.8319751 ]\n",
      " [0.83046931]] | y: 0.7838047268500579 | Predicción actual: [[0.8291104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0044075739569962025, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82681239]\n",
      " [0.83018667]\n",
      " [0.83253878]\n",
      " [0.83358997]\n",
      " [0.83324379]\n",
      " [0.8319751 ]\n",
      " [0.83046931]\n",
      " [0.82911038]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002902923384681344, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83018667]\n",
      " [0.83253878]\n",
      " [0.83358997]\n",
      " [0.83324379]\n",
      " [0.8319751 ]\n",
      " [0.83046931]\n",
      " [0.82911038]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8430152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005710480734705925, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83253878]\n",
      " [0.83358997]\n",
      " [0.83324379]\n",
      " [0.8319751 ]\n",
      " [0.83046931]\n",
      " [0.82911038]\n",
      " [0.81828749]\n",
      " [0.84301519]] | y: 0.7605579232855482 | Predicción actual: [[0.8435375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012552036787383258, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83358997]\n",
      " [0.83324379]\n",
      " [0.8319751 ]\n",
      " [0.83046931]\n",
      " [0.82911038]\n",
      " [0.81828749]\n",
      " [0.84301519]\n",
      " [0.84353751]] | y: 0.7915536613715615 | Predicción actual: [[0.84343266]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07704600691795349, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83324379]\n",
      " [0.8319751 ]\n",
      " [0.83046931]\n",
      " [0.82911038]\n",
      " [0.81828749]\n",
      " [0.84301519]\n",
      " [0.84353751]\n",
      " [0.84343266]] | y: 0.7686943045331267 | Predicción actual: [[0.84241486]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0065298243425786495, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8319751 ]\n",
      " [0.83046931]\n",
      " [0.82911038]\n",
      " [0.81828749]\n",
      " [0.84301519]\n",
      " [0.84353751]\n",
      " [0.84343266]\n",
      " [0.84241486]] | y: 0.7686943045331267 | Predicción actual: [[0.8418993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007734180544503033, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83046931]\n",
      " [0.82911038]\n",
      " [0.81828749]\n",
      " [0.84301519]\n",
      " [0.84353751]\n",
      " [0.84343266]\n",
      " [0.84241486]\n",
      " [0.84189928]] | y: 0.7989151491669895 | Predicción actual: [[0.8421958]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011003135296050459, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82911038]\n",
      " [0.81828749]\n",
      " [0.84301519]\n",
      " [0.84353751]\n",
      " [0.84343266]\n",
      " [0.84241486]\n",
      " [0.84189928]\n",
      " [0.84219581]] | y: 0.7900038744672608 | Predicción actual: [[0.8434797]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02649020217359066, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.84301519]\n",
      " [0.84353751]\n",
      " [0.84343266]\n",
      " [0.84241486]\n",
      " [0.84189928]\n",
      " [0.84219581]\n",
      " [0.84347969]] | y: 0.760170476559473 | Predicción actual: [[0.8460338]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.56599980982719e-05, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84301519]\n",
      " [0.84353751]\n",
      " [0.84343266]\n",
      " [0.84241486]\n",
      " [0.84189928]\n",
      " [0.84219581]\n",
      " [0.84347969]\n",
      " [0.84603381]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08459749072790146, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84353751]\n",
      " [0.84343266]\n",
      " [0.84241486]\n",
      " [0.84189928]\n",
      " [0.84219581]\n",
      " [0.84347969]\n",
      " [0.84603381]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.85073906]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024391324259340763, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84343266]\n",
      " [0.84241486]\n",
      " [0.84189928]\n",
      " [0.84219581]\n",
      " [0.84347969]\n",
      " [0.84603381]\n",
      " [0.68539326]\n",
      " [0.85073906]] | y: 0.6648585819449826 | Predicción actual: [[0.8475521]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042177844792604446, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84241486]\n",
      " [0.84189928]\n",
      " [0.84219581]\n",
      " [0.84347969]\n",
      " [0.84603381]\n",
      " [0.68539326]\n",
      " [0.85073906]\n",
      " [0.84755212]] | y: 0.7078651685393258 | Predicción actual: [[0.8425968]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020501915365457535, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84189928]\n",
      " [0.84219581]\n",
      " [0.84347969]\n",
      " [0.84603381]\n",
      " [0.68539326]\n",
      " [0.85073906]\n",
      " [0.84755212]\n",
      " [0.84259683]] | y: 0.6648585819449826 | Predicción actual: [[0.8364845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09014823287725449, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84219581]\n",
      " [0.84347969]\n",
      " [0.84603381]\n",
      " [0.68539326]\n",
      " [0.85073906]\n",
      " [0.84755212]\n",
      " [0.84259683]\n",
      " [0.83648449]] | y: 0.7113521890740022 | Predicción actual: [[0.829051]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004342295229434967, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84347969]\n",
      " [0.84603381]\n",
      " [0.68539326]\n",
      " [0.85073906]\n",
      " [0.84755212]\n",
      " [0.84259683]\n",
      " [0.83648449]\n",
      " [0.82905102]] | y: 0.6772568771793879 | Predicción actual: [[0.82101554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019580457359552383, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84603381]\n",
      " [0.68539326]\n",
      " [0.85073906]\n",
      " [0.84755212]\n",
      " [0.84259683]\n",
      " [0.83648449]\n",
      " [0.82905102]\n",
      " [0.82101554]] | y: 0.7621077101898488 | Predicción actual: [[0.8122787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01768670603632927, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.85073906]\n",
      " [0.84755212]\n",
      " [0.84259683]\n",
      " [0.83648449]\n",
      " [0.82905102]\n",
      " [0.82101554]\n",
      " [0.81227869]] | y: 0.8070515304145678 | Predicción actual: [[0.80271757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004531033802777529, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85073906]\n",
      " [0.84755212]\n",
      " [0.84259683]\n",
      " [0.83648449]\n",
      " [0.82905102]\n",
      " [0.82101554]\n",
      " [0.81227869]\n",
      " [0.80271757]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02437645196914673, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84755212]\n",
      " [0.84259683]\n",
      " [0.83648449]\n",
      " [0.82905102]\n",
      " [0.82101554]\n",
      " [0.81227869]\n",
      " [0.80271757]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.832699]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003657924011349678, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84259683]\n",
      " [0.83648449]\n",
      " [0.82905102]\n",
      " [0.82101554]\n",
      " [0.81227869]\n",
      " [0.80271757]\n",
      " [0.81518791]\n",
      " [0.832699  ]] | y: 0.9597055404881829 | Predicción actual: [[0.8260754]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05886764079332352, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83648449]\n",
      " [0.82905102]\n",
      " [0.82101554]\n",
      " [0.81227869]\n",
      " [0.80271757]\n",
      " [0.81518791]\n",
      " [0.832699  ]\n",
      " [0.82607538]] | y: 0.9643549012010848 | Predicción actual: [[0.8201413]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07145369052886963, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82905102]\n",
      " [0.82101554]\n",
      " [0.81227869]\n",
      " [0.80271757]\n",
      " [0.81518791]\n",
      " [0.832699  ]\n",
      " [0.82607538]\n",
      " [0.82014132]] | y: 0.8880278961642774 | Predicción actual: [[0.8155073]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007691605133004487, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82101554]\n",
      " [0.81227869]\n",
      " [0.80271757]\n",
      " [0.81518791]\n",
      " [0.832699  ]\n",
      " [0.82607538]\n",
      " [0.82014132]\n",
      " [0.81550729]] | y: 0.8926772568771792 | Predicción actual: [[0.8123671]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0058951531536877155, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81227869]\n",
      " [0.80271757]\n",
      " [0.81518791]\n",
      " [0.832699  ]\n",
      " [0.82607538]\n",
      " [0.82014132]\n",
      " [0.81550729]\n",
      " [0.81236708]] | y: 0.8752421542037967 | Predicción actual: [[0.81140447]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006063413806259632, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80271757]\n",
      " [0.81518791]\n",
      " [0.832699  ]\n",
      " [0.82607538]\n",
      " [0.82014132]\n",
      " [0.81550729]\n",
      " [0.81236708]\n",
      " [0.81140447]] | y: 0.8508330104610615 | Predicción actual: [[0.8130578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004464390221983194, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.832699  ]\n",
      " [0.82607538]\n",
      " [0.82014132]\n",
      " [0.81550729]\n",
      " [0.81236708]\n",
      " [0.81140447]\n",
      " [0.81305778]] | y: 0.8488957768306855 | Predicción actual: [[0.8177275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004996609408408403, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.832699  ]\n",
      " [0.82607538]\n",
      " [0.82014132]\n",
      " [0.81550729]\n",
      " [0.81236708]\n",
      " [0.81140447]\n",
      " [0.81305778]\n",
      " [0.81772751]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00542615819722414, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82607538]\n",
      " [0.82014132]\n",
      " [0.81550729]\n",
      " [0.81236708]\n",
      " [0.81140447]\n",
      " [0.81305778]\n",
      " [0.81772751]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.8162036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09353399276733398, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82014132]\n",
      " [0.81550729]\n",
      " [0.81236708]\n",
      " [0.81140447]\n",
      " [0.81305778]\n",
      " [0.81772751]\n",
      " [0.96241767]\n",
      " [0.81620359]] | y: 0.9407206509104997 | Predicción actual: [[0.81628793]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002912642899900675, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81550729]\n",
      " [0.81236708]\n",
      " [0.81140447]\n",
      " [0.81305778]\n",
      " [0.81772751]\n",
      " [0.96241767]\n",
      " [0.81620359]\n",
      " [0.81628793]] | y: 0.9724912824486633 | Predicción actual: [[0.8189015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007838763413019478, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81236708]\n",
      " [0.81140447]\n",
      " [0.81305778]\n",
      " [0.81772751]\n",
      " [0.96241767]\n",
      " [0.81620359]\n",
      " [0.81628793]\n",
      " [0.81890148]] | y: 0.9969004261913985 | Predicción actual: [[0.82404524]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040005289018154144, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81140447]\n",
      " [0.81305778]\n",
      " [0.81772751]\n",
      " [0.96241767]\n",
      " [0.81620359]\n",
      " [0.81628793]\n",
      " [0.81890148]\n",
      " [0.82404524]] | y: 0.951181712514529 | Predicción actual: [[0.8315479]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02290230058133602, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81305778]\n",
      " [0.81772751]\n",
      " [0.96241767]\n",
      " [0.81620359]\n",
      " [0.81628793]\n",
      " [0.81890148]\n",
      " [0.82404524]\n",
      " [0.83154792]] | y: 0.8957768306857805 | Predicción actual: [[0.8404846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002731616608798504, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81772751]\n",
      " [0.96241767]\n",
      " [0.81620359]\n",
      " [0.81628793]\n",
      " [0.81890148]\n",
      " [0.82404524]\n",
      " [0.83154792]\n",
      " [0.84048462]] | y: 0.8814413018209997 | Predicción actual: [[0.84940875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00032439519418403506, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.81620359]\n",
      " [0.81628793]\n",
      " [0.81890148]\n",
      " [0.82404524]\n",
      " [0.83154792]\n",
      " [0.84048462]\n",
      " [0.84940875]] | y: 0.9170864006199149 | Predicción actual: [[0.8572049]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011258721351623535, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81620359]\n",
      " [0.81628793]\n",
      " [0.81890148]\n",
      " [0.82404524]\n",
      " [0.83154792]\n",
      " [0.84048462]\n",
      " [0.84940875]\n",
      " [0.85720491]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009459901601076126, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81628793]\n",
      " [0.81890148]\n",
      " [0.82404524]\n",
      " [0.83154792]\n",
      " [0.84048462]\n",
      " [0.84940875]\n",
      " [0.85720491]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.8279387]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011598505079746246, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81890148]\n",
      " [0.82404524]\n",
      " [0.83154792]\n",
      " [0.84048462]\n",
      " [0.84940875]\n",
      " [0.85720491]\n",
      " [0.91979853]\n",
      " [0.82793868]] | y: 0.9682293684618366 | Predicción actual: [[0.8347937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032505064737051725, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82404524]\n",
      " [0.83154792]\n",
      " [0.84048462]\n",
      " [0.84940875]\n",
      " [0.85720491]\n",
      " [0.91979853]\n",
      " [0.82793868]\n",
      " [0.83479369]] | y: 0.9577683068578069 | Predicción actual: [[0.8425751]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07671989500522614, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.23062442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027932459488511086, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23062442]] | y: 0.10422316931421921 | Predicción actual: [[0.21554355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012000801973044872, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23062442]\n",
      " [0.21554355]] | y: 0.15420379697791559 | Predicción actual: [[0.21990356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005063224583864212, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23062442]\n",
      " [0.21554355]\n",
      " [0.21990356]] | y: 0.1557535838822161 | Predicción actual: [[0.23189475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00525142066180706, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23062442]\n",
      " [0.21554355]\n",
      " [0.21990356]\n",
      " [0.23189475]] | y: 0.12553273924835334 | Predicción actual: [[0.24566318]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01363582443445921, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23062442]\n",
      " [0.21554355]\n",
      " [0.21990356]\n",
      " [0.23189475]\n",
      " [0.24566318]] | y: 0.1456799690042619 | Predicción actual: [[0.25766632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012094210833311081, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23062442]\n",
      " [0.21554355]\n",
      " [0.21990356]\n",
      " [0.23189475]\n",
      " [0.24566318]\n",
      " [0.25766632]] | y: 0.1464548624564122 | Predicción actual: [[0.28182194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016403034329414368, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.23062442]\n",
      " [0.21554355]\n",
      " [0.21990356]\n",
      " [0.23189475]\n",
      " [0.24566318]\n",
      " [0.25766632]\n",
      " [0.28182194]] | y: 0.1960480433940332 | Predicción actual: [[0.31191665]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015533465892076492, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23062442]\n",
      " [0.21554355]\n",
      " [0.21990356]\n",
      " [0.23189475]\n",
      " [0.24566318]\n",
      " [0.25766632]\n",
      " [0.28182194]\n",
      " [0.31191665]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023624008521437645, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21554355]\n",
      " [0.21990356]\n",
      " [0.23189475]\n",
      " [0.24566318]\n",
      " [0.25766632]\n",
      " [0.28182194]\n",
      " [0.31191665]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.35081172]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026947155594825745, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21990356]\n",
      " [0.23189475]\n",
      " [0.24566318]\n",
      " [0.25766632]\n",
      " [0.28182194]\n",
      " [0.31191665]\n",
      " [0.2305308 ]\n",
      " [0.35081172]] | y: 0.211933359163115 | Predicción actual: [[0.3581046]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01590730994939804, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23189475]\n",
      " [0.24566318]\n",
      " [0.25766632]\n",
      " [0.28182194]\n",
      " [0.31191665]\n",
      " [0.2305308 ]\n",
      " [0.35081172]\n",
      " [0.35810459]] | y: 0.2072839984502131 | Predicción actual: [[0.36729145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015294544398784637, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24566318]\n",
      " [0.25766632]\n",
      " [0.28182194]\n",
      " [0.31191665]\n",
      " [0.2305308 ]\n",
      " [0.35081172]\n",
      " [0.35810459]\n",
      " [0.36729145]] | y: 0.19294846958543205 | Predicción actual: [[0.37717938]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02669893018901348, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25766632]\n",
      " [0.28182194]\n",
      " [0.31191665]\n",
      " [0.2305308 ]\n",
      " [0.35081172]\n",
      " [0.35810459]\n",
      " [0.36729145]\n",
      " [0.37717938]] | y: 0.19682293684618352 | Predicción actual: [[0.38760623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041729241609573364, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28182194]\n",
      " [0.31191665]\n",
      " [0.2305308 ]\n",
      " [0.35081172]\n",
      " [0.35810459]\n",
      " [0.36729145]\n",
      " [0.37717938]\n",
      " [0.38760623]] | y: 0.21425803951956607 | Predicción actual: [[0.39910677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015107760205864906, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31191665]\n",
      " [0.2305308 ]\n",
      " [0.35081172]\n",
      " [0.35810459]\n",
      " [0.36729145]\n",
      " [0.37717938]\n",
      " [0.38760623]\n",
      " [0.39910677]] | y: 0.18132506780317698 | Predicción actual: [[0.40903327]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028525255620479584, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.35081172]\n",
      " [0.35810459]\n",
      " [0.36729145]\n",
      " [0.37717938]\n",
      " [0.38760623]\n",
      " [0.39910677]\n",
      " [0.40903327]] | y: 0.17512592018597434 | Predicción actual: [[0.41564095]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026869429275393486, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35081172]\n",
      " [0.35810459]\n",
      " [0.36729145]\n",
      " [0.37717938]\n",
      " [0.38760623]\n",
      " [0.39910677]\n",
      " [0.40903327]\n",
      " [0.41564095]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10228211432695389, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35810459]\n",
      " [0.36729145]\n",
      " [0.37717938]\n",
      " [0.38760623]\n",
      " [0.39910677]\n",
      " [0.40903327]\n",
      " [0.41564095]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.4496249]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0787172019481659, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36729145]\n",
      " [0.37717938]\n",
      " [0.38760623]\n",
      " [0.39910677]\n",
      " [0.40903327]\n",
      " [0.41564095]\n",
      " [0.14800465]\n",
      " [0.4496249 ]] | y: 0.19217357613328173 | Predicción actual: [[0.452827]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06302572786808014, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37717938]\n",
      " [0.38760623]\n",
      " [0.39910677]\n",
      " [0.40903327]\n",
      " [0.41564095]\n",
      " [0.14800465]\n",
      " [0.4496249 ]\n",
      " [0.45282701]] | y: 0.1859744285160791 | Predicción actual: [[0.45401737]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031145004555583, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38760623]\n",
      " [0.39910677]\n",
      " [0.40903327]\n",
      " [0.41564095]\n",
      " [0.14800465]\n",
      " [0.4496249 ]\n",
      " [0.45282701]\n",
      " [0.45401737]] | y: 0.26695079426578844 | Predicción actual: [[0.4533722]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06085323914885521, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39910677]\n",
      " [0.40903327]\n",
      " [0.41564095]\n",
      " [0.14800465]\n",
      " [0.4496249 ]\n",
      " [0.45282701]\n",
      " [0.45401737]\n",
      " [0.45337221]] | y: 0.2925222781867493 | Predicción actual: [[0.4511121]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03875671699643135, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40903327]\n",
      " [0.41564095]\n",
      " [0.14800465]\n",
      " [0.4496249 ]\n",
      " [0.45282701]\n",
      " [0.45401737]\n",
      " [0.45337221]\n",
      " [0.45111209]] | y: 0.3177063153816349 | Predicción actual: [[0.44747153]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03565960004925728, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41564095]\n",
      " [0.14800465]\n",
      " [0.4496249 ]\n",
      " [0.45282701]\n",
      " [0.45401737]\n",
      " [0.45337221]\n",
      " [0.45111209]\n",
      " [0.44747153]] | y: 0.31266950794265785 | Predicción actual: [[0.44319496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006814982742071152, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.4496249 ]\n",
      " [0.45282701]\n",
      " [0.45401737]\n",
      " [0.45337221]\n",
      " [0.45111209]\n",
      " [0.44747153]\n",
      " [0.44319496]] | y: 0.2890352576520729 | Predicción actual: [[0.43942776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012299811467528343, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4496249 ]\n",
      " [0.45282701]\n",
      " [0.45401737]\n",
      " [0.45337221]\n",
      " [0.45111209]\n",
      " [0.44747153]\n",
      " [0.44319496]\n",
      " [0.43942776]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028071632608771324, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45282701]\n",
      " [0.45401737]\n",
      " [0.45337221]\n",
      " [0.45111209]\n",
      " [0.44747153]\n",
      " [0.44319496]\n",
      " [0.43942776]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.5004833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043118808418512344, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45401737]\n",
      " [0.45337221]\n",
      " [0.45111209]\n",
      " [0.44747153]\n",
      " [0.44319496]\n",
      " [0.43942776]\n",
      " [0.28283611]\n",
      " [0.50048327]] | y: 0.2758620689655173 | Predicción actual: [[0.49674982]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05408449098467827, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45337221]\n",
      " [0.45111209]\n",
      " [0.44747153]\n",
      " [0.44319496]\n",
      " [0.43942776]\n",
      " [0.28283611]\n",
      " [0.50048327]\n",
      " [0.49674982]] | y: 0.2746997287872917 | Predicción actual: [[0.4917263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04275341331958771, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45111209]\n",
      " [0.44747153]\n",
      " [0.44319496]\n",
      " [0.43942776]\n",
      " [0.28283611]\n",
      " [0.50048327]\n",
      " [0.49674982]\n",
      " [0.49172631]] | y: 0.275474622239442 | Predicción actual: [[0.486436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036342814564704895, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44747153]\n",
      " [0.44319496]\n",
      " [0.43942776]\n",
      " [0.28283611]\n",
      " [0.50048327]\n",
      " [0.49674982]\n",
      " [0.49172631]\n",
      " [0.48643601]] | y: 0.3347539713289423 | Predicción actual: [[0.4819625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014259710907936096, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44319496]\n",
      " [0.43942776]\n",
      " [0.28283611]\n",
      " [0.50048327]\n",
      " [0.49674982]\n",
      " [0.49172631]\n",
      " [0.48643601]\n",
      " [0.4819625 ]] | y: 0.35567609453700116 | Predicción actual: [[0.479339]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030331799760460854, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43942776]\n",
      " [0.28283611]\n",
      " [0.50048327]\n",
      " [0.49674982]\n",
      " [0.49172631]\n",
      " [0.48643601]\n",
      " [0.4819625 ]\n",
      " [0.479339  ]] | y: 0.3366912049593181 | Predicción actual: [[0.47921547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009569442830979824, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.50048327]\n",
      " [0.49674982]\n",
      " [0.49172631]\n",
      " [0.48643601]\n",
      " [0.4819625 ]\n",
      " [0.479339  ]\n",
      " [0.47921547]] | y: 0.3335916311507167 | Predicción actual: [[0.48194098]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0079279113560915, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50048327]\n",
      " [0.49674982]\n",
      " [0.49172631]\n",
      " [0.48643601]\n",
      " [0.4819625 ]\n",
      " [0.479339  ]\n",
      " [0.47921547]\n",
      " [0.48194098]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018400665372610092, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49674982]\n",
      " [0.49172631]\n",
      " [0.48643601]\n",
      " [0.4819625 ]\n",
      " [0.479339  ]\n",
      " [0.47921547]\n",
      " [0.48194098]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5203516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0039057284593582153, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49172631]\n",
      " [0.48643601]\n",
      " [0.4819625 ]\n",
      " [0.479339  ]\n",
      " [0.47921547]\n",
      " [0.48194098]\n",
      " [0.3847346 ]\n",
      " [0.52035159]] | y: 0.5962805114296785 | Predicción actual: [[0.515555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01615804433822632, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48643601]\n",
      " [0.4819625 ]\n",
      " [0.479339  ]\n",
      " [0.47921547]\n",
      " [0.48194098]\n",
      " [0.3847346 ]\n",
      " [0.52035159]\n",
      " [0.51555502]] | y: 0.574583494769469 | Predicción actual: [[0.5113369]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023099067620933056, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4819625 ]\n",
      " [0.479339  ]\n",
      " [0.47921547]\n",
      " [0.48194098]\n",
      " [0.3847346 ]\n",
      " [0.52035159]\n",
      " [0.51555502]\n",
      " [0.51133692]] | y: 0.6063541263076326 | Predicción actual: [[0.5082415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004896511323750019, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.479339  ]\n",
      " [0.47921547]\n",
      " [0.48194098]\n",
      " [0.3847346 ]\n",
      " [0.52035159]\n",
      " [0.51555502]\n",
      " [0.51133692]\n",
      " [0.50824147]] | y: 0.5846571096474236 | Predicción actual: [[0.50664055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013266058638691902, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47921547]\n",
      " [0.48194098]\n",
      " [0.3847346 ]\n",
      " [0.52035159]\n",
      " [0.51555502]\n",
      " [0.51133692]\n",
      " [0.50824147]\n",
      " [0.50664055]] | y: 0.5687717938783416 | Predicción actual: [[0.50658]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014217051677405834, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48194098]\n",
      " [0.3847346 ]\n",
      " [0.52035159]\n",
      " [0.51555502]\n",
      " [0.51133692]\n",
      " [0.50824147]\n",
      " [0.50664055]\n",
      " [0.50658   ]] | y: 0.6427741185586981 | Predicción actual: [[0.5077798]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028480149805545807, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.52035159]\n",
      " [0.51555502]\n",
      " [0.51133692]\n",
      " [0.50824147]\n",
      " [0.50664055]\n",
      " [0.50658   ]\n",
      " [0.50777978]] | y: 0.6617590081363811 | Predicción actual: [[0.5097526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024241143837571144, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52035159]\n",
      " [0.51555502]\n",
      " [0.51133692]\n",
      " [0.50824147]\n",
      " [0.50664055]\n",
      " [0.50658   ]\n",
      " [0.50777978]\n",
      " [0.50975257]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032528381794691086, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51555502]\n",
      " [0.51133692]\n",
      " [0.50824147]\n",
      " [0.50664055]\n",
      " [0.50658   ]\n",
      " [0.50777978]\n",
      " [0.50975257]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.53580064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06380041688680649, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51133692]\n",
      " [0.50824147]\n",
      " [0.50664055]\n",
      " [0.50658   ]\n",
      " [0.50777978]\n",
      " [0.50975257]\n",
      " [0.67299496]\n",
      " [0.53580064]] | y: 0.703990701278574 | Predicción actual: [[0.5369534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022058861330151558, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50824147]\n",
      " [0.50664055]\n",
      " [0.50658   ]\n",
      " [0.50777978]\n",
      " [0.50975257]\n",
      " [0.67299496]\n",
      " [0.53580064]\n",
      " [0.53695339]] | y: 0.7272375048430839 | Predicción actual: [[0.540781]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04748284071683884, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50664055]\n",
      " [0.50658   ]\n",
      " [0.50777978]\n",
      " [0.50975257]\n",
      " [0.67299496]\n",
      " [0.53580064]\n",
      " [0.53695339]\n",
      " [0.54078102]] | y: 0.722588144130182 | Predicción actual: [[0.54731107]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052373867481946945, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50658   ]\n",
      " [0.50777978]\n",
      " [0.50975257]\n",
      " [0.67299496]\n",
      " [0.53580064]\n",
      " [0.53695339]\n",
      " [0.54078102]\n",
      " [0.54731107]] | y: 0.771793878341728 | Predicción actual: [[0.5562519]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.057536594569683075, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50777978]\n",
      " [0.50975257]\n",
      " [0.67299496]\n",
      " [0.53580064]\n",
      " [0.53695339]\n",
      " [0.54078102]\n",
      " [0.54731107]\n",
      " [0.55625188]] | y: 0.7245253777605578 | Predicción actual: [[0.5671895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019538244232535362, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50975257]\n",
      " [0.67299496]\n",
      " [0.53580064]\n",
      " [0.53695339]\n",
      " [0.54078102]\n",
      " [0.54731107]\n",
      " [0.55625188]\n",
      " [0.56718951]] | y: 0.6710577295621851 | Predicción actual: [[0.57961047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004562149289995432, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.53580064]\n",
      " [0.53695339]\n",
      " [0.54078102]\n",
      " [0.54731107]\n",
      " [0.55625188]\n",
      " [0.56718951]\n",
      " [0.57961047]] | y: 0.6737698566447115 | Predicción actual: [[0.5929713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002145930891856551, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53580064]\n",
      " [0.53695339]\n",
      " [0.54078102]\n",
      " [0.54731107]\n",
      " [0.55625188]\n",
      " [0.56718951]\n",
      " [0.57961047]\n",
      " [0.59297132]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05024370551109314, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53695339]\n",
      " [0.54078102]\n",
      " [0.54731107]\n",
      " [0.55625188]\n",
      " [0.56718951]\n",
      " [0.57961047]\n",
      " [0.59297132]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.57182]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030276527628302574, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54078102]\n",
      " [0.54731107]\n",
      " [0.55625188]\n",
      " [0.56718951]\n",
      " [0.57961047]\n",
      " [0.59297132]\n",
      " [0.71445176]\n",
      " [0.57182002]] | y: 0.722588144130182 | Predicción actual: [[0.58034366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018701160326600075, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54731107]\n",
      " [0.55625188]\n",
      " [0.56718951]\n",
      " [0.57961047]\n",
      " [0.59297132]\n",
      " [0.71445176]\n",
      " [0.57182002]\n",
      " [0.58034366]] | y: 0.6993413405656723 | Predicción actual: [[0.59079564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.712590867304243e-05, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55625188]\n",
      " [0.56718951]\n",
      " [0.57961047]\n",
      " [0.59297132]\n",
      " [0.71445176]\n",
      " [0.57182002]\n",
      " [0.58034366]\n",
      " [0.59079564]] | y: 0.7373111197210385 | Predicción actual: [[0.6021456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007296527735888958, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56718951]\n",
      " [0.57961047]\n",
      " [0.59297132]\n",
      " [0.71445176]\n",
      " [0.57182002]\n",
      " [0.58034366]\n",
      " [0.59079564]\n",
      " [0.60214561]] | y: 0.7214258039519565 | Predicción actual: [[0.61344695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001845371094532311, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57961047]\n",
      " [0.59297132]\n",
      " [0.71445176]\n",
      " [0.57182002]\n",
      " [0.58034366]\n",
      " [0.59079564]\n",
      " [0.60214561]\n",
      " [0.61344695]] | y: 0.7187136768694304 | Predicción actual: [[0.6236258]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0421021543443203, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59297132]\n",
      " [0.71445176]\n",
      " [0.57182002]\n",
      " [0.58034366]\n",
      " [0.59079564]\n",
      " [0.60214561]\n",
      " [0.61344695]\n",
      " [0.62362581]] | y: 0.6741573033707864 | Predicción actual: [[0.63190734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009786870796233416, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.57182002]\n",
      " [0.58034366]\n",
      " [0.59079564]\n",
      " [0.60214561]\n",
      " [0.61344695]\n",
      " [0.62362581]\n",
      " [0.63190734]] | y: 0.698566447113522 | Predicción actual: [[0.6374382]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029285477474331856, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57182002]\n",
      " [0.58034366]\n",
      " [0.59079564]\n",
      " [0.60214561]\n",
      " [0.61344695]\n",
      " [0.62362581]\n",
      " [0.63190734]\n",
      " [0.63743818]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0932995792245492e-05, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58034366]\n",
      " [0.59079564]\n",
      " [0.60214561]\n",
      " [0.61344695]\n",
      " [0.62362581]\n",
      " [0.63190734]\n",
      " [0.63743818]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.62092847]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018655819818377495, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59079564]\n",
      " [0.60214561]\n",
      " [0.61344695]\n",
      " [0.62362581]\n",
      " [0.63190734]\n",
      " [0.63743818]\n",
      " [0.72103836]\n",
      " [0.62092847]] | y: 0.7562960092987214 | Predicción actual: [[0.631328]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025635402649641037, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60214561]\n",
      " [0.61344695]\n",
      " [0.62362581]\n",
      " [0.63190734]\n",
      " [0.63743818]\n",
      " [0.72103836]\n",
      " [0.62092847]\n",
      " [0.63132799]] | y: 0.8275862068965516 | Predicción actual: [[0.64180803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003164944937452674, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61344695]\n",
      " [0.62362581]\n",
      " [0.63190734]\n",
      " [0.63743818]\n",
      " [0.72103836]\n",
      " [0.62092847]\n",
      " [0.63132799]\n",
      " [0.64180803]] | y: 0.8388221619527314 | Predicción actual: [[0.65157574]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07445430010557175, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62362581]\n",
      " [0.63190734]\n",
      " [0.63743818]\n",
      " [0.72103836]\n",
      " [0.62092847]\n",
      " [0.63132799]\n",
      " [0.64180803]\n",
      " [0.65157574]] | y: 0.7942657884540876 | Predicción actual: [[0.6603122]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01834563910961151, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63190734]\n",
      " [0.63743818]\n",
      " [0.72103836]\n",
      " [0.62092847]\n",
      " [0.63132799]\n",
      " [0.64180803]\n",
      " [0.65157574]\n",
      " [0.66031218]] | y: 0.7838047268500579 | Predicción actual: [[0.667707]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003952257800847292, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63743818]\n",
      " [0.72103836]\n",
      " [0.62092847]\n",
      " [0.63132799]\n",
      " [0.64180803]\n",
      " [0.65157574]\n",
      " [0.66031218]\n",
      " [0.66770703]] | y: 0.7679194110809764 | Predicción actual: [[0.67382234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024910027161240578, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62092847]\n",
      " [0.63132799]\n",
      " [0.64180803]\n",
      " [0.65157574]\n",
      " [0.66031218]\n",
      " [0.66770703]\n",
      " [0.67382234]] | y: 0.7845796203022084 | Predicción actual: [[0.67928386]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.4212322387029417e-05, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62092847]\n",
      " [0.63132799]\n",
      " [0.64180803]\n",
      " [0.65157574]\n",
      " [0.66031218]\n",
      " [0.66770703]\n",
      " [0.67382234]\n",
      " [0.67928386]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006278933957219124, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63132799]\n",
      " [0.64180803]\n",
      " [0.65157574]\n",
      " [0.66031218]\n",
      " [0.66770703]\n",
      " [0.67382234]\n",
      " [0.67928386]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.67294073]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04497972130775452, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64180803]\n",
      " [0.65157574]\n",
      " [0.66031218]\n",
      " [0.66770703]\n",
      " [0.67382234]\n",
      " [0.67928386]\n",
      " [0.87872917]\n",
      " [0.67294073]] | y: 0.8488957768306855 | Predicción actual: [[0.68464744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04915544018149376, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65157574]\n",
      " [0.66031218]\n",
      " [0.66770703]\n",
      " [0.67382234]\n",
      " [0.67928386]\n",
      " [0.87872917]\n",
      " [0.67294073]\n",
      " [0.68464744]] | y: 0.8182874854707476 | Predicción actual: [[0.69737095]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014210172928869724, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66031218]\n",
      " [0.66770703]\n",
      " [0.67382234]\n",
      " [0.67928386]\n",
      " [0.87872917]\n",
      " [0.67294073]\n",
      " [0.68464744]\n",
      " [0.69737095]] | y: 0.8268113134444013 | Predicción actual: [[0.7107668]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022578004747629166, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66770703]\n",
      " [0.67382234]\n",
      " [0.67928386]\n",
      " [0.87872917]\n",
      " [0.67294073]\n",
      " [0.68464744]\n",
      " [0.69737095]\n",
      " [0.71076679]] | y: 0.7853545137543589 | Predicción actual: [[0.724609]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006374302785843611, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67382234]\n",
      " [0.67928386]\n",
      " [0.87872917]\n",
      " [0.67294073]\n",
      " [0.68464744]\n",
      " [0.69737095]\n",
      " [0.71076679]\n",
      " [0.72460902]] | y: 0.7892289810151103 | Predicción actual: [[0.7386474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00040544403600506485, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67928386]\n",
      " [0.87872917]\n",
      " [0.67294073]\n",
      " [0.68464744]\n",
      " [0.69737095]\n",
      " [0.71076679]\n",
      " [0.72460902]\n",
      " [0.7386474 ]] | y: 0.8341728012398295 | Predicción actual: [[0.7527133]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001585329882800579, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.67294073]\n",
      " [0.68464744]\n",
      " [0.69737095]\n",
      " [0.71076679]\n",
      " [0.72460902]\n",
      " [0.7386474 ]\n",
      " [0.75271332]] | y: 0.8124757845796202 | Predicción actual: [[0.7667203]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02601826749742031, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67294073]\n",
      " [0.68464744]\n",
      " [0.69737095]\n",
      " [0.71076679]\n",
      " [0.72460902]\n",
      " [0.7386474 ]\n",
      " [0.75271332]\n",
      " [0.76672029]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027499692514538765, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68464744]\n",
      " [0.69737095]\n",
      " [0.71076679]\n",
      " [0.72460902]\n",
      " [0.7386474 ]\n",
      " [0.75271332]\n",
      " [0.76672029]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7380543]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007330302149057388, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69737095]\n",
      " [0.71076679]\n",
      " [0.72460902]\n",
      " [0.7386474 ]\n",
      " [0.75271332]\n",
      " [0.76672029]\n",
      " [0.80123983]\n",
      " [0.73805428]] | y: 0.793490895001937 | Predicción actual: [[0.75171363]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013129704631865025, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71076679]\n",
      " [0.72460902]\n",
      " [0.7386474 ]\n",
      " [0.75271332]\n",
      " [0.76672029]\n",
      " [0.80123983]\n",
      " [0.73805428]\n",
      " [0.75171363]] | y: 0.760170476559473 | Predicción actual: [[0.76510394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002783083589747548, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72460902]\n",
      " [0.7386474 ]\n",
      " [0.75271332]\n",
      " [0.76672029]\n",
      " [0.80123983]\n",
      " [0.73805428]\n",
      " [0.75171363]\n",
      " [0.76510394]] | y: 0.7353738860906625 | Predicción actual: [[0.7774047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.86237176018767e-05, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7386474 ]\n",
      " [0.75271332]\n",
      " [0.76672029]\n",
      " [0.80123983]\n",
      " [0.73805428]\n",
      " [0.75171363]\n",
      " [0.76510394]\n",
      " [0.77740473]] | y: 0.7101898488957767 | Predicción actual: [[0.7878252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026055430993437767, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75271332]\n",
      " [0.76672029]\n",
      " [0.80123983]\n",
      " [0.73805428]\n",
      " [0.75171363]\n",
      " [0.76510394]\n",
      " [0.77740473]\n",
      " [0.78782523]] | y: 0.7121270825261525 | Predicción actual: [[0.7955007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0334317684173584, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76672029]\n",
      " [0.80123983]\n",
      " [0.73805428]\n",
      " [0.75171363]\n",
      " [0.76510394]\n",
      " [0.77740473]\n",
      " [0.78782523]\n",
      " [0.7955007 ]] | y: 0.7396358000774894 | Predicción actual: [[0.7999847]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012112411670386791, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.73805428]\n",
      " [0.75171363]\n",
      " [0.76510394]\n",
      " [0.77740473]\n",
      " [0.78782523]\n",
      " [0.7955007 ]\n",
      " [0.79998469]] | y: 0.7361487795428128 | Predicción actual: [[0.8011928]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002007625997066498, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73805428]\n",
      " [0.75171363]\n",
      " [0.76510394]\n",
      " [0.77740473]\n",
      " [0.78782523]\n",
      " [0.7955007 ]\n",
      " [0.79998469]\n",
      " [0.80119282]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034034568816423416, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75171363]\n",
      " [0.76510394]\n",
      " [0.77740473]\n",
      " [0.78782523]\n",
      " [0.7955007 ]\n",
      " [0.79998469]\n",
      " [0.80119282]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8026224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01191797573119402, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76510394]\n",
      " [0.77740473]\n",
      " [0.78782523]\n",
      " [0.7955007 ]\n",
      " [0.79998469]\n",
      " [0.80119282]\n",
      " [0.66757071]\n",
      " [0.80262238]] | y: 0.696629213483146 | Predicción actual: [[0.8094088]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0446774996817112, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77740473]\n",
      " [0.78782523]\n",
      " [0.7955007 ]\n",
      " [0.79998469]\n",
      " [0.80119282]\n",
      " [0.66757071]\n",
      " [0.80262238]\n",
      " [0.80940878]] | y: 0.6559473072452537 | Predicción actual: [[0.8126617]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04061851277947426, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78782523]\n",
      " [0.7955007 ]\n",
      " [0.79998469]\n",
      " [0.80119282]\n",
      " [0.66757071]\n",
      " [0.80262238]\n",
      " [0.80940878]\n",
      " [0.81266171]] | y: 0.6788066640836885 | Predicción actual: [[0.8124155]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06428387761116028, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7955007 ]\n",
      " [0.79998469]\n",
      " [0.80119282]\n",
      " [0.66757071]\n",
      " [0.80262238]\n",
      " [0.80940878]\n",
      " [0.81266171]\n",
      " [0.81241548]] | y: 0.6760945370011622 | Predicción actual: [[0.80898565]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001130737247876823, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79998469]\n",
      " [0.80119282]\n",
      " [0.66757071]\n",
      " [0.80262238]\n",
      " [0.80940878]\n",
      " [0.81266171]\n",
      " [0.81241548]\n",
      " [0.80898565]] | y: 0.7295621851995349 | Predicción actual: [[0.8037738]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002578184474259615, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80119282]\n",
      " [0.66757071]\n",
      " [0.80262238]\n",
      " [0.80940878]\n",
      " [0.81266171]\n",
      " [0.81241548]\n",
      " [0.80898565]\n",
      " [0.80377382]] | y: 0.7012785741960481 | Predicción actual: [[0.79786986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014947443269193172, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.80262238]\n",
      " [0.80940878]\n",
      " [0.81266171]\n",
      " [0.81241548]\n",
      " [0.80898565]\n",
      " [0.80377382]\n",
      " [0.79786986]] | y: 0.767531964354901 | Predicción actual: [[0.79235005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005749743431806564, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80262238]\n",
      " [0.80940878]\n",
      " [0.81266171]\n",
      " [0.81241548]\n",
      " [0.80898565]\n",
      " [0.80377382]\n",
      " [0.79786986]\n",
      " [0.79235005]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023515622597187757, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80940878]\n",
      " [0.81266171]\n",
      " [0.81241548]\n",
      " [0.80898565]\n",
      " [0.80377382]\n",
      " [0.79786986]\n",
      " [0.79235005]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.826843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00013168581062927842, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81266171]\n",
      " [0.81241548]\n",
      " [0.80898565]\n",
      " [0.80377382]\n",
      " [0.79786986]\n",
      " [0.79235005]\n",
      " [0.75513367]\n",
      " [0.82684302]] | y: 0.7520340953118947 | Predicción actual: [[0.8241974]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009628275875002146, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81241548]\n",
      " [0.80898565]\n",
      " [0.80377382]\n",
      " [0.79786986]\n",
      " [0.79235005]\n",
      " [0.75513367]\n",
      " [0.82684302]\n",
      " [0.82419741]] | y: 0.7098024021697016 | Predicción actual: [[0.820085]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003809808986261487, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80898565]\n",
      " [0.80377382]\n",
      " [0.79786986]\n",
      " [0.79235005]\n",
      " [0.75513367]\n",
      " [0.82684302]\n",
      " [0.82419741]\n",
      " [0.82008499]] | y: 0.6904300658659435 | Predicción actual: [[0.81563807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008782950229942799, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80377382]\n",
      " [0.79786986]\n",
      " [0.79235005]\n",
      " [0.75513367]\n",
      " [0.82684302]\n",
      " [0.82419741]\n",
      " [0.82008499]\n",
      " [0.81563807]] | y: 0.7543587756683454 | Predicción actual: [[0.81206053]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003140366869047284, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79786986]\n",
      " [0.79235005]\n",
      " [0.75513367]\n",
      " [0.82684302]\n",
      " [0.82419741]\n",
      " [0.82008499]\n",
      " [0.81563807]\n",
      " [0.81206053]] | y: 0.7222006974041069 | Predicción actual: [[0.8105183]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011921490542590618, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79235005]\n",
      " [0.75513367]\n",
      " [0.82684302]\n",
      " [0.82419741]\n",
      " [0.82008499]\n",
      " [0.81563807]\n",
      " [0.81206053]\n",
      " [0.81051832]] | y: 0.8485083301046106 | Predicción actual: [[0.81125396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02259022369980812, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.82684302]\n",
      " [0.82419741]\n",
      " [0.82008499]\n",
      " [0.81563807]\n",
      " [0.81206053]\n",
      " [0.81051832]\n",
      " [0.81125396]] | y: 0.9054629988376597 | Predicción actual: [[0.8148643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006279198452830315, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82684302]\n",
      " [0.82419741]\n",
      " [0.82008499]\n",
      " [0.81563807]\n",
      " [0.81206053]\n",
      " [0.81051832]\n",
      " [0.81125396]\n",
      " [0.81486428]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.186684913700446e-05, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82419741]\n",
      " [0.82008499]\n",
      " [0.81563807]\n",
      " [0.81206053]\n",
      " [0.81051832]\n",
      " [0.81125396]\n",
      " [0.81486428]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.82785267]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0041363914497196674, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82008499]\n",
      " [0.81563807]\n",
      " [0.81206053]\n",
      " [0.81051832]\n",
      " [0.81125396]\n",
      " [0.81486428]\n",
      " [0.8822162 ]\n",
      " [0.82785267]] | y: 0.889577683068578 | Predicción actual: [[0.8258785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007803384214639664, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81563807]\n",
      " [0.81206053]\n",
      " [0.81051832]\n",
      " [0.81125396]\n",
      " [0.81486428]\n",
      " [0.8822162 ]\n",
      " [0.82785267]\n",
      " [0.8258785 ]] | y: 0.8748547074777218 | Predicción actual: [[0.8257648]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021576927974820137, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81206053]\n",
      " [0.81051832]\n",
      " [0.81125396]\n",
      " [0.81486428]\n",
      " [0.8822162 ]\n",
      " [0.82785267]\n",
      " [0.8258785 ]\n",
      " [0.82576478]] | y: 0.9132119333591631 | Predicción actual: [[0.8275907]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004534284584224224, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81051832]\n",
      " [0.81125396]\n",
      " [0.81486428]\n",
      " [0.8822162 ]\n",
      " [0.82785267]\n",
      " [0.8258785 ]\n",
      " [0.82576478]\n",
      " [0.8275907 ]] | y: 1.0 | Predicción actual: [[0.8315034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019057907164096832, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81125396]\n",
      " [0.81486428]\n",
      " [0.8822162 ]\n",
      " [0.82785267]\n",
      " [0.8258785 ]\n",
      " [0.82576478]\n",
      " [0.8275907 ]\n",
      " [0.83150339]] | y: 0.9705540488182873 | Predicción actual: [[0.837091]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011934313923120499, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81486428]\n",
      " [0.8822162 ]\n",
      " [0.82785267]\n",
      " [0.8258785 ]\n",
      " [0.82576478]\n",
      " [0.8275907 ]\n",
      " [0.83150339]\n",
      " [0.83709103]] | y: 0.8888027896164277 | Predicción actual: [[0.8435417]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03195445239543915, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.82785267]\n",
      " [0.8258785 ]\n",
      " [0.82576478]\n",
      " [0.8275907 ]\n",
      " [0.83150339]\n",
      " [0.83709103]\n",
      " [0.84354168]] | y: 0.877954281286323 | Predicción actual: [[0.8499313]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024739669635891914, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82785267]\n",
      " [0.8258785 ]\n",
      " [0.82576478]\n",
      " [0.8275907 ]\n",
      " [0.83150339]\n",
      " [0.83709103]\n",
      " [0.84354168]\n",
      " [0.8499313 ]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015155939385294914, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8258785 ]\n",
      " [0.82576478]\n",
      " [0.8275907 ]\n",
      " [0.83150339]\n",
      " [0.83709103]\n",
      " [0.84354168]\n",
      " [0.8499313 ]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.83810484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028784144669771194, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82576478]\n",
      " [0.8275907 ]\n",
      " [0.83150339]\n",
      " [0.83709103]\n",
      " [0.84354168]\n",
      " [0.8499313 ]\n",
      " [0.84889578]\n",
      " [0.83810484]] | y: 0.8550949244478885 | Predicción actual: [[0.84095466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007833129726350307, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8275907 ]\n",
      " [0.83150339]\n",
      " [0.83709103]\n",
      " [0.84354168]\n",
      " [0.8499313 ]\n",
      " [0.84889578]\n",
      " [0.83810484]\n",
      " [0.84095466]] | y: 0.8752421542037967 | Predicción actual: [[0.84478563]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008367522968910635, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83150339]\n",
      " [0.83709103]\n",
      " [0.84354168]\n",
      " [0.8499313 ]\n",
      " [0.84889578]\n",
      " [0.83810484]\n",
      " [0.84095466]\n",
      " [0.84478563]] | y: 0.857032158078264 | Predicción actual: [[0.84877884]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002182655269280076, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83709103]\n",
      " [0.84354168]\n",
      " [0.8499313 ]\n",
      " [0.84889578]\n",
      " [0.83810484]\n",
      " [0.84095466]\n",
      " [0.84478563]\n",
      " [0.84877884]] | y: 0.8500581170089112 | Predicción actual: [[0.85238606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006208750419318676, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84354168]\n",
      " [0.8499313 ]\n",
      " [0.84889578]\n",
      " [0.83810484]\n",
      " [0.84095466]\n",
      " [0.84478563]\n",
      " [0.84877884]\n",
      " [0.85238606]] | y: 0.8426966292134832 | Predicción actual: [[0.8548097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035494884941726923, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8499313 ]\n",
      " [0.84889578]\n",
      " [0.83810484]\n",
      " [0.84095466]\n",
      " [0.84478563]\n",
      " [0.84877884]\n",
      " [0.85238606]\n",
      " [0.8548097 ]] | y: 0.8229368461836497 | Predicción actual: [[0.8555582]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032775993458926678, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.83810484]\n",
      " [0.84095466]\n",
      " [0.84478563]\n",
      " [0.84877884]\n",
      " [0.85238606]\n",
      " [0.8548097 ]\n",
      " [0.85555822]] | y: 0.7745060054242543 | Predicción actual: [[0.85475814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005469245952554047, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83810484]\n",
      " [0.84095466]\n",
      " [0.84478563]\n",
      " [0.84877884]\n",
      " [0.85238606]\n",
      " [0.8548097 ]\n",
      " [0.85555822]\n",
      " [0.85475814]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008283238857984543, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84095466]\n",
      " [0.84478563]\n",
      " [0.84877884]\n",
      " [0.85238606]\n",
      " [0.8548097 ]\n",
      " [0.85555822]\n",
      " [0.85475814]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.85680324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005445617251098156, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84478563]\n",
      " [0.84877884]\n",
      " [0.85238606]\n",
      " [0.8548097 ]\n",
      " [0.85555822]\n",
      " [0.85475814]\n",
      " [0.78419217]\n",
      " [0.85680324]] | y: 0.854320030995738 | Predicción actual: [[0.8583307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00018681261281017214, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84877884]\n",
      " [0.85238606]\n",
      " [0.8548097 ]\n",
      " [0.85555822]\n",
      " [0.85475814]\n",
      " [0.78419217]\n",
      " [0.85680324]\n",
      " [0.85833073]] | y: 0.8368849283223556 | Predicción actual: [[0.858701]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01133618876338005, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85238606]\n",
      " [0.8548097 ]\n",
      " [0.85555822]\n",
      " [0.85475814]\n",
      " [0.78419217]\n",
      " [0.85680324]\n",
      " [0.85833073]\n",
      " [0.85870099]] | y: 0.8299108872530028 | Predicción actual: [[0.85750103]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0039309351705014706, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8548097 ]\n",
      " [0.85555822]\n",
      " [0.85475814]\n",
      " [0.78419217]\n",
      " [0.85680324]\n",
      " [0.85833073]\n",
      " [0.85870099]\n",
      " [0.85750103]] | y: 0.887253002712127 | Predicción actual: [[0.85498303]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01224565226584673, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85555822]\n",
      " [0.85475814]\n",
      " [0.78419217]\n",
      " [0.85680324]\n",
      " [0.85833073]\n",
      " [0.85870099]\n",
      " [0.85750103]\n",
      " [0.85498303]] | y: 0.8597442851607902 | Predicción actual: [[0.85145354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005659613525494933, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85475814]\n",
      " [0.78419217]\n",
      " [0.85680324]\n",
      " [0.85833073]\n",
      " [0.85870099]\n",
      " [0.85750103]\n",
      " [0.85498303]\n",
      " [0.85145354]] | y: 0.8395970554048819 | Predicción actual: [[0.84787655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002593747340142727, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.85680324]\n",
      " [0.85833073]\n",
      " [0.85870099]\n",
      " [0.85750103]\n",
      " [0.85498303]\n",
      " [0.85145354]\n",
      " [0.84787655]] | y: 0.7838047268500579 | Predicción actual: [[0.8448411]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029960988089442253, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85680324]\n",
      " [0.85833073]\n",
      " [0.85870099]\n",
      " [0.85750103]\n",
      " [0.85498303]\n",
      " [0.85145354]\n",
      " [0.84787655]\n",
      " [0.84484112]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008001740090548992, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85833073]\n",
      " [0.85870099]\n",
      " [0.85750103]\n",
      " [0.85498303]\n",
      " [0.85145354]\n",
      " [0.84787655]\n",
      " [0.84484112]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8611543]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0496336854994297, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85870099]\n",
      " [0.85750103]\n",
      " [0.85498303]\n",
      " [0.85145354]\n",
      " [0.84787655]\n",
      " [0.84484112]\n",
      " [0.81828749]\n",
      " [0.86115432]] | y: 0.7605579232855482 | Predicción actual: [[0.8582916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009463163441978395, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85750103]\n",
      " [0.85498303]\n",
      " [0.85145354]\n",
      " [0.84787655]\n",
      " [0.84484112]\n",
      " [0.81828749]\n",
      " [0.86115432]\n",
      " [0.85829163]] | y: 0.7915536613715615 | Predicción actual: [[0.85478014]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002204563934355974, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85498303]\n",
      " [0.85145354]\n",
      " [0.84787655]\n",
      " [0.84484112]\n",
      " [0.81828749]\n",
      " [0.86115432]\n",
      " [0.85829163]\n",
      " [0.85478014]] | y: 0.7686943045331267 | Predicción actual: [[0.8513245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07597886025905609, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85145354]\n",
      " [0.84787655]\n",
      " [0.84484112]\n",
      " [0.81828749]\n",
      " [0.86115432]\n",
      " [0.85829163]\n",
      " [0.85478014]\n",
      " [0.8513245 ]] | y: 0.7686943045331267 | Predicción actual: [[0.8477197]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003282350953668356, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84787655]\n",
      " [0.84484112]\n",
      " [0.81828749]\n",
      " [0.86115432]\n",
      " [0.85829163]\n",
      " [0.85478014]\n",
      " [0.8513245 ]\n",
      " [0.84771973]] | y: 0.7989151491669895 | Predicción actual: [[0.8450775]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02685725688934326, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84484112]\n",
      " [0.81828749]\n",
      " [0.86115432]\n",
      " [0.85829163]\n",
      " [0.85478014]\n",
      " [0.8513245 ]\n",
      " [0.84771973]\n",
      " [0.84507751]] | y: 0.7900038744672608 | Predicción actual: [[0.8433276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003019089810550213, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.86115432]\n",
      " [0.85829163]\n",
      " [0.85478014]\n",
      " [0.8513245 ]\n",
      " [0.84771973]\n",
      " [0.84507751]\n",
      " [0.84332758]] | y: 0.760170476559473 | Predicción actual: [[0.84290475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03185688704252243, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86115432]\n",
      " [0.85829163]\n",
      " [0.85478014]\n",
      " [0.8513245 ]\n",
      " [0.84771973]\n",
      " [0.84507751]\n",
      " [0.84332758]\n",
      " [0.84290475]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030435447115451097, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85829163]\n",
      " [0.85478014]\n",
      " [0.8513245 ]\n",
      " [0.84771973]\n",
      " [0.84507751]\n",
      " [0.84332758]\n",
      " [0.84290475]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8447302]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08624770492315292, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85478014]\n",
      " [0.8513245 ]\n",
      " [0.84771973]\n",
      " [0.84507751]\n",
      " [0.84332758]\n",
      " [0.84290475]\n",
      " [0.68539326]\n",
      " [0.8447302 ]] | y: 0.6648585819449826 | Predicción actual: [[0.83761096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016199523815885186, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8513245 ]\n",
      " [0.84771973]\n",
      " [0.84507751]\n",
      " [0.84332758]\n",
      " [0.84290475]\n",
      " [0.68539326]\n",
      " [0.8447302 ]\n",
      " [0.83761096]] | y: 0.7078651685393258 | Predicción actual: [[0.8294898]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05132097750902176, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84771973]\n",
      " [0.84507751]\n",
      " [0.84332758]\n",
      " [0.84290475]\n",
      " [0.68539326]\n",
      " [0.8447302 ]\n",
      " [0.83761096]\n",
      " [0.82948983]] | y: 0.6648585819449826 | Predicción actual: [[0.82012206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038169585168361664, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84507751]\n",
      " [0.84332758]\n",
      " [0.84290475]\n",
      " [0.68539326]\n",
      " [0.8447302 ]\n",
      " [0.83761096]\n",
      " [0.82948983]\n",
      " [0.82012206]] | y: 0.7113521890740022 | Predicción actual: [[0.81000125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.14719519019126892, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84332758]\n",
      " [0.84290475]\n",
      " [0.68539326]\n",
      " [0.8447302 ]\n",
      " [0.83761096]\n",
      " [0.82948983]\n",
      " [0.82012206]\n",
      " [0.81000125]] | y: 0.6772568771793879 | Predicción actual: [[0.79871064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00481968792155385, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84290475]\n",
      " [0.68539326]\n",
      " [0.8447302 ]\n",
      " [0.83761096]\n",
      " [0.82948983]\n",
      " [0.82012206]\n",
      " [0.81000125]\n",
      " [0.79871064]] | y: 0.7621077101898488 | Predicción actual: [[0.78716356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013342027086764574, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.8447302 ]\n",
      " [0.83761096]\n",
      " [0.82948983]\n",
      " [0.82012206]\n",
      " [0.81000125]\n",
      " [0.79871064]\n",
      " [0.78716356]] | y: 0.8070515304145678 | Predicción actual: [[0.77534026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001066871773218736, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8447302 ]\n",
      " [0.83761096]\n",
      " [0.82948983]\n",
      " [0.82012206]\n",
      " [0.81000125]\n",
      " [0.79871064]\n",
      " [0.78716356]\n",
      " [0.77534026]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002969726629089564, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83761096]\n",
      " [0.82948983]\n",
      " [0.82012206]\n",
      " [0.81000125]\n",
      " [0.79871064]\n",
      " [0.78716356]\n",
      " [0.77534026]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7971351]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03885366767644882, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82948983]\n",
      " [0.82012206]\n",
      " [0.81000125]\n",
      " [0.79871064]\n",
      " [0.78716356]\n",
      " [0.77534026]\n",
      " [0.81518791]\n",
      " [0.79713511]] | y: 0.9597055404881829 | Predicción actual: [[0.7881627]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08084338903427124, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82012206]\n",
      " [0.81000125]\n",
      " [0.79871064]\n",
      " [0.78716356]\n",
      " [0.77534026]\n",
      " [0.81518791]\n",
      " [0.79713511]\n",
      " [0.78816271]] | y: 0.9643549012010848 | Predicción actual: [[0.7802718]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06379605084657669, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81000125]\n",
      " [0.79871064]\n",
      " [0.78716356]\n",
      " [0.77534026]\n",
      " [0.81518791]\n",
      " [0.79713511]\n",
      " [0.78816271]\n",
      " [0.78027183]] | y: 0.8880278961642774 | Predicción actual: [[0.7739911]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006720064207911491, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79871064]\n",
      " [0.78716356]\n",
      " [0.77534026]\n",
      " [0.81518791]\n",
      " [0.79713511]\n",
      " [0.78816271]\n",
      " [0.78027183]\n",
      " [0.77399111]] | y: 0.8926772568771792 | Predicción actual: [[0.769498]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01026076078414917, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78716356]\n",
      " [0.77534026]\n",
      " [0.81518791]\n",
      " [0.79713511]\n",
      " [0.78816271]\n",
      " [0.78027183]\n",
      " [0.77399111]\n",
      " [0.76949799]] | y: 0.8752421542037967 | Predicción actual: [[0.76734304]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032307994551956654, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77534026]\n",
      " [0.81518791]\n",
      " [0.79713511]\n",
      " [0.78816271]\n",
      " [0.78027183]\n",
      " [0.77399111]\n",
      " [0.76949799]\n",
      " [0.76734304]] | y: 0.8508330104610615 | Predicción actual: [[0.7676913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.056369703495875e-05, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.79713511]\n",
      " [0.78816271]\n",
      " [0.78027183]\n",
      " [0.77399111]\n",
      " [0.76949799]\n",
      " [0.76734304]\n",
      " [0.76769131]] | y: 0.8488957768306855 | Predicción actual: [[0.770658]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012079136213287711, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79713511]\n",
      " [0.78816271]\n",
      " [0.78027183]\n",
      " [0.77399111]\n",
      " [0.76949799]\n",
      " [0.76734304]\n",
      " [0.76769131]\n",
      " [0.77065802]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07047531753778458, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78816271]\n",
      " [0.78027183]\n",
      " [0.77399111]\n",
      " [0.76949799]\n",
      " [0.76734304]\n",
      " [0.76769131]\n",
      " [0.77065802]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.75834703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07657576352357864, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78027183]\n",
      " [0.77399111]\n",
      " [0.76949799]\n",
      " [0.76734304]\n",
      " [0.76769131]\n",
      " [0.77065802]\n",
      " [0.96241767]\n",
      " [0.75834703]] | y: 0.9407206509104997 | Predicción actual: [[0.7579067]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03924380987882614, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77399111]\n",
      " [0.76949799]\n",
      " [0.76734304]\n",
      " [0.76769131]\n",
      " [0.77065802]\n",
      " [0.96241767]\n",
      " [0.75834703]\n",
      " [0.75790668]] | y: 0.9724912824486633 | Predicción actual: [[0.7607674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11255869269371033, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76949799]\n",
      " [0.76734304]\n",
      " [0.76769131]\n",
      " [0.77065802]\n",
      " [0.96241767]\n",
      " [0.75834703]\n",
      " [0.75790668]\n",
      " [0.7607674 ]] | y: 0.9969004261913985 | Predicción actual: [[0.76668364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.15231619775295258, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76734304]\n",
      " [0.76769131]\n",
      " [0.77065802]\n",
      " [0.96241767]\n",
      " [0.75834703]\n",
      " [0.75790668]\n",
      " [0.7607674 ]\n",
      " [0.76668364]] | y: 0.951181712514529 | Predicción actual: [[0.7750146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045109234750270844, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76769131]\n",
      " [0.77065802]\n",
      " [0.96241767]\n",
      " [0.75834703]\n",
      " [0.75790668]\n",
      " [0.7607674 ]\n",
      " [0.76668364]\n",
      " [0.77501458]] | y: 0.8957768306857805 | Predicción actual: [[0.7846126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006322947447188199, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77065802]\n",
      " [0.96241767]\n",
      " [0.75834703]\n",
      " [0.75790668]\n",
      " [0.7607674 ]\n",
      " [0.76668364]\n",
      " [0.77501458]\n",
      " [0.7846126 ]] | y: 0.8814413018209997 | Predicción actual: [[0.79410416]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020150043070316315, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.75834703]\n",
      " [0.75790668]\n",
      " [0.7607674 ]\n",
      " [0.76668364]\n",
      " [0.77501458]\n",
      " [0.7846126 ]\n",
      " [0.79410416]] | y: 0.9170864006199149 | Predicción actual: [[0.8025572]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016396138817071915, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75834703]\n",
      " [0.75790668]\n",
      " [0.7607674 ]\n",
      " [0.76668364]\n",
      " [0.77501458]\n",
      " [0.7846126 ]\n",
      " [0.79410416]\n",
      " [0.80255717]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010924335569143295, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75790668]\n",
      " [0.7607674 ]\n",
      " [0.76668364]\n",
      " [0.77501458]\n",
      " [0.7846126 ]\n",
      " [0.79410416]\n",
      " [0.80255717]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7629967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0226308424025774, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7607674 ]\n",
      " [0.76668364]\n",
      " [0.77501458]\n",
      " [0.7846126 ]\n",
      " [0.79410416]\n",
      " [0.80255717]\n",
      " [0.91979853]\n",
      " [0.76299667]] | y: 0.9682293684618366 | Predicción actual: [[0.771894]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09079425781965256, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76668364]\n",
      " [0.77501458]\n",
      " [0.7846126 ]\n",
      " [0.79410416]\n",
      " [0.80255717]\n",
      " [0.91979853]\n",
      " [0.76299667]\n",
      " [0.77189398]] | y: 0.9577683068578069 | Predicción actual: [[0.7826153]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05116519331932068, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.22608866]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03666554018855095, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22608866]] | y: 0.10422316931421921 | Predicción actual: [[0.2114244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01582328975200653, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22608866]\n",
      " [0.2114244 ]] | y: 0.15420379697791559 | Predicción actual: [[0.21594661]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002104429295286536, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22608866]\n",
      " [0.2114244 ]\n",
      " [0.21594661]] | y: 0.1557535838822161 | Predicción actual: [[0.22797377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006420997902750969, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22608866]\n",
      " [0.2114244 ]\n",
      " [0.21594661]\n",
      " [0.22797377]] | y: 0.12553273924835334 | Predicción actual: [[0.24166554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014359481632709503, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22608866]\n",
      " [0.2114244 ]\n",
      " [0.21594661]\n",
      " [0.22797377]\n",
      " [0.24166554]] | y: 0.1456799690042619 | Predicción actual: [[0.25347787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018247321248054504, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.22608866]\n",
      " [0.2114244 ]\n",
      " [0.21594661]\n",
      " [0.22797377]\n",
      " [0.24166554]\n",
      " [0.25347787]] | y: 0.1464548624564122 | Predicción actual: [[0.27723697]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026951655745506287, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.22608866]\n",
      " [0.2114244 ]\n",
      " [0.21594661]\n",
      " [0.22797377]\n",
      " [0.24166554]\n",
      " [0.25347787]\n",
      " [0.27723697]] | y: 0.1960480433940332 | Predicción actual: [[0.30674738]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013153890147805214, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22608866]\n",
      " [0.2114244 ]\n",
      " [0.21594661]\n",
      " [0.22797377]\n",
      " [0.24166554]\n",
      " [0.25347787]\n",
      " [0.27723697]\n",
      " [0.30674738]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015341004356741905, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2114244 ]\n",
      " [0.21594661]\n",
      " [0.22797377]\n",
      " [0.24166554]\n",
      " [0.25347787]\n",
      " [0.27723697]\n",
      " [0.30674738]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3451591]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024372827261686325, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21594661]\n",
      " [0.22797377]\n",
      " [0.24166554]\n",
      " [0.25347787]\n",
      " [0.27723697]\n",
      " [0.30674738]\n",
      " [0.2305308 ]\n",
      " [0.34515911]] | y: 0.211933359163115 | Predicción actual: [[0.35263428]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010214675217866898, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22797377]\n",
      " [0.24166554]\n",
      " [0.25347787]\n",
      " [0.27723697]\n",
      " [0.30674738]\n",
      " [0.2305308 ]\n",
      " [0.34515911]\n",
      " [0.35263428]] | y: 0.2072839984502131 | Predicción actual: [[0.36196604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02530977502465248, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24166554]\n",
      " [0.25347787]\n",
      " [0.27723697]\n",
      " [0.30674738]\n",
      " [0.2305308 ]\n",
      " [0.34515911]\n",
      " [0.35263428]\n",
      " [0.36196604]] | y: 0.19294846958543205 | Predicción actual: [[0.37195033]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036067623645067215, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25347787]\n",
      " [0.27723697]\n",
      " [0.30674738]\n",
      " [0.2305308 ]\n",
      " [0.34515911]\n",
      " [0.35263428]\n",
      " [0.36196604]\n",
      " [0.37195033]] | y: 0.19682293684618352 | Predicción actual: [[0.38244554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04000624269247055, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27723697]\n",
      " [0.30674738]\n",
      " [0.2305308 ]\n",
      " [0.34515911]\n",
      " [0.35263428]\n",
      " [0.36196604]\n",
      " [0.37195033]\n",
      " [0.38244554]] | y: 0.21425803951956607 | Predicción actual: [[0.39402652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047308530658483505, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30674738]\n",
      " [0.2305308 ]\n",
      " [0.34515911]\n",
      " [0.35263428]\n",
      " [0.36196604]\n",
      " [0.37195033]\n",
      " [0.38244554]\n",
      " [0.39402652]] | y: 0.18132506780317698 | Predicción actual: [[0.4040284]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10175731778144836, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.34515911]\n",
      " [0.35263428]\n",
      " [0.36196604]\n",
      " [0.37195033]\n",
      " [0.38244554]\n",
      " [0.39402652]\n",
      " [0.40402839]] | y: 0.17512592018597434 | Predicción actual: [[0.41070703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039161860942840576, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34515911]\n",
      " [0.35263428]\n",
      " [0.36196604]\n",
      " [0.37195033]\n",
      " [0.38244554]\n",
      " [0.39402652]\n",
      " [0.40402839]\n",
      " [0.41070703]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07563714683055878, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35263428]\n",
      " [0.36196604]\n",
      " [0.37195033]\n",
      " [0.38244554]\n",
      " [0.39402652]\n",
      " [0.40402839]\n",
      " [0.41070703]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.44356474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08702455461025238, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36196604]\n",
      " [0.37195033]\n",
      " [0.38244554]\n",
      " [0.39402652]\n",
      " [0.40402839]\n",
      " [0.41070703]\n",
      " [0.14800465]\n",
      " [0.44356474]] | y: 0.19217357613328173 | Predicción actual: [[0.44685596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.062018342316150665, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37195033]\n",
      " [0.38244554]\n",
      " [0.39402652]\n",
      " [0.40402839]\n",
      " [0.41070703]\n",
      " [0.14800465]\n",
      " [0.44356474]\n",
      " [0.44685596]] | y: 0.1859744285160791 | Predicción actual: [[0.4481565]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04284900054335594, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38244554]\n",
      " [0.39402652]\n",
      " [0.40402839]\n",
      " [0.41070703]\n",
      " [0.14800465]\n",
      " [0.44356474]\n",
      " [0.44685596]\n",
      " [0.44815651]] | y: 0.26695079426578844 | Predicción actual: [[0.44761088]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031633105129003525, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39402652]\n",
      " [0.40402839]\n",
      " [0.41070703]\n",
      " [0.14800465]\n",
      " [0.44356474]\n",
      " [0.44685596]\n",
      " [0.44815651]\n",
      " [0.44761088]] | y: 0.2925222781867493 | Predicción actual: [[0.4455066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03349749743938446, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40402839]\n",
      " [0.41070703]\n",
      " [0.14800465]\n",
      " [0.44356474]\n",
      " [0.44685596]\n",
      " [0.44815651]\n",
      " [0.44761088]\n",
      " [0.4455066 ]] | y: 0.3177063153816349 | Predicción actual: [[0.44200522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005878351628780365, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41070703]\n",
      " [0.14800465]\n",
      " [0.44356474]\n",
      " [0.44685596]\n",
      " [0.44815651]\n",
      " [0.44761088]\n",
      " [0.4455066 ]\n",
      " [0.44200522]] | y: 0.31266950794265785 | Predicción actual: [[0.43789977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030453220009803772, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.44356474]\n",
      " [0.44685596]\n",
      " [0.44815651]\n",
      " [0.44761088]\n",
      " [0.4455066 ]\n",
      " [0.44200522]\n",
      " [0.43789977]] | y: 0.2890352576520729 | Predicción actual: [[0.43417442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020304733887314796, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44356474]\n",
      " [0.44685596]\n",
      " [0.44815651]\n",
      " [0.44761088]\n",
      " [0.4455066 ]\n",
      " [0.44200522]\n",
      " [0.43789977]\n",
      " [0.43417442]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0628780648112297, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44685596]\n",
      " [0.44815651]\n",
      " [0.44761088]\n",
      " [0.4455066 ]\n",
      " [0.44200522]\n",
      " [0.43789977]\n",
      " [0.43417442]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.49403423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03269094228744507, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44815651]\n",
      " [0.44761088]\n",
      " [0.4455066 ]\n",
      " [0.44200522]\n",
      " [0.43789977]\n",
      " [0.43417442]\n",
      " [0.28283611]\n",
      " [0.49403423]] | y: 0.2758620689655173 | Predicción actual: [[0.49043128]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045707132667303085, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44761088]\n",
      " [0.4455066 ]\n",
      " [0.44200522]\n",
      " [0.43789977]\n",
      " [0.43417442]\n",
      " [0.28283611]\n",
      " [0.49403423]\n",
      " [0.49043128]] | y: 0.2746997287872917 | Predicción actual: [[0.48559004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02943924255669117, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4455066 ]\n",
      " [0.44200522]\n",
      " [0.43789977]\n",
      " [0.43417442]\n",
      " [0.28283611]\n",
      " [0.49403423]\n",
      " [0.49043128]\n",
      " [0.48559004]] | y: 0.275474622239442 | Predicción actual: [[0.48053014]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022913170978426933, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44200522]\n",
      " [0.43789977]\n",
      " [0.43417442]\n",
      " [0.28283611]\n",
      " [0.49403423]\n",
      " [0.49043128]\n",
      " [0.48559004]\n",
      " [0.48053014]] | y: 0.3347539713289423 | Predicción actual: [[0.4762922]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0245340708643198, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43789977]\n",
      " [0.43417442]\n",
      " [0.28283611]\n",
      " [0.49403423]\n",
      " [0.49043128]\n",
      " [0.48559004]\n",
      " [0.48053014]\n",
      " [0.47629219]] | y: 0.35567609453700116 | Predicción actual: [[0.47383052]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02230054885149002, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43417442]\n",
      " [0.28283611]\n",
      " [0.49403423]\n",
      " [0.49043128]\n",
      " [0.48559004]\n",
      " [0.48053014]\n",
      " [0.47629219]\n",
      " [0.47383052]] | y: 0.3366912049593181 | Predicción actual: [[0.47382903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014920317567884922, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.49403423]\n",
      " [0.49043128]\n",
      " [0.48559004]\n",
      " [0.48053014]\n",
      " [0.47629219]\n",
      " [0.47383052]\n",
      " [0.47382903]] | y: 0.3335916311507167 | Predicción actual: [[0.47661394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0055551305413246155, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49403423]\n",
      " [0.49043128]\n",
      " [0.48559004]\n",
      " [0.48053014]\n",
      " [0.47629219]\n",
      " [0.47383052]\n",
      " [0.47382903]\n",
      " [0.47661394]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02928106114268303, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49043128]\n",
      " [0.48559004]\n",
      " [0.48053014]\n",
      " [0.47629219]\n",
      " [0.47383052]\n",
      " [0.47382903]\n",
      " [0.47661394]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5139423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011462431866675615, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48559004]\n",
      " [0.48053014]\n",
      " [0.47629219]\n",
      " [0.47383052]\n",
      " [0.47382903]\n",
      " [0.47661394]\n",
      " [0.3847346 ]\n",
      " [0.5139423 ]] | y: 0.5962805114296785 | Predicción actual: [[0.5093425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005786845926195383, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48053014]\n",
      " [0.47629219]\n",
      " [0.47383052]\n",
      " [0.47382903]\n",
      " [0.47661394]\n",
      " [0.3847346 ]\n",
      " [0.5139423 ]\n",
      " [0.50934249]] | y: 0.574583494769469 | Predicción actual: [[0.5053101]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008304326795041561, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47629219]\n",
      " [0.47383052]\n",
      " [0.47382903]\n",
      " [0.47661394]\n",
      " [0.3847346 ]\n",
      " [0.5139423 ]\n",
      " [0.50934249]\n",
      " [0.50531012]] | y: 0.6063541263076326 | Predicción actual: [[0.5024182]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011963320896029472, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47383052]\n",
      " [0.47382903]\n",
      " [0.47661394]\n",
      " [0.3847346 ]\n",
      " [0.5139423 ]\n",
      " [0.50934249]\n",
      " [0.50531012]\n",
      " [0.50241822]] | y: 0.5846571096474236 | Predicción actual: [[0.5010111]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009851683862507343, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47382903]\n",
      " [0.47661394]\n",
      " [0.3847346 ]\n",
      " [0.5139423 ]\n",
      " [0.50934249]\n",
      " [0.50531012]\n",
      " [0.50241822]\n",
      " [0.50101107]] | y: 0.5687717938783416 | Predicción actual: [[0.5010951]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.9681940102600493e-05, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47661394]\n",
      " [0.3847346 ]\n",
      " [0.5139423 ]\n",
      " [0.50934249]\n",
      " [0.50531012]\n",
      " [0.50241822]\n",
      " [0.50101107]\n",
      " [0.50109512]] | y: 0.6427741185586981 | Predicción actual: [[0.50231695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03038344532251358, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.5139423 ]\n",
      " [0.50934249]\n",
      " [0.50531012]\n",
      " [0.50241822]\n",
      " [0.50101107]\n",
      " [0.50109512]\n",
      " [0.50231695]] | y: 0.6617590081363811 | Predicción actual: [[0.5042793]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012985135428607464, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5139423 ]\n",
      " [0.50934249]\n",
      " [0.50531012]\n",
      " [0.50241822]\n",
      " [0.50101107]\n",
      " [0.50109512]\n",
      " [0.50231695]\n",
      " [0.50427932]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01264890469610691, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50934249]\n",
      " [0.50531012]\n",
      " [0.50241822]\n",
      " [0.50101107]\n",
      " [0.50109512]\n",
      " [0.50231695]\n",
      " [0.50427932]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5289805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010745787993073463, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50531012]\n",
      " [0.50241822]\n",
      " [0.50101107]\n",
      " [0.50109512]\n",
      " [0.50231695]\n",
      " [0.50427932]\n",
      " [0.67299496]\n",
      " [0.52898049]] | y: 0.703990701278574 | Predicción actual: [[0.53012437]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014786872081458569, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50241822]\n",
      " [0.50101107]\n",
      " [0.50109512]\n",
      " [0.50231695]\n",
      " [0.50427932]\n",
      " [0.67299496]\n",
      " [0.52898049]\n",
      " [0.53012437]] | y: 0.7272375048430839 | Predicción actual: [[0.53394806]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01823919452726841, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50101107]\n",
      " [0.50109512]\n",
      " [0.50231695]\n",
      " [0.50427932]\n",
      " [0.67299496]\n",
      " [0.52898049]\n",
      " [0.53012437]\n",
      " [0.53394806]] | y: 0.722588144130182 | Predicción actual: [[0.54041463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037004999816417694, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50109512]\n",
      " [0.50231695]\n",
      " [0.50427932]\n",
      " [0.67299496]\n",
      " [0.52898049]\n",
      " [0.53012437]\n",
      " [0.53394806]\n",
      " [0.54041463]] | y: 0.771793878341728 | Predicción actual: [[0.5492369]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08062656968832016, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50231695]\n",
      " [0.50427932]\n",
      " [0.67299496]\n",
      " [0.52898049]\n",
      " [0.53012437]\n",
      " [0.53394806]\n",
      " [0.54041463]\n",
      " [0.54923689]] | y: 0.7245253777605578 | Predicción actual: [[0.56001556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05444769188761711, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50427932]\n",
      " [0.67299496]\n",
      " [0.52898049]\n",
      " [0.53012437]\n",
      " [0.53394806]\n",
      " [0.54041463]\n",
      " [0.54923689]\n",
      " [0.56001556]] | y: 0.6710577295621851 | Predicción actual: [[0.5722684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004518772941082716, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.52898049]\n",
      " [0.53012437]\n",
      " [0.53394806]\n",
      " [0.54041463]\n",
      " [0.54923689]\n",
      " [0.56001556]\n",
      " [0.57226843]] | y: 0.6737698566447115 | Predicción actual: [[0.58554035]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030829256400465965, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52898049]\n",
      " [0.53012437]\n",
      " [0.53394806]\n",
      " [0.54041463]\n",
      " [0.54923689]\n",
      " [0.56001556]\n",
      " [0.57226843]\n",
      " [0.58554035]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008566888980567455, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53012437]\n",
      " [0.53394806]\n",
      " [0.54041463]\n",
      " [0.54923689]\n",
      " [0.56001556]\n",
      " [0.57226843]\n",
      " [0.58554035]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5630099]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021201206371188164, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53394806]\n",
      " [0.54041463]\n",
      " [0.54923689]\n",
      " [0.56001556]\n",
      " [0.57226843]\n",
      " [0.58554035]\n",
      " [0.71445176]\n",
      " [0.56300992]] | y: 0.722588144130182 | Predicción actual: [[0.57152104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028983520343899727, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54041463]\n",
      " [0.54923689]\n",
      " [0.56001556]\n",
      " [0.57226843]\n",
      " [0.58554035]\n",
      " [0.71445176]\n",
      " [0.56300992]\n",
      " [0.57152104]] | y: 0.6993413405656723 | Predicción actual: [[0.5820006]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003833546070381999, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54923689]\n",
      " [0.56001556]\n",
      " [0.57226843]\n",
      " [0.58554035]\n",
      " [0.71445176]\n",
      " [0.56300992]\n",
      " [0.57152104]\n",
      " [0.58200061]] | y: 0.7373111197210385 | Predicción actual: [[0.5934522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025090673938393593, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56001556]\n",
      " [0.57226843]\n",
      " [0.58554035]\n",
      " [0.71445176]\n",
      " [0.56300992]\n",
      " [0.57152104]\n",
      " [0.58200061]\n",
      " [0.59345222]] | y: 0.7214258039519565 | Predicción actual: [[0.6049207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025105176493525505, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57226843]\n",
      " [0.58554035]\n",
      " [0.71445176]\n",
      " [0.56300992]\n",
      " [0.57152104]\n",
      " [0.58200061]\n",
      " [0.59345222]\n",
      " [0.60492069]] | y: 0.7187136768694304 | Predicción actual: [[0.6153649]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01597829908132553, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58554035]\n",
      " [0.71445176]\n",
      " [0.56300992]\n",
      " [0.57152104]\n",
      " [0.58200061]\n",
      " [0.59345222]\n",
      " [0.60492069]\n",
      " [0.61536491]] | y: 0.6741573033707864 | Predicción actual: [[0.62384045]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001129691256210208, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56300992]\n",
      " [0.57152104]\n",
      " [0.58200061]\n",
      " [0.59345222]\n",
      " [0.60492069]\n",
      " [0.61536491]\n",
      " [0.62384045]] | y: 0.698566447113522 | Predicción actual: [[0.6295236]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025696749798953533, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56300992]\n",
      " [0.57152104]\n",
      " [0.58200061]\n",
      " [0.59345222]\n",
      " [0.60492069]\n",
      " [0.61536491]\n",
      " [0.62384045]\n",
      " [0.62952358]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009595798328518867, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57152104]\n",
      " [0.58200061]\n",
      " [0.59345222]\n",
      " [0.60492069]\n",
      " [0.61536491]\n",
      " [0.62384045]\n",
      " [0.62952358]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6112893]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024868011474609375, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58200061]\n",
      " [0.59345222]\n",
      " [0.60492069]\n",
      " [0.61536491]\n",
      " [0.62384045]\n",
      " [0.62952358]\n",
      " [0.72103836]\n",
      " [0.61128932]] | y: 0.7562960092987214 | Predicción actual: [[0.6219886]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004743508470710367, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59345222]\n",
      " [0.60492069]\n",
      " [0.61536491]\n",
      " [0.62384045]\n",
      " [0.62952358]\n",
      " [0.72103836]\n",
      " [0.61128932]\n",
      " [0.62198859]] | y: 0.8275862068965516 | Predicción actual: [[0.63270146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.16613268852233887, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60492069]\n",
      " [0.61536491]\n",
      " [0.62384045]\n",
      " [0.62952358]\n",
      " [0.72103836]\n",
      " [0.61128932]\n",
      " [0.62198859]\n",
      " [0.63270146]] | y: 0.8388221619527314 | Predicción actual: [[0.64295983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04307974502444267, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61536491]\n",
      " [0.62384045]\n",
      " [0.62952358]\n",
      " [0.72103836]\n",
      " [0.61128932]\n",
      " [0.62198859]\n",
      " [0.63270146]\n",
      " [0.64295983]] | y: 0.7942657884540876 | Predicción actual: [[0.652127]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021465793251991272, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62384045]\n",
      " [0.62952358]\n",
      " [0.72103836]\n",
      " [0.61128932]\n",
      " [0.62198859]\n",
      " [0.63270146]\n",
      " [0.64295983]\n",
      " [0.65212703]] | y: 0.7838047268500579 | Predicción actual: [[0.65989375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020676303654909134, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62952358]\n",
      " [0.72103836]\n",
      " [0.61128932]\n",
      " [0.62198859]\n",
      " [0.63270146]\n",
      " [0.64295983]\n",
      " [0.65212703]\n",
      " [0.65989375]] | y: 0.7679194110809764 | Predicción actual: [[0.6663875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034337444230914116, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.61128932]\n",
      " [0.62198859]\n",
      " [0.63270146]\n",
      " [0.64295983]\n",
      " [0.65212703]\n",
      " [0.65989375]\n",
      " [0.6663875 ]] | y: 0.7845796203022084 | Predicción actual: [[0.67203516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012422554194927216, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61128932]\n",
      " [0.62198859]\n",
      " [0.63270146]\n",
      " [0.64295983]\n",
      " [0.65212703]\n",
      " [0.65989375]\n",
      " [0.6663875 ]\n",
      " [0.67203516]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01748993992805481, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62198859]\n",
      " [0.63270146]\n",
      " [0.64295983]\n",
      " [0.65212703]\n",
      " [0.65989375]\n",
      " [0.6663875 ]\n",
      " [0.67203516]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.66438097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009838253259658813, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63270146]\n",
      " [0.64295983]\n",
      " [0.65212703]\n",
      " [0.65989375]\n",
      " [0.6663875 ]\n",
      " [0.67203516]\n",
      " [0.87872917]\n",
      " [0.66438097]] | y: 0.8488957768306855 | Predicción actual: [[0.6765939]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05818139389157295, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64295983]\n",
      " [0.65212703]\n",
      " [0.65989375]\n",
      " [0.6663875 ]\n",
      " [0.67203516]\n",
      " [0.87872917]\n",
      " [0.66438097]\n",
      " [0.6765939 ]] | y: 0.8182874854707476 | Predicción actual: [[0.6899008]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005667887628078461, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65212703]\n",
      " [0.65989375]\n",
      " [0.6663875 ]\n",
      " [0.67203516]\n",
      " [0.87872917]\n",
      " [0.66438097]\n",
      " [0.6765939 ]\n",
      " [0.68990082]] | y: 0.8268113134444013 | Predicción actual: [[0.7038038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018934793770313263, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65989375]\n",
      " [0.6663875 ]\n",
      " [0.67203516]\n",
      " [0.87872917]\n",
      " [0.66438097]\n",
      " [0.6765939 ]\n",
      " [0.68990082]\n",
      " [0.70380378]] | y: 0.7853545137543589 | Predicción actual: [[0.7181076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.075743946596049e-06, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6663875 ]\n",
      " [0.67203516]\n",
      " [0.87872917]\n",
      " [0.66438097]\n",
      " [0.6765939 ]\n",
      " [0.68990082]\n",
      " [0.70380378]\n",
      " [0.71810758]] | y: 0.7892289810151103 | Predicción actual: [[0.73245084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.8836057279258966e-05, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67203516]\n",
      " [0.87872917]\n",
      " [0.66438097]\n",
      " [0.6765939 ]\n",
      " [0.68990082]\n",
      " [0.70380378]\n",
      " [0.71810758]\n",
      " [0.73245084]] | y: 0.8341728012398295 | Predicción actual: [[0.74671507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021628722548484802, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.66438097]\n",
      " [0.6765939 ]\n",
      " [0.68990082]\n",
      " [0.70380378]\n",
      " [0.71810758]\n",
      " [0.73245084]\n",
      " [0.74671507]] | y: 0.8124757845796202 | Predicción actual: [[0.761028]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00304866349324584, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66438097]\n",
      " [0.6765939 ]\n",
      " [0.68990082]\n",
      " [0.70380378]\n",
      " [0.71810758]\n",
      " [0.73245084]\n",
      " [0.74671507]\n",
      " [0.76102799]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.246731259627268e-05, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6765939 ]\n",
      " [0.68990082]\n",
      " [0.70380378]\n",
      " [0.71810758]\n",
      " [0.73245084]\n",
      " [0.74671507]\n",
      " [0.76102799]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.73054093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021425746381282806, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68990082]\n",
      " [0.70380378]\n",
      " [0.71810758]\n",
      " [0.73245084]\n",
      " [0.74671507]\n",
      " [0.76102799]\n",
      " [0.80123983]\n",
      " [0.73054093]] | y: 0.793490895001937 | Predicción actual: [[0.74435365]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003574998409021646, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70380378]\n",
      " [0.71810758]\n",
      " [0.73245084]\n",
      " [0.74671507]\n",
      " [0.76102799]\n",
      " [0.80123983]\n",
      " [0.73054093]\n",
      " [0.74435365]] | y: 0.760170476559473 | Predicción actual: [[0.7577483]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013193969614803791, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71810758]\n",
      " [0.73245084]\n",
      " [0.74671507]\n",
      " [0.76102799]\n",
      " [0.80123983]\n",
      " [0.73054093]\n",
      " [0.74435365]\n",
      " [0.75774831]] | y: 0.7353738860906625 | Predicción actual: [[0.7697297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001906449324451387, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73245084]\n",
      " [0.74671507]\n",
      " [0.76102799]\n",
      " [0.80123983]\n",
      " [0.73054093]\n",
      " [0.74435365]\n",
      " [0.75774831]\n",
      " [0.76972967]] | y: 0.7101898488957767 | Predicción actual: [[0.7798589]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011873223818838596, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74671507]\n",
      " [0.76102799]\n",
      " [0.80123983]\n",
      " [0.73054093]\n",
      " [0.74435365]\n",
      " [0.75774831]\n",
      " [0.76972967]\n",
      " [0.77985889]] | y: 0.7121270825261525 | Predicción actual: [[0.7872951]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020184645429253578, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76102799]\n",
      " [0.80123983]\n",
      " [0.73054093]\n",
      " [0.74435365]\n",
      " [0.75774831]\n",
      " [0.76972967]\n",
      " [0.77985889]\n",
      " [0.7872951 ]] | y: 0.7396358000774894 | Predicción actual: [[0.7915521]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00037319603143259883, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.73054093]\n",
      " [0.74435365]\n",
      " [0.75774831]\n",
      " [0.76972967]\n",
      " [0.77985889]\n",
      " [0.7872951 ]\n",
      " [0.79155213]] | y: 0.7361487795428128 | Predicción actual: [[0.7926039]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02530127950012684, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73054093]\n",
      " [0.74435365]\n",
      " [0.75774831]\n",
      " [0.76972967]\n",
      " [0.77985889]\n",
      " [0.7872951 ]\n",
      " [0.79155213]\n",
      " [0.79260391]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021302984096109867, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74435365]\n",
      " [0.75774831]\n",
      " [0.76972967]\n",
      " [0.77985889]\n",
      " [0.7872951 ]\n",
      " [0.79155213]\n",
      " [0.79260391]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.79285234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015993010252714157, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75774831]\n",
      " [0.76972967]\n",
      " [0.77985889]\n",
      " [0.7872951 ]\n",
      " [0.79155213]\n",
      " [0.79260391]\n",
      " [0.66757071]\n",
      " [0.79285234]] | y: 0.696629213483146 | Predicción actual: [[0.8000447]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05587295815348625, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76972967]\n",
      " [0.77985889]\n",
      " [0.7872951 ]\n",
      " [0.79155213]\n",
      " [0.79260391]\n",
      " [0.66757071]\n",
      " [0.79285234]\n",
      " [0.80004472]] | y: 0.6559473072452537 | Predicción actual: [[0.8036242]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03304903209209442, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77985889]\n",
      " [0.7872951 ]\n",
      " [0.79155213]\n",
      " [0.79260391]\n",
      " [0.66757071]\n",
      " [0.79285234]\n",
      " [0.80004472]\n",
      " [0.80362421]] | y: 0.6788066640836885 | Predicción actual: [[0.8038165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00048177922144532204, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7872951 ]\n",
      " [0.79155213]\n",
      " [0.79260391]\n",
      " [0.66757071]\n",
      " [0.79285234]\n",
      " [0.80004472]\n",
      " [0.80362421]\n",
      " [0.8038165 ]] | y: 0.6760945370011622 | Predicción actual: [[0.8013688]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02555343322455883, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79155213]\n",
      " [0.79260391]\n",
      " [0.66757071]\n",
      " [0.79285234]\n",
      " [0.80004472]\n",
      " [0.80362421]\n",
      " [0.8038165 ]\n",
      " [0.80136877]] | y: 0.7295621851995349 | Predicción actual: [[0.79687464]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039203912019729614, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79260391]\n",
      " [0.66757071]\n",
      " [0.79285234]\n",
      " [0.80004472]\n",
      " [0.80362421]\n",
      " [0.8038165 ]\n",
      " [0.80136877]\n",
      " [0.79687464]] | y: 0.7012785741960481 | Predicción actual: [[0.7913802]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003240564139559865, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.79285234]\n",
      " [0.80004472]\n",
      " [0.80362421]\n",
      " [0.8038165 ]\n",
      " [0.80136877]\n",
      " [0.79687464]\n",
      " [0.79138023]] | y: 0.767531964354901 | Predicción actual: [[0.7864168]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014173263683915138, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79285234]\n",
      " [0.80004472]\n",
      " [0.80362421]\n",
      " [0.8038165 ]\n",
      " [0.80136877]\n",
      " [0.79687464]\n",
      " [0.79138023]\n",
      " [0.78641683]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00042132369708269835, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80004472]\n",
      " [0.80362421]\n",
      " [0.8038165 ]\n",
      " [0.80136877]\n",
      " [0.79687464]\n",
      " [0.79138023]\n",
      " [0.78641683]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.81921744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019369829446077347, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80362421]\n",
      " [0.8038165 ]\n",
      " [0.80136877]\n",
      " [0.79687464]\n",
      " [0.79138023]\n",
      " [0.78641683]\n",
      " [0.75513367]\n",
      " [0.81921744]] | y: 0.7520340953118947 | Predicción actual: [[0.8169053]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.504960452322848e-05, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8038165 ]\n",
      " [0.80136877]\n",
      " [0.79687464]\n",
      " [0.79138023]\n",
      " [0.78641683]\n",
      " [0.75513367]\n",
      " [0.81921744]\n",
      " [0.81690532]] | y: 0.7098024021697016 | Predicción actual: [[0.81329846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010796711780130863, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80136877]\n",
      " [0.79687464]\n",
      " [0.79138023]\n",
      " [0.78641683]\n",
      " [0.75513367]\n",
      " [0.81921744]\n",
      " [0.81690532]\n",
      " [0.81329846]] | y: 0.6904300658659435 | Predicción actual: [[0.80931526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0055036284029483795, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79687464]\n",
      " [0.79138023]\n",
      " [0.78641683]\n",
      " [0.75513367]\n",
      " [0.81921744]\n",
      " [0.81690532]\n",
      " [0.81329846]\n",
      " [0.80931526]] | y: 0.7543587756683454 | Predicción actual: [[0.8060857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014571703504770994, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79138023]\n",
      " [0.78641683]\n",
      " [0.75513367]\n",
      " [0.81921744]\n",
      " [0.81690532]\n",
      " [0.81329846]\n",
      " [0.80931526]\n",
      " [0.80608571]] | y: 0.7222006974041069 | Predicción actual: [[0.80459994]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010810762643814087, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78641683]\n",
      " [0.75513367]\n",
      " [0.81921744]\n",
      " [0.81690532]\n",
      " [0.81329846]\n",
      " [0.80931526]\n",
      " [0.80608571]\n",
      " [0.80459994]] | y: 0.8485083301046106 | Predicción actual: [[0.8053268]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031487629748880863, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.81921744]\n",
      " [0.81690532]\n",
      " [0.81329846]\n",
      " [0.80931526]\n",
      " [0.80608571]\n",
      " [0.80459994]\n",
      " [0.80532682]] | y: 0.9054629988376597 | Predicción actual: [[0.80864215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012709335424005985, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81921744]\n",
      " [0.81690532]\n",
      " [0.81329846]\n",
      " [0.80931526]\n",
      " [0.80608571]\n",
      " [0.80459994]\n",
      " [0.80532682]\n",
      " [0.80864215]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021855738013982773, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81690532]\n",
      " [0.81329846]\n",
      " [0.80931526]\n",
      " [0.80608571]\n",
      " [0.80459994]\n",
      " [0.80532682]\n",
      " [0.80864215]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.82001364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010236961767077446, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81329846]\n",
      " [0.80931526]\n",
      " [0.80608571]\n",
      " [0.80459994]\n",
      " [0.80532682]\n",
      " [0.80864215]\n",
      " [0.8822162 ]\n",
      " [0.82001364]] | y: 0.889577683068578 | Predicción actual: [[0.8187507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02832937426865101, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80931526]\n",
      " [0.80608571]\n",
      " [0.80459994]\n",
      " [0.80532682]\n",
      " [0.80864215]\n",
      " [0.8822162 ]\n",
      " [0.82001364]\n",
      " [0.81875068]] | y: 0.8748547074777218 | Predicción actual: [[0.8193552]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020498945377767086, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80608571]\n",
      " [0.80459994]\n",
      " [0.80532682]\n",
      " [0.80864215]\n",
      " [0.8822162 ]\n",
      " [0.82001364]\n",
      " [0.81875068]\n",
      " [0.81935519]] | y: 0.9132119333591631 | Predicción actual: [[0.82190466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027273179963231087, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80459994]\n",
      " [0.80532682]\n",
      " [0.80864215]\n",
      " [0.8822162 ]\n",
      " [0.82001364]\n",
      " [0.81875068]\n",
      " [0.81935519]\n",
      " [0.82190466]] | y: 1.0 | Predicción actual: [[0.82657135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003789234207943082, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80532682]\n",
      " [0.80864215]\n",
      " [0.8822162 ]\n",
      " [0.82001364]\n",
      " [0.81875068]\n",
      " [0.81935519]\n",
      " [0.82190466]\n",
      " [0.82657135]] | y: 0.9705540488182873 | Predicción actual: [[0.8327074]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03967671096324921, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80864215]\n",
      " [0.8822162 ]\n",
      " [0.82001364]\n",
      " [0.81875068]\n",
      " [0.81935519]\n",
      " [0.82190466]\n",
      " [0.82657135]\n",
      " [0.83270741]] | y: 0.8888027896164277 | Predicción actual: [[0.839817]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004014645237475634, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.82001364]\n",
      " [0.81875068]\n",
      " [0.81935519]\n",
      " [0.82190466]\n",
      " [0.82657135]\n",
      " [0.83270741]\n",
      " [0.83981699]] | y: 0.877954281286323 | Predicción actual: [[0.84674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008021949790418148, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82001364]\n",
      " [0.81875068]\n",
      " [0.81935519]\n",
      " [0.82190466]\n",
      " [0.82657135]\n",
      " [0.83270741]\n",
      " [0.83981699]\n",
      " [0.84674001]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007115453481674194, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81875068]\n",
      " [0.81935519]\n",
      " [0.82190466]\n",
      " [0.82657135]\n",
      " [0.83270741]\n",
      " [0.83981699]\n",
      " [0.84674001]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.83449405]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.868100636987947e-06, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81935519]\n",
      " [0.82190466]\n",
      " [0.82657135]\n",
      " [0.83270741]\n",
      " [0.83981699]\n",
      " [0.84674001]\n",
      " [0.84889578]\n",
      " [0.83449405]] | y: 0.8550949244478885 | Predicción actual: [[0.83803004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014339194167405367, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82190466]\n",
      " [0.82657135]\n",
      " [0.83270741]\n",
      " [0.83981699]\n",
      " [0.84674001]\n",
      " [0.84889578]\n",
      " [0.83449405]\n",
      " [0.83803004]] | y: 0.8752421542037967 | Predicción actual: [[0.8424411]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004257194232195616, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82657135]\n",
      " [0.83270741]\n",
      " [0.83981699]\n",
      " [0.84674001]\n",
      " [0.84889578]\n",
      " [0.83449405]\n",
      " [0.83803004]\n",
      " [0.84244108]] | y: 0.857032158078264 | Predicción actual: [[0.8468986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01021082978695631, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83270741]\n",
      " [0.83981699]\n",
      " [0.84674001]\n",
      " [0.84889578]\n",
      " [0.83449405]\n",
      " [0.83803004]\n",
      " [0.84244108]\n",
      " [0.84689862]] | y: 0.8500581170089112 | Predicción actual: [[0.8509984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004905054229311645, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83981699]\n",
      " [0.84674001]\n",
      " [0.84889578]\n",
      " [0.83449405]\n",
      " [0.83803004]\n",
      " [0.84244108]\n",
      " [0.84689862]\n",
      " [0.8509984 ]] | y: 0.8426966292134832 | Predicción actual: [[0.853876]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028784270398318768, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84674001]\n",
      " [0.84889578]\n",
      " [0.83449405]\n",
      " [0.83803004]\n",
      " [0.84244108]\n",
      " [0.84689862]\n",
      " [0.8509984 ]\n",
      " [0.85387599]] | y: 0.8229368461836497 | Predicción actual: [[0.85499144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0186015572398901, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.83449405]\n",
      " [0.83803004]\n",
      " [0.84244108]\n",
      " [0.84689862]\n",
      " [0.8509984 ]\n",
      " [0.85387599]\n",
      " [0.85499144]] | y: 0.7745060054242543 | Predicción actual: [[0.85405993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035204723477363586, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83449405]\n",
      " [0.83803004]\n",
      " [0.84244108]\n",
      " [0.84689862]\n",
      " [0.8509984 ]\n",
      " [0.85387599]\n",
      " [0.85499144]\n",
      " [0.85405993]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03795197233557701, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83803004]\n",
      " [0.84244108]\n",
      " [0.84689862]\n",
      " [0.8509984 ]\n",
      " [0.85387599]\n",
      " [0.85499144]\n",
      " [0.85405993]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8543152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.465563248842955e-05, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84244108]\n",
      " [0.84689862]\n",
      " [0.8509984 ]\n",
      " [0.85387599]\n",
      " [0.85499144]\n",
      " [0.85405993]\n",
      " [0.78419217]\n",
      " [0.85431522]] | y: 0.854320030995738 | Predicción actual: [[0.8555508]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018327388679608703, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84689862]\n",
      " [0.8509984 ]\n",
      " [0.85387599]\n",
      " [0.85499144]\n",
      " [0.85405993]\n",
      " [0.78419217]\n",
      " [0.85431522]\n",
      " [0.85555083]] | y: 0.8368849283223556 | Predicción actual: [[0.85565084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008990829810500145, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8509984 ]\n",
      " [0.85387599]\n",
      " [0.85499144]\n",
      " [0.85405993]\n",
      " [0.78419217]\n",
      " [0.85431522]\n",
      " [0.85555083]\n",
      " [0.85565084]] | y: 0.8299108872530028 | Predicción actual: [[0.85442877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027935782447457314, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85387599]\n",
      " [0.85499144]\n",
      " [0.85405993]\n",
      " [0.78419217]\n",
      " [0.85431522]\n",
      " [0.85555083]\n",
      " [0.85565084]\n",
      " [0.85442877]] | y: 0.887253002712127 | Predicción actual: [[0.85213566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020552061323542148, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85499144]\n",
      " [0.85405993]\n",
      " [0.78419217]\n",
      " [0.85431522]\n",
      " [0.85555083]\n",
      " [0.85565084]\n",
      " [0.85442877]\n",
      " [0.85213566]] | y: 0.8597442851607902 | Predicción actual: [[0.8488491]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005844012484885752, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85405993]\n",
      " [0.78419217]\n",
      " [0.85431522]\n",
      " [0.85555083]\n",
      " [0.85565084]\n",
      " [0.85442877]\n",
      " [0.85213566]\n",
      " [0.84884912]] | y: 0.8395970554048819 | Predicción actual: [[0.8452728]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01695398800075054, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.85431522]\n",
      " [0.85555083]\n",
      " [0.85565084]\n",
      " [0.85442877]\n",
      " [0.85213566]\n",
      " [0.84884912]\n",
      " [0.84527278]] | y: 0.7838047268500579 | Predicción actual: [[0.8418015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.199293082114309e-05, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85431522]\n",
      " [0.85555083]\n",
      " [0.85565084]\n",
      " [0.85442877]\n",
      " [0.85213566]\n",
      " [0.84884912]\n",
      " [0.84527278]\n",
      " [0.84180152]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008212888613343239, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85555083]\n",
      " [0.85565084]\n",
      " [0.85442877]\n",
      " [0.85213566]\n",
      " [0.84884912]\n",
      " [0.84527278]\n",
      " [0.84180152]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8581443]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006807890022173524, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85565084]\n",
      " [0.85442877]\n",
      " [0.85213566]\n",
      " [0.84884912]\n",
      " [0.84527278]\n",
      " [0.84180152]\n",
      " [0.81828749]\n",
      " [0.85814428]] | y: 0.7605579232855482 | Predicción actual: [[0.85622936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037857044488191605, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85442877]\n",
      " [0.85213566]\n",
      " [0.84884912]\n",
      " [0.84527278]\n",
      " [0.84180152]\n",
      " [0.81828749]\n",
      " [0.85814428]\n",
      " [0.85622936]] | y: 0.7915536613715615 | Predicción actual: [[0.85329384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00037547017564065754, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85213566]\n",
      " [0.84884912]\n",
      " [0.84527278]\n",
      " [0.84180152]\n",
      " [0.81828749]\n",
      " [0.85814428]\n",
      " [0.85622936]\n",
      " [0.85329384]] | y: 0.7686943045331267 | Predicción actual: [[0.85036933]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012084927409887314, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84884912]\n",
      " [0.84527278]\n",
      " [0.84180152]\n",
      " [0.81828749]\n",
      " [0.85814428]\n",
      " [0.85622936]\n",
      " [0.85329384]\n",
      " [0.85036933]] | y: 0.7686943045331267 | Predicción actual: [[0.8476961]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011402895674109459, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84527278]\n",
      " [0.84180152]\n",
      " [0.81828749]\n",
      " [0.85814428]\n",
      " [0.85622936]\n",
      " [0.85329384]\n",
      " [0.85036933]\n",
      " [0.84769613]] | y: 0.7989151491669895 | Predicción actual: [[0.8457941]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00013180484529584646, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84180152]\n",
      " [0.81828749]\n",
      " [0.85814428]\n",
      " [0.85622936]\n",
      " [0.85329384]\n",
      " [0.85036933]\n",
      " [0.84769613]\n",
      " [0.84579408]] | y: 0.7900038744672608 | Predicción actual: [[0.84519655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.795971365936566e-05, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.85814428]\n",
      " [0.85622936]\n",
      " [0.85329384]\n",
      " [0.85036933]\n",
      " [0.84769613]\n",
      " [0.84579408]\n",
      " [0.84519655]] | y: 0.760170476559473 | Predicción actual: [[0.845986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0338582880795002, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85814428]\n",
      " [0.85622936]\n",
      " [0.85329384]\n",
      " [0.85036933]\n",
      " [0.84769613]\n",
      " [0.84579408]\n",
      " [0.84519655]\n",
      " [0.84598601]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008437952026724815, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85622936]\n",
      " [0.85329384]\n",
      " [0.85036933]\n",
      " [0.84769613]\n",
      " [0.84579408]\n",
      " [0.84519655]\n",
      " [0.84598601]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.84945756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015041626058518887, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85329384]\n",
      " [0.85036933]\n",
      " [0.84769613]\n",
      " [0.84579408]\n",
      " [0.84519655]\n",
      " [0.84598601]\n",
      " [0.68539326]\n",
      " [0.84945756]] | y: 0.6648585819449826 | Predicción actual: [[0.84375274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07356114685535431, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85036933]\n",
      " [0.84769613]\n",
      " [0.84579408]\n",
      " [0.84519655]\n",
      " [0.84598601]\n",
      " [0.68539326]\n",
      " [0.84945756]\n",
      " [0.84375274]] | y: 0.7078651685393258 | Predicción actual: [[0.83645076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0044243838638067245, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84769613]\n",
      " [0.84579408]\n",
      " [0.84519655]\n",
      " [0.84598601]\n",
      " [0.68539326]\n",
      " [0.84945756]\n",
      " [0.84375274]\n",
      " [0.83645076]] | y: 0.6648585819449826 | Predicción actual: [[0.8282875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036112098023295403, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84579408]\n",
      " [0.84519655]\n",
      " [0.84598601]\n",
      " [0.68539326]\n",
      " [0.84945756]\n",
      " [0.84375274]\n",
      " [0.83645076]\n",
      " [0.82828748]] | y: 0.7113521890740022 | Predicción actual: [[0.8195476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05542248860001564, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84519655]\n",
      " [0.84598601]\n",
      " [0.68539326]\n",
      " [0.84945756]\n",
      " [0.84375274]\n",
      " [0.83645076]\n",
      " [0.82828748]\n",
      " [0.81954759]] | y: 0.6772568771793879 | Predicción actual: [[0.80997896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015109056606888771, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84598601]\n",
      " [0.68539326]\n",
      " [0.84945756]\n",
      " [0.84375274]\n",
      " [0.83645076]\n",
      " [0.82828748]\n",
      " [0.81954759]\n",
      " [0.80997896]] | y: 0.7621077101898488 | Predicción actual: [[0.79987335]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005118946428410709, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84945756]\n",
      " [0.84375274]\n",
      " [0.83645076]\n",
      " [0.82828748]\n",
      " [0.81954759]\n",
      " [0.80997896]\n",
      " [0.79987335]] | y: 0.8070515304145678 | Predicción actual: [[0.78925097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03956013545393944, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84945756]\n",
      " [0.84375274]\n",
      " [0.83645076]\n",
      " [0.82828748]\n",
      " [0.81954759]\n",
      " [0.80997896]\n",
      " [0.79987335]\n",
      " [0.78925097]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009653291665017605, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84375274]\n",
      " [0.83645076]\n",
      " [0.82828748]\n",
      " [0.81954759]\n",
      " [0.80997896]\n",
      " [0.79987335]\n",
      " [0.78925097]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8160937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004430451896041632, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83645076]\n",
      " [0.82828748]\n",
      " [0.81954759]\n",
      " [0.80997896]\n",
      " [0.79987335]\n",
      " [0.78925097]\n",
      " [0.81518791]\n",
      " [0.81609368]] | y: 0.9597055404881829 | Predicción actual: [[0.80814296]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019782499875873327, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82828748]\n",
      " [0.81954759]\n",
      " [0.80997896]\n",
      " [0.79987335]\n",
      " [0.78925097]\n",
      " [0.81518791]\n",
      " [0.81609368]\n",
      " [0.80814296]] | y: 0.9643549012010848 | Predicción actual: [[0.80075896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006509827799163759, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81954759]\n",
      " [0.80997896]\n",
      " [0.79987335]\n",
      " [0.78925097]\n",
      " [0.81518791]\n",
      " [0.81609368]\n",
      " [0.80814296]\n",
      " [0.80075896]] | y: 0.8880278961642774 | Predicción actual: [[0.794671]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011660918593406677, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80997896]\n",
      " [0.79987335]\n",
      " [0.78925097]\n",
      " [0.81518791]\n",
      " [0.81609368]\n",
      " [0.80814296]\n",
      " [0.80075896]\n",
      " [0.794671  ]] | y: 0.8926772568771792 | Predicción actual: [[0.790048]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.2894432074972428e-05, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79987335]\n",
      " [0.78925097]\n",
      " [0.81518791]\n",
      " [0.81609368]\n",
      " [0.80814296]\n",
      " [0.80075896]\n",
      " [0.794671  ]\n",
      " [0.790048  ]] | y: 0.8752421542037967 | Predicción actual: [[0.787633]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00497019337490201, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78925097]\n",
      " [0.81518791]\n",
      " [0.81609368]\n",
      " [0.80814296]\n",
      " [0.80075896]\n",
      " [0.794671  ]\n",
      " [0.790048  ]\n",
      " [0.787633  ]] | y: 0.8508330104610615 | Predicción actual: [[0.7878686]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002731597749516368, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.81609368]\n",
      " [0.80814296]\n",
      " [0.80075896]\n",
      " [0.794671  ]\n",
      " [0.790048  ]\n",
      " [0.787633  ]\n",
      " [0.78786862]] | y: 0.8488957768306855 | Predicción actual: [[0.790976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001166259404271841, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81609368]\n",
      " [0.80814296]\n",
      " [0.80075896]\n",
      " [0.794671  ]\n",
      " [0.790048  ]\n",
      " [0.787633  ]\n",
      " [0.78786862]\n",
      " [0.79097599]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06855521351099014, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80814296]\n",
      " [0.80075896]\n",
      " [0.794671  ]\n",
      " [0.790048  ]\n",
      " [0.787633  ]\n",
      " [0.78786862]\n",
      " [0.79097599]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7827186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008038699626922607, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80075896]\n",
      " [0.794671  ]\n",
      " [0.790048  ]\n",
      " [0.787633  ]\n",
      " [0.78786862]\n",
      " [0.79097599]\n",
      " [0.96241767]\n",
      " [0.7827186 ]] | y: 0.9407206509104997 | Predicción actual: [[0.78148496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0211580079048872, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.794671  ]\n",
      " [0.790048  ]\n",
      " [0.787633  ]\n",
      " [0.78786862]\n",
      " [0.79097599]\n",
      " [0.96241767]\n",
      " [0.7827186 ]\n",
      " [0.78148496]] | y: 0.9724912824486633 | Predicción actual: [[0.7833522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08004824817180634, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.790048  ]\n",
      " [0.787633  ]\n",
      " [0.78786862]\n",
      " [0.79097599]\n",
      " [0.96241767]\n",
      " [0.7827186 ]\n",
      " [0.78148496]\n",
      " [0.7833522 ]] | y: 0.9969004261913985 | Predicción actual: [[0.7882098]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1398639678955078, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.787633  ]\n",
      " [0.78786862]\n",
      " [0.79097599]\n",
      " [0.96241767]\n",
      " [0.7827186 ]\n",
      " [0.78148496]\n",
      " [0.7833522 ]\n",
      " [0.7882098 ]] | y: 0.951181712514529 | Predicción actual: [[0.79557014]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03588627651333809, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78786862]\n",
      " [0.79097599]\n",
      " [0.96241767]\n",
      " [0.7827186 ]\n",
      " [0.78148496]\n",
      " [0.7833522 ]\n",
      " [0.7882098 ]\n",
      " [0.79557014]] | y: 0.8957768306857805 | Predicción actual: [[0.8043295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038864046800881624, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79097599]\n",
      " [0.96241767]\n",
      " [0.7827186 ]\n",
      " [0.78148496]\n",
      " [0.7833522 ]\n",
      " [0.7882098 ]\n",
      " [0.79557014]\n",
      " [0.80432951]] | y: 0.8814413018209997 | Predicción actual: [[0.8131744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038054224103689194, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.7827186 ]\n",
      " [0.78148496]\n",
      " [0.7833522 ]\n",
      " [0.7882098 ]\n",
      " [0.79557014]\n",
      " [0.80432951]\n",
      " [0.81317443]] | y: 0.9170864006199149 | Predicción actual: [[0.8211025]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0330379381775856, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7827186 ]\n",
      " [0.78148496]\n",
      " [0.7833522 ]\n",
      " [0.7882098 ]\n",
      " [0.79557014]\n",
      " [0.80432951]\n",
      " [0.81317443]\n",
      " [0.8211025 ]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002296325284987688, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78148496]\n",
      " [0.7833522 ]\n",
      " [0.7882098 ]\n",
      " [0.79557014]\n",
      " [0.80432951]\n",
      " [0.81317443]\n",
      " [0.8211025 ]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.78488404]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029197577387094498, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7833522 ]\n",
      " [0.7882098 ]\n",
      " [0.79557014]\n",
      " [0.80432951]\n",
      " [0.81317443]\n",
      " [0.8211025 ]\n",
      " [0.91979853]\n",
      " [0.78488404]] | y: 0.9682293684618366 | Predicción actual: [[0.79251707]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06567088514566422, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7882098 ]\n",
      " [0.79557014]\n",
      " [0.80432951]\n",
      " [0.81317443]\n",
      " [0.8211025 ]\n",
      " [0.91979853]\n",
      " [0.78488404]\n",
      " [0.79251707]] | y: 0.9577683068578069 | Predicción actual: [[0.80194104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01557653397321701, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.22381]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03899620473384857, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22381   ]] | y: 0.10422316931421921 | Predicción actual: [[0.20893985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007262738421559334, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22381   ]\n",
      " [0.20893985]] | y: 0.15420379697791559 | Predicción actual: [[0.21335816]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000846856040880084, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22381   ]\n",
      " [0.20893985]\n",
      " [0.21335816]] | y: 0.1557535838822161 | Predicción actual: [[0.22528067]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033362486865371466, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22381   ]\n",
      " [0.20893985]\n",
      " [0.21335816]\n",
      " [0.22528067]] | y: 0.12553273924835334 | Predicción actual: [[0.23882166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01786033995449543, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22381   ]\n",
      " [0.20893985]\n",
      " [0.21335816]\n",
      " [0.22528067]\n",
      " [0.23882166]] | y: 0.1456799690042619 | Predicción actual: [[0.25039235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009015696123242378, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.22381   ]\n",
      " [0.20893985]\n",
      " [0.21335816]\n",
      " [0.22528067]\n",
      " [0.23882166]\n",
      " [0.25039235]] | y: 0.1464548624564122 | Predicción actual: [[0.2738744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024003898724913597, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.22381   ]\n",
      " [0.20893985]\n",
      " [0.21335816]\n",
      " [0.22528067]\n",
      " [0.23882166]\n",
      " [0.25039235]\n",
      " [0.2738744 ]] | y: 0.1960480433940332 | Predicción actual: [[0.30301753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015159567818045616, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22381   ]\n",
      " [0.20893985]\n",
      " [0.21335816]\n",
      " [0.22528067]\n",
      " [0.23882166]\n",
      " [0.25039235]\n",
      " [0.2738744 ]\n",
      " [0.30301753]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009961233474314213, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20893985]\n",
      " [0.21335816]\n",
      " [0.22528067]\n",
      " [0.23882166]\n",
      " [0.25039235]\n",
      " [0.2738744 ]\n",
      " [0.30301753]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.34081292]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020466398447752, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21335816]\n",
      " [0.22528067]\n",
      " [0.23882166]\n",
      " [0.25039235]\n",
      " [0.2738744 ]\n",
      " [0.30301753]\n",
      " [0.2305308 ]\n",
      " [0.34081292]] | y: 0.211933359163115 | Predicción actual: [[0.34819937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016543766483664513, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22528067]\n",
      " [0.23882166]\n",
      " [0.25039235]\n",
      " [0.2738744 ]\n",
      " [0.30301753]\n",
      " [0.2305308 ]\n",
      " [0.34081292]\n",
      " [0.34819937]] | y: 0.2072839984502131 | Predicción actual: [[0.35743743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008761501871049404, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23882166]\n",
      " [0.25039235]\n",
      " [0.2738744 ]\n",
      " [0.30301753]\n",
      " [0.2305308 ]\n",
      " [0.34081292]\n",
      " [0.34819937]\n",
      " [0.35743743]] | y: 0.19294846958543205 | Predicción actual: [[0.36736026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04526688903570175, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25039235]\n",
      " [0.2738744 ]\n",
      " [0.30301753]\n",
      " [0.2305308 ]\n",
      " [0.34081292]\n",
      " [0.34819937]\n",
      " [0.35743743]\n",
      " [0.36736026]] | y: 0.19682293684618352 | Predicción actual: [[0.37777117]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04252682253718376, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2738744 ]\n",
      " [0.30301753]\n",
      " [0.2305308 ]\n",
      " [0.34081292]\n",
      " [0.34819937]\n",
      " [0.35743743]\n",
      " [0.36736026]\n",
      " [0.37777117]] | y: 0.21425803951956607 | Predicción actual: [[0.38927427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018559755757451057, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30301753]\n",
      " [0.2305308 ]\n",
      " [0.34081292]\n",
      " [0.34819937]\n",
      " [0.35743743]\n",
      " [0.36736026]\n",
      " [0.37777117]\n",
      " [0.38927427]] | y: 0.18132506780317698 | Predicción actual: [[0.39926633]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040869876742362976, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.34081292]\n",
      " [0.34819937]\n",
      " [0.35743743]\n",
      " [0.36736026]\n",
      " [0.37777117]\n",
      " [0.38927427]\n",
      " [0.39926633]] | y: 0.17512592018597434 | Predicción actual: [[0.40605542]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027964500710368156, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34081292]\n",
      " [0.34819937]\n",
      " [0.35743743]\n",
      " [0.36736026]\n",
      " [0.37777117]\n",
      " [0.38927427]\n",
      " [0.39926633]\n",
      " [0.40605542]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07159121334552765, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34819937]\n",
      " [0.35743743]\n",
      " [0.36736026]\n",
      " [0.37777117]\n",
      " [0.38927427]\n",
      " [0.39926633]\n",
      " [0.40605542]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.4382343]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11241667717695236, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35743743]\n",
      " [0.36736026]\n",
      " [0.37777117]\n",
      " [0.38927427]\n",
      " [0.39926633]\n",
      " [0.40605542]\n",
      " [0.14800465]\n",
      " [0.4382343 ]] | y: 0.19217357613328173 | Predicción actual: [[0.44161034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05521059408783913, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36736026]\n",
      " [0.37777117]\n",
      " [0.38927427]\n",
      " [0.39926633]\n",
      " [0.40605542]\n",
      " [0.14800465]\n",
      " [0.4382343 ]\n",
      " [0.44161034]] | y: 0.1859744285160791 | Predicción actual: [[0.44303703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0737442895770073, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37777117]\n",
      " [0.38927427]\n",
      " [0.39926633]\n",
      " [0.40605542]\n",
      " [0.14800465]\n",
      " [0.4382343 ]\n",
      " [0.44161034]\n",
      " [0.44303703]] | y: 0.26695079426578844 | Predicción actual: [[0.44258136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021967515349388123, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38927427]\n",
      " [0.39926633]\n",
      " [0.40605542]\n",
      " [0.14800465]\n",
      " [0.4382343 ]\n",
      " [0.44161034]\n",
      " [0.44303703]\n",
      " [0.44258136]] | y: 0.2925222781867493 | Predicción actual: [[0.44066906]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0239202197226405e-07, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39926633]\n",
      " [0.40605542]\n",
      " [0.14800465]\n",
      " [0.4382343 ]\n",
      " [0.44161034]\n",
      " [0.44303703]\n",
      " [0.44258136]\n",
      " [0.44066906]] | y: 0.3177063153816349 | Predicción actual: [[0.4374696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007894289679825306, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40605542]\n",
      " [0.14800465]\n",
      " [0.4382343 ]\n",
      " [0.44161034]\n",
      " [0.44303703]\n",
      " [0.44258136]\n",
      " [0.44066906]\n",
      " [0.4374696 ]] | y: 0.31266950794265785 | Predicción actual: [[0.43362743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017434692708775401, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.4382343 ]\n",
      " [0.44161034]\n",
      " [0.44303703]\n",
      " [0.44258136]\n",
      " [0.44066906]\n",
      " [0.4374696 ]\n",
      " [0.43362743]] | y: 0.2890352576520729 | Predicción actual: [[0.43018687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015544362366199493, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4382343 ]\n",
      " [0.44161034]\n",
      " [0.44303703]\n",
      " [0.44258136]\n",
      " [0.44066906]\n",
      " [0.4374696 ]\n",
      " [0.43362743]\n",
      " [0.43018687]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039074353873729706, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44161034]\n",
      " [0.44303703]\n",
      " [0.44258136]\n",
      " [0.44066906]\n",
      " [0.4374696 ]\n",
      " [0.43362743]\n",
      " [0.43018687]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.48983654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025890668854117393, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44303703]\n",
      " [0.44258136]\n",
      " [0.44066906]\n",
      " [0.4374696 ]\n",
      " [0.43362743]\n",
      " [0.43018687]\n",
      " [0.28283611]\n",
      " [0.48983654]] | y: 0.2758620689655173 | Predicción actual: [[0.48666137]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07250368595123291, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44258136]\n",
      " [0.44066906]\n",
      " [0.4374696 ]\n",
      " [0.43362743]\n",
      " [0.43018687]\n",
      " [0.28283611]\n",
      " [0.48983654]\n",
      " [0.48666137]] | y: 0.2746997287872917 | Predicción actual: [[0.4821976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044926416128873825, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44066906]\n",
      " [0.4374696 ]\n",
      " [0.43362743]\n",
      " [0.43018687]\n",
      " [0.28283611]\n",
      " [0.48983654]\n",
      " [0.48666137]\n",
      " [0.48219761]] | y: 0.275474622239442 | Predicción actual: [[0.47750652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03675517812371254, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4374696 ]\n",
      " [0.43362743]\n",
      " [0.43018687]\n",
      " [0.28283611]\n",
      " [0.48983654]\n",
      " [0.48666137]\n",
      " [0.48219761]\n",
      " [0.47750652]] | y: 0.3347539713289423 | Predicción actual: [[0.47361392]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016645370051264763, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43362743]\n",
      " [0.43018687]\n",
      " [0.28283611]\n",
      " [0.48983654]\n",
      " [0.48666137]\n",
      " [0.48219761]\n",
      " [0.47750652]\n",
      " [0.47361392]] | y: 0.35567609453700116 | Predicción actual: [[0.47150457]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021824916824698448, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43018687]\n",
      " [0.28283611]\n",
      " [0.48983654]\n",
      " [0.48666137]\n",
      " [0.48219761]\n",
      " [0.47750652]\n",
      " [0.47361392]\n",
      " [0.47150457]] | y: 0.3366912049593181 | Predicción actual: [[0.47184572]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006783640943467617, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.48983654]\n",
      " [0.48666137]\n",
      " [0.48219761]\n",
      " [0.47750652]\n",
      " [0.47361392]\n",
      " [0.47150457]\n",
      " [0.47184572]] | y: 0.3335916311507167 | Predicción actual: [[0.4749834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04101099818944931, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48983654]\n",
      " [0.48666137]\n",
      " [0.48219761]\n",
      " [0.47750652]\n",
      " [0.47361392]\n",
      " [0.47150457]\n",
      " [0.47184572]\n",
      " [0.47498339]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01352311484515667, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48666137]\n",
      " [0.48219761]\n",
      " [0.47750652]\n",
      " [0.47361392]\n",
      " [0.47150457]\n",
      " [0.47184572]\n",
      " [0.47498339]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5122018]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008118299301713705, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48219761]\n",
      " [0.47750652]\n",
      " [0.47361392]\n",
      " [0.47150457]\n",
      " [0.47184572]\n",
      " [0.47498339]\n",
      " [0.3847346 ]\n",
      " [0.51220179]] | y: 0.5962805114296785 | Predicción actual: [[0.5078925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024522429332137108, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47750652]\n",
      " [0.47361392]\n",
      " [0.47150457]\n",
      " [0.47184572]\n",
      " [0.47498339]\n",
      " [0.3847346 ]\n",
      " [0.51220179]\n",
      " [0.50789249]] | y: 0.574583494769469 | Predicción actual: [[0.5041859]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006262690294533968, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47361392]\n",
      " [0.47150457]\n",
      " [0.47184572]\n",
      " [0.47498339]\n",
      " [0.3847346 ]\n",
      " [0.51220179]\n",
      " [0.50789249]\n",
      " [0.50418591]] | y: 0.6063541263076326 | Predicción actual: [[0.501564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015197529457509518, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47150457]\n",
      " [0.47184572]\n",
      " [0.47498339]\n",
      " [0.3847346 ]\n",
      " [0.51220179]\n",
      " [0.50789249]\n",
      " [0.50418591]\n",
      " [0.50156403]] | y: 0.5846571096474236 | Predicción actual: [[0.5004216]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002250123070552945, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47184572]\n",
      " [0.47498339]\n",
      " [0.3847346 ]\n",
      " [0.51220179]\n",
      " [0.50789249]\n",
      " [0.50418591]\n",
      " [0.50156403]\n",
      " [0.50042158]] | y: 0.5687717938783416 | Predicción actual: [[0.5007189]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003374694148078561, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47498339]\n",
      " [0.3847346 ]\n",
      " [0.51220179]\n",
      " [0.50789249]\n",
      " [0.50418591]\n",
      " [0.50156403]\n",
      " [0.50042158]\n",
      " [0.50071889]] | y: 0.6427741185586981 | Predicción actual: [[0.50217277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061701539903879166, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.51220179]\n",
      " [0.50789249]\n",
      " [0.50418591]\n",
      " [0.50156403]\n",
      " [0.50042158]\n",
      " [0.50071889]\n",
      " [0.50217277]] | y: 0.6617590081363811 | Predicción actual: [[0.5043481]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00854971818625927, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51220179]\n",
      " [0.50789249]\n",
      " [0.50418591]\n",
      " [0.50156403]\n",
      " [0.50042158]\n",
      " [0.50071889]\n",
      " [0.50217277]\n",
      " [0.5043481 ]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003304749494418502, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50789249]\n",
      " [0.50418591]\n",
      " [0.50156403]\n",
      " [0.50042158]\n",
      " [0.50071889]\n",
      " [0.50217277]\n",
      " [0.5043481 ]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5292837]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03016507625579834, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50418591]\n",
      " [0.50156403]\n",
      " [0.50042158]\n",
      " [0.50071889]\n",
      " [0.50217277]\n",
      " [0.5043481 ]\n",
      " [0.67299496]\n",
      " [0.5292837 ]] | y: 0.703990701278574 | Predicción actual: [[0.5306794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05889381840825081, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50156403]\n",
      " [0.50042158]\n",
      " [0.50071889]\n",
      " [0.50217277]\n",
      " [0.5043481 ]\n",
      " [0.67299496]\n",
      " [0.5292837 ]\n",
      " [0.5306794 ]] | y: 0.7272375048430839 | Predicción actual: [[0.5348134]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0348452664911747, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50042158]\n",
      " [0.50071889]\n",
      " [0.50217277]\n",
      " [0.5043481 ]\n",
      " [0.67299496]\n",
      " [0.5292837 ]\n",
      " [0.5306794 ]\n",
      " [0.5348134 ]] | y: 0.722588144130182 | Predicción actual: [[0.5416241]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015705913305282593, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50071889]\n",
      " [0.50217277]\n",
      " [0.5043481 ]\n",
      " [0.67299496]\n",
      " [0.5292837 ]\n",
      " [0.5306794 ]\n",
      " [0.5348134 ]\n",
      " [0.54162413]] | y: 0.771793878341728 | Predicción actual: [[0.55075175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05745609849691391, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50217277]\n",
      " [0.5043481 ]\n",
      " [0.67299496]\n",
      " [0.5292837 ]\n",
      " [0.5306794 ]\n",
      " [0.5348134 ]\n",
      " [0.54162413]\n",
      " [0.55075175]] | y: 0.7245253777605578 | Predicción actual: [[0.56183565]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034946657717227936, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5043481 ]\n",
      " [0.67299496]\n",
      " [0.5292837 ]\n",
      " [0.5306794 ]\n",
      " [0.5348134 ]\n",
      " [0.54162413]\n",
      " [0.55075175]\n",
      " [0.56183565]] | y: 0.6710577295621851 | Predicción actual: [[0.5743932]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016141334548592567, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.5292837 ]\n",
      " [0.5306794 ]\n",
      " [0.5348134 ]\n",
      " [0.54162413]\n",
      " [0.55075175]\n",
      " [0.56183565]\n",
      " [0.57439321]] | y: 0.6737698566447115 | Predicción actual: [[0.58803755]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02045232616364956, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5292837 ]\n",
      " [0.5306794 ]\n",
      " [0.5348134 ]\n",
      " [0.54162413]\n",
      " [0.55075175]\n",
      " [0.56183565]\n",
      " [0.57439321]\n",
      " [0.58803755]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036658626049757004, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5306794 ]\n",
      " [0.5348134 ]\n",
      " [0.54162413]\n",
      " [0.55075175]\n",
      " [0.56183565]\n",
      " [0.57439321]\n",
      " [0.58803755]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.56590164]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009585140272974968, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5348134 ]\n",
      " [0.54162413]\n",
      " [0.55075175]\n",
      " [0.56183565]\n",
      " [0.57439321]\n",
      " [0.58803755]\n",
      " [0.71445176]\n",
      " [0.56590164]] | y: 0.722588144130182 | Predicción actual: [[0.57478136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007569541689008474, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54162413]\n",
      " [0.55075175]\n",
      " [0.56183565]\n",
      " [0.57439321]\n",
      " [0.58803755]\n",
      " [0.71445176]\n",
      " [0.56590164]\n",
      " [0.57478136]] | y: 0.6993413405656723 | Predicción actual: [[0.5855617]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02555682510137558, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55075175]\n",
      " [0.56183565]\n",
      " [0.57439321]\n",
      " [0.58803755]\n",
      " [0.71445176]\n",
      " [0.56590164]\n",
      " [0.57478136]\n",
      " [0.58556169]] | y: 0.7373111197210385 | Predicción actual: [[0.59737563]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013512561097741127, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56183565]\n",
      " [0.57439321]\n",
      " [0.58803755]\n",
      " [0.71445176]\n",
      " [0.56590164]\n",
      " [0.57478136]\n",
      " [0.58556169]\n",
      " [0.59737563]] | y: 0.7214258039519565 | Predicción actual: [[0.6091579]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007256198208779097, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57439321]\n",
      " [0.58803755]\n",
      " [0.71445176]\n",
      " [0.56590164]\n",
      " [0.57478136]\n",
      " [0.58556169]\n",
      " [0.59737563]\n",
      " [0.60915792]] | y: 0.7187136768694304 | Predicción actual: [[0.6198346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011623142287135124, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58803755]\n",
      " [0.71445176]\n",
      " [0.56590164]\n",
      " [0.57478136]\n",
      " [0.58556169]\n",
      " [0.59737563]\n",
      " [0.60915792]\n",
      " [0.6198346 ]] | y: 0.6741573033707864 | Predicción actual: [[0.6285078]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00042453769128769636, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56590164]\n",
      " [0.57478136]\n",
      " [0.58556169]\n",
      " [0.59737563]\n",
      " [0.60915792]\n",
      " [0.6198346 ]\n",
      " [0.62850779]] | y: 0.698566447113522 | Predicción actual: [[0.63428396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00021385961736086756, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56590164]\n",
      " [0.57478136]\n",
      " [0.58556169]\n",
      " [0.59737563]\n",
      " [0.60915792]\n",
      " [0.6198346 ]\n",
      " [0.62850779]\n",
      " [0.63428396]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017996549606323242, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57478136]\n",
      " [0.58556169]\n",
      " [0.59737563]\n",
      " [0.60915792]\n",
      " [0.6198346 ]\n",
      " [0.62850779]\n",
      " [0.63428396]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6166789]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024049554020166397, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58556169]\n",
      " [0.59737563]\n",
      " [0.60915792]\n",
      " [0.6198346 ]\n",
      " [0.62850779]\n",
      " [0.63428396]\n",
      " [0.72103836]\n",
      " [0.61667889]] | y: 0.7562960092987214 | Predicción actual: [[0.6275653]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005983652547001839, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59737563]\n",
      " [0.60915792]\n",
      " [0.6198346 ]\n",
      " [0.62850779]\n",
      " [0.63428396]\n",
      " [0.72103836]\n",
      " [0.61667889]\n",
      " [0.62756532]] | y: 0.8275862068965516 | Predicción actual: [[0.6384808]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015274485340341926, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60915792]\n",
      " [0.6198346 ]\n",
      " [0.62850779]\n",
      " [0.63428396]\n",
      " [0.72103836]\n",
      " [0.61667889]\n",
      " [0.62756532]\n",
      " [0.63848078]] | y: 0.8388221619527314 | Predicción actual: [[0.64862925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08748447149991989, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6198346 ]\n",
      " [0.62850779]\n",
      " [0.63428396]\n",
      " [0.72103836]\n",
      " [0.61667889]\n",
      " [0.62756532]\n",
      " [0.63848078]\n",
      " [0.64862925]] | y: 0.7942657884540876 | Predicción actual: [[0.6576995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02913654036819935, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62850779]\n",
      " [0.63428396]\n",
      " [0.72103836]\n",
      " [0.61667889]\n",
      " [0.62756532]\n",
      " [0.63848078]\n",
      " [0.64862925]\n",
      " [0.65769953]] | y: 0.7838047268500579 | Predicción actual: [[0.66536516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007764144334942102, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63428396]\n",
      " [0.72103836]\n",
      " [0.61667889]\n",
      " [0.62756532]\n",
      " [0.63848078]\n",
      " [0.64862925]\n",
      " [0.65769953]\n",
      " [0.66536516]] | y: 0.7679194110809764 | Predicción actual: [[0.6716898]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07723358273506165, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.61667889]\n",
      " [0.62756532]\n",
      " [0.63848078]\n",
      " [0.64862925]\n",
      " [0.65769953]\n",
      " [0.66536516]\n",
      " [0.67168981]] | y: 0.7845796203022084 | Predicción actual: [[0.6773756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015851283445954323, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61667889]\n",
      " [0.62756532]\n",
      " [0.63848078]\n",
      " [0.64862925]\n",
      " [0.65769953]\n",
      " [0.66536516]\n",
      " [0.67168981]\n",
      " [0.67737561]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.058738887310028076, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62756532]\n",
      " [0.63848078]\n",
      " [0.64862925]\n",
      " [0.65769953]\n",
      " [0.66536516]\n",
      " [0.67168981]\n",
      " [0.67737561]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.67114276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023905277252197266, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63848078]\n",
      " [0.64862925]\n",
      " [0.65769953]\n",
      " [0.66536516]\n",
      " [0.67168981]\n",
      " [0.67737561]\n",
      " [0.87872917]\n",
      " [0.67114276]] | y: 0.8488957768306855 | Predicción actual: [[0.6835765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09825059026479721, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64862925]\n",
      " [0.65769953]\n",
      " [0.66536516]\n",
      " [0.67168981]\n",
      " [0.67737561]\n",
      " [0.87872917]\n",
      " [0.67114276]\n",
      " [0.68357652]] | y: 0.8182874854707476 | Predicción actual: [[0.69705623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009688342921435833, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65769953]\n",
      " [0.66536516]\n",
      " [0.67168981]\n",
      " [0.67737561]\n",
      " [0.87872917]\n",
      " [0.67114276]\n",
      " [0.68357652]\n",
      " [0.69705623]] | y: 0.8268113134444013 | Predicción actual: [[0.7111602]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0690850093960762, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66536516]\n",
      " [0.67168981]\n",
      " [0.67737561]\n",
      " [0.87872917]\n",
      " [0.67114276]\n",
      " [0.68357652]\n",
      " [0.69705623]\n",
      " [0.71116018]] | y: 0.7853545137543589 | Predicción actual: [[0.7257995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005584819242358208, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67168981]\n",
      " [0.67737561]\n",
      " [0.87872917]\n",
      " [0.67114276]\n",
      " [0.68357652]\n",
      " [0.69705623]\n",
      " [0.71116018]\n",
      " [0.7257995 ]] | y: 0.7892289810151103 | Predicción actual: [[0.7406379]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006590778939425945, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67737561]\n",
      " [0.87872917]\n",
      " [0.67114276]\n",
      " [0.68357652]\n",
      " [0.69705623]\n",
      " [0.71116018]\n",
      " [0.7257995 ]\n",
      " [0.7406379 ]] | y: 0.8341728012398295 | Predicción actual: [[0.75563514]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0069713587872684, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.67114276]\n",
      " [0.68357652]\n",
      " [0.69705623]\n",
      " [0.71116018]\n",
      " [0.7257995 ]\n",
      " [0.7406379 ]\n",
      " [0.75563514]] | y: 0.8124757845796202 | Predicción actual: [[0.77069587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004539680201560259, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67114276]\n",
      " [0.68357652]\n",
      " [0.69705623]\n",
      " [0.71116018]\n",
      " [0.7257995 ]\n",
      " [0.7406379 ]\n",
      " [0.75563514]\n",
      " [0.77069587]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00043457598076201975, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68357652]\n",
      " [0.69705623]\n",
      " [0.71116018]\n",
      " [0.7257995 ]\n",
      " [0.7406379 ]\n",
      " [0.75563514]\n",
      " [0.77069587]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7425165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011577267199754715, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69705623]\n",
      " [0.71116018]\n",
      " [0.7257995 ]\n",
      " [0.7406379 ]\n",
      " [0.75563514]\n",
      " [0.77069587]\n",
      " [0.80123983]\n",
      " [0.74251652]] | y: 0.793490895001937 | Predicción actual: [[0.75708354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.177842134187813e-06, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71116018]\n",
      " [0.7257995 ]\n",
      " [0.7406379 ]\n",
      " [0.75563514]\n",
      " [0.77069587]\n",
      " [0.80123983]\n",
      " [0.74251652]\n",
      " [0.75708354]] | y: 0.760170476559473 | Predicción actual: [[0.7711811]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021664327010512352, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7257995 ]\n",
      " [0.7406379 ]\n",
      " [0.75563514]\n",
      " [0.77069587]\n",
      " [0.80123983]\n",
      " [0.74251652]\n",
      " [0.75708354]\n",
      " [0.77118111]] | y: 0.7353738860906625 | Predicción actual: [[0.7842726]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010479463264346123, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7406379 ]\n",
      " [0.75563514]\n",
      " [0.77069587]\n",
      " [0.80123983]\n",
      " [0.74251652]\n",
      " [0.75708354]\n",
      " [0.77118111]\n",
      " [0.78427261]] | y: 0.7101898488957767 | Predicción actual: [[0.7952284]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008567385375499725, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75563514]\n",
      " [0.77069587]\n",
      " [0.80123983]\n",
      " [0.74251652]\n",
      " [0.75708354]\n",
      " [0.77118111]\n",
      " [0.78427261]\n",
      " [0.79522842]] | y: 0.7121270825261525 | Predicción actual: [[0.80351186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.307478517759591e-05, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77069587]\n",
      " [0.80123983]\n",
      " [0.74251652]\n",
      " [0.75708354]\n",
      " [0.77118111]\n",
      " [0.78427261]\n",
      " [0.79522842]\n",
      " [0.80351186]] | y: 0.7396358000774894 | Predicción actual: [[0.8088519]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015744870528578758, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.74251652]\n",
      " [0.75708354]\n",
      " [0.77118111]\n",
      " [0.78427261]\n",
      " [0.79522842]\n",
      " [0.80351186]\n",
      " [0.8088519 ]] | y: 0.7361487795428128 | Predicción actual: [[0.8106714]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015766036231070757, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74251652]\n",
      " [0.75708354]\n",
      " [0.77118111]\n",
      " [0.78427261]\n",
      " [0.79522842]\n",
      " [0.80351186]\n",
      " [0.8088519 ]\n",
      " [0.81067139]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00313201523385942, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75708354]\n",
      " [0.77118111]\n",
      " [0.78427261]\n",
      " [0.79522842]\n",
      " [0.80351186]\n",
      " [0.8088519 ]\n",
      " [0.81067139]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.81526935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08213572949171066, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77118111]\n",
      " [0.78427261]\n",
      " [0.79522842]\n",
      " [0.80351186]\n",
      " [0.8088519 ]\n",
      " [0.81067139]\n",
      " [0.66757071]\n",
      " [0.81526935]] | y: 0.696629213483146 | Predicción actual: [[0.8227586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03397020325064659, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78427261]\n",
      " [0.79522842]\n",
      " [0.80351186]\n",
      " [0.8088519 ]\n",
      " [0.81067139]\n",
      " [0.66757071]\n",
      " [0.81526935]\n",
      " [0.82275862]] | y: 0.6559473072452537 | Predicción actual: [[0.82662094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02030293270945549, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79522842]\n",
      " [0.80351186]\n",
      " [0.8088519 ]\n",
      " [0.81067139]\n",
      " [0.66757071]\n",
      " [0.81526935]\n",
      " [0.82275862]\n",
      " [0.82662094]] | y: 0.6788066640836885 | Predicción actual: [[0.82693934]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016871774569153786, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80351186]\n",
      " [0.8088519 ]\n",
      " [0.81067139]\n",
      " [0.66757071]\n",
      " [0.81526935]\n",
      " [0.82275862]\n",
      " [0.82662094]\n",
      " [0.82693934]] | y: 0.6760945370011622 | Predicción actual: [[0.82430947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013005152344703674, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8088519 ]\n",
      " [0.81067139]\n",
      " [0.66757071]\n",
      " [0.81526935]\n",
      " [0.82275862]\n",
      " [0.82662094]\n",
      " [0.82693934]\n",
      " [0.82430947]] | y: 0.7295621851995349 | Predicción actual: [[0.81970143]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003855317481793463, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81067139]\n",
      " [0.66757071]\n",
      " [0.81526935]\n",
      " [0.82275862]\n",
      " [0.82662094]\n",
      " [0.82693934]\n",
      " [0.82430947]\n",
      " [0.81970143]] | y: 0.7012785741960481 | Predicción actual: [[0.8144283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000689103442709893, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.81526935]\n",
      " [0.82275862]\n",
      " [0.82662094]\n",
      " [0.82693934]\n",
      " [0.82430947]\n",
      " [0.81970143]\n",
      " [0.81442833]] | y: 0.767531964354901 | Predicción actual: [[0.80982023]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006132911657914519, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81526935]\n",
      " [0.82275862]\n",
      " [0.82662094]\n",
      " [0.82693934]\n",
      " [0.82430947]\n",
      " [0.81970143]\n",
      " [0.81442833]\n",
      " [0.80982023]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01707695797085762, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82275862]\n",
      " [0.82662094]\n",
      " [0.82693934]\n",
      " [0.82430947]\n",
      " [0.81970143]\n",
      " [0.81442833]\n",
      " [0.80982023]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.849962]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024868180975317955, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82662094]\n",
      " [0.82693934]\n",
      " [0.82430947]\n",
      " [0.81970143]\n",
      " [0.81442833]\n",
      " [0.80982023]\n",
      " [0.75513367]\n",
      " [0.849962  ]] | y: 0.7520340953118947 | Predicción actual: [[0.84741414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015529243275523186, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82693934]\n",
      " [0.82430947]\n",
      " [0.81970143]\n",
      " [0.81442833]\n",
      " [0.80982023]\n",
      " [0.75513367]\n",
      " [0.849962  ]\n",
      " [0.84741414]] | y: 0.7098024021697016 | Predicción actual: [[0.84307945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010180124081671238, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82430947]\n",
      " [0.81970143]\n",
      " [0.81442833]\n",
      " [0.80982023]\n",
      " [0.75513367]\n",
      " [0.849962  ]\n",
      " [0.84741414]\n",
      " [0.84307945]] | y: 0.6904300658659435 | Predicción actual: [[0.83845985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060499370098114014, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81970143]\n",
      " [0.81442833]\n",
      " [0.80982023]\n",
      " [0.75513367]\n",
      " [0.849962  ]\n",
      " [0.84741414]\n",
      " [0.84307945]\n",
      " [0.83845985]] | y: 0.7543587756683454 | Predicción actual: [[0.8343575]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01849244348704815, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81442833]\n",
      " [0.80982023]\n",
      " [0.75513367]\n",
      " [0.849962  ]\n",
      " [0.84741414]\n",
      " [0.84307945]\n",
      " [0.83845985]\n",
      " [0.8343575 ]] | y: 0.7222006974041069 | Predicción actual: [[0.83210903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008434963412582874, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80982023]\n",
      " [0.75513367]\n",
      " [0.849962  ]\n",
      " [0.84741414]\n",
      " [0.84307945]\n",
      " [0.83845985]\n",
      " [0.8343575 ]\n",
      " [0.83210903]] | y: 0.8485083301046106 | Predicción actual: [[0.8324356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.872478403849527e-05, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.849962  ]\n",
      " [0.84741414]\n",
      " [0.84307945]\n",
      " [0.83845985]\n",
      " [0.8343575 ]\n",
      " [0.83210903]\n",
      " [0.83243561]] | y: 0.9054629988376597 | Predicción actual: [[0.835604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.099294503452256e-05, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.849962  ]\n",
      " [0.84741414]\n",
      " [0.84307945]\n",
      " [0.83845985]\n",
      " [0.8343575 ]\n",
      " [0.83210903]\n",
      " [0.83243561]\n",
      " [0.83560401]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005945739336311817, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84741414]\n",
      " [0.84307945]\n",
      " [0.83845985]\n",
      " [0.8343575 ]\n",
      " [0.83210903]\n",
      " [0.83243561]\n",
      " [0.83560401]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8523229]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014848588034510612, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84307945]\n",
      " [0.83845985]\n",
      " [0.8343575 ]\n",
      " [0.83210903]\n",
      " [0.83243561]\n",
      " [0.83560401]\n",
      " [0.8822162 ]\n",
      " [0.85232288]] | y: 0.889577683068578 | Predicción actual: [[0.84906703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017196057364344597, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83845985]\n",
      " [0.8343575 ]\n",
      " [0.83210903]\n",
      " [0.83243561]\n",
      " [0.83560401]\n",
      " [0.8822162 ]\n",
      " [0.85232288]\n",
      " [0.84906703]] | y: 0.8748547074777218 | Predicción actual: [[0.84764624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021844390779733658, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8343575 ]\n",
      " [0.83210903]\n",
      " [0.83243561]\n",
      " [0.83560401]\n",
      " [0.8822162 ]\n",
      " [0.85232288]\n",
      " [0.84906703]\n",
      " [0.84764624]] | y: 0.9132119333591631 | Predicción actual: [[0.84843314]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013530489522963762, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83210903]\n",
      " [0.83243561]\n",
      " [0.83560401]\n",
      " [0.8822162 ]\n",
      " [0.85232288]\n",
      " [0.84906703]\n",
      " [0.84764624]\n",
      " [0.84843314]] | y: 1.0 | Predicción actual: [[0.85112584]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004632720723748207, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83243561]\n",
      " [0.83560401]\n",
      " [0.8822162 ]\n",
      " [0.85232288]\n",
      " [0.84906703]\n",
      " [0.84764624]\n",
      " [0.84843314]\n",
      " [0.85112584]] | y: 0.9705540488182873 | Predicción actual: [[0.85553384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029207762330770493, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83560401]\n",
      " [0.8822162 ]\n",
      " [0.85232288]\n",
      " [0.84906703]\n",
      " [0.84764624]\n",
      " [0.84843314]\n",
      " [0.85112584]\n",
      " [0.85553384]] | y: 0.8888027896164277 | Predicción actual: [[0.8602347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011627293191850185, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.85232288]\n",
      " [0.84906703]\n",
      " [0.84764624]\n",
      " [0.84843314]\n",
      " [0.85112584]\n",
      " [0.85553384]\n",
      " [0.86023468]] | y: 0.877954281286323 | Predicción actual: [[0.8649976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013489390257745981, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85232288]\n",
      " [0.84906703]\n",
      " [0.84764624]\n",
      " [0.84843314]\n",
      " [0.85112584]\n",
      " [0.85553384]\n",
      " [0.86023468]\n",
      " [0.86499763]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.067316230153665e-05, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84906703]\n",
      " [0.84764624]\n",
      " [0.84843314]\n",
      " [0.85112584]\n",
      " [0.85553384]\n",
      " [0.86023468]\n",
      " [0.86499763]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.85583496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02115410566329956, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84764624]\n",
      " [0.84843314]\n",
      " [0.85112584]\n",
      " [0.85553384]\n",
      " [0.86023468]\n",
      " [0.86499763]\n",
      " [0.84889578]\n",
      " [0.85583496]] | y: 0.8550949244478885 | Predicción actual: [[0.85676014]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002356478478759527, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84843314]\n",
      " [0.85112584]\n",
      " [0.85553384]\n",
      " [0.86023468]\n",
      " [0.86499763]\n",
      " [0.84889578]\n",
      " [0.85583496]\n",
      " [0.85676014]] | y: 0.8752421542037967 | Predicción actual: [[0.85859525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001909444254124537, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85112584]\n",
      " [0.85553384]\n",
      " [0.86023468]\n",
      " [0.86499763]\n",
      " [0.84889578]\n",
      " [0.85583496]\n",
      " [0.85676014]\n",
      " [0.85859525]] | y: 0.857032158078264 | Predicción actual: [[0.8606421]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021146981045603752, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85553384]\n",
      " [0.86023468]\n",
      " [0.86499763]\n",
      " [0.84889578]\n",
      " [0.85583496]\n",
      " [0.85676014]\n",
      " [0.85859525]\n",
      " [0.86064208]] | y: 0.8500581170089112 | Predicción actual: [[0.8625022]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06013232469558716, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86023468]\n",
      " [0.86499763]\n",
      " [0.84889578]\n",
      " [0.85583496]\n",
      " [0.85676014]\n",
      " [0.85859525]\n",
      " [0.86064208]\n",
      " [0.86250222]] | y: 0.8426966292134832 | Predicción actual: [[0.8626357]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004915139637887478, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86499763]\n",
      " [0.84889578]\n",
      " [0.85583496]\n",
      " [0.85676014]\n",
      " [0.85859525]\n",
      " [0.86064208]\n",
      " [0.86250222]\n",
      " [0.86263567]] | y: 0.8229368461836497 | Predicción actual: [[0.8613983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001805111882276833, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.85583496]\n",
      " [0.85676014]\n",
      " [0.85859525]\n",
      " [0.86064208]\n",
      " [0.86250222]\n",
      " [0.86263567]\n",
      " [0.86139828]] | y: 0.7745060054242543 | Predicción actual: [[0.8589262]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016400121967308223, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85583496]\n",
      " [0.85676014]\n",
      " [0.85859525]\n",
      " [0.86064208]\n",
      " [0.86250222]\n",
      " [0.86263567]\n",
      " [0.86139828]\n",
      " [0.85892618]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004878884647041559, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85676014]\n",
      " [0.85859525]\n",
      " [0.86064208]\n",
      " [0.86250222]\n",
      " [0.86263567]\n",
      " [0.86139828]\n",
      " [0.85892618]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.86130667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003442628774791956, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85859525]\n",
      " [0.86064208]\n",
      " [0.86250222]\n",
      " [0.86263567]\n",
      " [0.86139828]\n",
      " [0.85892618]\n",
      " [0.78419217]\n",
      " [0.86130667]] | y: 0.854320030995738 | Predicción actual: [[0.8605856]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0382273867726326, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86064208]\n",
      " [0.86250222]\n",
      " [0.86263567]\n",
      " [0.86139828]\n",
      " [0.85892618]\n",
      " [0.78419217]\n",
      " [0.86130667]\n",
      " [0.86058557]] | y: 0.8368849283223556 | Predicción actual: [[0.8582829]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.463314639404416e-05, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86250222]\n",
      " [0.86263567]\n",
      " [0.86139828]\n",
      " [0.85892618]\n",
      " [0.78419217]\n",
      " [0.86130667]\n",
      " [0.86058557]\n",
      " [0.85828292]] | y: 0.8299108872530028 | Predicción actual: [[0.85484874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020550882443785667, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86263567]\n",
      " [0.86139828]\n",
      " [0.85892618]\n",
      " [0.78419217]\n",
      " [0.86130667]\n",
      " [0.86058557]\n",
      " [0.85828292]\n",
      " [0.85484874]] | y: 0.887253002712127 | Predicción actual: [[0.85002446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004426842089742422, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86139828]\n",
      " [0.85892618]\n",
      " [0.78419217]\n",
      " [0.86130667]\n",
      " [0.86058557]\n",
      " [0.85828292]\n",
      " [0.85484874]\n",
      " [0.85002446]] | y: 0.8597442851607902 | Predicción actual: [[0.8446208]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006585515104234219, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85892618]\n",
      " [0.78419217]\n",
      " [0.86130667]\n",
      " [0.86058557]\n",
      " [0.85828292]\n",
      " [0.85484874]\n",
      " [0.85002446]\n",
      " [0.84462082]] | y: 0.8395970554048819 | Predicción actual: [[0.83917207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00264844112098217, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.86130667]\n",
      " [0.86058557]\n",
      " [0.85828292]\n",
      " [0.85484874]\n",
      " [0.85002446]\n",
      " [0.84462082]\n",
      " [0.83917207]] | y: 0.7838047268500579 | Predicción actual: [[0.83447486]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000770367740187794, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86130667]\n",
      " [0.86058557]\n",
      " [0.85828292]\n",
      " [0.85484874]\n",
      " [0.85002446]\n",
      " [0.84462082]\n",
      " [0.83917207]\n",
      " [0.83447486]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019920009654015303, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86058557]\n",
      " [0.85828292]\n",
      " [0.85484874]\n",
      " [0.85002446]\n",
      " [0.84462082]\n",
      " [0.83917207]\n",
      " [0.83447486]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.84776396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.847171564710152e-07, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85828292]\n",
      " [0.85484874]\n",
      " [0.85002446]\n",
      " [0.84462082]\n",
      " [0.83917207]\n",
      " [0.83447486]\n",
      " [0.81828749]\n",
      " [0.84776396]] | y: 0.7605579232855482 | Predicción actual: [[0.8432609]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017088719177991152, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85484874]\n",
      " [0.85002446]\n",
      " [0.84462082]\n",
      " [0.83917207]\n",
      " [0.83447486]\n",
      " [0.81828749]\n",
      " [0.84776396]\n",
      " [0.84326088]] | y: 0.7915536613715615 | Predicción actual: [[0.83839136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004541022062767297, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85002446]\n",
      " [0.84462082]\n",
      " [0.83917207]\n",
      " [0.83447486]\n",
      " [0.81828749]\n",
      " [0.84776396]\n",
      " [0.84326088]\n",
      " [0.83839136]] | y: 0.7686943045331267 | Predicción actual: [[0.8336585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0216365959495306, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84462082]\n",
      " [0.83917207]\n",
      " [0.83447486]\n",
      " [0.81828749]\n",
      " [0.84776396]\n",
      " [0.84326088]\n",
      " [0.83839136]\n",
      " [0.83365852]] | y: 0.7686943045331267 | Predicción actual: [[0.82937235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008690367452800274, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83917207]\n",
      " [0.83447486]\n",
      " [0.81828749]\n",
      " [0.84776396]\n",
      " [0.84326088]\n",
      " [0.83839136]\n",
      " [0.83365852]\n",
      " [0.82937235]] | y: 0.7989151491669895 | Predicción actual: [[0.8260567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.111993570812047e-05, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83447486]\n",
      " [0.81828749]\n",
      " [0.84776396]\n",
      " [0.84326088]\n",
      " [0.83839136]\n",
      " [0.83365852]\n",
      " [0.82937235]\n",
      " [0.82605672]] | y: 0.7900038744672608 | Predicción actual: [[0.824062]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011178542859852314, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.84776396]\n",
      " [0.84326088]\n",
      " [0.83839136]\n",
      " [0.83365852]\n",
      " [0.82937235]\n",
      " [0.82605672]\n",
      " [0.82406199]] | y: 0.760170476559473 | Predicción actual: [[0.82305706]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010813458357006311, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84776396]\n",
      " [0.84326088]\n",
      " [0.83839136]\n",
      " [0.83365852]\n",
      " [0.82937235]\n",
      " [0.82605672]\n",
      " [0.82406199]\n",
      " [0.82305706]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0104069784283638, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84326088]\n",
      " [0.83839136]\n",
      " [0.83365852]\n",
      " [0.82937235]\n",
      " [0.82605672]\n",
      " [0.82406199]\n",
      " [0.82305706]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.82062805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005938397254794836, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83839136]\n",
      " [0.83365852]\n",
      " [0.82937235]\n",
      " [0.82605672]\n",
      " [0.82406199]\n",
      " [0.82305706]\n",
      " [0.68539326]\n",
      " [0.82062805]] | y: 0.6648585819449826 | Predicción actual: [[0.8138046]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018385205185040832, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83365852]\n",
      " [0.82937235]\n",
      " [0.82605672]\n",
      " [0.82406199]\n",
      " [0.82305706]\n",
      " [0.68539326]\n",
      " [0.82062805]\n",
      " [0.81380463]] | y: 0.7078651685393258 | Predicción actual: [[0.8062184]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007189564872533083, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82937235]\n",
      " [0.82605672]\n",
      " [0.82406199]\n",
      " [0.82305706]\n",
      " [0.68539326]\n",
      " [0.82062805]\n",
      " [0.81380463]\n",
      " [0.80621839]] | y: 0.6648585819449826 | Predicción actual: [[0.7979297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009585524909198284, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82605672]\n",
      " [0.82406199]\n",
      " [0.82305706]\n",
      " [0.68539326]\n",
      " [0.82062805]\n",
      " [0.81380463]\n",
      " [0.80621839]\n",
      " [0.7979297 ]] | y: 0.7113521890740022 | Predicción actual: [[0.7891026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.351328243501484e-06, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82406199]\n",
      " [0.82305706]\n",
      " [0.68539326]\n",
      " [0.82062805]\n",
      " [0.81380463]\n",
      " [0.80621839]\n",
      " [0.7979297 ]\n",
      " [0.78910261]] | y: 0.6772568771793879 | Predicción actual: [[0.7799461]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00019776463159359992, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82305706]\n",
      " [0.68539326]\n",
      " [0.82062805]\n",
      " [0.81380463]\n",
      " [0.80621839]\n",
      " [0.7979297 ]\n",
      " [0.78910261]\n",
      " [0.77994609]] | y: 0.7621077101898488 | Predicción actual: [[0.7703319]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037682761903852224, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.82062805]\n",
      " [0.81380463]\n",
      " [0.80621839]\n",
      " [0.7979297 ]\n",
      " [0.78910261]\n",
      " [0.77994609]\n",
      " [0.77033192]] | y: 0.8070515304145678 | Predicción actual: [[0.7602807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033300574868917465, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82062805]\n",
      " [0.81380463]\n",
      " [0.80621839]\n",
      " [0.7979297 ]\n",
      " [0.78910261]\n",
      " [0.77994609]\n",
      " [0.77033192]\n",
      " [0.76028073]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010858324356377125, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81380463]\n",
      " [0.80621839]\n",
      " [0.7979297 ]\n",
      " [0.78910261]\n",
      " [0.77994609]\n",
      " [0.77033192]\n",
      " [0.76028073]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7807047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029350774362683296, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80621839]\n",
      " [0.7979297 ]\n",
      " [0.78910261]\n",
      " [0.77994609]\n",
      " [0.77033192]\n",
      " [0.76028073]\n",
      " [0.81518791]\n",
      " [0.78070468]] | y: 0.9597055404881829 | Predicción actual: [[0.774082]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022612160071730614, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7979297 ]\n",
      " [0.78910261]\n",
      " [0.77994609]\n",
      " [0.77033192]\n",
      " [0.76028073]\n",
      " [0.81518791]\n",
      " [0.78070468]\n",
      " [0.77408201]] | y: 0.9643549012010848 | Predicción actual: [[0.7685923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010487140389159322, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78910261]\n",
      " [0.77994609]\n",
      " [0.77033192]\n",
      " [0.76028073]\n",
      " [0.81518791]\n",
      " [0.78070468]\n",
      " [0.77408201]\n",
      " [0.7685923 ]] | y: 0.8880278961642774 | Predicción actual: [[0.76439404]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022386698983609676, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77994609]\n",
      " [0.77033192]\n",
      " [0.76028073]\n",
      " [0.81518791]\n",
      " [0.78070468]\n",
      " [0.77408201]\n",
      " [0.7685923 ]\n",
      " [0.76439404]] | y: 0.8926772568771792 | Predicción actual: [[0.7619878]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000753912958316505, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77033192]\n",
      " [0.76028073]\n",
      " [0.81518791]\n",
      " [0.78070468]\n",
      " [0.77408201]\n",
      " [0.7685923 ]\n",
      " [0.76439404]\n",
      " [0.76198781]] | y: 0.8752421542037967 | Predicción actual: [[0.76160806]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009954399429261684, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76028073]\n",
      " [0.81518791]\n",
      " [0.78070468]\n",
      " [0.77408201]\n",
      " [0.7685923 ]\n",
      " [0.76439404]\n",
      " [0.76198781]\n",
      " [0.76160806]] | y: 0.8508330104610615 | Predicción actual: [[0.7636307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02136239968240261, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78070468]\n",
      " [0.77408201]\n",
      " [0.7685923 ]\n",
      " [0.76439404]\n",
      " [0.76198781]\n",
      " [0.76160806]\n",
      " [0.76363069]] | y: 0.8488957768306855 | Predicción actual: [[0.7683221]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048062391579151154, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78070468]\n",
      " [0.77408201]\n",
      " [0.7685923 ]\n",
      " [0.76439404]\n",
      " [0.76198781]\n",
      " [0.76160806]\n",
      " [0.76363069]\n",
      " [0.76832211]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012704080902040005, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77408201]\n",
      " [0.7685923 ]\n",
      " [0.76439404]\n",
      " [0.76198781]\n",
      " [0.76160806]\n",
      " [0.76363069]\n",
      " [0.76832211]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.75626564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.053232591599226, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7685923 ]\n",
      " [0.76439404]\n",
      " [0.76198781]\n",
      " [0.76160806]\n",
      " [0.76363069]\n",
      " [0.76832211]\n",
      " [0.96241767]\n",
      " [0.75626564]] | y: 0.9407206509104997 | Predicción actual: [[0.7579787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023730464279651642, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76439404]\n",
      " [0.76198781]\n",
      " [0.76160806]\n",
      " [0.76363069]\n",
      " [0.76832211]\n",
      " [0.96241767]\n",
      " [0.75626564]\n",
      " [0.75797868]] | y: 0.9724912824486633 | Predicción actual: [[0.762798]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06569642573595047, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76198781]\n",
      " [0.76160806]\n",
      " [0.76363069]\n",
      " [0.76832211]\n",
      " [0.96241767]\n",
      " [0.75626564]\n",
      " [0.75797868]\n",
      " [0.76279801]] | y: 0.9969004261913985 | Predicción actual: [[0.7705209]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011847025714814663, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76160806]\n",
      " [0.76363069]\n",
      " [0.76832211]\n",
      " [0.96241767]\n",
      " [0.75626564]\n",
      " [0.75797868]\n",
      " [0.76279801]\n",
      " [0.77052093]] | y: 0.951181712514529 | Predicción actual: [[0.78024316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018617965281009674, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76363069]\n",
      " [0.76832211]\n",
      " [0.96241767]\n",
      " [0.75626564]\n",
      " [0.75797868]\n",
      " [0.76279801]\n",
      " [0.77052093]\n",
      " [0.78024316]] | y: 0.8957768306857805 | Predicción actual: [[0.7910764]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017747143283486366, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76832211]\n",
      " [0.96241767]\n",
      " [0.75626564]\n",
      " [0.75797868]\n",
      " [0.76279801]\n",
      " [0.77052093]\n",
      " [0.78024316]\n",
      " [0.79107642]] | y: 0.8814413018209997 | Predicción actual: [[0.8019067]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012297796783968806, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.75626564]\n",
      " [0.75797868]\n",
      " [0.76279801]\n",
      " [0.77052093]\n",
      " [0.78024316]\n",
      " [0.79107642]\n",
      " [0.8019067 ]] | y: 0.9170864006199149 | Predicción actual: [[0.8113964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0679733082652092, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75626564]\n",
      " [0.75797868]\n",
      " [0.76279801]\n",
      " [0.77052093]\n",
      " [0.78024316]\n",
      " [0.79107642]\n",
      " [0.8019067 ]\n",
      " [0.81139642]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05943933501839638, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75797868]\n",
      " [0.76279801]\n",
      " [0.77052093]\n",
      " [0.78024316]\n",
      " [0.79107642]\n",
      " [0.8019067 ]\n",
      " [0.81139642]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.77339]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01354055292904377, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76279801]\n",
      " [0.77052093]\n",
      " [0.78024316]\n",
      " [0.79107642]\n",
      " [0.8019067 ]\n",
      " [0.81139642]\n",
      " [0.91979853]\n",
      " [0.77339   ]] | y: 0.9682293684618366 | Predicción actual: [[0.783888]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0333784744143486, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77052093]\n",
      " [0.78024316]\n",
      " [0.79107642]\n",
      " [0.8019067 ]\n",
      " [0.81139642]\n",
      " [0.91979853]\n",
      " [0.77339   ]\n",
      " [0.78388798]] | y: 0.9577683068578069 | Predicción actual: [[0.7958844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055423665791749954, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.22364223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03621026128530502, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22364223]] | y: 0.10422316931421921 | Predicción actual: [[0.20869154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012291964143514633, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22364223]\n",
      " [0.20869154]] | y: 0.15420379697791559 | Predicción actual: [[0.21322665]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00815825816243887, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22364223]\n",
      " [0.20869154]\n",
      " [0.21322665]] | y: 0.1557535838822161 | Predicción actual: [[0.2253299]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009264979511499405, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22364223]\n",
      " [0.20869154]\n",
      " [0.21322665]\n",
      " [0.22532991]] | y: 0.12553273924835334 | Predicción actual: [[0.2390547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025502892211079597, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22364223]\n",
      " [0.20869154]\n",
      " [0.21322665]\n",
      " [0.22532991]\n",
      " [0.23905469]] | y: 0.1456799690042619 | Predicción actual: [[0.25076684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011614786460995674, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.22364223]\n",
      " [0.20869154]\n",
      " [0.21322665]\n",
      " [0.22532991]\n",
      " [0.23905469]\n",
      " [0.25076684]] | y: 0.1464548624564122 | Predicción actual: [[0.2745604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020867841318249702, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.22364223]\n",
      " [0.20869154]\n",
      " [0.21322665]\n",
      " [0.22532991]\n",
      " [0.23905469]\n",
      " [0.25076684]\n",
      " [0.27456039]] | y: 0.1960480433940332 | Predicción actual: [[0.30412948]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005102740600705147, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22364223]\n",
      " [0.20869154]\n",
      " [0.21322665]\n",
      " [0.22532991]\n",
      " [0.23905469]\n",
      " [0.25076684]\n",
      " [0.27456039]\n",
      " [0.30412948]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022619707509875298, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20869154]\n",
      " [0.21322665]\n",
      " [0.22532991]\n",
      " [0.23905469]\n",
      " [0.25076684]\n",
      " [0.27456039]\n",
      " [0.30412948]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.34263587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04571938514709473, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21322665]\n",
      " [0.22532991]\n",
      " [0.23905469]\n",
      " [0.25076684]\n",
      " [0.27456039]\n",
      " [0.30412948]\n",
      " [0.2305308 ]\n",
      " [0.34263587]] | y: 0.211933359163115 | Predicción actual: [[0.35022488]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025622496381402016, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22532991]\n",
      " [0.23905469]\n",
      " [0.25076684]\n",
      " [0.27456039]\n",
      " [0.30412948]\n",
      " [0.2305308 ]\n",
      " [0.34263587]\n",
      " [0.35022488]] | y: 0.2072839984502131 | Predicción actual: [[0.35969752]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010515805333852768, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23905469]\n",
      " [0.25076684]\n",
      " [0.27456039]\n",
      " [0.30412948]\n",
      " [0.2305308 ]\n",
      " [0.34263587]\n",
      " [0.35022488]\n",
      " [0.35969752]] | y: 0.19294846958543205 | Predicción actual: [[0.3698774]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020426485687494278, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25076684]\n",
      " [0.27456039]\n",
      " [0.30412948]\n",
      " [0.2305308 ]\n",
      " [0.34263587]\n",
      " [0.35022488]\n",
      " [0.35969752]\n",
      " [0.3698774 ]] | y: 0.19682293684618352 | Predicción actual: [[0.38062093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02040252462029457, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27456039]\n",
      " [0.30412948]\n",
      " [0.2305308 ]\n",
      " [0.34263587]\n",
      " [0.35022488]\n",
      " [0.35969752]\n",
      " [0.3698774 ]\n",
      " [0.38062093]] | y: 0.21425803951956607 | Predicción actual: [[0.39255244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022449685260653496, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30412948]\n",
      " [0.2305308 ]\n",
      " [0.34263587]\n",
      " [0.35022488]\n",
      " [0.35969752]\n",
      " [0.3698774 ]\n",
      " [0.38062093]\n",
      " [0.39255244]] | y: 0.18132506780317698 | Predicción actual: [[0.40294048]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05572211742401123, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.34263587]\n",
      " [0.35022488]\n",
      " [0.35969752]\n",
      " [0.3698774 ]\n",
      " [0.38062093]\n",
      " [0.39255244]\n",
      " [0.40294048]] | y: 0.17512592018597434 | Predicción actual: [[0.4100196]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049563199281692505, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34263587]\n",
      " [0.35022488]\n",
      " [0.35969752]\n",
      " [0.3698774 ]\n",
      " [0.38062093]\n",
      " [0.39255244]\n",
      " [0.40294048]\n",
      " [0.41001961]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10359874367713928, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35022488]\n",
      " [0.35969752]\n",
      " [0.3698774 ]\n",
      " [0.38062093]\n",
      " [0.39255244]\n",
      " [0.40294048]\n",
      " [0.41001961]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.44336858]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10832156985998154, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35969752]\n",
      " [0.3698774 ]\n",
      " [0.38062093]\n",
      " [0.39255244]\n",
      " [0.40294048]\n",
      " [0.41001961]\n",
      " [0.14800465]\n",
      " [0.44336858]] | y: 0.19217357613328173 | Predicción actual: [[0.44692463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0755511149764061, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3698774 ]\n",
      " [0.38062093]\n",
      " [0.39255244]\n",
      " [0.40294048]\n",
      " [0.41001961]\n",
      " [0.14800465]\n",
      " [0.44336858]\n",
      " [0.44692463]] | y: 0.1859744285160791 | Predicción actual: [[0.44846347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0737207904458046, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38062093]\n",
      " [0.39255244]\n",
      " [0.40294048]\n",
      " [0.41001961]\n",
      " [0.14800465]\n",
      " [0.44336858]\n",
      " [0.44692463]\n",
      " [0.44846347]] | y: 0.26695079426578844 | Predicción actual: [[0.44808942]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041079081594944, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39255244]\n",
      " [0.40294048]\n",
      " [0.41001961]\n",
      " [0.14800465]\n",
      " [0.44336858]\n",
      " [0.44692463]\n",
      " [0.44846347]\n",
      " [0.44808942]] | y: 0.2925222781867493 | Predicción actual: [[0.44612223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010259232483804226, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40294048]\n",
      " [0.41001961]\n",
      " [0.14800465]\n",
      " [0.44336858]\n",
      " [0.44692463]\n",
      " [0.44846347]\n",
      " [0.44808942]\n",
      " [0.44612223]] | y: 0.3177063153816349 | Predicción actual: [[0.44277558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006864306516945362, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41001961]\n",
      " [0.14800465]\n",
      " [0.44336858]\n",
      " [0.44692463]\n",
      " [0.44846347]\n",
      " [0.44808942]\n",
      " [0.44612223]\n",
      " [0.44277558]] | y: 0.31266950794265785 | Predicción actual: [[0.43877274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01997467502951622, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.44336858]\n",
      " [0.44692463]\n",
      " [0.44846347]\n",
      " [0.44808942]\n",
      " [0.44612223]\n",
      " [0.44277558]\n",
      " [0.43877274]] | y: 0.2890352576520729 | Predicción actual: [[0.4351347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04234999418258667, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44336858]\n",
      " [0.44692463]\n",
      " [0.44846347]\n",
      " [0.44808942]\n",
      " [0.44612223]\n",
      " [0.44277558]\n",
      " [0.43877274]\n",
      " [0.43513471]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04335511103272438, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44692463]\n",
      " [0.44846347]\n",
      " [0.44808942]\n",
      " [0.44612223]\n",
      " [0.44277558]\n",
      " [0.43877274]\n",
      " [0.43513471]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.49640515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026625104248523712, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44846347]\n",
      " [0.44808942]\n",
      " [0.44612223]\n",
      " [0.44277558]\n",
      " [0.43877274]\n",
      " [0.43513471]\n",
      " [0.28283611]\n",
      " [0.49640515]] | y: 0.2758620689655173 | Predicción actual: [[0.49286604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09039986878633499, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44808942]\n",
      " [0.44612223]\n",
      " [0.44277558]\n",
      " [0.43877274]\n",
      " [0.43513471]\n",
      " [0.28283611]\n",
      " [0.49640515]\n",
      " [0.49286604]] | y: 0.2746997287872917 | Predicción actual: [[0.48794594]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06610468029975891, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44612223]\n",
      " [0.44277558]\n",
      " [0.43877274]\n",
      " [0.43513471]\n",
      " [0.28283611]\n",
      " [0.49640515]\n",
      " [0.49286604]\n",
      " [0.48794594]] | y: 0.275474622239442 | Predicción actual: [[0.48273122]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03697086125612259, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44277558]\n",
      " [0.43877274]\n",
      " [0.43513471]\n",
      " [0.28283611]\n",
      " [0.49640515]\n",
      " [0.49286604]\n",
      " [0.48794594]\n",
      " [0.48273122]] | y: 0.3347539713289423 | Predicción actual: [[0.47835222]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033009403850883245, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43877274]\n",
      " [0.43513471]\n",
      " [0.28283611]\n",
      " [0.49640515]\n",
      " [0.49286604]\n",
      " [0.48794594]\n",
      " [0.48273122]\n",
      " [0.47835222]] | y: 0.35567609453700116 | Predicción actual: [[0.47588724]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002084895095322281, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43513471]\n",
      " [0.28283611]\n",
      " [0.49640515]\n",
      " [0.49286604]\n",
      " [0.48794594]\n",
      " [0.48273122]\n",
      " [0.47835222]\n",
      " [0.47588724]] | y: 0.3366912049593181 | Predicción actual: [[0.4760577]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025798853486776352, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.49640515]\n",
      " [0.49286604]\n",
      " [0.48794594]\n",
      " [0.48273122]\n",
      " [0.47835222]\n",
      " [0.47588724]\n",
      " [0.47605771]] | y: 0.3335916311507167 | Predicción actual: [[0.4790667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014739537611603737, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49640515]\n",
      " [0.49286604]\n",
      " [0.48794594]\n",
      " [0.48273122]\n",
      " [0.47835222]\n",
      " [0.47588724]\n",
      " [0.47605771]\n",
      " [0.4790667 ]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003763221437111497, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49286604]\n",
      " [0.48794594]\n",
      " [0.48273122]\n",
      " [0.47835222]\n",
      " [0.47588724]\n",
      " [0.47605771]\n",
      " [0.4790667 ]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5176087]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017643801402300596, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48794594]\n",
      " [0.48273122]\n",
      " [0.47835222]\n",
      " [0.47588724]\n",
      " [0.47605771]\n",
      " [0.4790667 ]\n",
      " [0.3847346 ]\n",
      " [0.5176087 ]] | y: 0.5962805114296785 | Predicción actual: [[0.5128871]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001235488336533308, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48273122]\n",
      " [0.47835222]\n",
      " [0.47588724]\n",
      " [0.47605771]\n",
      " [0.4790667 ]\n",
      " [0.3847346 ]\n",
      " [0.5176087 ]\n",
      " [0.51288712]] | y: 0.574583494769469 | Predicción actual: [[0.50872606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012078514555469155, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47835222]\n",
      " [0.47588724]\n",
      " [0.47605771]\n",
      " [0.4790667 ]\n",
      " [0.3847346 ]\n",
      " [0.5176087 ]\n",
      " [0.51288712]\n",
      " [0.50872606]] | y: 0.6063541263076326 | Predicción actual: [[0.5057407]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01799885369837284, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47588724]\n",
      " [0.47605771]\n",
      " [0.4790667 ]\n",
      " [0.3847346 ]\n",
      " [0.5176087 ]\n",
      " [0.51288712]\n",
      " [0.50872606]\n",
      " [0.5057407 ]] | y: 0.5846571096474236 | Predicción actual: [[0.5043459]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001507673441665247, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47605771]\n",
      " [0.4790667 ]\n",
      " [0.3847346 ]\n",
      " [0.5176087 ]\n",
      " [0.51288712]\n",
      " [0.50872606]\n",
      " [0.5057407 ]\n",
      " [0.50434589]] | y: 0.5687717938783416 | Predicción actual: [[0.5044574]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029433860909193754, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4790667 ]\n",
      " [0.3847346 ]\n",
      " [0.5176087 ]\n",
      " [0.51288712]\n",
      " [0.50872606]\n",
      " [0.5057407 ]\n",
      " [0.50434589]\n",
      " [0.50445741]] | y: 0.6427741185586981 | Predicción actual: [[0.5057846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019360622391104698, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.5176087 ]\n",
      " [0.51288712]\n",
      " [0.50872606]\n",
      " [0.5057407 ]\n",
      " [0.50434589]\n",
      " [0.50445741]\n",
      " [0.50578457]] | y: 0.6617590081363811 | Predicción actual: [[0.50784636]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004798161331564188, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5176087 ]\n",
      " [0.51288712]\n",
      " [0.50872606]\n",
      " [0.5057407 ]\n",
      " [0.50434589]\n",
      " [0.50445741]\n",
      " [0.50578457]\n",
      " [0.50784636]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0332547202706337, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51288712]\n",
      " [0.50872606]\n",
      " [0.5057407 ]\n",
      " [0.50434589]\n",
      " [0.50445741]\n",
      " [0.50578457]\n",
      " [0.50784636]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.53367746]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04539915546774864, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50872606]\n",
      " [0.5057407 ]\n",
      " [0.50434589]\n",
      " [0.50445741]\n",
      " [0.50578457]\n",
      " [0.50784636]\n",
      " [0.67299496]\n",
      " [0.53367746]] | y: 0.703990701278574 | Predicción actual: [[0.53482157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005730956792831421, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5057407 ]\n",
      " [0.50434589]\n",
      " [0.50445741]\n",
      " [0.50578457]\n",
      " [0.50784636]\n",
      " [0.67299496]\n",
      " [0.53367746]\n",
      " [0.53482157]] | y: 0.7272375048430839 | Predicción actual: [[0.53867906]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034508801996707916, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50434589]\n",
      " [0.50445741]\n",
      " [0.50578457]\n",
      " [0.50784636]\n",
      " [0.67299496]\n",
      " [0.53367746]\n",
      " [0.53482157]\n",
      " [0.53867906]] | y: 0.722588144130182 | Predicción actual: [[0.5452988]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04289138689637184, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50445741]\n",
      " [0.50578457]\n",
      " [0.50784636]\n",
      " [0.67299496]\n",
      " [0.53367746]\n",
      " [0.53482157]\n",
      " [0.53867906]\n",
      " [0.54529881]] | y: 0.771793878341728 | Predicción actual: [[0.5543586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041380319744348526, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50578457]\n",
      " [0.50784636]\n",
      " [0.67299496]\n",
      " [0.53367746]\n",
      " [0.53482157]\n",
      " [0.53867906]\n",
      " [0.54529881]\n",
      " [0.5543586 ]] | y: 0.7245253777605578 | Predicción actual: [[0.565422]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03223809227347374, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50784636]\n",
      " [0.67299496]\n",
      " [0.53367746]\n",
      " [0.53482157]\n",
      " [0.53867906]\n",
      " [0.54529881]\n",
      " [0.5543586 ]\n",
      " [0.565422  ]] | y: 0.6710577295621851 | Predicción actual: [[0.5780105]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02714393101632595, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.53367746]\n",
      " [0.53482157]\n",
      " [0.53867906]\n",
      " [0.54529881]\n",
      " [0.5543586 ]\n",
      " [0.565422  ]\n",
      " [0.5780105 ]] | y: 0.6737698566447115 | Predicción actual: [[0.5917676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012259137816727161, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53367746]\n",
      " [0.53482157]\n",
      " [0.53867906]\n",
      " [0.54529881]\n",
      " [0.5543586 ]\n",
      " [0.565422  ]\n",
      " [0.5780105 ]\n",
      " [0.59176761]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07620090246200562, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53482157]\n",
      " [0.53867906]\n",
      " [0.54529881]\n",
      " [0.5543586 ]\n",
      " [0.565422  ]\n",
      " [0.5780105 ]\n",
      " [0.59176761]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5700618]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01971975713968277, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53867906]\n",
      " [0.54529881]\n",
      " [0.5543586 ]\n",
      " [0.565422  ]\n",
      " [0.5780105 ]\n",
      " [0.59176761]\n",
      " [0.71445176]\n",
      " [0.5700618 ]] | y: 0.722588144130182 | Predicción actual: [[0.57893485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024408753961324692, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54529881]\n",
      " [0.5543586 ]\n",
      " [0.565422  ]\n",
      " [0.5780105 ]\n",
      " [0.59176761]\n",
      " [0.71445176]\n",
      " [0.5700618 ]\n",
      " [0.57893485]] | y: 0.6993413405656723 | Predicción actual: [[0.58981544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020013123750686646, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5543586 ]\n",
      " [0.565422  ]\n",
      " [0.5780105 ]\n",
      " [0.59176761]\n",
      " [0.71445176]\n",
      " [0.5700618 ]\n",
      " [0.57893485]\n",
      " [0.58981544]] | y: 0.7373111197210385 | Predicción actual: [[0.60175294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018308568745851517, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.565422  ]\n",
      " [0.5780105 ]\n",
      " [0.59176761]\n",
      " [0.71445176]\n",
      " [0.5700618 ]\n",
      " [0.57893485]\n",
      " [0.58981544]\n",
      " [0.60175294]] | y: 0.7214258039519565 | Predicción actual: [[0.613687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019161638338118792, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5780105 ]\n",
      " [0.59176761]\n",
      " [0.71445176]\n",
      " [0.5700618 ]\n",
      " [0.57893485]\n",
      " [0.58981544]\n",
      " [0.60175294]\n",
      " [0.61368698]] | y: 0.7187136768694304 | Predicción actual: [[0.6244779]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009358259849250317, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59176761]\n",
      " [0.71445176]\n",
      " [0.5700618 ]\n",
      " [0.57893485]\n",
      " [0.58981544]\n",
      " [0.60175294]\n",
      " [0.61368698]\n",
      " [0.62447792]] | y: 0.6741573033707864 | Predicción actual: [[0.6332507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001984330825507641, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.5700618 ]\n",
      " [0.57893485]\n",
      " [0.58981544]\n",
      " [0.60175294]\n",
      " [0.61368698]\n",
      " [0.62447792]\n",
      " [0.63325071]] | y: 0.698566447113522 | Predicción actual: [[0.6391753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013067950494587421, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5700618 ]\n",
      " [0.57893485]\n",
      " [0.58981544]\n",
      " [0.60175294]\n",
      " [0.61368698]\n",
      " [0.62447792]\n",
      " [0.63325071]\n",
      " [0.6391753 ]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036402687430381775, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57893485]\n",
      " [0.58981544]\n",
      " [0.60175294]\n",
      " [0.61368698]\n",
      " [0.62447792]\n",
      " [0.63325071]\n",
      " [0.6391753 ]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.62272835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01954372599720955, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58981544]\n",
      " [0.60175294]\n",
      " [0.61368698]\n",
      " [0.62447792]\n",
      " [0.63325071]\n",
      " [0.6391753 ]\n",
      " [0.72103836]\n",
      " [0.62272835]] | y: 0.7562960092987214 | Predicción actual: [[0.63395125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09124825894832611, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60175294]\n",
      " [0.61368698]\n",
      " [0.62447792]\n",
      " [0.63325071]\n",
      " [0.6391753 ]\n",
      " [0.72103836]\n",
      " [0.62272835]\n",
      " [0.63395125]] | y: 0.8275862068965516 | Predicción actual: [[0.6453276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006357248872518539, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61368698]\n",
      " [0.62447792]\n",
      " [0.63325071]\n",
      " [0.6391753 ]\n",
      " [0.72103836]\n",
      " [0.62272835]\n",
      " [0.63395125]\n",
      " [0.64532763]] | y: 0.8388221619527314 | Predicción actual: [[0.6559463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01134598907083273, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62447792]\n",
      " [0.63325071]\n",
      " [0.6391753 ]\n",
      " [0.72103836]\n",
      " [0.62272835]\n",
      " [0.63395125]\n",
      " [0.64532763]\n",
      " [0.65594631]] | y: 0.7942657884540876 | Predicción actual: [[0.66530395]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005354748107492924, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63325071]\n",
      " [0.6391753 ]\n",
      " [0.72103836]\n",
      " [0.62272835]\n",
      " [0.63395125]\n",
      " [0.64532763]\n",
      " [0.65594631]\n",
      " [0.66530395]] | y: 0.7838047268500579 | Predicción actual: [[0.6731707]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010259251110255718, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6391753 ]\n",
      " [0.72103836]\n",
      " [0.62272835]\n",
      " [0.63395125]\n",
      " [0.64532763]\n",
      " [0.65594631]\n",
      " [0.66530395]\n",
      " [0.67317069]] | y: 0.7679194110809764 | Predicción actual: [[0.6797633]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036377066280692816, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62272835]\n",
      " [0.63395125]\n",
      " [0.64532763]\n",
      " [0.65594631]\n",
      " [0.66530395]\n",
      " [0.67317069]\n",
      " [0.67976332]] | y: 0.7845796203022084 | Predicción actual: [[0.6854401]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005831393878906965, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62272835]\n",
      " [0.63395125]\n",
      " [0.64532763]\n",
      " [0.65594631]\n",
      " [0.66530395]\n",
      " [0.67317069]\n",
      " [0.67976332]\n",
      " [0.68544012]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09550245106220245, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63395125]\n",
      " [0.64532763]\n",
      " [0.65594631]\n",
      " [0.66530395]\n",
      " [0.67317069]\n",
      " [0.67976332]\n",
      " [0.68544012]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.68051547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0458512157201767, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64532763]\n",
      " [0.65594631]\n",
      " [0.66530395]\n",
      " [0.67317069]\n",
      " [0.67976332]\n",
      " [0.68544012]\n",
      " [0.87872917]\n",
      " [0.68051547]] | y: 0.8488957768306855 | Predicción actual: [[0.693162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008107109926640987, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65594631]\n",
      " [0.66530395]\n",
      " [0.67317069]\n",
      " [0.67976332]\n",
      " [0.68544012]\n",
      " [0.87872917]\n",
      " [0.68051547]\n",
      " [0.69316202]] | y: 0.8182874854707476 | Predicción actual: [[0.7065763]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00014297530287876725, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66530395]\n",
      " [0.67317069]\n",
      " [0.67976332]\n",
      " [0.68544012]\n",
      " [0.87872917]\n",
      " [0.68051547]\n",
      " [0.69316202]\n",
      " [0.70657629]] | y: 0.8268113134444013 | Predicción actual: [[0.720411]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017289163544774055, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67317069]\n",
      " [0.67976332]\n",
      " [0.68544012]\n",
      " [0.87872917]\n",
      " [0.68051547]\n",
      " [0.69316202]\n",
      " [0.70657629]\n",
      " [0.720411  ]] | y: 0.7853545137543589 | Predicción actual: [[0.7346503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01702233776450157, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67976332]\n",
      " [0.68544012]\n",
      " [0.87872917]\n",
      " [0.68051547]\n",
      " [0.69316202]\n",
      " [0.70657629]\n",
      " [0.720411  ]\n",
      " [0.73465031]] | y: 0.7892289810151103 | Predicción actual: [[0.74917513]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004134520888328552, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68544012]\n",
      " [0.87872917]\n",
      " [0.68051547]\n",
      " [0.69316202]\n",
      " [0.70657629]\n",
      " [0.720411  ]\n",
      " [0.73465031]\n",
      " [0.74917513]] | y: 0.8341728012398295 | Predicción actual: [[0.7638368]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00327159627340734, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.68051547]\n",
      " [0.69316202]\n",
      " [0.70657629]\n",
      " [0.720411  ]\n",
      " [0.73465031]\n",
      " [0.74917513]\n",
      " [0.7638368 ]] | y: 0.8124757845796202 | Predicción actual: [[0.77839637]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012680081650614738, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68051547]\n",
      " [0.69316202]\n",
      " [0.70657629]\n",
      " [0.720411  ]\n",
      " [0.73465031]\n",
      " [0.74917513]\n",
      " [0.7638368 ]\n",
      " [0.77839637]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018300351221114397, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69316202]\n",
      " [0.70657629]\n",
      " [0.720411  ]\n",
      " [0.73465031]\n",
      " [0.74917513]\n",
      " [0.7638368 ]\n",
      " [0.77839637]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.75125915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014231951907277107, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70657629]\n",
      " [0.720411  ]\n",
      " [0.73465031]\n",
      " [0.74917513]\n",
      " [0.7638368 ]\n",
      " [0.77839637]\n",
      " [0.80123983]\n",
      " [0.75125915]] | y: 0.793490895001937 | Predicción actual: [[0.76530826]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.913372635608539e-05, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.720411  ]\n",
      " [0.73465031]\n",
      " [0.74917513]\n",
      " [0.7638368 ]\n",
      " [0.77839637]\n",
      " [0.80123983]\n",
      " [0.75125915]\n",
      " [0.76530826]] | y: 0.760170476559473 | Predicción actual: [[0.778788]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00013784087786916643, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73465031]\n",
      " [0.74917513]\n",
      " [0.7638368 ]\n",
      " [0.77839637]\n",
      " [0.80123983]\n",
      " [0.75125915]\n",
      " [0.76530826]\n",
      " [0.77878797]] | y: 0.7353738860906625 | Predicción actual: [[0.79099655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041897647082805634, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74917513]\n",
      " [0.7638368 ]\n",
      " [0.77839637]\n",
      " [0.80123983]\n",
      " [0.75125915]\n",
      " [0.76530826]\n",
      " [0.77878797]\n",
      " [0.79099655]] | y: 0.7101898488957767 | Predicción actual: [[0.8008504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016286433674395084, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7638368 ]\n",
      " [0.77839637]\n",
      " [0.80123983]\n",
      " [0.75125915]\n",
      " [0.76530826]\n",
      " [0.77878797]\n",
      " [0.79099655]\n",
      " [0.80085039]] | y: 0.7121270825261525 | Predicción actual: [[0.80820423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04009838029742241, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77839637]\n",
      " [0.80123983]\n",
      " [0.75125915]\n",
      " [0.76530826]\n",
      " [0.77878797]\n",
      " [0.79099655]\n",
      " [0.80085039]\n",
      " [0.80820423]] | y: 0.7396358000774894 | Predicción actual: [[0.8122148]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0074872602708637714, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.75125915]\n",
      " [0.76530826]\n",
      " [0.77878797]\n",
      " [0.79099655]\n",
      " [0.80085039]\n",
      " [0.80820423]\n",
      " [0.81221479]] | y: 0.7361487795428128 | Predicción actual: [[0.81292284]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006648983806371689, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75125915]\n",
      " [0.76530826]\n",
      " [0.77878797]\n",
      " [0.79099655]\n",
      " [0.80085039]\n",
      " [0.80820423]\n",
      " [0.81221479]\n",
      " [0.81292284]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012235627509653568, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76530826]\n",
      " [0.77878797]\n",
      " [0.79099655]\n",
      " [0.80085039]\n",
      " [0.80820423]\n",
      " [0.81221479]\n",
      " [0.81292284]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.81729203]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029619602486491203, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77878797]\n",
      " [0.79099655]\n",
      " [0.80085039]\n",
      " [0.80820423]\n",
      " [0.81221479]\n",
      " [0.81292284]\n",
      " [0.66757071]\n",
      " [0.81729203]] | y: 0.696629213483146 | Predicción actual: [[0.8236566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00044159716344438493, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79099655]\n",
      " [0.80085039]\n",
      " [0.80820423]\n",
      " [0.81221479]\n",
      " [0.81292284]\n",
      " [0.66757071]\n",
      " [0.81729203]\n",
      " [0.82365662]] | y: 0.6559473072452537 | Predicción actual: [[0.8267123]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0518096461892128, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80085039]\n",
      " [0.80820423]\n",
      " [0.81221479]\n",
      " [0.81292284]\n",
      " [0.66757071]\n",
      " [0.81729203]\n",
      " [0.82365662]\n",
      " [0.82671231]] | y: 0.6788066640836885 | Predicción actual: [[0.82598144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033234090078622103, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80820423]\n",
      " [0.81221479]\n",
      " [0.81292284]\n",
      " [0.66757071]\n",
      " [0.81729203]\n",
      " [0.82365662]\n",
      " [0.82671231]\n",
      " [0.82598144]] | y: 0.6760945370011622 | Predicción actual: [[0.8225064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00043008217471651733, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81221479]\n",
      " [0.81292284]\n",
      " [0.66757071]\n",
      " [0.81729203]\n",
      " [0.82365662]\n",
      " [0.82671231]\n",
      " [0.82598144]\n",
      " [0.82250643]] | y: 0.7295621851995349 | Predicción actual: [[0.8172498]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04109225049614906, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81292284]\n",
      " [0.66757071]\n",
      " [0.81729203]\n",
      " [0.82365662]\n",
      " [0.82671231]\n",
      " [0.82598144]\n",
      " [0.82250643]\n",
      " [0.81724977]] | y: 0.7012785741960481 | Predicción actual: [[0.8110811]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003284226404502988, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.81729203]\n",
      " [0.82365662]\n",
      " [0.82671231]\n",
      " [0.82598144]\n",
      " [0.82250643]\n",
      " [0.81724977]\n",
      " [0.81108111]] | y: 0.767531964354901 | Predicción actual: [[0.8058036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0068058534525334835, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81729203]\n",
      " [0.82365662]\n",
      " [0.82671231]\n",
      " [0.82598144]\n",
      " [0.82250643]\n",
      " [0.81724977]\n",
      " [0.81108111]\n",
      " [0.8058036 ]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012012275401502848, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82365662]\n",
      " [0.82671231]\n",
      " [0.82598144]\n",
      " [0.82250643]\n",
      " [0.81724977]\n",
      " [0.81108111]\n",
      " [0.8058036 ]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.84525424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00025909452233463526, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82671231]\n",
      " [0.82598144]\n",
      " [0.82250643]\n",
      " [0.81724977]\n",
      " [0.81108111]\n",
      " [0.8058036 ]\n",
      " [0.75513367]\n",
      " [0.84525424]] | y: 0.7520340953118947 | Predicción actual: [[0.84255487]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012960722669959068, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82598144]\n",
      " [0.82250643]\n",
      " [0.81724977]\n",
      " [0.81108111]\n",
      " [0.8058036 ]\n",
      " [0.75513367]\n",
      " [0.84525424]\n",
      " [0.84255487]] | y: 0.7098024021697016 | Predicción actual: [[0.8380926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008497375063598156, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82250643]\n",
      " [0.81724977]\n",
      " [0.81108111]\n",
      " [0.8058036 ]\n",
      " [0.75513367]\n",
      " [0.84525424]\n",
      " [0.84255487]\n",
      " [0.83809263]] | y: 0.6904300658659435 | Predicción actual: [[0.8333207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09039396792650223, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81724977]\n",
      " [0.81108111]\n",
      " [0.8058036 ]\n",
      " [0.75513367]\n",
      " [0.84525424]\n",
      " [0.84255487]\n",
      " [0.83809263]\n",
      " [0.83332068]] | y: 0.7543587756683454 | Predicción actual: [[0.82897544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002424597041681409, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81108111]\n",
      " [0.8058036 ]\n",
      " [0.75513367]\n",
      " [0.84525424]\n",
      " [0.84255487]\n",
      " [0.83809263]\n",
      " [0.83332068]\n",
      " [0.82897544]] | y: 0.7222006974041069 | Predicción actual: [[0.8267997]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012070870026946068, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8058036 ]\n",
      " [0.75513367]\n",
      " [0.84525424]\n",
      " [0.84255487]\n",
      " [0.83809263]\n",
      " [0.83332068]\n",
      " [0.82897544]\n",
      " [0.82679969]] | y: 0.8485083301046106 | Predicción actual: [[0.82764727]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.733332272939151e-06, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.84525424]\n",
      " [0.84255487]\n",
      " [0.83809263]\n",
      " [0.83332068]\n",
      " [0.82897544]\n",
      " [0.82679969]\n",
      " [0.82764727]] | y: 0.9054629988376597 | Predicción actual: [[0.83136874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009534869343042374, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84525424]\n",
      " [0.84255487]\n",
      " [0.83809263]\n",
      " [0.83332068]\n",
      " [0.82897544]\n",
      " [0.82679969]\n",
      " [0.82764727]\n",
      " [0.83136874]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00435386598110199, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84255487]\n",
      " [0.83809263]\n",
      " [0.83332068]\n",
      " [0.82897544]\n",
      " [0.82679969]\n",
      " [0.82764727]\n",
      " [0.83136874]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8482298]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008618338964879513, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83809263]\n",
      " [0.83332068]\n",
      " [0.82897544]\n",
      " [0.82679969]\n",
      " [0.82764727]\n",
      " [0.83136874]\n",
      " [0.8822162 ]\n",
      " [0.84822983]] | y: 0.889577683068578 | Predicción actual: [[0.84557086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.808348239748739e-05, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83332068]\n",
      " [0.82897544]\n",
      " [0.82679969]\n",
      " [0.82764727]\n",
      " [0.83136874]\n",
      " [0.8822162 ]\n",
      " [0.84822983]\n",
      " [0.84557086]] | y: 0.8748547074777218 | Predicción actual: [[0.8445506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007412015693262219, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82897544]\n",
      " [0.82679969]\n",
      " [0.82764727]\n",
      " [0.83136874]\n",
      " [0.8822162 ]\n",
      " [0.84822983]\n",
      " [0.84557086]\n",
      " [0.84455061]] | y: 0.9132119333591631 | Predicción actual: [[0.8455463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055623751133680344, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82679969]\n",
      " [0.82764727]\n",
      " [0.83136874]\n",
      " [0.8822162 ]\n",
      " [0.84822983]\n",
      " [0.84557086]\n",
      " [0.84455061]\n",
      " [0.84554631]] | y: 1.0 | Predicción actual: [[0.8491136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007829426787793636, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82764727]\n",
      " [0.83136874]\n",
      " [0.8822162 ]\n",
      " [0.84822983]\n",
      " [0.84557086]\n",
      " [0.84455061]\n",
      " [0.84554631]\n",
      " [0.84911358]] | y: 0.9705540488182873 | Predicción actual: [[0.8545051]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0041625769808888435, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83136874]\n",
      " [0.8822162 ]\n",
      " [0.84822983]\n",
      " [0.84557086]\n",
      " [0.84455061]\n",
      " [0.84554631]\n",
      " [0.84911358]\n",
      " [0.85450512]] | y: 0.8888027896164277 | Predicción actual: [[0.8607533]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013161249458789825, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.84822983]\n",
      " [0.84557086]\n",
      " [0.84455061]\n",
      " [0.84554631]\n",
      " [0.84911358]\n",
      " [0.85450512]\n",
      " [0.8607533 ]] | y: 0.877954281286323 | Predicción actual: [[0.8664307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014486677013337612, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84822983]\n",
      " [0.84557086]\n",
      " [0.84455061]\n",
      " [0.84554631]\n",
      " [0.84911358]\n",
      " [0.85450512]\n",
      " [0.8607533 ]\n",
      " [0.8664307 ]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005765345995314419, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84557086]\n",
      " [0.84455061]\n",
      " [0.84554631]\n",
      " [0.84911358]\n",
      " [0.85450512]\n",
      " [0.8607533 ]\n",
      " [0.8664307 ]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8583781]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007616181392222643, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84455061]\n",
      " [0.84554631]\n",
      " [0.84911358]\n",
      " [0.85450512]\n",
      " [0.8607533 ]\n",
      " [0.8664307 ]\n",
      " [0.84889578]\n",
      " [0.85837811]] | y: 0.8550949244478885 | Predicción actual: [[0.86042345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02120639570057392, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84554631]\n",
      " [0.84911358]\n",
      " [0.85450512]\n",
      " [0.8607533 ]\n",
      " [0.8664307 ]\n",
      " [0.84889578]\n",
      " [0.85837811]\n",
      " [0.86042345]] | y: 0.8752421542037967 | Predicción actual: [[0.8635971]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026356710121035576, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84911358]\n",
      " [0.85450512]\n",
      " [0.8607533 ]\n",
      " [0.8664307 ]\n",
      " [0.84889578]\n",
      " [0.85837811]\n",
      " [0.86042345]\n",
      " [0.8635971 ]] | y: 0.857032158078264 | Predicción actual: [[0.86736864]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012236486189067364, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85450512]\n",
      " [0.8607533 ]\n",
      " [0.8664307 ]\n",
      " [0.84889578]\n",
      " [0.85837811]\n",
      " [0.86042345]\n",
      " [0.8635971 ]\n",
      " [0.86736864]] | y: 0.8500581170089112 | Predicción actual: [[0.87037456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011106012389063835, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8607533 ]\n",
      " [0.8664307 ]\n",
      " [0.84889578]\n",
      " [0.85837811]\n",
      " [0.86042345]\n",
      " [0.8635971 ]\n",
      " [0.86736864]\n",
      " [0.87037456]] | y: 0.8426966292134832 | Predicción actual: [[0.87246406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02626517042517662, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8664307 ]\n",
      " [0.84889578]\n",
      " [0.85837811]\n",
      " [0.86042345]\n",
      " [0.8635971 ]\n",
      " [0.86736864]\n",
      " [0.87037456]\n",
      " [0.87246406]] | y: 0.8229368461836497 | Predicción actual: [[0.8726588]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04631304368376732, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.85837811]\n",
      " [0.86042345]\n",
      " [0.8635971 ]\n",
      " [0.86736864]\n",
      " [0.87037456]\n",
      " [0.87246406]\n",
      " [0.87265879]] | y: 0.7745060054242543 | Predicción actual: [[0.8709519]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.9513852496165782e-05, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85837811]\n",
      " [0.86042345]\n",
      " [0.8635971 ]\n",
      " [0.86736864]\n",
      " [0.87037456]\n",
      " [0.87246406]\n",
      " [0.87265879]\n",
      " [0.87095189]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026876132935285568, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86042345]\n",
      " [0.8635971 ]\n",
      " [0.86736864]\n",
      " [0.87037456]\n",
      " [0.87246406]\n",
      " [0.87265879]\n",
      " [0.87095189]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8759933]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014151125214993954, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8635971 ]\n",
      " [0.86736864]\n",
      " [0.87037456]\n",
      " [0.87246406]\n",
      " [0.87265879]\n",
      " [0.87095189]\n",
      " [0.78419217]\n",
      " [0.87599331]] | y: 0.854320030995738 | Predicción actual: [[0.87644035]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00023094455536920577, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86736864]\n",
      " [0.87037456]\n",
      " [0.87246406]\n",
      " [0.87265879]\n",
      " [0.87095189]\n",
      " [0.78419217]\n",
      " [0.87599331]\n",
      " [0.87644035]] | y: 0.8368849283223556 | Predicción actual: [[0.87562555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009120522066950798, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87037456]\n",
      " [0.87246406]\n",
      " [0.87265879]\n",
      " [0.87095189]\n",
      " [0.78419217]\n",
      " [0.87599331]\n",
      " [0.87644035]\n",
      " [0.87562555]] | y: 0.8299108872530028 | Predicción actual: [[0.87313193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05567532405257225, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87246406]\n",
      " [0.87265879]\n",
      " [0.87095189]\n",
      " [0.78419217]\n",
      " [0.87599331]\n",
      " [0.87644035]\n",
      " [0.87562555]\n",
      " [0.87313193]] | y: 0.887253002712127 | Predicción actual: [[0.8688545]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013697234680876136, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87265879]\n",
      " [0.87095189]\n",
      " [0.78419217]\n",
      " [0.87599331]\n",
      " [0.87644035]\n",
      " [0.87562555]\n",
      " [0.87313193]\n",
      " [0.86885452]] | y: 0.8597442851607902 | Predicción actual: [[0.8639659]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003565785591490567, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87095189]\n",
      " [0.78419217]\n",
      " [0.87599331]\n",
      " [0.87644035]\n",
      " [0.87562555]\n",
      " [0.87313193]\n",
      " [0.86885452]\n",
      " [0.86396593]] | y: 0.8395970554048819 | Predicción actual: [[0.8590688]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.3423271411738824e-05, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.87599331]\n",
      " [0.87644035]\n",
      " [0.87562555]\n",
      " [0.87313193]\n",
      " [0.86885452]\n",
      " [0.86396593]\n",
      " [0.85906881]] | y: 0.7838047268500579 | Predicción actual: [[0.8549649]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044557489454746246, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87599331]\n",
      " [0.87644035]\n",
      " [0.87562555]\n",
      " [0.87313193]\n",
      " [0.86885452]\n",
      " [0.86396593]\n",
      " [0.85906881]\n",
      " [0.85496491]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012071016244590282, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87644035]\n",
      " [0.87562555]\n",
      " [0.87313193]\n",
      " [0.86885452]\n",
      " [0.86396593]\n",
      " [0.85906881]\n",
      " [0.85496491]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8733214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036745688412338495, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87562555]\n",
      " [0.87313193]\n",
      " [0.86885452]\n",
      " [0.86396593]\n",
      " [0.85906881]\n",
      " [0.85496491]\n",
      " [0.81828749]\n",
      " [0.87332141]] | y: 0.7605579232855482 | Predicción actual: [[0.86887074]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02383098378777504, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87313193]\n",
      " [0.86885452]\n",
      " [0.86396593]\n",
      " [0.85906881]\n",
      " [0.85496491]\n",
      " [0.81828749]\n",
      " [0.87332141]\n",
      " [0.86887074]] | y: 0.7915536613715615 | Predicción actual: [[0.86343735]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.481124339392409e-05, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86885452]\n",
      " [0.86396593]\n",
      " [0.85906881]\n",
      " [0.85496491]\n",
      " [0.81828749]\n",
      " [0.87332141]\n",
      " [0.86887074]\n",
      " [0.86343735]] | y: 0.7686943045331267 | Predicción actual: [[0.8580245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010088569484651089, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86396593]\n",
      " [0.85906881]\n",
      " [0.85496491]\n",
      " [0.81828749]\n",
      " [0.87332141]\n",
      " [0.86887074]\n",
      " [0.86343735]\n",
      " [0.85802448]] | y: 0.7686943045331267 | Predicción actual: [[0.8531898]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02266196720302105, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85906881]\n",
      " [0.85496491]\n",
      " [0.81828749]\n",
      " [0.87332141]\n",
      " [0.86887074]\n",
      " [0.86343735]\n",
      " [0.85802448]\n",
      " [0.85318983]] | y: 0.7989151491669895 | Predicción actual: [[0.8492611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001455359742976725, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85496491]\n",
      " [0.81828749]\n",
      " [0.87332141]\n",
      " [0.86887074]\n",
      " [0.86343735]\n",
      " [0.85802448]\n",
      " [0.85318983]\n",
      " [0.84926111]] | y: 0.7900038744672608 | Predicción actual: [[0.8467311]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01277218759059906, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.87332141]\n",
      " [0.86887074]\n",
      " [0.86343735]\n",
      " [0.85802448]\n",
      " [0.85318983]\n",
      " [0.84926111]\n",
      " [0.84673113]] | y: 0.760170476559473 | Predicción actual: [[0.8453207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.99978879513219e-05, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87332141]\n",
      " [0.86887074]\n",
      " [0.86343735]\n",
      " [0.85802448]\n",
      " [0.85318983]\n",
      " [0.84926111]\n",
      " [0.84673113]\n",
      " [0.8453207 ]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10766620934009552, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86887074]\n",
      " [0.86343735]\n",
      " [0.85802448]\n",
      " [0.85318983]\n",
      " [0.84926111]\n",
      " [0.84673113]\n",
      " [0.8453207 ]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8474218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08528725057840347, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86343735]\n",
      " [0.85802448]\n",
      " [0.85318983]\n",
      " [0.84926111]\n",
      " [0.84673113]\n",
      " [0.8453207 ]\n",
      " [0.68539326]\n",
      " [0.84742182]] | y: 0.6648585819449826 | Predicción actual: [[0.83837056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035449691116809845, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85802448]\n",
      " [0.85318983]\n",
      " [0.84926111]\n",
      " [0.84673113]\n",
      " [0.8453207 ]\n",
      " [0.68539326]\n",
      " [0.84742182]\n",
      " [0.83837056]] | y: 0.7078651685393258 | Predicción actual: [[0.8282632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028039027005434036, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85318983]\n",
      " [0.84926111]\n",
      " [0.84673113]\n",
      " [0.8453207 ]\n",
      " [0.68539326]\n",
      " [0.84742182]\n",
      " [0.83837056]\n",
      " [0.82826322]] | y: 0.6648585819449826 | Predicción actual: [[0.81739396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08099513500928879, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84926111]\n",
      " [0.84673113]\n",
      " [0.8453207 ]\n",
      " [0.68539326]\n",
      " [0.84742182]\n",
      " [0.83837056]\n",
      " [0.82826322]\n",
      " [0.81739396]] | y: 0.7113521890740022 | Predicción actual: [[0.8056858]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03739489987492561, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84673113]\n",
      " [0.8453207 ]\n",
      " [0.68539326]\n",
      " [0.84742182]\n",
      " [0.83837056]\n",
      " [0.82826322]\n",
      " [0.81739396]\n",
      " [0.80568582]] | y: 0.6772568771793879 | Predicción actual: [[0.7935102]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0051984163001179695, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8453207 ]\n",
      " [0.68539326]\n",
      " [0.84742182]\n",
      " [0.83837056]\n",
      " [0.82826322]\n",
      " [0.81739396]\n",
      " [0.80568582]\n",
      " [0.7935102 ]] | y: 0.7621077101898488 | Predicción actual: [[0.7810501]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001461471401853487, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84742182]\n",
      " [0.83837056]\n",
      " [0.82826322]\n",
      " [0.81739396]\n",
      " [0.80568582]\n",
      " [0.7935102 ]\n",
      " [0.78105009]] | y: 0.8070515304145678 | Predicción actual: [[0.7682888]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005799142527393997, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84742182]\n",
      " [0.83837056]\n",
      " [0.82826322]\n",
      " [0.81739396]\n",
      " [0.80568582]\n",
      " [0.7935102 ]\n",
      " [0.78105009]\n",
      " [0.76828879]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006585960276424885, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83837056]\n",
      " [0.82826322]\n",
      " [0.81739396]\n",
      " [0.80568582]\n",
      " [0.7935102 ]\n",
      " [0.78105009]\n",
      " [0.76828879]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7882588]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005306660663336515, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82826322]\n",
      " [0.81739396]\n",
      " [0.80568582]\n",
      " [0.7935102 ]\n",
      " [0.78105009]\n",
      " [0.76828879]\n",
      " [0.81518791]\n",
      " [0.78825879]] | y: 0.9597055404881829 | Predicción actual: [[0.77791667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010511130094528198, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81739396]\n",
      " [0.80568582]\n",
      " [0.7935102 ]\n",
      " [0.78105009]\n",
      " [0.76828879]\n",
      " [0.81518791]\n",
      " [0.78825879]\n",
      " [0.77791667]] | y: 0.9643549012010848 | Predicción actual: [[0.7687522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04087584838271141, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80568582]\n",
      " [0.7935102 ]\n",
      " [0.78105009]\n",
      " [0.76828879]\n",
      " [0.81518791]\n",
      " [0.78825879]\n",
      " [0.77791667]\n",
      " [0.76875222]] | y: 0.8880278961642774 | Predicción actual: [[0.7613678]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023894865065813065, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7935102 ]\n",
      " [0.78105009]\n",
      " [0.76828879]\n",
      " [0.81518791]\n",
      " [0.78825879]\n",
      " [0.77791667]\n",
      " [0.76875222]\n",
      " [0.7613678 ]] | y: 0.8926772568771792 | Predicción actual: [[0.75612074]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02346811257302761, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78105009]\n",
      " [0.76828879]\n",
      " [0.81518791]\n",
      " [0.78825879]\n",
      " [0.77791667]\n",
      " [0.76875222]\n",
      " [0.7613678 ]\n",
      " [0.75612074]] | y: 0.8752421542037967 | Predicción actual: [[0.7533029]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013226346112787724, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76828879]\n",
      " [0.81518791]\n",
      " [0.78825879]\n",
      " [0.77791667]\n",
      " [0.76875222]\n",
      " [0.7613678 ]\n",
      " [0.75612074]\n",
      " [0.75330287]] | y: 0.8508330104610615 | Predicción actual: [[0.7530561]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00028754741651937366, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78825879]\n",
      " [0.77791667]\n",
      " [0.76875222]\n",
      " [0.7613678 ]\n",
      " [0.75612074]\n",
      " [0.75330287]\n",
      " [0.75305611]] | y: 0.8488957768306855 | Predicción actual: [[0.7554019]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06115730479359627, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78825879]\n",
      " [0.77791667]\n",
      " [0.76875222]\n",
      " [0.7613678 ]\n",
      " [0.75612074]\n",
      " [0.75330287]\n",
      " [0.75305611]\n",
      " [0.75540191]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04671094939112663, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77791667]\n",
      " [0.76875222]\n",
      " [0.7613678 ]\n",
      " [0.75612074]\n",
      " [0.75330287]\n",
      " [0.75305611]\n",
      " [0.75540191]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.74000573]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01078767143189907, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76875222]\n",
      " [0.7613678 ]\n",
      " [0.75612074]\n",
      " [0.75330287]\n",
      " [0.75305611]\n",
      " [0.75540191]\n",
      " [0.96241767]\n",
      " [0.74000573]] | y: 0.9407206509104997 | Predicción actual: [[0.7389961]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04329180344939232, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7613678 ]\n",
      " [0.75612074]\n",
      " [0.75330287]\n",
      " [0.75305611]\n",
      " [0.75540191]\n",
      " [0.96241767]\n",
      " [0.74000573]\n",
      " [0.73899609]] | y: 0.9724912824486633 | Predicción actual: [[0.7415421]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.13077105581760406, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75612074]\n",
      " [0.75330287]\n",
      " [0.75305611]\n",
      " [0.75540191]\n",
      " [0.96241767]\n",
      " [0.74000573]\n",
      " [0.73899609]\n",
      " [0.7415421 ]] | y: 0.9969004261913985 | Predicción actual: [[0.7473474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.2818496823310852, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75330287]\n",
      " [0.75305611]\n",
      " [0.75540191]\n",
      " [0.96241767]\n",
      " [0.74000573]\n",
      " [0.73899609]\n",
      " [0.7415421 ]\n",
      " [0.74734741]] | y: 0.951181712514529 | Predicción actual: [[0.75565654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05043346807360649, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75305611]\n",
      " [0.75540191]\n",
      " [0.96241767]\n",
      " [0.74000573]\n",
      " [0.73899609]\n",
      " [0.7415421 ]\n",
      " [0.74734741]\n",
      " [0.75565654]] | y: 0.8957768306857805 | Predicción actual: [[0.7652433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006814640946686268, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75540191]\n",
      " [0.96241767]\n",
      " [0.74000573]\n",
      " [0.73899609]\n",
      " [0.7415421 ]\n",
      " [0.74734741]\n",
      " [0.75565654]\n",
      " [0.76524329]] | y: 0.8814413018209997 | Predicción actual: [[0.77467626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009450569748878479, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.74000573]\n",
      " [0.73899609]\n",
      " [0.7415421 ]\n",
      " [0.74734741]\n",
      " [0.75565654]\n",
      " [0.76524329]\n",
      " [0.77467626]] | y: 0.9170864006199149 | Predicción actual: [[0.78293973]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08653421700000763, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74000573]\n",
      " [0.73899609]\n",
      " [0.7415421 ]\n",
      " [0.74734741]\n",
      " [0.75565654]\n",
      " [0.76524329]\n",
      " [0.77467626]\n",
      " [0.78293973]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07684244215488434, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73899609]\n",
      " [0.7415421 ]\n",
      " [0.74734741]\n",
      " [0.75565654]\n",
      " [0.76524329]\n",
      " [0.77467626]\n",
      " [0.78293973]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.73907506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05206689611077309, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7415421 ]\n",
      " [0.74734741]\n",
      " [0.75565654]\n",
      " [0.76524329]\n",
      " [0.77467626]\n",
      " [0.78293973]\n",
      " [0.91979853]\n",
      " [0.73907506]] | y: 0.9682293684618366 | Predicción actual: [[0.74846584]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031564660370349884, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74734741]\n",
      " [0.75565654]\n",
      " [0.76524329]\n",
      " [0.77467626]\n",
      " [0.78293973]\n",
      " [0.91979853]\n",
      " [0.73907506]\n",
      " [0.74846584]] | y: 0.9577683068578069 | Predicción actual: [[0.75970936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03837387636303902, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.21747237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027776293456554413, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21747237]] | y: 0.10422316931421921 | Predicción actual: [[0.20278953]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014047128148376942, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21747237]\n",
      " [0.20278953]] | y: 0.15420379697791559 | Predicción actual: [[0.20724797]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003111271420493722, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21747237]\n",
      " [0.20278953]\n",
      " [0.20724797]] | y: 0.1557535838822161 | Predicción actual: [[0.21907629]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000265968672465533, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21747237]\n",
      " [0.20278953]\n",
      " [0.20724797]\n",
      " [0.21907629]] | y: 0.12553273924835334 | Predicción actual: [[0.2323816]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009696978144347668, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21747237]\n",
      " [0.20278953]\n",
      " [0.20724797]\n",
      " [0.21907629]\n",
      " [0.2323816 ]] | y: 0.1456799690042619 | Predicción actual: [[0.24354476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004531987011432648, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21747237]\n",
      " [0.20278953]\n",
      " [0.20724797]\n",
      " [0.21907629]\n",
      " [0.2323816 ]\n",
      " [0.24354476]] | y: 0.1464548624564122 | Predicción actual: [[0.26639596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016178444027900696, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.21747237]\n",
      " [0.20278953]\n",
      " [0.20724797]\n",
      " [0.21907629]\n",
      " [0.2323816 ]\n",
      " [0.24354476]\n",
      " [0.26639596]] | y: 0.1960480433940332 | Predicción actual: [[0.29466897]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013504832983016968, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21747237]\n",
      " [0.20278953]\n",
      " [0.20724797]\n",
      " [0.21907629]\n",
      " [0.2323816 ]\n",
      " [0.24354476]\n",
      " [0.26639596]\n",
      " [0.29466897]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002878136234357953, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20278953]\n",
      " [0.20724797]\n",
      " [0.21907629]\n",
      " [0.2323816 ]\n",
      " [0.24354476]\n",
      " [0.26639596]\n",
      " [0.29466897]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.33145136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02560264617204666, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20724797]\n",
      " [0.21907629]\n",
      " [0.2323816 ]\n",
      " [0.24354476]\n",
      " [0.26639596]\n",
      " [0.29466897]\n",
      " [0.2305308 ]\n",
      " [0.33145136]] | y: 0.211933359163115 | Predicción actual: [[0.33890197]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006799258757382631, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21907629]\n",
      " [0.2323816 ]\n",
      " [0.24354476]\n",
      " [0.26639596]\n",
      " [0.29466897]\n",
      " [0.2305308 ]\n",
      " [0.33145136]\n",
      " [0.33890197]] | y: 0.2072839984502131 | Predicción actual: [[0.34818947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022717928513884544, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2323816 ]\n",
      " [0.24354476]\n",
      " [0.26639596]\n",
      " [0.29466897]\n",
      " [0.2305308 ]\n",
      " [0.33145136]\n",
      " [0.33890197]\n",
      " [0.34818947]] | y: 0.19294846958543205 | Predicción actual: [[0.35810518]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0515526719391346, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24354476]\n",
      " [0.26639596]\n",
      " [0.29466897]\n",
      " [0.2305308 ]\n",
      " [0.33145136]\n",
      " [0.33890197]\n",
      " [0.34818947]\n",
      " [0.35810518]] | y: 0.19682293684618352 | Predicción actual: [[0.36849082]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06893403083086014, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26639596]\n",
      " [0.29466897]\n",
      " [0.2305308 ]\n",
      " [0.33145136]\n",
      " [0.33890197]\n",
      " [0.34818947]\n",
      " [0.35810518]\n",
      " [0.36849082]] | y: 0.21425803951956607 | Predicción actual: [[0.37994492]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029914919286966324, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.29466897]\n",
      " [0.2305308 ]\n",
      " [0.33145136]\n",
      " [0.33890197]\n",
      " [0.34818947]\n",
      " [0.35810518]\n",
      " [0.36849082]\n",
      " [0.37994492]] | y: 0.18132506780317698 | Predicción actual: [[0.3899337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041066188365221024, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.33145136]\n",
      " [0.33890197]\n",
      " [0.34818947]\n",
      " [0.35810518]\n",
      " [0.36849082]\n",
      " [0.37994492]\n",
      " [0.38993371]] | y: 0.17512592018597434 | Predicción actual: [[0.39684948]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06227266788482666, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33145136]\n",
      " [0.33890197]\n",
      " [0.34818947]\n",
      " [0.35810518]\n",
      " [0.36849082]\n",
      " [0.37994492]\n",
      " [0.38993371]\n",
      " [0.39684948]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054207943379879, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33890197]\n",
      " [0.34818947]\n",
      " [0.35810518]\n",
      " [0.36849082]\n",
      " [0.37994492]\n",
      " [0.38993371]\n",
      " [0.39684948]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.42708844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09007898718118668, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34818947]\n",
      " [0.35810518]\n",
      " [0.36849082]\n",
      " [0.37994492]\n",
      " [0.38993371]\n",
      " [0.39684948]\n",
      " [0.14800465]\n",
      " [0.42708844]] | y: 0.19217357613328173 | Predicción actual: [[0.4306021]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05493486672639847, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35810518]\n",
      " [0.36849082]\n",
      " [0.37994492]\n",
      " [0.38993371]\n",
      " [0.39684948]\n",
      " [0.14800465]\n",
      " [0.42708844]\n",
      " [0.4306021 ]] | y: 0.1859744285160791 | Predicción actual: [[0.43221137]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035947833210229874, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36849082]\n",
      " [0.37994492]\n",
      " [0.38993371]\n",
      " [0.39684948]\n",
      " [0.14800465]\n",
      " [0.42708844]\n",
      " [0.4306021 ]\n",
      " [0.43221137]] | y: 0.26695079426578844 | Predicción actual: [[0.43203545]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02269308641552925, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37994492]\n",
      " [0.38993371]\n",
      " [0.39684948]\n",
      " [0.14800465]\n",
      " [0.42708844]\n",
      " [0.4306021 ]\n",
      " [0.43221137]\n",
      " [0.43203545]] | y: 0.2925222781867493 | Predicción actual: [[0.43034136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01688450574874878, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38993371]\n",
      " [0.39684948]\n",
      " [0.14800465]\n",
      " [0.42708844]\n",
      " [0.4306021 ]\n",
      " [0.43221137]\n",
      " [0.43203545]\n",
      " [0.43034136]] | y: 0.3177063153816349 | Predicción actual: [[0.4272759]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011025385931134224, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39684948]\n",
      " [0.14800465]\n",
      " [0.42708844]\n",
      " [0.4306021 ]\n",
      " [0.43221137]\n",
      " [0.43203545]\n",
      " [0.43034136]\n",
      " [0.4272759 ]] | y: 0.31266950794265785 | Predicción actual: [[0.42351335]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01771756261587143, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.42708844]\n",
      " [0.4306021 ]\n",
      " [0.43221137]\n",
      " [0.43203545]\n",
      " [0.43034136]\n",
      " [0.4272759 ]\n",
      " [0.42351335]] | y: 0.2890352576520729 | Predicción actual: [[0.42000404]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004417991265654564, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42708844]\n",
      " [0.4306021 ]\n",
      " [0.43221137]\n",
      " [0.43203545]\n",
      " [0.43034136]\n",
      " [0.4272759 ]\n",
      " [0.42351335]\n",
      " [0.42000404]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0332615040242672, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4306021 ]\n",
      " [0.43221137]\n",
      " [0.43203545]\n",
      " [0.43034136]\n",
      " [0.4272759 ]\n",
      " [0.42351335]\n",
      " [0.42000404]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.477426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018969997763633728, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43221137]\n",
      " [0.43203545]\n",
      " [0.43034136]\n",
      " [0.4272759 ]\n",
      " [0.42351335]\n",
      " [0.42000404]\n",
      " [0.28283611]\n",
      " [0.47742599]] | y: 0.2758620689655173 | Predicción actual: [[0.47450247]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047768816351890564, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43203545]\n",
      " [0.43034136]\n",
      " [0.4272759 ]\n",
      " [0.42351335]\n",
      " [0.42000404]\n",
      " [0.28283611]\n",
      " [0.47742599]\n",
      " [0.47450247]] | y: 0.2746997287872917 | Predicción actual: [[0.4703853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03831923007965088, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43034136]\n",
      " [0.4272759 ]\n",
      " [0.42351335]\n",
      " [0.42000404]\n",
      " [0.28283611]\n",
      " [0.47742599]\n",
      " [0.47450247]\n",
      " [0.47038531]] | y: 0.275474622239442 | Predicción actual: [[0.46603215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00741544459015131, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4272759 ]\n",
      " [0.42351335]\n",
      " [0.42000404]\n",
      " [0.28283611]\n",
      " [0.47742599]\n",
      " [0.47450247]\n",
      " [0.47038531]\n",
      " [0.46603215]] | y: 0.3347539713289423 | Predicción actual: [[0.46250325]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015051927417516708, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42351335]\n",
      " [0.42000404]\n",
      " [0.28283611]\n",
      " [0.47742599]\n",
      " [0.47450247]\n",
      " [0.47038531]\n",
      " [0.46603215]\n",
      " [0.46250325]] | y: 0.35567609453700116 | Predicción actual: [[0.4606902]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012750151799991727, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42000404]\n",
      " [0.28283611]\n",
      " [0.47742599]\n",
      " [0.47450247]\n",
      " [0.47038531]\n",
      " [0.46603215]\n",
      " [0.46250325]\n",
      " [0.4606902 ]] | y: 0.3366912049593181 | Predicción actual: [[0.46132267]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005152367986738682, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.47742599]\n",
      " [0.47450247]\n",
      " [0.47038531]\n",
      " [0.46603215]\n",
      " [0.46250325]\n",
      " [0.4606902 ]\n",
      " [0.46132267]] | y: 0.3335916311507167 | Predicción actual: [[0.464692]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012731337919831276, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47742599]\n",
      " [0.47450247]\n",
      " [0.47038531]\n",
      " [0.46603215]\n",
      " [0.46250325]\n",
      " [0.4606902 ]\n",
      " [0.46132267]\n",
      " [0.464692  ]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05321849510073662, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47450247]\n",
      " [0.47038531]\n",
      " [0.46603215]\n",
      " [0.46250325]\n",
      " [0.4606902 ]\n",
      " [0.46132267]\n",
      " [0.464692  ]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.50008655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012810761108994484, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47038531]\n",
      " [0.46603215]\n",
      " [0.46250325]\n",
      " [0.4606902 ]\n",
      " [0.46132267]\n",
      " [0.464692  ]\n",
      " [0.3847346 ]\n",
      " [0.50008655]] | y: 0.5962805114296785 | Predicción actual: [[0.49630964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029263109900057316, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46603215]\n",
      " [0.46250325]\n",
      " [0.4606902 ]\n",
      " [0.46132267]\n",
      " [0.464692  ]\n",
      " [0.3847346 ]\n",
      " [0.50008655]\n",
      " [0.49630964]] | y: 0.574583494769469 | Predicción actual: [[0.4931021]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030120620504021645, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46250325]\n",
      " [0.4606902 ]\n",
      " [0.46132267]\n",
      " [0.464692  ]\n",
      " [0.3847346 ]\n",
      " [0.50008655]\n",
      " [0.49630964]\n",
      " [0.4931021 ]] | y: 0.6063541263076326 | Predicción actual: [[0.49106002]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031485140323638916, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4606902 ]\n",
      " [0.46132267]\n",
      " [0.464692  ]\n",
      " [0.3847346 ]\n",
      " [0.50008655]\n",
      " [0.49630964]\n",
      " [0.4931021 ]\n",
      " [0.49106002]] | y: 0.5846571096474236 | Predicción actual: [[0.49047998]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010372135788202286, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46132267]\n",
      " [0.464692  ]\n",
      " [0.3847346 ]\n",
      " [0.50008655]\n",
      " [0.49630964]\n",
      " [0.4931021 ]\n",
      " [0.49106002]\n",
      " [0.49047998]] | y: 0.5687717938783416 | Predicción actual: [[0.49131384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006282264366745949, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.464692  ]\n",
      " [0.3847346 ]\n",
      " [0.50008655]\n",
      " [0.49630964]\n",
      " [0.4931021 ]\n",
      " [0.49106002]\n",
      " [0.49047998]\n",
      " [0.49131384]] | y: 0.6427741185586981 | Predicción actual: [[0.49323693]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042534444481134415, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.50008655]\n",
      " [0.49630964]\n",
      " [0.4931021 ]\n",
      " [0.49106002]\n",
      " [0.49047998]\n",
      " [0.49131384]\n",
      " [0.49323693]] | y: 0.6617590081363811 | Predicción actual: [[0.4957874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037275850772857666, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50008655]\n",
      " [0.49630964]\n",
      " [0.4931021 ]\n",
      " [0.49106002]\n",
      " [0.49047998]\n",
      " [0.49131384]\n",
      " [0.49323693]\n",
      " [0.49578741]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02637707255780697, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49630964]\n",
      " [0.4931021 ]\n",
      " [0.49106002]\n",
      " [0.49047998]\n",
      " [0.49131384]\n",
      " [0.49323693]\n",
      " [0.49578741]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5193519]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024327712133526802, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4931021 ]\n",
      " [0.49106002]\n",
      " [0.49047998]\n",
      " [0.49131384]\n",
      " [0.49323693]\n",
      " [0.49578741]\n",
      " [0.67299496]\n",
      " [0.5193519 ]] | y: 0.703990701278574 | Predicción actual: [[0.5214621]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03756154701113701, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49106002]\n",
      " [0.49047998]\n",
      " [0.49131384]\n",
      " [0.49323693]\n",
      " [0.49578741]\n",
      " [0.67299496]\n",
      " [0.5193519 ]\n",
      " [0.52146208]] | y: 0.7272375048430839 | Predicción actual: [[0.5263168]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030363978818058968, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49047998]\n",
      " [0.49131384]\n",
      " [0.49323693]\n",
      " [0.49578741]\n",
      " [0.67299496]\n",
      " [0.5193519 ]\n",
      " [0.52146208]\n",
      " [0.52631682]] | y: 0.722588144130182 | Predicción actual: [[0.5338361]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01144606526941061, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49131384]\n",
      " [0.49323693]\n",
      " [0.49578741]\n",
      " [0.67299496]\n",
      " [0.5193519 ]\n",
      " [0.52146208]\n",
      " [0.52631682]\n",
      " [0.53383613]] | y: 0.771793878341728 | Predicción actual: [[0.5436304]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04926576837897301, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49323693]\n",
      " [0.49578741]\n",
      " [0.67299496]\n",
      " [0.5193519 ]\n",
      " [0.52146208]\n",
      " [0.52631682]\n",
      " [0.53383613]\n",
      " [0.54363042]] | y: 0.7245253777605578 | Predicción actual: [[0.55532473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040162380784749985, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49578741]\n",
      " [0.67299496]\n",
      " [0.5193519 ]\n",
      " [0.52146208]\n",
      " [0.52631682]\n",
      " [0.53383613]\n",
      " [0.54363042]\n",
      " [0.55532473]] | y: 0.6710577295621851 | Predicción actual: [[0.5684462]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03527531772851944, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.5193519 ]\n",
      " [0.52146208]\n",
      " [0.52631682]\n",
      " [0.53383613]\n",
      " [0.54363042]\n",
      " [0.55532473]\n",
      " [0.56844622]] | y: 0.6737698566447115 | Predicción actual: [[0.5826457]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019766120240092278, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5193519 ]\n",
      " [0.52146208]\n",
      " [0.52631682]\n",
      " [0.53383613]\n",
      " [0.54363042]\n",
      " [0.55532473]\n",
      " [0.56844622]\n",
      " [0.58264571]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03640107437968254, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52146208]\n",
      " [0.52631682]\n",
      " [0.53383613]\n",
      " [0.54363042]\n",
      " [0.55532473]\n",
      " [0.56844622]\n",
      " [0.58264571]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5591223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01803789660334587, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52631682]\n",
      " [0.53383613]\n",
      " [0.54363042]\n",
      " [0.55532473]\n",
      " [0.56844622]\n",
      " [0.58264571]\n",
      " [0.71445176]\n",
      " [0.55912232]] | y: 0.722588144130182 | Predicción actual: [[0.56869274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016119077801704407, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53383613]\n",
      " [0.54363042]\n",
      " [0.55532473]\n",
      " [0.56844622]\n",
      " [0.58264571]\n",
      " [0.71445176]\n",
      " [0.55912232]\n",
      " [0.56869274]] | y: 0.6993413405656723 | Predicción actual: [[0.5801966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006208936218172312, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54363042]\n",
      " [0.55532473]\n",
      " [0.56844622]\n",
      " [0.58264571]\n",
      " [0.71445176]\n",
      " [0.55912232]\n",
      " [0.56869274]\n",
      " [0.58019662]] | y: 0.7373111197210385 | Predicción actual: [[0.592638]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03355776518583298, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55532473]\n",
      " [0.56844622]\n",
      " [0.58264571]\n",
      " [0.71445176]\n",
      " [0.55912232]\n",
      " [0.56869274]\n",
      " [0.58019662]\n",
      " [0.59263802]] | y: 0.7214258039519565 | Predicción actual: [[0.60503566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006144599989056587, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56844622]\n",
      " [0.58264571]\n",
      " [0.71445176]\n",
      " [0.55912232]\n",
      " [0.56869274]\n",
      " [0.58019662]\n",
      " [0.59263802]\n",
      " [0.60503566]] | y: 0.7187136768694304 | Predicción actual: [[0.6162396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0362880565226078, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58264571]\n",
      " [0.71445176]\n",
      " [0.55912232]\n",
      " [0.56869274]\n",
      " [0.58019662]\n",
      " [0.59263802]\n",
      " [0.60503566]\n",
      " [0.61623961]] | y: 0.6741573033707864 | Predicción actual: [[0.6253965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010377934202551842, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55912232]\n",
      " [0.56869274]\n",
      " [0.58019662]\n",
      " [0.59263802]\n",
      " [0.60503566]\n",
      " [0.61623961]\n",
      " [0.62539649]] | y: 0.698566447113522 | Predicción actual: [[0.6316541]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009507893584668636, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55912232]\n",
      " [0.56869274]\n",
      " [0.58019662]\n",
      " [0.59263802]\n",
      " [0.60503566]\n",
      " [0.61623961]\n",
      " [0.62539649]\n",
      " [0.63165408]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019654554780572653, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56869274]\n",
      " [0.58019662]\n",
      " [0.59263802]\n",
      " [0.60503566]\n",
      " [0.61623961]\n",
      " [0.62539649]\n",
      " [0.63165408]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6137166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005165558308362961, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58019662]\n",
      " [0.59263802]\n",
      " [0.60503566]\n",
      " [0.61623961]\n",
      " [0.62539649]\n",
      " [0.63165408]\n",
      " [0.72103836]\n",
      " [0.6137166 ]] | y: 0.7562960092987214 | Predicción actual: [[0.6253456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009352598339319229, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59263802]\n",
      " [0.60503566]\n",
      " [0.61623961]\n",
      " [0.62539649]\n",
      " [0.63165408]\n",
      " [0.72103836]\n",
      " [0.6137166 ]\n",
      " [0.62534559]] | y: 0.8275862068965516 | Predicción actual: [[0.6369857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01828339882194996, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60503566]\n",
      " [0.61623961]\n",
      " [0.62539649]\n",
      " [0.63165408]\n",
      " [0.72103836]\n",
      " [0.6137166 ]\n",
      " [0.62534559]\n",
      " [0.63698572]] | y: 0.8388221619527314 | Predicción actual: [[0.64792645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0457642637193203, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61623961]\n",
      " [0.62539649]\n",
      " [0.63165408]\n",
      " [0.72103836]\n",
      " [0.6137166 ]\n",
      " [0.62534559]\n",
      " [0.63698572]\n",
      " [0.64792645]] | y: 0.7942657884540876 | Predicción actual: [[0.657671]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051852066069841385, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62539649]\n",
      " [0.63165408]\n",
      " [0.72103836]\n",
      " [0.6137166 ]\n",
      " [0.62534559]\n",
      " [0.63698572]\n",
      " [0.64792645]\n",
      " [0.65767097]] | y: 0.7838047268500579 | Predicción actual: [[0.66598856]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003839674638584256, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63165408]\n",
      " [0.72103836]\n",
      " [0.6137166 ]\n",
      " [0.62534559]\n",
      " [0.63698572]\n",
      " [0.64792645]\n",
      " [0.65767097]\n",
      " [0.66598856]] | y: 0.7679194110809764 | Predicción actual: [[0.67288625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015403568744659424, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.6137166 ]\n",
      " [0.62534559]\n",
      " [0.63698572]\n",
      " [0.64792645]\n",
      " [0.65767097]\n",
      " [0.66598856]\n",
      " [0.67288625]] | y: 0.7845796203022084 | Predicción actual: [[0.6790059]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034189652651548386, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6137166 ]\n",
      " [0.62534559]\n",
      " [0.63698572]\n",
      " [0.64792645]\n",
      " [0.65767097]\n",
      " [0.66598856]\n",
      " [0.67288625]\n",
      " [0.67900592]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034658197313547134, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62534559]\n",
      " [0.63698572]\n",
      " [0.64792645]\n",
      " [0.65767097]\n",
      " [0.66598856]\n",
      " [0.67288625]\n",
      " [0.67900592]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.67283934]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054326772689819336, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63698572]\n",
      " [0.64792645]\n",
      " [0.65767097]\n",
      " [0.66598856]\n",
      " [0.67288625]\n",
      " [0.67900592]\n",
      " [0.87872917]\n",
      " [0.67283934]] | y: 0.8488957768306855 | Predicción actual: [[0.685961]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036036744713783264, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64792645]\n",
      " [0.65767097]\n",
      " [0.66598856]\n",
      " [0.67288625]\n",
      " [0.67900592]\n",
      " [0.87872917]\n",
      " [0.67283934]\n",
      " [0.68596101]] | y: 0.8182874854707476 | Predicción actual: [[0.70000833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005880572833120823, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65767097]\n",
      " [0.66598856]\n",
      " [0.67288625]\n",
      " [0.67900592]\n",
      " [0.87872917]\n",
      " [0.67283934]\n",
      " [0.68596101]\n",
      " [0.70000833]] | y: 0.8268113134444013 | Predicción actual: [[0.7145814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013926666229963303, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66598856]\n",
      " [0.67288625]\n",
      " [0.67900592]\n",
      " [0.87872917]\n",
      " [0.67283934]\n",
      " [0.68596101]\n",
      " [0.70000833]\n",
      " [0.71458137]] | y: 0.7853545137543589 | Predicción actual: [[0.72950596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003551725996658206, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67288625]\n",
      " [0.67900592]\n",
      " [0.87872917]\n",
      " [0.67283934]\n",
      " [0.68596101]\n",
      " [0.70000833]\n",
      " [0.71458137]\n",
      " [0.72950596]] | y: 0.7892289810151103 | Predicción actual: [[0.74436843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008630206808447838, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67900592]\n",
      " [0.87872917]\n",
      " [0.67283934]\n",
      " [0.68596101]\n",
      " [0.70000833]\n",
      " [0.71458137]\n",
      " [0.72950596]\n",
      " [0.74436843]] | y: 0.8341728012398295 | Predicción actual: [[0.75937593]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032712756656110287, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.67283934]\n",
      " [0.68596101]\n",
      " [0.70000833]\n",
      " [0.71458137]\n",
      " [0.72950596]\n",
      " [0.74436843]\n",
      " [0.75937593]] | y: 0.8124757845796202 | Predicción actual: [[0.7744086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003953161940444261, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67283934]\n",
      " [0.68596101]\n",
      " [0.70000833]\n",
      " [0.71458137]\n",
      " [0.72950596]\n",
      " [0.74436843]\n",
      " [0.75937593]\n",
      " [0.77440858]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018079323694109917, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68596101]\n",
      " [0.70000833]\n",
      " [0.71458137]\n",
      " [0.72950596]\n",
      " [0.74436843]\n",
      " [0.75937593]\n",
      " [0.77440858]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7463956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015430523490067571, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70000833]\n",
      " [0.71458137]\n",
      " [0.72950596]\n",
      " [0.74436843]\n",
      " [0.75937593]\n",
      " [0.77440858]\n",
      " [0.80123983]\n",
      " [0.74639559]] | y: 0.793490895001937 | Predicción actual: [[0.7610085]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00026278599398210645, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71458137]\n",
      " [0.72950596]\n",
      " [0.74436843]\n",
      " [0.75937593]\n",
      " [0.77440858]\n",
      " [0.80123983]\n",
      " [0.74639559]\n",
      " [0.7610085 ]] | y: 0.760170476559473 | Predicción actual: [[0.77499396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017047885921783745, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72950596]\n",
      " [0.74436843]\n",
      " [0.75937593]\n",
      " [0.77440858]\n",
      " [0.80123983]\n",
      " [0.74639559]\n",
      " [0.7610085 ]\n",
      " [0.77499396]] | y: 0.7353738860906625 | Predicción actual: [[0.78763163]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00024515308905392885, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74436843]\n",
      " [0.75937593]\n",
      " [0.77440858]\n",
      " [0.80123983]\n",
      " [0.74639559]\n",
      " [0.7610085 ]\n",
      " [0.77499396]\n",
      " [0.78763163]] | y: 0.7101898488957767 | Predicción actual: [[0.79822385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.04893100191839e-05, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75937593]\n",
      " [0.77440858]\n",
      " [0.80123983]\n",
      " [0.74639559]\n",
      " [0.7610085 ]\n",
      " [0.77499396]\n",
      " [0.78763163]\n",
      " [0.79822385]] | y: 0.7121270825261525 | Predicción actual: [[0.8062987]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.4547367754857987e-05, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77440858]\n",
      " [0.80123983]\n",
      " [0.74639559]\n",
      " [0.7610085 ]\n",
      " [0.77499396]\n",
      " [0.78763163]\n",
      " [0.79822385]\n",
      " [0.80629867]] | y: 0.7396358000774894 | Predicción actual: [[0.8113853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05024910345673561, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.74639559]\n",
      " [0.7610085 ]\n",
      " [0.77499396]\n",
      " [0.78763163]\n",
      " [0.79822385]\n",
      " [0.80629867]\n",
      " [0.81138527]] | y: 0.7361487795428128 | Predicción actual: [[0.8126907]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.722490641346667e-06, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74639559]\n",
      " [0.7610085 ]\n",
      " [0.77499396]\n",
      " [0.78763163]\n",
      " [0.79822385]\n",
      " [0.80629867]\n",
      " [0.81138527]\n",
      " [0.81269068]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013939048163592815, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7610085 ]\n",
      " [0.77499396]\n",
      " [0.78763163]\n",
      " [0.79822385]\n",
      " [0.80629867]\n",
      " [0.81138527]\n",
      " [0.81269068]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.81749463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036289975978434086, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77499396]\n",
      " [0.78763163]\n",
      " [0.79822385]\n",
      " [0.80629867]\n",
      " [0.81138527]\n",
      " [0.81269068]\n",
      " [0.66757071]\n",
      " [0.81749463]] | y: 0.696629213483146 | Predicción actual: [[0.82496977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034204624593257904, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78763163]\n",
      " [0.79822385]\n",
      " [0.80629867]\n",
      " [0.81138527]\n",
      " [0.81269068]\n",
      " [0.66757071]\n",
      " [0.81749463]\n",
      " [0.82496977]] | y: 0.6559473072452537 | Predicción actual: [[0.82871515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007047639694064856, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79822385]\n",
      " [0.80629867]\n",
      " [0.81138527]\n",
      " [0.81269068]\n",
      " [0.66757071]\n",
      " [0.81749463]\n",
      " [0.82496977]\n",
      " [0.82871515]] | y: 0.6788066640836885 | Predicción actual: [[0.82904243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07378553599119186, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80629867]\n",
      " [0.81138527]\n",
      " [0.81269068]\n",
      " [0.66757071]\n",
      " [0.81749463]\n",
      " [0.82496977]\n",
      " [0.82871515]\n",
      " [0.82904243]] | y: 0.6760945370011622 | Predicción actual: [[0.82605976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020033197477459908, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81138527]\n",
      " [0.81269068]\n",
      " [0.66757071]\n",
      " [0.81749463]\n",
      " [0.82496977]\n",
      " [0.82871515]\n",
      " [0.82904243]\n",
      " [0.82605976]] | y: 0.7295621851995349 | Predicción actual: [[0.82103986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010239795781672001, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81269068]\n",
      " [0.66757071]\n",
      " [0.81749463]\n",
      " [0.82496977]\n",
      " [0.82871515]\n",
      " [0.82904243]\n",
      " [0.82605976]\n",
      " [0.82103986]] | y: 0.7012785741960481 | Predicción actual: [[0.81524557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013439659029245377, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.81749463]\n",
      " [0.82496977]\n",
      " [0.82871515]\n",
      " [0.82904243]\n",
      " [0.82605976]\n",
      " [0.82103986]\n",
      " [0.81524557]] | y: 0.767531964354901 | Predicción actual: [[0.8101149]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038457874208688736, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81749463]\n",
      " [0.82496977]\n",
      " [0.82871515]\n",
      " [0.82904243]\n",
      " [0.82605976]\n",
      " [0.82103986]\n",
      " [0.81524557]\n",
      " [0.81011492]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04506460949778557, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82496977]\n",
      " [0.82871515]\n",
      " [0.82904243]\n",
      " [0.82605976]\n",
      " [0.82103986]\n",
      " [0.81524557]\n",
      " [0.81011492]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.84903723]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02496861293911934, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82871515]\n",
      " [0.82904243]\n",
      " [0.82605976]\n",
      " [0.82103986]\n",
      " [0.81524557]\n",
      " [0.81011492]\n",
      " [0.75513367]\n",
      " [0.84903723]] | y: 0.7520340953118947 | Predicción actual: [[0.8453854]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04143761843442917, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82904243]\n",
      " [0.82605976]\n",
      " [0.82103986]\n",
      " [0.81524557]\n",
      " [0.81011492]\n",
      " [0.75513367]\n",
      " [0.84903723]\n",
      " [0.84538537]] | y: 0.7098024021697016 | Predicción actual: [[0.8397702]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043769389390945435, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82605976]\n",
      " [0.82103986]\n",
      " [0.81524557]\n",
      " [0.81011492]\n",
      " [0.75513367]\n",
      " [0.84903723]\n",
      " [0.84538537]\n",
      " [0.8397702 ]] | y: 0.6904300658659435 | Predicción actual: [[0.8334433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033509496599435806, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82103986]\n",
      " [0.81524557]\n",
      " [0.81011492]\n",
      " [0.75513367]\n",
      " [0.84903723]\n",
      " [0.84538537]\n",
      " [0.8397702 ]\n",
      " [0.83344328]] | y: 0.7543587756683454 | Predicción actual: [[0.82785785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004880724940448999, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81524557]\n",
      " [0.81011492]\n",
      " [0.75513367]\n",
      " [0.84903723]\n",
      " [0.84538537]\n",
      " [0.8397702 ]\n",
      " [0.83344328]\n",
      " [0.82785785]] | y: 0.7222006974041069 | Predicción actual: [[0.8242776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09272179752588272, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81011492]\n",
      " [0.75513367]\n",
      " [0.84903723]\n",
      " [0.84538537]\n",
      " [0.8397702 ]\n",
      " [0.83344328]\n",
      " [0.82785785]\n",
      " [0.82427758]] | y: 0.8485083301046106 | Predicción actual: [[0.82270163]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028046960942447186, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.84903723]\n",
      " [0.84538537]\n",
      " [0.8397702 ]\n",
      " [0.83344328]\n",
      " [0.82785785]\n",
      " [0.82427758]\n",
      " [0.82270163]] | y: 0.9054629988376597 | Predicción actual: [[0.8239912]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012944266200065613, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84903723]\n",
      " [0.84538537]\n",
      " [0.8397702 ]\n",
      " [0.83344328]\n",
      " [0.82785785]\n",
      " [0.82427758]\n",
      " [0.82270163]\n",
      " [0.82399118]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007391114719212055, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84538537]\n",
      " [0.8397702 ]\n",
      " [0.83344328]\n",
      " [0.82785785]\n",
      " [0.82427758]\n",
      " [0.82270163]\n",
      " [0.82399118]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8372816]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01615242287516594, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8397702 ]\n",
      " [0.83344328]\n",
      " [0.82785785]\n",
      " [0.82427758]\n",
      " [0.82270163]\n",
      " [0.82399118]\n",
      " [0.8822162 ]\n",
      " [0.83728158]] | y: 0.889577683068578 | Predicción actual: [[0.83261186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.618240927811712e-05, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83344328]\n",
      " [0.82785785]\n",
      " [0.82427758]\n",
      " [0.82270163]\n",
      " [0.82399118]\n",
      " [0.8822162 ]\n",
      " [0.83728158]\n",
      " [0.83261186]] | y: 0.8748547074777218 | Predicción actual: [[0.8296057]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012136586010456085, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82785785]\n",
      " [0.82427758]\n",
      " [0.82270163]\n",
      " [0.82399118]\n",
      " [0.8822162 ]\n",
      " [0.83728158]\n",
      " [0.83261186]\n",
      " [0.8296057 ]] | y: 0.9132119333591631 | Predicción actual: [[0.828784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00118233822286129, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82427758]\n",
      " [0.82270163]\n",
      " [0.82399118]\n",
      " [0.8822162 ]\n",
      " [0.83728158]\n",
      " [0.83261186]\n",
      " [0.8296057 ]\n",
      " [0.82878399]] | y: 1.0 | Predicción actual: [[0.8300984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024032272398471832, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82270163]\n",
      " [0.82399118]\n",
      " [0.8822162 ]\n",
      " [0.83728158]\n",
      " [0.83261186]\n",
      " [0.8296057 ]\n",
      " [0.82878399]\n",
      " [0.83009839]] | y: 0.9705540488182873 | Predicción actual: [[0.8332457]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.280237721512094e-05, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82399118]\n",
      " [0.8822162 ]\n",
      " [0.83728158]\n",
      " [0.83261186]\n",
      " [0.8296057 ]\n",
      " [0.82878399]\n",
      " [0.83009839]\n",
      " [0.83324569]] | y: 0.8888027896164277 | Predicción actual: [[0.83726275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0065734474919736385, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.83728158]\n",
      " [0.83261186]\n",
      " [0.8296057 ]\n",
      " [0.82878399]\n",
      " [0.83009839]\n",
      " [0.83324569]\n",
      " [0.83726275]] | y: 0.877954281286323 | Predicción actual: [[0.84130204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038452832959592342, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83728158]\n",
      " [0.83261186]\n",
      " [0.8296057 ]\n",
      " [0.82878399]\n",
      " [0.83009839]\n",
      " [0.83324569]\n",
      " [0.83726275]\n",
      " [0.84130204]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004888556897640228, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83261186]\n",
      " [0.8296057 ]\n",
      " [0.82878399]\n",
      " [0.83009839]\n",
      " [0.83324569]\n",
      " [0.83726275]\n",
      " [0.84130204]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8269694]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0463181734085083, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8296057 ]\n",
      " [0.82878399]\n",
      " [0.83009839]\n",
      " [0.83324569]\n",
      " [0.83726275]\n",
      " [0.84130204]\n",
      " [0.84889578]\n",
      " [0.82696939]] | y: 0.8550949244478885 | Predicción actual: [[0.82728297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.3570995583431795e-05, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82878399]\n",
      " [0.83009839]\n",
      " [0.83324569]\n",
      " [0.83726275]\n",
      " [0.84130204]\n",
      " [0.84889578]\n",
      " [0.82696939]\n",
      " [0.82728297]] | y: 0.8752421542037967 | Predicción actual: [[0.82869625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017041037790477276, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83009839]\n",
      " [0.83324569]\n",
      " [0.83726275]\n",
      " [0.84130204]\n",
      " [0.84889578]\n",
      " [0.82696939]\n",
      " [0.82728297]\n",
      " [0.82869625]] | y: 0.857032158078264 | Predicción actual: [[0.8306026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03926090896129608, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83324569]\n",
      " [0.83726275]\n",
      " [0.84130204]\n",
      " [0.84889578]\n",
      " [0.82696939]\n",
      " [0.82728297]\n",
      " [0.82869625]\n",
      " [0.83060259]] | y: 0.8500581170089112 | Predicción actual: [[0.832555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02026948519051075, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83726275]\n",
      " [0.84130204]\n",
      " [0.84889578]\n",
      " [0.82696939]\n",
      " [0.82728297]\n",
      " [0.82869625]\n",
      " [0.83060259]\n",
      " [0.832555  ]] | y: 0.8426966292134832 | Predicción actual: [[0.8332205]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005883699283003807, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84130204]\n",
      " [0.84889578]\n",
      " [0.82696939]\n",
      " [0.82728297]\n",
      " [0.82869625]\n",
      " [0.83060259]\n",
      " [0.832555  ]\n",
      " [0.83322048]] | y: 0.8229368461836497 | Predicción actual: [[0.8323546]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03521136939525604, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.82696939]\n",
      " [0.82728297]\n",
      " [0.82869625]\n",
      " [0.83060259]\n",
      " [0.832555  ]\n",
      " [0.83322048]\n",
      " [0.83235461]] | y: 0.7745060054242543 | Predicción actual: [[0.8295458]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013935579918324947, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82696939]\n",
      " [0.82728297]\n",
      " [0.82869625]\n",
      " [0.83060259]\n",
      " [0.832555  ]\n",
      " [0.83322048]\n",
      " [0.83235461]\n",
      " [0.8295458 ]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011188034899532795, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82728297]\n",
      " [0.82869625]\n",
      " [0.83060259]\n",
      " [0.832555  ]\n",
      " [0.83322048]\n",
      " [0.83235461]\n",
      " [0.8295458 ]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8239576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015725116827525198, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82869625]\n",
      " [0.83060259]\n",
      " [0.832555  ]\n",
      " [0.83322048]\n",
      " [0.83235461]\n",
      " [0.8295458 ]\n",
      " [0.78419217]\n",
      " [0.82395762]] | y: 0.854320030995738 | Predicción actual: [[0.8235773]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08537939190864563, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83060259]\n",
      " [0.832555  ]\n",
      " [0.83322048]\n",
      " [0.83235461]\n",
      " [0.8295458 ]\n",
      " [0.78419217]\n",
      " [0.82395762]\n",
      " [0.82357728]] | y: 0.8368849283223556 | Predicción actual: [[0.8228065]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003609755774959922, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.832555  ]\n",
      " [0.83322048]\n",
      " [0.83235461]\n",
      " [0.8295458 ]\n",
      " [0.78419217]\n",
      " [0.82395762]\n",
      " [0.82357728]\n",
      " [0.82280648]] | y: 0.8299108872530028 | Predicción actual: [[0.8208367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02789728157222271, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83322048]\n",
      " [0.83235461]\n",
      " [0.8295458 ]\n",
      " [0.78419217]\n",
      " [0.82395762]\n",
      " [0.82357728]\n",
      " [0.82280648]\n",
      " [0.82083672]] | y: 0.887253002712127 | Predicción actual: [[0.8173451]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020915099594276398, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83235461]\n",
      " [0.8295458 ]\n",
      " [0.78419217]\n",
      " [0.82395762]\n",
      " [0.82357728]\n",
      " [0.82280648]\n",
      " [0.82083672]\n",
      " [0.81734508]] | y: 0.8597442851607902 | Predicción actual: [[0.8131338]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009062155149877071, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8295458 ]\n",
      " [0.78419217]\n",
      " [0.82395762]\n",
      " [0.82357728]\n",
      " [0.82280648]\n",
      " [0.82083672]\n",
      " [0.81734508]\n",
      " [0.81313378]] | y: 0.8395970554048819 | Predicción actual: [[0.8084513]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002652944822330028, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.82395762]\n",
      " [0.82357728]\n",
      " [0.82280648]\n",
      " [0.82083672]\n",
      " [0.81734508]\n",
      " [0.81313378]\n",
      " [0.80845129]] | y: 0.7838047268500579 | Predicción actual: [[0.80419415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017580966232344508, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82395762]\n",
      " [0.82357728]\n",
      " [0.82280648]\n",
      " [0.82083672]\n",
      " [0.81734508]\n",
      " [0.81313378]\n",
      " [0.80845129]\n",
      " [0.80419415]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.1551273928489536e-05, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82357728]\n",
      " [0.82280648]\n",
      " [0.82083672]\n",
      " [0.81734508]\n",
      " [0.81313378]\n",
      " [0.80845129]\n",
      " [0.80419415]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8107463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02044197916984558, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82280648]\n",
      " [0.82083672]\n",
      " [0.81734508]\n",
      " [0.81313378]\n",
      " [0.80845129]\n",
      " [0.80419415]\n",
      " [0.81828749]\n",
      " [0.81074631]] | y: 0.7605579232855482 | Predicción actual: [[0.80854815]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009908495470881462, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82083672]\n",
      " [0.81734508]\n",
      " [0.81313378]\n",
      " [0.80845129]\n",
      " [0.80419415]\n",
      " [0.81828749]\n",
      " [0.81074631]\n",
      " [0.80854815]] | y: 0.7915536613715615 | Predicción actual: [[0.806169]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003896205686032772, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81734508]\n",
      " [0.81313378]\n",
      " [0.80845129]\n",
      " [0.80419415]\n",
      " [0.81828749]\n",
      " [0.81074631]\n",
      " [0.80854815]\n",
      " [0.80616897]] | y: 0.7686943045331267 | Predicción actual: [[0.8039163]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03256163001060486, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81313378]\n",
      " [0.80845129]\n",
      " [0.80419415]\n",
      " [0.81828749]\n",
      " [0.81074631]\n",
      " [0.80854815]\n",
      " [0.80616897]\n",
      " [0.80391628]] | y: 0.7686943045331267 | Predicción actual: [[0.80241203]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012171798385679722, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80845129]\n",
      " [0.80419415]\n",
      " [0.81828749]\n",
      " [0.81074631]\n",
      " [0.80854815]\n",
      " [0.80616897]\n",
      " [0.80391628]\n",
      " [0.80241203]] | y: 0.7989151491669895 | Predicción actual: [[0.8014769]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028659731149673462, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80419415]\n",
      " [0.81828749]\n",
      " [0.81074631]\n",
      " [0.80854815]\n",
      " [0.80616897]\n",
      " [0.80391628]\n",
      " [0.80241203]\n",
      " [0.8014769 ]] | y: 0.7900038744672608 | Predicción actual: [[0.8018147]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028202736284583807, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.81074631]\n",
      " [0.80854815]\n",
      " [0.80616897]\n",
      " [0.80391628]\n",
      " [0.80241203]\n",
      " [0.8014769 ]\n",
      " [0.80181468]] | y: 0.760170476559473 | Predicción actual: [[0.80321276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017705323174595833, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81074631]\n",
      " [0.80854815]\n",
      " [0.80616897]\n",
      " [0.80391628]\n",
      " [0.80241203]\n",
      " [0.8014769 ]\n",
      " [0.80181468]\n",
      " [0.80321276]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014278735965490341, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80854815]\n",
      " [0.80616897]\n",
      " [0.80391628]\n",
      " [0.80241203]\n",
      " [0.8014769 ]\n",
      " [0.80181468]\n",
      " [0.80321276]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.7975054]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049535125494003296, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80616897]\n",
      " [0.80391628]\n",
      " [0.80241203]\n",
      " [0.8014769 ]\n",
      " [0.80181468]\n",
      " [0.80321276]\n",
      " [0.68539326]\n",
      " [0.79750538]] | y: 0.6648585819449826 | Predicción actual: [[0.7937571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025563400238752365, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80391628]\n",
      " [0.80241203]\n",
      " [0.8014769 ]\n",
      " [0.80181468]\n",
      " [0.80321276]\n",
      " [0.68539326]\n",
      " [0.79750538]\n",
      " [0.79375708]] | y: 0.7078651685393258 | Predicción actual: [[0.78898966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001171762851299718, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80241203]\n",
      " [0.8014769 ]\n",
      " [0.80181468]\n",
      " [0.80321276]\n",
      " [0.68539326]\n",
      " [0.79750538]\n",
      " [0.79375708]\n",
      " [0.78898966]] | y: 0.6648585819449826 | Predicción actual: [[0.78356034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005414795596152544, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8014769 ]\n",
      " [0.80181468]\n",
      " [0.80321276]\n",
      " [0.68539326]\n",
      " [0.79750538]\n",
      " [0.79375708]\n",
      " [0.78898966]\n",
      " [0.78356034]] | y: 0.7113521890740022 | Predicción actual: [[0.7774237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006577169056981802, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80181468]\n",
      " [0.80321276]\n",
      " [0.68539326]\n",
      " [0.79750538]\n",
      " [0.79375708]\n",
      " [0.78898966]\n",
      " [0.78356034]\n",
      " [0.77742368]] | y: 0.6772568771793879 | Predicción actual: [[0.77077144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010432704584673047, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80321276]\n",
      " [0.68539326]\n",
      " [0.79750538]\n",
      " [0.79375708]\n",
      " [0.78898966]\n",
      " [0.78356034]\n",
      " [0.77742368]\n",
      " [0.77077144]] | y: 0.7621077101898488 | Predicción actual: [[0.7632643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003859086718875915, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.79750538]\n",
      " [0.79375708]\n",
      " [0.78898966]\n",
      " [0.78356034]\n",
      " [0.77742368]\n",
      " [0.77077144]\n",
      " [0.7632643 ]] | y: 0.8070515304145678 | Predicción actual: [[0.75482446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01031313743442297, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79750538]\n",
      " [0.79375708]\n",
      " [0.78898966]\n",
      " [0.78356034]\n",
      " [0.77742368]\n",
      " [0.77077144]\n",
      " [0.7632643 ]\n",
      " [0.75482446]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008212964748963714, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79375708]\n",
      " [0.78898966]\n",
      " [0.78356034]\n",
      " [0.77742368]\n",
      " [0.77077144]\n",
      " [0.7632643 ]\n",
      " [0.75482446]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7748402]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03290373459458351, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78898966]\n",
      " [0.78356034]\n",
      " [0.77742368]\n",
      " [0.77077144]\n",
      " [0.7632643 ]\n",
      " [0.75482446]\n",
      " [0.81518791]\n",
      " [0.77484018]] | y: 0.9597055404881829 | Predicción actual: [[0.7709186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037935808300971985, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78356034]\n",
      " [0.77742368]\n",
      " [0.77077144]\n",
      " [0.7632643 ]\n",
      " [0.75482446]\n",
      " [0.81518791]\n",
      " [0.77484018]\n",
      " [0.77091861]] | y: 0.9643549012010848 | Predicción actual: [[0.7679857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05369533225893974, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77742368]\n",
      " [0.77077144]\n",
      " [0.7632643 ]\n",
      " [0.75482446]\n",
      " [0.81518791]\n",
      " [0.77484018]\n",
      " [0.77091861]\n",
      " [0.7679857 ]] | y: 0.8880278961642774 | Predicción actual: [[0.76644695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02551202103495598, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77077144]\n",
      " [0.7632643 ]\n",
      " [0.75482446]\n",
      " [0.81518791]\n",
      " [0.77484018]\n",
      " [0.77091861]\n",
      " [0.7679857 ]\n",
      " [0.76644695]] | y: 0.8926772568771792 | Predicción actual: [[0.76655245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024436866864562035, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7632643 ]\n",
      " [0.75482446]\n",
      " [0.81518791]\n",
      " [0.77484018]\n",
      " [0.77091861]\n",
      " [0.7679857 ]\n",
      " [0.76644695]\n",
      " [0.76655245]] | y: 0.8752421542037967 | Predicción actual: [[0.76858205]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05069810152053833, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75482446]\n",
      " [0.81518791]\n",
      " [0.77484018]\n",
      " [0.77091861]\n",
      " [0.7679857 ]\n",
      " [0.76644695]\n",
      " [0.76655245]\n",
      " [0.76858205]] | y: 0.8508330104610615 | Predicción actual: [[0.7729601]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02134936861693859, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.77484018]\n",
      " [0.77091861]\n",
      " [0.7679857 ]\n",
      " [0.76644695]\n",
      " [0.76655245]\n",
      " [0.76858205]\n",
      " [0.77296013]] | y: 0.8488957768306855 | Predicción actual: [[0.7799753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006065170164220035, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77484018]\n",
      " [0.77091861]\n",
      " [0.7679857 ]\n",
      " [0.76644695]\n",
      " [0.76655245]\n",
      " [0.76858205]\n",
      " [0.77296013]\n",
      " [0.7799753 ]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017413467168807983, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77091861]\n",
      " [0.7679857 ]\n",
      " [0.76644695]\n",
      " [0.76655245]\n",
      " [0.76858205]\n",
      " [0.77296013]\n",
      " [0.7799753 ]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7711098]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.053104087710380554, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7679857 ]\n",
      " [0.76644695]\n",
      " [0.76655245]\n",
      " [0.76858205]\n",
      " [0.77296013]\n",
      " [0.7799753 ]\n",
      " [0.96241767]\n",
      " [0.77110982]] | y: 0.9407206509104997 | Predicción actual: [[0.7753565]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0519426055252552, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76644695]\n",
      " [0.76655245]\n",
      " [0.76858205]\n",
      " [0.77296013]\n",
      " [0.7799753 ]\n",
      " [0.96241767]\n",
      " [0.77110982]\n",
      " [0.77535647]] | y: 0.9724912824486633 | Predicción actual: [[0.7826576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036410853266716, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76655245]\n",
      " [0.76858205]\n",
      " [0.77296013]\n",
      " [0.7799753 ]\n",
      " [0.96241767]\n",
      " [0.77110982]\n",
      " [0.77535647]\n",
      " [0.78265762]] | y: 0.9969004261913985 | Predicción actual: [[0.79262507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04708874598145485, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76858205]\n",
      " [0.77296013]\n",
      " [0.7799753 ]\n",
      " [0.96241767]\n",
      " [0.77110982]\n",
      " [0.77535647]\n",
      " [0.78265762]\n",
      " [0.79262507]] | y: 0.951181712514529 | Predicción actual: [[0.80462986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001328635262325406, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77296013]\n",
      " [0.7799753 ]\n",
      " [0.96241767]\n",
      " [0.77110982]\n",
      " [0.77535647]\n",
      " [0.78265762]\n",
      " [0.79262507]\n",
      " [0.80462986]] | y: 0.8957768306857805 | Predicción actual: [[0.81738114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015212126076221466, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7799753 ]\n",
      " [0.96241767]\n",
      " [0.77110982]\n",
      " [0.77535647]\n",
      " [0.78265762]\n",
      " [0.79262507]\n",
      " [0.80462986]\n",
      " [0.81738114]] | y: 0.8814413018209997 | Predicción actual: [[0.8300543]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04979454725980759, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.77110982]\n",
      " [0.77535647]\n",
      " [0.78265762]\n",
      " [0.79262507]\n",
      " [0.80462986]\n",
      " [0.81738114]\n",
      " [0.83005428]] | y: 0.9170864006199149 | Predicción actual: [[0.8415862]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000282333669019863, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77110982]\n",
      " [0.77535647]\n",
      " [0.78265762]\n",
      " [0.79262507]\n",
      " [0.80462986]\n",
      " [0.81738114]\n",
      " [0.83005428]\n",
      " [0.84158617]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02610972337424755, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77535647]\n",
      " [0.78265762]\n",
      " [0.79262507]\n",
      " [0.80462986]\n",
      " [0.81738114]\n",
      " [0.83005428]\n",
      " [0.84158617]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.8094252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008021832443773746, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78265762]\n",
      " [0.79262507]\n",
      " [0.80462986]\n",
      " [0.81738114]\n",
      " [0.83005428]\n",
      " [0.84158617]\n",
      " [0.91979853]\n",
      " [0.80942518]] | y: 0.9682293684618366 | Predicción actual: [[0.82174456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.52263076719828e-05, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79262507]\n",
      " [0.80462986]\n",
      " [0.81738114]\n",
      " [0.83005428]\n",
      " [0.84158617]\n",
      " [0.91979853]\n",
      " [0.80942518]\n",
      " [0.82174456]] | y: 0.9577683068578069 | Predicción actual: [[0.83490145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030762804672122, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.22405897]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0444796197116375, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22405897]] | y: 0.10422316931421921 | Predicción actual: [[0.20860125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009412230923771858, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22405897]\n",
      " [0.20860125]] | y: 0.15420379697791559 | Predicción actual: [[0.21313097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002757186768576503, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22405897]\n",
      " [0.20860125]\n",
      " [0.21313097]] | y: 0.1557535838822161 | Predicción actual: [[0.2254262]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0049491021782159805, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22405897]\n",
      " [0.20860125]\n",
      " [0.21313097]\n",
      " [0.2254262 ]] | y: 0.12553273924835334 | Predicción actual: [[0.2393869]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016770143061876297, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.22405897]\n",
      " [0.20860125]\n",
      " [0.21313097]\n",
      " [0.2254262 ]\n",
      " [0.2393869 ]] | y: 0.1456799690042619 | Predicción actual: [[0.25129578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01621897518634796, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.22405897]\n",
      " [0.20860125]\n",
      " [0.21313097]\n",
      " [0.2254262 ]\n",
      " [0.2393869 ]\n",
      " [0.25129578]] | y: 0.1464548624564122 | Predicción actual: [[0.27557427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016581937670707703, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.22405897]\n",
      " [0.20860125]\n",
      " [0.21313097]\n",
      " [0.2254262 ]\n",
      " [0.2393869 ]\n",
      " [0.25129578]\n",
      " [0.27557427]] | y: 0.1960480433940332 | Predicción actual: [[0.30579877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016133297234773636, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22405897]\n",
      " [0.20860125]\n",
      " [0.21313097]\n",
      " [0.2254262 ]\n",
      " [0.2393869 ]\n",
      " [0.25129578]\n",
      " [0.27557427]\n",
      " [0.30579877]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008431016467511654, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20860125]\n",
      " [0.21313097]\n",
      " [0.2254262 ]\n",
      " [0.2393869 ]\n",
      " [0.25129578]\n",
      " [0.27557427]\n",
      " [0.30579877]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.34511945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03009902872145176, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21313097]\n",
      " [0.2254262 ]\n",
      " [0.2393869 ]\n",
      " [0.25129578]\n",
      " [0.27557427]\n",
      " [0.30579877]\n",
      " [0.2305308 ]\n",
      " [0.34511945]] | y: 0.211933359163115 | Predicción actual: [[0.35298672]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015676381066441536, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2254262 ]\n",
      " [0.2393869 ]\n",
      " [0.25129578]\n",
      " [0.27557427]\n",
      " [0.30579877]\n",
      " [0.2305308 ]\n",
      " [0.34511945]\n",
      " [0.35298672]] | y: 0.2072839984502131 | Predicción actual: [[0.36286107]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010614289902150631, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2393869 ]\n",
      " [0.25129578]\n",
      " [0.27557427]\n",
      " [0.30579877]\n",
      " [0.2305308 ]\n",
      " [0.34511945]\n",
      " [0.35298672]\n",
      " [0.36286107]] | y: 0.19294846958543205 | Predicción actual: [[0.3734862]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021207693964242935, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25129578]\n",
      " [0.27557427]\n",
      " [0.30579877]\n",
      " [0.2305308 ]\n",
      " [0.34511945]\n",
      " [0.35298672]\n",
      " [0.36286107]\n",
      " [0.37348619]] | y: 0.19682293684618352 | Predicción actual: [[0.38471752]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03632288798689842, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27557427]\n",
      " [0.30579877]\n",
      " [0.2305308 ]\n",
      " [0.34511945]\n",
      " [0.35298672]\n",
      " [0.36286107]\n",
      " [0.37348619]\n",
      " [0.38471752]] | y: 0.21425803951956607 | Predicción actual: [[0.39718747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03137758746743202, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30579877]\n",
      " [0.2305308 ]\n",
      " [0.34511945]\n",
      " [0.35298672]\n",
      " [0.36286107]\n",
      " [0.37348619]\n",
      " [0.38471752]\n",
      " [0.39718747]] | y: 0.18132506780317698 | Predicción actual: [[0.40805265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06120733544230461, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.34511945]\n",
      " [0.35298672]\n",
      " [0.36286107]\n",
      " [0.37348619]\n",
      " [0.38471752]\n",
      " [0.39718747]\n",
      " [0.40805265]] | y: 0.17512592018597434 | Predicción actual: [[0.41547439]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06488145887851715, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34511945]\n",
      " [0.35298672]\n",
      " [0.36286107]\n",
      " [0.37348619]\n",
      " [0.38471752]\n",
      " [0.39718747]\n",
      " [0.40805265]\n",
      " [0.41547439]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10060760378837585, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35298672]\n",
      " [0.36286107]\n",
      " [0.37348619]\n",
      " [0.38471752]\n",
      " [0.39718747]\n",
      " [0.40805265]\n",
      " [0.41547439]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.450587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11287130415439606, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36286107]\n",
      " [0.37348619]\n",
      " [0.38471752]\n",
      " [0.39718747]\n",
      " [0.40805265]\n",
      " [0.41547439]\n",
      " [0.14800465]\n",
      " [0.450587  ]] | y: 0.19217357613328173 | Predicción actual: [[0.45447263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09172213822603226, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37348619]\n",
      " [0.38471752]\n",
      " [0.39718747]\n",
      " [0.40805265]\n",
      " [0.41547439]\n",
      " [0.14800465]\n",
      " [0.450587  ]\n",
      " [0.45447263]] | y: 0.1859744285160791 | Predicción actual: [[0.45624846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05485319346189499, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38471752]\n",
      " [0.39718747]\n",
      " [0.40805265]\n",
      " [0.41547439]\n",
      " [0.14800465]\n",
      " [0.450587  ]\n",
      " [0.45447263]\n",
      " [0.45624846]] | y: 0.26695079426578844 | Predicción actual: [[0.45607626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048174548894166946, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39718747]\n",
      " [0.40805265]\n",
      " [0.41547439]\n",
      " [0.14800465]\n",
      " [0.450587  ]\n",
      " [0.45447263]\n",
      " [0.45624846]\n",
      " [0.45607626]] | y: 0.2925222781867493 | Predicción actual: [[0.45422816]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006364170461893082, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40805265]\n",
      " [0.41547439]\n",
      " [0.14800465]\n",
      " [0.450587  ]\n",
      " [0.45447263]\n",
      " [0.45624846]\n",
      " [0.45607626]\n",
      " [0.45422816]] | y: 0.3177063153816349 | Predicción actual: [[0.4509476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03265387937426567, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41547439]\n",
      " [0.14800465]\n",
      " [0.450587  ]\n",
      " [0.45447263]\n",
      " [0.45624846]\n",
      " [0.45607626]\n",
      " [0.45422816]\n",
      " [0.45094761]] | y: 0.31266950794265785 | Predicción actual: [[0.44691393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05428971350193024, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.450587  ]\n",
      " [0.45447263]\n",
      " [0.45624846]\n",
      " [0.45607626]\n",
      " [0.45422816]\n",
      " [0.45094761]\n",
      " [0.44691393]] | y: 0.2890352576520729 | Predicción actual: [[0.44321907]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04601099714636803, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.450587  ]\n",
      " [0.45447263]\n",
      " [0.45624846]\n",
      " [0.45607626]\n",
      " [0.45422816]\n",
      " [0.45094761]\n",
      " [0.44691393]\n",
      " [0.44321907]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05548296868801117, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45447263]\n",
      " [0.45624846]\n",
      " [0.45607626]\n",
      " [0.45422816]\n",
      " [0.45094761]\n",
      " [0.44691393]\n",
      " [0.44321907]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.50762576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022191112861037254, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45624846]\n",
      " [0.45607626]\n",
      " [0.45422816]\n",
      " [0.45094761]\n",
      " [0.44691393]\n",
      " [0.44321907]\n",
      " [0.28283611]\n",
      " [0.50762576]] | y: 0.2758620689655173 | Predicción actual: [[0.5038822]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04354066401720047, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45607626]\n",
      " [0.45422816]\n",
      " [0.45094761]\n",
      " [0.44691393]\n",
      " [0.44321907]\n",
      " [0.28283611]\n",
      " [0.50762576]\n",
      " [0.50388223]] | y: 0.2746997287872917 | Predicción actual: [[0.49876672]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048322465270757675, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45422816]\n",
      " [0.45094761]\n",
      " [0.44691393]\n",
      " [0.44321907]\n",
      " [0.28283611]\n",
      " [0.50762576]\n",
      " [0.50388223]\n",
      " [0.49876672]] | y: 0.275474622239442 | Predicción actual: [[0.49334645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02314469963312149, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45094761]\n",
      " [0.44691393]\n",
      " [0.44321907]\n",
      " [0.28283611]\n",
      " [0.50762576]\n",
      " [0.50388223]\n",
      " [0.49876672]\n",
      " [0.49334645]] | y: 0.3347539713289423 | Predicción actual: [[0.48882577]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01084637176245451, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44691393]\n",
      " [0.44321907]\n",
      " [0.28283611]\n",
      " [0.50762576]\n",
      " [0.50388223]\n",
      " [0.49876672]\n",
      " [0.49334645]\n",
      " [0.48882577]] | y: 0.35567609453700116 | Predicción actual: [[0.4862794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028191709890961647, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44321907]\n",
      " [0.28283611]\n",
      " [0.50762576]\n",
      " [0.50388223]\n",
      " [0.49876672]\n",
      " [0.49334645]\n",
      " [0.48882577]\n",
      " [0.4862794 ]] | y: 0.3366912049593181 | Predicción actual: [[0.48642835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003540183650329709, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.50762576]\n",
      " [0.50388223]\n",
      " [0.49876672]\n",
      " [0.49334645]\n",
      " [0.48882577]\n",
      " [0.4862794 ]\n",
      " [0.48642835]] | y: 0.3335916311507167 | Predicción actual: [[0.48970446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04315199702978134, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50762576]\n",
      " [0.50388223]\n",
      " [0.49876672]\n",
      " [0.49334645]\n",
      " [0.48882577]\n",
      " [0.4862794 ]\n",
      " [0.48642835]\n",
      " [0.48970446]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037444330751895905, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50388223]\n",
      " [0.49876672]\n",
      " [0.49334645]\n",
      " [0.48882577]\n",
      " [0.4862794 ]\n",
      " [0.48642835]\n",
      " [0.48970446]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.53121156]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.597244019852951e-05, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49876672]\n",
      " [0.49334645]\n",
      " [0.48882577]\n",
      " [0.4862794 ]\n",
      " [0.48642835]\n",
      " [0.48970446]\n",
      " [0.3847346 ]\n",
      " [0.53121156]] | y: 0.5962805114296785 | Predicción actual: [[0.525915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007338132709264755, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49334645]\n",
      " [0.48882577]\n",
      " [0.4862794 ]\n",
      " [0.48642835]\n",
      " [0.48970446]\n",
      " [0.3847346 ]\n",
      " [0.53121156]\n",
      " [0.52591503]] | y: 0.574583494769469 | Predicción actual: [[0.5212338]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004711735062301159, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48882577]\n",
      " [0.4862794 ]\n",
      " [0.48642835]\n",
      " [0.48970446]\n",
      " [0.3847346 ]\n",
      " [0.53121156]\n",
      " [0.52591503]\n",
      " [0.5212338 ]] | y: 0.6063541263076326 | Predicción actual: [[0.5178181]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006206493126228452, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4862794 ]\n",
      " [0.48642835]\n",
      " [0.48970446]\n",
      " [0.3847346 ]\n",
      " [0.53121156]\n",
      " [0.52591503]\n",
      " [0.5212338 ]\n",
      " [0.51781809]] | y: 0.5846571096474236 | Predicción actual: [[0.51601857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002844680566340685, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48642835]\n",
      " [0.48970446]\n",
      " [0.3847346 ]\n",
      " [0.53121156]\n",
      " [0.52591503]\n",
      " [0.5212338 ]\n",
      " [0.51781809]\n",
      " [0.51601857]] | y: 0.5687717938783416 | Predicción actual: [[0.51587415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006929617375135422, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48970446]\n",
      " [0.3847346 ]\n",
      " [0.53121156]\n",
      " [0.52591503]\n",
      " [0.5212338 ]\n",
      " [0.51781809]\n",
      " [0.51601857]\n",
      " [0.51587415]] | y: 0.6427741185586981 | Predicción actual: [[0.5170801]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02241615392267704, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.53121156]\n",
      " [0.52591503]\n",
      " [0.5212338 ]\n",
      " [0.51781809]\n",
      " [0.51601857]\n",
      " [0.51587415]\n",
      " [0.51708013]] | y: 0.6617590081363811 | Predicción actual: [[0.51906717]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013798702508211136, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53121156]\n",
      " [0.52591503]\n",
      " [0.5212338 ]\n",
      " [0.51781809]\n",
      " [0.51601857]\n",
      " [0.51587415]\n",
      " [0.51708013]\n",
      " [0.51906717]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014105535112321377, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52591503]\n",
      " [0.5212338 ]\n",
      " [0.51781809]\n",
      " [0.51601857]\n",
      " [0.51587415]\n",
      " [0.51708013]\n",
      " [0.51906717]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5477659]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04377834126353264, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5212338 ]\n",
      " [0.51781809]\n",
      " [0.51601857]\n",
      " [0.51587415]\n",
      " [0.51708013]\n",
      " [0.51906717]\n",
      " [0.67299496]\n",
      " [0.54776591]] | y: 0.703990701278574 | Predicción actual: [[0.548407]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019892357289791107, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51781809]\n",
      " [0.51601857]\n",
      " [0.51587415]\n",
      " [0.51708013]\n",
      " [0.51906717]\n",
      " [0.67299496]\n",
      " [0.54776591]\n",
      " [0.54840702]] | y: 0.7272375048430839 | Predicción actual: [[0.55188817]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052051909267902374, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51601857]\n",
      " [0.51587415]\n",
      " [0.51708013]\n",
      " [0.51906717]\n",
      " [0.67299496]\n",
      " [0.54776591]\n",
      " [0.54840702]\n",
      " [0.55188817]] | y: 0.722588144130182 | Predicción actual: [[0.5582551]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03505431115627289, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51587415]\n",
      " [0.51708013]\n",
      " [0.51906717]\n",
      " [0.67299496]\n",
      " [0.54776591]\n",
      " [0.54840702]\n",
      " [0.55188817]\n",
      " [0.55825508]] | y: 0.771793878341728 | Predicción actual: [[0.567193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060273658484220505, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51708013]\n",
      " [0.51906717]\n",
      " [0.67299496]\n",
      " [0.54776591]\n",
      " [0.54840702]\n",
      " [0.55188817]\n",
      " [0.55825508]\n",
      " [0.56719297]] | y: 0.7245253777605578 | Predicción actual: [[0.5783003]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02809462696313858, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51906717]\n",
      " [0.67299496]\n",
      " [0.54776591]\n",
      " [0.54840702]\n",
      " [0.55188817]\n",
      " [0.55825508]\n",
      " [0.56719297]\n",
      " [0.5783003 ]] | y: 0.6710577295621851 | Predicción actual: [[0.5910615]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01925002969801426, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.54776591]\n",
      " [0.54840702]\n",
      " [0.55188817]\n",
      " [0.55825508]\n",
      " [0.56719297]\n",
      " [0.5783003 ]\n",
      " [0.59106147]] | y: 0.6737698566447115 | Predicción actual: [[0.6051215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009429455967620015, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54776591]\n",
      " [0.54840702]\n",
      " [0.55188817]\n",
      " [0.55825508]\n",
      " [0.56719297]\n",
      " [0.5783003 ]\n",
      " [0.59106147]\n",
      " [0.60512149]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05530543625354767, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54840702]\n",
      " [0.55188817]\n",
      " [0.55825508]\n",
      " [0.56719297]\n",
      " [0.5783003 ]\n",
      " [0.59106147]\n",
      " [0.60512149]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.58548373]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01661214977502823, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55188817]\n",
      " [0.55825508]\n",
      " [0.56719297]\n",
      " [0.5783003 ]\n",
      " [0.59106147]\n",
      " [0.60512149]\n",
      " [0.71445176]\n",
      " [0.58548373]] | y: 0.722588144130182 | Predicción actual: [[0.5941647]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04466210678219795, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55825508]\n",
      " [0.56719297]\n",
      " [0.5783003 ]\n",
      " [0.59106147]\n",
      " [0.60512149]\n",
      " [0.71445176]\n",
      " [0.58548373]\n",
      " [0.59416473]] | y: 0.6993413405656723 | Predicción actual: [[0.60493433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014558333903551102, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56719297]\n",
      " [0.5783003 ]\n",
      " [0.59106147]\n",
      " [0.60512149]\n",
      " [0.71445176]\n",
      " [0.58548373]\n",
      " [0.59416473]\n",
      " [0.60493433]] | y: 0.7373111197210385 | Predicción actual: [[0.6167845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013550668954849243, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5783003 ]\n",
      " [0.59106147]\n",
      " [0.60512149]\n",
      " [0.71445176]\n",
      " [0.58548373]\n",
      " [0.59416473]\n",
      " [0.60493433]\n",
      " [0.61678451]] | y: 0.7214258039519565 | Predicción actual: [[0.62856996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016720693558454514, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59106147]\n",
      " [0.60512149]\n",
      " [0.71445176]\n",
      " [0.58548373]\n",
      " [0.59416473]\n",
      " [0.60493433]\n",
      " [0.61678451]\n",
      " [0.62856996]] | y: 0.7187136768694304 | Predicción actual: [[0.63930714]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033814909402281046, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60512149]\n",
      " [0.71445176]\n",
      " [0.58548373]\n",
      " [0.59416473]\n",
      " [0.60493433]\n",
      " [0.61678451]\n",
      " [0.62856996]\n",
      " [0.63930714]] | y: 0.6741573033707864 | Predicción actual: [[0.6479803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013496837578713894, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.58548373]\n",
      " [0.59416473]\n",
      " [0.60493433]\n",
      " [0.61678451]\n",
      " [0.62856996]\n",
      " [0.63930714]\n",
      " [0.64798027]] | y: 0.698566447113522 | Predicción actual: [[0.6538368]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002229029778391123, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58548373]\n",
      " [0.59416473]\n",
      " [0.60493433]\n",
      " [0.61678451]\n",
      " [0.62856996]\n",
      " [0.63930714]\n",
      " [0.64798027]\n",
      " [0.65383679]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009252029471099377, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59416473]\n",
      " [0.60493433]\n",
      " [0.61678451]\n",
      " [0.62856996]\n",
      " [0.63930714]\n",
      " [0.64798027]\n",
      " [0.65383679]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.64033765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037358480039983988, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60493433]\n",
      " [0.61678451]\n",
      " [0.62856996]\n",
      " [0.63930714]\n",
      " [0.64798027]\n",
      " [0.65383679]\n",
      " [0.72103836]\n",
      " [0.64033765]] | y: 0.7562960092987214 | Predicción actual: [[0.65138]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04473171755671501, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61678451]\n",
      " [0.62856996]\n",
      " [0.63930714]\n",
      " [0.64798027]\n",
      " [0.65383679]\n",
      " [0.72103836]\n",
      " [0.64033765]\n",
      " [0.65138   ]] | y: 0.8275862068965516 | Predicción actual: [[0.6624557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02707076072692871, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62856996]\n",
      " [0.63930714]\n",
      " [0.64798027]\n",
      " [0.65383679]\n",
      " [0.72103836]\n",
      " [0.64033765]\n",
      " [0.65138   ]\n",
      " [0.66245568]] | y: 0.8388221619527314 | Predicción actual: [[0.67279834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04666690155863762, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63930714]\n",
      " [0.64798027]\n",
      " [0.65383679]\n",
      " [0.72103836]\n",
      " [0.64033765]\n",
      " [0.65138   ]\n",
      " [0.66245568]\n",
      " [0.67279834]] | y: 0.7942657884540876 | Predicción actual: [[0.681981]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04946335405111313, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64798027]\n",
      " [0.65383679]\n",
      " [0.72103836]\n",
      " [0.64033765]\n",
      " [0.65138   ]\n",
      " [0.66245568]\n",
      " [0.67279834]\n",
      " [0.68198103]] | y: 0.7838047268500579 | Predicción actual: [[0.6898306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016035113483667374, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65383679]\n",
      " [0.72103836]\n",
      " [0.64033765]\n",
      " [0.65138   ]\n",
      " [0.66245568]\n",
      " [0.67279834]\n",
      " [0.68198103]\n",
      " [0.6898306 ]] | y: 0.7679194110809764 | Predicción actual: [[0.6965047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03886224329471588, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.64033765]\n",
      " [0.65138   ]\n",
      " [0.66245568]\n",
      " [0.67279834]\n",
      " [0.68198103]\n",
      " [0.6898306 ]\n",
      " [0.69650471]] | y: 0.7845796203022084 | Predicción actual: [[0.7026912]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019852764904499054, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64033765]\n",
      " [0.65138   ]\n",
      " [0.66245568]\n",
      " [0.67279834]\n",
      " [0.68198103]\n",
      " [0.6898306 ]\n",
      " [0.69650471]\n",
      " [0.7026912 ]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01101683173328638, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65138   ]\n",
      " [0.66245568]\n",
      " [0.67279834]\n",
      " [0.68198103]\n",
      " [0.6898306 ]\n",
      " [0.69650471]\n",
      " [0.7026912 ]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.7024131]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021305445581674576, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66245568]\n",
      " [0.67279834]\n",
      " [0.68198103]\n",
      " [0.6898306 ]\n",
      " [0.69650471]\n",
      " [0.7026912 ]\n",
      " [0.87872917]\n",
      " [0.70241308]] | y: 0.8488957768306855 | Predicción actual: [[0.71516097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023101703263819218, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67279834]\n",
      " [0.68198103]\n",
      " [0.6898306 ]\n",
      " [0.69650471]\n",
      " [0.7026912 ]\n",
      " [0.87872917]\n",
      " [0.70241308]\n",
      " [0.71516097]] | y: 0.8182874854707476 | Predicción actual: [[0.72859955]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00750519847497344, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68198103]\n",
      " [0.6898306 ]\n",
      " [0.69650471]\n",
      " [0.7026912 ]\n",
      " [0.87872917]\n",
      " [0.70241308]\n",
      " [0.71516097]\n",
      " [0.72859955]] | y: 0.8268113134444013 | Predicción actual: [[0.74262637]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.676624196988996e-05, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6898306 ]\n",
      " [0.69650471]\n",
      " [0.7026912 ]\n",
      " [0.87872917]\n",
      " [0.70241308]\n",
      " [0.71516097]\n",
      " [0.72859955]\n",
      " [0.74262637]] | y: 0.7853545137543589 | Predicción actual: [[0.75698256]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.447136886185035e-05, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69650471]\n",
      " [0.7026912 ]\n",
      " [0.87872917]\n",
      " [0.70241308]\n",
      " [0.71516097]\n",
      " [0.72859955]\n",
      " [0.74262637]\n",
      " [0.75698256]] | y: 0.7892289810151103 | Predicción actual: [[0.77163976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010192876681685448, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7026912 ]\n",
      " [0.87872917]\n",
      " [0.70241308]\n",
      " [0.71516097]\n",
      " [0.72859955]\n",
      " [0.74262637]\n",
      " [0.75698256]\n",
      " [0.77163976]] | y: 0.8341728012398295 | Predicción actual: [[0.78671813]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013403580524027348, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.70241308]\n",
      " [0.71516097]\n",
      " [0.72859955]\n",
      " [0.74262637]\n",
      " [0.75698256]\n",
      " [0.77163976]\n",
      " [0.78671813]] | y: 0.8124757845796202 | Predicción actual: [[0.8020339]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.746420406969264e-05, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70241308]\n",
      " [0.71516097]\n",
      " [0.72859955]\n",
      " [0.74262637]\n",
      " [0.75698256]\n",
      " [0.77163976]\n",
      " [0.78671813]\n",
      " [0.8020339 ]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0258464552462101, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71516097]\n",
      " [0.72859955]\n",
      " [0.74262637]\n",
      " [0.75698256]\n",
      " [0.77163976]\n",
      " [0.78671813]\n",
      " [0.8020339 ]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.77995676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004410304594784975, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72859955]\n",
      " [0.74262637]\n",
      " [0.75698256]\n",
      " [0.77163976]\n",
      " [0.78671813]\n",
      " [0.8020339 ]\n",
      " [0.80123983]\n",
      " [0.77995676]] | y: 0.793490895001937 | Predicción actual: [[0.79393554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004604777495842427, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74262637]\n",
      " [0.75698256]\n",
      " [0.77163976]\n",
      " [0.78671813]\n",
      " [0.8020339 ]\n",
      " [0.80123983]\n",
      " [0.77995676]\n",
      " [0.79393554]] | y: 0.760170476559473 | Predicción actual: [[0.80719054]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004609390627592802, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75698256]\n",
      " [0.77163976]\n",
      " [0.78671813]\n",
      " [0.8020339 ]\n",
      " [0.80123983]\n",
      " [0.77995676]\n",
      " [0.79393554]\n",
      " [0.80719054]] | y: 0.7353738860906625 | Predicción actual: [[0.8189747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031884072814136744, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77163976]\n",
      " [0.78671813]\n",
      " [0.8020339 ]\n",
      " [0.80123983]\n",
      " [0.77995676]\n",
      " [0.79393554]\n",
      " [0.80719054]\n",
      " [0.81897467]] | y: 0.7101898488957767 | Predicción actual: [[0.8287406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00033714939490891993, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78671813]\n",
      " [0.8020339 ]\n",
      " [0.80123983]\n",
      " [0.77995676]\n",
      " [0.79393554]\n",
      " [0.80719054]\n",
      " [0.81897467]\n",
      " [0.8287406 ]] | y: 0.7121270825261525 | Predicción actual: [[0.83605635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008655907586216927, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8020339 ]\n",
      " [0.80123983]\n",
      " [0.77995676]\n",
      " [0.79393554]\n",
      " [0.80719054]\n",
      " [0.81897467]\n",
      " [0.8287406 ]\n",
      " [0.83605635]] | y: 0.7396358000774894 | Predicción actual: [[0.8403217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013012956827878952, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.77995676]\n",
      " [0.79393554]\n",
      " [0.80719054]\n",
      " [0.81897467]\n",
      " [0.8287406 ]\n",
      " [0.83605635]\n",
      " [0.84032172]] | y: 0.7361487795428128 | Predicción actual: [[0.84119666]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006178867071866989, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77995676]\n",
      " [0.79393554]\n",
      " [0.80719054]\n",
      " [0.81897467]\n",
      " [0.8287406 ]\n",
      " [0.83605635]\n",
      " [0.84032172]\n",
      " [0.84119666]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03526603803038597, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79393554]\n",
      " [0.80719054]\n",
      " [0.81897467]\n",
      " [0.8287406 ]\n",
      " [0.83605635]\n",
      " [0.84032172]\n",
      " [0.84119666]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.85299367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0882028341293335, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80719054]\n",
      " [0.81897467]\n",
      " [0.8287406 ]\n",
      " [0.83605635]\n",
      " [0.84032172]\n",
      " [0.84119666]\n",
      " [0.66757071]\n",
      " [0.85299367]] | y: 0.696629213483146 | Predicción actual: [[0.8584858]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01012356299906969, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81897467]\n",
      " [0.8287406 ]\n",
      " [0.83605635]\n",
      " [0.84032172]\n",
      " [0.84119666]\n",
      " [0.66757071]\n",
      " [0.85299367]\n",
      " [0.85848582]] | y: 0.6559473072452537 | Predicción actual: [[0.86027706]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12641261518001556, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8287406 ]\n",
      " [0.83605635]\n",
      " [0.84032172]\n",
      " [0.84119666]\n",
      " [0.66757071]\n",
      " [0.85299367]\n",
      " [0.85848582]\n",
      " [0.86027706]] | y: 0.6788066640836885 | Predicción actual: [[0.857924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0057123275473713875, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83605635]\n",
      " [0.84032172]\n",
      " [0.84119666]\n",
      " [0.66757071]\n",
      " [0.85299367]\n",
      " [0.85848582]\n",
      " [0.86027706]\n",
      " [0.85792398]] | y: 0.6760945370011622 | Predicción actual: [[0.8528704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02011585794389248, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84032172]\n",
      " [0.84119666]\n",
      " [0.66757071]\n",
      " [0.85299367]\n",
      " [0.85848582]\n",
      " [0.86027706]\n",
      " [0.85792398]\n",
      " [0.8528704 ]] | y: 0.7295621851995349 | Predicción actual: [[0.8459865]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007117243949323893, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84119666]\n",
      " [0.66757071]\n",
      " [0.85299367]\n",
      " [0.85848582]\n",
      " [0.86027706]\n",
      " [0.85792398]\n",
      " [0.8528704 ]\n",
      " [0.84598649]] | y: 0.7012785741960481 | Predicción actual: [[0.83868676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07107416540384293, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.85299367]\n",
      " [0.85848582]\n",
      " [0.86027706]\n",
      " [0.85792398]\n",
      " [0.8528704 ]\n",
      " [0.84598649]\n",
      " [0.83868676]] | y: 0.767531964354901 | Predicción actual: [[0.83195215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0102871498093009, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85299367]\n",
      " [0.85848582]\n",
      " [0.86027706]\n",
      " [0.85792398]\n",
      " [0.8528704 ]\n",
      " [0.84598649]\n",
      " [0.83868676]\n",
      " [0.83195215]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004877352621406317, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85848582]\n",
      " [0.86027706]\n",
      " [0.85792398]\n",
      " [0.8528704 ]\n",
      " [0.84598649]\n",
      " [0.83868676]\n",
      " [0.83195215]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.87659204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01809816248714924, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86027706]\n",
      " [0.85792398]\n",
      " [0.8528704 ]\n",
      " [0.84598649]\n",
      " [0.83868676]\n",
      " [0.83195215]\n",
      " [0.75513367]\n",
      " [0.87659204]] | y: 0.7520340953118947 | Predicción actual: [[0.87052673]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041131723672151566, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85792398]\n",
      " [0.8528704 ]\n",
      " [0.84598649]\n",
      " [0.83868676]\n",
      " [0.83195215]\n",
      " [0.75513367]\n",
      " [0.87659204]\n",
      " [0.87052673]] | y: 0.7098024021697016 | Predicción actual: [[0.8624317]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003300043288618326, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8528704 ]\n",
      " [0.84598649]\n",
      " [0.83868676]\n",
      " [0.83195215]\n",
      " [0.75513367]\n",
      " [0.87659204]\n",
      " [0.87052673]\n",
      " [0.8624317 ]] | y: 0.6904300658659435 | Predicción actual: [[0.8544674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03183767572045326, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84598649]\n",
      " [0.83868676]\n",
      " [0.83195215]\n",
      " [0.75513367]\n",
      " [0.87659204]\n",
      " [0.87052673]\n",
      " [0.8624317 ]\n",
      " [0.85446739]] | y: 0.7543587756683454 | Predicción actual: [[0.8474762]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03230428695678711, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83868676]\n",
      " [0.83195215]\n",
      " [0.75513367]\n",
      " [0.87659204]\n",
      " [0.87052673]\n",
      " [0.8624317 ]\n",
      " [0.85446739]\n",
      " [0.84747618]] | y: 0.7222006974041069 | Predicción actual: [[0.8425505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.2316322681726888e-05, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83195215]\n",
      " [0.75513367]\n",
      " [0.87659204]\n",
      " [0.87052673]\n",
      " [0.8624317 ]\n",
      " [0.85446739]\n",
      " [0.84747618]\n",
      " [0.84255052]] | y: 0.8485083301046106 | Predicción actual: [[0.8406864]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033480506390333176, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.87659204]\n",
      " [0.87052673]\n",
      " [0.8624317 ]\n",
      " [0.85446739]\n",
      " [0.84747618]\n",
      " [0.84255052]\n",
      " [0.84068638]] | y: 0.9054629988376597 | Predicción actual: [[0.8418689]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006936952937394381, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87659204]\n",
      " [0.87052673]\n",
      " [0.8624317 ]\n",
      " [0.85446739]\n",
      " [0.84747618]\n",
      " [0.84255052]\n",
      " [0.84068638]\n",
      " [0.84186888]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012874491512775421, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87052673]\n",
      " [0.8624317 ]\n",
      " [0.85446739]\n",
      " [0.84747618]\n",
      " [0.84255052]\n",
      " [0.84068638]\n",
      " [0.84186888]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.85993207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012300220550969243, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8624317 ]\n",
      " [0.85446739]\n",
      " [0.84747618]\n",
      " [0.84255052]\n",
      " [0.84068638]\n",
      " [0.84186888]\n",
      " [0.8822162 ]\n",
      " [0.85993207]] | y: 0.889577683068578 | Predicción actual: [[0.85346377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006679450743831694, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85446739]\n",
      " [0.84747618]\n",
      " [0.84255052]\n",
      " [0.84068638]\n",
      " [0.84186888]\n",
      " [0.8822162 ]\n",
      " [0.85993207]\n",
      " [0.85346377]] | y: 0.8748547074777218 | Predicción actual: [[0.8490485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.625073289498687e-05, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84747618]\n",
      " [0.84255052]\n",
      " [0.84068638]\n",
      " [0.84186888]\n",
      " [0.8822162 ]\n",
      " [0.85993207]\n",
      " [0.85346377]\n",
      " [0.8490485 ]] | y: 0.9132119333591631 | Predicción actual: [[0.8469712]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031779755372554064, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84255052]\n",
      " [0.84068638]\n",
      " [0.84186888]\n",
      " [0.8822162 ]\n",
      " [0.85993207]\n",
      " [0.85346377]\n",
      " [0.8490485 ]\n",
      " [0.84697121]] | y: 1.0 | Predicción actual: [[0.84712946]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05006387457251549, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84068638]\n",
      " [0.84186888]\n",
      " [0.8822162 ]\n",
      " [0.85993207]\n",
      " [0.85346377]\n",
      " [0.8490485 ]\n",
      " [0.84697121]\n",
      " [0.84712946]] | y: 0.9705540488182873 | Predicción actual: [[0.84962183]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02650349587202072, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84186888]\n",
      " [0.8822162 ]\n",
      " [0.85993207]\n",
      " [0.85346377]\n",
      " [0.8490485 ]\n",
      " [0.84697121]\n",
      " [0.84712946]\n",
      " [0.84962183]] | y: 0.8888027896164277 | Predicción actual: [[0.8526606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003257384814787656, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.85993207]\n",
      " [0.85346377]\n",
      " [0.8490485 ]\n",
      " [0.84697121]\n",
      " [0.84712946]\n",
      " [0.84962183]\n",
      " [0.8526606 ]] | y: 0.877954281286323 | Predicción actual: [[0.85572875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006502802949398756, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85993207]\n",
      " [0.85346377]\n",
      " [0.8490485 ]\n",
      " [0.84697121]\n",
      " [0.84712946]\n",
      " [0.84962183]\n",
      " [0.8526606 ]\n",
      " [0.85572875]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04088635742664337, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85346377]\n",
      " [0.8490485 ]\n",
      " [0.84697121]\n",
      " [0.84712946]\n",
      " [0.84962183]\n",
      " [0.8526606 ]\n",
      " [0.85572875]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8428539]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032755315769463778, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8490485 ]\n",
      " [0.84697121]\n",
      " [0.84712946]\n",
      " [0.84962183]\n",
      " [0.8526606 ]\n",
      " [0.85572875]\n",
      " [0.84889578]\n",
      " [0.8428539 ]] | y: 0.8550949244478885 | Predicción actual: [[0.8404872]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00905490480363369, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84697121]\n",
      " [0.84712946]\n",
      " [0.84962183]\n",
      " [0.8526606 ]\n",
      " [0.85572875]\n",
      " [0.84889578]\n",
      " [0.8428539 ]\n",
      " [0.84048718]] | y: 0.8752421542037967 | Predicción actual: [[0.8391667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002013901714235544, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84712946]\n",
      " [0.84962183]\n",
      " [0.8526606 ]\n",
      " [0.85572875]\n",
      " [0.84889578]\n",
      " [0.8428539 ]\n",
      " [0.84048718]\n",
      " [0.8391667 ]] | y: 0.857032158078264 | Predicción actual: [[0.83855814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009761582128703594, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84962183]\n",
      " [0.8526606 ]\n",
      " [0.85572875]\n",
      " [0.84889578]\n",
      " [0.8428539 ]\n",
      " [0.84048718]\n",
      " [0.8391667 ]\n",
      " [0.83855814]] | y: 0.8500581170089112 | Predicción actual: [[0.83800715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05021503567695618, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8526606 ]\n",
      " [0.85572875]\n",
      " [0.84889578]\n",
      " [0.8428539 ]\n",
      " [0.84048718]\n",
      " [0.8391667 ]\n",
      " [0.83855814]\n",
      " [0.83800715]] | y: 0.8426966292134832 | Predicción actual: [[0.8368102]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015644057421013713, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85572875]\n",
      " [0.84889578]\n",
      " [0.8428539 ]\n",
      " [0.84048718]\n",
      " [0.8391667 ]\n",
      " [0.83855814]\n",
      " [0.83800715]\n",
      " [0.83681017]] | y: 0.8229368461836497 | Predicción actual: [[0.8343217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009653815650381148, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.8428539 ]\n",
      " [0.84048718]\n",
      " [0.8391667 ]\n",
      " [0.83855814]\n",
      " [0.83800715]\n",
      " [0.83681017]\n",
      " [0.83432168]] | y: 0.7745060054242543 | Predicción actual: [[0.83034617]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.2777743652113713e-05, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8428539 ]\n",
      " [0.84048718]\n",
      " [0.8391667 ]\n",
      " [0.83855814]\n",
      " [0.83800715]\n",
      " [0.83681017]\n",
      " [0.83432168]\n",
      " [0.83034617]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007598360534757376, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84048718]\n",
      " [0.8391667 ]\n",
      " [0.83855814]\n",
      " [0.83800715]\n",
      " [0.83681017]\n",
      " [0.83432168]\n",
      " [0.83034617]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8255353]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015497350133955479, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8391667 ]\n",
      " [0.83855814]\n",
      " [0.83800715]\n",
      " [0.83681017]\n",
      " [0.83432168]\n",
      " [0.83034617]\n",
      " [0.78419217]\n",
      " [0.8255353 ]] | y: 0.854320030995738 | Predicción actual: [[0.823062]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009761652909219265, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83855814]\n",
      " [0.83800715]\n",
      " [0.83681017]\n",
      " [0.83432168]\n",
      " [0.83034617]\n",
      " [0.78419217]\n",
      " [0.8255353 ]\n",
      " [0.823062  ]] | y: 0.8368849283223556 | Predicción actual: [[0.82027036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006943805143237114, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83800715]\n",
      " [0.83681017]\n",
      " [0.83432168]\n",
      " [0.83034617]\n",
      " [0.78419217]\n",
      " [0.8255353 ]\n",
      " [0.823062  ]\n",
      " [0.82027036]] | y: 0.8299108872530028 | Predicción actual: [[0.81686896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026097165420651436, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83681017]\n",
      " [0.83432168]\n",
      " [0.83034617]\n",
      " [0.78419217]\n",
      " [0.8255353 ]\n",
      " [0.823062  ]\n",
      " [0.82027036]\n",
      " [0.81686896]] | y: 0.887253002712127 | Predicción actual: [[0.8129334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015827158465981483, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83432168]\n",
      " [0.83034617]\n",
      " [0.78419217]\n",
      " [0.8255353 ]\n",
      " [0.823062  ]\n",
      " [0.82027036]\n",
      " [0.81686896]\n",
      " [0.81293339]] | y: 0.8597442851607902 | Predicción actual: [[0.8086241]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.7040914574172348e-05, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83034617]\n",
      " [0.78419217]\n",
      " [0.8255353 ]\n",
      " [0.823062  ]\n",
      " [0.82027036]\n",
      " [0.81686896]\n",
      " [0.81293339]\n",
      " [0.80862409]] | y: 0.8395970554048819 | Predicción actual: [[0.8041716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012144726933911443, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.8255353 ]\n",
      " [0.823062  ]\n",
      " [0.82027036]\n",
      " [0.81686896]\n",
      " [0.81293339]\n",
      " [0.80862409]\n",
      " [0.80417162]] | y: 0.7838047268500579 | Predicción actual: [[0.8001749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007111383602023125, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8255353 ]\n",
      " [0.823062  ]\n",
      " [0.82027036]\n",
      " [0.81686896]\n",
      " [0.81293339]\n",
      " [0.80862409]\n",
      " [0.80417162]\n",
      " [0.80017489]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032882271334528923, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.823062  ]\n",
      " [0.82027036]\n",
      " [0.81686896]\n",
      " [0.81293339]\n",
      " [0.80862409]\n",
      " [0.80417162]\n",
      " [0.80017489]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.80647296]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00200989143922925, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82027036]\n",
      " [0.81686896]\n",
      " [0.81293339]\n",
      " [0.80862409]\n",
      " [0.80417162]\n",
      " [0.80017489]\n",
      " [0.81828749]\n",
      " [0.80647296]] | y: 0.7605579232855482 | Predicción actual: [[0.8038698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09919390827417374, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81686896]\n",
      " [0.81293339]\n",
      " [0.80862409]\n",
      " [0.80417162]\n",
      " [0.80017489]\n",
      " [0.81828749]\n",
      " [0.80647296]\n",
      " [0.80386978]] | y: 0.7915536613715615 | Predicción actual: [[0.8006271]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012010498903691769, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81293339]\n",
      " [0.80862409]\n",
      " [0.80417162]\n",
      " [0.80017489]\n",
      " [0.81828749]\n",
      " [0.80647296]\n",
      " [0.80386978]\n",
      " [0.80062711]] | y: 0.7686943045331267 | Predicción actual: [[0.79778177]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015962345525622368, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80862409]\n",
      " [0.80417162]\n",
      " [0.80017489]\n",
      " [0.81828749]\n",
      " [0.80647296]\n",
      " [0.80386978]\n",
      " [0.80062711]\n",
      " [0.79778177]] | y: 0.7686943045331267 | Predicción actual: [[0.7953913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034089491236954927, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80417162]\n",
      " [0.80017489]\n",
      " [0.81828749]\n",
      " [0.80647296]\n",
      " [0.80386978]\n",
      " [0.80062711]\n",
      " [0.79778177]\n",
      " [0.79539132]] | y: 0.7989151491669895 | Predicción actual: [[0.79398763]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.920312443980947e-05, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80017489]\n",
      " [0.81828749]\n",
      " [0.80647296]\n",
      " [0.80386978]\n",
      " [0.80062711]\n",
      " [0.79778177]\n",
      " [0.79539132]\n",
      " [0.79398763]] | y: 0.7900038744672608 | Predicción actual: [[0.79356426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00122239557094872, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.80647296]\n",
      " [0.80386978]\n",
      " [0.80062711]\n",
      " [0.79778177]\n",
      " [0.79539132]\n",
      " [0.79398763]\n",
      " [0.79356426]] | y: 0.760170476559473 | Predicción actual: [[0.79404986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005834707990288734, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80647296]\n",
      " [0.80386978]\n",
      " [0.80062711]\n",
      " [0.79778177]\n",
      " [0.79539132]\n",
      " [0.79398763]\n",
      " [0.79356426]\n",
      " [0.79404986]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035565149039030075, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80386978]\n",
      " [0.80062711]\n",
      " [0.79778177]\n",
      " [0.79539132]\n",
      " [0.79398763]\n",
      " [0.79356426]\n",
      " [0.79404986]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.78550607]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05509462207555771, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80062711]\n",
      " [0.79778177]\n",
      " [0.79539132]\n",
      " [0.79398763]\n",
      " [0.79356426]\n",
      " [0.79404986]\n",
      " [0.68539326]\n",
      " [0.78550607]] | y: 0.6648585819449826 | Predicción actual: [[0.78079885]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008210716769099236, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79778177]\n",
      " [0.79539132]\n",
      " [0.79398763]\n",
      " [0.79356426]\n",
      " [0.79404986]\n",
      " [0.68539326]\n",
      " [0.78550607]\n",
      " [0.78079885]] | y: 0.7078651685393258 | Predicción actual: [[0.775376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.759121606592089e-05, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79539132]\n",
      " [0.79398763]\n",
      " [0.79356426]\n",
      " [0.79404986]\n",
      " [0.68539326]\n",
      " [0.78550607]\n",
      " [0.78079885]\n",
      " [0.77537602]] | y: 0.6648585819449826 | Predicción actual: [[0.7693693]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024253468960523605, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79398763]\n",
      " [0.79356426]\n",
      " [0.79404986]\n",
      " [0.68539326]\n",
      " [0.78550607]\n",
      " [0.78079885]\n",
      " [0.77537602]\n",
      " [0.7693693 ]] | y: 0.7113521890740022 | Predicción actual: [[0.76250976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015822509303689003, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79356426]\n",
      " [0.79404986]\n",
      " [0.68539326]\n",
      " [0.78550607]\n",
      " [0.78079885]\n",
      " [0.77537602]\n",
      " [0.7693693 ]\n",
      " [0.76250976]] | y: 0.6772568771793879 | Predicción actual: [[0.7547721]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002639448211994022, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79404986]\n",
      " [0.68539326]\n",
      " [0.78550607]\n",
      " [0.78079885]\n",
      " [0.77537602]\n",
      " [0.7693693 ]\n",
      " [0.76250976]\n",
      " [0.75477213]] | y: 0.7621077101898488 | Predicción actual: [[0.74628454]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005622852593660355, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.78550607]\n",
      " [0.78079885]\n",
      " [0.77537602]\n",
      " [0.7693693 ]\n",
      " [0.76250976]\n",
      " [0.75477213]\n",
      " [0.74628454]] | y: 0.8070515304145678 | Predicción actual: [[0.7367328]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004615810699760914, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78550607]\n",
      " [0.78079885]\n",
      " [0.77537602]\n",
      " [0.7693693 ]\n",
      " [0.76250976]\n",
      " [0.75477213]\n",
      " [0.74628454]\n",
      " [0.73673278]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00041838764445856214, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78079885]\n",
      " [0.77537602]\n",
      " [0.7693693 ]\n",
      " [0.76250976]\n",
      " [0.75477213]\n",
      " [0.74628454]\n",
      " [0.73673278]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.75122297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013539832085371017, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77537602]\n",
      " [0.7693693 ]\n",
      " [0.76250976]\n",
      " [0.75477213]\n",
      " [0.74628454]\n",
      " [0.73673278]\n",
      " [0.81518791]\n",
      " [0.75122297]] | y: 0.9597055404881829 | Predicción actual: [[0.7463289]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05714186653494835, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7693693 ]\n",
      " [0.76250976]\n",
      " [0.75477213]\n",
      " [0.74628454]\n",
      " [0.73673278]\n",
      " [0.81518791]\n",
      " [0.75122297]\n",
      " [0.74632889]] | y: 0.9643549012010848 | Predicción actual: [[0.74257994]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.148305281996727, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76250976]\n",
      " [0.75477213]\n",
      " [0.74628454]\n",
      " [0.73673278]\n",
      " [0.81518791]\n",
      " [0.75122297]\n",
      " [0.74632889]\n",
      " [0.74257994]] | y: 0.8880278961642774 | Predicción actual: [[0.74034566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06995654106140137, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75477213]\n",
      " [0.74628454]\n",
      " [0.73673278]\n",
      " [0.81518791]\n",
      " [0.75122297]\n",
      " [0.74632889]\n",
      " [0.74257994]\n",
      " [0.74034566]] | y: 0.8926772568771792 | Predicción actual: [[0.7397853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004760416690260172, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74628454]\n",
      " [0.73673278]\n",
      " [0.81518791]\n",
      " [0.75122297]\n",
      " [0.74632889]\n",
      " [0.74257994]\n",
      " [0.74034566]\n",
      " [0.73978531]] | y: 0.8752421542037967 | Predicción actual: [[0.7407185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0411715991795063, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73673278]\n",
      " [0.81518791]\n",
      " [0.75122297]\n",
      " [0.74632889]\n",
      " [0.74257994]\n",
      " [0.74034566]\n",
      " [0.73978531]\n",
      " [0.74071848]] | y: 0.8508330104610615 | Predicción actual: [[0.7438375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003086740616708994, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.75122297]\n",
      " [0.74632889]\n",
      " [0.74257994]\n",
      " [0.74034566]\n",
      " [0.73978531]\n",
      " [0.74071848]\n",
      " [0.74383748]] | y: 0.8488957768306855 | Predicción actual: [[0.7493016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024654611479490995, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75122297]\n",
      " [0.74632889]\n",
      " [0.74257994]\n",
      " [0.74034566]\n",
      " [0.73978531]\n",
      " [0.74071848]\n",
      " [0.74383748]\n",
      " [0.74930161]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0313313789665699, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74632889]\n",
      " [0.74257994]\n",
      " [0.74034566]\n",
      " [0.73978531]\n",
      " [0.74071848]\n",
      " [0.74383748]\n",
      " [0.74930161]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7327812]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08442699164152145, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74257994]\n",
      " [0.74034566]\n",
      " [0.73978531]\n",
      " [0.74071848]\n",
      " [0.74383748]\n",
      " [0.74930161]\n",
      " [0.96241767]\n",
      " [0.73278117]] | y: 0.9407206509104997 | Predicción actual: [[0.7362772]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08585982024669647, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74034566]\n",
      " [0.73978531]\n",
      " [0.74071848]\n",
      " [0.74383748]\n",
      " [0.74930161]\n",
      " [0.96241767]\n",
      " [0.73278117]\n",
      " [0.73627722]] | y: 0.9724912824486633 | Predicción actual: [[0.742997]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061694759875535965, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73978531]\n",
      " [0.74071848]\n",
      " [0.74383748]\n",
      " [0.74930161]\n",
      " [0.96241767]\n",
      " [0.73278117]\n",
      " [0.73627722]\n",
      " [0.74299699]] | y: 0.9969004261913985 | Predicción actual: [[0.75241166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04589398205280304, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74071848]\n",
      " [0.74383748]\n",
      " [0.74930161]\n",
      " [0.96241767]\n",
      " [0.73278117]\n",
      " [0.73627722]\n",
      " [0.74299699]\n",
      " [0.75241166]] | y: 0.951181712514529 | Predicción actual: [[0.7637056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.058553289622068405, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74383748]\n",
      " [0.74930161]\n",
      " [0.96241767]\n",
      " [0.73278117]\n",
      " [0.73627722]\n",
      " [0.74299699]\n",
      " [0.75241166]\n",
      " [0.76370561]] | y: 0.8957768306857805 | Predicción actual: [[0.7760067]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005126349627971649, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74930161]\n",
      " [0.96241767]\n",
      " [0.73278117]\n",
      " [0.73627722]\n",
      " [0.74299699]\n",
      " [0.75241166]\n",
      " [0.76370561]\n",
      " [0.7760067 ]] | y: 0.8814413018209997 | Predicción actual: [[0.7879694]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008826129487715662, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.73278117]\n",
      " [0.73627722]\n",
      " [0.74299699]\n",
      " [0.75241166]\n",
      " [0.76370561]\n",
      " [0.7760067 ]\n",
      " [0.78796941]] | y: 0.9170864006199149 | Predicción actual: [[0.7983985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03347251936793327, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73278117]\n",
      " [0.73627722]\n",
      " [0.74299699]\n",
      " [0.75241166]\n",
      " [0.76370561]\n",
      " [0.7760067 ]\n",
      " [0.78796941]\n",
      " [0.79839849]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06751017272472382, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73627722]\n",
      " [0.74299699]\n",
      " [0.75241166]\n",
      " [0.76370561]\n",
      " [0.7760067 ]\n",
      " [0.78796941]\n",
      " [0.79839849]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.75699127]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024987583979964256, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74299699]\n",
      " [0.75241166]\n",
      " [0.76370561]\n",
      " [0.7760067 ]\n",
      " [0.78796941]\n",
      " [0.79839849]\n",
      " [0.91979853]\n",
      " [0.75699127]] | y: 0.9682293684618366 | Predicción actual: [[0.76927537]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051752977073192596, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75241166]\n",
      " [0.76370561]\n",
      " [0.7760067 ]\n",
      " [0.78796941]\n",
      " [0.79839849]\n",
      " [0.91979853]\n",
      " [0.75699127]\n",
      " [0.76927537]] | y: 0.9577683068578069 | Predicción actual: [[0.78302056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02144244685769081, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.21746735]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03241630643606186, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21746735]] | y: 0.10422316931421921 | Predicción actual: [[0.2023438]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003265548497438431, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21746735]\n",
      " [0.20234381]] | y: 0.15420379697791559 | Predicción actual: [[0.20686881]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003356652334332466, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21746735]\n",
      " [0.20234381]\n",
      " [0.20686881]] | y: 0.1557535838822161 | Predicción actual: [[0.21894214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007893074303865433, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21746735]\n",
      " [0.20234381]\n",
      " [0.20686881]\n",
      " [0.21894214]] | y: 0.12553273924835334 | Predicción actual: [[0.23249704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021521037444472313, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21746735]\n",
      " [0.20234381]\n",
      " [0.20686881]\n",
      " [0.21894214]\n",
      " [0.23249704]] | y: 0.1456799690042619 | Predicción actual: [[0.24382244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003969329874962568, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21746735]\n",
      " [0.20234381]\n",
      " [0.20686881]\n",
      " [0.21894214]\n",
      " [0.23249704]\n",
      " [0.24382244]] | y: 0.1464548624564122 | Predicción actual: [[0.26714703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013678666204214096, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.21746735]\n",
      " [0.20234381]\n",
      " [0.20686881]\n",
      " [0.21894214]\n",
      " [0.23249704]\n",
      " [0.24382244]\n",
      " [0.26714703]] | y: 0.1960480433940332 | Predicción actual: [[0.2960652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020512878894805908, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21746735]\n",
      " [0.20234381]\n",
      " [0.20686881]\n",
      " [0.21894214]\n",
      " [0.23249704]\n",
      " [0.24382244]\n",
      " [0.26714703]\n",
      " [0.29606521]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019240809604525566, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20234381]\n",
      " [0.20686881]\n",
      " [0.21894214]\n",
      " [0.23249704]\n",
      " [0.24382244]\n",
      " [0.26714703]\n",
      " [0.29606521]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3336587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010849869810044765, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20686881]\n",
      " [0.21894214]\n",
      " [0.23249704]\n",
      " [0.24382244]\n",
      " [0.26714703]\n",
      " [0.29606521]\n",
      " [0.2305308 ]\n",
      " [0.3336587 ]] | y: 0.211933359163115 | Predicción actual: [[0.34138402]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007273026742041111, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21894214]\n",
      " [0.23249704]\n",
      " [0.24382244]\n",
      " [0.26714703]\n",
      " [0.29606521]\n",
      " [0.2305308 ]\n",
      " [0.3336587 ]\n",
      " [0.34138402]] | y: 0.2072839984502131 | Predicción actual: [[0.3510433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015624456107616425, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23249704]\n",
      " [0.24382244]\n",
      " [0.26714703]\n",
      " [0.29606521]\n",
      " [0.2305308 ]\n",
      " [0.3336587 ]\n",
      " [0.34138402]\n",
      " [0.35104331]] | y: 0.19294846958543205 | Predicción actual: [[0.36138526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021661831066012383, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24382244]\n",
      " [0.26714703]\n",
      " [0.29606521]\n",
      " [0.2305308 ]\n",
      " [0.3336587 ]\n",
      " [0.34138402]\n",
      " [0.35104331]\n",
      " [0.36138526]] | y: 0.19682293684618352 | Predicción actual: [[0.3722909]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0214290339499712, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26714703]\n",
      " [0.29606521]\n",
      " [0.2305308 ]\n",
      " [0.3336587 ]\n",
      " [0.34138402]\n",
      " [0.35104331]\n",
      " [0.36138526]\n",
      " [0.37229091]] | y: 0.21425803951956607 | Predicción actual: [[0.38443503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011615393683314323, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.29606521]\n",
      " [0.2305308 ]\n",
      " [0.3336587 ]\n",
      " [0.34138402]\n",
      " [0.35104331]\n",
      " [0.36138526]\n",
      " [0.37229091]\n",
      " [0.38443503]] | y: 0.18132506780317698 | Predicción actual: [[0.39510155]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031173886731266975, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.3336587 ]\n",
      " [0.34138402]\n",
      " [0.35104331]\n",
      " [0.36138526]\n",
      " [0.37229091]\n",
      " [0.38443503]\n",
      " [0.39510155]] | y: 0.17512592018597434 | Predicción actual: [[0.40257215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05562041699886322, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3336587 ]\n",
      " [0.34138402]\n",
      " [0.35104331]\n",
      " [0.36138526]\n",
      " [0.37229091]\n",
      " [0.38443503]\n",
      " [0.39510155]\n",
      " [0.40257215]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08540651202201843, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34138402]\n",
      " [0.35104331]\n",
      " [0.36138526]\n",
      " [0.37229091]\n",
      " [0.38443503]\n",
      " [0.39510155]\n",
      " [0.40257215]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.43493506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0742960050702095, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35104331]\n",
      " [0.36138526]\n",
      " [0.37229091]\n",
      " [0.38443503]\n",
      " [0.39510155]\n",
      " [0.40257215]\n",
      " [0.14800465]\n",
      " [0.43493506]] | y: 0.19217357613328173 | Predicción actual: [[0.4389788]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0639510378241539, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36138526]\n",
      " [0.37229091]\n",
      " [0.38443503]\n",
      " [0.39510155]\n",
      " [0.40257215]\n",
      " [0.14800465]\n",
      " [0.43493506]\n",
      " [0.43897879]] | y: 0.1859744285160791 | Predicción actual: [[0.44104186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06739930063486099, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37229091]\n",
      " [0.38443503]\n",
      " [0.39510155]\n",
      " [0.40257215]\n",
      " [0.14800465]\n",
      " [0.43493506]\n",
      " [0.43897879]\n",
      " [0.44104186]] | y: 0.26695079426578844 | Predicción actual: [[0.44120917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012450924143195152, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38443503]\n",
      " [0.39510155]\n",
      " [0.40257215]\n",
      " [0.14800465]\n",
      " [0.43493506]\n",
      " [0.43897879]\n",
      " [0.44104186]\n",
      " [0.44120917]] | y: 0.2925222781867493 | Predicción actual: [[0.43983567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015168393962085247, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39510155]\n",
      " [0.40257215]\n",
      " [0.14800465]\n",
      " [0.43493506]\n",
      " [0.43897879]\n",
      " [0.44104186]\n",
      " [0.44120917]\n",
      " [0.43983567]] | y: 0.3177063153816349 | Predicción actual: [[0.43701708]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027329472824931145, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40257215]\n",
      " [0.14800465]\n",
      " [0.43493506]\n",
      " [0.43897879]\n",
      " [0.44104186]\n",
      " [0.44120917]\n",
      " [0.43983567]\n",
      " [0.43701708]] | y: 0.31266950794265785 | Predicción actual: [[0.43341535]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028174228966236115, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.43493506]\n",
      " [0.43897879]\n",
      " [0.44104186]\n",
      " [0.44120917]\n",
      " [0.43983567]\n",
      " [0.43701708]\n",
      " [0.43341535]] | y: 0.2890352576520729 | Predicción actual: [[0.43007463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031085532158613205, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43493506]\n",
      " [0.43897879]\n",
      " [0.44104186]\n",
      " [0.44120917]\n",
      " [0.43983567]\n",
      " [0.43701708]\n",
      " [0.43341535]\n",
      " [0.43007463]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03373332694172859, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43897879]\n",
      " [0.44104186]\n",
      " [0.44120917]\n",
      " [0.43983567]\n",
      " [0.43701708]\n",
      " [0.43341535]\n",
      " [0.43007463]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.49146518]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022475680336356163, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44104186]\n",
      " [0.44120917]\n",
      " [0.43983567]\n",
      " [0.43701708]\n",
      " [0.43341535]\n",
      " [0.43007463]\n",
      " [0.28283611]\n",
      " [0.49146518]] | y: 0.2758620689655173 | Predicción actual: [[0.4885001]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06167973205447197, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44120917]\n",
      " [0.43983567]\n",
      " [0.43701708]\n",
      " [0.43341535]\n",
      " [0.43007463]\n",
      " [0.28283611]\n",
      " [0.49146518]\n",
      " [0.48850009]] | y: 0.2746997287872917 | Predicción actual: [[0.4841935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04076021909713745, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43983567]\n",
      " [0.43701708]\n",
      " [0.43341535]\n",
      " [0.43007463]\n",
      " [0.28283611]\n",
      " [0.49146518]\n",
      " [0.48850009]\n",
      " [0.4841935 ]] | y: 0.275474622239442 | Predicción actual: [[0.47961193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024525482207536697, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43701708]\n",
      " [0.43341535]\n",
      " [0.43007463]\n",
      " [0.28283611]\n",
      " [0.49146518]\n",
      " [0.48850009]\n",
      " [0.4841935 ]\n",
      " [0.47961193]] | y: 0.3347539713289423 | Predicción actual: [[0.47584832]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02073623798787594, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43341535]\n",
      " [0.43007463]\n",
      " [0.28283611]\n",
      " [0.49146518]\n",
      " [0.48850009]\n",
      " [0.4841935 ]\n",
      " [0.47961193]\n",
      " [0.47584832]] | y: 0.35567609453700116 | Predicción actual: [[0.4739101]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02007155865430832, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43007463]\n",
      " [0.28283611]\n",
      " [0.49146518]\n",
      " [0.48850009]\n",
      " [0.4841935 ]\n",
      " [0.47961193]\n",
      " [0.47584832]\n",
      " [0.47391009]] | y: 0.3366912049593181 | Predicción actual: [[0.47454178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02792755328118801, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.49146518]\n",
      " [0.48850009]\n",
      " [0.4841935 ]\n",
      " [0.47961193]\n",
      " [0.47584832]\n",
      " [0.47391009]\n",
      " [0.47454178]] | y: 0.3335916311507167 | Predicción actual: [[0.4780682]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04041455313563347, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49146518]\n",
      " [0.48850009]\n",
      " [0.4841935 ]\n",
      " [0.47961193]\n",
      " [0.47584832]\n",
      " [0.47391009]\n",
      " [0.47454178]\n",
      " [0.4780682 ]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027658792212605476, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48850009]\n",
      " [0.4841935 ]\n",
      " [0.47961193]\n",
      " [0.47584832]\n",
      " [0.47391009]\n",
      " [0.47454178]\n",
      " [0.4780682 ]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.51697177]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011439026333391666, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4841935 ]\n",
      " [0.47961193]\n",
      " [0.47584832]\n",
      " [0.47391009]\n",
      " [0.47454178]\n",
      " [0.4780682 ]\n",
      " [0.3847346 ]\n",
      " [0.51697177]] | y: 0.5962805114296785 | Predicción actual: [[0.5125748]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00605678791180253, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47961193]\n",
      " [0.47584832]\n",
      " [0.47391009]\n",
      " [0.47454178]\n",
      " [0.4780682 ]\n",
      " [0.3847346 ]\n",
      " [0.51697177]\n",
      " [0.51257479]] | y: 0.574583494769469 | Predicción actual: [[0.5087581]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016261093551293015, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47584832]\n",
      " [0.47391009]\n",
      " [0.47454178]\n",
      " [0.4780682 ]\n",
      " [0.3847346 ]\n",
      " [0.51697177]\n",
      " [0.51257479]\n",
      " [0.50875813]] | y: 0.6063541263076326 | Predicción actual: [[0.5061019]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005343283526599407, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47391009]\n",
      " [0.47454178]\n",
      " [0.4780682 ]\n",
      " [0.3847346 ]\n",
      " [0.51697177]\n",
      " [0.51257479]\n",
      " [0.50875813]\n",
      " [0.50610191]] | y: 0.5846571096474236 | Predicción actual: [[0.5049784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017818139865994453, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47454178]\n",
      " [0.4780682 ]\n",
      " [0.3847346 ]\n",
      " [0.51697177]\n",
      " [0.51257479]\n",
      " [0.50875813]\n",
      " [0.50610191]\n",
      " [0.50497842]] | y: 0.5687717938783416 | Predicción actual: [[0.5054275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011114398948848248, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4780682 ]\n",
      " [0.3847346 ]\n",
      " [0.51697177]\n",
      " [0.51257479]\n",
      " [0.50875813]\n",
      " [0.50610191]\n",
      " [0.50497842]\n",
      " [0.50542748]] | y: 0.6427741185586981 | Predicción actual: [[0.50710803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024641141295433044, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.51697177]\n",
      " [0.51257479]\n",
      " [0.50875813]\n",
      " [0.50610191]\n",
      " [0.50497842]\n",
      " [0.50542748]\n",
      " [0.50710803]] | y: 0.6617590081363811 | Predicción actual: [[0.5094848]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011782289482653141, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51697177]\n",
      " [0.51257479]\n",
      " [0.50875813]\n",
      " [0.50610191]\n",
      " [0.50497842]\n",
      " [0.50542748]\n",
      " [0.50710803]\n",
      " [0.50948483]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005978701636195183, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51257479]\n",
      " [0.50875813]\n",
      " [0.50610191]\n",
      " [0.50497842]\n",
      " [0.50542748]\n",
      " [0.50710803]\n",
      " [0.50948483]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.53623366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028317999094724655, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50875813]\n",
      " [0.50610191]\n",
      " [0.50497842]\n",
      " [0.50542748]\n",
      " [0.50710803]\n",
      " [0.50948483]\n",
      " [0.67299496]\n",
      " [0.53623366]] | y: 0.703990701278574 | Predicción actual: [[0.53759843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013522179797291756, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50610191]\n",
      " [0.50497842]\n",
      " [0.50542748]\n",
      " [0.50710803]\n",
      " [0.50948483]\n",
      " [0.67299496]\n",
      " [0.53623366]\n",
      " [0.53759843]] | y: 0.7272375048430839 | Predicción actual: [[0.54174757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03141583874821663, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50497842]\n",
      " [0.50542748]\n",
      " [0.50710803]\n",
      " [0.50948483]\n",
      " [0.67299496]\n",
      " [0.53623366]\n",
      " [0.53759843]\n",
      " [0.54174757]] | y: 0.722588144130182 | Predicción actual: [[0.54869765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03051641210913658, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50542748]\n",
      " [0.50710803]\n",
      " [0.50948483]\n",
      " [0.67299496]\n",
      " [0.53623366]\n",
      " [0.53759843]\n",
      " [0.54174757]\n",
      " [0.54869765]] | y: 0.771793878341728 | Predicción actual: [[0.5581329]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06790964305400848, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50710803]\n",
      " [0.50948483]\n",
      " [0.67299496]\n",
      " [0.53623366]\n",
      " [0.53759843]\n",
      " [0.54174757]\n",
      " [0.54869765]\n",
      " [0.55813289]] | y: 0.7245253777605578 | Predicción actual: [[0.5696481]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02011854574084282, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50948483]\n",
      " [0.67299496]\n",
      " [0.53623366]\n",
      " [0.53759843]\n",
      " [0.54174757]\n",
      " [0.54869765]\n",
      " [0.55813289]\n",
      " [0.56964809]] | y: 0.6710577295621851 | Predicción actual: [[0.582704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005986788310110569, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.53623366]\n",
      " [0.53759843]\n",
      " [0.54174757]\n",
      " [0.54869765]\n",
      " [0.55813289]\n",
      " [0.56964809]\n",
      " [0.58270401]] | y: 0.6737698566447115 | Predicción actual: [[0.59691834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010111668147146702, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53623366]\n",
      " [0.53759843]\n",
      " [0.54174757]\n",
      " [0.54869765]\n",
      " [0.55813289]\n",
      " [0.56964809]\n",
      " [0.58270401]\n",
      " [0.59691834]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018246793188154697, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53759843]\n",
      " [0.54174757]\n",
      " [0.54869765]\n",
      " [0.55813289]\n",
      " [0.56964809]\n",
      " [0.58270401]\n",
      " [0.59691834]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5753905]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021798375993967056, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54174757]\n",
      " [0.54869765]\n",
      " [0.55813289]\n",
      " [0.56964809]\n",
      " [0.58270401]\n",
      " [0.59691834]\n",
      " [0.71445176]\n",
      " [0.57539052]] | y: 0.722588144130182 | Predicción actual: [[0.5844555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03458881378173828, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54869765]\n",
      " [0.55813289]\n",
      " [0.56964809]\n",
      " [0.58270401]\n",
      " [0.59691834]\n",
      " [0.71445176]\n",
      " [0.57539052]\n",
      " [0.58445549]] | y: 0.6993413405656723 | Predicción actual: [[0.595571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01135510765016079, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55813289]\n",
      " [0.56964809]\n",
      " [0.58270401]\n",
      " [0.59691834]\n",
      " [0.71445176]\n",
      " [0.57539052]\n",
      " [0.58445549]\n",
      " [0.59557098]] | y: 0.7373111197210385 | Predicción actual: [[0.6077139]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025744082406163216, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56964809]\n",
      " [0.58270401]\n",
      " [0.59691834]\n",
      " [0.71445176]\n",
      " [0.57539052]\n",
      " [0.58445549]\n",
      " [0.59557098]\n",
      " [0.60771388]] | y: 0.7214258039519565 | Predicción actual: [[0.61983776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010035650338977575, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58270401]\n",
      " [0.59691834]\n",
      " [0.71445176]\n",
      " [0.57539052]\n",
      " [0.58445549]\n",
      " [0.59557098]\n",
      " [0.60771388]\n",
      " [0.61983776]] | y: 0.7187136768694304 | Predicción actual: [[0.63073194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028856106102466583, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59691834]\n",
      " [0.71445176]\n",
      " [0.57539052]\n",
      " [0.58445549]\n",
      " [0.59557098]\n",
      " [0.60771388]\n",
      " [0.61983776]\n",
      " [0.63073194]] | y: 0.6741573033707864 | Predicción actual: [[0.63957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002032631542533636, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.57539052]\n",
      " [0.58445549]\n",
      " [0.59557098]\n",
      " [0.60771388]\n",
      " [0.61983776]\n",
      " [0.63073194]\n",
      " [0.63957   ]] | y: 0.698566447113522 | Predicción actual: [[0.6454472]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.748414696427062e-05, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57539052]\n",
      " [0.58445549]\n",
      " [0.59557098]\n",
      " [0.60771388]\n",
      " [0.61983776]\n",
      " [0.63073194]\n",
      " [0.63957   ]\n",
      " [0.64544719]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003129173768684268, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58445549]\n",
      " [0.59557098]\n",
      " [0.60771388]\n",
      " [0.61983776]\n",
      " [0.63073194]\n",
      " [0.63957   ]\n",
      " [0.64544719]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6298367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033306121826171875, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59557098]\n",
      " [0.60771388]\n",
      " [0.61983776]\n",
      " [0.63073194]\n",
      " [0.63957   ]\n",
      " [0.64544719]\n",
      " [0.72103836]\n",
      " [0.62983668]] | y: 0.7562960092987214 | Predicción actual: [[0.6411646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024443073198199272, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60771388]\n",
      " [0.61983776]\n",
      " [0.63073194]\n",
      " [0.63957   ]\n",
      " [0.64544719]\n",
      " [0.72103836]\n",
      " [0.62983668]\n",
      " [0.6411646 ]] | y: 0.8275862068965516 | Predicción actual: [[0.65249515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051512762904167175, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61983776]\n",
      " [0.63073194]\n",
      " [0.63957   ]\n",
      " [0.64544719]\n",
      " [0.72103836]\n",
      " [0.62983668]\n",
      " [0.6411646 ]\n",
      " [0.65249515]] | y: 0.8388221619527314 | Predicción actual: [[0.66313654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013238330371677876, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63073194]\n",
      " [0.63957   ]\n",
      " [0.64544719]\n",
      " [0.72103836]\n",
      " [0.62983668]\n",
      " [0.6411646 ]\n",
      " [0.65249515]\n",
      " [0.66313654]] | y: 0.7942657884540876 | Predicción actual: [[0.67245376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.0180693506263196e-05, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63957   ]\n",
      " [0.64544719]\n",
      " [0.72103836]\n",
      " [0.62983668]\n",
      " [0.6411646 ]\n",
      " [0.65249515]\n",
      " [0.66313654]\n",
      " [0.67245376]] | y: 0.7838047268500579 | Predicción actual: [[0.6801347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019171182066202164, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64544719]\n",
      " [0.72103836]\n",
      " [0.62983668]\n",
      " [0.6411646 ]\n",
      " [0.65249515]\n",
      " [0.66313654]\n",
      " [0.67245376]\n",
      " [0.68013471]] | y: 0.7679194110809764 | Predicción actual: [[0.6865852]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011043662205338478, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62983668]\n",
      " [0.6411646 ]\n",
      " [0.65249515]\n",
      " [0.66313654]\n",
      " [0.67245376]\n",
      " [0.68013471]\n",
      " [0.68658519]] | y: 0.7845796203022084 | Predicción actual: [[0.6924055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002706435276195407, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62983668]\n",
      " [0.6411646 ]\n",
      " [0.65249515]\n",
      " [0.66313654]\n",
      " [0.67245376]\n",
      " [0.68013471]\n",
      " [0.68658519]\n",
      " [0.69240552]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009084286168217659, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6411646 ]\n",
      " [0.65249515]\n",
      " [0.66313654]\n",
      " [0.67245376]\n",
      " [0.68013471]\n",
      " [0.68658519]\n",
      " [0.69240552]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6890402]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010417172685265541, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65249515]\n",
      " [0.66313654]\n",
      " [0.67245376]\n",
      " [0.68013471]\n",
      " [0.68658519]\n",
      " [0.69240552]\n",
      " [0.87872917]\n",
      " [0.68904018]] | y: 0.8488957768306855 | Predicción actual: [[0.70153356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006675936747342348, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66313654]\n",
      " [0.67245376]\n",
      " [0.68013471]\n",
      " [0.68658519]\n",
      " [0.69240552]\n",
      " [0.87872917]\n",
      " [0.68904018]\n",
      " [0.70153356]] | y: 0.8182874854707476 | Predicción actual: [[0.71476364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008998965844511986, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67245376]\n",
      " [0.68013471]\n",
      " [0.68658519]\n",
      " [0.69240552]\n",
      " [0.87872917]\n",
      " [0.68904018]\n",
      " [0.70153356]\n",
      " [0.71476364]] | y: 0.8268113134444013 | Predicción actual: [[0.7285151]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06844854354858398, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68013471]\n",
      " [0.68658519]\n",
      " [0.69240552]\n",
      " [0.87872917]\n",
      " [0.68904018]\n",
      " [0.70153356]\n",
      " [0.71476364]\n",
      " [0.72851509]] | y: 0.7853545137543589 | Predicción actual: [[0.7428008]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00152141647413373, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68658519]\n",
      " [0.69240552]\n",
      " [0.87872917]\n",
      " [0.68904018]\n",
      " [0.70153356]\n",
      " [0.71476364]\n",
      " [0.72851509]\n",
      " [0.74280077]] | y: 0.7892289810151103 | Predicción actual: [[0.7572092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002764919539913535, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69240552]\n",
      " [0.87872917]\n",
      " [0.68904018]\n",
      " [0.70153356]\n",
      " [0.71476364]\n",
      " [0.72851509]\n",
      " [0.74280077]\n",
      " [0.75720918]] | y: 0.8341728012398295 | Predicción actual: [[0.7716778]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015355684445239604, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.68904018]\n",
      " [0.70153356]\n",
      " [0.71476364]\n",
      " [0.72851509]\n",
      " [0.74280077]\n",
      " [0.75720918]\n",
      " [0.77167779]] | y: 0.8124757845796202 | Predicción actual: [[0.7862384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002437237184494734, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68904018]\n",
      " [0.70153356]\n",
      " [0.71476364]\n",
      " [0.72851509]\n",
      " [0.74280077]\n",
      " [0.75720918]\n",
      " [0.77167779]\n",
      " [0.78623837]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003032008244190365, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70153356]\n",
      " [0.71476364]\n",
      " [0.72851509]\n",
      " [0.74280077]\n",
      " [0.75720918]\n",
      " [0.77167779]\n",
      " [0.78623837]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7596778]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.340481372215436e-07, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71476364]\n",
      " [0.72851509]\n",
      " [0.74280077]\n",
      " [0.75720918]\n",
      " [0.77167779]\n",
      " [0.78623837]\n",
      " [0.80123983]\n",
      " [0.75967783]] | y: 0.793490895001937 | Predicción actual: [[0.77314556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017171755898743868, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72851509]\n",
      " [0.74280077]\n",
      " [0.75720918]\n",
      " [0.77167779]\n",
      " [0.78623837]\n",
      " [0.80123983]\n",
      " [0.75967783]\n",
      " [0.77314556]] | y: 0.760170476559473 | Predicción actual: [[0.786085]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00035088378353975713, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74280077]\n",
      " [0.75720918]\n",
      " [0.77167779]\n",
      " [0.78623837]\n",
      " [0.80123983]\n",
      " [0.75967783]\n",
      " [0.77314556]\n",
      " [0.78608501]] | y: 0.7353738860906625 | Predicción actual: [[0.7976935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016487957909703255, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75720918]\n",
      " [0.77167779]\n",
      " [0.78623837]\n",
      " [0.80123983]\n",
      " [0.75967783]\n",
      " [0.77314556]\n",
      " [0.78608501]\n",
      " [0.79769349]] | y: 0.7101898488957767 | Predicción actual: [[0.8073547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015678316354751587, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77167779]\n",
      " [0.78623837]\n",
      " [0.80123983]\n",
      " [0.75967783]\n",
      " [0.77314556]\n",
      " [0.78608501]\n",
      " [0.79769349]\n",
      " [0.80735469]] | y: 0.7121270825261525 | Predicción actual: [[0.8142265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00719136418774724, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78623837]\n",
      " [0.80123983]\n",
      " [0.75967783]\n",
      " [0.77314556]\n",
      " [0.78608501]\n",
      " [0.79769349]\n",
      " [0.80735469]\n",
      " [0.81422651]] | y: 0.7396358000774894 | Predicción actual: [[0.8179984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005141627043485641, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.75967783]\n",
      " [0.77314556]\n",
      " [0.78608501]\n",
      " [0.79769349]\n",
      " [0.80735469]\n",
      " [0.81422651]\n",
      " [0.81799841]] | y: 0.7361487795428128 | Predicción actual: [[0.81849766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023502986878156662, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75967783]\n",
      " [0.77314556]\n",
      " [0.78608501]\n",
      " [0.79769349]\n",
      " [0.80735469]\n",
      " [0.81422651]\n",
      " [0.81799841]\n",
      " [0.81849766]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005627135280519724, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77314556]\n",
      " [0.78608501]\n",
      " [0.79769349]\n",
      " [0.80735469]\n",
      " [0.81422651]\n",
      " [0.81799841]\n",
      " [0.81849766]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8243924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.632210478419438e-05, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78608501]\n",
      " [0.79769349]\n",
      " [0.80735469]\n",
      " [0.81422651]\n",
      " [0.81799841]\n",
      " [0.81849766]\n",
      " [0.66757071]\n",
      " [0.82439238]] | y: 0.696629213483146 | Predicción actual: [[0.83069843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002239950466901064, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79769349]\n",
      " [0.80735469]\n",
      " [0.81422651]\n",
      " [0.81799841]\n",
      " [0.81849766]\n",
      " [0.66757071]\n",
      " [0.82439238]\n",
      " [0.83069843]] | y: 0.6559473072452537 | Predicción actual: [[0.8335404]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05763291195034981, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80735469]\n",
      " [0.81422651]\n",
      " [0.81799841]\n",
      " [0.81849766]\n",
      " [0.66757071]\n",
      " [0.82439238]\n",
      " [0.83069843]\n",
      " [0.83354038]] | y: 0.6788066640836885 | Predicción actual: [[0.832594]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021067019551992416, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81422651]\n",
      " [0.81799841]\n",
      " [0.81849766]\n",
      " [0.66757071]\n",
      " [0.82439238]\n",
      " [0.83069843]\n",
      " [0.83354038]\n",
      " [0.83259398]] | y: 0.6760945370011622 | Predicción actual: [[0.82868916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06554282456636429, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81799841]\n",
      " [0.81849766]\n",
      " [0.66757071]\n",
      " [0.82439238]\n",
      " [0.83069843]\n",
      " [0.83354038]\n",
      " [0.83259398]\n",
      " [0.82868916]] | y: 0.7295621851995349 | Predicción actual: [[0.8226034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025725876912474632, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81849766]\n",
      " [0.66757071]\n",
      " [0.82439238]\n",
      " [0.83069843]\n",
      " [0.83354038]\n",
      " [0.83259398]\n",
      " [0.82868916]\n",
      " [0.8226034 ]] | y: 0.7012785741960481 | Predicción actual: [[0.81585807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017119184136390686, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.82439238]\n",
      " [0.83069843]\n",
      " [0.83354038]\n",
      " [0.83259398]\n",
      " [0.82868916]\n",
      " [0.8226034 ]\n",
      " [0.81585807]] | y: 0.767531964354901 | Predicción actual: [[0.8098979]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014194829389452934, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82439238]\n",
      " [0.83069843]\n",
      " [0.83354038]\n",
      " [0.83259398]\n",
      " [0.82868916]\n",
      " [0.8226034 ]\n",
      " [0.81585807]\n",
      " [0.8098979 ]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011542007327079773, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83069843]\n",
      " [0.83354038]\n",
      " [0.83259398]\n",
      " [0.82868916]\n",
      " [0.8226034 ]\n",
      " [0.81585807]\n",
      " [0.8098979 ]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.84929305]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0396852120757103, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83354038]\n",
      " [0.83259398]\n",
      " [0.82868916]\n",
      " [0.8226034 ]\n",
      " [0.81585807]\n",
      " [0.8098979 ]\n",
      " [0.75513367]\n",
      " [0.84929305]] | y: 0.7520340953118947 | Predicción actual: [[0.844748]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013279290869832039, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83259398]\n",
      " [0.82868916]\n",
      " [0.8226034 ]\n",
      " [0.81585807]\n",
      " [0.8098979 ]\n",
      " [0.75513367]\n",
      " [0.84929305]\n",
      " [0.84474802]] | y: 0.7098024021697016 | Predicción actual: [[0.83846915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01735234260559082, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82868916]\n",
      " [0.8226034 ]\n",
      " [0.81585807]\n",
      " [0.8098979 ]\n",
      " [0.75513367]\n",
      " [0.84929305]\n",
      " [0.84474802]\n",
      " [0.83846915]] | y: 0.6904300658659435 | Predicción actual: [[0.83180803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06076481565833092, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8226034 ]\n",
      " [0.81585807]\n",
      " [0.8098979 ]\n",
      " [0.75513367]\n",
      " [0.84929305]\n",
      " [0.84474802]\n",
      " [0.83846915]\n",
      " [0.83180803]] | y: 0.7543587756683454 | Predicción actual: [[0.8257986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019199228845536709, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81585807]\n",
      " [0.8098979 ]\n",
      " [0.75513367]\n",
      " [0.84929305]\n",
      " [0.84474802]\n",
      " [0.83846915]\n",
      " [0.83180803]\n",
      " [0.82579857]] | y: 0.7222006974041069 | Predicción actual: [[0.82200414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000984719255939126, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8098979 ]\n",
      " [0.75513367]\n",
      " [0.84929305]\n",
      " [0.84474802]\n",
      " [0.83846915]\n",
      " [0.83180803]\n",
      " [0.82579857]\n",
      " [0.82200414]] | y: 0.8485083301046106 | Predicción actual: [[0.8210089]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010017154738307, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.84929305]\n",
      " [0.84474802]\n",
      " [0.83846915]\n",
      " [0.83180803]\n",
      " [0.82579857]\n",
      " [0.82200414]\n",
      " [0.82100892]] | y: 0.9054629988376597 | Predicción actual: [[0.823036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010407230583950877, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84929305]\n",
      " [0.84474802]\n",
      " [0.83846915]\n",
      " [0.83180803]\n",
      " [0.82579857]\n",
      " [0.82200414]\n",
      " [0.82100892]\n",
      " [0.82303602]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00040099883335642517, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84474802]\n",
      " [0.83846915]\n",
      " [0.83180803]\n",
      " [0.82579857]\n",
      " [0.82200414]\n",
      " [0.82100892]\n",
      " [0.82303602]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.83651996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016704758629202843, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83846915]\n",
      " [0.83180803]\n",
      " [0.82579857]\n",
      " [0.82200414]\n",
      " [0.82100892]\n",
      " [0.82303602]\n",
      " [0.8822162 ]\n",
      " [0.83651996]] | y: 0.889577683068578 | Predicción actual: [[0.83181804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004042027052491903, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83180803]\n",
      " [0.82579857]\n",
      " [0.82200414]\n",
      " [0.82100892]\n",
      " [0.82303602]\n",
      " [0.8822162 ]\n",
      " [0.83651996]\n",
      " [0.83181804]] | y: 0.8748547074777218 | Predicción actual: [[0.8288086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005844355095177889, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82579857]\n",
      " [0.82200414]\n",
      " [0.82100892]\n",
      " [0.82303602]\n",
      " [0.8822162 ]\n",
      " [0.83651996]\n",
      " [0.83181804]\n",
      " [0.82880861]] | y: 0.9132119333591631 | Predicción actual: [[0.8278968]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050890978425741196, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82200414]\n",
      " [0.82100892]\n",
      " [0.82303602]\n",
      " [0.8822162 ]\n",
      " [0.83651996]\n",
      " [0.83181804]\n",
      " [0.82880861]\n",
      " [0.82789677]] | y: 1.0 | Predicción actual: [[0.82963145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09807892888784409, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82100892]\n",
      " [0.82303602]\n",
      " [0.8822162 ]\n",
      " [0.83651996]\n",
      " [0.83181804]\n",
      " [0.82880861]\n",
      " [0.82789677]\n",
      " [0.82963145]] | y: 0.9705540488182873 | Predicción actual: [[0.83353204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0040258620865643024, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82303602]\n",
      " [0.8822162 ]\n",
      " [0.83651996]\n",
      " [0.83181804]\n",
      " [0.82880861]\n",
      " [0.82789677]\n",
      " [0.82963145]\n",
      " [0.83353204]] | y: 0.8888027896164277 | Predicción actual: [[0.8380109]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05521926283836365, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.83651996]\n",
      " [0.83181804]\n",
      " [0.82880861]\n",
      " [0.82789677]\n",
      " [0.82963145]\n",
      " [0.83353204]\n",
      " [0.83801091]] | y: 0.877954281286323 | Predicción actual: [[0.84253955]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006075450219213963, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83651996]\n",
      " [0.83181804]\n",
      " [0.82880861]\n",
      " [0.82789677]\n",
      " [0.82963145]\n",
      " [0.83353204]\n",
      " [0.83801091]\n",
      " [0.84253955]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01031202357262373, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83181804]\n",
      " [0.82880861]\n",
      " [0.82789677]\n",
      " [0.82963145]\n",
      " [0.83353204]\n",
      " [0.83801091]\n",
      " [0.84253955]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.82815486]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.461457936282386e-06, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82880861]\n",
      " [0.82789677]\n",
      " [0.82963145]\n",
      " [0.83353204]\n",
      " [0.83801091]\n",
      " [0.84253955]\n",
      " [0.84889578]\n",
      " [0.82815486]] | y: 0.8550949244478885 | Predicción actual: [[0.8283819]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02163771726191044, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82789677]\n",
      " [0.82963145]\n",
      " [0.83353204]\n",
      " [0.83801091]\n",
      " [0.84253955]\n",
      " [0.84889578]\n",
      " [0.82815486]\n",
      " [0.8283819 ]] | y: 0.8752421542037967 | Predicción actual: [[0.83005875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02365262806415558, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82963145]\n",
      " [0.83353204]\n",
      " [0.83801091]\n",
      " [0.84253955]\n",
      " [0.84889578]\n",
      " [0.82815486]\n",
      " [0.8283819 ]\n",
      " [0.83005875]] | y: 0.857032158078264 | Predicción actual: [[0.8325778]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004102923907339573, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83353204]\n",
      " [0.83801091]\n",
      " [0.84253955]\n",
      " [0.84889578]\n",
      " [0.82815486]\n",
      " [0.8283819 ]\n",
      " [0.83005875]\n",
      " [0.83257782]] | y: 0.8500581170089112 | Predicción actual: [[0.83490443]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005438775289803743, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83801091]\n",
      " [0.84253955]\n",
      " [0.84889578]\n",
      " [0.82815486]\n",
      " [0.8283819 ]\n",
      " [0.83005875]\n",
      " [0.83257782]\n",
      " [0.83490443]] | y: 0.8426966292134832 | Predicción actual: [[0.8362389]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001426376838935539, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84253955]\n",
      " [0.84889578]\n",
      " [0.82815486]\n",
      " [0.8283819 ]\n",
      " [0.83005875]\n",
      " [0.83257782]\n",
      " [0.83490443]\n",
      " [0.83623892]] | y: 0.8229368461836497 | Predicción actual: [[0.8360427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026141181588172913, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.82815486]\n",
      " [0.8283819 ]\n",
      " [0.83005875]\n",
      " [0.83257782]\n",
      " [0.83490443]\n",
      " [0.83623892]\n",
      " [0.8360427 ]] | y: 0.7745060054242543 | Predicción actual: [[0.83427215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.613990212325007e-05, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82815486]\n",
      " [0.8283819 ]\n",
      " [0.83005875]\n",
      " [0.83257782]\n",
      " [0.83490443]\n",
      " [0.83623892]\n",
      " [0.8360427 ]\n",
      " [0.83427215]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015789285534992814, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8283819 ]\n",
      " [0.83005875]\n",
      " [0.83257782]\n",
      " [0.83490443]\n",
      " [0.83623892]\n",
      " [0.8360427 ]\n",
      " [0.83427215]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.83136415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01063778530806303, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83005875]\n",
      " [0.83257782]\n",
      " [0.83490443]\n",
      " [0.83623892]\n",
      " [0.8360427 ]\n",
      " [0.83427215]\n",
      " [0.78419217]\n",
      " [0.83136415]] | y: 0.854320030995738 | Predicción actual: [[0.8324605]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003731550183147192, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83257782]\n",
      " [0.83490443]\n",
      " [0.83623892]\n",
      " [0.8360427 ]\n",
      " [0.83427215]\n",
      " [0.78419217]\n",
      " [0.83136415]\n",
      " [0.83246052]] | y: 0.8368849283223556 | Predicción actual: [[0.83285356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008064639754593372, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83490443]\n",
      " [0.83623892]\n",
      " [0.8360427 ]\n",
      " [0.83427215]\n",
      " [0.78419217]\n",
      " [0.83136415]\n",
      " [0.83246052]\n",
      " [0.83285356]] | y: 0.8299108872530028 | Predicción actual: [[0.8319036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.8141023474527174e-06, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83623892]\n",
      " [0.8360427 ]\n",
      " [0.83427215]\n",
      " [0.78419217]\n",
      " [0.83136415]\n",
      " [0.83246052]\n",
      " [0.83285356]\n",
      " [0.83190358]] | y: 0.887253002712127 | Predicción actual: [[0.82986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007376548834145069, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8360427 ]\n",
      " [0.83427215]\n",
      " [0.78419217]\n",
      " [0.83136415]\n",
      " [0.83246052]\n",
      " [0.83285356]\n",
      " [0.83190358]\n",
      " [0.82985997]] | y: 0.8597442851607902 | Predicción actual: [[0.8272103]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.3119926052240771e-06, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83427215]\n",
      " [0.78419217]\n",
      " [0.83136415]\n",
      " [0.83246052]\n",
      " [0.83285356]\n",
      " [0.83190358]\n",
      " [0.82985997]\n",
      " [0.82721031]] | y: 0.8395970554048819 | Predicción actual: [[0.8243325]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00389462080784142, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.83136415]\n",
      " [0.83246052]\n",
      " [0.83285356]\n",
      " [0.83190358]\n",
      " [0.82985997]\n",
      " [0.82721031]\n",
      " [0.82433248]] | y: 0.7838047268500579 | Predicción actual: [[0.8219548]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008086171932518482, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83136415]\n",
      " [0.83246052]\n",
      " [0.83285356]\n",
      " [0.83190358]\n",
      " [0.82985997]\n",
      " [0.82721031]\n",
      " [0.82433248]\n",
      " [0.82195479]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011548518668860197, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83246052]\n",
      " [0.83285356]\n",
      " [0.83190358]\n",
      " [0.82985997]\n",
      " [0.82721031]\n",
      " [0.82433248]\n",
      " [0.82195479]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8345357]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01277865469455719, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83285356]\n",
      " [0.83190358]\n",
      " [0.82985997]\n",
      " [0.82721031]\n",
      " [0.82433248]\n",
      " [0.82195479]\n",
      " [0.81828749]\n",
      " [0.83453572]] | y: 0.7605579232855482 | Predicción actual: [[0.8335522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01153524685651064, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83190358]\n",
      " [0.82985997]\n",
      " [0.82721031]\n",
      " [0.82433248]\n",
      " [0.82195479]\n",
      " [0.81828749]\n",
      " [0.83453572]\n",
      " [0.83355218]] | y: 0.7915536613715615 | Predicción actual: [[0.83192885]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.653008313151076e-05, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82985997]\n",
      " [0.82721031]\n",
      " [0.82433248]\n",
      " [0.82195479]\n",
      " [0.81828749]\n",
      " [0.83453572]\n",
      " [0.83355218]\n",
      " [0.83192885]] | y: 0.7686943045331267 | Predicción actual: [[0.83037007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011782386573031545, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82721031]\n",
      " [0.82433248]\n",
      " [0.82195479]\n",
      " [0.81828749]\n",
      " [0.83453572]\n",
      " [0.83355218]\n",
      " [0.83192885]\n",
      " [0.83037007]] | y: 0.7686943045331267 | Predicción actual: [[0.8292892]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024265538901090622, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82433248]\n",
      " [0.82195479]\n",
      " [0.81828749]\n",
      " [0.83453572]\n",
      " [0.83355218]\n",
      " [0.83192885]\n",
      " [0.83037007]\n",
      " [0.8292892 ]] | y: 0.7989151491669895 | Predicción actual: [[0.8287611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.941713970969431e-05, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82195479]\n",
      " [0.81828749]\n",
      " [0.83453572]\n",
      " [0.83355218]\n",
      " [0.83192885]\n",
      " [0.83037007]\n",
      " [0.8292892 ]\n",
      " [0.8287611 ]] | y: 0.7900038744672608 | Predicción actual: [[0.8293636]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02187010459601879, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.83453572]\n",
      " [0.83355218]\n",
      " [0.83192885]\n",
      " [0.83037007]\n",
      " [0.8292892 ]\n",
      " [0.8287611 ]\n",
      " [0.82936358]] | y: 0.760170476559473 | Predicción actual: [[0.83124185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003515486838296056, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83453572]\n",
      " [0.83355218]\n",
      " [0.83192885]\n",
      " [0.83037007]\n",
      " [0.8292892 ]\n",
      " [0.8287611 ]\n",
      " [0.82936358]\n",
      " [0.83124185]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007495822501368821, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83355218]\n",
      " [0.83192885]\n",
      " [0.83037007]\n",
      " [0.8292892 ]\n",
      " [0.8287611 ]\n",
      " [0.82936358]\n",
      " [0.83124185]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.83223575]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.2375674694776535, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83192885]\n",
      " [0.83037007]\n",
      " [0.8292892 ]\n",
      " [0.8287611 ]\n",
      " [0.82936358]\n",
      " [0.83124185]\n",
      " [0.68539326]\n",
      " [0.83223575]] | y: 0.6648585819449826 | Predicción actual: [[0.827599]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033817128278315067, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83037007]\n",
      " [0.8292892 ]\n",
      " [0.8287611 ]\n",
      " [0.82936358]\n",
      " [0.83124185]\n",
      " [0.68539326]\n",
      " [0.83223575]\n",
      " [0.82759899]] | y: 0.7078651685393258 | Predicción actual: [[0.8219222]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020727192983031273, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8292892 ]\n",
      " [0.8287611 ]\n",
      " [0.82936358]\n",
      " [0.83124185]\n",
      " [0.68539326]\n",
      " [0.83223575]\n",
      " [0.82759899]\n",
      " [0.82192218]] | y: 0.6648585819449826 | Predicción actual: [[0.8151546]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03351619839668274, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8287611 ]\n",
      " [0.82936358]\n",
      " [0.83124185]\n",
      " [0.68539326]\n",
      " [0.83223575]\n",
      " [0.82759899]\n",
      " [0.82192218]\n",
      " [0.81515461]] | y: 0.7113521890740022 | Predicción actual: [[0.8073757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0956762284040451, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82936358]\n",
      " [0.83124185]\n",
      " [0.68539326]\n",
      " [0.83223575]\n",
      " [0.82759899]\n",
      " [0.82192218]\n",
      " [0.81515461]\n",
      " [0.80737573]] | y: 0.6772568771793879 | Predicción actual: [[0.79840875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008245578967034817, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83124185]\n",
      " [0.68539326]\n",
      " [0.83223575]\n",
      " [0.82759899]\n",
      " [0.82192218]\n",
      " [0.81515461]\n",
      " [0.80737573]\n",
      " [0.79840875]] | y: 0.7621077101898488 | Predicción actual: [[0.7887778]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017968734726309776, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.83223575]\n",
      " [0.82759899]\n",
      " [0.82192218]\n",
      " [0.81515461]\n",
      " [0.80737573]\n",
      " [0.79840875]\n",
      " [0.78877783]] | y: 0.8070515304145678 | Predicción actual: [[0.7781823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02034987509250641, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83223575]\n",
      " [0.82759899]\n",
      " [0.82192218]\n",
      " [0.81515461]\n",
      " [0.80737573]\n",
      " [0.79840875]\n",
      " [0.78877783]\n",
      " [0.77818233]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002458026399835944, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82759899]\n",
      " [0.82192218]\n",
      " [0.81515461]\n",
      " [0.80737573]\n",
      " [0.79840875]\n",
      " [0.78877783]\n",
      " [0.77818233]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.80248016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0223255418241024, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82192218]\n",
      " [0.81515461]\n",
      " [0.80737573]\n",
      " [0.79840875]\n",
      " [0.78877783]\n",
      " [0.77818233]\n",
      " [0.81518791]\n",
      " [0.80248016]] | y: 0.9597055404881829 | Predicción actual: [[0.7955534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03513870760798454, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81515461]\n",
      " [0.80737573]\n",
      " [0.79840875]\n",
      " [0.78877783]\n",
      " [0.77818233]\n",
      " [0.81518791]\n",
      " [0.80248016]\n",
      " [0.79555339]] | y: 0.9643549012010848 | Predicción actual: [[0.78942835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030865509063005447, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80737573]\n",
      " [0.79840875]\n",
      " [0.78877783]\n",
      " [0.77818233]\n",
      " [0.81518791]\n",
      " [0.80248016]\n",
      " [0.79555339]\n",
      " [0.78942835]] | y: 0.8880278961642774 | Predicción actual: [[0.7846107]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02481846511363983, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79840875]\n",
      " [0.78877783]\n",
      " [0.77818233]\n",
      " [0.81518791]\n",
      " [0.80248016]\n",
      " [0.79555339]\n",
      " [0.78942835]\n",
      " [0.78461069]] | y: 0.8926772568771792 | Predicción actual: [[0.78153837]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.3573181806568755e-06, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78877783]\n",
      " [0.77818233]\n",
      " [0.81518791]\n",
      " [0.80248016]\n",
      " [0.79555339]\n",
      " [0.78942835]\n",
      " [0.78461069]\n",
      " [0.78153837]] | y: 0.8752421542037967 | Predicción actual: [[0.7805025]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003467826871201396, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77818233]\n",
      " [0.81518791]\n",
      " [0.80248016]\n",
      " [0.79555339]\n",
      " [0.78942835]\n",
      " [0.78461069]\n",
      " [0.78153837]\n",
      " [0.7805025 ]] | y: 0.8508330104610615 | Predicción actual: [[0.7819787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00037656817585229874, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.80248016]\n",
      " [0.79555339]\n",
      " [0.78942835]\n",
      " [0.78461069]\n",
      " [0.78153837]\n",
      " [0.7805025 ]\n",
      " [0.78197873]] | y: 0.8488957768306855 | Predicción actual: [[0.78631234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04680000618100166, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80248016]\n",
      " [0.79555339]\n",
      " [0.78942835]\n",
      " [0.78461069]\n",
      " [0.78153837]\n",
      " [0.7805025 ]\n",
      " [0.78197873]\n",
      " [0.78631234]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01516784355044365, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79555339]\n",
      " [0.78942835]\n",
      " [0.78461069]\n",
      " [0.78153837]\n",
      " [0.7805025 ]\n",
      " [0.78197873]\n",
      " [0.78631234]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.77779937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02042454667389393, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78942835]\n",
      " [0.78461069]\n",
      " [0.78153837]\n",
      " [0.7805025 ]\n",
      " [0.78197873]\n",
      " [0.78631234]\n",
      " [0.96241767]\n",
      " [0.77779937]] | y: 0.9407206509104997 | Predicción actual: [[0.77836263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019807808101177216, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78461069]\n",
      " [0.78153837]\n",
      " [0.7805025 ]\n",
      " [0.78197873]\n",
      " [0.78631234]\n",
      " [0.96241767]\n",
      " [0.77779937]\n",
      " [0.77836263]] | y: 0.9724912824486633 | Predicción actual: [[0.78204596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019228633493185043, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78153837]\n",
      " [0.7805025 ]\n",
      " [0.78197873]\n",
      " [0.78631234]\n",
      " [0.96241767]\n",
      " [0.77779937]\n",
      " [0.77836263]\n",
      " [0.78204596]] | y: 0.9969004261913985 | Predicción actual: [[0.7885653]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055975403636693954, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7805025 ]\n",
      " [0.78197873]\n",
      " [0.78631234]\n",
      " [0.96241767]\n",
      " [0.77779937]\n",
      " [0.77836263]\n",
      " [0.78204596]\n",
      " [0.78856528]] | y: 0.951181712514529 | Predicción actual: [[0.7974101]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05761370807886124, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78197873]\n",
      " [0.78631234]\n",
      " [0.96241767]\n",
      " [0.77779937]\n",
      " [0.77836263]\n",
      " [0.78204596]\n",
      " [0.78856528]\n",
      " [0.79741007]] | y: 0.8957768306857805 | Predicción actual: [[0.80765057]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020453041419386864, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78631234]\n",
      " [0.96241767]\n",
      " [0.77779937]\n",
      " [0.77836263]\n",
      " [0.78204596]\n",
      " [0.78856528]\n",
      " [0.79741007]\n",
      " [0.80765057]] | y: 0.8814413018209997 | Predicción actual: [[0.81804246]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011903448030352592, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.77779937]\n",
      " [0.77836263]\n",
      " [0.78204596]\n",
      " [0.78856528]\n",
      " [0.79741007]\n",
      " [0.80765057]\n",
      " [0.81804246]] | y: 0.9170864006199149 | Predicción actual: [[0.8271836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00890288595110178, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77779937]\n",
      " [0.77836263]\n",
      " [0.78204596]\n",
      " [0.78856528]\n",
      " [0.79741007]\n",
      " [0.80765057]\n",
      " [0.81804246]\n",
      " [0.8271836 ]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010907621122896671, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77836263]\n",
      " [0.78204596]\n",
      " [0.78856528]\n",
      " [0.79741007]\n",
      " [0.80765057]\n",
      " [0.81804246]\n",
      " [0.8271836 ]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7911726]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04876537248492241, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78204596]\n",
      " [0.78856528]\n",
      " [0.79741007]\n",
      " [0.80765057]\n",
      " [0.81804246]\n",
      " [0.8271836 ]\n",
      " [0.91979853]\n",
      " [0.79117262]] | y: 0.9682293684618366 | Predicción actual: [[0.80060595]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09394054114818573, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78856528]\n",
      " [0.79741007]\n",
      " [0.80765057]\n",
      " [0.81804246]\n",
      " [0.8271836 ]\n",
      " [0.91979853]\n",
      " [0.79117262]\n",
      " [0.80060595]] | y: 0.9577683068578069 | Predicción actual: [[0.81172544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00528631592169404, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.21455973]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017925508320331573, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21455973]] | y: 0.10422316931421921 | Predicción actual: [[0.1993059]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009994118474423885, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21455973]\n",
      " [0.19930591]] | y: 0.15420379697791559 | Predicción actual: [[0.20370615]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016946290852501988, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21455973]\n",
      " [0.19930591]\n",
      " [0.20370615]] | y: 0.1557535838822161 | Predicción actual: [[0.21562092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0057645863853394985, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21455973]\n",
      " [0.19930591]\n",
      " [0.20370615]\n",
      " [0.21562092]] | y: 0.12553273924835334 | Predicción actual: [[0.22894743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01239759474992752, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21455973]\n",
      " [0.19930591]\n",
      " [0.20370615]\n",
      " [0.21562092]\n",
      " [0.22894743]] | y: 0.1456799690042619 | Predicción actual: [[0.23996213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004950425587594509, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21455973]\n",
      " [0.19930591]\n",
      " [0.20370615]\n",
      " [0.21562092]\n",
      " [0.22894743]\n",
      " [0.23996213]] | y: 0.1464548624564122 | Predicción actual: [[0.26285738]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008018100634217262, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.21455973]\n",
      " [0.19930591]\n",
      " [0.20370615]\n",
      " [0.21562092]\n",
      " [0.22894743]\n",
      " [0.23996213]\n",
      " [0.26285738]] | y: 0.1960480433940332 | Predicción actual: [[0.2912117]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006773116998374462, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21455973]\n",
      " [0.19930591]\n",
      " [0.20370615]\n",
      " [0.21562092]\n",
      " [0.22894743]\n",
      " [0.23996213]\n",
      " [0.26285738]\n",
      " [0.29121169]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022547367960214615, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19930591]\n",
      " [0.20370615]\n",
      " [0.21562092]\n",
      " [0.22894743]\n",
      " [0.23996213]\n",
      " [0.26285738]\n",
      " [0.29121169]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.32796314]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006929297465831041, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20370615]\n",
      " [0.21562092]\n",
      " [0.22894743]\n",
      " [0.23996213]\n",
      " [0.26285738]\n",
      " [0.29121169]\n",
      " [0.2305308 ]\n",
      " [0.32796314]] | y: 0.211933359163115 | Predicción actual: [[0.33555716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019327931106090546, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21562092]\n",
      " [0.22894743]\n",
      " [0.23996213]\n",
      " [0.26285738]\n",
      " [0.29121169]\n",
      " [0.2305308 ]\n",
      " [0.32796314]\n",
      " [0.33555716]] | y: 0.2072839984502131 | Predicción actual: [[0.34505165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03731758892536163, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22894743]\n",
      " [0.23996213]\n",
      " [0.26285738]\n",
      " [0.29121169]\n",
      " [0.2305308 ]\n",
      " [0.32796314]\n",
      " [0.33555716]\n",
      " [0.34505165]] | y: 0.19294846958543205 | Predicción actual: [[0.35517985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026013370603322983, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23996213]\n",
      " [0.26285738]\n",
      " [0.29121169]\n",
      " [0.2305308 ]\n",
      " [0.32796314]\n",
      " [0.33555716]\n",
      " [0.34505165]\n",
      " [0.35517985]] | y: 0.19682293684618352 | Predicción actual: [[0.36586305]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02680829167366028, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.26285738]\n",
      " [0.29121169]\n",
      " [0.2305308 ]\n",
      " [0.32796314]\n",
      " [0.33555716]\n",
      " [0.34505165]\n",
      " [0.35517985]\n",
      " [0.36586305]] | y: 0.21425803951956607 | Predicción actual: [[0.3777778]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021615128964185715, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.29121169]\n",
      " [0.2305308 ]\n",
      " [0.32796314]\n",
      " [0.33555716]\n",
      " [0.34505165]\n",
      " [0.35517985]\n",
      " [0.36586305]\n",
      " [0.37777781]] | y: 0.18132506780317698 | Predicción actual: [[0.3882252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06001799926161766, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.32796314]\n",
      " [0.33555716]\n",
      " [0.34505165]\n",
      " [0.35517985]\n",
      " [0.36586305]\n",
      " [0.37777781]\n",
      " [0.3882252 ]] | y: 0.17512592018597434 | Predicción actual: [[0.39549467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0659317597746849, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32796314]\n",
      " [0.33555716]\n",
      " [0.34505165]\n",
      " [0.35517985]\n",
      " [0.36586305]\n",
      " [0.37777781]\n",
      " [0.3882252 ]\n",
      " [0.39549467]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.14367340505123138, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33555716]\n",
      " [0.34505165]\n",
      " [0.35517985]\n",
      " [0.36586305]\n",
      " [0.37777781]\n",
      " [0.3882252 ]\n",
      " [0.39549467]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.42596832]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06761880964040756, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34505165]\n",
      " [0.35517985]\n",
      " [0.36586305]\n",
      " [0.37777781]\n",
      " [0.3882252 ]\n",
      " [0.39549467]\n",
      " [0.14800465]\n",
      " [0.42596832]] | y: 0.19217357613328173 | Predicción actual: [[0.42973584]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044968586415052414, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35517985]\n",
      " [0.36586305]\n",
      " [0.37777781]\n",
      " [0.3882252 ]\n",
      " [0.39549467]\n",
      " [0.14800465]\n",
      " [0.42596832]\n",
      " [0.42973584]] | y: 0.1859744285160791 | Predicción actual: [[0.43161228]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04710991308093071, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36586305]\n",
      " [0.37777781]\n",
      " [0.3882252 ]\n",
      " [0.39549467]\n",
      " [0.14800465]\n",
      " [0.42596832]\n",
      " [0.42973584]\n",
      " [0.43161228]] | y: 0.26695079426578844 | Predicción actual: [[0.43167123]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020337216556072235, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37777781]\n",
      " [0.3882252 ]\n",
      " [0.39549467]\n",
      " [0.14800465]\n",
      " [0.42596832]\n",
      " [0.42973584]\n",
      " [0.43161228]\n",
      " [0.43167123]] | y: 0.2925222781867493 | Predicción actual: [[0.43018538]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01281487662345171, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3882252 ]\n",
      " [0.39549467]\n",
      " [0.14800465]\n",
      " [0.42596832]\n",
      " [0.42973584]\n",
      " [0.43161228]\n",
      " [0.43167123]\n",
      " [0.43018538]] | y: 0.3177063153816349 | Predicción actual: [[0.42725942]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02300213649868965, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39549467]\n",
      " [0.14800465]\n",
      " [0.42596832]\n",
      " [0.42973584]\n",
      " [0.43161228]\n",
      " [0.43167123]\n",
      " [0.43018538]\n",
      " [0.42725942]] | y: 0.31266950794265785 | Predicción actual: [[0.4235276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024960560724139214, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.42596832]\n",
      " [0.42973584]\n",
      " [0.43161228]\n",
      " [0.43167123]\n",
      " [0.43018538]\n",
      " [0.42725942]\n",
      " [0.4235276 ]] | y: 0.2890352576520729 | Predicción actual: [[0.4199989]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006377357989549637, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42596832]\n",
      " [0.42973584]\n",
      " [0.43161228]\n",
      " [0.43167123]\n",
      " [0.43018538]\n",
      " [0.42725942]\n",
      " [0.4235276 ]\n",
      " [0.41999891]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030119875445961952, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42973584]\n",
      " [0.43161228]\n",
      " [0.43167123]\n",
      " [0.43018538]\n",
      " [0.42725942]\n",
      " [0.4235276 ]\n",
      " [0.41999891]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.47888613]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027077116072177887, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43161228]\n",
      " [0.43167123]\n",
      " [0.43018538]\n",
      " [0.42725942]\n",
      " [0.4235276 ]\n",
      " [0.41999891]\n",
      " [0.28283611]\n",
      " [0.47888613]] | y: 0.2758620689655173 | Predicción actual: [[0.47597477]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05466543510556221, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43167123]\n",
      " [0.43018538]\n",
      " [0.42725942]\n",
      " [0.4235276 ]\n",
      " [0.41999891]\n",
      " [0.28283611]\n",
      " [0.47888613]\n",
      " [0.47597477]] | y: 0.2746997287872917 | Predicción actual: [[0.47181478]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050611719489097595, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43018538]\n",
      " [0.42725942]\n",
      " [0.4235276 ]\n",
      " [0.41999891]\n",
      " [0.28283611]\n",
      " [0.47888613]\n",
      " [0.47597477]\n",
      " [0.47181478]] | y: 0.275474622239442 | Predicción actual: [[0.4673851]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03629177808761597, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42725942]\n",
      " [0.4235276 ]\n",
      " [0.41999891]\n",
      " [0.28283611]\n",
      " [0.47888613]\n",
      " [0.47597477]\n",
      " [0.47181478]\n",
      " [0.46738511]] | y: 0.3347539713289423 | Predicción actual: [[0.46373636]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00903328601270914, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4235276 ]\n",
      " [0.41999891]\n",
      " [0.28283611]\n",
      " [0.47888613]\n",
      " [0.47597477]\n",
      " [0.47181478]\n",
      " [0.46738511]\n",
      " [0.46373636]] | y: 0.35567609453700116 | Predicción actual: [[0.46189907]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03188292309641838, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41999891]\n",
      " [0.28283611]\n",
      " [0.47888613]\n",
      " [0.47597477]\n",
      " [0.47181478]\n",
      " [0.46738511]\n",
      " [0.46373636]\n",
      " [0.46189907]] | y: 0.3366912049593181 | Predicción actual: [[0.46251798]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02523440681397915, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.47888613]\n",
      " [0.47597477]\n",
      " [0.47181478]\n",
      " [0.46738511]\n",
      " [0.46373636]\n",
      " [0.46189907]\n",
      " [0.46251798]] | y: 0.3335916311507167 | Predicción actual: [[0.46595722]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011207247152924538, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47888613]\n",
      " [0.47597477]\n",
      " [0.47181478]\n",
      " [0.46738511]\n",
      " [0.46373636]\n",
      " [0.46189907]\n",
      " [0.46251798]\n",
      " [0.46595722]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016528433188796043, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47597477]\n",
      " [0.47181478]\n",
      " [0.46738511]\n",
      " [0.46373636]\n",
      " [0.46189907]\n",
      " [0.46251798]\n",
      " [0.46595722]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.502189]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007925109821371734, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47181478]\n",
      " [0.46738511]\n",
      " [0.46373636]\n",
      " [0.46189907]\n",
      " [0.46251798]\n",
      " [0.46595722]\n",
      " [0.3847346 ]\n",
      " [0.50218898]] | y: 0.5962805114296785 | Predicción actual: [[0.49811444]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006869048345834017, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46738511]\n",
      " [0.46373636]\n",
      " [0.46189907]\n",
      " [0.46251798]\n",
      " [0.46595722]\n",
      " [0.3847346 ]\n",
      " [0.50218898]\n",
      " [0.49811444]] | y: 0.574583494769469 | Predicción actual: [[0.4946584]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026628002524375916, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46373636]\n",
      " [0.46189907]\n",
      " [0.46251798]\n",
      " [0.46595722]\n",
      " [0.3847346 ]\n",
      " [0.50218898]\n",
      " [0.49811444]\n",
      " [0.49465841]] | y: 0.6063541263076326 | Predicción actual: [[0.49241874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01737385429441929, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46189907]\n",
      " [0.46251798]\n",
      " [0.46595722]\n",
      " [0.3847346 ]\n",
      " [0.50218898]\n",
      " [0.49811444]\n",
      " [0.49465841]\n",
      " [0.49241874]] | y: 0.5846571096474236 | Predicción actual: [[0.4916992]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017517892410978675, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46251798]\n",
      " [0.46595722]\n",
      " [0.3847346 ]\n",
      " [0.50218898]\n",
      " [0.49811444]\n",
      " [0.49465841]\n",
      " [0.49241874]\n",
      " [0.49169919]] | y: 0.5687717938783416 | Predicción actual: [[0.49241623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018536661518737674, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46595722]\n",
      " [0.3847346 ]\n",
      " [0.50218898]\n",
      " [0.49811444]\n",
      " [0.49465841]\n",
      " [0.49241874]\n",
      " [0.49169919]\n",
      " [0.49241623]] | y: 0.6427741185586981 | Predicción actual: [[0.4942499]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049130797386169434, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.50218898]\n",
      " [0.49811444]\n",
      " [0.49465841]\n",
      " [0.49241874]\n",
      " [0.49169919]\n",
      " [0.49241623]\n",
      " [0.49424991]] | y: 0.6617590081363811 | Predicción actual: [[0.4967332]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048341743648052216, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50218898]\n",
      " [0.49811444]\n",
      " [0.49465841]\n",
      " [0.49241874]\n",
      " [0.49169919]\n",
      " [0.49241623]\n",
      " [0.49424991]\n",
      " [0.49673319]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03638870269060135, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49811444]\n",
      " [0.49465841]\n",
      " [0.49241874]\n",
      " [0.49169919]\n",
      " [0.49241623]\n",
      " [0.49424991]\n",
      " [0.49673319]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5208047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020302338525652885, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49465841]\n",
      " [0.49241874]\n",
      " [0.49169919]\n",
      " [0.49241623]\n",
      " [0.49424991]\n",
      " [0.49673319]\n",
      " [0.67299496]\n",
      " [0.5208047 ]] | y: 0.703990701278574 | Predicción actual: [[0.52271473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020688647404313087, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49241874]\n",
      " [0.49169919]\n",
      " [0.49241623]\n",
      " [0.49424991]\n",
      " [0.49673319]\n",
      " [0.67299496]\n",
      " [0.5208047 ]\n",
      " [0.52271473]] | y: 0.7272375048430839 | Predicción actual: [[0.5274426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0329848937690258, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49169919]\n",
      " [0.49241623]\n",
      " [0.49424991]\n",
      " [0.49673319]\n",
      " [0.67299496]\n",
      " [0.5208047 ]\n",
      " [0.52271473]\n",
      " [0.52744257]] | y: 0.722588144130182 | Predicción actual: [[0.5349375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060517698526382446, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49241623]\n",
      " [0.49424991]\n",
      " [0.49673319]\n",
      " [0.67299496]\n",
      " [0.5208047 ]\n",
      " [0.52271473]\n",
      " [0.52744257]\n",
      " [0.5349375 ]] | y: 0.771793878341728 | Predicción actual: [[0.54486775]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030628759413957596, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49424991]\n",
      " [0.49673319]\n",
      " [0.67299496]\n",
      " [0.5208047 ]\n",
      " [0.52271473]\n",
      " [0.52744257]\n",
      " [0.5349375 ]\n",
      " [0.54486775]] | y: 0.7245253777605578 | Predicción actual: [[0.55674684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04796365648508072, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49673319]\n",
      " [0.67299496]\n",
      " [0.5208047 ]\n",
      " [0.52271473]\n",
      " [0.52744257]\n",
      " [0.5349375 ]\n",
      " [0.54486775]\n",
      " [0.55674684]] | y: 0.6710577295621851 | Predicción actual: [[0.5701314]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013963069766759872, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.5208047 ]\n",
      " [0.52271473]\n",
      " [0.52744257]\n",
      " [0.5349375 ]\n",
      " [0.54486775]\n",
      " [0.55674684]\n",
      " [0.57013142]] | y: 0.6737698566447115 | Predicción actual: [[0.58461875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007128642871975899, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5208047 ]\n",
      " [0.52271473]\n",
      " [0.52744257]\n",
      " [0.5349375 ]\n",
      " [0.54486775]\n",
      " [0.55674684]\n",
      " [0.57013142]\n",
      " [0.58461875]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021918540820479393, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52271473]\n",
      " [0.52744257]\n",
      " [0.5349375 ]\n",
      " [0.54486775]\n",
      " [0.55674684]\n",
      " [0.57013142]\n",
      " [0.58461875]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5606923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029371853917837143, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52744257]\n",
      " [0.5349375 ]\n",
      " [0.54486775]\n",
      " [0.55674684]\n",
      " [0.57013142]\n",
      " [0.58461875]\n",
      " [0.71445176]\n",
      " [0.56069231]] | y: 0.722588144130182 | Predicción actual: [[0.57045]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023774797096848488, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5349375 ]\n",
      " [0.54486775]\n",
      " [0.55674684]\n",
      " [0.57013142]\n",
      " [0.58461875]\n",
      " [0.71445176]\n",
      " [0.56069231]\n",
      " [0.57045001]] | y: 0.6993413405656723 | Predicción actual: [[0.5822466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022415831685066223, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54486775]\n",
      " [0.55674684]\n",
      " [0.57013142]\n",
      " [0.58461875]\n",
      " [0.71445176]\n",
      " [0.56069231]\n",
      " [0.57045001]\n",
      " [0.5822466 ]] | y: 0.7373111197210385 | Predicción actual: [[0.5950817]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04389285296201706, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55674684]\n",
      " [0.57013142]\n",
      " [0.58461875]\n",
      " [0.71445176]\n",
      " [0.56069231]\n",
      " [0.57045001]\n",
      " [0.5822466 ]\n",
      " [0.59508169]] | y: 0.7214258039519565 | Predicción actual: [[0.6078728]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001828500971896574, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57013142]\n",
      " [0.58461875]\n",
      " [0.71445176]\n",
      " [0.56069231]\n",
      " [0.57045001]\n",
      " [0.5822466 ]\n",
      " [0.59508169]\n",
      " [0.60787278]] | y: 0.7187136768694304 | Predicción actual: [[0.6193525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038202276919037104, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58461875]\n",
      " [0.71445176]\n",
      " [0.56069231]\n",
      " [0.57045001]\n",
      " [0.5822466 ]\n",
      " [0.59508169]\n",
      " [0.60787278]\n",
      " [0.61935252]] | y: 0.6741573033707864 | Predicción actual: [[0.62860173]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004540132940746844, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56069231]\n",
      " [0.57045001]\n",
      " [0.5822466 ]\n",
      " [0.59508169]\n",
      " [0.60787278]\n",
      " [0.61935252]\n",
      " [0.62860173]] | y: 0.698566447113522 | Predicción actual: [[0.6347283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07800149917602539, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56069231]\n",
      " [0.57045001]\n",
      " [0.5822466 ]\n",
      " [0.59508169]\n",
      " [0.60787278]\n",
      " [0.61935252]\n",
      " [0.62860173]\n",
      " [0.63472831]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014123649336397648, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57045001]\n",
      " [0.5822466 ]\n",
      " [0.59508169]\n",
      " [0.60787278]\n",
      " [0.61935252]\n",
      " [0.62860173]\n",
      " [0.63472831]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.61696666]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007114739622920752, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5822466 ]\n",
      " [0.59508169]\n",
      " [0.60787278]\n",
      " [0.61935252]\n",
      " [0.62860173]\n",
      " [0.63472831]\n",
      " [0.72103836]\n",
      " [0.61696666]] | y: 0.7562960092987214 | Predicción actual: [[0.6290369]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007056759670376778, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59508169]\n",
      " [0.60787278]\n",
      " [0.61935252]\n",
      " [0.62860173]\n",
      " [0.63472831]\n",
      " [0.72103836]\n",
      " [0.61696666]\n",
      " [0.6290369 ]] | y: 0.8275862068965516 | Predicción actual: [[0.6410588]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039873138070106506, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60787278]\n",
      " [0.61935252]\n",
      " [0.62860173]\n",
      " [0.63472831]\n",
      " [0.72103836]\n",
      " [0.61696666]\n",
      " [0.6290369 ]\n",
      " [0.6410588 ]] | y: 0.8388221619527314 | Predicción actual: [[0.65234387]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012061403132975101, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61935252]\n",
      " [0.62860173]\n",
      " [0.63472831]\n",
      " [0.72103836]\n",
      " [0.61696666]\n",
      " [0.6290369 ]\n",
      " [0.6410588 ]\n",
      " [0.65234387]] | y: 0.7942657884540876 | Predicción actual: [[0.6622243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007061487063765526, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62860173]\n",
      " [0.63472831]\n",
      " [0.72103836]\n",
      " [0.61696666]\n",
      " [0.6290369 ]\n",
      " [0.6410588 ]\n",
      " [0.65234387]\n",
      " [0.66222429]] | y: 0.7838047268500579 | Predicción actual: [[0.6704861]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04171875864267349, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63472831]\n",
      " [0.72103836]\n",
      " [0.61696666]\n",
      " [0.6290369 ]\n",
      " [0.6410588 ]\n",
      " [0.65234387]\n",
      " [0.66222429]\n",
      " [0.67048609]] | y: 0.7679194110809764 | Predicción actual: [[0.67746127]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0321989580988884, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.61696666]\n",
      " [0.6290369 ]\n",
      " [0.6410588 ]\n",
      " [0.65234387]\n",
      " [0.66222429]\n",
      " [0.67048609]\n",
      " [0.67746127]] | y: 0.7845796203022084 | Predicción actual: [[0.6837856]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025480687618255615, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61696666]\n",
      " [0.6290369 ]\n",
      " [0.6410588 ]\n",
      " [0.65234387]\n",
      " [0.66222429]\n",
      " [0.67048609]\n",
      " [0.67746127]\n",
      " [0.68378562]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02299521304666996, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6290369 ]\n",
      " [0.6410588 ]\n",
      " [0.65234387]\n",
      " [0.66222429]\n",
      " [0.67048609]\n",
      " [0.67746127]\n",
      " [0.68378562]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6786546]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05985324829816818, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6410588 ]\n",
      " [0.65234387]\n",
      " [0.66222429]\n",
      " [0.67048609]\n",
      " [0.67746127]\n",
      " [0.68378562]\n",
      " [0.87872917]\n",
      " [0.67865461]] | y: 0.8488957768306855 | Predicción actual: [[0.6921597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01685429736971855, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65234387]\n",
      " [0.66222429]\n",
      " [0.67048609]\n",
      " [0.67746127]\n",
      " [0.68378562]\n",
      " [0.87872917]\n",
      " [0.67865461]\n",
      " [0.69215971]] | y: 0.8182874854707476 | Predicción actual: [[0.7064553]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024755196645855904, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66222429]\n",
      " [0.67048609]\n",
      " [0.67746127]\n",
      " [0.68378562]\n",
      " [0.87872917]\n",
      " [0.67865461]\n",
      " [0.69215971]\n",
      " [0.70645529]] | y: 0.8268113134444013 | Predicción actual: [[0.72130966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0207946615992114e-05, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67048609]\n",
      " [0.67746127]\n",
      " [0.68378562]\n",
      " [0.87872917]\n",
      " [0.67865461]\n",
      " [0.69215971]\n",
      " [0.70645529]\n",
      " [0.72130966]] | y: 0.7853545137543589 | Predicción actual: [[0.7363635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012268273159861565, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67746127]\n",
      " [0.68378562]\n",
      " [0.87872917]\n",
      " [0.67865461]\n",
      " [0.69215971]\n",
      " [0.70645529]\n",
      " [0.72130966]\n",
      " [0.73636347]] | y: 0.7892289810151103 | Predicción actual: [[0.7517036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005369300022721291, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68378562]\n",
      " [0.87872917]\n",
      " [0.67865461]\n",
      " [0.69215971]\n",
      " [0.70645529]\n",
      " [0.72130966]\n",
      " [0.73636347]\n",
      " [0.75170362]] | y: 0.8341728012398295 | Predicción actual: [[0.7672392]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014955720398575068, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.67865461]\n",
      " [0.69215971]\n",
      " [0.70645529]\n",
      " [0.72130966]\n",
      " [0.73636347]\n",
      " [0.75170362]\n",
      " [0.76723921]] | y: 0.8124757845796202 | Predicción actual: [[0.78283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004850498866289854, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67865461]\n",
      " [0.69215971]\n",
      " [0.70645529]\n",
      " [0.72130966]\n",
      " [0.73636347]\n",
      " [0.75170362]\n",
      " [0.76723921]\n",
      " [0.78283   ]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003991497680544853, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69215971]\n",
      " [0.70645529]\n",
      " [0.72130966]\n",
      " [0.73636347]\n",
      " [0.75170362]\n",
      " [0.76723921]\n",
      " [0.78283   ]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7562136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016099974745884538, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70645529]\n",
      " [0.72130966]\n",
      " [0.73636347]\n",
      " [0.75170362]\n",
      " [0.76723921]\n",
      " [0.78283   ]\n",
      " [0.80123983]\n",
      " [0.75621361]] | y: 0.793490895001937 | Predicción actual: [[0.7712572]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012931276112794876, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72130966]\n",
      " [0.73636347]\n",
      " [0.75170362]\n",
      " [0.76723921]\n",
      " [0.78283   ]\n",
      " [0.80123983]\n",
      " [0.75621361]\n",
      " [0.77125722]] | y: 0.760170476559473 | Predicción actual: [[0.7854331]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.569625035510398e-06, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73636347]\n",
      " [0.75170362]\n",
      " [0.76723921]\n",
      " [0.78283   ]\n",
      " [0.80123983]\n",
      " [0.75621361]\n",
      " [0.77125722]\n",
      " [0.78543311]] | y: 0.7353738860906625 | Predicción actual: [[0.7982463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04679185897111893, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75170362]\n",
      " [0.76723921]\n",
      " [0.78283   ]\n",
      " [0.80123983]\n",
      " [0.75621361]\n",
      " [0.77125722]\n",
      " [0.78543311]\n",
      " [0.79824632]] | y: 0.7101898488957767 | Predicción actual: [[0.80859435]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014527914114296436, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76723921]\n",
      " [0.78283   ]\n",
      " [0.80123983]\n",
      " [0.75621361]\n",
      " [0.77125722]\n",
      " [0.78543311]\n",
      " [0.79824632]\n",
      " [0.80859435]] | y: 0.7121270825261525 | Predicción actual: [[0.81614476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001866035396233201, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78283   ]\n",
      " [0.80123983]\n",
      " [0.75621361]\n",
      " [0.77125722]\n",
      " [0.78543311]\n",
      " [0.79824632]\n",
      " [0.80859435]\n",
      " [0.81614476]] | y: 0.7396358000774894 | Predicción actual: [[0.82073194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025944309309124947, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.75621361]\n",
      " [0.77125722]\n",
      " [0.78543311]\n",
      " [0.79824632]\n",
      " [0.80859435]\n",
      " [0.81614476]\n",
      " [0.82073194]] | y: 0.7361487795428128 | Predicción actual: [[0.82164353]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02296525053679943, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75621361]\n",
      " [0.77125722]\n",
      " [0.78543311]\n",
      " [0.79824632]\n",
      " [0.80859435]\n",
      " [0.81614476]\n",
      " [0.82073194]\n",
      " [0.82164353]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038033586461097, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77125722]\n",
      " [0.78543311]\n",
      " [0.79824632]\n",
      " [0.80859435]\n",
      " [0.81614476]\n",
      " [0.82073194]\n",
      " [0.82164353]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8280839]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03776464983820915, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78543311]\n",
      " [0.79824632]\n",
      " [0.80859435]\n",
      " [0.81614476]\n",
      " [0.82073194]\n",
      " [0.82164353]\n",
      " [0.66757071]\n",
      " [0.82808387]] | y: 0.696629213483146 | Predicción actual: [[0.8347247]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03269278630614281, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79824632]\n",
      " [0.80859435]\n",
      " [0.81614476]\n",
      " [0.82073194]\n",
      " [0.82164353]\n",
      " [0.66757071]\n",
      " [0.82808387]\n",
      " [0.83472472]] | y: 0.6559473072452537 | Predicción actual: [[0.83745456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01325155608355999, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80859435]\n",
      " [0.81614476]\n",
      " [0.82073194]\n",
      " [0.82164353]\n",
      " [0.66757071]\n",
      " [0.82808387]\n",
      " [0.83472472]\n",
      " [0.83745456]] | y: 0.6788066640836885 | Predicción actual: [[0.83651817]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029426919296383858, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81614476]\n",
      " [0.82073194]\n",
      " [0.82164353]\n",
      " [0.66757071]\n",
      " [0.82808387]\n",
      " [0.83472472]\n",
      " [0.83745456]\n",
      " [0.83651817]] | y: 0.6760945370011622 | Predicción actual: [[0.8324771]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039608925580978394, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82073194]\n",
      " [0.82164353]\n",
      " [0.66757071]\n",
      " [0.82808387]\n",
      " [0.83472472]\n",
      " [0.83745456]\n",
      " [0.83651817]\n",
      " [0.83247709]] | y: 0.7295621851995349 | Predicción actual: [[0.8263285]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015802172711119056, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82164353]\n",
      " [0.66757071]\n",
      " [0.82808387]\n",
      " [0.83472472]\n",
      " [0.83745456]\n",
      " [0.83651817]\n",
      " [0.83247709]\n",
      " [0.82632852]] | y: 0.7012785741960481 | Predicción actual: [[0.81976736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034297287464141846, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.82808387]\n",
      " [0.83472472]\n",
      " [0.83745456]\n",
      " [0.83651817]\n",
      " [0.83247709]\n",
      " [0.82632852]\n",
      " [0.81976736]] | y: 0.767531964354901 | Predicción actual: [[0.81379145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012827321188524365, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82808387]\n",
      " [0.83472472]\n",
      " [0.83745456]\n",
      " [0.83651817]\n",
      " [0.83247709]\n",
      " [0.82632852]\n",
      " [0.81976736]\n",
      " [0.81379145]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007145814131945372, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83472472]\n",
      " [0.83745456]\n",
      " [0.83651817]\n",
      " [0.83247709]\n",
      " [0.82632852]\n",
      " [0.81976736]\n",
      " [0.81379145]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.85515434]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023140419274568558, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83745456]\n",
      " [0.83651817]\n",
      " [0.83247709]\n",
      " [0.82632852]\n",
      " [0.81976736]\n",
      " [0.81379145]\n",
      " [0.75513367]\n",
      " [0.85515434]] | y: 0.7520340953118947 | Predicción actual: [[0.8508756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008853633771650493, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83651817]\n",
      " [0.83247709]\n",
      " [0.82632852]\n",
      " [0.81976736]\n",
      " [0.81379145]\n",
      " [0.75513367]\n",
      " [0.85515434]\n",
      " [0.85087562]] | y: 0.7098024021697016 | Predicción actual: [[0.8450026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013113670283928514, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83247709]\n",
      " [0.82632852]\n",
      " [0.81976736]\n",
      " [0.81379145]\n",
      " [0.75513367]\n",
      " [0.85515434]\n",
      " [0.85087562]\n",
      " [0.84500259]] | y: 0.6904300658659435 | Predicción actual: [[0.8388913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005656854249536991, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82632852]\n",
      " [0.81976736]\n",
      " [0.81379145]\n",
      " [0.75513367]\n",
      " [0.85515434]\n",
      " [0.85087562]\n",
      " [0.84500259]\n",
      " [0.83889133]] | y: 0.7543587756683454 | Predicción actual: [[0.83384955]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013639639131724834, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81976736]\n",
      " [0.81379145]\n",
      " [0.75513367]\n",
      " [0.85515434]\n",
      " [0.85087562]\n",
      " [0.84500259]\n",
      " [0.83889133]\n",
      " [0.83384955]] | y: 0.7222006974041069 | Predicción actual: [[0.8309154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0304663497954607, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81379145]\n",
      " [0.75513367]\n",
      " [0.85515434]\n",
      " [0.85087562]\n",
      " [0.84500259]\n",
      " [0.83889133]\n",
      " [0.83384955]\n",
      " [0.83091539]] | y: 0.8485083301046106 | Predicción actual: [[0.8305363]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012985285371541977, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.85515434]\n",
      " [0.85087562]\n",
      " [0.84500259]\n",
      " [0.83889133]\n",
      " [0.83384955]\n",
      " [0.83091539]\n",
      " [0.83053631]] | y: 0.9054629988376597 | Predicción actual: [[0.83296895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.008582658978412e-06, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85515434]\n",
      " [0.85087562]\n",
      " [0.84500259]\n",
      " [0.83889133]\n",
      " [0.83384955]\n",
      " [0.83091539]\n",
      " [0.83053631]\n",
      " [0.83296895]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00014551660569850355, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85087562]\n",
      " [0.84500259]\n",
      " [0.83889133]\n",
      " [0.83384955]\n",
      " [0.83091539]\n",
      " [0.83053631]\n",
      " [0.83296895]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8489825]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054460559040308, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84500259]\n",
      " [0.83889133]\n",
      " [0.83384955]\n",
      " [0.83091539]\n",
      " [0.83053631]\n",
      " [0.83296895]\n",
      " [0.8822162 ]\n",
      " [0.84898251]] | y: 0.889577683068578 | Predicción actual: [[0.84480923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01714973710477352, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83889133]\n",
      " [0.83384955]\n",
      " [0.83091539]\n",
      " [0.83053631]\n",
      " [0.83296895]\n",
      " [0.8822162 ]\n",
      " [0.84898251]\n",
      " [0.84480923]] | y: 0.8748547074777218 | Predicción actual: [[0.8426975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009408318437635899, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83384955]\n",
      " [0.83091539]\n",
      " [0.83053631]\n",
      " [0.83296895]\n",
      " [0.8822162 ]\n",
      " [0.84898251]\n",
      " [0.84480923]\n",
      " [0.8426975 ]] | y: 0.9132119333591631 | Predicción actual: [[0.8429739]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006159073673188686, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83091539]\n",
      " [0.83053631]\n",
      " [0.83296895]\n",
      " [0.8822162 ]\n",
      " [0.84898251]\n",
      " [0.84480923]\n",
      " [0.8426975 ]\n",
      " [0.84297389]] | y: 1.0 | Predicción actual: [[0.84553075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04182640090584755, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83053631]\n",
      " [0.83296895]\n",
      " [0.8822162 ]\n",
      " [0.84898251]\n",
      " [0.84480923]\n",
      " [0.8426975 ]\n",
      " [0.84297389]\n",
      " [0.84553075]] | y: 0.9705540488182873 | Predicción actual: [[0.8500755]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02313133515417576, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83296895]\n",
      " [0.8822162 ]\n",
      " [0.84898251]\n",
      " [0.84480923]\n",
      " [0.8426975 ]\n",
      " [0.84297389]\n",
      " [0.84553075]\n",
      " [0.85007548]] | y: 0.8888027896164277 | Predicción actual: [[0.8557121]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033008020371198654, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.84898251]\n",
      " [0.84480923]\n",
      " [0.8426975 ]\n",
      " [0.84297389]\n",
      " [0.84553075]\n",
      " [0.85007548]\n",
      " [0.85571212]] | y: 0.877954281286323 | Predicción actual: [[0.8614634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015613289549946785, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84898251]\n",
      " [0.84480923]\n",
      " [0.8426975 ]\n",
      " [0.84297389]\n",
      " [0.84553075]\n",
      " [0.85007548]\n",
      " [0.85571212]\n",
      " [0.86146343]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011641385965049267, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84480923]\n",
      " [0.8426975 ]\n",
      " [0.84297389]\n",
      " [0.84553075]\n",
      " [0.85007548]\n",
      " [0.85571212]\n",
      " [0.86146343]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8529013]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010054294398287311, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8426975 ]\n",
      " [0.84297389]\n",
      " [0.84553075]\n",
      " [0.85007548]\n",
      " [0.85571212]\n",
      " [0.86146343]\n",
      " [0.84889578]\n",
      " [0.85290128]] | y: 0.8550949244478885 | Predicción actual: [[0.8544471]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01376317162066698, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84297389]\n",
      " [0.84553075]\n",
      " [0.85007548]\n",
      " [0.85571212]\n",
      " [0.86146343]\n",
      " [0.84889578]\n",
      " [0.85290128]\n",
      " [0.85444713]] | y: 0.8752421542037967 | Predicción actual: [[0.8572526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020523553248494864, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84553075]\n",
      " [0.85007548]\n",
      " [0.85571212]\n",
      " [0.86146343]\n",
      " [0.84889578]\n",
      " [0.85290128]\n",
      " [0.85444713]\n",
      " [0.8572526 ]] | y: 0.857032158078264 | Predicción actual: [[0.8605558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005105331540107727, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85007548]\n",
      " [0.85571212]\n",
      " [0.86146343]\n",
      " [0.84889578]\n",
      " [0.85290128]\n",
      " [0.85444713]\n",
      " [0.8572526 ]\n",
      " [0.86055583]] | y: 0.8500581170089112 | Predicción actual: [[0.86340237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001895090681500733, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85571212]\n",
      " [0.86146343]\n",
      " [0.84889578]\n",
      " [0.85290128]\n",
      " [0.85444713]\n",
      " [0.8572526 ]\n",
      " [0.86055583]\n",
      " [0.86340237]] | y: 0.8426966292134832 | Predicción actual: [[0.86526424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.208784503134666e-06, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86146343]\n",
      " [0.84889578]\n",
      " [0.85290128]\n",
      " [0.85444713]\n",
      " [0.8572526 ]\n",
      " [0.86055583]\n",
      " [0.86340237]\n",
      " [0.86526424]] | y: 0.8229368461836497 | Predicción actual: [[0.86573875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013728286139667034, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.85290128]\n",
      " [0.85444713]\n",
      " [0.8572526 ]\n",
      " [0.86055583]\n",
      " [0.86340237]\n",
      " [0.86526424]\n",
      " [0.86573875]] | y: 0.7745060054242543 | Predicción actual: [[0.8644238]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003215321572497487, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85290128]\n",
      " [0.85444713]\n",
      " [0.8572526 ]\n",
      " [0.86055583]\n",
      " [0.86340237]\n",
      " [0.86526424]\n",
      " [0.86573875]\n",
      " [0.86442381]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004737464245408773, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85444713]\n",
      " [0.8572526 ]\n",
      " [0.86055583]\n",
      " [0.86340237]\n",
      " [0.86526424]\n",
      " [0.86573875]\n",
      " [0.86442381]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8684375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013630212051793933, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8572526 ]\n",
      " [0.86055583]\n",
      " [0.86340237]\n",
      " [0.86526424]\n",
      " [0.86573875]\n",
      " [0.86442381]\n",
      " [0.78419217]\n",
      " [0.86843753]] | y: 0.854320030995738 | Predicción actual: [[0.8691208]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.044327503535897e-05, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86055583]\n",
      " [0.86340237]\n",
      " [0.86526424]\n",
      " [0.86573875]\n",
      " [0.86442381]\n",
      " [0.78419217]\n",
      " [0.86843753]\n",
      " [0.86912078]] | y: 0.8368849283223556 | Predicción actual: [[0.86864525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017243612557649612, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86340237]\n",
      " [0.86526424]\n",
      " [0.86573875]\n",
      " [0.86442381]\n",
      " [0.78419217]\n",
      " [0.86843753]\n",
      " [0.86912078]\n",
      " [0.86864525]] | y: 0.8299108872530028 | Predicción actual: [[0.8665358]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012779989279806614, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86526424]\n",
      " [0.86573875]\n",
      " [0.86442381]\n",
      " [0.78419217]\n",
      " [0.86843753]\n",
      " [0.86912078]\n",
      " [0.86864525]\n",
      " [0.86653578]] | y: 0.887253002712127 | Predicción actual: [[0.8630602]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014108933508396149, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86573875]\n",
      " [0.86442381]\n",
      " [0.78419217]\n",
      " [0.86843753]\n",
      " [0.86912078]\n",
      " [0.86864525]\n",
      " [0.86653578]\n",
      " [0.86306018]] | y: 0.8597442851607902 | Predicción actual: [[0.858634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01631765067577362, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86442381]\n",
      " [0.78419217]\n",
      " [0.86843753]\n",
      " [0.86912078]\n",
      " [0.86864525]\n",
      " [0.86653578]\n",
      " [0.86306018]\n",
      " [0.858634  ]] | y: 0.8395970554048819 | Predicción actual: [[0.85386074]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015655682364013046, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.86843753]\n",
      " [0.86912078]\n",
      " [0.86864525]\n",
      " [0.86653578]\n",
      " [0.86306018]\n",
      " [0.858634  ]\n",
      " [0.85386074]] | y: 0.7838047268500579 | Predicción actual: [[0.8497646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.058141636662185e-05, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86843753]\n",
      " [0.86912078]\n",
      " [0.86864525]\n",
      " [0.86653578]\n",
      " [0.86306018]\n",
      " [0.858634  ]\n",
      " [0.85386074]\n",
      " [0.84976459]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013401474803686142, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86912078]\n",
      " [0.86864525]\n",
      " [0.86653578]\n",
      " [0.86306018]\n",
      " [0.858634  ]\n",
      " [0.85386074]\n",
      " [0.84976459]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8675125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002326695714145899, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86864525]\n",
      " [0.86653578]\n",
      " [0.86306018]\n",
      " [0.858634  ]\n",
      " [0.85386074]\n",
      " [0.84976459]\n",
      " [0.81828749]\n",
      " [0.86751252]] | y: 0.7605579232855482 | Predicción actual: [[0.8637987]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0041150664910674095, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86653578]\n",
      " [0.86306018]\n",
      " [0.858634  ]\n",
      " [0.85386074]\n",
      " [0.84976459]\n",
      " [0.81828749]\n",
      " [0.86751252]\n",
      " [0.86379868]] | y: 0.7915536613715615 | Predicción actual: [[0.85931027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001992336241528392, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86306018]\n",
      " [0.858634  ]\n",
      " [0.85386074]\n",
      " [0.84976459]\n",
      " [0.81828749]\n",
      " [0.86751252]\n",
      " [0.86379868]\n",
      " [0.85931027]] | y: 0.7686943045331267 | Predicción actual: [[0.8547214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009073586203157902, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.858634  ]\n",
      " [0.85386074]\n",
      " [0.84976459]\n",
      " [0.81828749]\n",
      " [0.86751252]\n",
      " [0.86379868]\n",
      " [0.85931027]\n",
      " [0.85472143]] | y: 0.7686943045331267 | Predicción actual: [[0.8505571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0201122909784317, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85386074]\n",
      " [0.84976459]\n",
      " [0.81828749]\n",
      " [0.86751252]\n",
      " [0.86379868]\n",
      " [0.85931027]\n",
      " [0.85472143]\n",
      " [0.85055709]] | y: 0.7989151491669895 | Predicción actual: [[0.84725225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07299838215112686, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84976459]\n",
      " [0.81828749]\n",
      " [0.86751252]\n",
      " [0.86379868]\n",
      " [0.85931027]\n",
      " [0.85472143]\n",
      " [0.85055709]\n",
      " [0.84725225]] | y: 0.7900038744672608 | Predicción actual: [[0.84476966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007775345351547003, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.86751252]\n",
      " [0.86379868]\n",
      " [0.85931027]\n",
      " [0.85472143]\n",
      " [0.85055709]\n",
      " [0.84725225]\n",
      " [0.84476966]] | y: 0.760170476559473 | Predicción actual: [[0.84360284]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09289129078388214, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86751252]\n",
      " [0.86379868]\n",
      " [0.85931027]\n",
      " [0.85472143]\n",
      " [0.85055709]\n",
      " [0.84725225]\n",
      " [0.84476966]\n",
      " [0.84360284]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1172175258398056, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86379868]\n",
      " [0.85931027]\n",
      " [0.85472143]\n",
      " [0.85055709]\n",
      " [0.84725225]\n",
      " [0.84476966]\n",
      " [0.84360284]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8436596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09550657868385315, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85931027]\n",
      " [0.85472143]\n",
      " [0.85055709]\n",
      " [0.84725225]\n",
      " [0.84476966]\n",
      " [0.84360284]\n",
      " [0.68539326]\n",
      " [0.84365958]] | y: 0.6648585819449826 | Predicción actual: [[0.8343363]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03599577397108078, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85472143]\n",
      " [0.85055709]\n",
      " [0.84725225]\n",
      " [0.84476966]\n",
      " [0.84360284]\n",
      " [0.68539326]\n",
      " [0.84365958]\n",
      " [0.83433628]] | y: 0.7078651685393258 | Predicción actual: [[0.8238914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023842323571443558, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85055709]\n",
      " [0.84725225]\n",
      " [0.84476966]\n",
      " [0.84360284]\n",
      " [0.68539326]\n",
      " [0.84365958]\n",
      " [0.83433628]\n",
      " [0.8238914 ]] | y: 0.6648585819449826 | Predicción actual: [[0.8128218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013569764560088515, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84725225]\n",
      " [0.84476966]\n",
      " [0.84360284]\n",
      " [0.68539326]\n",
      " [0.84365958]\n",
      " [0.83433628]\n",
      " [0.8238914 ]\n",
      " [0.81282181]] | y: 0.7113521890740022 | Predicción actual: [[0.8012971]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06562180072069168, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84476966]\n",
      " [0.84360284]\n",
      " [0.68539326]\n",
      " [0.84365958]\n",
      " [0.83433628]\n",
      " [0.8238914 ]\n",
      " [0.81282181]\n",
      " [0.80129713]] | y: 0.6772568771793879 | Predicción actual: [[0.78889334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04771316796541214, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84360284]\n",
      " [0.68539326]\n",
      " [0.84365958]\n",
      " [0.83433628]\n",
      " [0.8238914 ]\n",
      " [0.81282181]\n",
      " [0.80129713]\n",
      " [0.78889334]] | y: 0.7621077101898488 | Predicción actual: [[0.77578574]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003069947473704815, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84365958]\n",
      " [0.83433628]\n",
      " [0.8238914 ]\n",
      " [0.81282181]\n",
      " [0.80129713]\n",
      " [0.78889334]\n",
      " [0.77578574]] | y: 0.8070515304145678 | Predicción actual: [[0.76227903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0046808794140815735, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84365958]\n",
      " [0.83433628]\n",
      " [0.8238914 ]\n",
      " [0.81282181]\n",
      " [0.80129713]\n",
      " [0.78889334]\n",
      " [0.77578574]\n",
      " [0.76227903]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022207358852028847, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83433628]\n",
      " [0.8238914 ]\n",
      " [0.81282181]\n",
      " [0.80129713]\n",
      " [0.78889334]\n",
      " [0.77578574]\n",
      " [0.76227903]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.781232]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003641981747932732, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8238914 ]\n",
      " [0.81282181]\n",
      " [0.80129713]\n",
      " [0.78889334]\n",
      " [0.77578574]\n",
      " [0.76227903]\n",
      " [0.81518791]\n",
      " [0.781232  ]] | y: 0.9597055404881829 | Predicción actual: [[0.77052975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07166218012571335, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81282181]\n",
      " [0.80129713]\n",
      " [0.78889334]\n",
      " [0.77578574]\n",
      " [0.76227903]\n",
      " [0.81518791]\n",
      " [0.781232  ]\n",
      " [0.77052975]] | y: 0.9643549012010848 | Predicción actual: [[0.76129824]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05485327169299126, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80129713]\n",
      " [0.78889334]\n",
      " [0.77578574]\n",
      " [0.76227903]\n",
      " [0.81518791]\n",
      " [0.781232  ]\n",
      " [0.77052975]\n",
      " [0.76129824]] | y: 0.8880278961642774 | Predicción actual: [[0.75389385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0040191709995269775, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78889334]\n",
      " [0.77578574]\n",
      " [0.76227903]\n",
      " [0.81518791]\n",
      " [0.781232  ]\n",
      " [0.77052975]\n",
      " [0.76129824]\n",
      " [0.75389385]] | y: 0.8926772568771792 | Predicción actual: [[0.7483824]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002077153418213129, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77578574]\n",
      " [0.76227903]\n",
      " [0.81518791]\n",
      " [0.781232  ]\n",
      " [0.77052975]\n",
      " [0.76129824]\n",
      " [0.75389385]\n",
      " [0.74838239]] | y: 0.8752421542037967 | Predicción actual: [[0.74497104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06541711837053299, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76227903]\n",
      " [0.81518791]\n",
      " [0.781232  ]\n",
      " [0.77052975]\n",
      " [0.76129824]\n",
      " [0.75389385]\n",
      " [0.74838239]\n",
      " [0.74497104]] | y: 0.8508330104610615 | Predicción actual: [[0.7443989]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038084036204963923, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.781232  ]\n",
      " [0.77052975]\n",
      " [0.76129824]\n",
      " [0.75389385]\n",
      " [0.74838239]\n",
      " [0.74497104]\n",
      " [0.74439889]] | y: 0.8488957768306855 | Predicción actual: [[0.7466147]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02703039161860943, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.781232  ]\n",
      " [0.77052975]\n",
      " [0.76129824]\n",
      " [0.75389385]\n",
      " [0.74838239]\n",
      " [0.74497104]\n",
      " [0.74439889]\n",
      " [0.74661469]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10155609995126724, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77052975]\n",
      " [0.76129824]\n",
      " [0.75389385]\n",
      " [0.74838239]\n",
      " [0.74497104]\n",
      " [0.74439889]\n",
      " [0.74661469]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7288472]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12341143935918808, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76129824]\n",
      " [0.75389385]\n",
      " [0.74838239]\n",
      " [0.74497104]\n",
      " [0.74439889]\n",
      " [0.74661469]\n",
      " [0.96241767]\n",
      " [0.72884721]] | y: 0.9407206509104997 | Predicción actual: [[0.7279457]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050638288259506226, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75389385]\n",
      " [0.74838239]\n",
      " [0.74497104]\n",
      " [0.74439889]\n",
      " [0.74661469]\n",
      " [0.96241767]\n",
      " [0.72884721]\n",
      " [0.72794569]] | y: 0.9724912824486633 | Predicción actual: [[0.7306294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11045993864536285, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74838239]\n",
      " [0.74497104]\n",
      " [0.74439889]\n",
      " [0.74661469]\n",
      " [0.96241767]\n",
      " [0.72884721]\n",
      " [0.72794569]\n",
      " [0.73062938]] | y: 0.9969004261913985 | Predicción actual: [[0.7365206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07015522569417953, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74497104]\n",
      " [0.74439889]\n",
      " [0.74661469]\n",
      " [0.96241767]\n",
      " [0.72884721]\n",
      " [0.72794569]\n",
      " [0.73062938]\n",
      " [0.73652059]] | y: 0.951181712514529 | Predicción actual: [[0.7448027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10856680572032928, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74439889]\n",
      " [0.74661469]\n",
      " [0.96241767]\n",
      " [0.72884721]\n",
      " [0.72794569]\n",
      " [0.73062938]\n",
      " [0.73652059]\n",
      " [0.74480271]] | y: 0.8957768306857805 | Predicción actual: [[0.754526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09132492542266846, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74661469]\n",
      " [0.96241767]\n",
      " [0.72884721]\n",
      " [0.72794569]\n",
      " [0.73062938]\n",
      " [0.73652059]\n",
      " [0.74480271]\n",
      " [0.75452602]] | y: 0.8814413018209997 | Predicción actual: [[0.7643952]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006723504513502121, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.72884721]\n",
      " [0.72794569]\n",
      " [0.73062938]\n",
      " [0.73652059]\n",
      " [0.74480271]\n",
      " [0.75452602]\n",
      " [0.76439518]] | y: 0.9170864006199149 | Predicción actual: [[0.77295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009332371409982443, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72884721]\n",
      " [0.72794569]\n",
      " [0.73062938]\n",
      " [0.73652059]\n",
      " [0.74480271]\n",
      " [0.75452602]\n",
      " [0.76439518]\n",
      " [0.77294999]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03259827196598053, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72794569]\n",
      " [0.73062938]\n",
      " [0.73652059]\n",
      " [0.74480271]\n",
      " [0.75452602]\n",
      " [0.76439518]\n",
      " [0.77294999]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.72588915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01670280285179615, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73062938]\n",
      " [0.73652059]\n",
      " [0.74480271]\n",
      " [0.75452602]\n",
      " [0.76439518]\n",
      " [0.77294999]\n",
      " [0.91979853]\n",
      " [0.72588915]] | y: 0.9682293684618366 | Predicción actual: [[0.73532593]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09273102134466171, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73652059]\n",
      " [0.74480271]\n",
      " [0.75452602]\n",
      " [0.76439518]\n",
      " [0.77294999]\n",
      " [0.91979853]\n",
      " [0.72588915]\n",
      " [0.73532593]] | y: 0.9577683068578069 | Predicción actual: [[0.74682677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030917050316929817, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20821878]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040398694574832916, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20821878]] | y: 0.10422316931421921 | Predicción actual: [[0.1933248]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011994943022727966, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20821878]\n",
      " [0.1933248 ]] | y: 0.15420379697791559 | Predicción actual: [[0.19763072]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035183518193662167, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20821878]\n",
      " [0.1933248 ]\n",
      " [0.19763072]] | y: 0.1557535838822161 | Predicción actual: [[0.20919698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001862865872681141, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20821878]\n",
      " [0.1933248 ]\n",
      " [0.19763072]\n",
      " [0.20919698]] | y: 0.12553273924835334 | Predicción actual: [[0.22201264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01203696895390749, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20821878]\n",
      " [0.1933248 ]\n",
      " [0.19763072]\n",
      " [0.20919698]\n",
      " [0.22201264]] | y: 0.1456799690042619 | Predicción actual: [[0.23237792]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014878232963383198, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20821878]\n",
      " [0.1933248 ]\n",
      " [0.19763072]\n",
      " [0.20919698]\n",
      " [0.22201264]\n",
      " [0.23237792]] | y: 0.1464548624564122 | Predicción actual: [[0.25413418]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008367347531020641, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20821878]\n",
      " [0.1933248 ]\n",
      " [0.19763072]\n",
      " [0.20919698]\n",
      " [0.22201264]\n",
      " [0.23237792]\n",
      " [0.25413418]] | y: 0.1960480433940332 | Predicción actual: [[0.28095484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010772834531962872, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20821878]\n",
      " [0.1933248 ]\n",
      " [0.19763072]\n",
      " [0.20919698]\n",
      " [0.22201264]\n",
      " [0.23237792]\n",
      " [0.25413418]\n",
      " [0.28095484]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010632222518324852, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.1933248 ]\n",
      " [0.19763072]\n",
      " [0.20919698]\n",
      " [0.22201264]\n",
      " [0.23237792]\n",
      " [0.25413418]\n",
      " [0.28095484]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.31560993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008862689137458801, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19763072]\n",
      " [0.20919698]\n",
      " [0.22201264]\n",
      " [0.23237792]\n",
      " [0.25413418]\n",
      " [0.28095484]\n",
      " [0.2305308 ]\n",
      " [0.31560993]] | y: 0.211933359163115 | Predicción actual: [[0.32286334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006703214719891548, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20919698]\n",
      " [0.22201264]\n",
      " [0.23237792]\n",
      " [0.25413418]\n",
      " [0.28095484]\n",
      " [0.2305308 ]\n",
      " [0.31560993]\n",
      " [0.32286334]] | y: 0.2072839984502131 | Predicción actual: [[0.3319366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0344366692006588, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22201264]\n",
      " [0.23237792]\n",
      " [0.25413418]\n",
      " [0.28095484]\n",
      " [0.2305308 ]\n",
      " [0.31560993]\n",
      " [0.32286334]\n",
      " [0.3319366 ]] | y: 0.19294846958543205 | Predicción actual: [[0.3415902]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02925814315676689, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23237792]\n",
      " [0.25413418]\n",
      " [0.28095484]\n",
      " [0.2305308 ]\n",
      " [0.31560993]\n",
      " [0.32286334]\n",
      " [0.3319366 ]\n",
      " [0.3415902 ]] | y: 0.19682293684618352 | Predicción actual: [[0.35173935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028363946825265884, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25413418]\n",
      " [0.28095484]\n",
      " [0.2305308 ]\n",
      " [0.31560993]\n",
      " [0.32286334]\n",
      " [0.3319366 ]\n",
      " [0.3415902 ]\n",
      " [0.35173935]] | y: 0.21425803951956607 | Predicción actual: [[0.363053]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05057083070278168, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28095484]\n",
      " [0.2305308 ]\n",
      " [0.31560993]\n",
      " [0.32286334]\n",
      " [0.3319366 ]\n",
      " [0.3415902 ]\n",
      " [0.35173935]\n",
      " [0.36305299]] | y: 0.18132506780317698 | Predicción actual: [[0.3729417]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05124412849545479, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31560993]\n",
      " [0.32286334]\n",
      " [0.3319366 ]\n",
      " [0.3415902 ]\n",
      " [0.35173935]\n",
      " [0.36305299]\n",
      " [0.3729417 ]] | y: 0.17512592018597434 | Predicción actual: [[0.379901]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06394326686859131, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31560993]\n",
      " [0.32286334]\n",
      " [0.3319366 ]\n",
      " [0.3415902 ]\n",
      " [0.35173935]\n",
      " [0.36305299]\n",
      " [0.3729417 ]\n",
      " [0.37990099]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04944558069109917, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32286334]\n",
      " [0.3319366 ]\n",
      " [0.3415902 ]\n",
      " [0.35173935]\n",
      " [0.36305299]\n",
      " [0.3729417 ]\n",
      " [0.37990099]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40675285]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0943639725446701, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3319366 ]\n",
      " [0.3415902 ]\n",
      " [0.35173935]\n",
      " [0.36305299]\n",
      " [0.3729417 ]\n",
      " [0.37990099]\n",
      " [0.14800465]\n",
      " [0.40675285]] | y: 0.19217357613328173 | Predicción actual: [[0.41034743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030896125361323357, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3415902 ]\n",
      " [0.35173935]\n",
      " [0.36305299]\n",
      " [0.3729417 ]\n",
      " [0.37990099]\n",
      " [0.14800465]\n",
      " [0.40675285]\n",
      " [0.41034743]] | y: 0.1859744285160791 | Predicción actual: [[0.4121948]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05133689194917679, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35173935]\n",
      " [0.36305299]\n",
      " [0.3729417 ]\n",
      " [0.37990099]\n",
      " [0.14800465]\n",
      " [0.40675285]\n",
      " [0.41034743]\n",
      " [0.41219479]] | y: 0.26695079426578844 | Predicción actual: [[0.41231957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010454637929797173, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36305299]\n",
      " [0.3729417 ]\n",
      " [0.37990099]\n",
      " [0.14800465]\n",
      " [0.40675285]\n",
      " [0.41034743]\n",
      " [0.41219479]\n",
      " [0.41231957]] | y: 0.2925222781867493 | Predicción actual: [[0.41099557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005651166662573814, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3729417 ]\n",
      " [0.37990099]\n",
      " [0.14800465]\n",
      " [0.40675285]\n",
      " [0.41034743]\n",
      " [0.41219479]\n",
      " [0.41231957]\n",
      " [0.41099557]] | y: 0.3177063153816349 | Predicción actual: [[0.4082962]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011599384248256683, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37990099]\n",
      " [0.14800465]\n",
      " [0.40675285]\n",
      " [0.41034743]\n",
      " [0.41219479]\n",
      " [0.41231957]\n",
      " [0.41099557]\n",
      " [0.4082962 ]] | y: 0.31266950794265785 | Predicción actual: [[0.40480638]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012347333133220673, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40675285]\n",
      " [0.41034743]\n",
      " [0.41219479]\n",
      " [0.41231957]\n",
      " [0.41099557]\n",
      " [0.4082962 ]\n",
      " [0.40480638]] | y: 0.2890352576520729 | Predicción actual: [[0.4014281]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005552194081246853, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40675285]\n",
      " [0.41034743]\n",
      " [0.41219479]\n",
      " [0.41231957]\n",
      " [0.41099557]\n",
      " [0.4082962 ]\n",
      " [0.40480638]\n",
      " [0.4014281 ]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01972467079758644, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41034743]\n",
      " [0.41219479]\n",
      " [0.41231957]\n",
      " [0.41099557]\n",
      " [0.4082962 ]\n",
      " [0.40480638]\n",
      " [0.4014281 ]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.4552197]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014333344995975494, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41219479]\n",
      " [0.41231957]\n",
      " [0.41099557]\n",
      " [0.4082962 ]\n",
      " [0.40480638]\n",
      " [0.4014281 ]\n",
      " [0.28283611]\n",
      " [0.45521969]] | y: 0.2758620689655173 | Predicción actual: [[0.45287177]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01636778935790062, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41231957]\n",
      " [0.41099557]\n",
      " [0.4082962 ]\n",
      " [0.40480638]\n",
      " [0.4014281 ]\n",
      " [0.28283611]\n",
      " [0.45521969]\n",
      " [0.45287177]] | y: 0.2746997287872917 | Predicción actual: [[0.44949773]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028519373387098312, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41099557]\n",
      " [0.4082962 ]\n",
      " [0.40480638]\n",
      " [0.4014281 ]\n",
      " [0.28283611]\n",
      " [0.45521969]\n",
      " [0.45287177]\n",
      " [0.44949773]] | y: 0.275474622239442 | Predicción actual: [[0.44593528]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020262042060494423, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4082962 ]\n",
      " [0.40480638]\n",
      " [0.4014281 ]\n",
      " [0.28283611]\n",
      " [0.45521969]\n",
      " [0.45287177]\n",
      " [0.44949773]\n",
      " [0.44593528]] | y: 0.3347539713289423 | Predicción actual: [[0.44310698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018215544521808624, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40480638]\n",
      " [0.4014281 ]\n",
      " [0.28283611]\n",
      " [0.45521969]\n",
      " [0.45287177]\n",
      " [0.44949773]\n",
      " [0.44593528]\n",
      " [0.44310698]] | y: 0.35567609453700116 | Predicción actual: [[0.44188204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037991362623870373, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4014281 ]\n",
      " [0.28283611]\n",
      " [0.45521969]\n",
      " [0.45287177]\n",
      " [0.44949773]\n",
      " [0.44593528]\n",
      " [0.44310698]\n",
      " [0.44188204]] | y: 0.3366912049593181 | Predicción actual: [[0.44296482]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03260025382041931, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.45521969]\n",
      " [0.45287177]\n",
      " [0.44949773]\n",
      " [0.44593528]\n",
      " [0.44310698]\n",
      " [0.44188204]\n",
      " [0.44296482]] | y: 0.3335916311507167 | Predicción actual: [[0.4465931]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022948402911424637, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45521969]\n",
      " [0.45287177]\n",
      " [0.44949773]\n",
      " [0.44593528]\n",
      " [0.44310698]\n",
      " [0.44188204]\n",
      " [0.44296482]\n",
      " [0.44659311]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007230309420265257, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45287177]\n",
      " [0.44949773]\n",
      " [0.44593528]\n",
      " [0.44310698]\n",
      " [0.44188204]\n",
      " [0.44296482]\n",
      " [0.44659311]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.47859663]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020912105683237314, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44949773]\n",
      " [0.44593528]\n",
      " [0.44310698]\n",
      " [0.44188204]\n",
      " [0.44296482]\n",
      " [0.44659311]\n",
      " [0.3847346 ]\n",
      " [0.47859663]] | y: 0.5962805114296785 | Predicción actual: [[0.47571206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020267855376005173, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44593528]\n",
      " [0.44310698]\n",
      " [0.44188204]\n",
      " [0.44296482]\n",
      " [0.44659311]\n",
      " [0.3847346 ]\n",
      " [0.47859663]\n",
      " [0.47571206]] | y: 0.574583494769469 | Predicción actual: [[0.4734698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02296026609838009, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44310698]\n",
      " [0.44188204]\n",
      " [0.44296482]\n",
      " [0.44659311]\n",
      " [0.3847346 ]\n",
      " [0.47859663]\n",
      " [0.47571206]\n",
      " [0.47346979]] | y: 0.6063541263076326 | Predicción actual: [[0.4723394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029134944081306458, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44188204]\n",
      " [0.44296482]\n",
      " [0.44659311]\n",
      " [0.3847346 ]\n",
      " [0.47859663]\n",
      " [0.47571206]\n",
      " [0.47346979]\n",
      " [0.47233939]] | y: 0.5846571096474236 | Predicción actual: [[0.47258437]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004640618804842234, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44296482]\n",
      " [0.44659311]\n",
      " [0.3847346 ]\n",
      " [0.47859663]\n",
      " [0.47571206]\n",
      " [0.47346979]\n",
      " [0.47233939]\n",
      " [0.47258437]] | y: 0.5687717938783416 | Predicción actual: [[0.474113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016266285674646497, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44659311]\n",
      " [0.3847346 ]\n",
      " [0.47859663]\n",
      " [0.47571206]\n",
      " [0.47346979]\n",
      " [0.47233939]\n",
      " [0.47258437]\n",
      " [0.47411299]] | y: 0.6427741185586981 | Predicción actual: [[0.47658324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02990737371146679, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.47859663]\n",
      " [0.47571206]\n",
      " [0.47346979]\n",
      " [0.47233939]\n",
      " [0.47258437]\n",
      " [0.47411299]\n",
      " [0.47658324]] | y: 0.6617590081363811 | Predicción actual: [[0.47956064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06584055721759796, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47859663]\n",
      " [0.47571206]\n",
      " [0.47346979]\n",
      " [0.47233939]\n",
      " [0.47258437]\n",
      " [0.47411299]\n",
      " [0.47658324]\n",
      " [0.47956064]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04694057255983353, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47571206]\n",
      " [0.47346979]\n",
      " [0.47233939]\n",
      " [0.47258437]\n",
      " [0.47411299]\n",
      " [0.47658324]\n",
      " [0.47956064]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.49995637]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036653582006692886, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47346979]\n",
      " [0.47233939]\n",
      " [0.47258437]\n",
      " [0.47411299]\n",
      " [0.47658324]\n",
      " [0.47956064]\n",
      " [0.67299496]\n",
      " [0.49995637]] | y: 0.703990701278574 | Predicción actual: [[0.5029783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05847065895795822, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47233939]\n",
      " [0.47258437]\n",
      " [0.47411299]\n",
      " [0.47658324]\n",
      " [0.47956064]\n",
      " [0.67299496]\n",
      " [0.49995637]\n",
      " [0.50297832]] | y: 0.7272375048430839 | Predicción actual: [[0.5087848]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06981439888477325, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47258437]\n",
      " [0.47411299]\n",
      " [0.47658324]\n",
      " [0.47956064]\n",
      " [0.67299496]\n",
      " [0.49995637]\n",
      " [0.50297832]\n",
      " [0.50878477]] | y: 0.722588144130182 | Predicción actual: [[0.5172703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04036244750022888, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47411299]\n",
      " [0.47658324]\n",
      " [0.47956064]\n",
      " [0.67299496]\n",
      " [0.49995637]\n",
      " [0.50297832]\n",
      " [0.50878477]\n",
      " [0.51727033]] | y: 0.771793878341728 | Predicción actual: [[0.52801627]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08508654683828354, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47658324]\n",
      " [0.47956064]\n",
      " [0.67299496]\n",
      " [0.49995637]\n",
      " [0.50297832]\n",
      " [0.50878477]\n",
      " [0.51727033]\n",
      " [0.52801627]] | y: 0.7245253777605578 | Predicción actual: [[0.5405876]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.057438384741544724, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47956064]\n",
      " [0.67299496]\n",
      " [0.49995637]\n",
      " [0.50297832]\n",
      " [0.50878477]\n",
      " [0.51727033]\n",
      " [0.52801627]\n",
      " [0.5405876 ]] | y: 0.6710577295621851 | Predicción actual: [[0.5544952]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026958569884300232, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.49995637]\n",
      " [0.50297832]\n",
      " [0.50878477]\n",
      " [0.51727033]\n",
      " [0.52801627]\n",
      " [0.5405876 ]\n",
      " [0.55449522]] | y: 0.6737698566447115 | Predicción actual: [[0.5693673]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016236633528023958, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49995637]\n",
      " [0.50297832]\n",
      " [0.50878477]\n",
      " [0.51727033]\n",
      " [0.52801627]\n",
      " [0.5405876 ]\n",
      " [0.55449522]\n",
      " [0.56936729]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04237913340330124, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50297832]\n",
      " [0.50878477]\n",
      " [0.51727033]\n",
      " [0.52801627]\n",
      " [0.5405876 ]\n",
      " [0.55449522]\n",
      " [0.56936729]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5425511]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06450974941253662, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50878477]\n",
      " [0.51727033]\n",
      " [0.52801627]\n",
      " [0.5405876 ]\n",
      " [0.55449522]\n",
      " [0.56936729]\n",
      " [0.71445176]\n",
      " [0.5425511 ]] | y: 0.722588144130182 | Predicción actual: [[0.5531715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026735547930002213, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51727033]\n",
      " [0.52801627]\n",
      " [0.5405876 ]\n",
      " [0.55449522]\n",
      " [0.56936729]\n",
      " [0.71445176]\n",
      " [0.5425511 ]\n",
      " [0.55317152]] | y: 0.6993413405656723 | Predicción actual: [[0.5657922]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018410135060548782, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52801627]\n",
      " [0.5405876 ]\n",
      " [0.55449522]\n",
      " [0.56936729]\n",
      " [0.71445176]\n",
      " [0.5425511 ]\n",
      " [0.55317152]\n",
      " [0.5657922 ]] | y: 0.7373111197210385 | Predicción actual: [[0.5793666]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006061752326786518, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5405876 ]\n",
      " [0.55449522]\n",
      " [0.56936729]\n",
      " [0.71445176]\n",
      " [0.5425511 ]\n",
      " [0.55317152]\n",
      " [0.5657922 ]\n",
      " [0.57936662]] | y: 0.7214258039519565 | Predicción actual: [[0.5927168]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009878413751721382, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55449522]\n",
      " [0.56936729]\n",
      " [0.71445176]\n",
      " [0.5425511 ]\n",
      " [0.55317152]\n",
      " [0.5657922 ]\n",
      " [0.57936662]\n",
      " [0.59271681]] | y: 0.7187136768694304 | Predicción actual: [[0.6047421]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011623784899711609, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56936729]\n",
      " [0.71445176]\n",
      " [0.5425511 ]\n",
      " [0.55317152]\n",
      " [0.5657922 ]\n",
      " [0.57936662]\n",
      " [0.59271681]\n",
      " [0.60474211]] | y: 0.6741573033707864 | Predicción actual: [[0.6144716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005607889965176582, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.5425511 ]\n",
      " [0.55317152]\n",
      " [0.5657922 ]\n",
      " [0.57936662]\n",
      " [0.59271681]\n",
      " [0.60474211]\n",
      " [0.61447161]] | y: 0.698566447113522 | Predicción actual: [[0.62090933]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020499337464571, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5425511 ]\n",
      " [0.55317152]\n",
      " [0.5657922 ]\n",
      " [0.57936662]\n",
      " [0.59271681]\n",
      " [0.60474211]\n",
      " [0.61447161]\n",
      " [0.62090933]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03719125688076019, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55317152]\n",
      " [0.5657922 ]\n",
      " [0.57936662]\n",
      " [0.59271681]\n",
      " [0.60474211]\n",
      " [0.61447161]\n",
      " [0.62090933]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.60012233]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016638680244795978, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5657922 ]\n",
      " [0.57936662]\n",
      " [0.59271681]\n",
      " [0.60474211]\n",
      " [0.61447161]\n",
      " [0.62090933]\n",
      " [0.72103836]\n",
      " [0.60012233]] | y: 0.7562960092987214 | Predicción actual: [[0.6126776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0064121815375983715, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57936662]\n",
      " [0.59271681]\n",
      " [0.60474211]\n",
      " [0.61447161]\n",
      " [0.62090933]\n",
      " [0.72103836]\n",
      " [0.60012233]\n",
      " [0.61267757]] | y: 0.8275862068965516 | Predicción actual: [[0.6251867]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00982795748859644, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59271681]\n",
      " [0.60474211]\n",
      " [0.61447161]\n",
      " [0.62090933]\n",
      " [0.72103836]\n",
      " [0.60012233]\n",
      " [0.61267757]\n",
      " [0.62518668]] | y: 0.8388221619527314 | Predicción actual: [[0.63683754]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03646392002701759, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60474211]\n",
      " [0.61447161]\n",
      " [0.62090933]\n",
      " [0.72103836]\n",
      " [0.60012233]\n",
      " [0.61267757]\n",
      " [0.62518668]\n",
      " [0.63683754]] | y: 0.7942657884540876 | Predicción actual: [[0.64711916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019631417468190193, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61447161]\n",
      " [0.62090933]\n",
      " [0.72103836]\n",
      " [0.60012233]\n",
      " [0.61267757]\n",
      " [0.62518668]\n",
      " [0.63683754]\n",
      " [0.64711916]] | y: 0.7838047268500579 | Predicción actual: [[0.65573066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002182777738198638, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62090933]\n",
      " [0.72103836]\n",
      " [0.60012233]\n",
      " [0.61267757]\n",
      " [0.62518668]\n",
      " [0.63683754]\n",
      " [0.64711916]\n",
      " [0.65573066]] | y: 0.7679194110809764 | Predicción actual: [[0.6627471]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.311659232480451e-05, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.60012233]\n",
      " [0.61267757]\n",
      " [0.62518668]\n",
      " [0.63683754]\n",
      " [0.64711916]\n",
      " [0.65573066]\n",
      " [0.66274709]] | y: 0.7845796203022084 | Predicción actual: [[0.66875184]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004662823397666216, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60012233]\n",
      " [0.61267757]\n",
      " [0.62518668]\n",
      " [0.63683754]\n",
      " [0.64711916]\n",
      " [0.65573066]\n",
      " [0.66274709]\n",
      " [0.66875184]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05483386665582657, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61267757]\n",
      " [0.62518668]\n",
      " [0.63683754]\n",
      " [0.64711916]\n",
      " [0.65573066]\n",
      " [0.66274709]\n",
      " [0.66875184]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6596792]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1276494413614273, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62518668]\n",
      " [0.63683754]\n",
      " [0.64711916]\n",
      " [0.65573066]\n",
      " [0.66274709]\n",
      " [0.66875184]\n",
      " [0.87872917]\n",
      " [0.65967917]] | y: 0.8488957768306855 | Predicción actual: [[0.67334837]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038580283522605896, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63683754]\n",
      " [0.64711916]\n",
      " [0.65573066]\n",
      " [0.66274709]\n",
      " [0.66875184]\n",
      " [0.87872917]\n",
      " [0.65967917]\n",
      " [0.67334837]] | y: 0.8182874854707476 | Predicción actual: [[0.68787575]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021481094881892204, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64711916]\n",
      " [0.65573066]\n",
      " [0.66274709]\n",
      " [0.66875184]\n",
      " [0.87872917]\n",
      " [0.65967917]\n",
      " [0.67334837]\n",
      " [0.68787575]] | y: 0.8268113134444013 | Predicción actual: [[0.70291]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009244130924344063, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65573066]\n",
      " [0.66274709]\n",
      " [0.66875184]\n",
      " [0.87872917]\n",
      " [0.65967917]\n",
      " [0.67334837]\n",
      " [0.68787575]\n",
      " [0.70291001]] | y: 0.7853545137543589 | Predicción actual: [[0.7181505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008750149863772094, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66274709]\n",
      " [0.66875184]\n",
      " [0.87872917]\n",
      " [0.65967917]\n",
      " [0.67334837]\n",
      " [0.68787575]\n",
      " [0.70291001]\n",
      " [0.7181505 ]] | y: 0.7892289810151103 | Predicción actual: [[0.7332839]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007064095698297024, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66875184]\n",
      " [0.87872917]\n",
      " [0.65967917]\n",
      " [0.67334837]\n",
      " [0.68787575]\n",
      " [0.70291001]\n",
      " [0.7181505 ]\n",
      " [0.73328388]] | y: 0.8341728012398295 | Predicción actual: [[0.7482924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11785281449556351, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.65967917]\n",
      " [0.67334837]\n",
      " [0.68787575]\n",
      " [0.70291001]\n",
      " [0.7181505 ]\n",
      " [0.73328388]\n",
      " [0.74829239]] | y: 0.8124757845796202 | Predicción actual: [[0.7635409]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004628956783562899, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65967917]\n",
      " [0.67334837]\n",
      " [0.68787575]\n",
      " [0.70291001]\n",
      " [0.7181505 ]\n",
      " [0.73328388]\n",
      " [0.74829239]\n",
      " [0.76354092]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022163091227412224, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67334837]\n",
      " [0.68787575]\n",
      " [0.70291001]\n",
      " [0.7181505 ]\n",
      " [0.73328388]\n",
      " [0.74829239]\n",
      " [0.76354092]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.73278034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005209931172430515, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68787575]\n",
      " [0.70291001]\n",
      " [0.7181505 ]\n",
      " [0.73328388]\n",
      " [0.74829239]\n",
      " [0.76354092]\n",
      " [0.80123983]\n",
      " [0.73278034]] | y: 0.793490895001937 | Predicción actual: [[0.748178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002873907098546624, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70291001]\n",
      " [0.7181505 ]\n",
      " [0.73328388]\n",
      " [0.74829239]\n",
      " [0.76354092]\n",
      " [0.80123983]\n",
      " [0.73278034]\n",
      " [0.74817801]] | y: 0.760170476559473 | Predicción actual: [[0.7628758]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005735302111133933, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7181505 ]\n",
      " [0.73328388]\n",
      " [0.74829239]\n",
      " [0.76354092]\n",
      " [0.80123983]\n",
      " [0.73278034]\n",
      " [0.74817801]\n",
      " [0.7628758 ]] | y: 0.7353738860906625 | Predicción actual: [[0.77615654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028191469609737396, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73328388]\n",
      " [0.74829239]\n",
      " [0.76354092]\n",
      " [0.80123983]\n",
      " [0.73278034]\n",
      " [0.74817801]\n",
      " [0.7628758 ]\n",
      " [0.77615654]] | y: 0.7101898488957767 | Predicción actual: [[0.78742844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019954951480031013, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74829239]\n",
      " [0.76354092]\n",
      " [0.80123983]\n",
      " [0.73278034]\n",
      " [0.74817801]\n",
      " [0.7628758 ]\n",
      " [0.77615654]\n",
      " [0.78742844]] | y: 0.7121270825261525 | Predicción actual: [[0.79580647]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.6604254799167393e-06, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76354092]\n",
      " [0.80123983]\n",
      " [0.73278034]\n",
      " [0.74817801]\n",
      " [0.7628758 ]\n",
      " [0.77615654]\n",
      " [0.78742844]\n",
      " [0.79580647]] | y: 0.7396358000774894 | Predicción actual: [[0.80114204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008794126100838184, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.73278034]\n",
      " [0.74817801]\n",
      " [0.7628758 ]\n",
      " [0.77615654]\n",
      " [0.78742844]\n",
      " [0.79580647]\n",
      " [0.80114204]] | y: 0.7361487795428128 | Predicción actual: [[0.8028738]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015417050570249557, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73278034]\n",
      " [0.74817801]\n",
      " [0.7628758 ]\n",
      " [0.77615654]\n",
      " [0.78742844]\n",
      " [0.79580647]\n",
      " [0.80114204]\n",
      " [0.80287379]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012644668109714985, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74817801]\n",
      " [0.7628758 ]\n",
      " [0.77615654]\n",
      " [0.78742844]\n",
      " [0.79580647]\n",
      " [0.80114204]\n",
      " [0.80287379]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.80590516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029426081106066704, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7628758 ]\n",
      " [0.77615654]\n",
      " [0.78742844]\n",
      " [0.79580647]\n",
      " [0.80114204]\n",
      " [0.80287379]\n",
      " [0.66757071]\n",
      " [0.80590516]] | y: 0.696629213483146 | Predicción actual: [[0.8142425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044601235538721085, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77615654]\n",
      " [0.78742844]\n",
      " [0.79580647]\n",
      " [0.80114204]\n",
      " [0.80287379]\n",
      " [0.66757071]\n",
      " [0.80590516]\n",
      " [0.81424248]] | y: 0.6559473072452537 | Predicción actual: [[0.818734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09131905436515808, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78742844]\n",
      " [0.79580647]\n",
      " [0.80114204]\n",
      " [0.80287379]\n",
      " [0.66757071]\n",
      " [0.80590516]\n",
      " [0.81424248]\n",
      " [0.81873399]] | y: 0.6788066640836885 | Predicción actual: [[0.8192504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004241147544234991, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79580647]\n",
      " [0.80114204]\n",
      " [0.80287379]\n",
      " [0.66757071]\n",
      " [0.80590516]\n",
      " [0.81424248]\n",
      " [0.81873399]\n",
      " [0.8192504 ]] | y: 0.6760945370011622 | Predicción actual: [[0.81685543]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007090497296303511, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80114204]\n",
      " [0.80287379]\n",
      " [0.66757071]\n",
      " [0.80590516]\n",
      " [0.81424248]\n",
      " [0.81873399]\n",
      " [0.8192504 ]\n",
      " [0.81685543]] | y: 0.7295621851995349 | Predicción actual: [[0.8124905]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010672473348677158, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80287379]\n",
      " [0.66757071]\n",
      " [0.80590516]\n",
      " [0.81424248]\n",
      " [0.81873399]\n",
      " [0.8192504 ]\n",
      " [0.81685543]\n",
      " [0.81249052]] | y: 0.7012785741960481 | Predicción actual: [[0.807276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05162667855620384, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.80590516]\n",
      " [0.81424248]\n",
      " [0.81873399]\n",
      " [0.8192504 ]\n",
      " [0.81685543]\n",
      " [0.81249052]\n",
      " [0.80727601]] | y: 0.767531964354901 | Predicción actual: [[0.8023346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009199324995279312, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80590516]\n",
      " [0.81424248]\n",
      " [0.81873399]\n",
      " [0.8192504 ]\n",
      " [0.81685543]\n",
      " [0.81249052]\n",
      " [0.80727601]\n",
      " [0.80233461]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008875653147697449, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81424248]\n",
      " [0.81873399]\n",
      " [0.8192504 ]\n",
      " [0.81685543]\n",
      " [0.81249052]\n",
      " [0.80727601]\n",
      " [0.80233461]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8413467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021784210577607155, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81873399]\n",
      " [0.8192504 ]\n",
      " [0.81685543]\n",
      " [0.81249052]\n",
      " [0.80727601]\n",
      " [0.80233461]\n",
      " [0.75513367]\n",
      " [0.84134668]] | y: 0.7520340953118947 | Predicción actual: [[0.8392929]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06777212023735046, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8192504 ]\n",
      " [0.81685543]\n",
      " [0.81249052]\n",
      " [0.80727601]\n",
      " [0.80233461]\n",
      " [0.75513367]\n",
      " [0.84134668]\n",
      " [0.83929288]] | y: 0.7098024021697016 | Predicción actual: [[0.83499104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043129242956638336, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81685543]\n",
      " [0.81249052]\n",
      " [0.80727601]\n",
      " [0.80233461]\n",
      " [0.75513367]\n",
      " [0.84134668]\n",
      " [0.83929288]\n",
      " [0.83499104]] | y: 0.6904300658659435 | Predicción actual: [[0.8300564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008564362302422523, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81249052]\n",
      " [0.80727601]\n",
      " [0.80233461]\n",
      " [0.75513367]\n",
      " [0.84134668]\n",
      " [0.83929288]\n",
      " [0.83499104]\n",
      " [0.83005643]] | y: 0.7543587756683454 | Predicción actual: [[0.8260399]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01532233227044344, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80727601]\n",
      " [0.80233461]\n",
      " [0.75513367]\n",
      " [0.84134668]\n",
      " [0.83929288]\n",
      " [0.83499104]\n",
      " [0.83005643]\n",
      " [0.82603991]] | y: 0.7222006974041069 | Predicción actual: [[0.8238815]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.580193515517749e-05, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80233461]\n",
      " [0.75513367]\n",
      " [0.84134668]\n",
      " [0.83929288]\n",
      " [0.83499104]\n",
      " [0.83005643]\n",
      " [0.82603991]\n",
      " [0.82388151]] | y: 0.8485083301046106 | Predicción actual: [[0.82444286]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00227131019346416, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.84134668]\n",
      " [0.83929288]\n",
      " [0.83499104]\n",
      " [0.83005643]\n",
      " [0.82603991]\n",
      " [0.82388151]\n",
      " [0.82444286]] | y: 0.9054629988376597 | Predicción actual: [[0.82797885]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028039485216140747, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84134668]\n",
      " [0.83929288]\n",
      " [0.83499104]\n",
      " [0.83005643]\n",
      " [0.82603991]\n",
      " [0.82388151]\n",
      " [0.82444286]\n",
      " [0.82797885]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00324825057759881, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83929288]\n",
      " [0.83499104]\n",
      " [0.83005643]\n",
      " [0.82603991]\n",
      " [0.82388151]\n",
      " [0.82444286]\n",
      " [0.82797885]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.84389967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005515566444955766, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83499104]\n",
      " [0.83005643]\n",
      " [0.82603991]\n",
      " [0.82388151]\n",
      " [0.82444286]\n",
      " [0.82797885]\n",
      " [0.8822162 ]\n",
      " [0.84389967]] | y: 0.889577683068578 | Predicción actual: [[0.8409362]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006958117242902517, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83005643]\n",
      " [0.82603991]\n",
      " [0.82388151]\n",
      " [0.82444286]\n",
      " [0.82797885]\n",
      " [0.8822162 ]\n",
      " [0.84389967]\n",
      " [0.84093618]] | y: 0.8748547074777218 | Predicción actual: [[0.8394588]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023155400529503822, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82603991]\n",
      " [0.82388151]\n",
      " [0.82444286]\n",
      " [0.82797885]\n",
      " [0.8822162 ]\n",
      " [0.84389967]\n",
      " [0.84093618]\n",
      " [0.83945882]] | y: 0.9132119333591631 | Predicción actual: [[0.8404148]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023803038522601128, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82388151]\n",
      " [0.82444286]\n",
      " [0.82797885]\n",
      " [0.8822162 ]\n",
      " [0.84389967]\n",
      " [0.84093618]\n",
      " [0.83945882]\n",
      " [0.84041482]] | y: 1.0 | Predicción actual: [[0.8437309]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01033044420182705, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82444286]\n",
      " [0.82797885]\n",
      " [0.8822162 ]\n",
      " [0.84389967]\n",
      " [0.84093618]\n",
      " [0.83945882]\n",
      " [0.84041482]\n",
      " [0.84373093]] | y: 0.9705540488182873 | Predicción actual: [[0.84885883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055007580667734146, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82797885]\n",
      " [0.8822162 ]\n",
      " [0.84389967]\n",
      " [0.84093618]\n",
      " [0.83945882]\n",
      " [0.84041482]\n",
      " [0.84373093]\n",
      " [0.84885883]] | y: 0.8888027896164277 | Predicción actual: [[0.85511106]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001782241277396679, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.84389967]\n",
      " [0.84093618]\n",
      " [0.83945882]\n",
      " [0.84041482]\n",
      " [0.84373093]\n",
      " [0.84885883]\n",
      " [0.85511106]] | y: 0.877954281286323 | Predicción actual: [[0.8611034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029719600453972816, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84389967]\n",
      " [0.84093618]\n",
      " [0.83945882]\n",
      " [0.84041482]\n",
      " [0.84373093]\n",
      " [0.84885883]\n",
      " [0.85511106]\n",
      " [0.86110342]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.0789458327926695e-06, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84093618]\n",
      " [0.83945882]\n",
      " [0.84041482]\n",
      " [0.84373093]\n",
      " [0.84885883]\n",
      " [0.85511106]\n",
      " [0.86110342]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.850892]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017070096218958497, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83945882]\n",
      " [0.84041482]\n",
      " [0.84373093]\n",
      " [0.84885883]\n",
      " [0.85511106]\n",
      " [0.86110342]\n",
      " [0.84889578]\n",
      " [0.85089201]] | y: 0.8550949244478885 | Predicción actual: [[0.8523466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01529329176992178, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84041482]\n",
      " [0.84373093]\n",
      " [0.84885883]\n",
      " [0.85511106]\n",
      " [0.86110342]\n",
      " [0.84889578]\n",
      " [0.85089201]\n",
      " [0.8523466 ]] | y: 0.8752421542037967 | Predicción actual: [[0.85506684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006467398256063461, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84373093]\n",
      " [0.84885883]\n",
      " [0.85511106]\n",
      " [0.86110342]\n",
      " [0.84889578]\n",
      " [0.85089201]\n",
      " [0.8523466 ]\n",
      " [0.85506684]] | y: 0.857032158078264 | Predicción actual: [[0.85795105]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011338473297655582, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84885883]\n",
      " [0.85511106]\n",
      " [0.86110342]\n",
      " [0.84889578]\n",
      " [0.85089201]\n",
      " [0.8523466 ]\n",
      " [0.85506684]\n",
      " [0.85795105]] | y: 0.8500581170089112 | Predicción actual: [[0.8601767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029062967747449875, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85511106]\n",
      " [0.86110342]\n",
      " [0.84889578]\n",
      " [0.85089201]\n",
      " [0.8523466 ]\n",
      " [0.85506684]\n",
      " [0.85795105]\n",
      " [0.86017668]] | y: 0.8426966292134832 | Predicción actual: [[0.86091447]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020955633372068405, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86110342]\n",
      " [0.84889578]\n",
      " [0.85089201]\n",
      " [0.8523466 ]\n",
      " [0.85506684]\n",
      " [0.85795105]\n",
      " [0.86017668]\n",
      " [0.86091447]] | y: 0.8229368461836497 | Predicción actual: [[0.86034214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005621341988444328, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.85089201]\n",
      " [0.8523466 ]\n",
      " [0.85506684]\n",
      " [0.85795105]\n",
      " [0.86017668]\n",
      " [0.86091447]\n",
      " [0.86034214]] | y: 0.7745060054242543 | Predicción actual: [[0.85797304]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07662350684404373, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85089201]\n",
      " [0.8523466 ]\n",
      " [0.85506684]\n",
      " [0.85795105]\n",
      " [0.86017668]\n",
      " [0.86091447]\n",
      " [0.86034214]\n",
      " [0.85797304]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.79399807570735e-07, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8523466 ]\n",
      " [0.85506684]\n",
      " [0.85795105]\n",
      " [0.86017668]\n",
      " [0.86091447]\n",
      " [0.86034214]\n",
      " [0.85797304]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8589274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004888531751930714, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85506684]\n",
      " [0.85795105]\n",
      " [0.86017668]\n",
      " [0.86091447]\n",
      " [0.86034214]\n",
      " [0.85797304]\n",
      " [0.78419217]\n",
      " [0.85892743]] | y: 0.854320030995738 | Predicción actual: [[0.8586253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05057749152183533, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85795105]\n",
      " [0.86017668]\n",
      " [0.86091447]\n",
      " [0.86034214]\n",
      " [0.85797304]\n",
      " [0.78419217]\n",
      " [0.85892743]\n",
      " [0.85862529]] | y: 0.8368849283223556 | Predicción actual: [[0.85653526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012121071631554514, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86017668]\n",
      " [0.86091447]\n",
      " [0.86034214]\n",
      " [0.85797304]\n",
      " [0.78419217]\n",
      " [0.85892743]\n",
      " [0.85862529]\n",
      " [0.85653526]] | y: 0.8299108872530028 | Predicción actual: [[0.85311186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010929488344118, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86091447]\n",
      " [0.86034214]\n",
      " [0.85797304]\n",
      " [0.78419217]\n",
      " [0.85892743]\n",
      " [0.85862529]\n",
      " [0.85653526]\n",
      " [0.85311186]] | y: 0.887253002712127 | Predicción actual: [[0.8484985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004940981511026621, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86034214]\n",
      " [0.85797304]\n",
      " [0.78419217]\n",
      " [0.85892743]\n",
      " [0.85862529]\n",
      " [0.85653526]\n",
      " [0.85311186]\n",
      " [0.84849852]] | y: 0.8597442851607902 | Predicción actual: [[0.84341115]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005325069185346365, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85797304]\n",
      " [0.78419217]\n",
      " [0.85892743]\n",
      " [0.85862529]\n",
      " [0.85653526]\n",
      " [0.85311186]\n",
      " [0.84849852]\n",
      " [0.84341115]] | y: 0.8395970554048819 | Predicción actual: [[0.83805794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007815752178430557, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.85892743]\n",
      " [0.85862529]\n",
      " [0.85653526]\n",
      " [0.85311186]\n",
      " [0.84849852]\n",
      " [0.84341115]\n",
      " [0.83805794]] | y: 0.7838047268500579 | Predicción actual: [[0.8331007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0058904956094920635, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85892743]\n",
      " [0.85862529]\n",
      " [0.85653526]\n",
      " [0.85311186]\n",
      " [0.84849852]\n",
      " [0.84341115]\n",
      " [0.83805794]\n",
      " [0.83310068]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.6352921850048006e-05, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85862529]\n",
      " [0.85653526]\n",
      " [0.85311186]\n",
      " [0.84849852]\n",
      " [0.84341115]\n",
      " [0.83805794]\n",
      " [0.83310068]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8463481]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011064806021749973, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85653526]\n",
      " [0.85311186]\n",
      " [0.84849852]\n",
      " [0.84341115]\n",
      " [0.83805794]\n",
      " [0.83310068]\n",
      " [0.81828749]\n",
      " [0.84634811]] | y: 0.7605579232855482 | Predicción actual: [[0.84184015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00048634546692483127, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85311186]\n",
      " [0.84849852]\n",
      " [0.84341115]\n",
      " [0.83805794]\n",
      " [0.83310068]\n",
      " [0.81828749]\n",
      " [0.84634811]\n",
      " [0.84184015]] | y: 0.7915536613715615 | Predicción actual: [[0.8369799]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016043779032770544, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84849852]\n",
      " [0.84341115]\n",
      " [0.83805794]\n",
      " [0.83310068]\n",
      " [0.81828749]\n",
      " [0.84634811]\n",
      " [0.84184015]\n",
      " [0.83697993]] | y: 0.7686943045331267 | Predicción actual: [[0.8323504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0148342689499259, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84341115]\n",
      " [0.83805794]\n",
      " [0.83310068]\n",
      " [0.81828749]\n",
      " [0.84634811]\n",
      " [0.84184015]\n",
      " [0.83697993]\n",
      " [0.83235037]] | y: 0.7686943045331267 | Predicción actual: [[0.8282111]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012839799746870995, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83805794]\n",
      " [0.83310068]\n",
      " [0.81828749]\n",
      " [0.84634811]\n",
      " [0.84184015]\n",
      " [0.83697993]\n",
      " [0.83235037]\n",
      " [0.82821113]] | y: 0.7989151491669895 | Predicción actual: [[0.8249265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021393257193267345, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83310068]\n",
      " [0.81828749]\n",
      " [0.84634811]\n",
      " [0.84184015]\n",
      " [0.83697993]\n",
      " [0.83235037]\n",
      " [0.82821113]\n",
      " [0.8249265 ]] | y: 0.7900038744672608 | Predicción actual: [[0.8228765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017917795106768608, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.84634811]\n",
      " [0.84184015]\n",
      " [0.83697993]\n",
      " [0.83235037]\n",
      " [0.82821113]\n",
      " [0.8249265 ]\n",
      " [0.82287651]] | y: 0.760170476559473 | Predicción actual: [[0.8218563]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.264226193598006e-05, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84634811]\n",
      " [0.84184015]\n",
      " [0.83697993]\n",
      " [0.83235037]\n",
      " [0.82821113]\n",
      " [0.8249265 ]\n",
      " [0.82287651]\n",
      " [0.82185632]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.0639448905512836e-07, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84184015]\n",
      " [0.83697993]\n",
      " [0.83235037]\n",
      " [0.82821113]\n",
      " [0.8249265 ]\n",
      " [0.82287651]\n",
      " [0.82185632]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8192848]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06389207392930984, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83697993]\n",
      " [0.83235037]\n",
      " [0.82821113]\n",
      " [0.8249265 ]\n",
      " [0.82287651]\n",
      " [0.82185632]\n",
      " [0.68539326]\n",
      " [0.8192848 ]] | y: 0.6648585819449826 | Predicción actual: [[0.8122075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08365881443023682, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83235037]\n",
      " [0.82821113]\n",
      " [0.8249265 ]\n",
      " [0.82287651]\n",
      " [0.82185632]\n",
      " [0.68539326]\n",
      " [0.8192848 ]\n",
      " [0.81220752]] | y: 0.7078651685393258 | Predicción actual: [[0.80386627]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016555532813072205, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82821113]\n",
      " [0.8249265 ]\n",
      " [0.82287651]\n",
      " [0.82185632]\n",
      " [0.68539326]\n",
      " [0.8192848 ]\n",
      " [0.81220752]\n",
      " [0.80386627]] | y: 0.6648585819449826 | Predicción actual: [[0.7947931]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01547241397202015, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8249265 ]\n",
      " [0.82287651]\n",
      " [0.82185632]\n",
      " [0.68539326]\n",
      " [0.8192848 ]\n",
      " [0.81220752]\n",
      " [0.80386627]\n",
      " [0.79479313]] | y: 0.7113521890740022 | Predicción actual: [[0.78515124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002650803653523326, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82287651]\n",
      " [0.82185632]\n",
      " [0.68539326]\n",
      " [0.8192848 ]\n",
      " [0.81220752]\n",
      " [0.80386627]\n",
      " [0.79479313]\n",
      " [0.78515124]] | y: 0.6772568771793879 | Predicción actual: [[0.775116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02318860962986946, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82185632]\n",
      " [0.68539326]\n",
      " [0.8192848 ]\n",
      " [0.81220752]\n",
      " [0.80386627]\n",
      " [0.79479313]\n",
      " [0.78515124]\n",
      " [0.77511603]] | y: 0.7621077101898488 | Predicción actual: [[0.76439345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010283620096743107, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.8192848 ]\n",
      " [0.81220752]\n",
      " [0.80386627]\n",
      " [0.79479313]\n",
      " [0.78515124]\n",
      " [0.77511603]\n",
      " [0.76439345]] | y: 0.8070515304145678 | Predicción actual: [[0.75326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027791480533778667, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8192848 ]\n",
      " [0.81220752]\n",
      " [0.80386627]\n",
      " [0.79479313]\n",
      " [0.78515124]\n",
      " [0.77511603]\n",
      " [0.76439345]\n",
      " [0.75326002]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005678905174136162, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81220752]\n",
      " [0.80386627]\n",
      " [0.79479313]\n",
      " [0.78515124]\n",
      " [0.77511603]\n",
      " [0.76439345]\n",
      " [0.75326002]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7715099]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001210616435855627, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80386627]\n",
      " [0.79479313]\n",
      " [0.78515124]\n",
      " [0.77511603]\n",
      " [0.76439345]\n",
      " [0.75326002]\n",
      " [0.81518791]\n",
      " [0.77150989]] | y: 0.9597055404881829 | Predicción actual: [[0.7636067]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012079005129635334, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79479313]\n",
      " [0.78515124]\n",
      " [0.77511603]\n",
      " [0.76439345]\n",
      " [0.75326002]\n",
      " [0.81518791]\n",
      " [0.77150989]\n",
      " [0.76360673]] | y: 0.9643549012010848 | Predicción actual: [[0.75687104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019089121371507645, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78515124]\n",
      " [0.77511603]\n",
      " [0.76439345]\n",
      " [0.75326002]\n",
      " [0.81518791]\n",
      " [0.77150989]\n",
      " [0.76360673]\n",
      " [0.75687104]] | y: 0.8880278961642774 | Predicción actual: [[0.7517715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012555869296193123, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77511603]\n",
      " [0.76439345]\n",
      " [0.75326002]\n",
      " [0.81518791]\n",
      " [0.77150989]\n",
      " [0.76360673]\n",
      " [0.75687104]\n",
      " [0.75177151]] | y: 0.8926772568771792 | Predicción actual: [[0.748587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013160507660359144, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76439345]\n",
      " [0.75326002]\n",
      " [0.81518791]\n",
      " [0.77150989]\n",
      " [0.76360673]\n",
      " [0.75687104]\n",
      " [0.75177151]\n",
      " [0.74858701]] | y: 0.8752421542037967 | Predicción actual: [[0.7474466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001458467566408217, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75326002]\n",
      " [0.81518791]\n",
      " [0.77150989]\n",
      " [0.76360673]\n",
      " [0.75687104]\n",
      " [0.75177151]\n",
      " [0.74858701]\n",
      " [0.7474466 ]] | y: 0.8508330104610615 | Predicción actual: [[0.7486436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038888897746801376, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.77150989]\n",
      " [0.76360673]\n",
      " [0.75687104]\n",
      " [0.75177151]\n",
      " [0.74858701]\n",
      " [0.7474466 ]\n",
      " [0.74864358]] | y: 0.8488957768306855 | Predicción actual: [[0.7525716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09822705388069153, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77150989]\n",
      " [0.76360673]\n",
      " [0.75687104]\n",
      " [0.75177151]\n",
      " [0.74858701]\n",
      " [0.7474466 ]\n",
      " [0.74864358]\n",
      " [0.75257158]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029971759766340256, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76360673]\n",
      " [0.75687104]\n",
      " [0.75177151]\n",
      " [0.74858701]\n",
      " [0.7474466 ]\n",
      " [0.74864358]\n",
      " [0.75257158]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7365334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027407590299844742, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75687104]\n",
      " [0.75177151]\n",
      " [0.74858701]\n",
      " [0.7474466 ]\n",
      " [0.74864358]\n",
      " [0.75257158]\n",
      " [0.96241767]\n",
      " [0.7365334 ]] | y: 0.9407206509104997 | Predicción actual: [[0.73754245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.14267663657665253, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75177151]\n",
      " [0.74858701]\n",
      " [0.7474466 ]\n",
      " [0.74864358]\n",
      " [0.75257158]\n",
      " [0.96241767]\n",
      " [0.7365334 ]\n",
      " [0.73754245]] | y: 0.9724912824486633 | Predicción actual: [[0.7420753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05993887409567833, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74858701]\n",
      " [0.7474466 ]\n",
      " [0.74864358]\n",
      " [0.75257158]\n",
      " [0.96241767]\n",
      " [0.7365334 ]\n",
      " [0.73754245]\n",
      " [0.74207532]] | y: 0.9969004261913985 | Predicción actual: [[0.7495958]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10091755539178848, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7474466 ]\n",
      " [0.74864358]\n",
      " [0.75257158]\n",
      " [0.96241767]\n",
      " [0.7365334 ]\n",
      " [0.73754245]\n",
      " [0.74207532]\n",
      " [0.74959582]] | y: 0.951181712514529 | Predicción actual: [[0.7593823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018673164770007133, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74864358]\n",
      " [0.75257158]\n",
      " [0.96241767]\n",
      " [0.7365334 ]\n",
      " [0.73754245]\n",
      " [0.74207532]\n",
      " [0.74959582]\n",
      " [0.75938231]] | y: 0.8957768306857805 | Predicción actual: [[0.7702351]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03380664810538292, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75257158]\n",
      " [0.96241767]\n",
      " [0.7365334 ]\n",
      " [0.73754245]\n",
      " [0.74207532]\n",
      " [0.74959582]\n",
      " [0.75938231]\n",
      " [0.77023512]] | y: 0.8814413018209997 | Predicción actual: [[0.7810795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002081534592434764, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.7365334 ]\n",
      " [0.73754245]\n",
      " [0.74207532]\n",
      " [0.74959582]\n",
      " [0.75938231]\n",
      " [0.77023512]\n",
      " [0.78107947]] | y: 0.9170864006199149 | Predicción actual: [[0.79049516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04145814850926399, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7365334 ]\n",
      " [0.73754245]\n",
      " [0.74207532]\n",
      " [0.74959582]\n",
      " [0.75938231]\n",
      " [0.77023512]\n",
      " [0.78107947]\n",
      " [0.79049516]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03963065892457962, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73754245]\n",
      " [0.74207532]\n",
      " [0.74959582]\n",
      " [0.75938231]\n",
      " [0.77023512]\n",
      " [0.78107947]\n",
      " [0.79049516]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7470513]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09285274147987366, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74207532]\n",
      " [0.74959582]\n",
      " [0.75938231]\n",
      " [0.77023512]\n",
      " [0.78107947]\n",
      " [0.79049516]\n",
      " [0.91979853]\n",
      " [0.7470513 ]] | y: 0.9682293684618366 | Predicción actual: [[0.75799024]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06982921808958054, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74959582]\n",
      " [0.75938231]\n",
      " [0.77023512]\n",
      " [0.78107947]\n",
      " [0.79049516]\n",
      " [0.91979853]\n",
      " [0.7470513 ]\n",
      " [0.75799024]] | y: 0.9577683068578069 | Predicción actual: [[0.77068055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016684934496879578, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.21046695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023962315171957016, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21046695]] | y: 0.10422316931421921 | Predicción actual: [[0.19536956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018195107579231262, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21046695]\n",
      " [0.19536956]] | y: 0.15420379697791559 | Predicción actual: [[0.19978587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000671441899612546, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21046695]\n",
      " [0.19536956]\n",
      " [0.19978587]] | y: 0.1557535838822161 | Predicción actual: [[0.21162552]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016065661329776049, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21046695]\n",
      " [0.19536956]\n",
      " [0.19978587]\n",
      " [0.21162552]] | y: 0.12553273924835334 | Predicción actual: [[0.22478676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006977023556828499, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21046695]\n",
      " [0.19536956]\n",
      " [0.19978587]\n",
      " [0.21162552]\n",
      " [0.22478676]] | y: 0.1456799690042619 | Predicción actual: [[0.23553003]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014905384741723537, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21046695]\n",
      " [0.19536956]\n",
      " [0.19978587]\n",
      " [0.21162552]\n",
      " [0.22478676]\n",
      " [0.23553003]] | y: 0.1464548624564122 | Predicción actual: [[0.25795442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011963468044996262, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.21046695]\n",
      " [0.19536956]\n",
      " [0.19978587]\n",
      " [0.21162552]\n",
      " [0.22478676]\n",
      " [0.23553003]\n",
      " [0.25795442]] | y: 0.1960480433940332 | Predicción actual: [[0.28564698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006706104148179293, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21046695]\n",
      " [0.19536956]\n",
      " [0.19978587]\n",
      " [0.21162552]\n",
      " [0.22478676]\n",
      " [0.23553003]\n",
      " [0.25795442]\n",
      " [0.28564698]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014151323586702347, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19536956]\n",
      " [0.19978587]\n",
      " [0.21162552]\n",
      " [0.22478676]\n",
      " [0.23553003]\n",
      " [0.25795442]\n",
      " [0.28564698]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.32158944]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005485665984451771, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19978587]\n",
      " [0.21162552]\n",
      " [0.22478676]\n",
      " [0.23553003]\n",
      " [0.25795442]\n",
      " [0.28564698]\n",
      " [0.2305308 ]\n",
      " [0.32158944]] | y: 0.211933359163115 | Predicción actual: [[0.32918292]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02433883771300316, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21162552]\n",
      " [0.22478676]\n",
      " [0.23553003]\n",
      " [0.25795442]\n",
      " [0.28564698]\n",
      " [0.2305308 ]\n",
      " [0.32158944]\n",
      " [0.32918292]] | y: 0.2072839984502131 | Predicción actual: [[0.3386344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017304042354226112, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22478676]\n",
      " [0.23553003]\n",
      " [0.25795442]\n",
      " [0.28564698]\n",
      " [0.2305308 ]\n",
      " [0.32158944]\n",
      " [0.32918292]\n",
      " [0.3386344 ]] | y: 0.19294846958543205 | Predicción actual: [[0.34873492]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042413562536239624, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23553003]\n",
      " [0.25795442]\n",
      " [0.28564698]\n",
      " [0.2305308 ]\n",
      " [0.32158944]\n",
      " [0.32918292]\n",
      " [0.3386344 ]\n",
      " [0.34873492]] | y: 0.19682293684618352 | Predicción actual: [[0.3593439]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01762494631111622, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25795442]\n",
      " [0.28564698]\n",
      " [0.2305308 ]\n",
      " [0.32158944]\n",
      " [0.32918292]\n",
      " [0.3386344 ]\n",
      " [0.34873492]\n",
      " [0.35934389]] | y: 0.21425803951956607 | Predicción actual: [[0.37119773]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023371214047074318, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28564698]\n",
      " [0.2305308 ]\n",
      " [0.32158944]\n",
      " [0.32918292]\n",
      " [0.3386344 ]\n",
      " [0.34873492]\n",
      " [0.35934389]\n",
      " [0.37119773]] | y: 0.18132506780317698 | Predicción actual: [[0.3816259]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055039212107658386, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.32158944]\n",
      " [0.32918292]\n",
      " [0.3386344 ]\n",
      " [0.34873492]\n",
      " [0.35934389]\n",
      " [0.37119773]\n",
      " [0.38162589]] | y: 0.17512592018597434 | Predicción actual: [[0.3889861]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060096826404333115, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32158944]\n",
      " [0.32918292]\n",
      " [0.3386344 ]\n",
      " [0.34873492]\n",
      " [0.35934389]\n",
      " [0.37119773]\n",
      " [0.38162589]\n",
      " [0.38898611]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07476285099983215, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32918292]\n",
      " [0.3386344 ]\n",
      " [0.34873492]\n",
      " [0.35934389]\n",
      " [0.37119773]\n",
      " [0.38162589]\n",
      " [0.38898611]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.41825637]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0447215735912323, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3386344 ]\n",
      " [0.34873492]\n",
      " [0.35934389]\n",
      " [0.37119773]\n",
      " [0.38162589]\n",
      " [0.38898611]\n",
      " [0.14800465]\n",
      " [0.41825637]] | y: 0.19217357613328173 | Predicción actual: [[0.42225695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05974441021680832, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34873492]\n",
      " [0.35934389]\n",
      " [0.37119773]\n",
      " [0.38162589]\n",
      " [0.38898611]\n",
      " [0.14800465]\n",
      " [0.41825637]\n",
      " [0.42225695]] | y: 0.1859744285160791 | Predicción actual: [[0.42437682]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08778566867113113, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35934389]\n",
      " [0.37119773]\n",
      " [0.38162589]\n",
      " [0.38898611]\n",
      " [0.14800465]\n",
      " [0.41825637]\n",
      " [0.42225695]\n",
      " [0.42437682]] | y: 0.26695079426578844 | Predicción actual: [[0.424639]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04673147201538086, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37119773]\n",
      " [0.38162589]\n",
      " [0.38898611]\n",
      " [0.14800465]\n",
      " [0.41825637]\n",
      " [0.42225695]\n",
      " [0.42437682]\n",
      " [0.42463899]] | y: 0.2925222781867493 | Predicción actual: [[0.42332423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00929012056440115, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38162589]\n",
      " [0.38898611]\n",
      " [0.14800465]\n",
      " [0.41825637]\n",
      " [0.42225695]\n",
      " [0.42437682]\n",
      " [0.42463899]\n",
      " [0.42332423]] | y: 0.3177063153816349 | Predicción actual: [[0.4205875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010155060328543186, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38898611]\n",
      " [0.14800465]\n",
      " [0.41825637]\n",
      " [0.42225695]\n",
      " [0.42437682]\n",
      " [0.42463899]\n",
      " [0.42332423]\n",
      " [0.42058751]] | y: 0.31266950794265785 | Predicción actual: [[0.4170621]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017464889213442802, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.41825637]\n",
      " [0.42225695]\n",
      " [0.42437682]\n",
      " [0.42463899]\n",
      " [0.42332423]\n",
      " [0.42058751]\n",
      " [0.4170621 ]] | y: 0.2890352576520729 | Predicción actual: [[0.41369838]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006874443963170052, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41825637]\n",
      " [0.42225695]\n",
      " [0.42437682]\n",
      " [0.42463899]\n",
      " [0.42332423]\n",
      " [0.42058751]\n",
      " [0.4170621 ]\n",
      " [0.41369838]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031281717121601105, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42225695]\n",
      " [0.42437682]\n",
      " [0.42463899]\n",
      " [0.42332423]\n",
      " [0.42058751]\n",
      " [0.4170621 ]\n",
      " [0.41369838]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.47127327]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050565578043460846, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42437682]\n",
      " [0.42463899]\n",
      " [0.42332423]\n",
      " [0.42058751]\n",
      " [0.4170621 ]\n",
      " [0.41369838]\n",
      " [0.28283611]\n",
      " [0.47127327]] | y: 0.2758620689655173 | Predicción actual: [[0.46861508]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041517943143844604, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42463899]\n",
      " [0.42332423]\n",
      " [0.42058751]\n",
      " [0.4170621 ]\n",
      " [0.41369838]\n",
      " [0.28283611]\n",
      " [0.47127327]\n",
      " [0.46861508]] | y: 0.2746997287872917 | Predicción actual: [[0.46475884]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028107335790991783, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42332423]\n",
      " [0.42058751]\n",
      " [0.4170621 ]\n",
      " [0.41369838]\n",
      " [0.28283611]\n",
      " [0.47127327]\n",
      " [0.46861508]\n",
      " [0.46475884]] | y: 0.275474622239442 | Predicción actual: [[0.4606859]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051080018281936646, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42058751]\n",
      " [0.4170621 ]\n",
      " [0.41369838]\n",
      " [0.28283611]\n",
      " [0.47127327]\n",
      " [0.46861508]\n",
      " [0.46475884]\n",
      " [0.46068591]] | y: 0.3347539713289423 | Predicción actual: [[0.45734203]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015726806595921516, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4170621 ]\n",
      " [0.41369838]\n",
      " [0.28283611]\n",
      " [0.47127327]\n",
      " [0.46861508]\n",
      " [0.46475884]\n",
      " [0.46068591]\n",
      " [0.45734203]] | y: 0.35567609453700116 | Predicción actual: [[0.45574448]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010870768688619137, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41369838]\n",
      " [0.28283611]\n",
      " [0.47127327]\n",
      " [0.46861508]\n",
      " [0.46475884]\n",
      " [0.46068591]\n",
      " [0.45734203]\n",
      " [0.45574448]] | y: 0.3366912049593181 | Predicción actual: [[0.4566031]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010712887160480022, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.47127327]\n",
      " [0.46861508]\n",
      " [0.46475884]\n",
      " [0.46068591]\n",
      " [0.45734203]\n",
      " [0.45574448]\n",
      " [0.45660311]] | y: 0.3335916311507167 | Predicción actual: [[0.46025315]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03834623098373413, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47127327]\n",
      " [0.46861508]\n",
      " [0.46475884]\n",
      " [0.46068591]\n",
      " [0.45734203]\n",
      " [0.45574448]\n",
      " [0.45660311]\n",
      " [0.46025315]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01727193407714367, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46861508]\n",
      " [0.46475884]\n",
      " [0.46068591]\n",
      " [0.45734203]\n",
      " [0.45574448]\n",
      " [0.45660311]\n",
      " [0.46025315]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.4953017]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010722099978011101, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46475884]\n",
      " [0.46068591]\n",
      " [0.45734203]\n",
      " [0.45574448]\n",
      " [0.45660311]\n",
      " [0.46025315]\n",
      " [0.3847346 ]\n",
      " [0.49530169]] | y: 0.5962805114296785 | Predicción actual: [[0.4915574]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008126700296998024, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46068591]\n",
      " [0.45734203]\n",
      " [0.45574448]\n",
      " [0.45660311]\n",
      " [0.46025315]\n",
      " [0.3847346 ]\n",
      " [0.49530169]\n",
      " [0.49155739]] | y: 0.574583494769469 | Predicción actual: [[0.48844406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000937313016038388, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45734203]\n",
      " [0.45574448]\n",
      " [0.45660311]\n",
      " [0.46025315]\n",
      " [0.3847346 ]\n",
      " [0.49530169]\n",
      " [0.49155739]\n",
      " [0.48844406]] | y: 0.6063541263076326 | Predicción actual: [[0.48645243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004751143511384726, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45574448]\n",
      " [0.45660311]\n",
      " [0.46025315]\n",
      " [0.3847346 ]\n",
      " [0.49530169]\n",
      " [0.49155739]\n",
      " [0.48844406]\n",
      " [0.48645243]] | y: 0.5846571096474236 | Predicción actual: [[0.48591548]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005096673034131527, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45660311]\n",
      " [0.46025315]\n",
      " [0.3847346 ]\n",
      " [0.49530169]\n",
      " [0.49155739]\n",
      " [0.48844406]\n",
      " [0.48645243]\n",
      " [0.48591548]] | y: 0.5687717938783416 | Predicción actual: [[0.48680034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002492991916369647, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46025315]\n",
      " [0.3847346 ]\n",
      " [0.49530169]\n",
      " [0.49155739]\n",
      " [0.48844406]\n",
      " [0.48645243]\n",
      " [0.48591548]\n",
      " [0.48680034]] | y: 0.6427741185586981 | Predicción actual: [[0.48872855]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08494838327169418, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.49530169]\n",
      " [0.49155739]\n",
      " [0.48844406]\n",
      " [0.48645243]\n",
      " [0.48591548]\n",
      " [0.48680034]\n",
      " [0.48872855]] | y: 0.6617590081363811 | Predicción actual: [[0.49125075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025642789900302887, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49530169]\n",
      " [0.49155739]\n",
      " [0.48844406]\n",
      " [0.48645243]\n",
      " [0.48591548]\n",
      " [0.48680034]\n",
      " [0.48872855]\n",
      " [0.49125075]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023374266922473907, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49155739]\n",
      " [0.48844406]\n",
      " [0.48645243]\n",
      " [0.48591548]\n",
      " [0.48680034]\n",
      " [0.48872855]\n",
      " [0.49125075]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5139907]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08362182229757309, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48844406]\n",
      " [0.48645243]\n",
      " [0.48591548]\n",
      " [0.48680034]\n",
      " [0.48872855]\n",
      " [0.49125075]\n",
      " [0.67299496]\n",
      " [0.5139907 ]] | y: 0.703990701278574 | Predicción actual: [[0.5161057]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05021892488002777, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48645243]\n",
      " [0.48591548]\n",
      " [0.48680034]\n",
      " [0.48872855]\n",
      " [0.49125075]\n",
      " [0.67299496]\n",
      " [0.5139907 ]\n",
      " [0.51610571]] | y: 0.7272375048430839 | Predicción actual: [[0.5210558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01749088428914547, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48591548]\n",
      " [0.48680034]\n",
      " [0.48872855]\n",
      " [0.49125075]\n",
      " [0.67299496]\n",
      " [0.5139907 ]\n",
      " [0.51610571]\n",
      " [0.52105582]] | y: 0.722588144130182 | Predicción actual: [[0.52871597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.059262875467538834, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48680034]\n",
      " [0.48872855]\n",
      " [0.49125075]\n",
      " [0.67299496]\n",
      " [0.5139907 ]\n",
      " [0.51610571]\n",
      " [0.52105582]\n",
      " [0.52871597]] | y: 0.771793878341728 | Predicción actual: [[0.5387816]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035852860659360886, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48872855]\n",
      " [0.49125075]\n",
      " [0.67299496]\n",
      " [0.5139907 ]\n",
      " [0.51610571]\n",
      " [0.52105582]\n",
      " [0.52871597]\n",
      " [0.53878158]] | y: 0.7245253777605578 | Predicción actual: [[0.55074984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027894731611013412, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49125075]\n",
      " [0.67299496]\n",
      " [0.5139907 ]\n",
      " [0.51610571]\n",
      " [0.52105582]\n",
      " [0.52871597]\n",
      " [0.53878158]\n",
      " [0.55074984]] | y: 0.6710577295621851 | Predicción actual: [[0.56414336]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026835931930691004, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.5139907 ]\n",
      " [0.51610571]\n",
      " [0.52105582]\n",
      " [0.52871597]\n",
      " [0.53878158]\n",
      " [0.55074984]\n",
      " [0.56414336]] | y: 0.6737698566447115 | Predicción actual: [[0.5785411]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026795314624905586, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5139907 ]\n",
      " [0.51610571]\n",
      " [0.52105582]\n",
      " [0.52871597]\n",
      " [0.53878158]\n",
      " [0.55074984]\n",
      " [0.56414336]\n",
      " [0.5785411 ]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00897106621414423, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51610571]\n",
      " [0.52105582]\n",
      " [0.52871597]\n",
      " [0.53878158]\n",
      " [0.55074984]\n",
      " [0.56414336]\n",
      " [0.5785411 ]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.55308086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04751760512590408, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52105582]\n",
      " [0.52871597]\n",
      " [0.53878158]\n",
      " [0.55074984]\n",
      " [0.56414336]\n",
      " [0.5785411 ]\n",
      " [0.71445176]\n",
      " [0.55308086]] | y: 0.722588144130182 | Predicción actual: [[0.56288433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029411399737000465, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52871597]\n",
      " [0.53878158]\n",
      " [0.55074984]\n",
      " [0.56414336]\n",
      " [0.5785411 ]\n",
      " [0.71445176]\n",
      " [0.55308086]\n",
      " [0.56288433]] | y: 0.6993413405656723 | Predicción actual: [[0.57473576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018038458656519651, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53878158]\n",
      " [0.55074984]\n",
      " [0.56414336]\n",
      " [0.5785411 ]\n",
      " [0.71445176]\n",
      " [0.55308086]\n",
      " [0.56288433]\n",
      " [0.57473576]] | y: 0.7373111197210385 | Predicción actual: [[0.5875211]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012942592147737741, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55074984]\n",
      " [0.56414336]\n",
      " [0.5785411 ]\n",
      " [0.71445176]\n",
      " [0.55308086]\n",
      " [0.56288433]\n",
      " [0.57473576]\n",
      " [0.58752108]] | y: 0.7214258039519565 | Predicción actual: [[0.6000943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033501614816486835, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56414336]\n",
      " [0.5785411 ]\n",
      " [0.71445176]\n",
      " [0.55308086]\n",
      " [0.56288433]\n",
      " [0.57473576]\n",
      " [0.58752108]\n",
      " [0.60009432]] | y: 0.7187136768694304 | Predicción actual: [[0.6113662]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006001863512210548, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5785411 ]\n",
      " [0.71445176]\n",
      " [0.55308086]\n",
      " [0.56288433]\n",
      " [0.57473576]\n",
      " [0.58752108]\n",
      " [0.60009432]\n",
      " [0.61136621]] | y: 0.6741573033707864 | Predicción actual: [[0.6202635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006093622650951147, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55308086]\n",
      " [0.56288433]\n",
      " [0.57473576]\n",
      " [0.58752108]\n",
      " [0.60009432]\n",
      " [0.61136621]\n",
      " [0.62026352]] | y: 0.698566447113522 | Predicción actual: [[0.6260624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.81639464548789e-05, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55308086]\n",
      " [0.56288433]\n",
      " [0.57473576]\n",
      " [0.58752108]\n",
      " [0.60009432]\n",
      " [0.61136621]\n",
      " [0.62026352]\n",
      " [0.62606239]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02514629438519478, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56288433]\n",
      " [0.57473576]\n",
      " [0.58752108]\n",
      " [0.60009432]\n",
      " [0.61136621]\n",
      " [0.62026352]\n",
      " [0.62606239]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6058389]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014295278117060661, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57473576]\n",
      " [0.58752108]\n",
      " [0.60009432]\n",
      " [0.61136621]\n",
      " [0.62026352]\n",
      " [0.62606239]\n",
      " [0.72103836]\n",
      " [0.60583889]] | y: 0.7562960092987214 | Predicción actual: [[0.61757934]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014142561703920364, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58752108]\n",
      " [0.60009432]\n",
      " [0.61136621]\n",
      " [0.62026352]\n",
      " [0.62606239]\n",
      " [0.72103836]\n",
      " [0.60583889]\n",
      " [0.61757934]] | y: 0.8275862068965516 | Predicción actual: [[0.62921953]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04628254473209381, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60009432]\n",
      " [0.61136621]\n",
      " [0.62026352]\n",
      " [0.62606239]\n",
      " [0.72103836]\n",
      " [0.60583889]\n",
      " [0.61757934]\n",
      " [0.62921953]] | y: 0.8388221619527314 | Predicción actual: [[0.64012474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04688427224755287, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61136621]\n",
      " [0.62026352]\n",
      " [0.62606239]\n",
      " [0.72103836]\n",
      " [0.60583889]\n",
      " [0.61757934]\n",
      " [0.62921953]\n",
      " [0.64012474]] | y: 0.7942657884540876 | Predicción actual: [[0.6497108]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006351065821945667, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62026352]\n",
      " [0.62606239]\n",
      " [0.72103836]\n",
      " [0.60583889]\n",
      " [0.61757934]\n",
      " [0.62921953]\n",
      " [0.64012474]\n",
      " [0.64971077]] | y: 0.7838047268500579 | Predicción actual: [[0.65755516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014612624421715736, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62606239]\n",
      " [0.72103836]\n",
      " [0.60583889]\n",
      " [0.61757934]\n",
      " [0.62921953]\n",
      " [0.64012474]\n",
      " [0.64971077]\n",
      " [0.65755516]] | y: 0.7679194110809764 | Predicción actual: [[0.6639957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03384697064757347, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.60583889]\n",
      " [0.61757934]\n",
      " [0.62921953]\n",
      " [0.64012474]\n",
      " [0.64971077]\n",
      " [0.65755516]\n",
      " [0.66399568]] | y: 0.7845796203022084 | Predicción actual: [[0.66969824]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012230302207171917, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60583889]\n",
      " [0.61757934]\n",
      " [0.62921953]\n",
      " [0.64012474]\n",
      " [0.64971077]\n",
      " [0.65755516]\n",
      " [0.66399568]\n",
      " [0.66969824]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05205840989947319, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61757934]\n",
      " [0.62921953]\n",
      " [0.64012474]\n",
      " [0.64971077]\n",
      " [0.65755516]\n",
      " [0.66399568]\n",
      " [0.66969824]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6611343]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07677996903657913, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62921953]\n",
      " [0.64012474]\n",
      " [0.64971077]\n",
      " [0.65755516]\n",
      " [0.66399568]\n",
      " [0.66969824]\n",
      " [0.87872917]\n",
      " [0.6611343 ]] | y: 0.8488957768306855 | Predicción actual: [[0.6742724]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00212320638820529, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64012474]\n",
      " [0.64971077]\n",
      " [0.65755516]\n",
      " [0.66399568]\n",
      " [0.66969824]\n",
      " [0.87872917]\n",
      " [0.6611343 ]\n",
      " [0.67427242]] | y: 0.8182874854707476 | Predicción actual: [[0.68817335]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025081099942326546, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64971077]\n",
      " [0.65755516]\n",
      " [0.66399568]\n",
      " [0.66969824]\n",
      " [0.87872917]\n",
      " [0.6611343 ]\n",
      " [0.67427242]\n",
      " [0.68817335]] | y: 0.8268113134444013 | Predicción actual: [[0.7026732]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018545735627412796, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65755516]\n",
      " [0.66399568]\n",
      " [0.66969824]\n",
      " [0.87872917]\n",
      " [0.6611343 ]\n",
      " [0.67427242]\n",
      " [0.68817335]\n",
      " [0.7026732 ]] | y: 0.7853545137543589 | Predicción actual: [[0.7175142]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0048618800938129425, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66399568]\n",
      " [0.66969824]\n",
      " [0.87872917]\n",
      " [0.6611343 ]\n",
      " [0.67427242]\n",
      " [0.68817335]\n",
      " [0.7026732 ]\n",
      " [0.71751422]] | y: 0.7892289810151103 | Predicción actual: [[0.7325171]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012493672547861934, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66969824]\n",
      " [0.87872917]\n",
      " [0.6611343 ]\n",
      " [0.67427242]\n",
      " [0.68817335]\n",
      " [0.7026732 ]\n",
      " [0.71751422]\n",
      " [0.73251712]] | y: 0.8341728012398295 | Predicción actual: [[0.7474646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034753703512251377, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.6611343 ]\n",
      " [0.67427242]\n",
      " [0.68817335]\n",
      " [0.7026732 ]\n",
      " [0.71751422]\n",
      " [0.73251712]\n",
      " [0.7474646 ]] | y: 0.8124757845796202 | Predicción actual: [[0.76241446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006221678340807557, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6611343 ]\n",
      " [0.67427242]\n",
      " [0.68817335]\n",
      " [0.7026732 ]\n",
      " [0.71751422]\n",
      " [0.73251712]\n",
      " [0.7474646 ]\n",
      " [0.76241446]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008127370965667069, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67427242]\n",
      " [0.68817335]\n",
      " [0.7026732 ]\n",
      " [0.71751422]\n",
      " [0.73251712]\n",
      " [0.7474646 ]\n",
      " [0.76241446]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7304747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011446282267570496, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68817335]\n",
      " [0.7026732 ]\n",
      " [0.71751422]\n",
      " [0.73251712]\n",
      " [0.7474646 ]\n",
      " [0.76241446]\n",
      " [0.80123983]\n",
      " [0.73047471]] | y: 0.793490895001937 | Predicción actual: [[0.7451018]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006937052123248577, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7026732 ]\n",
      " [0.71751422]\n",
      " [0.73251712]\n",
      " [0.7474646 ]\n",
      " [0.76241446]\n",
      " [0.80123983]\n",
      " [0.73047471]\n",
      " [0.74510181]] | y: 0.760170476559473 | Predicción actual: [[0.75908375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008298698230646551, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71751422]\n",
      " [0.73251712]\n",
      " [0.7474646 ]\n",
      " [0.76241446]\n",
      " [0.80123983]\n",
      " [0.73047471]\n",
      " [0.74510181]\n",
      " [0.75908375]] | y: 0.7353738860906625 | Predicción actual: [[0.77182066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004624261986464262, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73251712]\n",
      " [0.7474646 ]\n",
      " [0.76241446]\n",
      " [0.80123983]\n",
      " [0.73047471]\n",
      " [0.74510181]\n",
      " [0.75908375]\n",
      " [0.77182066]] | y: 0.7101898488957767 | Predicción actual: [[0.782393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05498118698596954, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7474646 ]\n",
      " [0.76241446]\n",
      " [0.80123983]\n",
      " [0.73047471]\n",
      " [0.74510181]\n",
      " [0.75908375]\n",
      " [0.77182066]\n",
      " [0.78239298]] | y: 0.7121270825261525 | Predicción actual: [[0.78980273]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.5963369150995277e-05, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76241446]\n",
      " [0.80123983]\n",
      " [0.73047471]\n",
      " [0.74510181]\n",
      " [0.75908375]\n",
      " [0.77182066]\n",
      " [0.78239298]\n",
      " [0.78980273]] | y: 0.7396358000774894 | Predicción actual: [[0.79408664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015221280045807362, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.73047471]\n",
      " [0.74510181]\n",
      " [0.75908375]\n",
      " [0.77182066]\n",
      " [0.78239298]\n",
      " [0.78980273]\n",
      " [0.79408664]] | y: 0.7361487795428128 | Predicción actual: [[0.79495925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012122885091230273, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73047471]\n",
      " [0.74510181]\n",
      " [0.75908375]\n",
      " [0.77182066]\n",
      " [0.78239298]\n",
      " [0.78980273]\n",
      " [0.79408664]\n",
      " [0.79495925]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028490561991930008, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74510181]\n",
      " [0.75908375]\n",
      " [0.77182066]\n",
      " [0.78239298]\n",
      " [0.78980273]\n",
      " [0.79408664]\n",
      " [0.79495925]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.7951619]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010870302096009254, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75908375]\n",
      " [0.77182066]\n",
      " [0.78239298]\n",
      " [0.78980273]\n",
      " [0.79408664]\n",
      " [0.79495925]\n",
      " [0.66757071]\n",
      " [0.7951619 ]] | y: 0.696629213483146 | Predicción actual: [[0.8027902]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039852432906627655, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77182066]\n",
      " [0.78239298]\n",
      " [0.78980273]\n",
      " [0.79408664]\n",
      " [0.79495925]\n",
      " [0.66757071]\n",
      " [0.7951619 ]\n",
      " [0.80279022]] | y: 0.6559473072452537 | Predicción actual: [[0.80668175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008689844980835915, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78239298]\n",
      " [0.78980273]\n",
      " [0.79408664]\n",
      " [0.79495925]\n",
      " [0.66757071]\n",
      " [0.7951619 ]\n",
      " [0.80279022]\n",
      " [0.80668175]] | y: 0.6788066640836885 | Predicción actual: [[0.8070648]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04446146637201309, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78980273]\n",
      " [0.79408664]\n",
      " [0.79495925]\n",
      " [0.66757071]\n",
      " [0.7951619 ]\n",
      " [0.80279022]\n",
      " [0.80668175]\n",
      " [0.80706477]] | y: 0.6760945370011622 | Predicción actual: [[0.8041958]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00046596574247814715, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79408664]\n",
      " [0.79495925]\n",
      " [0.66757071]\n",
      " [0.7951619 ]\n",
      " [0.80279022]\n",
      " [0.80668175]\n",
      " [0.80706477]\n",
      " [0.80419582]] | y: 0.7295621851995349 | Predicción actual: [[0.799508]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01667371205985546, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79495925]\n",
      " [0.66757071]\n",
      " [0.7951619 ]\n",
      " [0.80279022]\n",
      " [0.80668175]\n",
      " [0.80706477]\n",
      " [0.80419582]\n",
      " [0.79950798]] | y: 0.7012785741960481 | Predicción actual: [[0.79395133]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007029547356069088, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.7951619 ]\n",
      " [0.80279022]\n",
      " [0.80668175]\n",
      " [0.80706477]\n",
      " [0.80419582]\n",
      " [0.79950798]\n",
      " [0.79395133]] | y: 0.767531964354901 | Predicción actual: [[0.7889484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016388393705710769, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7951619 ]\n",
      " [0.80279022]\n",
      " [0.80668175]\n",
      " [0.80706477]\n",
      " [0.80419582]\n",
      " [0.79950798]\n",
      " [0.79395133]\n",
      " [0.78894842]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001131863915361464, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80279022]\n",
      " [0.80668175]\n",
      " [0.80706477]\n",
      " [0.80419582]\n",
      " [0.79950798]\n",
      " [0.79395133]\n",
      " [0.78894842]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8242432]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009354466572403908, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80668175]\n",
      " [0.80706477]\n",
      " [0.80419582]\n",
      " [0.79950798]\n",
      " [0.79395133]\n",
      " [0.78894842]\n",
      " [0.75513367]\n",
      " [0.82424319]] | y: 0.7520340953118947 | Predicción actual: [[0.8221258]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021251851692795753, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80706477]\n",
      " [0.80419582]\n",
      " [0.79950798]\n",
      " [0.79395133]\n",
      " [0.78894842]\n",
      " [0.75513367]\n",
      " [0.82424319]\n",
      " [0.82212579]] | y: 0.7098024021697016 | Predicción actual: [[0.81823653]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006818654015660286, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80419582]\n",
      " [0.79950798]\n",
      " [0.79395133]\n",
      " [0.78894842]\n",
      " [0.75513367]\n",
      " [0.82424319]\n",
      " [0.82212579]\n",
      " [0.81823653]] | y: 0.6904300658659435 | Predicción actual: [[0.8139685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025538005866110325, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79950798]\n",
      " [0.79395133]\n",
      " [0.78894842]\n",
      " [0.75513367]\n",
      " [0.82424319]\n",
      " [0.82212579]\n",
      " [0.81823653]\n",
      " [0.81396848]] | y: 0.7543587756683454 | Predicción actual: [[0.8106935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019664853811264038, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79395133]\n",
      " [0.78894842]\n",
      " [0.75513367]\n",
      " [0.82424319]\n",
      " [0.82212579]\n",
      " [0.81823653]\n",
      " [0.81396848]\n",
      " [0.8106935 ]] | y: 0.7222006974041069 | Predicción actual: [[0.80915385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0354192852973938, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78894842]\n",
      " [0.75513367]\n",
      " [0.82424319]\n",
      " [0.82212579]\n",
      " [0.81823653]\n",
      " [0.81396848]\n",
      " [0.8106935 ]\n",
      " [0.80915385]] | y: 0.8485083301046106 | Predicción actual: [[0.80986273]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005865386337973177, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.82424319]\n",
      " [0.82212579]\n",
      " [0.81823653]\n",
      " [0.81396848]\n",
      " [0.8106935 ]\n",
      " [0.80915385]\n",
      " [0.80986273]] | y: 0.9054629988376597 | Predicción actual: [[0.8133435]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024431537836790085, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82424319]\n",
      " [0.82212579]\n",
      " [0.81823653]\n",
      " [0.81396848]\n",
      " [0.8106935 ]\n",
      " [0.80915385]\n",
      " [0.80986273]\n",
      " [0.81334352]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009921267628669739, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82212579]\n",
      " [0.81823653]\n",
      " [0.81396848]\n",
      " [0.8106935 ]\n",
      " [0.80915385]\n",
      " [0.80986273]\n",
      " [0.81334352]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8256962]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01038420107215643, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81823653]\n",
      " [0.81396848]\n",
      " [0.8106935 ]\n",
      " [0.80915385]\n",
      " [0.80986273]\n",
      " [0.81334352]\n",
      " [0.8822162 ]\n",
      " [0.82569617]] | y: 0.889577683068578 | Predicción actual: [[0.8238754]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02653655596077442, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81396848]\n",
      " [0.8106935 ]\n",
      " [0.80915385]\n",
      " [0.80986273]\n",
      " [0.81334352]\n",
      " [0.8822162 ]\n",
      " [0.82569617]\n",
      " [0.82387543]] | y: 0.8748547074777218 | Predicción actual: [[0.82402915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012084508314728737, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8106935 ]\n",
      " [0.80915385]\n",
      " [0.80986273]\n",
      " [0.81334352]\n",
      " [0.8822162 ]\n",
      " [0.82569617]\n",
      " [0.82387543]\n",
      " [0.82402915]] | y: 0.9132119333591631 | Predicción actual: [[0.8264281]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0048591624945402145, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80915385]\n",
      " [0.80986273]\n",
      " [0.81334352]\n",
      " [0.8822162 ]\n",
      " [0.82569617]\n",
      " [0.82387543]\n",
      " [0.82402915]\n",
      " [0.82642812]] | y: 1.0 | Predicción actual: [[0.8308632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023670965805649757, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80986273]\n",
      " [0.81334352]\n",
      " [0.8822162 ]\n",
      " [0.82569617]\n",
      " [0.82387543]\n",
      " [0.82402915]\n",
      " [0.82642812]\n",
      " [0.83086318]] | y: 0.9705540488182873 | Predicción actual: [[0.83700866]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014098258689045906, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81334352]\n",
      " [0.8822162 ]\n",
      " [0.82569617]\n",
      " [0.82387543]\n",
      " [0.82402915]\n",
      " [0.82642812]\n",
      " [0.83086318]\n",
      " [0.83700866]] | y: 0.8888027896164277 | Predicción actual: [[0.8438848]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016252966597676277, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.82569617]\n",
      " [0.82387543]\n",
      " [0.82402915]\n",
      " [0.82642812]\n",
      " [0.83086318]\n",
      " [0.83700866]\n",
      " [0.84388483]] | y: 0.877954281286323 | Predicción actual: [[0.85065424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007972825318574905, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82569617]\n",
      " [0.82387543]\n",
      " [0.82402915]\n",
      " [0.82642812]\n",
      " [0.83086318]\n",
      " [0.83700866]\n",
      " [0.84388483]\n",
      " [0.85065424]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017872776836156845, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82387543]\n",
      " [0.82402915]\n",
      " [0.82642812]\n",
      " [0.83086318]\n",
      " [0.83700866]\n",
      " [0.84388483]\n",
      " [0.85065424]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8388855]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011261907406151295, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82402915]\n",
      " [0.82642812]\n",
      " [0.83086318]\n",
      " [0.83700866]\n",
      " [0.84388483]\n",
      " [0.85065424]\n",
      " [0.84889578]\n",
      " [0.83888549]] | y: 0.8550949244478885 | Predicción actual: [[0.8425262]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027654122561216354, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82642812]\n",
      " [0.83086318]\n",
      " [0.83700866]\n",
      " [0.84388483]\n",
      " [0.85065424]\n",
      " [0.84889578]\n",
      " [0.83888549]\n",
      " [0.8425262 ]] | y: 0.8752421542037967 | Predicción actual: [[0.8472973]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007376876892521977, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83086318]\n",
      " [0.83700866]\n",
      " [0.84388483]\n",
      " [0.85065424]\n",
      " [0.84889578]\n",
      " [0.83888549]\n",
      " [0.8425262 ]\n",
      " [0.84729731]] | y: 0.857032158078264 | Predicción actual: [[0.85216445]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007850495167076588, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83700866]\n",
      " [0.84388483]\n",
      " [0.85065424]\n",
      " [0.84889578]\n",
      " [0.83888549]\n",
      " [0.8425262 ]\n",
      " [0.84729731]\n",
      " [0.85216445]] | y: 0.8500581170089112 | Predicción actual: [[0.8566311]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007420804351568222, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84388483]\n",
      " [0.85065424]\n",
      " [0.84889578]\n",
      " [0.83888549]\n",
      " [0.8425262 ]\n",
      " [0.84729731]\n",
      " [0.85216445]\n",
      " [0.8566311 ]] | y: 0.8426966292134832 | Predicción actual: [[0.85965645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010126117616891861, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85065424]\n",
      " [0.84889578]\n",
      " [0.83888549]\n",
      " [0.8425262 ]\n",
      " [0.84729731]\n",
      " [0.85216445]\n",
      " [0.8566311 ]\n",
      " [0.85965645]] | y: 0.8229368461836497 | Predicción actual: [[0.8608436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013474300503730774, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.83888549]\n",
      " [0.8425262 ]\n",
      " [0.84729731]\n",
      " [0.85216445]\n",
      " [0.8566311 ]\n",
      " [0.85965645]\n",
      " [0.8608436 ]] | y: 0.7745060054242543 | Predicción actual: [[0.8600938]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03940162435173988, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83888549]\n",
      " [0.8425262 ]\n",
      " [0.84729731]\n",
      " [0.85216445]\n",
      " [0.8566311 ]\n",
      " [0.85965645]\n",
      " [0.8608436 ]\n",
      " [0.86009377]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015144948847591877, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8425262 ]\n",
      " [0.84729731]\n",
      " [0.85216445]\n",
      " [0.8566311 ]\n",
      " [0.85965645]\n",
      " [0.8608436 ]\n",
      " [0.86009377]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.86240166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.519452315638773e-05, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84729731]\n",
      " [0.85216445]\n",
      " [0.8566311 ]\n",
      " [0.85965645]\n",
      " [0.8608436 ]\n",
      " [0.86009377]\n",
      " [0.78419217]\n",
      " [0.86240166]] | y: 0.854320030995738 | Predicción actual: [[0.864224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008821561350487173, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85216445]\n",
      " [0.8566311 ]\n",
      " [0.85965645]\n",
      " [0.8608436 ]\n",
      " [0.86009377]\n",
      " [0.78419217]\n",
      " [0.86240166]\n",
      " [0.86422402]] | y: 0.8368849283223556 | Predicción actual: [[0.86462045]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03371553122997284, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8566311 ]\n",
      " [0.85965645]\n",
      " [0.8608436 ]\n",
      " [0.86009377]\n",
      " [0.78419217]\n",
      " [0.86240166]\n",
      " [0.86422402]\n",
      " [0.86462045]] | y: 0.8299108872530028 | Predicción actual: [[0.86305475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035120879765599966, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85965645]\n",
      " [0.8608436 ]\n",
      " [0.86009377]\n",
      " [0.78419217]\n",
      " [0.86240166]\n",
      " [0.86422402]\n",
      " [0.86462045]\n",
      " [0.86305475]] | y: 0.887253002712127 | Predicción actual: [[0.85999054]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001166722722700797, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8608436 ]\n",
      " [0.86009377]\n",
      " [0.78419217]\n",
      " [0.86240166]\n",
      " [0.86422402]\n",
      " [0.86462045]\n",
      " [0.86305475]\n",
      " [0.85999054]] | y: 0.8597442851607902 | Predicción actual: [[0.85607994]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027228137478232384, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86009377]\n",
      " [0.78419217]\n",
      " [0.86240166]\n",
      " [0.86422402]\n",
      " [0.86462045]\n",
      " [0.86305475]\n",
      " [0.85999054]\n",
      " [0.85607994]] | y: 0.8395970554048819 | Predicción actual: [[0.8520734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019128357991576195, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.86240166]\n",
      " [0.86422402]\n",
      " [0.86462045]\n",
      " [0.86305475]\n",
      " [0.85999054]\n",
      " [0.85607994]\n",
      " [0.85207337]] | y: 0.7838047268500579 | Predicción actual: [[0.8482925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.067115024663508e-05, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86240166]\n",
      " [0.86422402]\n",
      " [0.86462045]\n",
      " [0.86305475]\n",
      " [0.85999054]\n",
      " [0.85607994]\n",
      " [0.85207337]\n",
      " [0.84829253]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00495743565261364, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86422402]\n",
      " [0.86462045]\n",
      " [0.86305475]\n",
      " [0.85999054]\n",
      " [0.85607994]\n",
      " [0.85207337]\n",
      " [0.84829253]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8661657]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.607463678345084e-05, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86462045]\n",
      " [0.86305475]\n",
      " [0.85999054]\n",
      " [0.85607994]\n",
      " [0.85207337]\n",
      " [0.84829253]\n",
      " [0.81828749]\n",
      " [0.8661657 ]] | y: 0.7605579232855482 | Predicción actual: [[0.86316884]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045728567987680435, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86305475]\n",
      " [0.85999054]\n",
      " [0.85607994]\n",
      " [0.85207337]\n",
      " [0.84829253]\n",
      " [0.81828749]\n",
      " [0.8661657 ]\n",
      " [0.86316884]] | y: 0.7915536613715615 | Predicción actual: [[0.8589162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014837841736152768, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85999054]\n",
      " [0.85607994]\n",
      " [0.85207337]\n",
      " [0.84829253]\n",
      " [0.81828749]\n",
      " [0.8661657 ]\n",
      " [0.86316884]\n",
      " [0.85891622]] | y: 0.7686943045331267 | Predicción actual: [[0.854578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023361966013908386, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85607994]\n",
      " [0.85207337]\n",
      " [0.84829253]\n",
      " [0.81828749]\n",
      " [0.8661657 ]\n",
      " [0.86316884]\n",
      " [0.85891622]\n",
      " [0.85457802]] | y: 0.7686943045331267 | Predicción actual: [[0.8505565]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061534762382507324, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85207337]\n",
      " [0.84829253]\n",
      " [0.81828749]\n",
      " [0.8661657 ]\n",
      " [0.86316884]\n",
      " [0.85891622]\n",
      " [0.85457802]\n",
      " [0.85055649]] | y: 0.7989151491669895 | Predicción actual: [[0.8471174]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00030781395616941154, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84829253]\n",
      " [0.81828749]\n",
      " [0.8661657 ]\n",
      " [0.86316884]\n",
      " [0.85891622]\n",
      " [0.85457802]\n",
      " [0.85055649]\n",
      " [0.84711742]] | y: 0.7900038744672608 | Predicción actual: [[0.84514093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009467207826673985, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.8661657 ]\n",
      " [0.86316884]\n",
      " [0.85891622]\n",
      " [0.85457802]\n",
      " [0.85055649]\n",
      " [0.84711742]\n",
      " [0.84514093]] | y: 0.760170476559473 | Predicción actual: [[0.84442514]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032048190478235483, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8661657 ]\n",
      " [0.86316884]\n",
      " [0.85891622]\n",
      " [0.85457802]\n",
      " [0.85055649]\n",
      " [0.84711742]\n",
      " [0.84514093]\n",
      " [0.84442514]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010581927374005318, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86316884]\n",
      " [0.85891622]\n",
      " [0.85457802]\n",
      " [0.85055649]\n",
      " [0.84711742]\n",
      " [0.84514093]\n",
      " [0.84442514]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8468646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.057941973209381104, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85891622]\n",
      " [0.85457802]\n",
      " [0.85055649]\n",
      " [0.84711742]\n",
      " [0.84514093]\n",
      " [0.84442514]\n",
      " [0.68539326]\n",
      " [0.84686458]] | y: 0.6648585819449826 | Predicción actual: [[0.8390508]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002116839401423931, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85457802]\n",
      " [0.85055649]\n",
      " [0.84711742]\n",
      " [0.84514093]\n",
      " [0.84442514]\n",
      " [0.68539326]\n",
      " [0.84686458]\n",
      " [0.83905083]] | y: 0.7078651685393258 | Predicción actual: [[0.83025277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03931079059839249, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85055649]\n",
      " [0.84711742]\n",
      " [0.84514093]\n",
      " [0.84442514]\n",
      " [0.68539326]\n",
      " [0.84686458]\n",
      " [0.83905083]\n",
      " [0.83025277]] | y: 0.6648585819449826 | Predicción actual: [[0.82038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06875474750995636, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84711742]\n",
      " [0.84514093]\n",
      " [0.84442514]\n",
      " [0.68539326]\n",
      " [0.84686458]\n",
      " [0.83905083]\n",
      " [0.83025277]\n",
      " [0.82037997]] | y: 0.7113521890740022 | Predicción actual: [[0.80957896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09075388312339783, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84514093]\n",
      " [0.84442514]\n",
      " [0.68539326]\n",
      " [0.84686458]\n",
      " [0.83905083]\n",
      " [0.83025277]\n",
      " [0.82037997]\n",
      " [0.80957896]] | y: 0.6772568771793879 | Predicción actual: [[0.797985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.6900855775456876e-05, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84442514]\n",
      " [0.68539326]\n",
      " [0.84686458]\n",
      " [0.83905083]\n",
      " [0.83025277]\n",
      " [0.82037997]\n",
      " [0.80957896]\n",
      " [0.79798502]] | y: 0.7621077101898488 | Predicción actual: [[0.7862111]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0069685522466897964, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84686458]\n",
      " [0.83905083]\n",
      " [0.83025277]\n",
      " [0.82037997]\n",
      " [0.80957896]\n",
      " [0.79798502]\n",
      " [0.78621107]] | y: 0.8070515304145678 | Predicción actual: [[0.7739093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.948983481270261e-06, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84686458]\n",
      " [0.83905083]\n",
      " [0.83025277]\n",
      " [0.82037997]\n",
      " [0.80957896]\n",
      " [0.79798502]\n",
      " [0.78621107]\n",
      " [0.77390927]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036923016887158155, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83905083]\n",
      " [0.83025277]\n",
      " [0.82037997]\n",
      " [0.80957896]\n",
      " [0.79798502]\n",
      " [0.78621107]\n",
      " [0.77390927]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.79643947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019261807203292847, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83025277]\n",
      " [0.82037997]\n",
      " [0.80957896]\n",
      " [0.79798502]\n",
      " [0.78621107]\n",
      " [0.77390927]\n",
      " [0.81518791]\n",
      " [0.79643947]] | y: 0.9597055404881829 | Predicción actual: [[0.7868186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05527025833725929, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82037997]\n",
      " [0.80957896]\n",
      " [0.79798502]\n",
      " [0.78621107]\n",
      " [0.77390927]\n",
      " [0.81518791]\n",
      " [0.79643947]\n",
      " [0.78681862]] | y: 0.9643549012010848 | Predicción actual: [[0.77835137]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004483398981392384, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80957896]\n",
      " [0.79798502]\n",
      " [0.78621107]\n",
      " [0.77390927]\n",
      " [0.81518791]\n",
      " [0.79643947]\n",
      " [0.78681862]\n",
      " [0.77835137]] | y: 0.8880278961642774 | Predicción actual: [[0.7713516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013632219284772873, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79798502]\n",
      " [0.78621107]\n",
      " [0.77390927]\n",
      " [0.81518791]\n",
      " [0.79643947]\n",
      " [0.78681862]\n",
      " [0.77835137]\n",
      " [0.77135158]] | y: 0.8926772568771792 | Predicción actual: [[0.76640695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009835143573582172, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78621107]\n",
      " [0.77390927]\n",
      " [0.81518791]\n",
      " [0.79643947]\n",
      " [0.78681862]\n",
      " [0.77835137]\n",
      " [0.77135158]\n",
      " [0.76640695]] | y: 0.8752421542037967 | Predicción actual: [[0.7639178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004955054027959704, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77390927]\n",
      " [0.81518791]\n",
      " [0.79643947]\n",
      " [0.78681862]\n",
      " [0.77835137]\n",
      " [0.77135158]\n",
      " [0.76640695]\n",
      " [0.7639178 ]] | y: 0.8508330104610615 | Predicción actual: [[0.7639717]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037656056229025126, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.79643947]\n",
      " [0.78681862]\n",
      " [0.77835137]\n",
      " [0.77135158]\n",
      " [0.76640695]\n",
      " [0.7639178 ]\n",
      " [0.76397169]] | y: 0.8488957768306855 | Predicción actual: [[0.76689696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005163090769201517, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79643947]\n",
      " [0.78681862]\n",
      " [0.77835137]\n",
      " [0.77135158]\n",
      " [0.76640695]\n",
      " [0.7639178 ]\n",
      " [0.76397169]\n",
      " [0.76689696]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04786181077361107, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78681862]\n",
      " [0.77835137]\n",
      " [0.77135158]\n",
      " [0.76640695]\n",
      " [0.7639178 ]\n",
      " [0.76397169]\n",
      " [0.76689696]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.75327766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0392683744430542, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77835137]\n",
      " [0.77135158]\n",
      " [0.76640695]\n",
      " [0.7639178 ]\n",
      " [0.76397169]\n",
      " [0.76689696]\n",
      " [0.96241767]\n",
      " [0.75327766]] | y: 0.9407206509104997 | Predicción actual: [[0.7523424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09074006229639053, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77135158]\n",
      " [0.76640695]\n",
      " [0.7639178 ]\n",
      " [0.76397169]\n",
      " [0.76689696]\n",
      " [0.96241767]\n",
      " [0.75327766]\n",
      " [0.7523424 ]] | y: 0.9724912824486633 | Predicción actual: [[0.75498474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017240652814507484, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76640695]\n",
      " [0.7639178 ]\n",
      " [0.76397169]\n",
      " [0.76689696]\n",
      " [0.96241767]\n",
      " [0.75327766]\n",
      " [0.7523424 ]\n",
      " [0.75498474]] | y: 0.9969004261913985 | Predicción actual: [[0.76067966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03353459760546684, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7639178 ]\n",
      " [0.76397169]\n",
      " [0.76689696]\n",
      " [0.96241767]\n",
      " [0.75327766]\n",
      " [0.7523424 ]\n",
      " [0.75498474]\n",
      " [0.76067966]] | y: 0.951181712514529 | Predicción actual: [[0.7687367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006754535716027021, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76397169]\n",
      " [0.76689696]\n",
      " [0.96241767]\n",
      " [0.75327766]\n",
      " [0.7523424 ]\n",
      " [0.75498474]\n",
      " [0.76067966]\n",
      " [0.76873672]] | y: 0.8957768306857805 | Predicción actual: [[0.7779479]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009862354025244713, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76689696]\n",
      " [0.96241767]\n",
      " [0.75327766]\n",
      " [0.7523424 ]\n",
      " [0.75498474]\n",
      " [0.76067966]\n",
      " [0.76873672]\n",
      " [0.7779479 ]] | y: 0.8814413018209997 | Predicción actual: [[0.7871908]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008726152591407299, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.75327766]\n",
      " [0.7523424 ]\n",
      " [0.75498474]\n",
      " [0.76067966]\n",
      " [0.76873672]\n",
      " [0.7779479 ]\n",
      " [0.78719079]] | y: 0.9170864006199149 | Predicción actual: [[0.79510015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.066021124846884e-06, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75327766]\n",
      " [0.7523424 ]\n",
      " [0.75498474]\n",
      " [0.76067966]\n",
      " [0.76873672]\n",
      " [0.7779479 ]\n",
      " [0.78719079]\n",
      " [0.79510015]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009067284874618053, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7523424 ]\n",
      " [0.75498474]\n",
      " [0.76067966]\n",
      " [0.76873672]\n",
      " [0.7779479 ]\n",
      " [0.78719079]\n",
      " [0.79510015]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.75133115]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013645639643073082, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75498474]\n",
      " [0.76067966]\n",
      " [0.76873672]\n",
      " [0.7779479 ]\n",
      " [0.78719079]\n",
      " [0.79510015]\n",
      " [0.91979853]\n",
      " [0.75133115]] | y: 0.9682293684618366 | Predicción actual: [[0.75967157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06857746839523315, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76067966]\n",
      " [0.76873672]\n",
      " [0.7779479 ]\n",
      " [0.78719079]\n",
      " [0.79510015]\n",
      " [0.91979853]\n",
      " [0.75133115]\n",
      " [0.75967157]] | y: 0.9577683068578069 | Predicción actual: [[0.7698722]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007082690019160509, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20606126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02624274045228958, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20606126]] | y: 0.10422316931421921 | Predicción actual: [[0.19086918]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00784360058605671, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20606126]\n",
      " [0.19086918]] | y: 0.15420379697791559 | Predicción actual: [[0.19502023]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031963400542736053, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20606126]\n",
      " [0.19086918]\n",
      " [0.19502023]] | y: 0.1557535838822161 | Predicción actual: [[0.20644005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0071473559364676476, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20606126]\n",
      " [0.19086918]\n",
      " [0.19502023]\n",
      " [0.20644005]] | y: 0.12553273924835334 | Predicción actual: [[0.21904083]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033527598716318607, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20606126]\n",
      " [0.19086918]\n",
      " [0.19502023]\n",
      " [0.20644005]\n",
      " [0.21904083]] | y: 0.1456799690042619 | Predicción actual: [[0.22912134]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007889126427471638, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20606126]\n",
      " [0.19086918]\n",
      " [0.19502023]\n",
      " [0.20644005]\n",
      " [0.21904083]\n",
      " [0.22912134]] | y: 0.1464548624564122 | Predicción actual: [[0.25055453]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012169796042144299, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20606126]\n",
      " [0.19086918]\n",
      " [0.19502023]\n",
      " [0.20644005]\n",
      " [0.21904083]\n",
      " [0.22912134]\n",
      " [0.25055453]] | y: 0.1960480433940332 | Predicción actual: [[0.27693853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000802838709205389, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20606126]\n",
      " [0.19086918]\n",
      " [0.19502023]\n",
      " [0.20644005]\n",
      " [0.21904083]\n",
      " [0.22912134]\n",
      " [0.25055453]\n",
      " [0.27693853]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022603527177125216, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19086918]\n",
      " [0.19502023]\n",
      " [0.20644005]\n",
      " [0.21904083]\n",
      " [0.22912134]\n",
      " [0.25055453]\n",
      " [0.27693853]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.310867]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009297288954257965, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19502023]\n",
      " [0.20644005]\n",
      " [0.21904083]\n",
      " [0.22912134]\n",
      " [0.25055453]\n",
      " [0.27693853]\n",
      " [0.2305308 ]\n",
      " [0.31086701]] | y: 0.211933359163115 | Predicción actual: [[0.3179758]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0043446896597743034, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20644005]\n",
      " [0.21904083]\n",
      " [0.22912134]\n",
      " [0.25055453]\n",
      " [0.27693853]\n",
      " [0.2305308 ]\n",
      " [0.31086701]\n",
      " [0.31797579]] | y: 0.2072839984502131 | Predicción actual: [[0.3269191]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02078547514975071, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21904083]\n",
      " [0.22912134]\n",
      " [0.25055453]\n",
      " [0.27693853]\n",
      " [0.2305308 ]\n",
      " [0.31086701]\n",
      " [0.31797579]\n",
      " [0.32691911]] | y: 0.19294846958543205 | Predicción actual: [[0.3364621]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02855641208589077, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22912134]\n",
      " [0.25055453]\n",
      " [0.27693853]\n",
      " [0.2305308 ]\n",
      " [0.31086701]\n",
      " [0.31797579]\n",
      " [0.32691911]\n",
      " [0.33646211]] | y: 0.19682293684618352 | Predicción actual: [[0.34650093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01063526514917612, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25055453]\n",
      " [0.27693853]\n",
      " [0.2305308 ]\n",
      " [0.31086701]\n",
      " [0.31797579]\n",
      " [0.32691911]\n",
      " [0.33646211]\n",
      " [0.34650093]] | y: 0.21425803951956607 | Predicción actual: [[0.35774553]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02063911408185959, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27693853]\n",
      " [0.2305308 ]\n",
      " [0.31086701]\n",
      " [0.31797579]\n",
      " [0.32691911]\n",
      " [0.33646211]\n",
      " [0.34650093]\n",
      " [0.35774553]] | y: 0.18132506780317698 | Predicción actual: [[0.36762896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044302526861429214, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31086701]\n",
      " [0.31797579]\n",
      " [0.32691911]\n",
      " [0.33646211]\n",
      " [0.34650093]\n",
      " [0.35774553]\n",
      " [0.36762896]] | y: 0.17512592018597434 | Predicción actual: [[0.37462714]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013447502627968788, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31086701]\n",
      " [0.31797579]\n",
      " [0.32691911]\n",
      " [0.33646211]\n",
      " [0.34650093]\n",
      " [0.35774553]\n",
      " [0.36762896]\n",
      " [0.37462714]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01102526020258665, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31797579]\n",
      " [0.32691911]\n",
      " [0.33646211]\n",
      " [0.34650093]\n",
      " [0.35774553]\n",
      " [0.36762896]\n",
      " [0.37462714]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40073094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06599146127700806, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32691911]\n",
      " [0.33646211]\n",
      " [0.34650093]\n",
      " [0.35774553]\n",
      " [0.36762896]\n",
      " [0.37462714]\n",
      " [0.14800465]\n",
      " [0.40073094]] | y: 0.19217357613328173 | Predicción actual: [[0.40454686]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0915328711271286, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33646211]\n",
      " [0.34650093]\n",
      " [0.35774553]\n",
      " [0.36762896]\n",
      " [0.37462714]\n",
      " [0.14800465]\n",
      " [0.40073094]\n",
      " [0.40454686]] | y: 0.1859744285160791 | Predicción actual: [[0.4065446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05456814169883728, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34650093]\n",
      " [0.35774553]\n",
      " [0.36762896]\n",
      " [0.37462714]\n",
      " [0.14800465]\n",
      " [0.40073094]\n",
      " [0.40454686]\n",
      " [0.4065446 ]] | y: 0.26695079426578844 | Predicción actual: [[0.40684626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020036445930600166, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35774553]\n",
      " [0.36762896]\n",
      " [0.37462714]\n",
      " [0.14800465]\n",
      " [0.40073094]\n",
      " [0.40454686]\n",
      " [0.4065446 ]\n",
      " [0.40684626]] | y: 0.2925222781867493 | Predicción actual: [[0.40570068]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010130287148058414, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36762896]\n",
      " [0.37462714]\n",
      " [0.14800465]\n",
      " [0.40073094]\n",
      " [0.40454686]\n",
      " [0.4065446 ]\n",
      " [0.40684626]\n",
      " [0.40570068]] | y: 0.3177063153816349 | Predicción actual: [[0.40317547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007727921009063721, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37462714]\n",
      " [0.14800465]\n",
      " [0.40073094]\n",
      " [0.40454686]\n",
      " [0.4065446 ]\n",
      " [0.40684626]\n",
      " [0.40570068]\n",
      " [0.40317547]] | y: 0.31266950794265785 | Predicción actual: [[0.39985776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009285364300012589, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40073094]\n",
      " [0.40454686]\n",
      " [0.4065446 ]\n",
      " [0.40684626]\n",
      " [0.40570068]\n",
      " [0.40317547]\n",
      " [0.39985776]] | y: 0.2890352576520729 | Predicción actual: [[0.39662942]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0174332857131958, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40073094]\n",
      " [0.40454686]\n",
      " [0.4065446 ]\n",
      " [0.40684626]\n",
      " [0.40570068]\n",
      " [0.40317547]\n",
      " [0.39985776]\n",
      " [0.39662942]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007087044883519411, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40454686]\n",
      " [0.4065446 ]\n",
      " [0.40684626]\n",
      " [0.40570068]\n",
      " [0.40317547]\n",
      " [0.39985776]\n",
      " [0.39662942]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.44951466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01646539755165577, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4065446 ]\n",
      " [0.40684626]\n",
      " [0.40570068]\n",
      " [0.40317547]\n",
      " [0.39985776]\n",
      " [0.39662942]\n",
      " [0.28283611]\n",
      " [0.44951466]] | y: 0.2758620689655173 | Predicción actual: [[0.4473854]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045631203800439835, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40684626]\n",
      " [0.40570068]\n",
      " [0.40317547]\n",
      " [0.39985776]\n",
      " [0.39662942]\n",
      " [0.28283611]\n",
      " [0.44951466]\n",
      " [0.4473854 ]] | y: 0.2746997287872917 | Predicción actual: [[0.44418803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034287575632333755, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40570068]\n",
      " [0.40317547]\n",
      " [0.39985776]\n",
      " [0.39662942]\n",
      " [0.28283611]\n",
      " [0.44951466]\n",
      " [0.4473854 ]\n",
      " [0.44418803]] | y: 0.275474622239442 | Predicción actual: [[0.440795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028564738109707832, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40317547]\n",
      " [0.39985776]\n",
      " [0.39662942]\n",
      " [0.28283611]\n",
      " [0.44951466]\n",
      " [0.4473854 ]\n",
      " [0.44418803]\n",
      " [0.440795  ]] | y: 0.3347539713289423 | Predicción actual: [[0.4381087]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009168845601379871, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39985776]\n",
      " [0.39662942]\n",
      " [0.28283611]\n",
      " [0.44951466]\n",
      " [0.4473854 ]\n",
      " [0.44418803]\n",
      " [0.440795  ]\n",
      " [0.43810871]] | y: 0.35567609453700116 | Predicción actual: [[0.4370304]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016377151478081942, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39662942]\n",
      " [0.28283611]\n",
      " [0.44951466]\n",
      " [0.4473854 ]\n",
      " [0.44418803]\n",
      " [0.440795  ]\n",
      " [0.43810871]\n",
      " [0.4370304 ]] | y: 0.3366912049593181 | Predicción actual: [[0.4382297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014141980558633804, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.44951466]\n",
      " [0.4473854 ]\n",
      " [0.44418803]\n",
      " [0.440795  ]\n",
      " [0.43810871]\n",
      " [0.4370304 ]\n",
      " [0.43822971]] | y: 0.3335916311507167 | Predicción actual: [[0.4419734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028349824249744415, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44951466]\n",
      " [0.4473854 ]\n",
      " [0.44418803]\n",
      " [0.440795  ]\n",
      " [0.43810871]\n",
      " [0.4370304 ]\n",
      " [0.43822971]\n",
      " [0.44197339]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02218637242913246, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4473854 ]\n",
      " [0.44418803]\n",
      " [0.440795  ]\n",
      " [0.43810871]\n",
      " [0.4370304 ]\n",
      " [0.43822971]\n",
      " [0.44197339]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.4728515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04364971071481705, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44418803]\n",
      " [0.440795  ]\n",
      " [0.43810871]\n",
      " [0.4370304 ]\n",
      " [0.43822971]\n",
      " [0.44197339]\n",
      " [0.3847346 ]\n",
      " [0.47285151]] | y: 0.5962805114296785 | Predicción actual: [[0.47009188]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02193465642631054, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.440795  ]\n",
      " [0.43810871]\n",
      " [0.4370304 ]\n",
      " [0.43822971]\n",
      " [0.44197339]\n",
      " [0.3847346 ]\n",
      " [0.47285151]\n",
      " [0.47009188]] | y: 0.574583494769469 | Predicción actual: [[0.46799162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0066732242703437805, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43810871]\n",
      " [0.4370304 ]\n",
      " [0.43822971]\n",
      " [0.44197339]\n",
      " [0.3847346 ]\n",
      " [0.47285151]\n",
      " [0.47009188]\n",
      " [0.46799162]] | y: 0.6063541263076326 | Predicción actual: [[0.46697032]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009391860105097294, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4370304 ]\n",
      " [0.43822971]\n",
      " [0.44197339]\n",
      " [0.3847346 ]\n",
      " [0.47285151]\n",
      " [0.47009188]\n",
      " [0.46799162]\n",
      " [0.46697032]] | y: 0.5846571096474236 | Predicción actual: [[0.4672781]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008237197995185852, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43822971]\n",
      " [0.44197339]\n",
      " [0.3847346 ]\n",
      " [0.47285151]\n",
      " [0.47009188]\n",
      " [0.46799162]\n",
      " [0.46697032]\n",
      " [0.46727809]] | y: 0.5687717938783416 | Predicción actual: [[0.46885192]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0073758624494075775, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44197339]\n",
      " [0.3847346 ]\n",
      " [0.47285151]\n",
      " [0.47009188]\n",
      " [0.46799162]\n",
      " [0.46697032]\n",
      " [0.46727809]\n",
      " [0.46885192]] | y: 0.6427741185586981 | Predicción actual: [[0.47135115]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017487118020653725, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.47285151]\n",
      " [0.47009188]\n",
      " [0.46799162]\n",
      " [0.46697032]\n",
      " [0.46727809]\n",
      " [0.46885192]\n",
      " [0.47135115]] | y: 0.6617590081363811 | Predicción actual: [[0.47427613]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01212218776345253, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47285151]\n",
      " [0.47009188]\n",
      " [0.46799162]\n",
      " [0.46697032]\n",
      " [0.46727809]\n",
      " [0.46885192]\n",
      " [0.47135115]\n",
      " [0.47427613]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03574938699603081, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47009188]\n",
      " [0.46799162]\n",
      " [0.46697032]\n",
      " [0.46727809]\n",
      " [0.46885192]\n",
      " [0.47135115]\n",
      " [0.47427613]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.49336204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04460848495364189, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46799162]\n",
      " [0.46697032]\n",
      " [0.46727809]\n",
      " [0.46885192]\n",
      " [0.47135115]\n",
      " [0.47427613]\n",
      " [0.67299496]\n",
      " [0.49336204]] | y: 0.703990701278574 | Predicción actual: [[0.49642634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029498228803277016, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46697032]\n",
      " [0.46727809]\n",
      " [0.46885192]\n",
      " [0.47135115]\n",
      " [0.47427613]\n",
      " [0.67299496]\n",
      " [0.49336204]\n",
      " [0.49642634]] | y: 0.7272375048430839 | Predicción actual: [[0.50225294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06475550681352615, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46727809]\n",
      " [0.46885192]\n",
      " [0.47135115]\n",
      " [0.47427613]\n",
      " [0.67299496]\n",
      " [0.49336204]\n",
      " [0.49642634]\n",
      " [0.50225294]] | y: 0.722588144130182 | Predicción actual: [[0.5107488]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031440459191799164, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46885192]\n",
      " [0.47135115]\n",
      " [0.47427613]\n",
      " [0.67299496]\n",
      " [0.49336204]\n",
      " [0.49642634]\n",
      " [0.50225294]\n",
      " [0.5107488 ]] | y: 0.771793878341728 | Predicción actual: [[0.5214759]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04489478841423988, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47135115]\n",
      " [0.47427613]\n",
      " [0.67299496]\n",
      " [0.49336204]\n",
      " [0.49642634]\n",
      " [0.50225294]\n",
      " [0.5107488 ]\n",
      " [0.52147591]] | y: 0.7245253777605578 | Predicción actual: [[0.53396297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004942548461258411, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47427613]\n",
      " [0.67299496]\n",
      " [0.49336204]\n",
      " [0.49642634]\n",
      " [0.50225294]\n",
      " [0.5107488 ]\n",
      " [0.52147591]\n",
      " [0.53396297]] | y: 0.6710577295621851 | Predicción actual: [[0.54763156]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012184993363916874, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.49336204]\n",
      " [0.49642634]\n",
      " [0.50225294]\n",
      " [0.5107488 ]\n",
      " [0.52147591]\n",
      " [0.53396297]\n",
      " [0.54763156]] | y: 0.6737698566447115 | Predicción actual: [[0.56219244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016455112025141716, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49336204]\n",
      " [0.49642634]\n",
      " [0.50225294]\n",
      " [0.5107488 ]\n",
      " [0.52147591]\n",
      " [0.53396297]\n",
      " [0.54763156]\n",
      " [0.56219244]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039287418127059937, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49642634]\n",
      " [0.50225294]\n",
      " [0.5107488 ]\n",
      " [0.52147591]\n",
      " [0.53396297]\n",
      " [0.54763156]\n",
      " [0.56219244]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5338709]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022202134132385254, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50225294]\n",
      " [0.5107488 ]\n",
      " [0.52147591]\n",
      " [0.53396297]\n",
      " [0.54763156]\n",
      " [0.56219244]\n",
      " [0.71445176]\n",
      " [0.53387088]] | y: 0.722588144130182 | Predicción actual: [[0.54440475]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020849570631980896, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5107488 ]\n",
      " [0.52147591]\n",
      " [0.53396297]\n",
      " [0.54763156]\n",
      " [0.56219244]\n",
      " [0.71445176]\n",
      " [0.53387088]\n",
      " [0.54440475]] | y: 0.6993413405656723 | Predicción actual: [[0.55694044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020105477422475815, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52147591]\n",
      " [0.53396297]\n",
      " [0.54763156]\n",
      " [0.56219244]\n",
      " [0.71445176]\n",
      " [0.53387088]\n",
      " [0.54440475]\n",
      " [0.55694044]] | y: 0.7373111197210385 | Predicción actual: [[0.5704281]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010692075826227665, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53396297]\n",
      " [0.54763156]\n",
      " [0.56219244]\n",
      " [0.71445176]\n",
      " [0.53387088]\n",
      " [0.54440475]\n",
      " [0.55694044]\n",
      " [0.57042807]] | y: 0.7214258039519565 | Predicción actual: [[0.58368844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035071276128292084, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54763156]\n",
      " [0.56219244]\n",
      " [0.71445176]\n",
      " [0.53387088]\n",
      " [0.54440475]\n",
      " [0.55694044]\n",
      " [0.57042807]\n",
      " [0.58368844]] | y: 0.7187136768694304 | Predicción actual: [[0.59565413]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07699017226696014, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56219244]\n",
      " [0.71445176]\n",
      " [0.53387088]\n",
      " [0.54440475]\n",
      " [0.55694044]\n",
      " [0.57042807]\n",
      " [0.58368844]\n",
      " [0.59565413]] | y: 0.6741573033707864 | Predicción actual: [[0.60540545]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012697848724201322, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.53387088]\n",
      " [0.54440475]\n",
      " [0.55694044]\n",
      " [0.57042807]\n",
      " [0.58368844]\n",
      " [0.59565413]\n",
      " [0.60540545]] | y: 0.698566447113522 | Predicción actual: [[0.61198556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014082961715757847, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53387088]\n",
      " [0.54440475]\n",
      " [0.55694044]\n",
      " [0.57042807]\n",
      " [0.58368844]\n",
      " [0.59565413]\n",
      " [0.60540545]\n",
      " [0.61198556]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01955287717282772, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54440475]\n",
      " [0.55694044]\n",
      " [0.57042807]\n",
      " [0.58368844]\n",
      " [0.59565413]\n",
      " [0.60540545]\n",
      " [0.61198556]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.58944815]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025629905983805656, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55694044]\n",
      " [0.57042807]\n",
      " [0.58368844]\n",
      " [0.59565413]\n",
      " [0.60540545]\n",
      " [0.61198556]\n",
      " [0.72103836]\n",
      " [0.58944815]] | y: 0.7562960092987214 | Predicción actual: [[0.6022957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02752622961997986, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57042807]\n",
      " [0.58368844]\n",
      " [0.59565413]\n",
      " [0.60540545]\n",
      " [0.61198556]\n",
      " [0.72103836]\n",
      " [0.58944815]\n",
      " [0.6022957 ]] | y: 0.8275862068965516 | Predicción actual: [[0.6152306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04729742184281349, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58368844]\n",
      " [0.59565413]\n",
      " [0.60540545]\n",
      " [0.61198556]\n",
      " [0.72103836]\n",
      " [0.58944815]\n",
      " [0.6022957 ]\n",
      " [0.61523062]] | y: 0.8388221619527314 | Predicción actual: [[0.62745357]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04795926809310913, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59565413]\n",
      " [0.60540545]\n",
      " [0.61198556]\n",
      " [0.72103836]\n",
      " [0.58944815]\n",
      " [0.6022957 ]\n",
      " [0.61523062]\n",
      " [0.62745357]] | y: 0.7942657884540876 | Predicción actual: [[0.6383459]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009646405465900898, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60540545]\n",
      " [0.61198556]\n",
      " [0.72103836]\n",
      " [0.58944815]\n",
      " [0.6022957 ]\n",
      " [0.61523062]\n",
      " [0.62745357]\n",
      " [0.6383459 ]] | y: 0.7838047268500579 | Predicción actual: [[0.6475223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00037115614395588636, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61198556]\n",
      " [0.72103836]\n",
      " [0.58944815]\n",
      " [0.6022957 ]\n",
      " [0.61523062]\n",
      " [0.62745357]\n",
      " [0.6383459 ]\n",
      " [0.64752227]] | y: 0.7679194110809764 | Predicción actual: [[0.65503275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010469031520187855, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.58944815]\n",
      " [0.6022957 ]\n",
      " [0.61523062]\n",
      " [0.62745357]\n",
      " [0.6383459 ]\n",
      " [0.64752227]\n",
      " [0.65503275]] | y: 0.7845796203022084 | Predicción actual: [[0.66159046]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006279368884861469, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58944815]\n",
      " [0.6022957 ]\n",
      " [0.61523062]\n",
      " [0.62745357]\n",
      " [0.6383459 ]\n",
      " [0.64752227]\n",
      " [0.65503275]\n",
      " [0.66159046]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0348406620323658, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6022957 ]\n",
      " [0.61523062]\n",
      " [0.62745357]\n",
      " [0.6383459 ]\n",
      " [0.64752227]\n",
      " [0.65503275]\n",
      " [0.66159046]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.65117383]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03427132964134216, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61523062]\n",
      " [0.62745357]\n",
      " [0.6383459 ]\n",
      " [0.64752227]\n",
      " [0.65503275]\n",
      " [0.66159046]\n",
      " [0.87872917]\n",
      " [0.65117383]] | y: 0.8488957768306855 | Predicción actual: [[0.66553795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030624045059084892, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62745357]\n",
      " [0.6383459 ]\n",
      " [0.64752227]\n",
      " [0.65503275]\n",
      " [0.66159046]\n",
      " [0.87872917]\n",
      " [0.65117383]\n",
      " [0.66553795]] | y: 0.8182874854707476 | Predicción actual: [[0.680799]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01109351497143507, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6383459 ]\n",
      " [0.64752227]\n",
      " [0.65503275]\n",
      " [0.66159046]\n",
      " [0.87872917]\n",
      " [0.65117383]\n",
      " [0.66553795]\n",
      " [0.68079901]] | y: 0.8268113134444013 | Predicción actual: [[0.69652456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005651090294122696, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64752227]\n",
      " [0.65503275]\n",
      " [0.66159046]\n",
      " [0.87872917]\n",
      " [0.65117383]\n",
      " [0.66553795]\n",
      " [0.68079901]\n",
      " [0.69652456]] | y: 0.7853545137543589 | Predicción actual: [[0.71239096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045481402426958084, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65503275]\n",
      " [0.66159046]\n",
      " [0.87872917]\n",
      " [0.65117383]\n",
      " [0.66553795]\n",
      " [0.68079901]\n",
      " [0.69652456]\n",
      " [0.71239096]] | y: 0.7892289810151103 | Predicción actual: [[0.7283731]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.155608273023972e-06, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66159046]\n",
      " [0.87872917]\n",
      " [0.65117383]\n",
      " [0.66553795]\n",
      " [0.68079901]\n",
      " [0.69652456]\n",
      " [0.71239096]\n",
      " [0.72837311]] | y: 0.8341728012398295 | Predicción actual: [[0.74420005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009423668496310711, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.65117383]\n",
      " [0.66553795]\n",
      " [0.68079901]\n",
      " [0.69652456]\n",
      " [0.71239096]\n",
      " [0.72837311]\n",
      " [0.74420005]] | y: 0.8124757845796202 | Predicción actual: [[0.75995797]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013146239798516035, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65117383]\n",
      " [0.66553795]\n",
      " [0.68079901]\n",
      " [0.69652456]\n",
      " [0.71239096]\n",
      " [0.72837311]\n",
      " [0.74420005]\n",
      " [0.75995797]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014669369906187057, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66553795]\n",
      " [0.68079901]\n",
      " [0.69652456]\n",
      " [0.71239096]\n",
      " [0.72837311]\n",
      " [0.74420005]\n",
      " [0.75995797]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7280433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01610651984810829, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68079901]\n",
      " [0.69652456]\n",
      " [0.71239096]\n",
      " [0.72837311]\n",
      " [0.74420005]\n",
      " [0.75995797]\n",
      " [0.80123983]\n",
      " [0.72804332]] | y: 0.793490895001937 | Predicción actual: [[0.7442656]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00039455335354432464, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69652456]\n",
      " [0.71239096]\n",
      " [0.72837311]\n",
      " [0.74420005]\n",
      " [0.75995797]\n",
      " [0.80123983]\n",
      " [0.72804332]\n",
      " [0.74426562]] | y: 0.760170476559473 | Predicción actual: [[0.7598996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002195198554545641, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71239096]\n",
      " [0.72837311]\n",
      " [0.74420005]\n",
      " [0.75995797]\n",
      " [0.80123983]\n",
      " [0.72804332]\n",
      " [0.74426562]\n",
      " [0.75989962]] | y: 0.7353738860906625 | Predicción actual: [[0.77418494]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020496727665886283, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72837311]\n",
      " [0.74420005]\n",
      " [0.75995797]\n",
      " [0.80123983]\n",
      " [0.72804332]\n",
      " [0.74426562]\n",
      " [0.75989962]\n",
      " [0.77418494]] | y: 0.7101898488957767 | Predicción actual: [[0.78630227]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001058666966855526, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74420005]\n",
      " [0.75995797]\n",
      " [0.80123983]\n",
      " [0.72804332]\n",
      " [0.74426562]\n",
      " [0.75989962]\n",
      " [0.77418494]\n",
      " [0.78630227]] | y: 0.7121270825261525 | Predicción actual: [[0.79558176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007493015727959573, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75995797]\n",
      " [0.80123983]\n",
      " [0.72804332]\n",
      " [0.74426562]\n",
      " [0.75989962]\n",
      " [0.77418494]\n",
      " [0.78630227]\n",
      " [0.79558176]] | y: 0.7396358000774894 | Predicción actual: [[0.8015977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003953689243644476, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.72804332]\n",
      " [0.74426562]\n",
      " [0.75989962]\n",
      " [0.77418494]\n",
      " [0.78630227]\n",
      " [0.79558176]\n",
      " [0.80159771]] | y: 0.7361487795428128 | Predicción actual: [[0.803979]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02163321152329445, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72804332]\n",
      " [0.74426562]\n",
      " [0.75989962]\n",
      " [0.77418494]\n",
      " [0.78630227]\n",
      " [0.79558176]\n",
      " [0.80159771]\n",
      " [0.80397898]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012826713733375072, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74426562]\n",
      " [0.75989962]\n",
      " [0.77418494]\n",
      " [0.78630227]\n",
      " [0.79558176]\n",
      " [0.80159771]\n",
      " [0.80397898]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.80689657]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0044365874491631985, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75989962]\n",
      " [0.77418494]\n",
      " [0.78630227]\n",
      " [0.79558176]\n",
      " [0.80159771]\n",
      " [0.80397898]\n",
      " [0.66757071]\n",
      " [0.80689657]] | y: 0.696629213483146 | Predicción actual: [[0.81619954]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012468065833672881, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77418494]\n",
      " [0.78630227]\n",
      " [0.79558176]\n",
      " [0.80159771]\n",
      " [0.80397898]\n",
      " [0.66757071]\n",
      " [0.80689657]\n",
      " [0.81619954]] | y: 0.6559473072452537 | Predicción actual: [[0.8220355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049221936613321304, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78630227]\n",
      " [0.79558176]\n",
      " [0.80159771]\n",
      " [0.80397898]\n",
      " [0.66757071]\n",
      " [0.80689657]\n",
      " [0.81619954]\n",
      " [0.82203549]] | y: 0.6788066640836885 | Predicción actual: [[0.82388765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022229887545108795, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79558176]\n",
      " [0.80159771]\n",
      " [0.80397898]\n",
      " [0.66757071]\n",
      " [0.80689657]\n",
      " [0.81619954]\n",
      " [0.82203549]\n",
      " [0.82388765]] | y: 0.6760945370011622 | Predicción actual: [[0.82248044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021083805710077286, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80159771]\n",
      " [0.80397898]\n",
      " [0.66757071]\n",
      " [0.80689657]\n",
      " [0.81619954]\n",
      " [0.82203549]\n",
      " [0.82388765]\n",
      " [0.82248044]] | y: 0.7295621851995349 | Predicción actual: [[0.81880397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026470120064914227, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80397898]\n",
      " [0.66757071]\n",
      " [0.80689657]\n",
      " [0.81619954]\n",
      " [0.82203549]\n",
      " [0.82388765]\n",
      " [0.82248044]\n",
      " [0.81880397]] | y: 0.7012785741960481 | Predicción actual: [[0.8144814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00014174781972542405, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.80689657]\n",
      " [0.81619954]\n",
      " [0.82203549]\n",
      " [0.82388765]\n",
      " [0.82248044]\n",
      " [0.81880397]\n",
      " [0.81448138]] | y: 0.767531964354901 | Predicción actual: [[0.8108342]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.0029870938742533e-05, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80689657]\n",
      " [0.81619954]\n",
      " [0.82203549]\n",
      " [0.82388765]\n",
      " [0.82248044]\n",
      " [0.81880397]\n",
      " [0.81448138]\n",
      " [0.81083423]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036106582265347242, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81619954]\n",
      " [0.82203549]\n",
      " [0.82388765]\n",
      " [0.82248044]\n",
      " [0.81880397]\n",
      " [0.81448138]\n",
      " [0.81083423]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8535823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060324475169181824, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82203549]\n",
      " [0.82388765]\n",
      " [0.82248044]\n",
      " [0.81880397]\n",
      " [0.81448138]\n",
      " [0.81083423]\n",
      " [0.75513367]\n",
      " [0.85358232]] | y: 0.7520340953118947 | Predicción actual: [[0.8525566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035987773444503546, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82388765]\n",
      " [0.82248044]\n",
      " [0.81880397]\n",
      " [0.81448138]\n",
      " [0.81083423]\n",
      " [0.75513367]\n",
      " [0.85358232]\n",
      " [0.85255659]] | y: 0.7098024021697016 | Predicción actual: [[0.84955674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01743662916123867, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82248044]\n",
      " [0.81880397]\n",
      " [0.81448138]\n",
      " [0.81083423]\n",
      " [0.75513367]\n",
      " [0.85358232]\n",
      " [0.85255659]\n",
      " [0.84955674]] | y: 0.6904300658659435 | Predicción actual: [[0.8458705]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06407984346151352, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81880397]\n",
      " [0.81448138]\n",
      " [0.81083423]\n",
      " [0.75513367]\n",
      " [0.85358232]\n",
      " [0.85255659]\n",
      " [0.84955674]\n",
      " [0.84587049]] | y: 0.7543587756683454 | Predicción actual: [[0.84264886]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005399294197559357, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81448138]\n",
      " [0.81083423]\n",
      " [0.75513367]\n",
      " [0.85358232]\n",
      " [0.85255659]\n",
      " [0.84955674]\n",
      " [0.84587049]\n",
      " [0.84264886]] | y: 0.7222006974041069 | Predicción actual: [[0.8415334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032299209386110306, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81083423]\n",
      " [0.75513367]\n",
      " [0.85358232]\n",
      " [0.85255659]\n",
      " [0.84955674]\n",
      " [0.84587049]\n",
      " [0.84264886]\n",
      " [0.84153342]] | y: 0.8485083301046106 | Predicción actual: [[0.8429408]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034709020983427763, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.85358232]\n",
      " [0.85255659]\n",
      " [0.84955674]\n",
      " [0.84587049]\n",
      " [0.84264886]\n",
      " [0.84153342]\n",
      " [0.84294081]] | y: 0.9054629988376597 | Predicción actual: [[0.84723705]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010574455372989178, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85358232]\n",
      " [0.85255659]\n",
      " [0.84955674]\n",
      " [0.84587049]\n",
      " [0.84264886]\n",
      " [0.84153342]\n",
      " [0.84294081]\n",
      " [0.84723705]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026621077209711075, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85255659]\n",
      " [0.84955674]\n",
      " [0.84587049]\n",
      " [0.84264886]\n",
      " [0.84153342]\n",
      " [0.84294081]\n",
      " [0.84723705]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8679506]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03745177015662193, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84955674]\n",
      " [0.84587049]\n",
      " [0.84264886]\n",
      " [0.84153342]\n",
      " [0.84294081]\n",
      " [0.84723705]\n",
      " [0.8822162 ]\n",
      " [0.86795062]] | y: 0.889577683068578 | Predicción actual: [[0.86590767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001720951753668487, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84587049]\n",
      " [0.84264886]\n",
      " [0.84153342]\n",
      " [0.84294081]\n",
      " [0.84723705]\n",
      " [0.8822162 ]\n",
      " [0.86795062]\n",
      " [0.86590767]] | y: 0.8748547074777218 | Predicción actual: [[0.86519307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00029035191982984543, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84264886]\n",
      " [0.84153342]\n",
      " [0.84294081]\n",
      " [0.84723705]\n",
      " [0.8822162 ]\n",
      " [0.86795062]\n",
      " [0.86590767]\n",
      " [0.86519307]] | y: 0.9132119333591631 | Predicción actual: [[0.86642194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017618361744098365, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84153342]\n",
      " [0.84294081]\n",
      " [0.84723705]\n",
      " [0.8822162 ]\n",
      " [0.86795062]\n",
      " [0.86590767]\n",
      " [0.86519307]\n",
      " [0.86642194]] | y: 1.0 | Predicción actual: [[0.86979765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024185623973608017, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84294081]\n",
      " [0.84723705]\n",
      " [0.8822162 ]\n",
      " [0.86795062]\n",
      " [0.86590767]\n",
      " [0.86519307]\n",
      " [0.86642194]\n",
      " [0.86979765]] | y: 0.9705540488182873 | Predicción actual: [[0.87512517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021915117278695107, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84723705]\n",
      " [0.8822162 ]\n",
      " [0.86795062]\n",
      " [0.86590767]\n",
      " [0.86519307]\n",
      " [0.86642194]\n",
      " [0.86979765]\n",
      " [0.87512517]] | y: 0.8888027896164277 | Predicción actual: [[0.8816068]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004348047077655792, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.86795062]\n",
      " [0.86590767]\n",
      " [0.86519307]\n",
      " [0.86642194]\n",
      " [0.86979765]\n",
      " [0.87512517]\n",
      " [0.88160682]] | y: 0.877954281286323 | Predicción actual: [[0.8877923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035036224871873856, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86795062]\n",
      " [0.86590767]\n",
      " [0.86519307]\n",
      " [0.86642194]\n",
      " [0.86979765]\n",
      " [0.87512517]\n",
      " [0.88160682]\n",
      " [0.88779229]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.7822563677327707e-05, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86590767]\n",
      " [0.86519307]\n",
      " [0.86642194]\n",
      " [0.86979765]\n",
      " [0.87512517]\n",
      " [0.88160682]\n",
      " [0.88779229]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8844146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008111881325021386, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86519307]\n",
      " [0.86642194]\n",
      " [0.86979765]\n",
      " [0.87512517]\n",
      " [0.88160682]\n",
      " [0.88779229]\n",
      " [0.84889578]\n",
      " [0.88441461]] | y: 0.8550949244478885 | Predicción actual: [[0.8858811]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04527157545089722, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86642194]\n",
      " [0.86979765]\n",
      " [0.87512517]\n",
      " [0.88160682]\n",
      " [0.88779229]\n",
      " [0.84889578]\n",
      " [0.88441461]\n",
      " [0.88588113]] | y: 0.8752421542037967 | Predicción actual: [[0.887525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01733436807990074, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86979765]\n",
      " [0.87512517]\n",
      " [0.88160682]\n",
      " [0.88779229]\n",
      " [0.84889578]\n",
      " [0.88441461]\n",
      " [0.88588113]\n",
      " [0.88752502]] | y: 0.857032158078264 | Predicción actual: [[0.88914174]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00026453391183167696, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87512517]\n",
      " [0.88160682]\n",
      " [0.88779229]\n",
      " [0.84889578]\n",
      " [0.88441461]\n",
      " [0.88588113]\n",
      " [0.88752502]\n",
      " [0.88914174]] | y: 0.8500581170089112 | Predicción actual: [[0.89041233]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010538898641243577, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88160682]\n",
      " [0.88779229]\n",
      " [0.84889578]\n",
      " [0.88441461]\n",
      " [0.88588113]\n",
      " [0.88752502]\n",
      " [0.88914174]\n",
      " [0.89041233]] | y: 0.8426966292134832 | Predicción actual: [[0.8907947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00031227650470100343, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88779229]\n",
      " [0.84889578]\n",
      " [0.88441461]\n",
      " [0.88588113]\n",
      " [0.88752502]\n",
      " [0.88914174]\n",
      " [0.89041233]\n",
      " [0.89079469]] | y: 0.8229368461836497 | Predicción actual: [[0.8898128]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.293447141710203e-05, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.88441461]\n",
      " [0.88588113]\n",
      " [0.88752502]\n",
      " [0.88914174]\n",
      " [0.89041233]\n",
      " [0.89079469]\n",
      " [0.88981283]] | y: 0.7745060054242543 | Predicción actual: [[0.887437]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019335219636559486, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88441461]\n",
      " [0.88588113]\n",
      " [0.88752502]\n",
      " [0.88914174]\n",
      " [0.89041233]\n",
      " [0.89079469]\n",
      " [0.88981283]\n",
      " [0.88743699]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0431893989443779, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88588113]\n",
      " [0.88752502]\n",
      " [0.88914174]\n",
      " [0.89041233]\n",
      " [0.89079469]\n",
      " [0.88981283]\n",
      " [0.88743699]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.89639413]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037920086178928614, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88752502]\n",
      " [0.88914174]\n",
      " [0.89041233]\n",
      " [0.89079469]\n",
      " [0.88981283]\n",
      " [0.88743699]\n",
      " [0.78419217]\n",
      " [0.89639413]] | y: 0.854320030995738 | Predicción actual: [[0.89441484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013640042394399643, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88914174]\n",
      " [0.89041233]\n",
      " [0.89079469]\n",
      " [0.88981283]\n",
      " [0.88743699]\n",
      " [0.78419217]\n",
      " [0.89639413]\n",
      " [0.89441484]] | y: 0.8368849283223556 | Predicción actual: [[0.8909191]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022276341915130615, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89041233]\n",
      " [0.89079469]\n",
      " [0.88981283]\n",
      " [0.88743699]\n",
      " [0.78419217]\n",
      " [0.89639413]\n",
      " [0.89441484]\n",
      " [0.89091909]] | y: 0.8299108872530028 | Predicción actual: [[0.88614863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009546361863613129, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89079469]\n",
      " [0.88981283]\n",
      " [0.88743699]\n",
      " [0.78419217]\n",
      " [0.89639413]\n",
      " [0.89441484]\n",
      " [0.89091909]\n",
      " [0.88614863]] | y: 0.887253002712127 | Predicción actual: [[0.8802378]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02051275596022606, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88981283]\n",
      " [0.88743699]\n",
      " [0.78419217]\n",
      " [0.89639413]\n",
      " [0.89441484]\n",
      " [0.89091909]\n",
      " [0.88614863]\n",
      " [0.88023782]] | y: 0.8597442851607902 | Predicción actual: [[0.873549]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004991327412426472, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88743699]\n",
      " [0.78419217]\n",
      " [0.89639413]\n",
      " [0.89441484]\n",
      " [0.89091909]\n",
      " [0.88614863]\n",
      " [0.88023782]\n",
      " [0.87354898]] | y: 0.8395970554048819 | Predicción actual: [[0.86725783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.3071117539075203e-05, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.89639413]\n",
      " [0.89441484]\n",
      " [0.89091909]\n",
      " [0.88614863]\n",
      " [0.88023782]\n",
      " [0.87354898]\n",
      " [0.86725783]] | y: 0.7838047268500579 | Predicción actual: [[0.8618311]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02032490074634552, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89639413]\n",
      " [0.89441484]\n",
      " [0.89091909]\n",
      " [0.88614863]\n",
      " [0.88023782]\n",
      " [0.87354898]\n",
      " [0.86725783]\n",
      " [0.86183113]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06380239874124527, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89441484]\n",
      " [0.89091909]\n",
      " [0.88614863]\n",
      " [0.88023782]\n",
      " [0.87354898]\n",
      " [0.86725783]\n",
      " [0.86183113]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.88147366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010545672848820686, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89091909]\n",
      " [0.88614863]\n",
      " [0.88023782]\n",
      " [0.87354898]\n",
      " [0.86725783]\n",
      " [0.86183113]\n",
      " [0.81828749]\n",
      " [0.88147366]] | y: 0.7605579232855482 | Predicción actual: [[0.874675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019753561355173588, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88614863]\n",
      " [0.88023782]\n",
      " [0.87354898]\n",
      " [0.86725783]\n",
      " [0.86183113]\n",
      " [0.81828749]\n",
      " [0.88147366]\n",
      " [0.87467498]] | y: 0.7915536613715615 | Predicción actual: [[0.8674613]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002131629968062043, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88023782]\n",
      " [0.87354898]\n",
      " [0.86725783]\n",
      " [0.86183113]\n",
      " [0.81828749]\n",
      " [0.88147366]\n",
      " [0.87467498]\n",
      " [0.86746132]] | y: 0.7686943045331267 | Predicción actual: [[0.86061424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007170029450207949, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87354898]\n",
      " [0.86725783]\n",
      " [0.86183113]\n",
      " [0.81828749]\n",
      " [0.88147366]\n",
      " [0.87467498]\n",
      " [0.86746132]\n",
      " [0.86061424]] | y: 0.7686943045331267 | Predicción actual: [[0.8545081]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017457257956266403, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86725783]\n",
      " [0.86183113]\n",
      " [0.81828749]\n",
      " [0.88147366]\n",
      " [0.87467498]\n",
      " [0.86746132]\n",
      " [0.86061424]\n",
      " [0.8545081 ]] | y: 0.7989151491669895 | Predicción actual: [[0.8495839]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018905017524957657, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86183113]\n",
      " [0.81828749]\n",
      " [0.88147366]\n",
      " [0.87467498]\n",
      " [0.86746132]\n",
      " [0.86061424]\n",
      " [0.8545081 ]\n",
      " [0.84958392]] | y: 0.7900038744672608 | Predicción actual: [[0.8464934]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10115991532802582, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.88147366]\n",
      " [0.87467498]\n",
      " [0.86746132]\n",
      " [0.86061424]\n",
      " [0.8545081 ]\n",
      " [0.84958392]\n",
      " [0.84649342]] | y: 0.760170476559473 | Predicción actual: [[0.84408206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023243064060807228, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88147366]\n",
      " [0.87467498]\n",
      " [0.86746132]\n",
      " [0.86061424]\n",
      " [0.8545081 ]\n",
      " [0.84958392]\n",
      " [0.84649342]\n",
      " [0.84408206]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030315514653921127, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87467498]\n",
      " [0.86746132]\n",
      " [0.86061424]\n",
      " [0.8545081 ]\n",
      " [0.84958392]\n",
      " [0.84649342]\n",
      " [0.84408206]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.84523094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02757367677986622, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86746132]\n",
      " [0.86061424]\n",
      " [0.8545081 ]\n",
      " [0.84958392]\n",
      " [0.84649342]\n",
      " [0.84408206]\n",
      " [0.68539326]\n",
      " [0.84523094]] | y: 0.6648585819449826 | Predicción actual: [[0.8352338]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1046125590801239, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86061424]\n",
      " [0.8545081 ]\n",
      " [0.84958392]\n",
      " [0.84649342]\n",
      " [0.84408206]\n",
      " [0.68539326]\n",
      " [0.84523094]\n",
      " [0.83523381]] | y: 0.7078651685393258 | Predicción actual: [[0.8240354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03409503027796745, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8545081 ]\n",
      " [0.84958392]\n",
      " [0.84649342]\n",
      " [0.84408206]\n",
      " [0.68539326]\n",
      " [0.84523094]\n",
      " [0.83523381]\n",
      " [0.82403541]] | y: 0.6648585819449826 | Predicción actual: [[0.8122148]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03546800836920738, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84958392]\n",
      " [0.84649342]\n",
      " [0.84408206]\n",
      " [0.68539326]\n",
      " [0.84523094]\n",
      " [0.83523381]\n",
      " [0.82403541]\n",
      " [0.81221479]] | y: 0.7113521890740022 | Predicción actual: [[0.7999654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010701088234782219, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84649342]\n",
      " [0.84408206]\n",
      " [0.68539326]\n",
      " [0.84523094]\n",
      " [0.83523381]\n",
      " [0.82403541]\n",
      " [0.81221479]\n",
      " [0.79996538]] | y: 0.6772568771793879 | Predicción actual: [[0.78750235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001969273143913597, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84408206]\n",
      " [0.68539326]\n",
      " [0.84523094]\n",
      " [0.83523381]\n",
      " [0.82403541]\n",
      " [0.81221479]\n",
      " [0.79996538]\n",
      " [0.78750235]] | y: 0.7621077101898488 | Predicción actual: [[0.7747455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00013148889411240816, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84523094]\n",
      " [0.83523381]\n",
      " [0.82403541]\n",
      " [0.81221479]\n",
      " [0.79996538]\n",
      " [0.78750235]\n",
      " [0.77474552]] | y: 0.8070515304145678 | Predicción actual: [[0.7616526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014609497971832752, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84523094]\n",
      " [0.83523381]\n",
      " [0.82403541]\n",
      " [0.81221479]\n",
      " [0.79996538]\n",
      " [0.78750235]\n",
      " [0.77474552]\n",
      " [0.76165259]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005345833487808704, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83523381]\n",
      " [0.82403541]\n",
      " [0.81221479]\n",
      " [0.79996538]\n",
      " [0.78750235]\n",
      " [0.77474552]\n",
      " [0.76165259]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7803276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016748713329434395, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82403541]\n",
      " [0.81221479]\n",
      " [0.79996538]\n",
      " [0.78750235]\n",
      " [0.77474552]\n",
      " [0.76165259]\n",
      " [0.81518791]\n",
      " [0.78032762]] | y: 0.9597055404881829 | Predicción actual: [[0.76944315]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07573114335536957, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81221479]\n",
      " [0.79996538]\n",
      " [0.78750235]\n",
      " [0.77474552]\n",
      " [0.76165259]\n",
      " [0.81518791]\n",
      " [0.78032762]\n",
      " [0.76944315]] | y: 0.9643549012010848 | Predicción actual: [[0.76015383]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09087689220905304, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79996538]\n",
      " [0.78750235]\n",
      " [0.77474552]\n",
      " [0.76165259]\n",
      " [0.81518791]\n",
      " [0.78032762]\n",
      " [0.76944315]\n",
      " [0.76015383]] | y: 0.8880278961642774 | Predicción actual: [[0.7529133]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007158194202929735, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78750235]\n",
      " [0.77474552]\n",
      " [0.76165259]\n",
      " [0.81518791]\n",
      " [0.78032762]\n",
      " [0.76944315]\n",
      " [0.76015383]\n",
      " [0.7529133 ]] | y: 0.8926772568771792 | Predicción actual: [[0.74776846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01972036063671112, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77474552]\n",
      " [0.76165259]\n",
      " [0.81518791]\n",
      " [0.78032762]\n",
      " [0.76944315]\n",
      " [0.76015383]\n",
      " [0.7529133 ]\n",
      " [0.74776846]] | y: 0.8752421542037967 | Predicción actual: [[0.74503523]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001385803334414959, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76165259]\n",
      " [0.81518791]\n",
      " [0.78032762]\n",
      " [0.76944315]\n",
      " [0.76015383]\n",
      " [0.7529133 ]\n",
      " [0.74776846]\n",
      " [0.74503523]] | y: 0.8508330104610615 | Predicción actual: [[0.7447571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0042593334801495075, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78032762]\n",
      " [0.76944315]\n",
      " [0.76015383]\n",
      " [0.7529133 ]\n",
      " [0.74776846]\n",
      " [0.74503523]\n",
      " [0.74475712]] | y: 0.8488957768306855 | Predicción actual: [[0.7469425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037239226512610912, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78032762]\n",
      " [0.76944315]\n",
      " [0.76015383]\n",
      " [0.7529133 ]\n",
      " [0.74776846]\n",
      " [0.74503523]\n",
      " [0.74475712]\n",
      " [0.74694252]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03756878152489662, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76944315]\n",
      " [0.76015383]\n",
      " [0.7529133 ]\n",
      " [0.74776846]\n",
      " [0.74503523]\n",
      " [0.74475712]\n",
      " [0.74694252]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.72860456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08794722706079483, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76015383]\n",
      " [0.7529133 ]\n",
      " [0.74776846]\n",
      " [0.74503523]\n",
      " [0.74475712]\n",
      " [0.74694252]\n",
      " [0.96241767]\n",
      " [0.72860456]] | y: 0.9407206509104997 | Predicción actual: [[0.7276175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07350356876850128, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7529133 ]\n",
      " [0.74776846]\n",
      " [0.74503523]\n",
      " [0.74475712]\n",
      " [0.74694252]\n",
      " [0.96241767]\n",
      " [0.72860456]\n",
      " [0.7276175 ]] | y: 0.9724912824486633 | Predicción actual: [[0.7303595]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06827972829341888, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74776846]\n",
      " [0.74503523]\n",
      " [0.74475712]\n",
      " [0.74694252]\n",
      " [0.96241767]\n",
      " [0.72860456]\n",
      " [0.7276175 ]\n",
      " [0.73035949]] | y: 0.9969004261913985 | Predicción actual: [[0.73628]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07959902286529541, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74503523]\n",
      " [0.74475712]\n",
      " [0.74694252]\n",
      " [0.96241767]\n",
      " [0.72860456]\n",
      " [0.7276175 ]\n",
      " [0.73035949]\n",
      " [0.73628002]] | y: 0.951181712514529 | Predicción actual: [[0.7445597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05027163028717041, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74475712]\n",
      " [0.74694252]\n",
      " [0.96241767]\n",
      " [0.72860456]\n",
      " [0.7276175 ]\n",
      " [0.73035949]\n",
      " [0.73628002]\n",
      " [0.74455971]] | y: 0.8957768306857805 | Predicción actual: [[0.75403714]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000113800706458278, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74694252]\n",
      " [0.96241767]\n",
      " [0.72860456]\n",
      " [0.7276175 ]\n",
      " [0.73035949]\n",
      " [0.73628002]\n",
      " [0.74455971]\n",
      " [0.75403714]] | y: 0.8814413018209997 | Predicción actual: [[0.7631957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007475804537534714, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.72860456]\n",
      " [0.7276175 ]\n",
      " [0.73035949]\n",
      " [0.73628002]\n",
      " [0.74455971]\n",
      " [0.75403714]\n",
      " [0.76319569]] | y: 0.9170864006199149 | Predicción actual: [[0.771066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029786545783281326, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72860456]\n",
      " [0.7276175 ]\n",
      " [0.73035949]\n",
      " [0.73628002]\n",
      " [0.74455971]\n",
      " [0.75403714]\n",
      " [0.76319569]\n",
      " [0.77106601]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015537504106760025, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7276175 ]\n",
      " [0.73035949]\n",
      " [0.73628002]\n",
      " [0.74455971]\n",
      " [0.75403714]\n",
      " [0.76319569]\n",
      " [0.77106601]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.72294044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1572331339120865, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73035949]\n",
      " [0.73628002]\n",
      " [0.74455971]\n",
      " [0.75403714]\n",
      " [0.76319569]\n",
      " [0.77106601]\n",
      " [0.91979853]\n",
      " [0.72294044]] | y: 0.9682293684618366 | Predicción actual: [[0.7321008]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07501525431871414, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73628002]\n",
      " [0.74455971]\n",
      " [0.75403714]\n",
      " [0.76319569]\n",
      " [0.77106601]\n",
      " [0.91979853]\n",
      " [0.72294044]\n",
      " [0.73210078]] | y: 0.9577683068578069 | Predicción actual: [[0.7432137]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03899746388196945, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20496541]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015201692469418049, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20496541]] | y: 0.10422316931421921 | Predicción actual: [[0.19001687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004968169145286083, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20496541]\n",
      " [0.19001687]] | y: 0.15420379697791559 | Predicción actual: [[0.19429252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00019575886835809797, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20496541]\n",
      " [0.19001687]\n",
      " [0.19429252]] | y: 0.1557535838822161 | Predicción actual: [[0.20579597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006123438943177462, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20496541]\n",
      " [0.19001687]\n",
      " [0.19429252]\n",
      " [0.20579597]] | y: 0.12553273924835334 | Predicción actual: [[0.21847041]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0204539205878973, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20496541]\n",
      " [0.19001687]\n",
      " [0.19429252]\n",
      " [0.20579597]\n",
      " [0.21847041]] | y: 0.1456799690042619 | Predicción actual: [[0.22857083]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014067832380533218, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20496541]\n",
      " [0.19001687]\n",
      " [0.19429252]\n",
      " [0.20579597]\n",
      " [0.21847041]\n",
      " [0.22857083]] | y: 0.1464548624564122 | Predicción actual: [[0.24995089]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009463113732635975, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20496541]\n",
      " [0.19001687]\n",
      " [0.19429252]\n",
      " [0.20579597]\n",
      " [0.21847041]\n",
      " [0.22857083]\n",
      " [0.24995089]] | y: 0.1960480433940332 | Predicción actual: [[0.27624798]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007904786616563797, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20496541]\n",
      " [0.19001687]\n",
      " [0.19429252]\n",
      " [0.20579597]\n",
      " [0.21847041]\n",
      " [0.22857083]\n",
      " [0.24995089]\n",
      " [0.27624798]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01399160921573639, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19001687]\n",
      " [0.19429252]\n",
      " [0.20579597]\n",
      " [0.21847041]\n",
      " [0.22857083]\n",
      " [0.24995089]\n",
      " [0.27624798]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.31015685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03308791667222977, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19429252]\n",
      " [0.20579597]\n",
      " [0.21847041]\n",
      " [0.22857083]\n",
      " [0.24995089]\n",
      " [0.27624798]\n",
      " [0.2305308 ]\n",
      " [0.31015685]] | y: 0.211933359163115 | Predicción actual: [[0.31729817]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009291254915297031, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20579597]\n",
      " [0.21847041]\n",
      " [0.22857083]\n",
      " [0.24995089]\n",
      " [0.27624798]\n",
      " [0.2305308 ]\n",
      " [0.31015685]\n",
      " [0.31729817]] | y: 0.2072839984502131 | Predicción actual: [[0.32624146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012628902681171894, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21847041]\n",
      " [0.22857083]\n",
      " [0.24995089]\n",
      " [0.27624798]\n",
      " [0.2305308 ]\n",
      " [0.31015685]\n",
      " [0.31729817]\n",
      " [0.32624146]] | y: 0.19294846958543205 | Predicción actual: [[0.3357883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01779305748641491, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22857083]\n",
      " [0.24995089]\n",
      " [0.27624798]\n",
      " [0.2305308 ]\n",
      " [0.31015685]\n",
      " [0.31729817]\n",
      " [0.32624146]\n",
      " [0.33578831]] | y: 0.19682293684618352 | Predicción actual: [[0.3458347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019521035254001617, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24995089]\n",
      " [0.27624798]\n",
      " [0.2305308 ]\n",
      " [0.31015685]\n",
      " [0.31729817]\n",
      " [0.32624146]\n",
      " [0.33578831]\n",
      " [0.3458347 ]] | y: 0.21425803951956607 | Predicción actual: [[0.3570608]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029523756355047226, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27624798]\n",
      " [0.2305308 ]\n",
      " [0.31015685]\n",
      " [0.31729817]\n",
      " [0.32624146]\n",
      " [0.33578831]\n",
      " [0.3458347 ]\n",
      " [0.35706079]] | y: 0.18132506780317698 | Predicción actual: [[0.36692008]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018071874976158142, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31015685]\n",
      " [0.31729817]\n",
      " [0.32624146]\n",
      " [0.33578831]\n",
      " [0.3458347 ]\n",
      " [0.35706079]\n",
      " [0.36692008]] | y: 0.17512592018597434 | Predicción actual: [[0.37396547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04804527759552002, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31015685]\n",
      " [0.31729817]\n",
      " [0.32624146]\n",
      " [0.33578831]\n",
      " [0.3458347 ]\n",
      " [0.35706079]\n",
      " [0.36692008]\n",
      " [0.37396547]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0534573458135128, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31729817]\n",
      " [0.32624146]\n",
      " [0.33578831]\n",
      " [0.3458347 ]\n",
      " [0.35706079]\n",
      " [0.36692008]\n",
      " [0.37396547]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.39975768]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06934760510921478, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32624146]\n",
      " [0.33578831]\n",
      " [0.3458347 ]\n",
      " [0.35706079]\n",
      " [0.36692008]\n",
      " [0.37396547]\n",
      " [0.14800465]\n",
      " [0.39975768]] | y: 0.19217357613328173 | Predicción actual: [[0.40348133]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05985649675130844, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33578831]\n",
      " [0.3458347 ]\n",
      " [0.35706079]\n",
      " [0.36692008]\n",
      " [0.37396547]\n",
      " [0.14800465]\n",
      " [0.39975768]\n",
      " [0.40348133]] | y: 0.1859744285160791 | Predicción actual: [[0.40545443]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05348895490169525, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3458347 ]\n",
      " [0.35706079]\n",
      " [0.36692008]\n",
      " [0.37396547]\n",
      " [0.14800465]\n",
      " [0.39975768]\n",
      " [0.40348133]\n",
      " [0.40545443]] | y: 0.26695079426578844 | Predicción actual: [[0.40573713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018080109730362892, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35706079]\n",
      " [0.36692008]\n",
      " [0.37396547]\n",
      " [0.14800465]\n",
      " [0.39975768]\n",
      " [0.40348133]\n",
      " [0.40545443]\n",
      " [0.40573713]] | y: 0.2925222781867493 | Predicción actual: [[0.4045747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021914498880505562, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36692008]\n",
      " [0.37396547]\n",
      " [0.14800465]\n",
      " [0.39975768]\n",
      " [0.40348133]\n",
      " [0.40545443]\n",
      " [0.40573713]\n",
      " [0.40457469]] | y: 0.3177063153816349 | Predicción actual: [[0.40200126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001220264588482678, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37396547]\n",
      " [0.14800465]\n",
      " [0.39975768]\n",
      " [0.40348133]\n",
      " [0.40545443]\n",
      " [0.40573713]\n",
      " [0.40457469]\n",
      " [0.40200126]] | y: 0.31266950794265785 | Predicción actual: [[0.39866057]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0051029641181230545, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.39975768]\n",
      " [0.40348133]\n",
      " [0.40545443]\n",
      " [0.40573713]\n",
      " [0.40457469]\n",
      " [0.40200126]\n",
      " [0.39866057]] | y: 0.2890352576520729 | Predicción actual: [[0.3953942]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014967285096645355, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39975768]\n",
      " [0.40348133]\n",
      " [0.40545443]\n",
      " [0.40573713]\n",
      " [0.40457469]\n",
      " [0.40200126]\n",
      " [0.39866057]\n",
      " [0.39539421]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026814840734004974, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40348133]\n",
      " [0.40545443]\n",
      " [0.40573713]\n",
      " [0.40457469]\n",
      " [0.40200126]\n",
      " [0.39866057]\n",
      " [0.39539421]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.4478317]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02758476324379444, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40545443]\n",
      " [0.40573713]\n",
      " [0.40457469]\n",
      " [0.40200126]\n",
      " [0.39866057]\n",
      " [0.39539421]\n",
      " [0.28283611]\n",
      " [0.44783169]] | y: 0.2758620689655173 | Predicción actual: [[0.44563946]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04903867840766907, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40573713]\n",
      " [0.40457469]\n",
      " [0.40200126]\n",
      " [0.39866057]\n",
      " [0.39539421]\n",
      " [0.28283611]\n",
      " [0.44783169]\n",
      " [0.44563946]] | y: 0.2746997287872917 | Predicción actual: [[0.44238442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025729088112711906, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40457469]\n",
      " [0.40200126]\n",
      " [0.39866057]\n",
      " [0.39539421]\n",
      " [0.28283611]\n",
      " [0.44783169]\n",
      " [0.44563946]\n",
      " [0.44238442]] | y: 0.275474622239442 | Predicción actual: [[0.43895993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044290054589509964, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40200126]\n",
      " [0.39866057]\n",
      " [0.39539421]\n",
      " [0.28283611]\n",
      " [0.44783169]\n",
      " [0.44563946]\n",
      " [0.44238442]\n",
      " [0.43895993]] | y: 0.3347539713289423 | Predicción actual: [[0.43620175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014074149541556835, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39866057]\n",
      " [0.39539421]\n",
      " [0.28283611]\n",
      " [0.44783169]\n",
      " [0.44563946]\n",
      " [0.44238442]\n",
      " [0.43895993]\n",
      " [0.43620175]] | y: 0.35567609453700116 | Predicción actual: [[0.43502873]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00991139654070139, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39539421]\n",
      " [0.28283611]\n",
      " [0.44783169]\n",
      " [0.44563946]\n",
      " [0.44238442]\n",
      " [0.43895993]\n",
      " [0.43620175]\n",
      " [0.43502873]] | y: 0.3366912049593181 | Predicción actual: [[0.4360784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009515410289168358, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.44783169]\n",
      " [0.44563946]\n",
      " [0.44238442]\n",
      " [0.43895993]\n",
      " [0.43620175]\n",
      " [0.43502873]\n",
      " [0.4360784 ]] | y: 0.3335916311507167 | Predicción actual: [[0.43966556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013837231323122978, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44783169]\n",
      " [0.44563946]\n",
      " [0.44238442]\n",
      " [0.43895993]\n",
      " [0.43620175]\n",
      " [0.43502873]\n",
      " [0.4360784 ]\n",
      " [0.43966556]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004125239793211222, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44563946]\n",
      " [0.44238442]\n",
      " [0.43895993]\n",
      " [0.43620175]\n",
      " [0.43502873]\n",
      " [0.4360784 ]\n",
      " [0.43966556]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.46997252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009328755550086498, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44238442]\n",
      " [0.43895993]\n",
      " [0.43620175]\n",
      " [0.43502873]\n",
      " [0.4360784 ]\n",
      " [0.43966556]\n",
      " [0.3847346 ]\n",
      " [0.46997252]] | y: 0.5962805114296785 | Predicción actual: [[0.4671883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020756036043167114, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43895993]\n",
      " [0.43620175]\n",
      " [0.43502873]\n",
      " [0.4360784 ]\n",
      " [0.43966556]\n",
      " [0.3847346 ]\n",
      " [0.46997252]\n",
      " [0.4671883 ]] | y: 0.574583494769469 | Predicción actual: [[0.46506497]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014597497880458832, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43620175]\n",
      " [0.43502873]\n",
      " [0.4360784 ]\n",
      " [0.43966556]\n",
      " [0.3847346 ]\n",
      " [0.46997252]\n",
      " [0.4671883 ]\n",
      " [0.46506497]] | y: 0.6063541263076326 | Predicción actual: [[0.46402943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022078022360801697, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43502873]\n",
      " [0.4360784 ]\n",
      " [0.43966556]\n",
      " [0.3847346 ]\n",
      " [0.46997252]\n",
      " [0.4671883 ]\n",
      " [0.46506497]\n",
      " [0.46402943]] | y: 0.5846571096474236 | Predicción actual: [[0.4643347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00770688196644187, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4360784 ]\n",
      " [0.43966556]\n",
      " [0.3847346 ]\n",
      " [0.46997252]\n",
      " [0.4671883 ]\n",
      " [0.46506497]\n",
      " [0.46402943]\n",
      " [0.4643347 ]] | y: 0.5687717938783416 | Predicción actual: [[0.46588773]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006657365243881941, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43966556]\n",
      " [0.3847346 ]\n",
      " [0.46997252]\n",
      " [0.4671883 ]\n",
      " [0.46506497]\n",
      " [0.46402943]\n",
      " [0.4643347 ]\n",
      " [0.46588773]] | y: 0.6427741185586981 | Predicción actual: [[0.46835887]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014059544540941715, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.46997252]\n",
      " [0.4671883 ]\n",
      " [0.46506497]\n",
      " [0.46402943]\n",
      " [0.4643347 ]\n",
      " [0.46588773]\n",
      " [0.46835887]] | y: 0.6617590081363811 | Predicción actual: [[0.4712486]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04009208828210831, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46997252]\n",
      " [0.4671883 ]\n",
      " [0.46506497]\n",
      " [0.46402943]\n",
      " [0.4643347 ]\n",
      " [0.46588773]\n",
      " [0.46835887]\n",
      " [0.4712486 ]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045763615518808365, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4671883 ]\n",
      " [0.46506497]\n",
      " [0.46402943]\n",
      " [0.4643347 ]\n",
      " [0.46588773]\n",
      " [0.46835887]\n",
      " [0.4712486 ]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.48971173]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07298031449317932, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46506497]\n",
      " [0.46402943]\n",
      " [0.4643347 ]\n",
      " [0.46588773]\n",
      " [0.46835887]\n",
      " [0.4712486 ]\n",
      " [0.67299496]\n",
      " [0.48971173]] | y: 0.703990701278574 | Predicción actual: [[0.49285322]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037250664085149765, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46402943]\n",
      " [0.4643347 ]\n",
      " [0.46588773]\n",
      " [0.46835887]\n",
      " [0.4712486 ]\n",
      " [0.67299496]\n",
      " [0.48971173]\n",
      " [0.49285322]] | y: 0.7272375048430839 | Predicción actual: [[0.49876153]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0577789843082428, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4643347 ]\n",
      " [0.46588773]\n",
      " [0.46835887]\n",
      " [0.4712486 ]\n",
      " [0.67299496]\n",
      " [0.48971173]\n",
      " [0.49285322]\n",
      " [0.49876153]] | y: 0.722588144130182 | Predicción actual: [[0.50732505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043086253106594086, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46588773]\n",
      " [0.46835887]\n",
      " [0.4712486 ]\n",
      " [0.67299496]\n",
      " [0.48971173]\n",
      " [0.49285322]\n",
      " [0.49876153]\n",
      " [0.50732505]] | y: 0.771793878341728 | Predicción actual: [[0.5181195]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054499123245477676, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46835887]\n",
      " [0.4712486 ]\n",
      " [0.67299496]\n",
      " [0.48971173]\n",
      " [0.49285322]\n",
      " [0.49876153]\n",
      " [0.50732505]\n",
      " [0.51811951]] | y: 0.7245253777605578 | Predicción actual: [[0.5306616]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02751116082072258, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4712486 ]\n",
      " [0.67299496]\n",
      " [0.48971173]\n",
      " [0.49285322]\n",
      " [0.49876153]\n",
      " [0.50732505]\n",
      " [0.51811951]\n",
      " [0.53066158]] | y: 0.6710577295621851 | Predicción actual: [[0.544437]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0335802398622036, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.48971173]\n",
      " [0.49285322]\n",
      " [0.49876153]\n",
      " [0.50732505]\n",
      " [0.51811951]\n",
      " [0.53066158]\n",
      " [0.54443699]] | y: 0.6737698566447115 | Predicción actual: [[0.55912423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03908684477210045, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48971173]\n",
      " [0.49285322]\n",
      " [0.49876153]\n",
      " [0.50732505]\n",
      " [0.51811951]\n",
      " [0.53066158]\n",
      " [0.54443699]\n",
      " [0.55912423]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043085213750600815, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49285322]\n",
      " [0.49876153]\n",
      " [0.50732505]\n",
      " [0.51811951]\n",
      " [0.53066158]\n",
      " [0.54443699]\n",
      " [0.55912423]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5305246]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05954058840870857, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49876153]\n",
      " [0.50732505]\n",
      " [0.51811951]\n",
      " [0.53066158]\n",
      " [0.54443699]\n",
      " [0.55912423]\n",
      " [0.71445176]\n",
      " [0.53052461]] | y: 0.722588144130182 | Predicción actual: [[0.54130554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024791015312075615, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50732505]\n",
      " [0.51811951]\n",
      " [0.53066158]\n",
      " [0.54443699]\n",
      " [0.55912423]\n",
      " [0.71445176]\n",
      " [0.53052461]\n",
      " [0.54130554]] | y: 0.6993413405656723 | Predicción actual: [[0.5540982]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006988817825913429, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51811951]\n",
      " [0.53066158]\n",
      " [0.54443699]\n",
      " [0.55912423]\n",
      " [0.71445176]\n",
      " [0.53052461]\n",
      " [0.54130554]\n",
      " [0.55409819]] | y: 0.7373111197210385 | Predicción actual: [[0.56780976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04512171819806099, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53066158]\n",
      " [0.54443699]\n",
      " [0.55912423]\n",
      " [0.71445176]\n",
      " [0.53052461]\n",
      " [0.54130554]\n",
      " [0.55409819]\n",
      " [0.56780976]] | y: 0.7214258039519565 | Predicción actual: [[0.5813784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01846214197576046, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54443699]\n",
      " [0.55912423]\n",
      " [0.71445176]\n",
      " [0.53052461]\n",
      " [0.54130554]\n",
      " [0.55409819]\n",
      " [0.56780976]\n",
      " [0.5813784 ]] | y: 0.7187136768694304 | Predicción actual: [[0.5936277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028265485540032387, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55912423]\n",
      " [0.71445176]\n",
      " [0.53052461]\n",
      " [0.54130554]\n",
      " [0.55409819]\n",
      " [0.56780976]\n",
      " [0.5813784 ]\n",
      " [0.59362769]] | y: 0.6741573033707864 | Predicción actual: [[0.6036109]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00025392434326931834, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.53052461]\n",
      " [0.54130554]\n",
      " [0.55409819]\n",
      " [0.56780976]\n",
      " [0.5813784 ]\n",
      " [0.59362769]\n",
      " [0.60361087]] | y: 0.698566447113522 | Predicción actual: [[0.61039954]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005777145270258188, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53052461]\n",
      " [0.54130554]\n",
      " [0.55409819]\n",
      " [0.56780976]\n",
      " [0.5813784 ]\n",
      " [0.59362769]\n",
      " [0.60361087]\n",
      " [0.61039954]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01568404957652092, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54130554]\n",
      " [0.55409819]\n",
      " [0.56780976]\n",
      " [0.5813784 ]\n",
      " [0.59362769]\n",
      " [0.60361087]\n",
      " [0.61039954]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.5872757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009412353858351707, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55409819]\n",
      " [0.56780976]\n",
      " [0.5813784 ]\n",
      " [0.59362769]\n",
      " [0.60361087]\n",
      " [0.61039954]\n",
      " [0.72103836]\n",
      " [0.58727568]] | y: 0.7562960092987214 | Predicción actual: [[0.60017633]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03866441175341606, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56780976]\n",
      " [0.5813784 ]\n",
      " [0.59362769]\n",
      " [0.60361087]\n",
      " [0.61039954]\n",
      " [0.72103836]\n",
      " [0.58727568]\n",
      " [0.60017633]] | y: 0.8275862068965516 | Predicción actual: [[0.61318564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11386644840240479, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5813784 ]\n",
      " [0.59362769]\n",
      " [0.60361087]\n",
      " [0.61039954]\n",
      " [0.72103836]\n",
      " [0.58727568]\n",
      " [0.60017633]\n",
      " [0.61318564]] | y: 0.8388221619527314 | Predicción actual: [[0.62553126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0077892690896987915, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59362769]\n",
      " [0.60361087]\n",
      " [0.61039954]\n",
      " [0.72103836]\n",
      " [0.58727568]\n",
      " [0.60017633]\n",
      " [0.61318564]\n",
      " [0.62553126]] | y: 0.7942657884540876 | Predicción actual: [[0.6363891]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0887235626578331, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60361087]\n",
      " [0.61039954]\n",
      " [0.72103836]\n",
      " [0.58727568]\n",
      " [0.60017633]\n",
      " [0.61318564]\n",
      " [0.62553126]\n",
      " [0.63638908]] | y: 0.7838047268500579 | Predicción actual: [[0.6456185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03326531872153282, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61039954]\n",
      " [0.72103836]\n",
      " [0.58727568]\n",
      " [0.60017633]\n",
      " [0.61318564]\n",
      " [0.62553126]\n",
      " [0.63638908]\n",
      " [0.6456185 ]] | y: 0.7679194110809764 | Predicción actual: [[0.6532896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03073575347661972, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.58727568]\n",
      " [0.60017633]\n",
      " [0.61318564]\n",
      " [0.62553126]\n",
      " [0.63638908]\n",
      " [0.6456185 ]\n",
      " [0.65328962]] | y: 0.7845796203022084 | Predicción actual: [[0.6599919]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03153090924024582, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58727568]\n",
      " [0.60017633]\n",
      " [0.61318564]\n",
      " [0.62553126]\n",
      " [0.63638908]\n",
      " [0.6456185 ]\n",
      " [0.65328962]\n",
      " [0.65999192]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11837171018123627, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60017633]\n",
      " [0.61318564]\n",
      " [0.62553126]\n",
      " [0.63638908]\n",
      " [0.6456185 ]\n",
      " [0.65328962]\n",
      " [0.65999192]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.64974725]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05277702957391739, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61318564]\n",
      " [0.62553126]\n",
      " [0.63638908]\n",
      " [0.6456185 ]\n",
      " [0.65328962]\n",
      " [0.65999192]\n",
      " [0.87872917]\n",
      " [0.64974725]] | y: 0.8488957768306855 | Predicción actual: [[0.6645041]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04352220892906189, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62553126]\n",
      " [0.63638908]\n",
      " [0.6456185 ]\n",
      " [0.65328962]\n",
      " [0.65999192]\n",
      " [0.87872917]\n",
      " [0.64974725]\n",
      " [0.66450411]] | y: 0.8182874854707476 | Predicción actual: [[0.6801837]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018256746232509613, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63638908]\n",
      " [0.6456185 ]\n",
      " [0.65328962]\n",
      " [0.65999192]\n",
      " [0.87872917]\n",
      " [0.64974725]\n",
      " [0.66450411]\n",
      " [0.68018371]] | y: 0.8268113134444013 | Predicción actual: [[0.69634664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0075464616529643536, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6456185 ]\n",
      " [0.65328962]\n",
      " [0.65999192]\n",
      " [0.87872917]\n",
      " [0.64974725]\n",
      " [0.66450411]\n",
      " [0.68018371]\n",
      " [0.69634664]] | y: 0.7853545137543589 | Predicción actual: [[0.7127096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006529371719807386, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65328962]\n",
      " [0.65999192]\n",
      " [0.87872917]\n",
      " [0.64974725]\n",
      " [0.66450411]\n",
      " [0.68018371]\n",
      " [0.69634664]\n",
      " [0.71270961]] | y: 0.7892289810151103 | Predicción actual: [[0.7290967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004641699139028788, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65999192]\n",
      " [0.87872917]\n",
      " [0.64974725]\n",
      " [0.66450411]\n",
      " [0.68018371]\n",
      " [0.69634664]\n",
      " [0.71270961]\n",
      " [0.72909671]] | y: 0.8341728012398295 | Predicción actual: [[0.74544674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006436269264668226, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.64974725]\n",
      " [0.66450411]\n",
      " [0.68018371]\n",
      " [0.69634664]\n",
      " [0.71270961]\n",
      " [0.72909671]\n",
      " [0.74544674]] | y: 0.8124757845796202 | Predicción actual: [[0.7614625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027121564373373985, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64974725]\n",
      " [0.66450411]\n",
      " [0.68018371]\n",
      " [0.69634664]\n",
      " [0.71270961]\n",
      " [0.72909671]\n",
      " [0.74544674]\n",
      " [0.76146251]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003487897804006934, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66450411]\n",
      " [0.68018371]\n",
      " [0.69634664]\n",
      " [0.71270961]\n",
      " [0.72909671]\n",
      " [0.74544674]\n",
      " [0.76146251]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7299004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0412137471139431, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68018371]\n",
      " [0.69634664]\n",
      " [0.71270961]\n",
      " [0.72909671]\n",
      " [0.74544674]\n",
      " [0.76146251]\n",
      " [0.80123983]\n",
      " [0.72990042]] | y: 0.793490895001937 | Predicción actual: [[0.74658674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01489062700420618, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69634664]\n",
      " [0.71270961]\n",
      " [0.72909671]\n",
      " [0.74544674]\n",
      " [0.76146251]\n",
      " [0.80123983]\n",
      " [0.72990042]\n",
      " [0.74658674]] | y: 0.760170476559473 | Predicción actual: [[0.7627938]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013562007807195187, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71270961]\n",
      " [0.72909671]\n",
      " [0.74544674]\n",
      " [0.76146251]\n",
      " [0.80123983]\n",
      " [0.72990042]\n",
      " [0.74658674]\n",
      " [0.76279378]] | y: 0.7353738860906625 | Predicción actual: [[0.7776942]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00021164267673157156, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72909671]\n",
      " [0.74544674]\n",
      " [0.76146251]\n",
      " [0.80123983]\n",
      " [0.72990042]\n",
      " [0.74658674]\n",
      " [0.76279378]\n",
      " [0.77769423]] | y: 0.7101898488957767 | Predicción actual: [[0.7903596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02237207256257534, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74544674]\n",
      " [0.76146251]\n",
      " [0.80123983]\n",
      " [0.72990042]\n",
      " [0.74658674]\n",
      " [0.76279378]\n",
      " [0.77769423]\n",
      " [0.79035962]] | y: 0.7121270825261525 | Predicción actual: [[0.7999252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009840937331318855, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76146251]\n",
      " [0.80123983]\n",
      " [0.72990042]\n",
      " [0.74658674]\n",
      " [0.76279378]\n",
      " [0.77769423]\n",
      " [0.79035962]\n",
      " [0.79992521]] | y: 0.7396358000774894 | Predicción actual: [[0.8060504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007116187829524279, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.72990042]\n",
      " [0.74658674]\n",
      " [0.76279378]\n",
      " [0.77769423]\n",
      " [0.79035962]\n",
      " [0.79992521]\n",
      " [0.80605042]] | y: 0.7361487795428128 | Predicción actual: [[0.80854356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013949958607554436, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72990042]\n",
      " [0.74658674]\n",
      " [0.76279378]\n",
      " [0.77769423]\n",
      " [0.79035962]\n",
      " [0.79992521]\n",
      " [0.80605042]\n",
      " [0.80854356]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002782693598419428, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74658674]\n",
      " [0.76279378]\n",
      " [0.77769423]\n",
      " [0.79035962]\n",
      " [0.79992521]\n",
      " [0.80605042]\n",
      " [0.80854356]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.81345576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016831421526148915, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76279378]\n",
      " [0.77769423]\n",
      " [0.79035962]\n",
      " [0.79992521]\n",
      " [0.80605042]\n",
      " [0.80854356]\n",
      " [0.66757071]\n",
      " [0.81345576]] | y: 0.696629213483146 | Predicción actual: [[0.82370186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06586425006389618, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77769423]\n",
      " [0.79035962]\n",
      " [0.79992521]\n",
      " [0.80605042]\n",
      " [0.80854356]\n",
      " [0.66757071]\n",
      " [0.81345576]\n",
      " [0.82370186]] | y: 0.6559473072452537 | Predicción actual: [[0.8297367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004171418491750956, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79035962]\n",
      " [0.79992521]\n",
      " [0.80605042]\n",
      " [0.80854356]\n",
      " [0.66757071]\n",
      " [0.81345576]\n",
      " [0.82370186]\n",
      " [0.82973671]] | y: 0.6788066640836885 | Predicción actual: [[0.8320227]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021292466670274734, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79992521]\n",
      " [0.80605042]\n",
      " [0.80854356]\n",
      " [0.66757071]\n",
      " [0.81345576]\n",
      " [0.82370186]\n",
      " [0.82973671]\n",
      " [0.83202273]] | y: 0.6760945370011622 | Predicción actual: [[0.83095485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01380990818142891, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80605042]\n",
      " [0.80854356]\n",
      " [0.66757071]\n",
      " [0.81345576]\n",
      " [0.82370186]\n",
      " [0.82973671]\n",
      " [0.83202273]\n",
      " [0.83095485]] | y: 0.7295621851995349 | Predicción actual: [[0.8276943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023240646347403526, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80854356]\n",
      " [0.66757071]\n",
      " [0.81345576]\n",
      " [0.82370186]\n",
      " [0.82973671]\n",
      " [0.83202273]\n",
      " [0.83095485]\n",
      " [0.8276943 ]] | y: 0.7012785741960481 | Predicción actual: [[0.82351226]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.896730337757617e-05, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.81345576]\n",
      " [0.82370186]\n",
      " [0.82973671]\n",
      " [0.83202273]\n",
      " [0.83095485]\n",
      " [0.8276943 ]\n",
      " [0.82351226]] | y: 0.767531964354901 | Predicción actual: [[0.8202218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.041705925483257e-05, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81345576]\n",
      " [0.82370186]\n",
      " [0.82973671]\n",
      " [0.83202273]\n",
      " [0.83095485]\n",
      " [0.8276943 ]\n",
      " [0.82351226]\n",
      " [0.82022178]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003582355100661516, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82370186]\n",
      " [0.82973671]\n",
      " [0.83202273]\n",
      " [0.83095485]\n",
      " [0.8276943 ]\n",
      " [0.82351226]\n",
      " [0.82022178]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.86551595]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017290667165070772, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82973671]\n",
      " [0.83202273]\n",
      " [0.83095485]\n",
      " [0.8276943 ]\n",
      " [0.82351226]\n",
      " [0.82022178]\n",
      " [0.75513367]\n",
      " [0.86551595]] | y: 0.7520340953118947 | Predicción actual: [[0.86504245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008637461811304092, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83202273]\n",
      " [0.83095485]\n",
      " [0.8276943 ]\n",
      " [0.82351226]\n",
      " [0.82022178]\n",
      " [0.75513367]\n",
      " [0.86551595]\n",
      " [0.86504245]] | y: 0.7098024021697016 | Predicción actual: [[0.86243695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033054038882255554, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83095485]\n",
      " [0.8276943 ]\n",
      " [0.82351226]\n",
      " [0.82022178]\n",
      " [0.75513367]\n",
      " [0.86551595]\n",
      " [0.86504245]\n",
      " [0.86243695]] | y: 0.6904300658659435 | Predicción actual: [[0.8589185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02046985551714897, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8276943 ]\n",
      " [0.82351226]\n",
      " [0.82022178]\n",
      " [0.75513367]\n",
      " [0.86551595]\n",
      " [0.86504245]\n",
      " [0.86243695]\n",
      " [0.85891849]] | y: 0.7543587756683454 | Predicción actual: [[0.8561186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008473129011690617, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82351226]\n",
      " [0.82022178]\n",
      " [0.75513367]\n",
      " [0.86551595]\n",
      " [0.86504245]\n",
      " [0.86243695]\n",
      " [0.85891849]\n",
      " [0.85611862]] | y: 0.7222006974041069 | Predicción actual: [[0.8556964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010305947624146938, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82022178]\n",
      " [0.75513367]\n",
      " [0.86551595]\n",
      " [0.86504245]\n",
      " [0.86243695]\n",
      " [0.85891849]\n",
      " [0.85611862]\n",
      " [0.85569638]] | y: 0.8485083301046106 | Predicción actual: [[0.85808146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016265755984932184, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.86551595]\n",
      " [0.86504245]\n",
      " [0.86243695]\n",
      " [0.85891849]\n",
      " [0.85611862]\n",
      " [0.85569638]\n",
      " [0.85808146]] | y: 0.9054629988376597 | Predicción actual: [[0.8636557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013550141593441367, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86551595]\n",
      " [0.86504245]\n",
      " [0.86243695]\n",
      " [0.85891849]\n",
      " [0.85611862]\n",
      " [0.85569638]\n",
      " [0.85808146]\n",
      " [0.86365569]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006146861705929041, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86504245]\n",
      " [0.86243695]\n",
      " [0.85891849]\n",
      " [0.85611862]\n",
      " [0.85569638]\n",
      " [0.85808146]\n",
      " [0.86365569]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.88965446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024506677873432636, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86243695]\n",
      " [0.85891849]\n",
      " [0.85611862]\n",
      " [0.85569638]\n",
      " [0.85808146]\n",
      " [0.86365569]\n",
      " [0.8822162 ]\n",
      " [0.88965446]] | y: 0.889577683068578 | Predicción actual: [[0.88761526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006965159438550472, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85891849]\n",
      " [0.85611862]\n",
      " [0.85569638]\n",
      " [0.85808146]\n",
      " [0.86365569]\n",
      " [0.8822162 ]\n",
      " [0.88965446]\n",
      " [0.88761526]] | y: 0.8748547074777218 | Predicción actual: [[0.8867899]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002983327955007553, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85611862]\n",
      " [0.85569638]\n",
      " [0.85808146]\n",
      " [0.86365569]\n",
      " [0.8822162 ]\n",
      " [0.88965446]\n",
      " [0.88761526]\n",
      " [0.88678992]] | y: 0.9132119333591631 | Predicción actual: [[0.8881937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007596427574753761, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85569638]\n",
      " [0.85808146]\n",
      " [0.86365569]\n",
      " [0.8822162 ]\n",
      " [0.88965446]\n",
      " [0.88761526]\n",
      " [0.88678992]\n",
      " [0.88819373]] | y: 1.0 | Predicción actual: [[0.89163566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011091017164289951, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85808146]\n",
      " [0.86365569]\n",
      " [0.8822162 ]\n",
      " [0.88965446]\n",
      " [0.88761526]\n",
      " [0.88678992]\n",
      " [0.88819373]\n",
      " [0.89163566]] | y: 0.9705540488182873 | Predicción actual: [[0.8970778]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.328077344936901e-07, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86365569]\n",
      " [0.8822162 ]\n",
      " [0.88965446]\n",
      " [0.88761526]\n",
      " [0.88678992]\n",
      " [0.88819373]\n",
      " [0.89163566]\n",
      " [0.8970778 ]] | y: 0.8888027896164277 | Predicción actual: [[0.90346754]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0041289194487035275, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.88965446]\n",
      " [0.88761526]\n",
      " [0.88678992]\n",
      " [0.88819373]\n",
      " [0.89163566]\n",
      " [0.8970778 ]\n",
      " [0.90346754]] | y: 0.877954281286323 | Predicción actual: [[0.90959066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005752673023380339, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88965446]\n",
      " [0.88761526]\n",
      " [0.88678992]\n",
      " [0.88819373]\n",
      " [0.89163566]\n",
      " [0.8970778 ]\n",
      " [0.90346754]\n",
      " [0.90959066]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026298854500055313, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88761526]\n",
      " [0.88678992]\n",
      " [0.88819373]\n",
      " [0.89163566]\n",
      " [0.8970778 ]\n",
      " [0.90346754]\n",
      " [0.90959066]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.910975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001169437076896429, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88678992]\n",
      " [0.88819373]\n",
      " [0.89163566]\n",
      " [0.8970778 ]\n",
      " [0.90346754]\n",
      " [0.90959066]\n",
      " [0.84889578]\n",
      " [0.91097498]] | y: 0.8550949244478885 | Predicción actual: [[0.9115331]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02029799111187458, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88819373]\n",
      " [0.89163566]\n",
      " [0.8970778 ]\n",
      " [0.90346754]\n",
      " [0.90959066]\n",
      " [0.84889578]\n",
      " [0.91097498]\n",
      " [0.91153312]] | y: 0.8752421542037967 | Predicción actual: [[0.9124372]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005295030307024717, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89163566]\n",
      " [0.8970778 ]\n",
      " [0.90346754]\n",
      " [0.90959066]\n",
      " [0.84889578]\n",
      " [0.91097498]\n",
      " [0.91153312]\n",
      " [0.9124372 ]] | y: 0.857032158078264 | Predicción actual: [[0.9136674]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018877520924434066, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8970778 ]\n",
      " [0.90346754]\n",
      " [0.90959066]\n",
      " [0.84889578]\n",
      " [0.91097498]\n",
      " [0.91153312]\n",
      " [0.9124372 ]\n",
      " [0.91366738]] | y: 0.8500581170089112 | Predicción actual: [[0.91460264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013453118735924363, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90346754]\n",
      " [0.90959066]\n",
      " [0.84889578]\n",
      " [0.91097498]\n",
      " [0.91153312]\n",
      " [0.9124372 ]\n",
      " [0.91366738]\n",
      " [0.91460264]] | y: 0.8426966292134832 | Predicción actual: [[0.91448075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05939595028758049, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90959066]\n",
      " [0.84889578]\n",
      " [0.91097498]\n",
      " [0.91153312]\n",
      " [0.9124372 ]\n",
      " [0.91366738]\n",
      " [0.91460264]\n",
      " [0.91448075]] | y: 0.8229368461836497 | Predicción actual: [[0.91242623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025414587929844856, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.91097498]\n",
      " [0.91153312]\n",
      " [0.9124372 ]\n",
      " [0.91366738]\n",
      " [0.91460264]\n",
      " [0.91448075]\n",
      " [0.91242623]] | y: 0.7745060054242543 | Predicción actual: [[0.9088428]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05131136626005173, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91097498]\n",
      " [0.91153312]\n",
      " [0.9124372 ]\n",
      " [0.91366738]\n",
      " [0.91460264]\n",
      " [0.91448075]\n",
      " [0.91242623]\n",
      " [0.9088428 ]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030597098171710968, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91153312]\n",
      " [0.9124372 ]\n",
      " [0.91366738]\n",
      " [0.91460264]\n",
      " [0.91448075]\n",
      " [0.91242623]\n",
      " [0.9088428 ]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.9218041]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01281815581023693, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.9124372 ]\n",
      " [0.91366738]\n",
      " [0.91460264]\n",
      " [0.91448075]\n",
      " [0.91242623]\n",
      " [0.9088428 ]\n",
      " [0.78419217]\n",
      " [0.92180407]] | y: 0.854320030995738 | Predicción actual: [[0.91799027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014698694460093975, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91366738]\n",
      " [0.91460264]\n",
      " [0.91448075]\n",
      " [0.91242623]\n",
      " [0.9088428 ]\n",
      " [0.78419217]\n",
      " [0.92180407]\n",
      " [0.91799027]] | y: 0.8368849283223556 | Predicción actual: [[0.9126297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01571374200284481, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91460264]\n",
      " [0.91448075]\n",
      " [0.91242623]\n",
      " [0.9088428 ]\n",
      " [0.78419217]\n",
      " [0.92180407]\n",
      " [0.91799027]\n",
      " [0.91262972]] | y: 0.8299108872530028 | Predicción actual: [[0.9057096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005084977950900793, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91448075]\n",
      " [0.91242623]\n",
      " [0.9088428 ]\n",
      " [0.78419217]\n",
      " [0.92180407]\n",
      " [0.91799027]\n",
      " [0.91262972]\n",
      " [0.90570962]] | y: 0.887253002712127 | Predicción actual: [[0.89767593]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013032035203650594, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91242623]\n",
      " [0.9088428 ]\n",
      " [0.78419217]\n",
      " [0.92180407]\n",
      " [0.91799027]\n",
      " [0.91262972]\n",
      " [0.90570962]\n",
      " [0.89767593]] | y: 0.8597442851607902 | Predicción actual: [[0.88934785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00039553901297040284, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.9088428 ]\n",
      " [0.78419217]\n",
      " [0.92180407]\n",
      " [0.91799027]\n",
      " [0.91262972]\n",
      " [0.90570962]\n",
      " [0.89767593]\n",
      " [0.88934785]] | y: 0.8395970554048819 | Predicción actual: [[0.8815299]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022110767662525177, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.92180407]\n",
      " [0.91799027]\n",
      " [0.91262972]\n",
      " [0.90570962]\n",
      " [0.89767593]\n",
      " [0.88934785]\n",
      " [0.88152993]] | y: 0.7838047268500579 | Predicción actual: [[0.87453914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028611700981855392, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92180407]\n",
      " [0.91799027]\n",
      " [0.91262972]\n",
      " [0.90570962]\n",
      " [0.89767593]\n",
      " [0.88934785]\n",
      " [0.88152993]\n",
      " [0.87453914]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007929126732051373, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91799027]\n",
      " [0.91262972]\n",
      " [0.90570962]\n",
      " [0.89767593]\n",
      " [0.88934785]\n",
      " [0.88152993]\n",
      " [0.87453914]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.89691865]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0069506908766925335, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91262972]\n",
      " [0.90570962]\n",
      " [0.89767593]\n",
      " [0.88934785]\n",
      " [0.88152993]\n",
      " [0.87453914]\n",
      " [0.81828749]\n",
      " [0.89691865]] | y: 0.7605579232855482 | Predicción actual: [[0.8877252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06367103010416031, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90570962]\n",
      " [0.89767593]\n",
      " [0.88934785]\n",
      " [0.88152993]\n",
      " [0.87453914]\n",
      " [0.81828749]\n",
      " [0.89691865]\n",
      " [0.88772517]] | y: 0.7915536613715615 | Predicción actual: [[0.87765133]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011963725090026855, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89767593]\n",
      " [0.88934785]\n",
      " [0.88152993]\n",
      " [0.87453914]\n",
      " [0.81828749]\n",
      " [0.89691865]\n",
      " [0.88772517]\n",
      " [0.87765133]] | y: 0.7686943045331267 | Predicción actual: [[0.86790913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05761620029807091, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88934785]\n",
      " [0.88152993]\n",
      " [0.87453914]\n",
      " [0.81828749]\n",
      " [0.89691865]\n",
      " [0.88772517]\n",
      " [0.87765133]\n",
      " [0.86790913]] | y: 0.7686943045331267 | Predicción actual: [[0.8588842]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017362112179398537, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88152993]\n",
      " [0.87453914]\n",
      " [0.81828749]\n",
      " [0.89691865]\n",
      " [0.88772517]\n",
      " [0.87765133]\n",
      " [0.86790913]\n",
      " [0.85888422]] | y: 0.7989151491669895 | Predicción actual: [[0.85133684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07139717787504196, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87453914]\n",
      " [0.81828749]\n",
      " [0.89691865]\n",
      " [0.88772517]\n",
      " [0.87765133]\n",
      " [0.86790913]\n",
      " [0.85888422]\n",
      " [0.85133684]] | y: 0.7900038744672608 | Predicción actual: [[0.8450285]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013200410176068544, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.89691865]\n",
      " [0.88772517]\n",
      " [0.87765133]\n",
      " [0.86790913]\n",
      " [0.85888422]\n",
      " [0.85133684]\n",
      " [0.84502852]] | y: 0.760170476559473 | Predicción actual: [[0.84057456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04843920096755028, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89691865]\n",
      " [0.88772517]\n",
      " [0.87765133]\n",
      " [0.86790913]\n",
      " [0.85888422]\n",
      " [0.85133684]\n",
      " [0.84502852]\n",
      " [0.84057456]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04738885536789894, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88772517]\n",
      " [0.87765133]\n",
      " [0.86790913]\n",
      " [0.85888422]\n",
      " [0.85133684]\n",
      " [0.84502852]\n",
      " [0.84057456]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8394239]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032402556389570236, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87765133]\n",
      " [0.86790913]\n",
      " [0.85888422]\n",
      " [0.85133684]\n",
      " [0.84502852]\n",
      " [0.84057456]\n",
      " [0.68539326]\n",
      " [0.83942389]] | y: 0.6648585819449826 | Predicción actual: [[0.82623625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04564952477812767, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86790913]\n",
      " [0.85888422]\n",
      " [0.85133684]\n",
      " [0.84502852]\n",
      " [0.84057456]\n",
      " [0.68539326]\n",
      " [0.83942389]\n",
      " [0.82623625]] | y: 0.7078651685393258 | Predicción actual: [[0.81242746]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02436048537492752, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85888422]\n",
      " [0.85133684]\n",
      " [0.84502852]\n",
      " [0.84057456]\n",
      " [0.68539326]\n",
      " [0.83942389]\n",
      " [0.82623625]\n",
      " [0.81242746]] | y: 0.6648585819449826 | Predicción actual: [[0.7983362]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001305282930843532, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85133684]\n",
      " [0.84502852]\n",
      " [0.84057456]\n",
      " [0.68539326]\n",
      " [0.83942389]\n",
      " [0.82623625]\n",
      " [0.81242746]\n",
      " [0.79833621]] | y: 0.7113521890740022 | Predicción actual: [[0.78449345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014211370144039392, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84502852]\n",
      " [0.84057456]\n",
      " [0.68539326]\n",
      " [0.83942389]\n",
      " [0.82623625]\n",
      " [0.81242746]\n",
      " [0.79833621]\n",
      " [0.78449345]] | y: 0.6772568771793879 | Predicción actual: [[0.77071077]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0056340317241847515, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84057456]\n",
      " [0.68539326]\n",
      " [0.83942389]\n",
      " [0.82623625]\n",
      " [0.81242746]\n",
      " [0.79833621]\n",
      " [0.78449345]\n",
      " [0.77071077]] | y: 0.7621077101898488 | Predicción actual: [[0.75706154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007333129644393921, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.83942389]\n",
      " [0.82623625]\n",
      " [0.81242746]\n",
      " [0.79833621]\n",
      " [0.78449345]\n",
      " [0.77071077]\n",
      " [0.75706154]] | y: 0.8070515304145678 | Predicción actual: [[0.74320495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024406015872955322, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83942389]\n",
      " [0.82623625]\n",
      " [0.81242746]\n",
      " [0.79833621]\n",
      " [0.78449345]\n",
      " [0.77071077]\n",
      " [0.75706154]\n",
      " [0.74320495]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009267676621675491, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82623625]\n",
      " [0.81242746]\n",
      " [0.79833621]\n",
      " [0.78449345]\n",
      " [0.77071077]\n",
      " [0.75706154]\n",
      " [0.74320495]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7581623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008648056536912918, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81242746]\n",
      " [0.79833621]\n",
      " [0.78449345]\n",
      " [0.77071077]\n",
      " [0.75706154]\n",
      " [0.74320495]\n",
      " [0.81518791]\n",
      " [0.75816232]] | y: 0.9597055404881829 | Predicción actual: [[0.7468326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08463327586650848, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79833621]\n",
      " [0.78449345]\n",
      " [0.77071077]\n",
      " [0.75706154]\n",
      " [0.74320495]\n",
      " [0.81518791]\n",
      " [0.75816232]\n",
      " [0.74683261]] | y: 0.9643549012010848 | Predicción actual: [[0.73746765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04249914735555649, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78449345]\n",
      " [0.77071077]\n",
      " [0.75706154]\n",
      " [0.74320495]\n",
      " [0.81518791]\n",
      " [0.75816232]\n",
      " [0.74683261]\n",
      " [0.73746765]] | y: 0.8880278961642774 | Predicción actual: [[0.7303525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018448149785399437, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77071077]\n",
      " [0.75706154]\n",
      " [0.74320495]\n",
      " [0.81518791]\n",
      " [0.75816232]\n",
      " [0.74683261]\n",
      " [0.73746765]\n",
      " [0.73035252]] | y: 0.8926772568771792 | Predicción actual: [[0.72554755]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01687411218881607, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75706154]\n",
      " [0.74320495]\n",
      " [0.81518791]\n",
      " [0.75816232]\n",
      " [0.74683261]\n",
      " [0.73746765]\n",
      " [0.73035252]\n",
      " [0.72554755]] | y: 0.8752421542037967 | Predicción actual: [[0.7231891]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009817466139793396, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74320495]\n",
      " [0.81518791]\n",
      " [0.75816232]\n",
      " [0.74683261]\n",
      " [0.73746765]\n",
      " [0.73035252]\n",
      " [0.72554755]\n",
      " [0.72318912]] | y: 0.8508330104610615 | Predicción actual: [[0.72330517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017744967713952065, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.75816232]\n",
      " [0.74683261]\n",
      " [0.73746765]\n",
      " [0.73035252]\n",
      " [0.72554755]\n",
      " [0.72318912]\n",
      " [0.72330517]] | y: 0.8488957768306855 | Predicción actual: [[0.72607136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03779268637299538, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75816232]\n",
      " [0.74683261]\n",
      " [0.73746765]\n",
      " [0.73035252]\n",
      " [0.72554755]\n",
      " [0.72318912]\n",
      " [0.72330517]\n",
      " [0.72607136]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.15322118997573853, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74683261]\n",
      " [0.73746765]\n",
      " [0.73035252]\n",
      " [0.72554755]\n",
      " [0.72318912]\n",
      " [0.72330517]\n",
      " [0.72607136]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7044346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04680041968822479, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73746765]\n",
      " [0.73035252]\n",
      " [0.72554755]\n",
      " [0.72318912]\n",
      " [0.72330517]\n",
      " [0.72607136]\n",
      " [0.96241767]\n",
      " [0.70443457]] | y: 0.9407206509104997 | Predicción actual: [[0.7045634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.27645930647850037, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73035252]\n",
      " [0.72554755]\n",
      " [0.72318912]\n",
      " [0.72330517]\n",
      " [0.72607136]\n",
      " [0.96241767]\n",
      " [0.70443457]\n",
      " [0.70456338]] | y: 0.9724912824486633 | Predicción actual: [[0.7085928]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06808234751224518, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72554755]\n",
      " [0.72318912]\n",
      " [0.72330517]\n",
      " [0.72607136]\n",
      " [0.96241767]\n",
      " [0.70443457]\n",
      " [0.70456338]\n",
      " [0.70859277]] | y: 0.9969004261913985 | Predicción actual: [[0.7158356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12893657386302948, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72318912]\n",
      " [0.72330517]\n",
      " [0.72607136]\n",
      " [0.96241767]\n",
      " [0.70443457]\n",
      " [0.70456338]\n",
      " [0.70859277]\n",
      " [0.71583557]] | y: 0.951181712514529 | Predicción actual: [[0.72544765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015131278894841671, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72330517]\n",
      " [0.72607136]\n",
      " [0.96241767]\n",
      " [0.70443457]\n",
      " [0.70456338]\n",
      " [0.70859277]\n",
      " [0.71583557]\n",
      " [0.72544765]] | y: 0.8957768306857805 | Predicción actual: [[0.73606944]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024975601583719254, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72607136]\n",
      " [0.96241767]\n",
      " [0.70443457]\n",
      " [0.70456338]\n",
      " [0.70859277]\n",
      " [0.71583557]\n",
      " [0.72544765]\n",
      " [0.73606944]] | y: 0.8814413018209997 | Predicción actual: [[0.7465528]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02292713150382042, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.70443457]\n",
      " [0.70456338]\n",
      " [0.70859277]\n",
      " [0.71583557]\n",
      " [0.72544765]\n",
      " [0.73606944]\n",
      " [0.74655282]] | y: 0.9170864006199149 | Predicción actual: [[0.7556816]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018052838742733, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70443457]\n",
      " [0.70456338]\n",
      " [0.70859277]\n",
      " [0.71583557]\n",
      " [0.72544765]\n",
      " [0.73606944]\n",
      " [0.74655282]\n",
      " [0.75568157]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004435834416653961, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70456338]\n",
      " [0.70859277]\n",
      " [0.71583557]\n",
      " [0.72544765]\n",
      " [0.73606944]\n",
      " [0.74655282]\n",
      " [0.75568157]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.70504236]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12475062906742096, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70859277]\n",
      " [0.71583557]\n",
      " [0.72544765]\n",
      " [0.73606944]\n",
      " [0.74655282]\n",
      " [0.75568157]\n",
      " [0.91979853]\n",
      " [0.70504236]] | y: 0.9682293684618366 | Predicción actual: [[0.715696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03524067997932434, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71583557]\n",
      " [0.72544765]\n",
      " [0.73606944]\n",
      " [0.74655282]\n",
      " [0.75568157]\n",
      " [0.91979853]\n",
      " [0.70504236]\n",
      " [0.71569598]] | y: 0.9577683068578069 | Predicción actual: [[0.72825295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03757624328136444, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20600748]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032261330634355545, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20600748]] | y: 0.10422316931421921 | Predicción actual: [[0.19104566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01025391649454832, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20600748]\n",
      " [0.19104566]] | y: 0.15420379697791559 | Predicción actual: [[0.19534911]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007528078276664019, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20600748]\n",
      " [0.19104566]\n",
      " [0.19534911]] | y: 0.1557535838822161 | Predicción actual: [[0.20691364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023295197170227766, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20600748]\n",
      " [0.19104566]\n",
      " [0.19534911]\n",
      " [0.20691364]] | y: 0.12553273924835334 | Predicción actual: [[0.2196711]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011305560357868671, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20600748]\n",
      " [0.19104566]\n",
      " [0.19534911]\n",
      " [0.20691364]\n",
      " [0.2196711 ]] | y: 0.1456799690042619 | Predicción actual: [[0.22989541]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003666754113510251, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20600748]\n",
      " [0.19104566]\n",
      " [0.19534911]\n",
      " [0.20691364]\n",
      " [0.2196711 ]\n",
      " [0.22989541]] | y: 0.1464548624564122 | Predicción actual: [[0.2514923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010694069787859917, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20600748]\n",
      " [0.19104566]\n",
      " [0.19534911]\n",
      " [0.20691364]\n",
      " [0.2196711 ]\n",
      " [0.22989541]\n",
      " [0.25149229]] | y: 0.1960480433940332 | Predicción actual: [[0.27806497]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016800514422357082, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20600748]\n",
      " [0.19104566]\n",
      " [0.19534911]\n",
      " [0.20691364]\n",
      " [0.2196711 ]\n",
      " [0.22989541]\n",
      " [0.25149229]\n",
      " [0.27806497]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004414239898324013, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19104566]\n",
      " [0.19534911]\n",
      " [0.20691364]\n",
      " [0.2196711 ]\n",
      " [0.22989541]\n",
      " [0.25149229]\n",
      " [0.27806497]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.31244108]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00681010028347373, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19534911]\n",
      " [0.20691364]\n",
      " [0.2196711 ]\n",
      " [0.22989541]\n",
      " [0.25149229]\n",
      " [0.27806497]\n",
      " [0.2305308 ]\n",
      " [0.31244108]] | y: 0.211933359163115 | Predicción actual: [[0.31975996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014232310466468334, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20691364]\n",
      " [0.2196711 ]\n",
      " [0.22989541]\n",
      " [0.25149229]\n",
      " [0.27806497]\n",
      " [0.2305308 ]\n",
      " [0.31244108]\n",
      " [0.31975996]] | y: 0.2072839984502131 | Predicción actual: [[0.32887977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01354935672134161, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2196711 ]\n",
      " [0.22989541]\n",
      " [0.25149229]\n",
      " [0.27806497]\n",
      " [0.2305308 ]\n",
      " [0.31244108]\n",
      " [0.31975996]\n",
      " [0.32887977]] | y: 0.19294846958543205 | Predicción actual: [[0.338609]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04255294054746628, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22989541]\n",
      " [0.25149229]\n",
      " [0.27806497]\n",
      " [0.2305308 ]\n",
      " [0.31244108]\n",
      " [0.31975996]\n",
      " [0.32887977]\n",
      " [0.33860901]] | y: 0.19682293684618352 | Predicción actual: [[0.34880808]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017709573730826378, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25149229]\n",
      " [0.27806497]\n",
      " [0.2305308 ]\n",
      " [0.31244108]\n",
      " [0.31975996]\n",
      " [0.32887977]\n",
      " [0.33860901]\n",
      " [0.34880808]] | y: 0.21425803951956607 | Predicción actual: [[0.36020696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02567850798368454, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27806497]\n",
      " [0.2305308 ]\n",
      " [0.31244108]\n",
      " [0.31975996]\n",
      " [0.32887977]\n",
      " [0.33860901]\n",
      " [0.34880808]\n",
      " [0.36020696]] | y: 0.18132506780317698 | Predicción actual: [[0.37023807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0405999980866909, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31244108]\n",
      " [0.31975996]\n",
      " [0.32887977]\n",
      " [0.33860901]\n",
      " [0.34880808]\n",
      " [0.36020696]\n",
      " [0.37023807]] | y: 0.17512592018597434 | Predicción actual: [[0.37738752]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06781741231679916, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31244108]\n",
      " [0.31975996]\n",
      " [0.32887977]\n",
      " [0.33860901]\n",
      " [0.34880808]\n",
      " [0.36020696]\n",
      " [0.37023807]\n",
      " [0.37738752]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07622822374105453, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31975996]\n",
      " [0.32887977]\n",
      " [0.33860901]\n",
      " [0.34880808]\n",
      " [0.36020696]\n",
      " [0.37023807]\n",
      " [0.37738752]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40387782]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05981304123997688, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32887977]\n",
      " [0.33860901]\n",
      " [0.34880808]\n",
      " [0.36020696]\n",
      " [0.37023807]\n",
      " [0.37738752]\n",
      " [0.14800465]\n",
      " [0.40387782]] | y: 0.19217357613328173 | Predicción actual: [[0.40766597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03903007507324219, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33860901]\n",
      " [0.34880808]\n",
      " [0.36020696]\n",
      " [0.37023807]\n",
      " [0.37738752]\n",
      " [0.14800465]\n",
      " [0.40387782]\n",
      " [0.40766597]] | y: 0.1859744285160791 | Predicción actual: [[0.40970814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04809896647930145, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34880808]\n",
      " [0.36020696]\n",
      " [0.37023807]\n",
      " [0.37738752]\n",
      " [0.14800465]\n",
      " [0.40387782]\n",
      " [0.40766597]\n",
      " [0.40970814]] | y: 0.26695079426578844 | Predicción actual: [[0.41003767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030013255774974823, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36020696]\n",
      " [0.37023807]\n",
      " [0.37738752]\n",
      " [0.14800465]\n",
      " [0.40387782]\n",
      " [0.40766597]\n",
      " [0.40970814]\n",
      " [0.41003767]] | y: 0.2925222781867493 | Predicción actual: [[0.40887702]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010862628929316998, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37023807]\n",
      " [0.37738752]\n",
      " [0.14800465]\n",
      " [0.40387782]\n",
      " [0.40766597]\n",
      " [0.40970814]\n",
      " [0.41003767]\n",
      " [0.40887702]] | y: 0.3177063153816349 | Predicción actual: [[0.40631625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00252751843072474, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37738752]\n",
      " [0.14800465]\n",
      " [0.40387782]\n",
      " [0.40766597]\n",
      " [0.40970814]\n",
      " [0.41003767]\n",
      " [0.40887702]\n",
      " [0.40631625]] | y: 0.31266950794265785 | Predicción actual: [[0.40296915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01993590220808983, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40387782]\n",
      " [0.40766597]\n",
      " [0.40970814]\n",
      " [0.41003767]\n",
      " [0.40887702]\n",
      " [0.40631625]\n",
      " [0.40296915]] | y: 0.2890352576520729 | Predicción actual: [[0.3996695]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044648729264736176, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40387782]\n",
      " [0.40766597]\n",
      " [0.40970814]\n",
      " [0.41003767]\n",
      " [0.40887702]\n",
      " [0.40631625]\n",
      " [0.40296915]\n",
      " [0.3996695 ]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04918299987912178, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40766597]\n",
      " [0.40970814]\n",
      " [0.41003767]\n",
      " [0.40887702]\n",
      " [0.40631625]\n",
      " [0.40296915]\n",
      " [0.3996695 ]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.45301372]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008614975027740002, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40970814]\n",
      " [0.41003767]\n",
      " [0.40887702]\n",
      " [0.40631625]\n",
      " [0.40296915]\n",
      " [0.3996695 ]\n",
      " [0.28283611]\n",
      " [0.45301372]] | y: 0.2758620689655173 | Predicción actual: [[0.45071593]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049859754741191864, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41003767]\n",
      " [0.40887702]\n",
      " [0.40631625]\n",
      " [0.40296915]\n",
      " [0.3996695 ]\n",
      " [0.28283611]\n",
      " [0.45301372]\n",
      " [0.45071593]] | y: 0.2746997287872917 | Predicción actual: [[0.44731998]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0347716398537159, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40887702]\n",
      " [0.40631625]\n",
      " [0.40296915]\n",
      " [0.3996695 ]\n",
      " [0.28283611]\n",
      " [0.45301372]\n",
      " [0.45071593]\n",
      " [0.44731998]] | y: 0.275474622239442 | Predicción actual: [[0.44371656]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017363933846354485, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40631625]\n",
      " [0.40296915]\n",
      " [0.3996695 ]\n",
      " [0.28283611]\n",
      " [0.45301372]\n",
      " [0.45071593]\n",
      " [0.44731998]\n",
      " [0.44371656]] | y: 0.3347539713289423 | Predicción actual: [[0.44084468]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011476445011794567, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40296915]\n",
      " [0.3996695 ]\n",
      " [0.28283611]\n",
      " [0.45301372]\n",
      " [0.45071593]\n",
      " [0.44731998]\n",
      " [0.44371656]\n",
      " [0.44084468]] | y: 0.35567609453700116 | Predicción actual: [[0.4395777]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013144317083060741, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3996695 ]\n",
      " [0.28283611]\n",
      " [0.45301372]\n",
      " [0.45071593]\n",
      " [0.44731998]\n",
      " [0.44371656]\n",
      " [0.44084468]\n",
      " [0.4395777 ]] | y: 0.3366912049593181 | Predicción actual: [[0.44054762]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005718054715543985, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.45301372]\n",
      " [0.45071593]\n",
      " [0.44731998]\n",
      " [0.44371656]\n",
      " [0.44084468]\n",
      " [0.4395777 ]\n",
      " [0.44054762]] | y: 0.3335916311507167 | Predicción actual: [[0.4441114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017099319025874138, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45301372]\n",
      " [0.45071593]\n",
      " [0.44731998]\n",
      " [0.44371656]\n",
      " [0.44084468]\n",
      " [0.4395777 ]\n",
      " [0.44054762]\n",
      " [0.44411141]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022878142073750496, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45071593]\n",
      " [0.44731998]\n",
      " [0.44371656]\n",
      " [0.44084468]\n",
      " [0.4395777 ]\n",
      " [0.44054762]\n",
      " [0.44411141]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.47537652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015104720368981361, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44731998]\n",
      " [0.44371656]\n",
      " [0.44084468]\n",
      " [0.4395777 ]\n",
      " [0.44054762]\n",
      " [0.44411141]\n",
      " [0.3847346 ]\n",
      " [0.47537652]] | y: 0.5962805114296785 | Predicción actual: [[0.47233805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0278768353164196, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44371656]\n",
      " [0.44084468]\n",
      " [0.4395777 ]\n",
      " [0.44054762]\n",
      " [0.44411141]\n",
      " [0.3847346 ]\n",
      " [0.47537652]\n",
      " [0.47233805]] | y: 0.574583494769469 | Predicción actual: [[0.46997002]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006095383316278458, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44084468]\n",
      " [0.4395777 ]\n",
      " [0.44054762]\n",
      " [0.44411141]\n",
      " [0.3847346 ]\n",
      " [0.47537652]\n",
      " [0.47233805]\n",
      " [0.46997002]] | y: 0.6063541263076326 | Predicción actual: [[0.46868917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04935986548662186, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4395777 ]\n",
      " [0.44054762]\n",
      " [0.44411141]\n",
      " [0.3847346 ]\n",
      " [0.47537652]\n",
      " [0.47233805]\n",
      " [0.46997002]\n",
      " [0.46868917]] | y: 0.5846571096474236 | Predicción actual: [[0.46879333]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03198840841650963, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44054762]\n",
      " [0.44411141]\n",
      " [0.3847346 ]\n",
      " [0.47537652]\n",
      " [0.47233805]\n",
      " [0.46997002]\n",
      " [0.46868917]\n",
      " [0.46879333]] | y: 0.5687717938783416 | Predicción actual: [[0.47021198]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017986954189836979, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44411141]\n",
      " [0.3847346 ]\n",
      " [0.47537652]\n",
      " [0.47233805]\n",
      " [0.46997002]\n",
      " [0.46868917]\n",
      " [0.46879333]\n",
      " [0.47021198]] | y: 0.6427741185586981 | Predicción actual: [[0.4725558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02435501478612423, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.47537652]\n",
      " [0.47233805]\n",
      " [0.46997002]\n",
      " [0.46868917]\n",
      " [0.46879333]\n",
      " [0.47021198]\n",
      " [0.47255579]] | y: 0.6617590081363811 | Predicción actual: [[0.4753549]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05254163220524788, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47537652]\n",
      " [0.47233805]\n",
      " [0.46997002]\n",
      " [0.46868917]\n",
      " [0.46879333]\n",
      " [0.47021198]\n",
      " [0.47255579]\n",
      " [0.47535491]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.058495987206697464, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47233805]\n",
      " [0.46997002]\n",
      " [0.46868917]\n",
      " [0.46879333]\n",
      " [0.47021198]\n",
      " [0.47255579]\n",
      " [0.47535491]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.49469417]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05397940054535866, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46997002]\n",
      " [0.46868917]\n",
      " [0.46879333]\n",
      " [0.47021198]\n",
      " [0.47255579]\n",
      " [0.47535491]\n",
      " [0.67299496]\n",
      " [0.49469417]] | y: 0.703990701278574 | Predicción actual: [[0.49761564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04015031456947327, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46868917]\n",
      " [0.46879333]\n",
      " [0.47021198]\n",
      " [0.47255579]\n",
      " [0.47535491]\n",
      " [0.67299496]\n",
      " [0.49469417]\n",
      " [0.49761564]] | y: 0.7272375048430839 | Predicción actual: [[0.5033114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04114918038249016, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46879333]\n",
      " [0.47021198]\n",
      " [0.47255579]\n",
      " [0.47535491]\n",
      " [0.67299496]\n",
      " [0.49469417]\n",
      " [0.49761564]\n",
      " [0.5033114 ]] | y: 0.722588144130182 | Predicción actual: [[0.5116633]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055453795939683914, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47021198]\n",
      " [0.47255579]\n",
      " [0.47535491]\n",
      " [0.67299496]\n",
      " [0.49469417]\n",
      " [0.49761564]\n",
      " [0.5033114 ]\n",
      " [0.51166332]] | y: 0.771793878341728 | Predicción actual: [[0.52228874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027651824057102203, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47255579]\n",
      " [0.47535491]\n",
      " [0.67299496]\n",
      " [0.49469417]\n",
      " [0.49761564]\n",
      " [0.5033114 ]\n",
      " [0.51166332]\n",
      " [0.52228874]] | y: 0.7245253777605578 | Predicción actual: [[0.53465766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04637445509433746, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47535491]\n",
      " [0.67299496]\n",
      " [0.49469417]\n",
      " [0.49761564]\n",
      " [0.5033114 ]\n",
      " [0.51166332]\n",
      " [0.52228874]\n",
      " [0.53465766]] | y: 0.6710577295621851 | Predicción actual: [[0.54832363]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006433194503188133, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.49469417]\n",
      " [0.49761564]\n",
      " [0.5033114 ]\n",
      " [0.51166332]\n",
      " [0.52228874]\n",
      " [0.53465766]\n",
      " [0.54832363]] | y: 0.6737698566447115 | Predicción actual: [[0.5628272]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021243596449494362, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49469417]\n",
      " [0.49761564]\n",
      " [0.5033114 ]\n",
      " [0.51166332]\n",
      " [0.52228874]\n",
      " [0.53465766]\n",
      " [0.54832363]\n",
      " [0.56282723]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06760015338659286, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49761564]\n",
      " [0.5033114 ]\n",
      " [0.51166332]\n",
      " [0.52228874]\n",
      " [0.53465766]\n",
      " [0.54832363]\n",
      " [0.56282723]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.53478336]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04404783621430397, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5033114 ]\n",
      " [0.51166332]\n",
      " [0.52228874]\n",
      " [0.53465766]\n",
      " [0.54832363]\n",
      " [0.56282723]\n",
      " [0.71445176]\n",
      " [0.53478336]] | y: 0.722588144130182 | Predicción actual: [[0.54525673]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0319058857858181, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51166332]\n",
      " [0.52228874]\n",
      " [0.53465766]\n",
      " [0.54832363]\n",
      " [0.56282723]\n",
      " [0.71445176]\n",
      " [0.53478336]\n",
      " [0.54525673]] | y: 0.6993413405656723 | Predicción actual: [[0.5577453]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024950118735432625, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52228874]\n",
      " [0.53465766]\n",
      " [0.54832363]\n",
      " [0.56282723]\n",
      " [0.71445176]\n",
      " [0.53478336]\n",
      " [0.54525673]\n",
      " [0.55774528]] | y: 0.7373111197210385 | Predicción actual: [[0.5712072]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006328320596367121, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53465766]\n",
      " [0.54832363]\n",
      " [0.56282723]\n",
      " [0.71445176]\n",
      " [0.53478336]\n",
      " [0.54525673]\n",
      " [0.55774528]\n",
      " [0.57120723]] | y: 0.7214258039519565 | Predicción actual: [[0.58443713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009391767904162407, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54832363]\n",
      " [0.56282723]\n",
      " [0.71445176]\n",
      " [0.53478336]\n",
      " [0.54525673]\n",
      " [0.55774528]\n",
      " [0.57120723]\n",
      " [0.58443713]] | y: 0.7187136768694304 | Predicción actual: [[0.5963378]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036999933421611786, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56282723]\n",
      " [0.71445176]\n",
      " [0.53478336]\n",
      " [0.54525673]\n",
      " [0.55774528]\n",
      " [0.57120723]\n",
      " [0.58443713]\n",
      " [0.5963378 ]] | y: 0.6741573033707864 | Predicción actual: [[0.6060007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000874743505846709, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.53478336]\n",
      " [0.54525673]\n",
      " [0.55774528]\n",
      " [0.57120723]\n",
      " [0.58443713]\n",
      " [0.5963378 ]\n",
      " [0.60600072]] | y: 0.698566447113522 | Predicción actual: [[0.61252433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015204746276140213, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53478336]\n",
      " [0.54525673]\n",
      " [0.55774528]\n",
      " [0.57120723]\n",
      " [0.58443713]\n",
      " [0.5963378 ]\n",
      " [0.60600072]\n",
      " [0.61252433]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026500778272747993, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54525673]\n",
      " [0.55774528]\n",
      " [0.57120723]\n",
      " [0.58443713]\n",
      " [0.5963378 ]\n",
      " [0.60600072]\n",
      " [0.61252433]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.5901194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023884767666459084, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55774528]\n",
      " [0.57120723]\n",
      " [0.58443713]\n",
      " [0.5963378 ]\n",
      " [0.60600072]\n",
      " [0.61252433]\n",
      " [0.72103836]\n",
      " [0.59011942]] | y: 0.7562960092987214 | Predicción actual: [[0.6028287]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024129483848810196, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57120723]\n",
      " [0.58443713]\n",
      " [0.5963378 ]\n",
      " [0.60600072]\n",
      " [0.61252433]\n",
      " [0.72103836]\n",
      " [0.59011942]\n",
      " [0.60282868]] | y: 0.8275862068965516 | Predicción actual: [[0.61561096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10528463870286942, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58443713]\n",
      " [0.5963378 ]\n",
      " [0.60600072]\n",
      " [0.61252433]\n",
      " [0.72103836]\n",
      " [0.59011942]\n",
      " [0.60282868]\n",
      " [0.61561096]] | y: 0.8388221619527314 | Predicción actual: [[0.6277199]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10158694535493851, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5963378 ]\n",
      " [0.60600072]\n",
      " [0.61252433]\n",
      " [0.72103836]\n",
      " [0.59011942]\n",
      " [0.60282868]\n",
      " [0.61561096]\n",
      " [0.62771988]] | y: 0.7942657884540876 | Predicción actual: [[0.63854015]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022116156294941902, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60600072]\n",
      " [0.61252433]\n",
      " [0.72103836]\n",
      " [0.59011942]\n",
      " [0.60282868]\n",
      " [0.61561096]\n",
      " [0.62771988]\n",
      " [0.63854015]] | y: 0.7838047268500579 | Predicción actual: [[0.6476954]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025447476655244827, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61252433]\n",
      " [0.72103836]\n",
      " [0.59011942]\n",
      " [0.60282868]\n",
      " [0.61561096]\n",
      " [0.62771988]\n",
      " [0.63854015]\n",
      " [0.64769542]] | y: 0.7679194110809764 | Predicción actual: [[0.65534306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022064846009016037, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.59011942]\n",
      " [0.60282868]\n",
      " [0.61561096]\n",
      " [0.62771988]\n",
      " [0.63854015]\n",
      " [0.64769542]\n",
      " [0.65534306]] | y: 0.7845796203022084 | Predicción actual: [[0.6620685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0049148136749863625, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59011942]\n",
      " [0.60282868]\n",
      " [0.61561096]\n",
      " [0.62771988]\n",
      " [0.63854015]\n",
      " [0.64769542]\n",
      " [0.65534306]\n",
      " [0.66206849]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04886825010180473, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60282868]\n",
      " [0.61561096]\n",
      " [0.62771988]\n",
      " [0.63854015]\n",
      " [0.64769542]\n",
      " [0.65534306]\n",
      " [0.66206849]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6520794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03749381750822067, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61561096]\n",
      " [0.62771988]\n",
      " [0.63854015]\n",
      " [0.64769542]\n",
      " [0.65534306]\n",
      " [0.66206849]\n",
      " [0.87872917]\n",
      " [0.6520794 ]] | y: 0.8488957768306855 | Predicción actual: [[0.666507]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05878176912665367, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62771988]\n",
      " [0.63854015]\n",
      " [0.64769542]\n",
      " [0.65534306]\n",
      " [0.66206849]\n",
      " [0.87872917]\n",
      " [0.6520794 ]\n",
      " [0.66650701]] | y: 0.8182874854707476 | Predicción actual: [[0.6819074]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024265816435217857, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63854015]\n",
      " [0.64769542]\n",
      " [0.65534306]\n",
      " [0.66206849]\n",
      " [0.87872917]\n",
      " [0.6520794 ]\n",
      " [0.66650701]\n",
      " [0.68190742]] | y: 0.8268113134444013 | Predicción actual: [[0.69785136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0062319994904100895, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64769542]\n",
      " [0.65534306]\n",
      " [0.66206849]\n",
      " [0.87872917]\n",
      " [0.6520794 ]\n",
      " [0.66650701]\n",
      " [0.68190742]\n",
      " [0.69785136]] | y: 0.7853545137543589 | Predicción actual: [[0.71397245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06487774103879929, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65534306]\n",
      " [0.66206849]\n",
      " [0.87872917]\n",
      " [0.6520794 ]\n",
      " [0.66650701]\n",
      " [0.68190742]\n",
      " [0.69785136]\n",
      " [0.71397245]] | y: 0.7892289810151103 | Predicción actual: [[0.7302643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06785596907138824, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66206849]\n",
      " [0.87872917]\n",
      " [0.6520794 ]\n",
      " [0.66650701]\n",
      " [0.68190742]\n",
      " [0.69785136]\n",
      " [0.71397245]\n",
      " [0.73026431]] | y: 0.8341728012398295 | Predicción actual: [[0.7466784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010412780568003654, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.6520794 ]\n",
      " [0.66650701]\n",
      " [0.68190742]\n",
      " [0.69785136]\n",
      " [0.71397245]\n",
      " [0.73026431]\n",
      " [0.74667841]] | y: 0.8124757845796202 | Predicción actual: [[0.7630206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.73021999723278e-05, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6520794 ]\n",
      " [0.66650701]\n",
      " [0.68190742]\n",
      " [0.69785136]\n",
      " [0.71397245]\n",
      " [0.73026431]\n",
      " [0.74667841]\n",
      " [0.76302058]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005138365551829338, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66650701]\n",
      " [0.68190742]\n",
      " [0.69785136]\n",
      " [0.71397245]\n",
      " [0.73026431]\n",
      " [0.74667841]\n",
      " [0.76302058]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7321481]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06354701519012451, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68190742]\n",
      " [0.69785136]\n",
      " [0.71397245]\n",
      " [0.73026431]\n",
      " [0.74667841]\n",
      " [0.76302058]\n",
      " [0.80123983]\n",
      " [0.73214811]] | y: 0.793490895001937 | Predicción actual: [[0.74886125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014750263653695583, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69785136]\n",
      " [0.71397245]\n",
      " [0.73026431]\n",
      " [0.74667841]\n",
      " [0.76302058]\n",
      " [0.80123983]\n",
      " [0.73214811]\n",
      " [0.74886125]] | y: 0.760170476559473 | Predicción actual: [[0.7647535]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023069342132657766, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71397245]\n",
      " [0.73026431]\n",
      " [0.74667841]\n",
      " [0.76302058]\n",
      " [0.80123983]\n",
      " [0.73214811]\n",
      " [0.74886125]\n",
      " [0.76475352]] | y: 0.7353738860906625 | Predicción actual: [[0.7793276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038117074873298407, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73026431]\n",
      " [0.74667841]\n",
      " [0.76302058]\n",
      " [0.80123983]\n",
      " [0.73214811]\n",
      " [0.74886125]\n",
      " [0.76475352]\n",
      " [0.77932757]] | y: 0.7101898488957767 | Predicción actual: [[0.7916939]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01940549910068512, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74667841]\n",
      " [0.76302058]\n",
      " [0.80123983]\n",
      " [0.73214811]\n",
      " [0.74886125]\n",
      " [0.76475352]\n",
      " [0.77932757]\n",
      " [0.79169393]] | y: 0.7121270825261525 | Predicción actual: [[0.8010621]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04126545786857605, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76302058]\n",
      " [0.80123983]\n",
      " [0.73214811]\n",
      " [0.74886125]\n",
      " [0.76475352]\n",
      " [0.77932757]\n",
      " [0.79169393]\n",
      " [0.80106211]] | y: 0.7396358000774894 | Predicción actual: [[0.8067969]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006875204853713512, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.73214811]\n",
      " [0.74886125]\n",
      " [0.76475352]\n",
      " [0.77932757]\n",
      " [0.79169393]\n",
      " [0.80106211]\n",
      " [0.80679691]] | y: 0.7361487795428128 | Predicción actual: [[0.80886745]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016675543040037155, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73214811]\n",
      " [0.74886125]\n",
      " [0.76475352]\n",
      " [0.77932757]\n",
      " [0.79169393]\n",
      " [0.80106211]\n",
      " [0.80679691]\n",
      " [0.80886745]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011813572607934475, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74886125]\n",
      " [0.76475352]\n",
      " [0.77932757]\n",
      " [0.79169393]\n",
      " [0.80106211]\n",
      " [0.80679691]\n",
      " [0.80886745]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.81244594]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03279101848602295, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76475352]\n",
      " [0.77932757]\n",
      " [0.79169393]\n",
      " [0.80106211]\n",
      " [0.80679691]\n",
      " [0.80886745]\n",
      " [0.66757071]\n",
      " [0.81244594]] | y: 0.696629213483146 | Predicción actual: [[0.82120204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01715940237045288, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77932757]\n",
      " [0.79169393]\n",
      " [0.80106211]\n",
      " [0.80679691]\n",
      " [0.80886745]\n",
      " [0.66757071]\n",
      " [0.81244594]\n",
      " [0.82120204]] | y: 0.6559473072452537 | Predicción actual: [[0.8261608]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001494981930591166, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79169393]\n",
      " [0.80106211]\n",
      " [0.80679691]\n",
      " [0.80886745]\n",
      " [0.66757071]\n",
      " [0.81244594]\n",
      " [0.82120204]\n",
      " [0.82616079]] | y: 0.6788066640836885 | Predicción actual: [[0.8274723]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008446495980024338, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80106211]\n",
      " [0.80679691]\n",
      " [0.80886745]\n",
      " [0.66757071]\n",
      " [0.81244594]\n",
      " [0.82120204]\n",
      " [0.82616079]\n",
      " [0.82747233]] | y: 0.6760945370011622 | Predicción actual: [[0.825553]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0606357604265213, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80679691]\n",
      " [0.80886745]\n",
      " [0.66757071]\n",
      " [0.81244594]\n",
      " [0.82120204]\n",
      " [0.82616079]\n",
      " [0.82747233]\n",
      " [0.825553  ]] | y: 0.7295621851995349 | Predicción actual: [[0.8210632]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005815143813379109, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80886745]\n",
      " [0.66757071]\n",
      " [0.81244594]\n",
      " [0.82120204]\n",
      " [0.82616079]\n",
      " [0.82747233]\n",
      " [0.825553  ]\n",
      " [0.82106322]] | y: 0.7012785741960481 | Predicción actual: [[0.81593776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012123051565140486, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.81244594]\n",
      " [0.82120204]\n",
      " [0.82616079]\n",
      " [0.82747233]\n",
      " [0.825553  ]\n",
      " [0.82106322]\n",
      " [0.81593776]] | y: 0.767531964354901 | Predicción actual: [[0.8115049]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04142368957400322, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81244594]\n",
      " [0.82120204]\n",
      " [0.82616079]\n",
      " [0.82747233]\n",
      " [0.825553  ]\n",
      " [0.82106322]\n",
      " [0.81593776]\n",
      " [0.8115049 ]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11630930751562119, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82120204]\n",
      " [0.82616079]\n",
      " [0.82747233]\n",
      " [0.825553  ]\n",
      " [0.82106322]\n",
      " [0.81593776]\n",
      " [0.8115049 ]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8520171]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017732981592416763, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82616079]\n",
      " [0.82747233]\n",
      " [0.825553  ]\n",
      " [0.82106322]\n",
      " [0.81593776]\n",
      " [0.8115049 ]\n",
      " [0.75513367]\n",
      " [0.8520171 ]] | y: 0.7520340953118947 | Predicción actual: [[0.849299]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011438618414103985, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82747233]\n",
      " [0.825553  ]\n",
      " [0.82106322]\n",
      " [0.81593776]\n",
      " [0.8115049 ]\n",
      " [0.75513367]\n",
      " [0.8520171 ]\n",
      " [0.84929901]] | y: 0.7098024021697016 | Predicción actual: [[0.8446789]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05449386313557625, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.825553  ]\n",
      " [0.82106322]\n",
      " [0.81593776]\n",
      " [0.8115049 ]\n",
      " [0.75513367]\n",
      " [0.8520171 ]\n",
      " [0.84929901]\n",
      " [0.84467888]] | y: 0.6904300658659435 | Predicción actual: [[0.83917433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038762150797992945, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82106322]\n",
      " [0.81593776]\n",
      " [0.8115049 ]\n",
      " [0.75513367]\n",
      " [0.8520171 ]\n",
      " [0.84929901]\n",
      " [0.84467888]\n",
      " [0.83917433]] | y: 0.7543587756683454 | Predicción actual: [[0.83454984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013373527908697724, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81593776]\n",
      " [0.8115049 ]\n",
      " [0.75513367]\n",
      " [0.8520171 ]\n",
      " [0.84929901]\n",
      " [0.84467888]\n",
      " [0.83917433]\n",
      " [0.83454984]] | y: 0.7222006974041069 | Predicción actual: [[0.83203804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.057688817381858826, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8115049 ]\n",
      " [0.75513367]\n",
      " [0.8520171 ]\n",
      " [0.84929901]\n",
      " [0.84467888]\n",
      " [0.83917433]\n",
      " [0.83454984]\n",
      " [0.83203804]] | y: 0.8485083301046106 | Predicción actual: [[0.83176416]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004253531340509653, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.8520171 ]\n",
      " [0.84929901]\n",
      " [0.84467888]\n",
      " [0.83917433]\n",
      " [0.83454984]\n",
      " [0.83203804]\n",
      " [0.83176416]] | y: 0.9054629988376597 | Predicción actual: [[0.8344307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010748287895694375, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8520171 ]\n",
      " [0.84929901]\n",
      " [0.84467888]\n",
      " [0.83917433]\n",
      " [0.83454984]\n",
      " [0.83203804]\n",
      " [0.83176416]\n",
      " [0.83443069]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0062476592138409615, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84929901]\n",
      " [0.84467888]\n",
      " [0.83917433]\n",
      " [0.83454984]\n",
      " [0.83203804]\n",
      " [0.83176416]\n",
      " [0.83443069]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.85060173]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018135884776711464, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84467888]\n",
      " [0.83917433]\n",
      " [0.83454984]\n",
      " [0.83203804]\n",
      " [0.83176416]\n",
      " [0.83443069]\n",
      " [0.8822162 ]\n",
      " [0.85060173]] | y: 0.889577683068578 | Predicción actual: [[0.8459804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038162317126989365, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83917433]\n",
      " [0.83454984]\n",
      " [0.83203804]\n",
      " [0.83176416]\n",
      " [0.83443069]\n",
      " [0.8822162 ]\n",
      " [0.85060173]\n",
      " [0.84598041]] | y: 0.8748547074777218 | Predicción actual: [[0.84332937]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010080992244184017, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83454984]\n",
      " [0.83203804]\n",
      " [0.83176416]\n",
      " [0.83443069]\n",
      " [0.8822162 ]\n",
      " [0.85060173]\n",
      " [0.84598041]\n",
      " [0.84332937]] | y: 0.9132119333591631 | Predicción actual: [[0.84262884]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.2371752947947243e-06, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83203804]\n",
      " [0.83176416]\n",
      " [0.83443069]\n",
      " [0.8822162 ]\n",
      " [0.85060173]\n",
      " [0.84598041]\n",
      " [0.84332937]\n",
      " [0.84262884]] | y: 1.0 | Predicción actual: [[0.8440476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02703401818871498, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83176416]\n",
      " [0.83443069]\n",
      " [0.8822162 ]\n",
      " [0.85060173]\n",
      " [0.84598041]\n",
      " [0.84332937]\n",
      " [0.84262884]\n",
      " [0.84404761]] | y: 0.9705540488182873 | Predicción actual: [[0.8473283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02973990887403488, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83443069]\n",
      " [0.8822162 ]\n",
      " [0.85060173]\n",
      " [0.84598041]\n",
      " [0.84332937]\n",
      " [0.84262884]\n",
      " [0.84404761]\n",
      " [0.84732831]] | y: 0.8888027896164277 | Predicción actual: [[0.8517064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023667681962251663, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.85060173]\n",
      " [0.84598041]\n",
      " [0.84332937]\n",
      " [0.84262884]\n",
      " [0.84404761]\n",
      " [0.84732831]\n",
      " [0.85170639]] | y: 0.877954281286323 | Predicción actual: [[0.8554463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022437209263443947, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85060173]\n",
      " [0.84598041]\n",
      " [0.84332937]\n",
      " [0.84262884]\n",
      " [0.84404761]\n",
      " [0.84732831]\n",
      " [0.85170639]\n",
      " [0.85544628]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00495693227276206, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84598041]\n",
      " [0.84332937]\n",
      " [0.84262884]\n",
      " [0.84404761]\n",
      " [0.84732831]\n",
      " [0.85170639]\n",
      " [0.85544628]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.84292144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001546726853121072, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84332937]\n",
      " [0.84262884]\n",
      " [0.84404761]\n",
      " [0.84732831]\n",
      " [0.85170639]\n",
      " [0.85544628]\n",
      " [0.84889578]\n",
      " [0.84292144]] | y: 0.8550949244478885 | Predicción actual: [[0.84226173]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011035796342184767, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84262884]\n",
      " [0.84404761]\n",
      " [0.84732831]\n",
      " [0.85170639]\n",
      " [0.85544628]\n",
      " [0.84889578]\n",
      " [0.84292144]\n",
      " [0.84226173]] | y: 0.8752421542037967 | Predicción actual: [[0.84259397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027939488063566387, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84404761]\n",
      " [0.84732831]\n",
      " [0.85170639]\n",
      " [0.85544628]\n",
      " [0.84889578]\n",
      " [0.84292144]\n",
      " [0.84226173]\n",
      " [0.84259397]] | y: 0.857032158078264 | Predicción actual: [[0.84339863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.657498746179044e-05, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84732831]\n",
      " [0.85170639]\n",
      " [0.85544628]\n",
      " [0.84889578]\n",
      " [0.84292144]\n",
      " [0.84226173]\n",
      " [0.84259397]\n",
      " [0.84339863]] | y: 0.8500581170089112 | Predicción actual: [[0.8439124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012170706177130342, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85170639]\n",
      " [0.85544628]\n",
      " [0.84889578]\n",
      " [0.84292144]\n",
      " [0.84226173]\n",
      " [0.84259397]\n",
      " [0.84339863]\n",
      " [0.84391242]] | y: 0.8426966292134832 | Predicción actual: [[0.84350306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.8738733312347904e-05, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85544628]\n",
      " [0.84889578]\n",
      " [0.84292144]\n",
      " [0.84226173]\n",
      " [0.84259397]\n",
      " [0.84339863]\n",
      " [0.84391242]\n",
      " [0.84350306]] | y: 0.8229368461836497 | Predicción actual: [[0.8415768]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007482258602976799, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.84292144]\n",
      " [0.84226173]\n",
      " [0.84259397]\n",
      " [0.84339863]\n",
      " [0.84391242]\n",
      " [0.84350306]\n",
      " [0.84157681]] | y: 0.7745060054242543 | Predicción actual: [[0.8379964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008156453841365874, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84292144]\n",
      " [0.84226173]\n",
      " [0.84259397]\n",
      " [0.84339863]\n",
      " [0.84391242]\n",
      " [0.84350306]\n",
      " [0.84157681]\n",
      " [0.83799642]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04967430233955383, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84226173]\n",
      " [0.84259397]\n",
      " [0.84339863]\n",
      " [0.84391242]\n",
      " [0.84350306]\n",
      " [0.84157681]\n",
      " [0.83799642]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8345784]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035886816680431366, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84259397]\n",
      " [0.84339863]\n",
      " [0.84391242]\n",
      " [0.84350306]\n",
      " [0.84157681]\n",
      " [0.83799642]\n",
      " [0.78419217]\n",
      " [0.83457839]] | y: 0.854320030995738 | Predicción actual: [[0.8331424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020525289699435234, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84339863]\n",
      " [0.84391242]\n",
      " [0.84350306]\n",
      " [0.84157681]\n",
      " [0.83799642]\n",
      " [0.78419217]\n",
      " [0.83457839]\n",
      " [0.8331424 ]] | y: 0.8368849283223556 | Predicción actual: [[0.83114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025708574801683426, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84391242]\n",
      " [0.84350306]\n",
      " [0.84157681]\n",
      " [0.83799642]\n",
      " [0.78419217]\n",
      " [0.83457839]\n",
      " [0.8331424 ]\n",
      " [0.83113998]] | y: 0.8299108872530028 | Predicción actual: [[0.82834417]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016781280282884836, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84350306]\n",
      " [0.84157681]\n",
      " [0.83799642]\n",
      " [0.78419217]\n",
      " [0.83457839]\n",
      " [0.8331424 ]\n",
      " [0.83113998]\n",
      " [0.82834417]] | y: 0.887253002712127 | Predicción actual: [[0.8246342]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011448233388364315, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84157681]\n",
      " [0.83799642]\n",
      " [0.78419217]\n",
      " [0.83457839]\n",
      " [0.8331424 ]\n",
      " [0.83113998]\n",
      " [0.82834417]\n",
      " [0.82463419]] | y: 0.8597442851607902 | Predicción actual: [[0.8204388]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002933847950771451, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83799642]\n",
      " [0.78419217]\n",
      " [0.83457839]\n",
      " [0.8331424 ]\n",
      " [0.83113998]\n",
      " [0.82834417]\n",
      " [0.82463419]\n",
      " [0.8204388 ]] | y: 0.8395970554048819 | Predicción actual: [[0.81619596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029408384580165148, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.83457839]\n",
      " [0.8331424 ]\n",
      " [0.83113998]\n",
      " [0.82834417]\n",
      " [0.82463419]\n",
      " [0.8204388 ]\n",
      " [0.81619596]] | y: 0.7838047268500579 | Predicción actual: [[0.81253177]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025391902774572372, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83457839]\n",
      " [0.8331424 ]\n",
      " [0.83113998]\n",
      " [0.82834417]\n",
      " [0.82463419]\n",
      " [0.8204388 ]\n",
      " [0.81619596]\n",
      " [0.81253177]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004938342142850161, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8331424 ]\n",
      " [0.83113998]\n",
      " [0.82834417]\n",
      " [0.82463419]\n",
      " [0.8204388 ]\n",
      " [0.81619596]\n",
      " [0.81253177]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.82174414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005251684924587607, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83113998]\n",
      " [0.82834417]\n",
      " [0.82463419]\n",
      " [0.8204388 ]\n",
      " [0.81619596]\n",
      " [0.81253177]\n",
      " [0.81828749]\n",
      " [0.82174414]] | y: 0.7605579232855482 | Predicción actual: [[0.81916976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.449013507226482e-05, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82834417]\n",
      " [0.82463419]\n",
      " [0.8204388 ]\n",
      " [0.81619596]\n",
      " [0.81253177]\n",
      " [0.81828749]\n",
      " [0.82174414]\n",
      " [0.81916976]] | y: 0.7915536613715615 | Predicción actual: [[0.81649977]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025449929758906364, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82463419]\n",
      " [0.8204388 ]\n",
      " [0.81619596]\n",
      " [0.81253177]\n",
      " [0.81828749]\n",
      " [0.82174414]\n",
      " [0.81916976]\n",
      " [0.81649977]] | y: 0.7686943045331267 | Predicción actual: [[0.8142998]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016062811017036438, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8204388 ]\n",
      " [0.81619596]\n",
      " [0.81253177]\n",
      " [0.81828749]\n",
      " [0.82174414]\n",
      " [0.81916976]\n",
      " [0.81649977]\n",
      " [0.81429982]] | y: 0.7686943045331267 | Predicción actual: [[0.81248677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002834992716088891, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81619596]\n",
      " [0.81253177]\n",
      " [0.81828749]\n",
      " [0.82174414]\n",
      " [0.81916976]\n",
      " [0.81649977]\n",
      " [0.81429982]\n",
      " [0.81248677]] | y: 0.7989151491669895 | Predicción actual: [[0.8116917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005188252544030547, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81253177]\n",
      " [0.81828749]\n",
      " [0.82174414]\n",
      " [0.81916976]\n",
      " [0.81649977]\n",
      " [0.81429982]\n",
      " [0.81248677]\n",
      " [0.8116917 ]] | y: 0.7900038744672608 | Predicción actual: [[0.81192]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.033886453835294e-05, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.82174414]\n",
      " [0.81916976]\n",
      " [0.81649977]\n",
      " [0.81429982]\n",
      " [0.81248677]\n",
      " [0.8116917 ]\n",
      " [0.81191999]] | y: 0.760170476559473 | Predicción actual: [[0.8131167]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027106705238111317, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82174414]\n",
      " [0.81916976]\n",
      " [0.81649977]\n",
      " [0.81429982]\n",
      " [0.81248677]\n",
      " [0.8116917 ]\n",
      " [0.81191999]\n",
      " [0.81311673]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00018859936972148716, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81916976]\n",
      " [0.81649977]\n",
      " [0.81429982]\n",
      " [0.81248677]\n",
      " [0.8116917 ]\n",
      " [0.81191999]\n",
      " [0.81311673]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.80994946]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008337313309311867, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81649977]\n",
      " [0.81429982]\n",
      " [0.81248677]\n",
      " [0.8116917 ]\n",
      " [0.81191999]\n",
      " [0.81311673]\n",
      " [0.68539326]\n",
      " [0.80994946]] | y: 0.6648585819449826 | Predicción actual: [[0.8063557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09852452576160431, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81429982]\n",
      " [0.81248677]\n",
      " [0.8116917 ]\n",
      " [0.81191999]\n",
      " [0.81311673]\n",
      " [0.68539326]\n",
      " [0.80994946]\n",
      " [0.80635571]] | y: 0.7078651685393258 | Predicción actual: [[0.80130917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08227750658988953, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81248677]\n",
      " [0.8116917 ]\n",
      " [0.81191999]\n",
      " [0.81311673]\n",
      " [0.68539326]\n",
      " [0.80994946]\n",
      " [0.80635571]\n",
      " [0.80130917]] | y: 0.6648585819449826 | Predicción actual: [[0.7949477]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012065881164744496, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8116917 ]\n",
      " [0.81191999]\n",
      " [0.81311673]\n",
      " [0.68539326]\n",
      " [0.80994946]\n",
      " [0.80635571]\n",
      " [0.80130917]\n",
      " [0.79494768]] | y: 0.7113521890740022 | Predicción actual: [[0.78798556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010502099990844727, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81191999]\n",
      " [0.81311673]\n",
      " [0.68539326]\n",
      " [0.80994946]\n",
      " [0.80635571]\n",
      " [0.80130917]\n",
      " [0.79494768]\n",
      " [0.78798556]] | y: 0.6772568771793879 | Predicción actual: [[0.7802558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021778667345643044, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81311673]\n",
      " [0.68539326]\n",
      " [0.80994946]\n",
      " [0.80635571]\n",
      " [0.80130917]\n",
      " [0.79494768]\n",
      " [0.78798556]\n",
      " [0.78025579]] | y: 0.7621077101898488 | Predicción actual: [[0.77162313]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016952831065282226, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.80994946]\n",
      " [0.80635571]\n",
      " [0.80130917]\n",
      " [0.79494768]\n",
      " [0.78798556]\n",
      " [0.78025579]\n",
      " [0.77162313]] | y: 0.8070515304145678 | Predicción actual: [[0.7622793]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017939865356311202, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80994946]\n",
      " [0.80635571]\n",
      " [0.80130917]\n",
      " [0.79494768]\n",
      " [0.78798556]\n",
      " [0.78025579]\n",
      " [0.77162313]\n",
      " [0.76227927]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009475247003138065, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80635571]\n",
      " [0.80130917]\n",
      " [0.79494768]\n",
      " [0.78798556]\n",
      " [0.78025579]\n",
      " [0.77162313]\n",
      " [0.76227927]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7837421]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.7212385500897653e-05, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80130917]\n",
      " [0.79494768]\n",
      " [0.78798556]\n",
      " [0.78025579]\n",
      " [0.77162313]\n",
      " [0.76227927]\n",
      " [0.81518791]\n",
      " [0.78374207]] | y: 0.9597055404881829 | Predicción actual: [[0.77818125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03525059297680855, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79494768]\n",
      " [0.78798556]\n",
      " [0.78025579]\n",
      " [0.77162313]\n",
      " [0.76227927]\n",
      " [0.81518791]\n",
      " [0.78374207]\n",
      " [0.77818125]] | y: 0.9643549012010848 | Predicción actual: [[0.7734963]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03142116591334343, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78798556]\n",
      " [0.78025579]\n",
      " [0.77162313]\n",
      " [0.76227927]\n",
      " [0.81518791]\n",
      " [0.78374207]\n",
      " [0.77818125]\n",
      " [0.77349633]] | y: 0.8880278961642774 | Predicción actual: [[0.770223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.1253001503064297e-05, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78025579]\n",
      " [0.77162313]\n",
      " [0.76227927]\n",
      " [0.81518791]\n",
      " [0.78374207]\n",
      " [0.77818125]\n",
      " [0.77349633]\n",
      " [0.77022302]] | y: 0.8926772568771792 | Predicción actual: [[0.7684283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03442894667387009, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77162313]\n",
      " [0.76227927]\n",
      " [0.81518791]\n",
      " [0.78374207]\n",
      " [0.77818125]\n",
      " [0.77349633]\n",
      " [0.77022302]\n",
      " [0.76842833]] | y: 0.8752421542037967 | Predicción actual: [[0.76876587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011955738300457597, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76227927]\n",
      " [0.81518791]\n",
      " [0.78374207]\n",
      " [0.77818125]\n",
      " [0.77349633]\n",
      " [0.77022302]\n",
      " [0.76842833]\n",
      " [0.76876587]] | y: 0.8508330104610615 | Predicción actual: [[0.7713975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003465699963271618, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78374207]\n",
      " [0.77818125]\n",
      " [0.77349633]\n",
      " [0.77022302]\n",
      " [0.76842833]\n",
      " [0.76876587]\n",
      " [0.77139747]] | y: 0.8488957768306855 | Predicción actual: [[0.7766793]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009469249285757542, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78374207]\n",
      " [0.77818125]\n",
      " [0.77349633]\n",
      " [0.77022302]\n",
      " [0.76842833]\n",
      " [0.76876587]\n",
      " [0.77139747]\n",
      " [0.77667928]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07144655287265778, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77818125]\n",
      " [0.77349633]\n",
      " [0.77022302]\n",
      " [0.76842833]\n",
      " [0.76876587]\n",
      " [0.77139747]\n",
      " [0.77667928]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7659536]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1569385528564453, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77349633]\n",
      " [0.77022302]\n",
      " [0.76842833]\n",
      " [0.76876587]\n",
      " [0.77139747]\n",
      " [0.77667928]\n",
      " [0.96241767]\n",
      " [0.7659536 ]] | y: 0.9407206509104997 | Predicción actual: [[0.7682525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0073569039814174175, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77022302]\n",
      " [0.76842833]\n",
      " [0.76876587]\n",
      " [0.77139747]\n",
      " [0.77667928]\n",
      " [0.96241767]\n",
      " [0.7659536 ]\n",
      " [0.76825249]] | y: 0.9724912824486633 | Predicción actual: [[0.7735195]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01572396606206894, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76842833]\n",
      " [0.76876587]\n",
      " [0.77139747]\n",
      " [0.77667928]\n",
      " [0.96241767]\n",
      " [0.7659536 ]\n",
      " [0.76825249]\n",
      " [0.77351952]] | y: 0.9969004261913985 | Predicción actual: [[0.7814629]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07107626646757126, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76876587]\n",
      " [0.77139747]\n",
      " [0.77667928]\n",
      " [0.96241767]\n",
      " [0.7659536 ]\n",
      " [0.76825249]\n",
      " [0.77351952]\n",
      " [0.78146291]] | y: 0.951181712514529 | Predicción actual: [[0.79163027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013541204854846, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77139747]\n",
      " [0.77667928]\n",
      " [0.96241767]\n",
      " [0.7659536 ]\n",
      " [0.76825249]\n",
      " [0.77351952]\n",
      " [0.78146291]\n",
      " [0.79163027]] | y: 0.8957768306857805 | Predicción actual: [[0.8028567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004673795192502439, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77667928]\n",
      " [0.96241767]\n",
      " [0.7659536 ]\n",
      " [0.76825249]\n",
      " [0.77351952]\n",
      " [0.78146291]\n",
      " [0.79163027]\n",
      " [0.80285668]] | y: 0.8814413018209997 | Predicción actual: [[0.813811]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007897280156612396, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.7659536 ]\n",
      " [0.76825249]\n",
      " [0.77351952]\n",
      " [0.78146291]\n",
      " [0.79163027]\n",
      " [0.80285668]\n",
      " [0.813811  ]] | y: 0.9170864006199149 | Predicción actual: [[0.823412]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.8588534658192657e-05, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7659536 ]\n",
      " [0.76825249]\n",
      " [0.77351952]\n",
      " [0.78146291]\n",
      " [0.79163027]\n",
      " [0.80285668]\n",
      " [0.813811  ]\n",
      " [0.823412  ]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014761500991880894, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76825249]\n",
      " [0.77351952]\n",
      " [0.78146291]\n",
      " [0.79163027]\n",
      " [0.80285668]\n",
      " [0.813811  ]\n",
      " [0.823412  ]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.78582066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043142613023519516, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77351952]\n",
      " [0.78146291]\n",
      " [0.79163027]\n",
      " [0.80285668]\n",
      " [0.813811  ]\n",
      " [0.823412  ]\n",
      " [0.91979853]\n",
      " [0.78582066]] | y: 0.9682293684618366 | Predicción actual: [[0.79610926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12514007091522217, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78146291]\n",
      " [0.79163027]\n",
      " [0.80285668]\n",
      " [0.813811  ]\n",
      " [0.823412  ]\n",
      " [0.91979853]\n",
      " [0.78582066]\n",
      " [0.79610926]] | y: 0.9577683068578069 | Predicción actual: [[0.8079415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00501741049811244, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.21135552]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032021038234233856, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21135552]] | y: 0.10422316931421921 | Predicción actual: [[0.19580449]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00755652179941535, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21135552]\n",
      " [0.19580449]] | y: 0.15420379697791559 | Predicción actual: [[0.20014377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022306228056550026, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21135552]\n",
      " [0.19580449]\n",
      " [0.20014377]] | y: 0.1557535838822161 | Predicción actual: [[0.21202984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002013539196923375, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21135552]\n",
      " [0.19580449]\n",
      " [0.20014377]\n",
      " [0.21202984]] | y: 0.12553273924835334 | Predicción actual: [[0.22526266]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01540260761976242, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21135552]\n",
      " [0.19580449]\n",
      " [0.20014377]\n",
      " [0.21202984]\n",
      " [0.22526266]] | y: 0.1456799690042619 | Predicción actual: [[0.23603511]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008642761036753654, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21135552]\n",
      " [0.19580449]\n",
      " [0.20014377]\n",
      " [0.21202984]\n",
      " [0.22526266]\n",
      " [0.23603511]] | y: 0.1464548624564122 | Predicción actual: [[0.25867903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020182151347398758, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.21135552]\n",
      " [0.19580449]\n",
      " [0.20014377]\n",
      " [0.21202984]\n",
      " [0.22526266]\n",
      " [0.23603511]\n",
      " [0.25867903]] | y: 0.1960480433940332 | Predicción actual: [[0.28665882]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006306625436991453, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21135552]\n",
      " [0.19580449]\n",
      " [0.20014377]\n",
      " [0.21202984]\n",
      " [0.22526266]\n",
      " [0.23603511]\n",
      " [0.25867903]\n",
      " [0.28665882]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036591750103980303, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19580449]\n",
      " [0.20014377]\n",
      " [0.21202984]\n",
      " [0.22526266]\n",
      " [0.23603511]\n",
      " [0.25867903]\n",
      " [0.28665882]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.32281554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02806105464696884, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20014377]\n",
      " [0.21202984]\n",
      " [0.22526266]\n",
      " [0.23603511]\n",
      " [0.25867903]\n",
      " [0.28665882]\n",
      " [0.2305308 ]\n",
      " [0.32281554]] | y: 0.211933359163115 | Predicción actual: [[0.33036396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009881467558443546, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21202984]\n",
      " [0.22526266]\n",
      " [0.23603511]\n",
      " [0.25867903]\n",
      " [0.28665882]\n",
      " [0.2305308 ]\n",
      " [0.32281554]\n",
      " [0.33036396]] | y: 0.2072839984502131 | Predicción actual: [[0.33985713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020663389936089516, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22526266]\n",
      " [0.23603511]\n",
      " [0.25867903]\n",
      " [0.28665882]\n",
      " [0.2305308 ]\n",
      " [0.32281554]\n",
      " [0.33036396]\n",
      " [0.33985713]] | y: 0.19294846958543205 | Predicción actual: [[0.35001042]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013809610158205032, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23603511]\n",
      " [0.25867903]\n",
      " [0.28665882]\n",
      " [0.2305308 ]\n",
      " [0.32281554]\n",
      " [0.33036396]\n",
      " [0.33985713]\n",
      " [0.35001042]] | y: 0.19682293684618352 | Predicción actual: [[0.360738]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03494890779256821, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25867903]\n",
      " [0.28665882]\n",
      " [0.2305308 ]\n",
      " [0.32281554]\n",
      " [0.33036396]\n",
      " [0.33985713]\n",
      " [0.35001042]\n",
      " [0.36073801]] | y: 0.21425803951956607 | Predicción actual: [[0.37270975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030781038105487823, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28665882]\n",
      " [0.2305308 ]\n",
      " [0.32281554]\n",
      " [0.33036396]\n",
      " [0.33985713]\n",
      " [0.35001042]\n",
      " [0.36073801]\n",
      " [0.37270975]] | y: 0.18132506780317698 | Predicción actual: [[0.38320422]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03533480316400528, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.32281554]\n",
      " [0.33036396]\n",
      " [0.33985713]\n",
      " [0.35001042]\n",
      " [0.36073801]\n",
      " [0.37270975]\n",
      " [0.38320422]] | y: 0.17512592018597434 | Predicción actual: [[0.39059058]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016788441687822342, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32281554]\n",
      " [0.33036396]\n",
      " [0.33985713]\n",
      " [0.35001042]\n",
      " [0.36073801]\n",
      " [0.37270975]\n",
      " [0.38320422]\n",
      " [0.39059058]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06506624072790146, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33036396]\n",
      " [0.33985713]\n",
      " [0.35001042]\n",
      " [0.36073801]\n",
      " [0.37270975]\n",
      " [0.38320422]\n",
      " [0.39059058]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.42051694]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05135191231966019, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33985713]\n",
      " [0.35001042]\n",
      " [0.36073801]\n",
      " [0.37270975]\n",
      " [0.38320422]\n",
      " [0.39059058]\n",
      " [0.14800465]\n",
      " [0.42051694]] | y: 0.19217357613328173 | Predicción actual: [[0.4246388]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042741287499666214, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35001042]\n",
      " [0.36073801]\n",
      " [0.37270975]\n",
      " [0.38320422]\n",
      " [0.39059058]\n",
      " [0.14800465]\n",
      " [0.42051694]\n",
      " [0.42463881]] | y: 0.1859744285160791 | Predicción actual: [[0.42689192]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061105627566576004, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36073801]\n",
      " [0.37270975]\n",
      " [0.38320422]\n",
      " [0.39059058]\n",
      " [0.14800465]\n",
      " [0.42051694]\n",
      " [0.42463881]\n",
      " [0.42689192]] | y: 0.26695079426578844 | Predicción actual: [[0.4273109]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034756045788526535, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37270975]\n",
      " [0.38320422]\n",
      " [0.39059058]\n",
      " [0.14800465]\n",
      " [0.42051694]\n",
      " [0.42463881]\n",
      " [0.42689192]\n",
      " [0.42731091]] | y: 0.2925222781867493 | Predicción actual: [[0.4261439]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013714645756408572, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38320422]\n",
      " [0.39059058]\n",
      " [0.14800465]\n",
      " [0.42051694]\n",
      " [0.42463881]\n",
      " [0.42689192]\n",
      " [0.42731091]\n",
      " [0.42614391]] | y: 0.3177063153816349 | Predicción actual: [[0.42355436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.140655361581594e-05, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39059058]\n",
      " [0.14800465]\n",
      " [0.42051694]\n",
      " [0.42463881]\n",
      " [0.42689192]\n",
      " [0.42731091]\n",
      " [0.42614391]\n",
      " [0.42355436]] | y: 0.31266950794265785 | Predicción actual: [[0.42021206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014450207818299532, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.42051694]\n",
      " [0.42463881]\n",
      " [0.42689192]\n",
      " [0.42731091]\n",
      " [0.42614391]\n",
      " [0.42355436]\n",
      " [0.42021206]] | y: 0.2890352576520729 | Predicción actual: [[0.4170971]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03021242469549179, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42051694]\n",
      " [0.42463881]\n",
      " [0.42689192]\n",
      " [0.42731091]\n",
      " [0.42614391]\n",
      " [0.42355436]\n",
      " [0.42021206]\n",
      " [0.41709709]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00798362772911787, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42463881]\n",
      " [0.42689192]\n",
      " [0.42731091]\n",
      " [0.42614391]\n",
      " [0.42355436]\n",
      " [0.42021206]\n",
      " [0.41709709]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.47629645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048210807144641876, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42689192]\n",
      " [0.42731091]\n",
      " [0.42614391]\n",
      " [0.42355436]\n",
      " [0.42021206]\n",
      " [0.41709709]\n",
      " [0.28283611]\n",
      " [0.47629645]] | y: 0.2758620689655173 | Predicción actual: [[0.47388077]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020891090855002403, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42731091]\n",
      " [0.42614391]\n",
      " [0.42355436]\n",
      " [0.42021206]\n",
      " [0.41709709]\n",
      " [0.28283611]\n",
      " [0.47629645]\n",
      " [0.47388077]] | y: 0.2746997287872917 | Predicción actual: [[0.47027513]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034946367144584656, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42614391]\n",
      " [0.42355436]\n",
      " [0.42021206]\n",
      " [0.41709709]\n",
      " [0.28283611]\n",
      " [0.47629645]\n",
      " [0.47388077]\n",
      " [0.47027513]] | y: 0.275474622239442 | Predicción actual: [[0.46641317]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04312530905008316, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42355436]\n",
      " [0.42021206]\n",
      " [0.41709709]\n",
      " [0.28283611]\n",
      " [0.47629645]\n",
      " [0.47388077]\n",
      " [0.47027513]\n",
      " [0.46641317]] | y: 0.3347539713289423 | Predicción actual: [[0.46330717]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016292687505483627, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42021206]\n",
      " [0.41709709]\n",
      " [0.28283611]\n",
      " [0.47629645]\n",
      " [0.47388077]\n",
      " [0.47027513]\n",
      " [0.46641317]\n",
      " [0.46330717]] | y: 0.35567609453700116 | Predicción actual: [[0.46198857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004665632266551256, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41709709]\n",
      " [0.28283611]\n",
      " [0.47629645]\n",
      " [0.47388077]\n",
      " [0.47027513]\n",
      " [0.46641317]\n",
      " [0.46330717]\n",
      " [0.46198857]] | y: 0.3366912049593181 | Predicción actual: [[0.46321476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009332607500255108, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.47629645]\n",
      " [0.47388077]\n",
      " [0.47027513]\n",
      " [0.46641317]\n",
      " [0.46330717]\n",
      " [0.46198857]\n",
      " [0.46321476]] | y: 0.3335916311507167 | Predicción actual: [[0.4673099]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030435893684625626, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47629645]\n",
      " [0.47388077]\n",
      " [0.47027513]\n",
      " [0.46641317]\n",
      " [0.46330717]\n",
      " [0.46198857]\n",
      " [0.46321476]\n",
      " [0.46730989]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007437753025442362, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47388077]\n",
      " [0.47027513]\n",
      " [0.46641317]\n",
      " [0.46330717]\n",
      " [0.46198857]\n",
      " [0.46321476]\n",
      " [0.46730989]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5046448]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034944836515933275, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47027513]\n",
      " [0.46641317]\n",
      " [0.46330717]\n",
      " [0.46198857]\n",
      " [0.46321476]\n",
      " [0.46730989]\n",
      " [0.3847346 ]\n",
      " [0.50464481]] | y: 0.5962805114296785 | Predicción actual: [[0.5011713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001081094960682094, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46641317]\n",
      " [0.46330717]\n",
      " [0.46198857]\n",
      " [0.46321476]\n",
      " [0.46730989]\n",
      " [0.3847346 ]\n",
      " [0.50464481]\n",
      " [0.50117129]] | y: 0.574583494769469 | Predicción actual: [[0.4982459]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002311522839590907, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46330717]\n",
      " [0.46198857]\n",
      " [0.46321476]\n",
      " [0.46730989]\n",
      " [0.3847346 ]\n",
      " [0.50464481]\n",
      " [0.50117129]\n",
      " [0.49824589]] | y: 0.6063541263076326 | Predicción actual: [[0.49645692]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015739162918180227, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46198857]\n",
      " [0.46321476]\n",
      " [0.46730989]\n",
      " [0.3847346 ]\n",
      " [0.50464481]\n",
      " [0.50117129]\n",
      " [0.49824589]\n",
      " [0.49645692]] | y: 0.5846571096474236 | Predicción actual: [[0.4961337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011378016322851181, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46321476]\n",
      " [0.46730989]\n",
      " [0.3847346 ]\n",
      " [0.50464481]\n",
      " [0.50117129]\n",
      " [0.49824589]\n",
      " [0.49645692]\n",
      " [0.49613369]] | y: 0.5687717938783416 | Predicción actual: [[0.49730614]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009681920520961285, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46730989]\n",
      " [0.3847346 ]\n",
      " [0.50464481]\n",
      " [0.50117129]\n",
      " [0.49824589]\n",
      " [0.49645692]\n",
      " [0.49613369]\n",
      " [0.49730614]] | y: 0.6427741185586981 | Predicción actual: [[0.49962273]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027618322521448135, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.50464481]\n",
      " [0.50117129]\n",
      " [0.49824589]\n",
      " [0.49645692]\n",
      " [0.49613369]\n",
      " [0.49730614]\n",
      " [0.49962273]] | y: 0.6617590081363811 | Predicción actual: [[0.5025399]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01342606358230114, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50464481]\n",
      " [0.50117129]\n",
      " [0.49824589]\n",
      " [0.49645692]\n",
      " [0.49613369]\n",
      " [0.49730614]\n",
      " [0.49962273]\n",
      " [0.50253987]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004109088331460953, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50117129]\n",
      " [0.49824589]\n",
      " [0.49645692]\n",
      " [0.49613369]\n",
      " [0.49730614]\n",
      " [0.49962273]\n",
      " [0.50253987]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5281548]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03072752058506012, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49824589]\n",
      " [0.49645692]\n",
      " [0.49613369]\n",
      " [0.49730614]\n",
      " [0.49962273]\n",
      " [0.50253987]\n",
      " [0.67299496]\n",
      " [0.52815479]] | y: 0.703990701278574 | Predicción actual: [[0.53030837]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034865789115428925, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49645692]\n",
      " [0.49613369]\n",
      " [0.49730614]\n",
      " [0.49962273]\n",
      " [0.50253987]\n",
      " [0.67299496]\n",
      " [0.52815479]\n",
      " [0.53030837]] | y: 0.7272375048430839 | Predicción actual: [[0.53528297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0729735866189003, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49613369]\n",
      " [0.49730614]\n",
      " [0.49962273]\n",
      " [0.50253987]\n",
      " [0.67299496]\n",
      " [0.52815479]\n",
      " [0.53030837]\n",
      " [0.53528297]] | y: 0.722588144130182 | Predicción actual: [[0.5430684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02144000306725502, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49730614]\n",
      " [0.49962273]\n",
      " [0.50253987]\n",
      " [0.67299496]\n",
      " [0.52815479]\n",
      " [0.53030837]\n",
      " [0.53528297]\n",
      " [0.54306841]] | y: 0.771793878341728 | Predicción actual: [[0.55327344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012402180582284927, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49962273]\n",
      " [0.50253987]\n",
      " [0.67299496]\n",
      " [0.52815479]\n",
      " [0.53030837]\n",
      " [0.53528297]\n",
      " [0.54306841]\n",
      " [0.55327344]] | y: 0.7245253777605578 | Predicción actual: [[0.5654111]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007914431393146515, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50253987]\n",
      " [0.67299496]\n",
      " [0.52815479]\n",
      " [0.53030837]\n",
      " [0.53528297]\n",
      " [0.54306841]\n",
      " [0.55327344]\n",
      " [0.56541109]] | y: 0.6710577295621851 | Predicción actual: [[0.57900405]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0072862873785197735, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.52815479]\n",
      " [0.53030837]\n",
      " [0.53528297]\n",
      " [0.54306841]\n",
      " [0.55327344]\n",
      " [0.56541109]\n",
      " [0.57900405]] | y: 0.6737698566447115 | Predicción actual: [[0.59372944]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016142682579811662, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52815479]\n",
      " [0.53030837]\n",
      " [0.53528297]\n",
      " [0.54306841]\n",
      " [0.55327344]\n",
      " [0.56541109]\n",
      " [0.57900405]\n",
      " [0.59372944]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.053385693579912186, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53030837]\n",
      " [0.53528297]\n",
      " [0.54306841]\n",
      " [0.55327344]\n",
      " [0.56541109]\n",
      " [0.57900405]\n",
      " [0.59372944]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.57097054]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01811142824590206, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53528297]\n",
      " [0.54306841]\n",
      " [0.55327344]\n",
      " [0.56541109]\n",
      " [0.57900405]\n",
      " [0.59372944]\n",
      " [0.71445176]\n",
      " [0.57097054]] | y: 0.722588144130182 | Predicción actual: [[0.5807338]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017937874421477318, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54306841]\n",
      " [0.55327344]\n",
      " [0.56541109]\n",
      " [0.57900405]\n",
      " [0.59372944]\n",
      " [0.71445176]\n",
      " [0.57097054]\n",
      " [0.58073378]] | y: 0.6993413405656723 | Predicción actual: [[0.59248585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008987649343907833, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55327344]\n",
      " [0.56541109]\n",
      " [0.57900405]\n",
      " [0.59372944]\n",
      " [0.71445176]\n",
      " [0.57097054]\n",
      " [0.58073378]\n",
      " [0.59248585]] | y: 0.7373111197210385 | Predicción actual: [[0.6051895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01826929673552513, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56541109]\n",
      " [0.57900405]\n",
      " [0.59372944]\n",
      " [0.71445176]\n",
      " [0.57097054]\n",
      " [0.58073378]\n",
      " [0.59248585]\n",
      " [0.6051895 ]] | y: 0.7214258039519565 | Predicción actual: [[0.61776185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020481539831962436, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57900405]\n",
      " [0.59372944]\n",
      " [0.71445176]\n",
      " [0.57097054]\n",
      " [0.58073378]\n",
      " [0.59248585]\n",
      " [0.6051895 ]\n",
      " [0.61776185]] | y: 0.7187136768694304 | Predicción actual: [[0.62899435]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01098213717341423, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59372944]\n",
      " [0.71445176]\n",
      " [0.57097054]\n",
      " [0.58073378]\n",
      " [0.59248585]\n",
      " [0.6051895 ]\n",
      " [0.61776185]\n",
      " [0.62899435]] | y: 0.6741573033707864 | Predicción actual: [[0.6380214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007958749309182167, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.57097054]\n",
      " [0.58073378]\n",
      " [0.59248585]\n",
      " [0.6051895 ]\n",
      " [0.61776185]\n",
      " [0.62899435]\n",
      " [0.63802141]] | y: 0.698566447113522 | Predicción actual: [[0.6440155]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014379849890246987, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57097054]\n",
      " [0.58073378]\n",
      " [0.59248585]\n",
      " [0.6051895 ]\n",
      " [0.61776185]\n",
      " [0.62899435]\n",
      " [0.63802141]\n",
      " [0.64401549]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05459000915288925, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58073378]\n",
      " [0.59248585]\n",
      " [0.6051895 ]\n",
      " [0.61776185]\n",
      " [0.62899435]\n",
      " [0.63802141]\n",
      " [0.64401549]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6279836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013428757898509502, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59248585]\n",
      " [0.6051895 ]\n",
      " [0.61776185]\n",
      " [0.62899435]\n",
      " [0.63802141]\n",
      " [0.64401549]\n",
      " [0.72103836]\n",
      " [0.62798363]] | y: 0.7562960092987214 | Predicción actual: [[0.63984764]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009738747030496597, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6051895 ]\n",
      " [0.61776185]\n",
      " [0.62899435]\n",
      " [0.63802141]\n",
      " [0.64401549]\n",
      " [0.72103836]\n",
      " [0.62798363]\n",
      " [0.63984764]] | y: 0.8275862068965516 | Predicción actual: [[0.65143174]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03246685490012169, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61776185]\n",
      " [0.62899435]\n",
      " [0.63802141]\n",
      " [0.64401549]\n",
      " [0.72103836]\n",
      " [0.62798363]\n",
      " [0.63984764]\n",
      " [0.65143174]] | y: 0.8388221619527314 | Predicción actual: [[0.6622162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017606180161237717, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62899435]\n",
      " [0.63802141]\n",
      " [0.64401549]\n",
      " [0.72103836]\n",
      " [0.62798363]\n",
      " [0.63984764]\n",
      " [0.65143174]\n",
      " [0.66221619]] | y: 0.7942657884540876 | Predicción actual: [[0.67162955]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021382838021963835, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63802141]\n",
      " [0.64401549]\n",
      " [0.72103836]\n",
      " [0.62798363]\n",
      " [0.63984764]\n",
      " [0.65143174]\n",
      " [0.66221619]\n",
      " [0.67162955]] | y: 0.7838047268500579 | Predicción actual: [[0.6792957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002824630821123719, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64401549]\n",
      " [0.72103836]\n",
      " [0.62798363]\n",
      " [0.63984764]\n",
      " [0.65143174]\n",
      " [0.66221619]\n",
      " [0.67162955]\n",
      " [0.67929572]] | y: 0.7679194110809764 | Predicción actual: [[0.68561876]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 8.583767339587212e-06, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62798363]\n",
      " [0.63984764]\n",
      " [0.65143174]\n",
      " [0.66221619]\n",
      " [0.67162955]\n",
      " [0.67929572]\n",
      " [0.68561876]] | y: 0.7845796203022084 | Predicción actual: [[0.6911935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.2121050733403536e-06, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62798363]\n",
      " [0.63984764]\n",
      " [0.65143174]\n",
      " [0.66221619]\n",
      " [0.67162955]\n",
      " [0.67929572]\n",
      " [0.68561876]\n",
      " [0.69119352]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018058717250823975, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63984764]\n",
      " [0.65143174]\n",
      " [0.66221619]\n",
      " [0.67162955]\n",
      " [0.67929572]\n",
      " [0.68561876]\n",
      " [0.69119352]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.68689317]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002647680463269353, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65143174]\n",
      " [0.66221619]\n",
      " [0.67162955]\n",
      " [0.67929572]\n",
      " [0.68561876]\n",
      " [0.69119352]\n",
      " [0.87872917]\n",
      " [0.68689317]] | y: 0.8488957768306855 | Predicción actual: [[0.6991469]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002696967450901866, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66221619]\n",
      " [0.67162955]\n",
      " [0.67929572]\n",
      " [0.68561876]\n",
      " [0.69119352]\n",
      " [0.87872917]\n",
      " [0.68689317]\n",
      " [0.69914693]] | y: 0.8182874854707476 | Predicción actual: [[0.7120499]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03133821487426758, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67162955]\n",
      " [0.67929572]\n",
      " [0.68561876]\n",
      " [0.69119352]\n",
      " [0.87872917]\n",
      " [0.68689317]\n",
      " [0.69914693]\n",
      " [0.7120499 ]] | y: 0.8268113134444013 | Predicción actual: [[0.7255114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052646175026893616, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67929572]\n",
      " [0.68561876]\n",
      " [0.69119352]\n",
      " [0.87872917]\n",
      " [0.68689317]\n",
      " [0.69914693]\n",
      " [0.7120499 ]\n",
      " [0.72551137]] | y: 0.7853545137543589 | Predicción actual: [[0.7394204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005494281649589539, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68561876]\n",
      " [0.69119352]\n",
      " [0.87872917]\n",
      " [0.68689317]\n",
      " [0.69914693]\n",
      " [0.7120499 ]\n",
      " [0.72551137]\n",
      " [0.73942041]] | y: 0.7892289810151103 | Predicción actual: [[0.7535085]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025958405807614326, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69119352]\n",
      " [0.87872917]\n",
      " [0.68689317]\n",
      " [0.69914693]\n",
      " [0.7120499 ]\n",
      " [0.72551137]\n",
      " [0.73942041]\n",
      " [0.75350851]] | y: 0.8341728012398295 | Predicción actual: [[0.7674005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015658678021281958, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.68689317]\n",
      " [0.69914693]\n",
      " [0.7120499 ]\n",
      " [0.72551137]\n",
      " [0.73942041]\n",
      " [0.75350851]\n",
      " [0.7674005 ]] | y: 0.8124757845796202 | Predicción actual: [[0.78142565]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000841175380628556, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68689317]\n",
      " [0.69914693]\n",
      " [0.7120499 ]\n",
      " [0.72551137]\n",
      " [0.73942041]\n",
      " [0.75350851]\n",
      " [0.7674005 ]\n",
      " [0.78142565]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008923380635678768, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69914693]\n",
      " [0.7120499 ]\n",
      " [0.72551137]\n",
      " [0.73942041]\n",
      " [0.75350851]\n",
      " [0.7674005 ]\n",
      " [0.78142565]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7535727]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03669819235801697, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7120499 ]\n",
      " [0.72551137]\n",
      " [0.73942041]\n",
      " [0.75350851]\n",
      " [0.7674005 ]\n",
      " [0.78142565]\n",
      " [0.80123983]\n",
      " [0.7535727 ]] | y: 0.793490895001937 | Predicción actual: [[0.76700294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019276350503787398, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72551137]\n",
      " [0.73942041]\n",
      " [0.75350851]\n",
      " [0.7674005 ]\n",
      " [0.78142565]\n",
      " [0.80123983]\n",
      " [0.7535727 ]\n",
      " [0.76700294]] | y: 0.760170476559473 | Predicción actual: [[0.7799131]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026398226618766785, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73942041]\n",
      " [0.75350851]\n",
      " [0.7674005 ]\n",
      " [0.78142565]\n",
      " [0.80123983]\n",
      " [0.7535727 ]\n",
      " [0.76700294]\n",
      " [0.77991313]] | y: 0.7353738860906625 | Predicción actual: [[0.79142845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002868201700039208, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75350851]\n",
      " [0.7674005 ]\n",
      " [0.78142565]\n",
      " [0.80123983]\n",
      " [0.7535727 ]\n",
      " [0.76700294]\n",
      " [0.77991313]\n",
      " [0.79142845]] | y: 0.7101898488957767 | Predicción actual: [[0.8009152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028257016092538834, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7674005 ]\n",
      " [0.78142565]\n",
      " [0.80123983]\n",
      " [0.7535727 ]\n",
      " [0.76700294]\n",
      " [0.77991313]\n",
      " [0.79142845]\n",
      " [0.80091518]] | y: 0.7121270825261525 | Predicción actual: [[0.8077513]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00014354604354593903, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78142565]\n",
      " [0.80123983]\n",
      " [0.7535727 ]\n",
      " [0.76700294]\n",
      " [0.77991313]\n",
      " [0.79142845]\n",
      " [0.80091518]\n",
      " [0.8077513 ]] | y: 0.7396358000774894 | Predicción actual: [[0.8117041]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020992374047636986, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.7535727 ]\n",
      " [0.76700294]\n",
      " [0.77991313]\n",
      " [0.79142845]\n",
      " [0.80091518]\n",
      " [0.8077513 ]\n",
      " [0.8117041 ]] | y: 0.7361487795428128 | Predicción actual: [[0.8123588]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017531017074361444, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7535727 ]\n",
      " [0.76700294]\n",
      " [0.77991313]\n",
      " [0.79142845]\n",
      " [0.80091518]\n",
      " [0.8077513 ]\n",
      " [0.8117041 ]\n",
      " [0.8123588 ]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004958317149430513, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76700294]\n",
      " [0.77991313]\n",
      " [0.79142845]\n",
      " [0.80091518]\n",
      " [0.8077513 ]\n",
      " [0.8117041 ]\n",
      " [0.8123588 ]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.81774056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007938800379633904, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77991313]\n",
      " [0.79142845]\n",
      " [0.80091518]\n",
      " [0.8077513 ]\n",
      " [0.8117041 ]\n",
      " [0.8123588 ]\n",
      " [0.66757071]\n",
      " [0.81774056]] | y: 0.696629213483146 | Predicción actual: [[0.82450193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018866283353418112, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79142845]\n",
      " [0.80091518]\n",
      " [0.8077513 ]\n",
      " [0.8117041 ]\n",
      " [0.8123588 ]\n",
      " [0.66757071]\n",
      " [0.81774056]\n",
      " [0.82450193]] | y: 0.6559473072452537 | Predicción actual: [[0.8278343]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02651558816432953, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80091518]\n",
      " [0.8077513 ]\n",
      " [0.8117041 ]\n",
      " [0.8123588 ]\n",
      " [0.66757071]\n",
      " [0.81774056]\n",
      " [0.82450193]\n",
      " [0.82783431]] | y: 0.6788066640836885 | Predicción actual: [[0.8276235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03041859343647957, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8077513 ]\n",
      " [0.8117041 ]\n",
      " [0.8123588 ]\n",
      " [0.66757071]\n",
      " [0.81774056]\n",
      " [0.82450193]\n",
      " [0.82783431]\n",
      " [0.82762349]] | y: 0.6760945370011622 | Predicción actual: [[0.82443017]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05879818648099899, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8117041 ]\n",
      " [0.8123588 ]\n",
      " [0.66757071]\n",
      " [0.81774056]\n",
      " [0.82450193]\n",
      " [0.82783431]\n",
      " [0.82762349]\n",
      " [0.82443017]] | y: 0.7295621851995349 | Predicción actual: [[0.81911904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023160463199019432, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8123588 ]\n",
      " [0.66757071]\n",
      " [0.81774056]\n",
      " [0.82450193]\n",
      " [0.82783431]\n",
      " [0.82762349]\n",
      " [0.82443017]\n",
      " [0.81911904]] | y: 0.7012785741960481 | Predicción actual: [[0.8131261]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017902959138154984, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.81774056]\n",
      " [0.82450193]\n",
      " [0.82783431]\n",
      " [0.82762349]\n",
      " [0.82443017]\n",
      " [0.81911904]\n",
      " [0.81312609]] | y: 0.767531964354901 | Predicción actual: [[0.8078637]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029978067614138126, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81774056]\n",
      " [0.82450193]\n",
      " [0.82783431]\n",
      " [0.82762349]\n",
      " [0.82443017]\n",
      " [0.81911904]\n",
      " [0.81312609]\n",
      " [0.80786371]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016494444571435452, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82450193]\n",
      " [0.82783431]\n",
      " [0.82762349]\n",
      " [0.82443017]\n",
      " [0.81911904]\n",
      " [0.81312609]\n",
      " [0.80786371]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8479004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02222064696252346, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82783431]\n",
      " [0.82762349]\n",
      " [0.82443017]\n",
      " [0.81911904]\n",
      " [0.81312609]\n",
      " [0.80786371]\n",
      " [0.75513367]\n",
      " [0.84790039]] | y: 0.7520340953118947 | Predicción actual: [[0.84467554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03957631066441536, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82762349]\n",
      " [0.82443017]\n",
      " [0.81911904]\n",
      " [0.81312609]\n",
      " [0.80786371]\n",
      " [0.75513367]\n",
      " [0.84790039]\n",
      " [0.84467554]] | y: 0.7098024021697016 | Predicción actual: [[0.8394969]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10826782882213593, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82443017]\n",
      " [0.81911904]\n",
      " [0.81312609]\n",
      " [0.80786371]\n",
      " [0.75513367]\n",
      " [0.84790039]\n",
      " [0.84467554]\n",
      " [0.83949691]] | y: 0.6904300658659435 | Predicción actual: [[0.8333698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09419486671686172, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81911904]\n",
      " [0.81312609]\n",
      " [0.80786371]\n",
      " [0.75513367]\n",
      " [0.84790039]\n",
      " [0.84467554]\n",
      " [0.83949691]\n",
      " [0.83336979]] | y: 0.7543587756683454 | Predicción actual: [[0.82776403]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004730254411697388, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81312609]\n",
      " [0.80786371]\n",
      " [0.75513367]\n",
      " [0.84790039]\n",
      " [0.84467554]\n",
      " [0.83949691]\n",
      " [0.83336979]\n",
      " [0.82776403]] | y: 0.7222006974041069 | Predicción actual: [[0.82435393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022385001182556152, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80786371]\n",
      " [0.75513367]\n",
      " [0.84790039]\n",
      " [0.84467554]\n",
      " [0.83949691]\n",
      " [0.83336979]\n",
      " [0.82776403]\n",
      " [0.82435393]] | y: 0.8485083301046106 | Predicción actual: [[0.8235466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018996572121977806, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.84790039]\n",
      " [0.84467554]\n",
      " [0.83949691]\n",
      " [0.83336979]\n",
      " [0.82776403]\n",
      " [0.82435393]\n",
      " [0.82354659]] | y: 0.9054629988376597 | Predicción actual: [[0.82586807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008644498884677887, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84790039]\n",
      " [0.84467554]\n",
      " [0.83949691]\n",
      " [0.83336979]\n",
      " [0.82776403]\n",
      " [0.82435393]\n",
      " [0.82354659]\n",
      " [0.82586807]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019865969195961952, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84467554]\n",
      " [0.83949691]\n",
      " [0.83336979]\n",
      " [0.82776403]\n",
      " [0.82435393]\n",
      " [0.82354659]\n",
      " [0.82586807]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8405779]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005619697738438845, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83949691]\n",
      " [0.83336979]\n",
      " [0.82776403]\n",
      " [0.82435393]\n",
      " [0.82354659]\n",
      " [0.82586807]\n",
      " [0.8822162 ]\n",
      " [0.8405779 ]] | y: 0.889577683068578 | Predicción actual: [[0.8361034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.533073484300985e-06, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83336979]\n",
      " [0.82776403]\n",
      " [0.82435393]\n",
      " [0.82354659]\n",
      " [0.82586807]\n",
      " [0.8822162 ]\n",
      " [0.8405779 ]\n",
      " [0.83610338]] | y: 0.8748547074777218 | Predicción actual: [[0.8332822]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012382302666082978, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82776403]\n",
      " [0.82435393]\n",
      " [0.82354659]\n",
      " [0.82586807]\n",
      " [0.8822162 ]\n",
      " [0.8405779 ]\n",
      " [0.83610338]\n",
      " [0.83328217]] | y: 0.9132119333591631 | Predicción actual: [[0.8327425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0045565953478217125, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82435393]\n",
      " [0.82354659]\n",
      " [0.82586807]\n",
      " [0.8822162 ]\n",
      " [0.8405779 ]\n",
      " [0.83610338]\n",
      " [0.83328217]\n",
      " [0.83274251]] | y: 1.0 | Predicción actual: [[0.8343139]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007741283159703016, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82354659]\n",
      " [0.82586807]\n",
      " [0.8822162 ]\n",
      " [0.8405779 ]\n",
      " [0.83610338]\n",
      " [0.83328217]\n",
      " [0.83274251]\n",
      " [0.83431393]] | y: 0.9705540488182873 | Predicción actual: [[0.8377617]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01565248891711235, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82586807]\n",
      " [0.8822162 ]\n",
      " [0.8405779 ]\n",
      " [0.83610338]\n",
      " [0.83328217]\n",
      " [0.83274251]\n",
      " [0.83431393]\n",
      " [0.8377617 ]] | y: 0.8888027896164277 | Predicción actual: [[0.8422945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014795846305787563, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.8405779 ]\n",
      " [0.83610338]\n",
      " [0.83328217]\n",
      " [0.83274251]\n",
      " [0.83431393]\n",
      " [0.8377617 ]\n",
      " [0.84229451]] | y: 0.877954281286323 | Predicción actual: [[0.846766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007617956725880504, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8405779 ]\n",
      " [0.83610338]\n",
      " [0.83328217]\n",
      " [0.83274251]\n",
      " [0.83431393]\n",
      " [0.8377617 ]\n",
      " [0.84229451]\n",
      " [0.846766  ]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002557103056460619, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83610338]\n",
      " [0.83328217]\n",
      " [0.83274251]\n",
      " [0.83431393]\n",
      " [0.8377617 ]\n",
      " [0.84229451]\n",
      " [0.846766  ]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.83305144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.680576340542757e-10, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83328217]\n",
      " [0.83274251]\n",
      " [0.83431393]\n",
      " [0.8377617 ]\n",
      " [0.84229451]\n",
      " [0.846766  ]\n",
      " [0.84889578]\n",
      " [0.83305144]] | y: 0.8550949244478885 | Predicción actual: [[0.83313316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.9458866518107243e-05, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83274251]\n",
      " [0.83431393]\n",
      " [0.8377617 ]\n",
      " [0.84229451]\n",
      " [0.846766  ]\n",
      " [0.84889578]\n",
      " [0.83305144]\n",
      " [0.83313316]] | y: 0.8752421542037967 | Predicción actual: [[0.8343551]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018534615635871887, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83431393]\n",
      " [0.8377617 ]\n",
      " [0.84229451]\n",
      " [0.846766  ]\n",
      " [0.84889578]\n",
      " [0.83305144]\n",
      " [0.83313316]\n",
      " [0.83435512]] | y: 0.857032158078264 | Predicción actual: [[0.83626956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018389805918559432, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8377617 ]\n",
      " [0.84229451]\n",
      " [0.846766  ]\n",
      " [0.84889578]\n",
      " [0.83305144]\n",
      " [0.83313316]\n",
      " [0.83435512]\n",
      " [0.83626956]] | y: 0.8500581170089112 | Predicción actual: [[0.83782357]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018842946738004684, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84229451]\n",
      " [0.846766  ]\n",
      " [0.84889578]\n",
      " [0.83305144]\n",
      " [0.83313316]\n",
      " [0.83435512]\n",
      " [0.83626956]\n",
      " [0.83782357]] | y: 0.8426966292134832 | Predicción actual: [[0.8386182]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012634026817977428, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.846766  ]\n",
      " [0.84889578]\n",
      " [0.83305144]\n",
      " [0.83313316]\n",
      " [0.83435512]\n",
      " [0.83626956]\n",
      " [0.83782357]\n",
      " [0.83861822]] | y: 0.8229368461836497 | Predicción actual: [[0.83808464]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018061097944155335, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.83305144]\n",
      " [0.83313316]\n",
      " [0.83435512]\n",
      " [0.83626956]\n",
      " [0.83782357]\n",
      " [0.83861822]\n",
      " [0.83808464]] | y: 0.7745060054242543 | Predicción actual: [[0.8357883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02906440943479538, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83305144]\n",
      " [0.83313316]\n",
      " [0.83435512]\n",
      " [0.83626956]\n",
      " [0.83782357]\n",
      " [0.83861822]\n",
      " [0.83808464]\n",
      " [0.83578831]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026286020874977112, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83313316]\n",
      " [0.83435512]\n",
      " [0.83626956]\n",
      " [0.83782357]\n",
      " [0.83861822]\n",
      " [0.83808464]\n",
      " [0.83578831]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8320008]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00125922542065382, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83435512]\n",
      " [0.83626956]\n",
      " [0.83782357]\n",
      " [0.83861822]\n",
      " [0.83808464]\n",
      " [0.83578831]\n",
      " [0.78419217]\n",
      " [0.83200079]] | y: 0.854320030995738 | Predicción actual: [[0.8317131]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003682963317260146, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83626956]\n",
      " [0.83782357]\n",
      " [0.83861822]\n",
      " [0.83808464]\n",
      " [0.83578831]\n",
      " [0.78419217]\n",
      " [0.83200079]\n",
      " [0.83171308]] | y: 0.8368849283223556 | Predicción actual: [[0.8307643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029212163761258125, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83782357]\n",
      " [0.83861822]\n",
      " [0.83808464]\n",
      " [0.83578831]\n",
      " [0.78419217]\n",
      " [0.83200079]\n",
      " [0.83171308]\n",
      " [0.83076429]] | y: 0.8299108872530028 | Predicción actual: [[0.8289878]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00838220864534378, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83861822]\n",
      " [0.83808464]\n",
      " [0.83578831]\n",
      " [0.78419217]\n",
      " [0.83200079]\n",
      " [0.83171308]\n",
      " [0.83076429]\n",
      " [0.82898778]] | y: 0.887253002712127 | Predicción actual: [[0.8259895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03784533217549324, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83808464]\n",
      " [0.83578831]\n",
      " [0.78419217]\n",
      " [0.83200079]\n",
      " [0.83171308]\n",
      " [0.83076429]\n",
      " [0.82898778]\n",
      " [0.82598948]] | y: 0.8597442851607902 | Predicción actual: [[0.82252526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041530855000019073, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83578831]\n",
      " [0.78419217]\n",
      " [0.83200079]\n",
      " [0.83171308]\n",
      " [0.83076429]\n",
      " [0.82898778]\n",
      " [0.82598948]\n",
      " [0.82252526]] | y: 0.8395970554048819 | Predicción actual: [[0.81902474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006059766281396151, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.83200079]\n",
      " [0.83171308]\n",
      " [0.83076429]\n",
      " [0.82898778]\n",
      " [0.82598948]\n",
      " [0.82252526]\n",
      " [0.81902474]] | y: 0.7838047268500579 | Predicción actual: [[0.8159364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011002009705407545, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83200079]\n",
      " [0.83171308]\n",
      " [0.83076429]\n",
      " [0.82898778]\n",
      " [0.82598948]\n",
      " [0.82252526]\n",
      " [0.81902474]\n",
      " [0.81593639]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022404411807656288, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83171308]\n",
      " [0.83076429]\n",
      " [0.82898778]\n",
      " [0.82598948]\n",
      " [0.82252526]\n",
      " [0.81902474]\n",
      " [0.81593639]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8270512]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005800093524158001, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83076429]\n",
      " [0.82898778]\n",
      " [0.82598948]\n",
      " [0.82252526]\n",
      " [0.81902474]\n",
      " [0.81593639]\n",
      " [0.81828749]\n",
      " [0.82705122]] | y: 0.7605579232855482 | Predicción actual: [[0.8258227]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004039556719362736, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82898778]\n",
      " [0.82598948]\n",
      " [0.82252526]\n",
      " [0.81902474]\n",
      " [0.81593639]\n",
      " [0.81828749]\n",
      " [0.82705122]\n",
      " [0.82582271]] | y: 0.7915536613715615 | Predicción actual: [[0.8242156]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004226460587233305, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82598948]\n",
      " [0.82252526]\n",
      " [0.81902474]\n",
      " [0.81593639]\n",
      " [0.81828749]\n",
      " [0.82705122]\n",
      " [0.82582271]\n",
      " [0.82421559]] | y: 0.7686943045331267 | Predicción actual: [[0.82275295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0065344395115971565, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82252526]\n",
      " [0.81902474]\n",
      " [0.81593639]\n",
      " [0.81828749]\n",
      " [0.82705122]\n",
      " [0.82582271]\n",
      " [0.82421559]\n",
      " [0.82275295]] | y: 0.7686943045331267 | Predicción actual: [[0.82175964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009587614797055721, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81902474]\n",
      " [0.81593639]\n",
      " [0.81828749]\n",
      " [0.82705122]\n",
      " [0.82582271]\n",
      " [0.82421559]\n",
      " [0.82275295]\n",
      " [0.82175964]] | y: 0.7989151491669895 | Predicción actual: [[0.8215235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020097203087061644, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81593639]\n",
      " [0.81828749]\n",
      " [0.82705122]\n",
      " [0.82582271]\n",
      " [0.82421559]\n",
      " [0.82275295]\n",
      " [0.82175964]\n",
      " [0.82152349]] | y: 0.7900038744672608 | Predicción actual: [[0.82248783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001409261953085661, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.82705122]\n",
      " [0.82582271]\n",
      " [0.82421559]\n",
      " [0.82275295]\n",
      " [0.82175964]\n",
      " [0.82152349]\n",
      " [0.82248783]] | y: 0.760170476559473 | Predicción actual: [[0.82462245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051226500421762466, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82705122]\n",
      " [0.82582271]\n",
      " [0.82421559]\n",
      " [0.82275295]\n",
      " [0.82175964]\n",
      " [0.82152349]\n",
      " [0.82248783]\n",
      " [0.82462245]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004519206006079912, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82582271]\n",
      " [0.82421559]\n",
      " [0.82275295]\n",
      " [0.82175964]\n",
      " [0.82152349]\n",
      " [0.82248783]\n",
      " [0.82462245]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8237146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03325936198234558, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82421559]\n",
      " [0.82275295]\n",
      " [0.82175964]\n",
      " [0.82152349]\n",
      " [0.82248783]\n",
      " [0.82462245]\n",
      " [0.68539326]\n",
      " [0.82371461]] | y: 0.6648585819449826 | Predicción actual: [[0.8202602]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03891680762171745, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82275295]\n",
      " [0.82175964]\n",
      " [0.82152349]\n",
      " [0.82248783]\n",
      " [0.82462245]\n",
      " [0.68539326]\n",
      " [0.82371461]\n",
      " [0.82026023]] | y: 0.7078651685393258 | Predicción actual: [[0.81547076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006932049058377743, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82175964]\n",
      " [0.82152349]\n",
      " [0.82248783]\n",
      " [0.82462245]\n",
      " [0.68539326]\n",
      " [0.82371461]\n",
      " [0.82026023]\n",
      " [0.81547076]] | y: 0.6648585819449826 | Predicción actual: [[0.8097056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04291074350476265, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82152349]\n",
      " [0.82248783]\n",
      " [0.82462245]\n",
      " [0.68539326]\n",
      " [0.82371461]\n",
      " [0.82026023]\n",
      " [0.81547076]\n",
      " [0.80970562]] | y: 0.7113521890740022 | Predicción actual: [[0.80283815]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004755738191306591, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82248783]\n",
      " [0.82462245]\n",
      " [0.68539326]\n",
      " [0.82371461]\n",
      " [0.82026023]\n",
      " [0.81547076]\n",
      " [0.80970562]\n",
      " [0.80283815]] | y: 0.6772568771793879 | Predicción actual: [[0.7952429]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01821497268974781, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82462245]\n",
      " [0.68539326]\n",
      " [0.82371461]\n",
      " [0.82026023]\n",
      " [0.81547076]\n",
      " [0.80970562]\n",
      " [0.80283815]\n",
      " [0.79524291]] | y: 0.7621077101898488 | Predicción actual: [[0.7867125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.1529443984036334e-05, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.82371461]\n",
      " [0.82026023]\n",
      " [0.81547076]\n",
      " [0.80970562]\n",
      " [0.80283815]\n",
      " [0.79524291]\n",
      " [0.78671253]] | y: 0.8070515304145678 | Predicción actual: [[0.77734095]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011040004901587963, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82371461]\n",
      " [0.82026023]\n",
      " [0.81547076]\n",
      " [0.80970562]\n",
      " [0.80283815]\n",
      " [0.79524291]\n",
      " [0.78671253]\n",
      " [0.77734095]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002131239278241992, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82026023]\n",
      " [0.81547076]\n",
      " [0.80970562]\n",
      " [0.80283815]\n",
      " [0.79524291]\n",
      " [0.78671253]\n",
      " [0.77734095]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8031106]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020215261727571487, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81547076]\n",
      " [0.80970562]\n",
      " [0.80283815]\n",
      " [0.79524291]\n",
      " [0.78671253]\n",
      " [0.77734095]\n",
      " [0.81518791]\n",
      " [0.8031106 ]] | y: 0.9597055404881829 | Predicción actual: [[0.7977406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03477438539266586, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80970562]\n",
      " [0.80283815]\n",
      " [0.79524291]\n",
      " [0.78671253]\n",
      " [0.77734095]\n",
      " [0.81518791]\n",
      " [0.8031106 ]\n",
      " [0.79774058]] | y: 0.9643549012010848 | Predicción actual: [[0.7931267]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09641633927822113, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80283815]\n",
      " [0.79524291]\n",
      " [0.78671253]\n",
      " [0.77734095]\n",
      " [0.81518791]\n",
      " [0.8031106 ]\n",
      " [0.79774058]\n",
      " [0.7931267 ]] | y: 0.8880278961642774 | Predicción actual: [[0.7899082]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009958467446267605, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79524291]\n",
      " [0.78671253]\n",
      " [0.77734095]\n",
      " [0.81518791]\n",
      " [0.8031106 ]\n",
      " [0.79774058]\n",
      " [0.7931267 ]\n",
      " [0.78990817]] | y: 0.8926772568771792 | Predicción actual: [[0.7883686]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055594343692064285, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78671253]\n",
      " [0.77734095]\n",
      " [0.81518791]\n",
      " [0.8031106 ]\n",
      " [0.79774058]\n",
      " [0.7931267 ]\n",
      " [0.78990817]\n",
      " [0.78836858]] | y: 0.8752421542037967 | Predicción actual: [[0.78911823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.874847455648705e-05, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77734095]\n",
      " [0.81518791]\n",
      " [0.8031106 ]\n",
      " [0.79774058]\n",
      " [0.7931267 ]\n",
      " [0.78990817]\n",
      " [0.78836858]\n",
      " [0.78911823]] | y: 0.8508330104610615 | Predicción actual: [[0.79230154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023911433294415474, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.8031106 ]\n",
      " [0.79774058]\n",
      " [0.7931267 ]\n",
      " [0.78990817]\n",
      " [0.78836858]\n",
      " [0.78911823]\n",
      " [0.79230154]] | y: 0.8488957768306855 | Predicción actual: [[0.7985707]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004136196512263268, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8031106 ]\n",
      " [0.79774058]\n",
      " [0.7931267 ]\n",
      " [0.78990817]\n",
      " [0.78836858]\n",
      " [0.78911823]\n",
      " [0.79230154]\n",
      " [0.79857069]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015003607608377934, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79774058]\n",
      " [0.7931267 ]\n",
      " [0.78990817]\n",
      " [0.78836858]\n",
      " [0.78911823]\n",
      " [0.79230154]\n",
      " [0.79857069]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7931159]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02377922646701336, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7931267 ]\n",
      " [0.78990817]\n",
      " [0.78836858]\n",
      " [0.78911823]\n",
      " [0.79230154]\n",
      " [0.79857069]\n",
      " [0.96241767]\n",
      " [0.79311591]] | y: 0.9407206509104997 | Predicción actual: [[0.7952366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0348794125020504, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78990817]\n",
      " [0.78836858]\n",
      " [0.78911823]\n",
      " [0.79230154]\n",
      " [0.79857069]\n",
      " [0.96241767]\n",
      " [0.79311591]\n",
      " [0.79523659]] | y: 0.9724912824486633 | Predicción actual: [[0.80048704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007071217522025108, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78836858]\n",
      " [0.78911823]\n",
      " [0.79230154]\n",
      " [0.79857069]\n",
      " [0.96241767]\n",
      " [0.79311591]\n",
      " [0.79523659]\n",
      " [0.80048704]] | y: 0.9969004261913985 | Predicción actual: [[0.8084366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029492149129509926, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78911823]\n",
      " [0.79230154]\n",
      " [0.79857069]\n",
      " [0.96241767]\n",
      " [0.79311591]\n",
      " [0.79523659]\n",
      " [0.80048704]\n",
      " [0.80843657]] | y: 0.951181712514529 | Predicción actual: [[0.8186237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015334656462073326, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79230154]\n",
      " [0.79857069]\n",
      " [0.96241767]\n",
      " [0.79311591]\n",
      " [0.79523659]\n",
      " [0.80048704]\n",
      " [0.80843657]\n",
      " [0.81862372]] | y: 0.8957768306857805 | Predicción actual: [[0.8300222]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002134498441591859, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79857069]\n",
      " [0.96241767]\n",
      " [0.79311591]\n",
      " [0.79523659]\n",
      " [0.80048704]\n",
      " [0.80843657]\n",
      " [0.81862372]\n",
      " [0.83002222]] | y: 0.8814413018209997 | Predicción actual: [[0.8414104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00212522828951478, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.79311591]\n",
      " [0.79523659]\n",
      " [0.80048704]\n",
      " [0.80843657]\n",
      " [0.81862372]\n",
      " [0.83002222]\n",
      " [0.8414104 ]] | y: 0.9170864006199149 | Predicción actual: [[0.8513074]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001356840250082314, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79311591]\n",
      " [0.79523659]\n",
      " [0.80048704]\n",
      " [0.80843657]\n",
      " [0.81862372]\n",
      " [0.83002222]\n",
      " [0.8414104 ]\n",
      " [0.85130739]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016055967658758163, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79523659]\n",
      " [0.80048704]\n",
      " [0.80843657]\n",
      " [0.81862372]\n",
      " [0.83002222]\n",
      " [0.8414104 ]\n",
      " [0.85130739]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.8197275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016422626795247197, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80048704]\n",
      " [0.80843657]\n",
      " [0.81862372]\n",
      " [0.83002222]\n",
      " [0.8414104 ]\n",
      " [0.85130739]\n",
      " [0.91979853]\n",
      " [0.81972748]] | y: 0.9682293684618366 | Predicción actual: [[0.8296644]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06092039495706558, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80843657]\n",
      " [0.81862372]\n",
      " [0.83002222]\n",
      " [0.8414104 ]\n",
      " [0.85130739]\n",
      " [0.91979853]\n",
      " [0.81972748]\n",
      " [0.82966441]] | y: 0.9577683068578069 | Predicción actual: [[0.84099376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001819133060052991, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.2111063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024871978908777237, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2111063 ]] | y: 0.10422316931421921 | Predicción actual: [[0.19527227]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0042391205206513405, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2111063 ]\n",
      " [0.19527227]] | y: 0.15420379697791559 | Predicción actual: [[0.19957975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030896603129804134, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2111063 ]\n",
      " [0.19527227]\n",
      " [0.19957975]] | y: 0.1557535838822161 | Predicción actual: [[0.21151222]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003420350607484579, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2111063 ]\n",
      " [0.19527227]\n",
      " [0.19957975]\n",
      " [0.21151222]] | y: 0.12553273924835334 | Predicción actual: [[0.22478981]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008480938151478767, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2111063 ]\n",
      " [0.19527227]\n",
      " [0.19957975]\n",
      " [0.21151222]\n",
      " [0.22478981]] | y: 0.1456799690042619 | Predicción actual: [[0.23557518]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003833202878013253, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.2111063 ]\n",
      " [0.19527227]\n",
      " [0.19957975]\n",
      " [0.21151222]\n",
      " [0.22478981]\n",
      " [0.23557518]] | y: 0.1464548624564122 | Predicción actual: [[0.25836208]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02253524586558342, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.2111063 ]\n",
      " [0.19527227]\n",
      " [0.19957975]\n",
      " [0.21151222]\n",
      " [0.22478981]\n",
      " [0.23557518]\n",
      " [0.25836208]] | y: 0.1960480433940332 | Predicción actual: [[0.2865279]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00923279020935297, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2111063 ]\n",
      " [0.19527227]\n",
      " [0.19957975]\n",
      " [0.21151222]\n",
      " [0.22478981]\n",
      " [0.23557518]\n",
      " [0.25836208]\n",
      " [0.2865279 ]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037893590051680803, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19527227]\n",
      " [0.19957975]\n",
      " [0.21151222]\n",
      " [0.22478981]\n",
      " [0.23557518]\n",
      " [0.25836208]\n",
      " [0.2865279 ]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3228521]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01580531895160675, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19957975]\n",
      " [0.21151222]\n",
      " [0.22478981]\n",
      " [0.23557518]\n",
      " [0.25836208]\n",
      " [0.2865279 ]\n",
      " [0.2305308 ]\n",
      " [0.3228521 ]] | y: 0.211933359163115 | Predicción actual: [[0.3304819]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015918904915452003, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21151222]\n",
      " [0.22478981]\n",
      " [0.23557518]\n",
      " [0.25836208]\n",
      " [0.2865279 ]\n",
      " [0.2305308 ]\n",
      " [0.3228521 ]\n",
      " [0.33048189]] | y: 0.2072839984502131 | Predicción actual: [[0.34008804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018063386902213097, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22478981]\n",
      " [0.23557518]\n",
      " [0.25836208]\n",
      " [0.2865279 ]\n",
      " [0.2305308 ]\n",
      " [0.3228521 ]\n",
      " [0.33048189]\n",
      " [0.34008804]] | y: 0.19294846958543205 | Predicción actual: [[0.35037935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02835242822766304, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23557518]\n",
      " [0.25836208]\n",
      " [0.2865279 ]\n",
      " [0.2305308 ]\n",
      " [0.3228521 ]\n",
      " [0.33048189]\n",
      " [0.34008804]\n",
      " [0.35037935]] | y: 0.19682293684618352 | Predicción actual: [[0.36123767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015568947419524193, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25836208]\n",
      " [0.2865279 ]\n",
      " [0.2305308 ]\n",
      " [0.3228521 ]\n",
      " [0.33048189]\n",
      " [0.34008804]\n",
      " [0.35037935]\n",
      " [0.36123767]] | y: 0.21425803951956607 | Predicción actual: [[0.37341613]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01384253241121769, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2865279 ]\n",
      " [0.2305308 ]\n",
      " [0.3228521 ]\n",
      " [0.33048189]\n",
      " [0.34008804]\n",
      " [0.35037935]\n",
      " [0.36123767]\n",
      " [0.37341613]] | y: 0.18132506780317698 | Predicción actual: [[0.38413128]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008989064954221249, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.3228521 ]\n",
      " [0.33048189]\n",
      " [0.34008804]\n",
      " [0.35037935]\n",
      " [0.36123767]\n",
      " [0.37341613]\n",
      " [0.38413128]] | y: 0.17512592018597434 | Predicción actual: [[0.3917375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050125401467084885, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3228521 ]\n",
      " [0.33048189]\n",
      " [0.34008804]\n",
      " [0.35037935]\n",
      " [0.36123767]\n",
      " [0.37341613]\n",
      " [0.38413128]\n",
      " [0.39173749]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09310866892337799, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33048189]\n",
      " [0.34008804]\n",
      " [0.35037935]\n",
      " [0.36123767]\n",
      " [0.37341613]\n",
      " [0.38413128]\n",
      " [0.39173749]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.42213783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0955740436911583, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34008804]\n",
      " [0.35037935]\n",
      " [0.36123767]\n",
      " [0.37341613]\n",
      " [0.38413128]\n",
      " [0.39173749]\n",
      " [0.14800465]\n",
      " [0.42213783]] | y: 0.19217357613328173 | Predicción actual: [[0.42630163]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09045430272817612, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35037935]\n",
      " [0.36123767]\n",
      " [0.37341613]\n",
      " [0.38413128]\n",
      " [0.39173749]\n",
      " [0.14800465]\n",
      " [0.42213783]\n",
      " [0.42630163]] | y: 0.1859744285160791 | Predicción actual: [[0.42850846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.053933773189783096, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36123767]\n",
      " [0.37341613]\n",
      " [0.38413128]\n",
      " [0.39173749]\n",
      " [0.14800465]\n",
      " [0.42213783]\n",
      " [0.42630163]\n",
      " [0.42850846]] | y: 0.26695079426578844 | Predicción actual: [[0.428885]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018811296671628952, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37341613]\n",
      " [0.38413128]\n",
      " [0.39173749]\n",
      " [0.14800465]\n",
      " [0.42213783]\n",
      " [0.42630163]\n",
      " [0.42850846]\n",
      " [0.42888501]] | y: 0.2925222781867493 | Predicción actual: [[0.4277082]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04239930585026741, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38413128]\n",
      " [0.39173749]\n",
      " [0.14800465]\n",
      " [0.42213783]\n",
      " [0.42630163]\n",
      " [0.42850846]\n",
      " [0.42888501]\n",
      " [0.42770821]] | y: 0.3177063153816349 | Predicción actual: [[0.42497572]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006969647016376257, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39173749]\n",
      " [0.14800465]\n",
      " [0.42213783]\n",
      " [0.42630163]\n",
      " [0.42850846]\n",
      " [0.42888501]\n",
      " [0.42770821]\n",
      " [0.42497572]] | y: 0.31266950794265785 | Predicción actual: [[0.42144057]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010564999654889107, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.42213783]\n",
      " [0.42630163]\n",
      " [0.42850846]\n",
      " [0.42888501]\n",
      " [0.42770821]\n",
      " [0.42497572]\n",
      " [0.42144057]] | y: 0.2890352576520729 | Predicción actual: [[0.41809162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008327982388436794, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42213783]\n",
      " [0.42630163]\n",
      " [0.42850846]\n",
      " [0.42888501]\n",
      " [0.42770821]\n",
      " [0.42497572]\n",
      " [0.42144057]\n",
      " [0.41809162]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06631279736757278, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42630163]\n",
      " [0.42850846]\n",
      " [0.42888501]\n",
      " [0.42770821]\n",
      " [0.42497572]\n",
      " [0.42144057]\n",
      " [0.41809162]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.47771788]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02060420997440815, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42850846]\n",
      " [0.42888501]\n",
      " [0.42770821]\n",
      " [0.42497572]\n",
      " [0.42144057]\n",
      " [0.41809162]\n",
      " [0.28283611]\n",
      " [0.47771788]] | y: 0.2758620689655173 | Predicción actual: [[0.47501168]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03390355408191681, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42888501]\n",
      " [0.42770821]\n",
      " [0.42497572]\n",
      " [0.42144057]\n",
      " [0.41809162]\n",
      " [0.28283611]\n",
      " [0.47771788]\n",
      " [0.47501168]] | y: 0.2746997287872917 | Predicción actual: [[0.4710785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0485507994890213, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42770821]\n",
      " [0.42497572]\n",
      " [0.42144057]\n",
      " [0.41809162]\n",
      " [0.28283611]\n",
      " [0.47771788]\n",
      " [0.47501168]\n",
      " [0.47107849]] | y: 0.275474622239442 | Predicción actual: [[0.4668643]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019622541964054108, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42497572]\n",
      " [0.42144057]\n",
      " [0.41809162]\n",
      " [0.28283611]\n",
      " [0.47771788]\n",
      " [0.47501168]\n",
      " [0.47107849]\n",
      " [0.46686429]] | y: 0.3347539713289423 | Predicción actual: [[0.46346307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023129940032958984, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42144057]\n",
      " [0.41809162]\n",
      " [0.28283611]\n",
      " [0.47771788]\n",
      " [0.47501168]\n",
      " [0.47107849]\n",
      " [0.46686429]\n",
      " [0.46346307]] | y: 0.35567609453700116 | Predicción actual: [[0.46186408]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030198678374290466, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41809162]\n",
      " [0.28283611]\n",
      " [0.47771788]\n",
      " [0.47501168]\n",
      " [0.47107849]\n",
      " [0.46686429]\n",
      " [0.46346307]\n",
      " [0.46186408]] | y: 0.3366912049593181 | Predicción actual: [[0.46277878]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05021340772509575, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.47771788]\n",
      " [0.47501168]\n",
      " [0.47107849]\n",
      " [0.46686429]\n",
      " [0.46346307]\n",
      " [0.46186408]\n",
      " [0.46277878]] | y: 0.3335916311507167 | Predicción actual: [[0.46651864]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008843068964779377, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47771788]\n",
      " [0.47501168]\n",
      " [0.47107849]\n",
      " [0.46686429]\n",
      " [0.46346307]\n",
      " [0.46186408]\n",
      " [0.46277878]\n",
      " [0.46651864]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0049743796698749065, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47501168]\n",
      " [0.47107849]\n",
      " [0.46686429]\n",
      " [0.46346307]\n",
      " [0.46186408]\n",
      " [0.46277878]\n",
      " [0.46651864]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.5035497]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00812647957354784, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47107849]\n",
      " [0.46686429]\n",
      " [0.46346307]\n",
      " [0.46186408]\n",
      " [0.46277878]\n",
      " [0.46651864]\n",
      " [0.3847346 ]\n",
      " [0.5035497 ]] | y: 0.5962805114296785 | Predicción actual: [[0.49966297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021561767905950546, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46686429]\n",
      " [0.46346307]\n",
      " [0.46186408]\n",
      " [0.46277878]\n",
      " [0.46651864]\n",
      " [0.3847346 ]\n",
      " [0.5035497 ]\n",
      " [0.49966297]] | y: 0.574583494769469 | Predicción actual: [[0.4964281]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030270438641309738, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46346307]\n",
      " [0.46186408]\n",
      " [0.46277878]\n",
      " [0.46651864]\n",
      " [0.3847346 ]\n",
      " [0.5035497 ]\n",
      " [0.49966297]\n",
      " [0.4964281 ]] | y: 0.6063541263076326 | Predicción actual: [[0.4944289]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005611389875411987, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46186408]\n",
      " [0.46277878]\n",
      " [0.46651864]\n",
      " [0.3847346 ]\n",
      " [0.5035497 ]\n",
      " [0.49966297]\n",
      " [0.4964281 ]\n",
      " [0.4944289 ]] | y: 0.5846571096474236 | Predicción actual: [[0.49393576]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004134421236813068, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46277878]\n",
      " [0.46651864]\n",
      " [0.3847346 ]\n",
      " [0.5035497 ]\n",
      " [0.49966297]\n",
      " [0.4964281 ]\n",
      " [0.4944289 ]\n",
      " [0.49393576]] | y: 0.5687717938783416 | Predicción actual: [[0.4949234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011043568141758442, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46651864]\n",
      " [0.3847346 ]\n",
      " [0.5035497 ]\n",
      " [0.49966297]\n",
      " [0.4964281 ]\n",
      " [0.4944289 ]\n",
      " [0.49393576]\n",
      " [0.49492341]] | y: 0.6427741185586981 | Predicción actual: [[0.49707747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009203807450830936, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.5035497 ]\n",
      " [0.49966297]\n",
      " [0.4964281 ]\n",
      " [0.4944289 ]\n",
      " [0.49393576]\n",
      " [0.49492341]\n",
      " [0.49707747]] | y: 0.6617590081363811 | Predicción actual: [[0.49982]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01881556399166584, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5035497 ]\n",
      " [0.49966297]\n",
      " [0.4964281 ]\n",
      " [0.4944289 ]\n",
      " [0.49393576]\n",
      " [0.49492341]\n",
      " [0.49707747]\n",
      " [0.49981999]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012173994444310665, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49966297]\n",
      " [0.4964281 ]\n",
      " [0.4944289 ]\n",
      " [0.49393576]\n",
      " [0.49492341]\n",
      " [0.49707747]\n",
      " [0.49981999]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.524896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04552656412124634, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4964281 ]\n",
      " [0.4944289 ]\n",
      " [0.49393576]\n",
      " [0.49492341]\n",
      " [0.49707747]\n",
      " [0.49981999]\n",
      " [0.67299496]\n",
      " [0.52489603]] | y: 0.703990701278574 | Predicción actual: [[0.526952]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046107128262519836, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4944289 ]\n",
      " [0.49393576]\n",
      " [0.49492341]\n",
      " [0.49707747]\n",
      " [0.49981999]\n",
      " [0.67299496]\n",
      " [0.52489603]\n",
      " [0.52695203]] | y: 0.7272375048430839 | Predicción actual: [[0.53189844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03300485759973526, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49393576]\n",
      " [0.49492341]\n",
      " [0.49707747]\n",
      " [0.49981999]\n",
      " [0.67299496]\n",
      " [0.52489603]\n",
      " [0.52695203]\n",
      " [0.53189844]] | y: 0.722588144130182 | Predicción actual: [[0.5396544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04009334370493889, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49492341]\n",
      " [0.49707747]\n",
      " [0.49981999]\n",
      " [0.67299496]\n",
      " [0.52489603]\n",
      " [0.52695203]\n",
      " [0.53189844]\n",
      " [0.53965437]] | y: 0.771793878341728 | Predicción actual: [[0.54988813]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0548226460814476, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49707747]\n",
      " [0.49981999]\n",
      " [0.67299496]\n",
      " [0.52489603]\n",
      " [0.52695203]\n",
      " [0.53189844]\n",
      " [0.53965437]\n",
      " [0.54988813]] | y: 0.7245253777605578 | Predicción actual: [[0.5621562]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05960361286997795, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49981999]\n",
      " [0.67299496]\n",
      " [0.52489603]\n",
      " [0.52695203]\n",
      " [0.53189844]\n",
      " [0.53965437]\n",
      " [0.54988813]\n",
      " [0.5621562 ]] | y: 0.6710577295621851 | Predicción actual: [[0.57598275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01860537938773632, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.52489603]\n",
      " [0.52695203]\n",
      " [0.53189844]\n",
      " [0.53965437]\n",
      " [0.54988813]\n",
      " [0.5621562 ]\n",
      " [0.57598275]] | y: 0.6737698566447115 | Predicción actual: [[0.59098697]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008573013357818127, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52489603]\n",
      " [0.52695203]\n",
      " [0.53189844]\n",
      " [0.53965437]\n",
      " [0.54988813]\n",
      " [0.5621562 ]\n",
      " [0.57598275]\n",
      " [0.59098697]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04463442414999008, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52695203]\n",
      " [0.53189844]\n",
      " [0.53965437]\n",
      " [0.54988813]\n",
      " [0.5621562 ]\n",
      " [0.57598275]\n",
      " [0.59098697]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5678865]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031024359166622162, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53189844]\n",
      " [0.53965437]\n",
      " [0.54988813]\n",
      " [0.5621562 ]\n",
      " [0.57598275]\n",
      " [0.59098697]\n",
      " [0.71445176]\n",
      " [0.56788647]] | y: 0.722588144130182 | Predicción actual: [[0.57803386]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08484219759702682, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53965437]\n",
      " [0.54988813]\n",
      " [0.5621562 ]\n",
      " [0.57598275]\n",
      " [0.59098697]\n",
      " [0.71445176]\n",
      " [0.56788647]\n",
      " [0.57803386]] | y: 0.6993413405656723 | Predicción actual: [[0.59029794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00874378066509962, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54988813]\n",
      " [0.5621562 ]\n",
      " [0.57598275]\n",
      " [0.59098697]\n",
      " [0.71445176]\n",
      " [0.56788647]\n",
      " [0.57803386]\n",
      " [0.59029794]] | y: 0.7373111197210385 | Predicción actual: [[0.6035602]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018178856000304222, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5621562 ]\n",
      " [0.57598275]\n",
      " [0.59098697]\n",
      " [0.71445176]\n",
      " [0.56788647]\n",
      " [0.57803386]\n",
      " [0.59029794]\n",
      " [0.60356021]] | y: 0.7214258039519565 | Predicción actual: [[0.61672455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004810291342437267, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57598275]\n",
      " [0.59098697]\n",
      " [0.71445176]\n",
      " [0.56788647]\n",
      " [0.57803386]\n",
      " [0.59029794]\n",
      " [0.60356021]\n",
      " [0.61672455]] | y: 0.7187136768694304 | Predicción actual: [[0.62861156]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01817220076918602, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59098697]\n",
      " [0.71445176]\n",
      " [0.56788647]\n",
      " [0.57803386]\n",
      " [0.59029794]\n",
      " [0.60356021]\n",
      " [0.61672455]\n",
      " [0.62861156]] | y: 0.6741573033707864 | Predicción actual: [[0.63827914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008725965395569801, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56788647]\n",
      " [0.57803386]\n",
      " [0.59029794]\n",
      " [0.60356021]\n",
      " [0.61672455]\n",
      " [0.62861156]\n",
      " [0.63827914]] | y: 0.698566447113522 | Predicción actual: [[0.64486426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017582319676876068, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56788647]\n",
      " [0.57803386]\n",
      " [0.59029794]\n",
      " [0.60356021]\n",
      " [0.61672455]\n",
      " [0.62861156]\n",
      " [0.63827914]\n",
      " [0.64486426]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001651798258535564, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57803386]\n",
      " [0.59029794]\n",
      " [0.60356021]\n",
      " [0.61672455]\n",
      " [0.62861156]\n",
      " [0.63827914]\n",
      " [0.64486426]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.62914896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031006764620542526, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59029794]\n",
      " [0.60356021]\n",
      " [0.61672455]\n",
      " [0.62861156]\n",
      " [0.63827914]\n",
      " [0.64486426]\n",
      " [0.72103836]\n",
      " [0.62914896]] | y: 0.7562960092987214 | Predicción actual: [[0.64180124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010165611281991005, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60356021]\n",
      " [0.61672455]\n",
      " [0.62861156]\n",
      " [0.63827914]\n",
      " [0.64486426]\n",
      " [0.72103836]\n",
      " [0.62914896]\n",
      " [0.64180124]] | y: 0.8275862068965516 | Predicción actual: [[0.65432066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02687329798936844, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61672455]\n",
      " [0.62861156]\n",
      " [0.63827914]\n",
      " [0.64486426]\n",
      " [0.72103836]\n",
      " [0.62914896]\n",
      " [0.64180124]\n",
      " [0.65432066]] | y: 0.8388221619527314 | Predicción actual: [[0.66598606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019379453733563423, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62861156]\n",
      " [0.63827914]\n",
      " [0.64486426]\n",
      " [0.72103836]\n",
      " [0.62914896]\n",
      " [0.64180124]\n",
      " [0.65432066]\n",
      " [0.66598606]] | y: 0.7942657884540876 | Predicción actual: [[0.6762319]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.290849993703887e-05, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63827914]\n",
      " [0.64486426]\n",
      " [0.72103836]\n",
      " [0.62914896]\n",
      " [0.64180124]\n",
      " [0.65432066]\n",
      " [0.66598606]\n",
      " [0.67623192]] | y: 0.7838047268500579 | Predicción actual: [[0.6847184]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007849681423977017, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64486426]\n",
      " [0.72103836]\n",
      " [0.62914896]\n",
      " [0.64180124]\n",
      " [0.65432066]\n",
      " [0.66598606]\n",
      " [0.67623192]\n",
      " [0.68471837]] | y: 0.7679194110809764 | Predicción actual: [[0.6917717]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03211129084229469, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62914896]\n",
      " [0.64180124]\n",
      " [0.65432066]\n",
      " [0.66598606]\n",
      " [0.67623192]\n",
      " [0.68471837]\n",
      " [0.69177169]] | y: 0.7845796203022084 | Predicción actual: [[0.69825464]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015680944547057152, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62914896]\n",
      " [0.64180124]\n",
      " [0.65432066]\n",
      " [0.66598606]\n",
      " [0.67623192]\n",
      " [0.68471837]\n",
      " [0.69177169]\n",
      " [0.69825464]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021996671333909035, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64180124]\n",
      " [0.65432066]\n",
      " [0.66598606]\n",
      " [0.67623192]\n",
      " [0.68471837]\n",
      " [0.69177169]\n",
      " [0.69825464]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.69648117]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043717753142118454, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65432066]\n",
      " [0.66598606]\n",
      " [0.67623192]\n",
      " [0.68471837]\n",
      " [0.69177169]\n",
      " [0.69825464]\n",
      " [0.87872917]\n",
      " [0.69648117]] | y: 0.8488957768306855 | Predicción actual: [[0.71026117]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08266521245241165, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66598606]\n",
      " [0.67623192]\n",
      " [0.68471837]\n",
      " [0.69177169]\n",
      " [0.69825464]\n",
      " [0.87872917]\n",
      " [0.69648117]\n",
      " [0.71026117]] | y: 0.8182874854707476 | Predicción actual: [[0.72481185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037476181983947754, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67623192]\n",
      " [0.68471837]\n",
      " [0.69177169]\n",
      " [0.69825464]\n",
      " [0.87872917]\n",
      " [0.69648117]\n",
      " [0.71026117]\n",
      " [0.72481185]] | y: 0.8268113134444013 | Predicción actual: [[0.73986393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.3917274322448066e-06, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68471837]\n",
      " [0.69177169]\n",
      " [0.69825464]\n",
      " [0.87872917]\n",
      " [0.69648117]\n",
      " [0.71026117]\n",
      " [0.72481185]\n",
      " [0.73986393]] | y: 0.7853545137543589 | Predicción actual: [[0.75507796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015341846272349358, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69177169]\n",
      " [0.69825464]\n",
      " [0.87872917]\n",
      " [0.69648117]\n",
      " [0.71026117]\n",
      " [0.72481185]\n",
      " [0.73986393]\n",
      " [0.75507796]] | y: 0.7892289810151103 | Predicción actual: [[0.77066517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003265782492235303, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69825464]\n",
      " [0.87872917]\n",
      " [0.69648117]\n",
      " [0.71026117]\n",
      " [0.72481185]\n",
      " [0.73986393]\n",
      " [0.75507796]\n",
      " [0.77066517]] | y: 0.8341728012398295 | Predicción actual: [[0.7864119]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025750700384378433, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.69648117]\n",
      " [0.71026117]\n",
      " [0.72481185]\n",
      " [0.73986393]\n",
      " [0.75507796]\n",
      " [0.77066517]\n",
      " [0.78641188]] | y: 0.8124757845796202 | Predicción actual: [[0.802605]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012732790783047676, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69648117]\n",
      " [0.71026117]\n",
      " [0.72481185]\n",
      " [0.73986393]\n",
      " [0.75507796]\n",
      " [0.77066517]\n",
      " [0.78641188]\n",
      " [0.80260497]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012235062196850777, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71026117]\n",
      " [0.72481185]\n",
      " [0.73986393]\n",
      " [0.75507796]\n",
      " [0.77066517]\n",
      " [0.78641188]\n",
      " [0.80260497]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.78040534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004670706577599049, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72481185]\n",
      " [0.73986393]\n",
      " [0.75507796]\n",
      " [0.77066517]\n",
      " [0.78641188]\n",
      " [0.80260497]\n",
      " [0.80123983]\n",
      " [0.78040534]] | y: 0.793490895001937 | Predicción actual: [[0.79567313]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009466755203902721, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73986393]\n",
      " [0.75507796]\n",
      " [0.77066517]\n",
      " [0.78641188]\n",
      " [0.80260497]\n",
      " [0.80123983]\n",
      " [0.78040534]\n",
      " [0.79567313]] | y: 0.760170476559473 | Predicción actual: [[0.8099485]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0279211588203907, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75507796]\n",
      " [0.77066517]\n",
      " [0.78641188]\n",
      " [0.80260497]\n",
      " [0.80123983]\n",
      " [0.78040534]\n",
      " [0.79567313]\n",
      " [0.8099485 ]] | y: 0.7353738860906625 | Predicción actual: [[0.8224163]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008463123813271523, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77066517]\n",
      " [0.78641188]\n",
      " [0.80260497]\n",
      " [0.80123983]\n",
      " [0.78040534]\n",
      " [0.79567313]\n",
      " [0.8099485 ]\n",
      " [0.82241631]] | y: 0.7101898488957767 | Predicción actual: [[0.8327157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032352120615541935, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78641188]\n",
      " [0.80260497]\n",
      " [0.80123983]\n",
      " [0.78040534]\n",
      " [0.79567313]\n",
      " [0.8099485 ]\n",
      " [0.82241631]\n",
      " [0.83271569]] | y: 0.7121270825261525 | Predicción actual: [[0.8403723]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006358758546411991, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80260497]\n",
      " [0.80123983]\n",
      " [0.78040534]\n",
      " [0.79567313]\n",
      " [0.8099485 ]\n",
      " [0.82241631]\n",
      " [0.83271569]\n",
      " [0.84037232]] | y: 0.7396358000774894 | Predicción actual: [[0.84513706]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00345630943775177, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.78040534]\n",
      " [0.79567313]\n",
      " [0.8099485 ]\n",
      " [0.82241631]\n",
      " [0.83271569]\n",
      " [0.84037232]\n",
      " [0.84513706]] | y: 0.7361487795428128 | Predicción actual: [[0.846478]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007574095390737057, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78040534]\n",
      " [0.79567313]\n",
      " [0.8099485 ]\n",
      " [0.82241631]\n",
      " [0.83271569]\n",
      " [0.84037232]\n",
      " [0.84513706]\n",
      " [0.84647799]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017023146210704, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79567313]\n",
      " [0.8099485 ]\n",
      " [0.82241631]\n",
      " [0.83271569]\n",
      " [0.84037232]\n",
      " [0.84513706]\n",
      " [0.84647799]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.86051375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02284177765250206, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8099485 ]\n",
      " [0.82241631]\n",
      " [0.83271569]\n",
      " [0.84037232]\n",
      " [0.84513706]\n",
      " [0.84647799]\n",
      " [0.66757071]\n",
      " [0.86051375]] | y: 0.696629213483146 | Predicción actual: [[0.86748123]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00729600852355361, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82241631]\n",
      " [0.83271569]\n",
      " [0.84037232]\n",
      " [0.84513706]\n",
      " [0.84647799]\n",
      " [0.66757071]\n",
      " [0.86051375]\n",
      " [0.86748123]] | y: 0.6559473072452537 | Predicción actual: [[0.8704564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038160596042871475, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83271569]\n",
      " [0.84037232]\n",
      " [0.84513706]\n",
      " [0.84647799]\n",
      " [0.66757071]\n",
      " [0.86051375]\n",
      " [0.86748123]\n",
      " [0.8704564 ]] | y: 0.6788066640836885 | Predicción actual: [[0.8695092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01348870899528265, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84037232]\n",
      " [0.84513706]\n",
      " [0.84647799]\n",
      " [0.66757071]\n",
      " [0.86051375]\n",
      " [0.86748123]\n",
      " [0.8704564 ]\n",
      " [0.86950922]] | y: 0.6760945370011622 | Predicción actual: [[0.86560047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06190848723053932, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84513706]\n",
      " [0.84647799]\n",
      " [0.66757071]\n",
      " [0.86051375]\n",
      " [0.86748123]\n",
      " [0.8704564 ]\n",
      " [0.86950922]\n",
      " [0.86560047]] | y: 0.7295621851995349 | Predicción actual: [[0.8595521]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002915178192779422, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84647799]\n",
      " [0.66757071]\n",
      " [0.86051375]\n",
      " [0.86748123]\n",
      " [0.8704564 ]\n",
      " [0.86950922]\n",
      " [0.86560047]\n",
      " [0.85955209]] | y: 0.7012785741960481 | Predicción actual: [[0.8532113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0239816065877676, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.86051375]\n",
      " [0.86748123]\n",
      " [0.8704564 ]\n",
      " [0.86950922]\n",
      " [0.86560047]\n",
      " [0.85955209]\n",
      " [0.85321128]] | y: 0.767531964354901 | Predicción actual: [[0.84788114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03416294604539871, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86051375]\n",
      " [0.86748123]\n",
      " [0.8704564 ]\n",
      " [0.86950922]\n",
      " [0.86560047]\n",
      " [0.85955209]\n",
      " [0.85321128]\n",
      " [0.84788114]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02721729688346386, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86748123]\n",
      " [0.8704564 ]\n",
      " [0.86950922]\n",
      " [0.86560047]\n",
      " [0.85955209]\n",
      " [0.85321128]\n",
      " [0.84788114]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8988469]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01148368138819933, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8704564 ]\n",
      " [0.86950922]\n",
      " [0.86560047]\n",
      " [0.85955209]\n",
      " [0.85321128]\n",
      " [0.84788114]\n",
      " [0.75513367]\n",
      " [0.89884692]] | y: 0.7520340953118947 | Predicción actual: [[0.8938346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04689031094312668, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86950922]\n",
      " [0.86560047]\n",
      " [0.85955209]\n",
      " [0.85321128]\n",
      " [0.84788114]\n",
      " [0.75513367]\n",
      " [0.89884692]\n",
      " [0.89383459]] | y: 0.7098024021697016 | Predicción actual: [[0.8865243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0801125094294548, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86560047]\n",
      " [0.85955209]\n",
      " [0.85321128]\n",
      " [0.84788114]\n",
      " [0.75513367]\n",
      " [0.89884692]\n",
      " [0.89383459]\n",
      " [0.88652432]] | y: 0.6904300658659435 | Predicción actual: [[0.87839144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02286430448293686, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85955209]\n",
      " [0.85321128]\n",
      " [0.84788114]\n",
      " [0.75513367]\n",
      " [0.89884692]\n",
      " [0.89383459]\n",
      " [0.88652432]\n",
      " [0.87839144]] | y: 0.7543587756683454 | Predicción actual: [[0.87136376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032077934592962265, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85321128]\n",
      " [0.84788114]\n",
      " [0.75513367]\n",
      " [0.89884692]\n",
      " [0.89383459]\n",
      " [0.88652432]\n",
      " [0.87839144]\n",
      " [0.87136376]] | y: 0.7222006974041069 | Predicción actual: [[0.86665416]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010690017370507121, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84788114]\n",
      " [0.75513367]\n",
      " [0.89884692]\n",
      " [0.89383459]\n",
      " [0.88652432]\n",
      " [0.87839144]\n",
      " [0.87136376]\n",
      " [0.86665416]] | y: 0.8485083301046106 | Predicción actual: [[0.8652413]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010175024362979457, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.89884692]\n",
      " [0.89383459]\n",
      " [0.88652432]\n",
      " [0.87839144]\n",
      " [0.87136376]\n",
      " [0.86665416]\n",
      " [0.86524129]] | y: 0.9054629988376597 | Predicción actual: [[0.8672218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.785439811414108e-05, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89884692]\n",
      " [0.89383459]\n",
      " [0.88652432]\n",
      " [0.87839144]\n",
      " [0.87136376]\n",
      " [0.86665416]\n",
      " [0.86524129]\n",
      " [0.86722177]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001750751631334424, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89383459]\n",
      " [0.88652432]\n",
      " [0.87839144]\n",
      " [0.87136376]\n",
      " [0.86665416]\n",
      " [0.86524129]\n",
      " [0.86722177]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.89206505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047860585153102875, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88652432]\n",
      " [0.87839144]\n",
      " [0.87136376]\n",
      " [0.86665416]\n",
      " [0.86524129]\n",
      " [0.86722177]\n",
      " [0.8822162 ]\n",
      " [0.89206505]] | y: 0.889577683068578 | Predicción actual: [[0.88540673]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015498374588787556, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87839144]\n",
      " [0.87136376]\n",
      " [0.86665416]\n",
      " [0.86524129]\n",
      " [0.86722177]\n",
      " [0.8822162 ]\n",
      " [0.89206505]\n",
      " [0.88540673]] | y: 0.8748547074777218 | Predicción actual: [[0.8801675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017326442524790764, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87136376]\n",
      " [0.86665416]\n",
      " [0.86524129]\n",
      " [0.86722177]\n",
      " [0.8822162 ]\n",
      " [0.89206505]\n",
      " [0.88540673]\n",
      " [0.88016748]] | y: 0.9132119333591631 | Predicción actual: [[0.87766033]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024561770260334015, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86665416]\n",
      " [0.86524129]\n",
      " [0.86722177]\n",
      " [0.8822162 ]\n",
      " [0.89206505]\n",
      " [0.88540673]\n",
      " [0.88016748]\n",
      " [0.87766033]] | y: 1.0 | Predicción actual: [[0.8775925]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02279447391629219, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86524129]\n",
      " [0.86722177]\n",
      " [0.8822162 ]\n",
      " [0.89206505]\n",
      " [0.88540673]\n",
      " [0.88016748]\n",
      " [0.87766033]\n",
      " [0.8775925 ]] | y: 0.9705540488182873 | Predicción actual: [[0.8799596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013385209254920483, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86722177]\n",
      " [0.8822162 ]\n",
      " [0.89206505]\n",
      " [0.88540673]\n",
      " [0.88016748]\n",
      " [0.87766033]\n",
      " [0.8775925 ]\n",
      " [0.87995958]] | y: 0.8888027896164277 | Predicción actual: [[0.88376445]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031723130960017443, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.89206505]\n",
      " [0.88540673]\n",
      " [0.88016748]\n",
      " [0.87766033]\n",
      " [0.8775925 ]\n",
      " [0.87995958]\n",
      " [0.88376445]] | y: 0.877954281286323 | Predicción actual: [[0.8877634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005015687202103436, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89206505]\n",
      " [0.88540673]\n",
      " [0.88016748]\n",
      " [0.87766033]\n",
      " [0.8775925 ]\n",
      " [0.87995958]\n",
      " [0.88376445]\n",
      " [0.88776338]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012432442046701908, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88540673]\n",
      " [0.88016748]\n",
      " [0.87766033]\n",
      " [0.8775925 ]\n",
      " [0.87995958]\n",
      " [0.88376445]\n",
      " [0.88776338]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8840744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050351232290267944, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88016748]\n",
      " [0.87766033]\n",
      " [0.8775925 ]\n",
      " [0.87995958]\n",
      " [0.88376445]\n",
      " [0.88776338]\n",
      " [0.84889578]\n",
      " [0.88407439]] | y: 0.8550949244478885 | Predicción actual: [[0.8813165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010733977891504765, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87766033]\n",
      " [0.8775925 ]\n",
      " [0.87995958]\n",
      " [0.88376445]\n",
      " [0.88776338]\n",
      " [0.84889578]\n",
      " [0.88407439]\n",
      " [0.88131648]] | y: 0.8752421542037967 | Predicción actual: [[0.8800771]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011052595218643546, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8775925 ]\n",
      " [0.87995958]\n",
      " [0.88376445]\n",
      " [0.88776338]\n",
      " [0.84889578]\n",
      " [0.88407439]\n",
      " [0.88131648]\n",
      " [0.88007712]] | y: 0.857032158078264 | Predicción actual: [[0.8795913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006238757632672787, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87995958]\n",
      " [0.88376445]\n",
      " [0.88776338]\n",
      " [0.84889578]\n",
      " [0.88407439]\n",
      " [0.88131648]\n",
      " [0.88007712]\n",
      " [0.87959129]] | y: 0.8500581170089112 | Predicción actual: [[0.8790862]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008912363555282354, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88376445]\n",
      " [0.88776338]\n",
      " [0.84889578]\n",
      " [0.88407439]\n",
      " [0.88131648]\n",
      " [0.88007712]\n",
      " [0.87959129]\n",
      " [0.8790862 ]] | y: 0.8426966292134832 | Predicción actual: [[0.8778317]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00742358760908246, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88776338]\n",
      " [0.84889578]\n",
      " [0.88407439]\n",
      " [0.88131648]\n",
      " [0.88007712]\n",
      " [0.87959129]\n",
      " [0.8790862 ]\n",
      " [0.8778317 ]] | y: 0.8229368461836497 | Predicción actual: [[0.8752113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.414731377735734e-05, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.88407439]\n",
      " [0.88131648]\n",
      " [0.88007712]\n",
      " [0.87959129]\n",
      " [0.8790862 ]\n",
      " [0.8778317 ]\n",
      " [0.8752113 ]] | y: 0.7745060054242543 | Predicción actual: [[0.8713109]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018672920996323228, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88407439]\n",
      " [0.88131648]\n",
      " [0.88007712]\n",
      " [0.87959129]\n",
      " [0.8790862 ]\n",
      " [0.8778317 ]\n",
      " [0.8752113 ]\n",
      " [0.87131089]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001664437004365027, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88131648]\n",
      " [0.88007712]\n",
      " [0.87959129]\n",
      " [0.8790862 ]\n",
      " [0.8778317 ]\n",
      " [0.8752113 ]\n",
      " [0.87131089]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8766322]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006389311049133539, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88007712]\n",
      " [0.87959129]\n",
      " [0.8790862 ]\n",
      " [0.8778317 ]\n",
      " [0.8752113 ]\n",
      " [0.87131089]\n",
      " [0.78419217]\n",
      " [0.87663221]] | y: 0.854320030995738 | Predicción actual: [[0.8735929]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018241548677906394, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87959129]\n",
      " [0.8790862 ]\n",
      " [0.8778317 ]\n",
      " [0.8752113 ]\n",
      " [0.87131089]\n",
      " [0.78419217]\n",
      " [0.87663221]\n",
      " [0.87359291]] | y: 0.8368849283223556 | Predicción actual: [[0.86967254]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001715975464321673, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8790862 ]\n",
      " [0.8778317 ]\n",
      " [0.8752113 ]\n",
      " [0.87131089]\n",
      " [0.78419217]\n",
      " [0.87663221]\n",
      " [0.87359291]\n",
      " [0.86967254]] | y: 0.8299108872530028 | Predicción actual: [[0.8648962]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017805305542424321, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8778317 ]\n",
      " [0.8752113 ]\n",
      " [0.87131089]\n",
      " [0.78419217]\n",
      " [0.87663221]\n",
      " [0.87359291]\n",
      " [0.86967254]\n",
      " [0.86489618]] | y: 0.887253002712127 | Predicción actual: [[0.8592414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011009851470589638, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8752113 ]\n",
      " [0.87131089]\n",
      " [0.78419217]\n",
      " [0.87663221]\n",
      " [0.87359291]\n",
      " [0.86967254]\n",
      " [0.86489618]\n",
      " [0.85924143]] | y: 0.8597442851607902 | Predicción actual: [[0.85342324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03559136763215065, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87131089]\n",
      " [0.78419217]\n",
      " [0.87663221]\n",
      " [0.87359291]\n",
      " [0.86967254]\n",
      " [0.86489618]\n",
      " [0.85924143]\n",
      " [0.85342324]] | y: 0.8395970554048819 | Predicción actual: [[0.8481557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002718192699830979, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.87663221]\n",
      " [0.87359291]\n",
      " [0.86967254]\n",
      " [0.86489618]\n",
      " [0.85924143]\n",
      " [0.85342324]\n",
      " [0.84815568]] | y: 0.7838047268500579 | Predicción actual: [[0.8437512]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029875747859477997, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87663221]\n",
      " [0.87359291]\n",
      " [0.86967254]\n",
      " [0.86489618]\n",
      " [0.85924143]\n",
      " [0.85342324]\n",
      " [0.84815568]\n",
      " [0.84375119]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.237454307556618e-05, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87359291]\n",
      " [0.86967254]\n",
      " [0.86489618]\n",
      " [0.85924143]\n",
      " [0.85342324]\n",
      " [0.84815568]\n",
      " [0.84375119]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8610524]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009337288211099803, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86967254]\n",
      " [0.86489618]\n",
      " [0.85924143]\n",
      " [0.85342324]\n",
      " [0.84815568]\n",
      " [0.84375119]\n",
      " [0.81828749]\n",
      " [0.86105239]] | y: 0.7605579232855482 | Predicción actual: [[0.8562165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1120588406920433, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86489618]\n",
      " [0.85924143]\n",
      " [0.85342324]\n",
      " [0.84815568]\n",
      " [0.84375119]\n",
      " [0.81828749]\n",
      " [0.86105239]\n",
      " [0.85621649]] | y: 0.7915536613715615 | Predicción actual: [[0.850444]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0057311286218464375, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85924143]\n",
      " [0.85342324]\n",
      " [0.84815568]\n",
      " [0.84375119]\n",
      " [0.81828749]\n",
      " [0.86105239]\n",
      " [0.85621649]\n",
      " [0.85044402]] | y: 0.7686943045331267 | Predicción actual: [[0.84530765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052977245301008224, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85342324]\n",
      " [0.84815568]\n",
      " [0.84375119]\n",
      " [0.81828749]\n",
      " [0.86105239]\n",
      " [0.85621649]\n",
      " [0.85044402]\n",
      " [0.84530765]] | y: 0.7686943045331267 | Predicción actual: [[0.8406929]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03264953941106796, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84815568]\n",
      " [0.84375119]\n",
      " [0.81828749]\n",
      " [0.86105239]\n",
      " [0.85621649]\n",
      " [0.85044402]\n",
      " [0.84530765]\n",
      " [0.84069288]] | y: 0.7989151491669895 | Predicción actual: [[0.8371113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024421948473900557, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84375119]\n",
      " [0.81828749]\n",
      " [0.86105239]\n",
      " [0.85621649]\n",
      " [0.85044402]\n",
      " [0.84530765]\n",
      " [0.84069288]\n",
      " [0.83711129]] | y: 0.7900038744672608 | Predicción actual: [[0.83492726]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010142731480300426, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.86105239]\n",
      " [0.85621649]\n",
      " [0.85044402]\n",
      " [0.84530765]\n",
      " [0.84069288]\n",
      " [0.83711129]\n",
      " [0.83492726]] | y: 0.760170476559473 | Predicción actual: [[0.8341423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02229359932243824, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86105239]\n",
      " [0.85621649]\n",
      " [0.85044402]\n",
      " [0.84530765]\n",
      " [0.84069288]\n",
      " [0.83711129]\n",
      " [0.83492726]\n",
      " [0.83414233]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05116824060678482, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85621649]\n",
      " [0.85044402]\n",
      " [0.84530765]\n",
      " [0.84069288]\n",
      " [0.83711129]\n",
      " [0.83492726]\n",
      " [0.83414233]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.83456767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0179392471909523, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85044402]\n",
      " [0.84530765]\n",
      " [0.84069288]\n",
      " [0.83711129]\n",
      " [0.83492726]\n",
      " [0.83414233]\n",
      " [0.68539326]\n",
      " [0.83456767]] | y: 0.6648585819449826 | Predicción actual: [[0.826847]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009693530388176441, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84530765]\n",
      " [0.84069288]\n",
      " [0.83711129]\n",
      " [0.83492726]\n",
      " [0.83414233]\n",
      " [0.68539326]\n",
      " [0.83456767]\n",
      " [0.82684702]] | y: 0.7078651685393258 | Predicción actual: [[0.8183765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005401493050158024, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84069288]\n",
      " [0.83711129]\n",
      " [0.83492726]\n",
      " [0.83414233]\n",
      " [0.68539326]\n",
      " [0.83456767]\n",
      " [0.82684702]\n",
      " [0.81837648]] | y: 0.6648585819449826 | Predicción actual: [[0.80926585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042419832199811935, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83711129]\n",
      " [0.83492726]\n",
      " [0.83414233]\n",
      " [0.68539326]\n",
      " [0.83456767]\n",
      " [0.82684702]\n",
      " [0.81837648]\n",
      " [0.80926585]] | y: 0.7113521890740022 | Predicción actual: [[0.7994408]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003665291878860444, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83492726]\n",
      " [0.83414233]\n",
      " [0.68539326]\n",
      " [0.83456767]\n",
      " [0.82684702]\n",
      " [0.81837648]\n",
      " [0.80926585]\n",
      " [0.7994408 ]] | y: 0.6772568771793879 | Predicción actual: [[0.78935355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0063789766281843185, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83414233]\n",
      " [0.68539326]\n",
      " [0.83456767]\n",
      " [0.82684702]\n",
      " [0.81837648]\n",
      " [0.80926585]\n",
      " [0.7994408 ]\n",
      " [0.78935355]] | y: 0.7621077101898488 | Predicción actual: [[0.77879333]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013641907833516598, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.83456767]\n",
      " [0.82684702]\n",
      " [0.81837648]\n",
      " [0.80926585]\n",
      " [0.7994408 ]\n",
      " [0.78935355]\n",
      " [0.77879333]] | y: 0.8070515304145678 | Predicción actual: [[0.7674724]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001971617341041565, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83456767]\n",
      " [0.82684702]\n",
      " [0.81837648]\n",
      " [0.80926585]\n",
      " [0.7994408 ]\n",
      " [0.78935355]\n",
      " [0.77879333]\n",
      " [0.76747239]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004624880093615502, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82684702]\n",
      " [0.81837648]\n",
      " [0.80926585]\n",
      " [0.7994408 ]\n",
      " [0.78935355]\n",
      " [0.77879333]\n",
      " [0.76747239]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7893175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005745069938711822, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81837648]\n",
      " [0.80926585]\n",
      " [0.7994408 ]\n",
      " [0.78935355]\n",
      " [0.77879333]\n",
      " [0.76747239]\n",
      " [0.81518791]\n",
      " [0.78931749]] | y: 0.9597055404881829 | Predicción actual: [[0.7807741]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047877565026283264, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80926585]\n",
      " [0.7994408 ]\n",
      " [0.78935355]\n",
      " [0.77879333]\n",
      " [0.76747239]\n",
      " [0.81518791]\n",
      " [0.78931749]\n",
      " [0.78077412]] | y: 0.9643549012010848 | Predicción actual: [[0.77352345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04218846932053566, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7994408 ]\n",
      " [0.78935355]\n",
      " [0.77879333]\n",
      " [0.76747239]\n",
      " [0.81518791]\n",
      " [0.78931749]\n",
      " [0.78077412]\n",
      " [0.77352345]] | y: 0.8880278961642774 | Predicción actual: [[0.76798385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03216069936752319, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78935355]\n",
      " [0.77879333]\n",
      " [0.76747239]\n",
      " [0.81518791]\n",
      " [0.78931749]\n",
      " [0.78077412]\n",
      " [0.77352345]\n",
      " [0.76798385]] | y: 0.8926772568771792 | Predicción actual: [[0.76451993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040346235036849976, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77879333]\n",
      " [0.76747239]\n",
      " [0.81518791]\n",
      " [0.78931749]\n",
      " [0.78077412]\n",
      " [0.77352345]\n",
      " [0.76798385]\n",
      " [0.76451993]] | y: 0.8752421542037967 | Predicción actual: [[0.76340604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017354054376482964, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76747239]\n",
      " [0.81518791]\n",
      " [0.78931749]\n",
      " [0.78077412]\n",
      " [0.77352345]\n",
      " [0.76798385]\n",
      " [0.76451993]\n",
      " [0.76340604]] | y: 0.8508330104610615 | Predicción actual: [[0.76482713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030354071408510208, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78931749]\n",
      " [0.78077412]\n",
      " [0.77352345]\n",
      " [0.76798385]\n",
      " [0.76451993]\n",
      " [0.76340604]\n",
      " [0.76482713]] | y: 0.8488957768306855 | Predicción actual: [[0.7691585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021760938689112663, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78931749]\n",
      " [0.78077412]\n",
      " [0.77352345]\n",
      " [0.76798385]\n",
      " [0.76451993]\n",
      " [0.76340604]\n",
      " [0.76482713]\n",
      " [0.76915848]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07968544960021973, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78077412]\n",
      " [0.77352345]\n",
      " [0.76798385]\n",
      " [0.76451993]\n",
      " [0.76340604]\n",
      " [0.76482713]\n",
      " [0.76915848]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.75698495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05826685577630997, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77352345]\n",
      " [0.76798385]\n",
      " [0.76451993]\n",
      " [0.76340604]\n",
      " [0.76482713]\n",
      " [0.76915848]\n",
      " [0.96241767]\n",
      " [0.75698495]] | y: 0.9407206509104997 | Predicción actual: [[0.75786704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033657681196928024, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76798385]\n",
      " [0.76451993]\n",
      " [0.76340604]\n",
      " [0.76482713]\n",
      " [0.76915848]\n",
      " [0.96241767]\n",
      " [0.75698495]\n",
      " [0.75786704]] | y: 0.9724912824486633 | Predicción actual: [[0.7621822]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038302943110466, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76451993]\n",
      " [0.76340604]\n",
      " [0.76482713]\n",
      " [0.76915848]\n",
      " [0.96241767]\n",
      " [0.75698495]\n",
      " [0.75786704]\n",
      " [0.76218218]] | y: 0.9969004261913985 | Predicción actual: [[0.7695719]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01883535459637642, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76340604]\n",
      " [0.76482713]\n",
      " [0.76915848]\n",
      " [0.96241767]\n",
      " [0.75698495]\n",
      " [0.75786704]\n",
      " [0.76218218]\n",
      " [0.7695719 ]] | y: 0.951181712514529 | Predicción actual: [[0.7791959]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07871997356414795, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76482713]\n",
      " [0.76915848]\n",
      " [0.96241767]\n",
      " [0.75698495]\n",
      " [0.75786704]\n",
      " [0.76218218]\n",
      " [0.7695719 ]\n",
      " [0.7791959 ]] | y: 0.8957768306857805 | Predicción actual: [[0.79020727]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013578635407611728, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76915848]\n",
      " [0.96241767]\n",
      " [0.75698495]\n",
      " [0.75786704]\n",
      " [0.76218218]\n",
      " [0.7695719 ]\n",
      " [0.7791959 ]\n",
      " [0.79020727]] | y: 0.8814413018209997 | Predicción actual: [[0.8009783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.6406494978582487e-05, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.75698495]\n",
      " [0.75786704]\n",
      " [0.76218218]\n",
      " [0.7695719 ]\n",
      " [0.7791959 ]\n",
      " [0.79020727]\n",
      " [0.8009783 ]] | y: 0.9170864006199149 | Predicción actual: [[0.81034994]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005410187877714634, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75698495]\n",
      " [0.75786704]\n",
      " [0.76218218]\n",
      " [0.7695719 ]\n",
      " [0.7791959 ]\n",
      " [0.79020727]\n",
      " [0.8009783 ]\n",
      " [0.81034994]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0895046591758728, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75786704]\n",
      " [0.76218218]\n",
      " [0.7695719 ]\n",
      " [0.7791959 ]\n",
      " [0.79020727]\n",
      " [0.8009783 ]\n",
      " [0.81034994]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7701103]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0297151617705822, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76218218]\n",
      " [0.7695719 ]\n",
      " [0.7791959 ]\n",
      " [0.79020727]\n",
      " [0.8009783 ]\n",
      " [0.81034994]\n",
      " [0.91979853]\n",
      " [0.77011031]] | y: 0.9682293684618366 | Predicción actual: [[0.78042394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061502858996391296, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7695719 ]\n",
      " [0.7791959 ]\n",
      " [0.79020727]\n",
      " [0.8009783 ]\n",
      " [0.81034994]\n",
      " [0.91979853]\n",
      " [0.77011031]\n",
      " [0.78042394]] | y: 0.9577683068578069 | Predicción actual: [[0.7924337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10255176573991776, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20668885]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017923790961503983, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20668885]] | y: 0.10422316931421921 | Predicción actual: [[0.19123924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006844100542366505, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20668885]\n",
      " [0.19123924]] | y: 0.15420379697791559 | Predicción actual: [[0.19563751]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000757917296141386, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20668885]\n",
      " [0.19123924]\n",
      " [0.19563751]] | y: 0.1557535838822161 | Predicción actual: [[0.20751487]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025203272234648466, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20668885]\n",
      " [0.19123924]\n",
      " [0.19563751]\n",
      " [0.20751487]] | y: 0.12553273924835334 | Predicción actual: [[0.22062482]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007850075140595436, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20668885]\n",
      " [0.19123924]\n",
      " [0.19563751]\n",
      " [0.20751487]\n",
      " [0.22062482]] | y: 0.1456799690042619 | Predicción actual: [[0.23113734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007644739933311939, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20668885]\n",
      " [0.19123924]\n",
      " [0.19563751]\n",
      " [0.20751487]\n",
      " [0.22062482]\n",
      " [0.23113734]] | y: 0.1464548624564122 | Predicción actual: [[0.25339124]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01565149426460266, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20668885]\n",
      " [0.19123924]\n",
      " [0.19563751]\n",
      " [0.20751487]\n",
      " [0.22062482]\n",
      " [0.23113734]\n",
      " [0.25339124]] | y: 0.1960480433940332 | Predicción actual: [[0.2808229]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0041041746735572815, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20668885]\n",
      " [0.19123924]\n",
      " [0.19563751]\n",
      " [0.20751487]\n",
      " [0.22062482]\n",
      " [0.23113734]\n",
      " [0.25339124]\n",
      " [0.2808229 ]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006434050388634205, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19123924]\n",
      " [0.19563751]\n",
      " [0.20751487]\n",
      " [0.22062482]\n",
      " [0.23113734]\n",
      " [0.25339124]\n",
      " [0.2808229 ]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.31637093]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01954040676355362, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19563751]\n",
      " [0.20751487]\n",
      " [0.22062482]\n",
      " [0.23113734]\n",
      " [0.25339124]\n",
      " [0.2808229 ]\n",
      " [0.2305308 ]\n",
      " [0.31637093]] | y: 0.211933359163115 | Predicción actual: [[0.32403746]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02303595468401909, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20751487]\n",
      " [0.22062482]\n",
      " [0.23113734]\n",
      " [0.25339124]\n",
      " [0.2808229 ]\n",
      " [0.2305308 ]\n",
      " [0.31637093]\n",
      " [0.32403746]] | y: 0.2072839984502131 | Predicción actual: [[0.33360365]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012315073050558567, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22062482]\n",
      " [0.23113734]\n",
      " [0.25339124]\n",
      " [0.2808229 ]\n",
      " [0.2305308 ]\n",
      " [0.31637093]\n",
      " [0.32403746]\n",
      " [0.33360365]] | y: 0.19294846958543205 | Predicción actual: [[0.34383193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03056258149445057, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.23113734]\n",
      " [0.25339124]\n",
      " [0.2808229 ]\n",
      " [0.2305308 ]\n",
      " [0.31637093]\n",
      " [0.32403746]\n",
      " [0.33360365]\n",
      " [0.34383193]] | y: 0.19682293684618352 | Predicción actual: [[0.3546005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04764972999691963, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25339124]\n",
      " [0.2808229 ]\n",
      " [0.2305308 ]\n",
      " [0.31637093]\n",
      " [0.32403746]\n",
      " [0.33360365]\n",
      " [0.34383193]\n",
      " [0.35460049]] | y: 0.21425803951956607 | Predicción actual: [[0.36661667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04029926657676697, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2808229 ]\n",
      " [0.2305308 ]\n",
      " [0.31637093]\n",
      " [0.32403746]\n",
      " [0.33360365]\n",
      " [0.34383193]\n",
      " [0.35460049]\n",
      " [0.36661667]] | y: 0.18132506780317698 | Predicción actual: [[0.37718517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035727646201848984, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31637093]\n",
      " [0.32403746]\n",
      " [0.33360365]\n",
      " [0.34383193]\n",
      " [0.35460049]\n",
      " [0.36661667]\n",
      " [0.37718517]] | y: 0.17512592018597434 | Predicción actual: [[0.3847274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05240925773978233, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31637093]\n",
      " [0.32403746]\n",
      " [0.33360365]\n",
      " [0.34383193]\n",
      " [0.35460049]\n",
      " [0.36661667]\n",
      " [0.37718517]\n",
      " [0.38472739]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08218160271644592, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32403746]\n",
      " [0.33360365]\n",
      " [0.34383193]\n",
      " [0.35460049]\n",
      " [0.36661667]\n",
      " [0.37718517]\n",
      " [0.38472739]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.41337943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09469343721866608, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33360365]\n",
      " [0.34383193]\n",
      " [0.35460049]\n",
      " [0.36661667]\n",
      " [0.37718517]\n",
      " [0.38472739]\n",
      " [0.14800465]\n",
      " [0.41337943]] | y: 0.19217357613328173 | Predicción actual: [[0.41749105]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07252811640501022, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34383193]\n",
      " [0.35460049]\n",
      " [0.36661667]\n",
      " [0.37718517]\n",
      " [0.38472739]\n",
      " [0.14800465]\n",
      " [0.41337943]\n",
      " [0.41749105]] | y: 0.1859744285160791 | Predicción actual: [[0.41972205]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04335476830601692, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35460049]\n",
      " [0.36661667]\n",
      " [0.37718517]\n",
      " [0.38472739]\n",
      " [0.14800465]\n",
      " [0.41337943]\n",
      " [0.41749105]\n",
      " [0.41972205]] | y: 0.26695079426578844 | Predicción actual: [[0.42016932]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02236926555633545, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36661667]\n",
      " [0.37718517]\n",
      " [0.38472739]\n",
      " [0.14800465]\n",
      " [0.41337943]\n",
      " [0.41749105]\n",
      " [0.41972205]\n",
      " [0.42016932]] | y: 0.2925222781867493 | Predicción actual: [[0.41906297]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009087502025067806, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37718517]\n",
      " [0.38472739]\n",
      " [0.14800465]\n",
      " [0.41337943]\n",
      " [0.41749105]\n",
      " [0.41972205]\n",
      " [0.42016932]\n",
      " [0.41906297]] | y: 0.3177063153816349 | Predicción actual: [[0.4164799]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01180187612771988, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38472739]\n",
      " [0.14800465]\n",
      " [0.41337943]\n",
      " [0.41749105]\n",
      " [0.41972205]\n",
      " [0.42016932]\n",
      " [0.41906297]\n",
      " [0.41647989]] | y: 0.31266950794265785 | Predicción actual: [[0.4130434]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005725100636482239, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.41337943]\n",
      " [0.41749105]\n",
      " [0.41972205]\n",
      " [0.42016932]\n",
      " [0.41906297]\n",
      " [0.41647989]\n",
      " [0.41304341]] | y: 0.2890352576520729 | Predicción actual: [[0.4097589]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014715926721692085, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41337943]\n",
      " [0.41749105]\n",
      " [0.41972205]\n",
      " [0.42016932]\n",
      " [0.41906297]\n",
      " [0.41647989]\n",
      " [0.41304341]\n",
      " [0.4097589 ]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05234759673476219, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41749105]\n",
      " [0.41972205]\n",
      " [0.42016932]\n",
      " [0.41906297]\n",
      " [0.41647989]\n",
      " [0.41304341]\n",
      " [0.4097589 ]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.46725523]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02657433971762657, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41972205]\n",
      " [0.42016932]\n",
      " [0.41906297]\n",
      " [0.41647989]\n",
      " [0.41304341]\n",
      " [0.4097589 ]\n",
      " [0.28283611]\n",
      " [0.46725523]] | y: 0.2758620689655173 | Predicción actual: [[0.4648097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030043374747037888, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.42016932]\n",
      " [0.41906297]\n",
      " [0.41647989]\n",
      " [0.41304341]\n",
      " [0.4097589 ]\n",
      " [0.28283611]\n",
      " [0.46725523]\n",
      " [0.46480969]] | y: 0.2746997287872917 | Predicción actual: [[0.46120033]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.057038772851228714, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41906297]\n",
      " [0.41647989]\n",
      " [0.41304341]\n",
      " [0.4097589 ]\n",
      " [0.28283611]\n",
      " [0.46725523]\n",
      " [0.46480969]\n",
      " [0.46120033]] | y: 0.275474622239442 | Predicción actual: [[0.45730427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03023156337440014, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41647989]\n",
      " [0.41304341]\n",
      " [0.4097589 ]\n",
      " [0.28283611]\n",
      " [0.46725523]\n",
      " [0.46480969]\n",
      " [0.46120033]\n",
      " [0.45730427]] | y: 0.3347539713289423 | Predicción actual: [[0.45417196]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01687445305287838, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41304341]\n",
      " [0.4097589 ]\n",
      " [0.28283611]\n",
      " [0.46725523]\n",
      " [0.46480969]\n",
      " [0.46120033]\n",
      " [0.45730427]\n",
      " [0.45417196]] | y: 0.35567609453700116 | Predicción actual: [[0.45278552]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00019550460274331272, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4097589 ]\n",
      " [0.28283611]\n",
      " [0.46725523]\n",
      " [0.46480969]\n",
      " [0.46120033]\n",
      " [0.45730427]\n",
      " [0.45417196]\n",
      " [0.45278552]] | y: 0.3366912049593181 | Predicción actual: [[0.45393234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009833104908466339, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.46725523]\n",
      " [0.46480969]\n",
      " [0.46120033]\n",
      " [0.45730427]\n",
      " [0.45417196]\n",
      " [0.45278552]\n",
      " [0.45393234]] | y: 0.3335916311507167 | Predicción actual: [[0.4579012]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02229948155581951, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46725523]\n",
      " [0.46480969]\n",
      " [0.46120033]\n",
      " [0.45730427]\n",
      " [0.45417196]\n",
      " [0.45278552]\n",
      " [0.45393234]\n",
      " [0.45790121]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06666623800992966, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46480969]\n",
      " [0.46120033]\n",
      " [0.45730427]\n",
      " [0.45417196]\n",
      " [0.45278552]\n",
      " [0.45393234]\n",
      " [0.45790121]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.49296236]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01604584790766239, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46120033]\n",
      " [0.45730427]\n",
      " [0.45417196]\n",
      " [0.45278552]\n",
      " [0.45393234]\n",
      " [0.45790121]\n",
      " [0.3847346 ]\n",
      " [0.49296236]] | y: 0.5962805114296785 | Predicción actual: [[0.4894384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049856998026371, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45730427]\n",
      " [0.45417196]\n",
      " [0.45278552]\n",
      " [0.45393234]\n",
      " [0.45790121]\n",
      " [0.3847346 ]\n",
      " [0.49296236]\n",
      " [0.48943841]] | y: 0.574583494769469 | Predicción actual: [[0.48660454]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021033525466918945, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45417196]\n",
      " [0.45278552]\n",
      " [0.45393234]\n",
      " [0.45790121]\n",
      " [0.3847346 ]\n",
      " [0.49296236]\n",
      " [0.48943841]\n",
      " [0.48660454]] | y: 0.6063541263076326 | Predicción actual: [[0.48497522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019534103572368622, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45278552]\n",
      " [0.45393234]\n",
      " [0.45790121]\n",
      " [0.3847346 ]\n",
      " [0.49296236]\n",
      " [0.48943841]\n",
      " [0.48660454]\n",
      " [0.48497522]] | y: 0.5846571096474236 | Predicción actual: [[0.48484436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004263971466571093, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45393234]\n",
      " [0.45790121]\n",
      " [0.3847346 ]\n",
      " [0.49296236]\n",
      " [0.48943841]\n",
      " [0.48660454]\n",
      " [0.48497522]\n",
      " [0.48484436]] | y: 0.5687717938783416 | Predicción actual: [[0.48613456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009211483411490917, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45790121]\n",
      " [0.3847346 ]\n",
      " [0.49296236]\n",
      " [0.48943841]\n",
      " [0.48660454]\n",
      " [0.48497522]\n",
      " [0.48484436]\n",
      " [0.48613456]] | y: 0.6427741185586981 | Predicción actual: [[0.48849583]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0857073962688446, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.49296236]\n",
      " [0.48943841]\n",
      " [0.48660454]\n",
      " [0.48497522]\n",
      " [0.48484436]\n",
      " [0.48613456]\n",
      " [0.48849583]] | y: 0.6617590081363811 | Predicción actual: [[0.4914132]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023008158430457115, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49296236]\n",
      " [0.48943841]\n",
      " [0.48660454]\n",
      " [0.48497522]\n",
      " [0.48484436]\n",
      " [0.48613456]\n",
      " [0.48849583]\n",
      " [0.49141321]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01508172694593668, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48943841]\n",
      " [0.48660454]\n",
      " [0.48497522]\n",
      " [0.48484436]\n",
      " [0.48613456]\n",
      " [0.48849583]\n",
      " [0.49141321]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.51469356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032919175922870636, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48660454]\n",
      " [0.48497522]\n",
      " [0.48484436]\n",
      " [0.48613456]\n",
      " [0.48849583]\n",
      " [0.49141321]\n",
      " [0.67299496]\n",
      " [0.51469356]] | y: 0.703990701278574 | Predicción actual: [[0.5171849]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03655288740992546, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48497522]\n",
      " [0.48484436]\n",
      " [0.48613456]\n",
      " [0.48849583]\n",
      " [0.49141321]\n",
      " [0.67299496]\n",
      " [0.51469356]\n",
      " [0.51718491]] | y: 0.7272375048430839 | Predicción actual: [[0.52254796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008119813166558743, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48484436]\n",
      " [0.48613456]\n",
      " [0.48849583]\n",
      " [0.49141321]\n",
      " [0.67299496]\n",
      " [0.51469356]\n",
      " [0.51718491]\n",
      " [0.52254796]] | y: 0.722588144130182 | Predicción actual: [[0.530631]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02465684339404106, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48613456]\n",
      " [0.48849583]\n",
      " [0.49141321]\n",
      " [0.67299496]\n",
      " [0.51469356]\n",
      " [0.51718491]\n",
      " [0.52254796]\n",
      " [0.53063101]] | y: 0.771793878341728 | Predicción actual: [[0.54111135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06951434165239334, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48849583]\n",
      " [0.49141321]\n",
      " [0.67299496]\n",
      " [0.51469356]\n",
      " [0.51718491]\n",
      " [0.52254796]\n",
      " [0.53063101]\n",
      " [0.54111135]] | y: 0.7245253777605578 | Predicción actual: [[0.5535677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08395838737487793, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49141321]\n",
      " [0.67299496]\n",
      " [0.51469356]\n",
      " [0.51718491]\n",
      " [0.52254796]\n",
      " [0.53063101]\n",
      " [0.54111135]\n",
      " [0.55356771]] | y: 0.6710577295621851 | Predicción actual: [[0.5675243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014847803860902786, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.51469356]\n",
      " [0.51718491]\n",
      " [0.52254796]\n",
      " [0.53063101]\n",
      " [0.54111135]\n",
      " [0.55356771]\n",
      " [0.56752431]] | y: 0.6737698566447115 | Predicción actual: [[0.58256865]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01494697667658329, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51469356]\n",
      " [0.51718491]\n",
      " [0.52254796]\n",
      " [0.53063101]\n",
      " [0.54111135]\n",
      " [0.55356771]\n",
      " [0.56752431]\n",
      " [0.58256865]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043870601803064346, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51718491]\n",
      " [0.52254796]\n",
      " [0.53063101]\n",
      " [0.54111135]\n",
      " [0.55356771]\n",
      " [0.56752431]\n",
      " [0.58256865]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5577307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07126908749341965, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52254796]\n",
      " [0.53063101]\n",
      " [0.54111135]\n",
      " [0.55356771]\n",
      " [0.56752431]\n",
      " [0.58256865]\n",
      " [0.71445176]\n",
      " [0.55773067]] | y: 0.722588144130182 | Predicción actual: [[0.5682068]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013249525800347328, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53063101]\n",
      " [0.54111135]\n",
      " [0.55356771]\n",
      " [0.56752431]\n",
      " [0.58256865]\n",
      " [0.71445176]\n",
      " [0.55773067]\n",
      " [0.56820679]] | y: 0.6993413405656723 | Predicción actual: [[0.58069116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012153773568570614, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54111135]\n",
      " [0.55356771]\n",
      " [0.56752431]\n",
      " [0.58256865]\n",
      " [0.71445176]\n",
      " [0.55773067]\n",
      " [0.56820679]\n",
      " [0.58069116]] | y: 0.7373111197210385 | Predicción actual: [[0.59416825]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030060952994972467, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55356771]\n",
      " [0.56752431]\n",
      " [0.58256865]\n",
      " [0.71445176]\n",
      " [0.55773067]\n",
      " [0.56820679]\n",
      " [0.58069116]\n",
      " [0.59416825]] | y: 0.7214258039519565 | Predicción actual: [[0.60744745]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027706706896424294, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56752431]\n",
      " [0.58256865]\n",
      " [0.71445176]\n",
      " [0.55773067]\n",
      " [0.56820679]\n",
      " [0.58069116]\n",
      " [0.59416825]\n",
      " [0.60744745]] | y: 0.7187136768694304 | Predicción actual: [[0.61939174]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00466086994856596, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58256865]\n",
      " [0.71445176]\n",
      " [0.55773067]\n",
      " [0.56820679]\n",
      " [0.58069116]\n",
      " [0.59416825]\n",
      " [0.60744745]\n",
      " [0.61939174]] | y: 0.6741573033707864 | Predicción actual: [[0.62901366]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009123903699219227, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55773067]\n",
      " [0.56820679]\n",
      " [0.58069116]\n",
      " [0.59416825]\n",
      " [0.60744745]\n",
      " [0.61939174]\n",
      " [0.62901366]] | y: 0.698566447113522 | Predicción actual: [[0.63551414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00015754729975014925, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55773067]\n",
      " [0.56820679]\n",
      " [0.58069116]\n",
      " [0.59416825]\n",
      " [0.60744745]\n",
      " [0.61939174]\n",
      " [0.62901366]\n",
      " [0.63551414]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014176896773278713, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56820679]\n",
      " [0.58069116]\n",
      " [0.59416825]\n",
      " [0.60744745]\n",
      " [0.61939174]\n",
      " [0.62901366]\n",
      " [0.63551414]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.61733985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008772630244493484, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58069116]\n",
      " [0.59416825]\n",
      " [0.60744745]\n",
      " [0.61939174]\n",
      " [0.62901366]\n",
      " [0.63551414]\n",
      " [0.72103836]\n",
      " [0.61733985]] | y: 0.7562960092987214 | Predicción actual: [[0.6299244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05158513784408569, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59416825]\n",
      " [0.60744745]\n",
      " [0.61939174]\n",
      " [0.62901366]\n",
      " [0.63551414]\n",
      " [0.72103836]\n",
      " [0.61733985]\n",
      " [0.62992442]] | y: 0.8275862068965516 | Predicción actual: [[0.6424947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013745835050940514, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60744745]\n",
      " [0.61939174]\n",
      " [0.62901366]\n",
      " [0.63551414]\n",
      " [0.72103836]\n",
      " [0.61733985]\n",
      " [0.62992442]\n",
      " [0.64249468]] | y: 0.8388221619527314 | Predicción actual: [[0.65414965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09049994498491287, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61939174]\n",
      " [0.62901366]\n",
      " [0.63551414]\n",
      " [0.72103836]\n",
      " [0.61733985]\n",
      " [0.62992442]\n",
      " [0.64249468]\n",
      " [0.65414965]] | y: 0.7942657884540876 | Predicción actual: [[0.66446346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003939939197152853, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62901366]\n",
      " [0.63551414]\n",
      " [0.72103836]\n",
      " [0.61733985]\n",
      " [0.62992442]\n",
      " [0.64249468]\n",
      " [0.65414965]\n",
      " [0.66446346]] | y: 0.7838047268500579 | Predicción actual: [[0.67304415]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006660896353423595, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63551414]\n",
      " [0.72103836]\n",
      " [0.61733985]\n",
      " [0.62992442]\n",
      " [0.64249468]\n",
      " [0.65414965]\n",
      " [0.66446346]\n",
      " [0.67304415]] | y: 0.7679194110809764 | Predicción actual: [[0.680167]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017378875985741615, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.61733985]\n",
      " [0.62992442]\n",
      " [0.64249468]\n",
      " [0.65414965]\n",
      " [0.66446346]\n",
      " [0.67304415]\n",
      " [0.68016702]] | y: 0.7845796203022084 | Predicción actual: [[0.686555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004861007444560528, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61733985]\n",
      " [0.62992442]\n",
      " [0.64249468]\n",
      " [0.65414965]\n",
      " [0.66446346]\n",
      " [0.67304415]\n",
      " [0.68016702]\n",
      " [0.68655503]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0684187263250351, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62992442]\n",
      " [0.64249468]\n",
      " [0.65414965]\n",
      " [0.66446346]\n",
      " [0.67304415]\n",
      " [0.68016702]\n",
      " [0.68655503]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6819623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03702268376946449, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64249468]\n",
      " [0.65414965]\n",
      " [0.66446346]\n",
      " [0.67304415]\n",
      " [0.68016702]\n",
      " [0.68655503]\n",
      " [0.87872917]\n",
      " [0.68196231]] | y: 0.8488957768306855 | Predicción actual: [[0.69589263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013475878164172173, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65414965]\n",
      " [0.66446346]\n",
      " [0.67304415]\n",
      " [0.68016702]\n",
      " [0.68655503]\n",
      " [0.87872917]\n",
      " [0.68196231]\n",
      " [0.69589263]] | y: 0.8182874854707476 | Predicción actual: [[0.71050984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05744501203298569, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66446346]\n",
      " [0.67304415]\n",
      " [0.68016702]\n",
      " [0.68655503]\n",
      " [0.87872917]\n",
      " [0.68196231]\n",
      " [0.69589263]\n",
      " [0.71050984]] | y: 0.8268113134444013 | Predicción actual: [[0.72570115]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006199368275702, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67304415]\n",
      " [0.68016702]\n",
      " [0.68655503]\n",
      " [0.87872917]\n",
      " [0.68196231]\n",
      " [0.69589263]\n",
      " [0.71050984]\n",
      " [0.72570115]] | y: 0.7853545137543589 | Predicción actual: [[0.741145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010984139516949654, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68016702]\n",
      " [0.68655503]\n",
      " [0.87872917]\n",
      " [0.68196231]\n",
      " [0.69589263]\n",
      " [0.71050984]\n",
      " [0.72570115]\n",
      " [0.74114501]] | y: 0.7892289810151103 | Predicción actual: [[0.75675344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00029457398341037333, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68655503]\n",
      " [0.87872917]\n",
      " [0.68196231]\n",
      " [0.69589263]\n",
      " [0.71050984]\n",
      " [0.72570115]\n",
      " [0.74114501]\n",
      " [0.75675344]] | y: 0.8341728012398295 | Predicción actual: [[0.77246916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017055248841643333, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.68196231]\n",
      " [0.69589263]\n",
      " [0.71050984]\n",
      " [0.72570115]\n",
      " [0.74114501]\n",
      " [0.75675344]\n",
      " [0.77246916]] | y: 0.8124757845796202 | Predicción actual: [[0.7884723]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004104061983525753, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68196231]\n",
      " [0.69589263]\n",
      " [0.71050984]\n",
      " [0.72570115]\n",
      " [0.74114501]\n",
      " [0.75675344]\n",
      " [0.77246916]\n",
      " [0.78847229]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007112464518286288, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69589263]\n",
      " [0.71050984]\n",
      " [0.72570115]\n",
      " [0.74114501]\n",
      " [0.75675344]\n",
      " [0.77246916]\n",
      " [0.78847229]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7626524]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.4453972552437335e-05, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71050984]\n",
      " [0.72570115]\n",
      " [0.74114501]\n",
      " [0.75675344]\n",
      " [0.77246916]\n",
      " [0.78847229]\n",
      " [0.80123983]\n",
      " [0.7626524 ]] | y: 0.793490895001937 | Predicción actual: [[0.7780354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003354330314323306, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72570115]\n",
      " [0.74114501]\n",
      " [0.75675344]\n",
      " [0.77246916]\n",
      " [0.78847229]\n",
      " [0.80123983]\n",
      " [0.7626524 ]\n",
      " [0.7780354 ]] | y: 0.760170476559473 | Predicción actual: [[0.7926078]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003353023203089833, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74114501]\n",
      " [0.75675344]\n",
      " [0.77246916]\n",
      " [0.78847229]\n",
      " [0.80123983]\n",
      " [0.7626524 ]\n",
      " [0.7780354 ]\n",
      " [0.79260778]] | y: 0.7353738860906625 | Predicción actual: [[0.80576575]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03241339325904846, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75675344]\n",
      " [0.77246916]\n",
      " [0.78847229]\n",
      " [0.80123983]\n",
      " [0.7626524 ]\n",
      " [0.7780354 ]\n",
      " [0.79260778]\n",
      " [0.80576575]] | y: 0.7101898488957767 | Predicción actual: [[0.8164638]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017371129244565964, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77246916]\n",
      " [0.78847229]\n",
      " [0.80123983]\n",
      " [0.7626524 ]\n",
      " [0.7780354 ]\n",
      " [0.79260778]\n",
      " [0.80576575]\n",
      " [0.81646383]] | y: 0.7121270825261525 | Predicción actual: [[0.8242914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05160753056406975, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78847229]\n",
      " [0.80123983]\n",
      " [0.7626524 ]\n",
      " [0.7780354 ]\n",
      " [0.79260778]\n",
      " [0.80576575]\n",
      " [0.81646383]\n",
      " [0.82429141]] | y: 0.7396358000774894 | Predicción actual: [[0.828617]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.477040652593132e-07, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.7626524 ]\n",
      " [0.7780354 ]\n",
      " [0.79260778]\n",
      " [0.80576575]\n",
      " [0.81646383]\n",
      " [0.82429141]\n",
      " [0.82861698]] | y: 0.7361487795428128 | Predicción actual: [[0.8295805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03966476768255234, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7626524 ]\n",
      " [0.7780354 ]\n",
      " [0.79260778]\n",
      " [0.80576575]\n",
      " [0.81646383]\n",
      " [0.82429141]\n",
      " [0.82861698]\n",
      " [0.82958049]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.033657241612672806, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7780354 ]\n",
      " [0.79260778]\n",
      " [0.80576575]\n",
      " [0.81646383]\n",
      " [0.82429141]\n",
      " [0.82861698]\n",
      " [0.82958049]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8378043]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015501193702220917, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79260778]\n",
      " [0.80576575]\n",
      " [0.81646383]\n",
      " [0.82429141]\n",
      " [0.82861698]\n",
      " [0.82958049]\n",
      " [0.66757071]\n",
      " [0.83780432]] | y: 0.696629213483146 | Predicción actual: [[0.8445207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036382675170898438, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80576575]\n",
      " [0.81646383]\n",
      " [0.82429141]\n",
      " [0.82861698]\n",
      " [0.82958049]\n",
      " [0.66757071]\n",
      " [0.83780432]\n",
      " [0.84452069]] | y: 0.6559473072452537 | Predicción actual: [[0.8476274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04867186024785042, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81646383]\n",
      " [0.82429141]\n",
      " [0.82861698]\n",
      " [0.82958049]\n",
      " [0.66757071]\n",
      " [0.83780432]\n",
      " [0.84452069]\n",
      " [0.8476274 ]] | y: 0.6788066640836885 | Predicción actual: [[0.8466656]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003599993360694498, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82429141]\n",
      " [0.82861698]\n",
      " [0.82958049]\n",
      " [0.66757071]\n",
      " [0.83780432]\n",
      " [0.84452069]\n",
      " [0.8476274 ]\n",
      " [0.84666562]] | y: 0.6760945370011622 | Predicción actual: [[0.8428397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055867888033390045, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82861698]\n",
      " [0.82958049]\n",
      " [0.66757071]\n",
      " [0.83780432]\n",
      " [0.84452069]\n",
      " [0.8476274 ]\n",
      " [0.84666562]\n",
      " [0.84283972]] | y: 0.7295621851995349 | Predicción actual: [[0.83670235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008066550362855196, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82958049]\n",
      " [0.66757071]\n",
      " [0.83780432]\n",
      " [0.84452069]\n",
      " [0.8476274 ]\n",
      " [0.84666562]\n",
      " [0.84283972]\n",
      " [0.83670235]] | y: 0.7012785741960481 | Predicción actual: [[0.83015484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025354836136102676, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.83780432]\n",
      " [0.84452069]\n",
      " [0.8476274 ]\n",
      " [0.84666562]\n",
      " [0.84283972]\n",
      " [0.83670235]\n",
      " [0.83015484]] | y: 0.767531964354901 | Predicción actual: [[0.8243569]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012473095208406448, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83780432]\n",
      " [0.84452069]\n",
      " [0.8476274 ]\n",
      " [0.84666562]\n",
      " [0.84283972]\n",
      " [0.83670235]\n",
      " [0.83015484]\n",
      " [0.82435691]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012684780173003674, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84452069]\n",
      " [0.8476274 ]\n",
      " [0.84666562]\n",
      " [0.84283972]\n",
      " [0.83670235]\n",
      " [0.83015484]\n",
      " [0.82435691]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.86902755]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022936716675758362, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8476274 ]\n",
      " [0.84666562]\n",
      " [0.84283972]\n",
      " [0.83670235]\n",
      " [0.83015484]\n",
      " [0.82435691]\n",
      " [0.75513367]\n",
      " [0.86902755]] | y: 0.7520340953118947 | Predicción actual: [[0.8646036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019717665389180183, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84666562]\n",
      " [0.84283972]\n",
      " [0.83670235]\n",
      " [0.83015484]\n",
      " [0.82435691]\n",
      " [0.75513367]\n",
      " [0.86902755]\n",
      " [0.86460358]] | y: 0.7098024021697016 | Predicción actual: [[0.8581906]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04789595678448677, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84283972]\n",
      " [0.83670235]\n",
      " [0.83015484]\n",
      " [0.82435691]\n",
      " [0.75513367]\n",
      " [0.86902755]\n",
      " [0.86460358]\n",
      " [0.8581906 ]] | y: 0.6904300658659435 | Predicción actual: [[0.85116744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021883979439735413, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83670235]\n",
      " [0.83015484]\n",
      " [0.82435691]\n",
      " [0.75513367]\n",
      " [0.86902755]\n",
      " [0.86460358]\n",
      " [0.8581906 ]\n",
      " [0.85116744]] | y: 0.7543587756683454 | Predicción actual: [[0.8451217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027088457136414945, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83015484]\n",
      " [0.82435691]\n",
      " [0.75513367]\n",
      " [0.86902755]\n",
      " [0.86460358]\n",
      " [0.8581906 ]\n",
      " [0.85116744]\n",
      " [0.84512168]] | y: 0.7222006974041069 | Predicción actual: [[0.8415558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009346051141619682, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82435691]\n",
      " [0.75513367]\n",
      " [0.86902755]\n",
      " [0.86460358]\n",
      " [0.8581906 ]\n",
      " [0.85116744]\n",
      " [0.84512168]\n",
      " [0.84155577]] | y: 0.8485083301046106 | Predicción actual: [[0.8408943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007702126633375883, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.86902755]\n",
      " [0.86460358]\n",
      " [0.8581906 ]\n",
      " [0.85116744]\n",
      " [0.84512168]\n",
      " [0.84155577]\n",
      " [0.84089428]] | y: 0.9054629988376597 | Predicción actual: [[0.84322065]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02445252239704132, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86902755]\n",
      " [0.86460358]\n",
      " [0.8581906 ]\n",
      " [0.85116744]\n",
      " [0.84512168]\n",
      " [0.84155577]\n",
      " [0.84089428]\n",
      " [0.84322065]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006358560640364885, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86460358]\n",
      " [0.8581906 ]\n",
      " [0.85116744]\n",
      " [0.84512168]\n",
      " [0.84155577]\n",
      " [0.84089428]\n",
      " [0.84322065]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8626103]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016440892359241843, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8581906 ]\n",
      " [0.85116744]\n",
      " [0.84512168]\n",
      " [0.84155577]\n",
      " [0.84089428]\n",
      " [0.84322065]\n",
      " [0.8822162 ]\n",
      " [0.86261028]] | y: 0.889577683068578 | Predicción actual: [[0.85736567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015384543221443892, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85116744]\n",
      " [0.84512168]\n",
      " [0.84155577]\n",
      " [0.84089428]\n",
      " [0.84322065]\n",
      " [0.8822162 ]\n",
      " [0.86261028]\n",
      " [0.85736567]] | y: 0.8748547074777218 | Predicción actual: [[0.8538568]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010757259093225002, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84512168]\n",
      " [0.84155577]\n",
      " [0.84089428]\n",
      " [0.84322065]\n",
      " [0.8822162 ]\n",
      " [0.86261028]\n",
      " [0.85736567]\n",
      " [0.8538568 ]] | y: 0.9132119333591631 | Predicción actual: [[0.8525298]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00166997779160738, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84155577]\n",
      " [0.84089428]\n",
      " [0.84322065]\n",
      " [0.8822162 ]\n",
      " [0.86261028]\n",
      " [0.85736567]\n",
      " [0.8538568 ]\n",
      " [0.85252982]] | y: 1.0 | Predicción actual: [[0.85372895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004847676493227482, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84089428]\n",
      " [0.84322065]\n",
      " [0.8822162 ]\n",
      " [0.86261028]\n",
      " [0.85736567]\n",
      " [0.8538568 ]\n",
      " [0.85252982]\n",
      " [0.85372895]] | y: 0.9705540488182873 | Predicción actual: [[0.85692]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013832093216478825, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84322065]\n",
      " [0.8822162 ]\n",
      " [0.86261028]\n",
      " [0.85736567]\n",
      " [0.8538568 ]\n",
      " [0.85252982]\n",
      " [0.85372895]\n",
      " [0.85692   ]] | y: 0.8888027896164277 | Predicción actual: [[0.8612918]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015576236881315708, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.86261028]\n",
      " [0.85736567]\n",
      " [0.8538568 ]\n",
      " [0.85252982]\n",
      " [0.85372895]\n",
      " [0.85692   ]\n",
      " [0.86129183]] | y: 0.877954281286323 | Predicción actual: [[0.8657807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0059349252842366695, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86261028]\n",
      " [0.85736567]\n",
      " [0.8538568 ]\n",
      " [0.85252982]\n",
      " [0.85372895]\n",
      " [0.85692   ]\n",
      " [0.86129183]\n",
      " [0.86578071]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005589639768004417, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85736567]\n",
      " [0.8538568 ]\n",
      " [0.85252982]\n",
      " [0.85372895]\n",
      " [0.85692   ]\n",
      " [0.86129183]\n",
      " [0.86578071]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.85687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025017419829964638, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8538568 ]\n",
      " [0.85252982]\n",
      " [0.85372895]\n",
      " [0.85692   ]\n",
      " [0.86129183]\n",
      " [0.86578071]\n",
      " [0.84889578]\n",
      " [0.85687   ]] | y: 0.8550949244478885 | Predicción actual: [[0.85639465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012259137816727161, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85252982]\n",
      " [0.85372895]\n",
      " [0.85692   ]\n",
      " [0.86129183]\n",
      " [0.86578071]\n",
      " [0.84889578]\n",
      " [0.85687   ]\n",
      " [0.85639465]] | y: 0.8752421542037967 | Predicción actual: [[0.85680026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012003188021481037, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85372895]\n",
      " [0.85692   ]\n",
      " [0.86129183]\n",
      " [0.86578071]\n",
      " [0.84889578]\n",
      " [0.85687   ]\n",
      " [0.85639465]\n",
      " [0.85680026]] | y: 0.857032158078264 | Predicción actual: [[0.8577278]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0068450509570539, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85692   ]\n",
      " [0.86129183]\n",
      " [0.86578071]\n",
      " [0.84889578]\n",
      " [0.85687   ]\n",
      " [0.85639465]\n",
      " [0.85680026]\n",
      " [0.85772783]] | y: 0.8500581170089112 | Predicción actual: [[0.85864234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0074219852685928345, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86129183]\n",
      " [0.86578071]\n",
      " [0.84889578]\n",
      " [0.85687   ]\n",
      " [0.85639465]\n",
      " [0.85680026]\n",
      " [0.85772783]\n",
      " [0.85864234]] | y: 0.8426966292134832 | Predicción actual: [[0.8585058]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006059710402041674, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86578071]\n",
      " [0.84889578]\n",
      " [0.85687   ]\n",
      " [0.85639465]\n",
      " [0.85680026]\n",
      " [0.85772783]\n",
      " [0.85864234]\n",
      " [0.85850579]] | y: 0.8229368461836497 | Predicción actual: [[0.8568757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02357475645840168, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.85687   ]\n",
      " [0.85639465]\n",
      " [0.85680026]\n",
      " [0.85772783]\n",
      " [0.85864234]\n",
      " [0.85850579]\n",
      " [0.85687572]] | y: 0.7745060054242543 | Predicción actual: [[0.8540092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004471306165214628, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85687   ]\n",
      " [0.85639465]\n",
      " [0.85680026]\n",
      " [0.85772783]\n",
      " [0.85864234]\n",
      " [0.85850579]\n",
      " [0.85687572]\n",
      " [0.85400921]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028324227314442396, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85639465]\n",
      " [0.85680026]\n",
      " [0.85772783]\n",
      " [0.85864234]\n",
      " [0.85850579]\n",
      " [0.85687572]\n",
      " [0.85400921]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8554877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010723094455897808, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85680026]\n",
      " [0.85772783]\n",
      " [0.85864234]\n",
      " [0.85850579]\n",
      " [0.85687572]\n",
      " [0.85400921]\n",
      " [0.78419217]\n",
      " [0.8554877 ]] | y: 0.854320030995738 | Predicción actual: [[0.85451585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008616839186288416, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85772783]\n",
      " [0.85864234]\n",
      " [0.85850579]\n",
      " [0.85687572]\n",
      " [0.85400921]\n",
      " [0.78419217]\n",
      " [0.8554877 ]\n",
      " [0.85451585]] | y: 0.8368849283223556 | Predicción actual: [[0.8527086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00257966760545969, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85864234]\n",
      " [0.85850579]\n",
      " [0.85687572]\n",
      " [0.85400921]\n",
      " [0.78419217]\n",
      " [0.8554877 ]\n",
      " [0.85451585]\n",
      " [0.85270858]] | y: 0.8299108872530028 | Predicción actual: [[0.84993374]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0060896375216543674, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85850579]\n",
      " [0.85687572]\n",
      " [0.85400921]\n",
      " [0.78419217]\n",
      " [0.8554877 ]\n",
      " [0.85451585]\n",
      " [0.85270858]\n",
      " [0.84993374]] | y: 0.887253002712127 | Predicción actual: [[0.84629554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005989334546029568, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85687572]\n",
      " [0.85400921]\n",
      " [0.78419217]\n",
      " [0.8554877 ]\n",
      " [0.85451585]\n",
      " [0.85270858]\n",
      " [0.84993374]\n",
      " [0.84629554]] | y: 0.8597442851607902 | Predicción actual: [[0.84223634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02128990925848484, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85400921]\n",
      " [0.78419217]\n",
      " [0.8554877 ]\n",
      " [0.85451585]\n",
      " [0.85270858]\n",
      " [0.84993374]\n",
      " [0.84629554]\n",
      " [0.84223634]] | y: 0.8395970554048819 | Predicción actual: [[0.83789355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006435704883188009, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.8554877 ]\n",
      " [0.85451585]\n",
      " [0.85270858]\n",
      " [0.84993374]\n",
      " [0.84629554]\n",
      " [0.84223634]\n",
      " [0.83789355]] | y: 0.7838047268500579 | Predicción actual: [[0.8340472]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00542387505993247, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8554877 ]\n",
      " [0.85451585]\n",
      " [0.85270858]\n",
      " [0.84993374]\n",
      " [0.84629554]\n",
      " [0.84223634]\n",
      " [0.83789355]\n",
      " [0.8340472 ]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007635306101292372, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85451585]\n",
      " [0.85270858]\n",
      " [0.84993374]\n",
      " [0.84629554]\n",
      " [0.84223634]\n",
      " [0.83789355]\n",
      " [0.8340472 ]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.84841955]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017820382490754128, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85270858]\n",
      " [0.84993374]\n",
      " [0.84629554]\n",
      " [0.84223634]\n",
      " [0.83789355]\n",
      " [0.8340472 ]\n",
      " [0.81828749]\n",
      " [0.84841955]] | y: 0.7605579232855482 | Predicción actual: [[0.8448809]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020685680210590363, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84993374]\n",
      " [0.84629554]\n",
      " [0.84223634]\n",
      " [0.83789355]\n",
      " [0.8340472 ]\n",
      " [0.81828749]\n",
      " [0.84841955]\n",
      " [0.84488088]] | y: 0.7915536613715615 | Predicción actual: [[0.84083295]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008505068719387054, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84629554]\n",
      " [0.84223634]\n",
      " [0.83789355]\n",
      " [0.8340472 ]\n",
      " [0.81828749]\n",
      " [0.84841955]\n",
      " [0.84488088]\n",
      " [0.84083295]] | y: 0.7686943045331267 | Predicción actual: [[0.83684975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001836287439800799, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84223634]\n",
      " [0.83789355]\n",
      " [0.8340472 ]\n",
      " [0.81828749]\n",
      " [0.84841955]\n",
      " [0.84488088]\n",
      " [0.84083295]\n",
      " [0.83684975]] | y: 0.7686943045331267 | Predicción actual: [[0.83349895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020051163155585527, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83789355]\n",
      " [0.8340472 ]\n",
      " [0.81828749]\n",
      " [0.84841955]\n",
      " [0.84488088]\n",
      " [0.84083295]\n",
      " [0.83684975]\n",
      " [0.83349895]] | y: 0.7989151491669895 | Predicción actual: [[0.83124703]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006487642414867878, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8340472 ]\n",
      " [0.81828749]\n",
      " [0.84841955]\n",
      " [0.84488088]\n",
      " [0.84083295]\n",
      " [0.83684975]\n",
      " [0.83349895]\n",
      " [0.83124703]] | y: 0.7900038744672608 | Predicción actual: [[0.8300835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014809247804805636, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.84841955]\n",
      " [0.84488088]\n",
      " [0.84083295]\n",
      " [0.83684975]\n",
      " [0.83349895]\n",
      " [0.83124703]\n",
      " [0.83008349]] | y: 0.760170476559473 | Predicción actual: [[0.83006084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020544473081827164, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84841955]\n",
      " [0.84488088]\n",
      " [0.84083295]\n",
      " [0.83684975]\n",
      " [0.83349895]\n",
      " [0.83124703]\n",
      " [0.83008349]\n",
      " [0.83006084]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009527257643640041, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84488088]\n",
      " [0.84083295]\n",
      " [0.83684975]\n",
      " [0.83349895]\n",
      " [0.83124703]\n",
      " [0.83008349]\n",
      " [0.83006084]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.82932687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0543024055659771, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84083295]\n",
      " [0.83684975]\n",
      " [0.83349895]\n",
      " [0.83124703]\n",
      " [0.83008349]\n",
      " [0.83006084]\n",
      " [0.68539326]\n",
      " [0.82932687]] | y: 0.6648585819449826 | Predicción actual: [[0.82274085]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.13715718686580658, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83684975]\n",
      " [0.83349895]\n",
      " [0.83124703]\n",
      " [0.83008349]\n",
      " [0.83006084]\n",
      " [0.68539326]\n",
      " [0.82932687]\n",
      " [0.82274085]] | y: 0.7078651685393258 | Predicción actual: [[0.8145355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030918413773179054, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83349895]\n",
      " [0.83124703]\n",
      " [0.83008349]\n",
      " [0.83006084]\n",
      " [0.68539326]\n",
      " [0.82932687]\n",
      " [0.82274085]\n",
      " [0.8145355 ]] | y: 0.6648585819449826 | Predicción actual: [[0.8054757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060632944107055664, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83124703]\n",
      " [0.83008349]\n",
      " [0.83006084]\n",
      " [0.68539326]\n",
      " [0.82932687]\n",
      " [0.82274085]\n",
      " [0.8145355 ]\n",
      " [0.80547571]] | y: 0.7113521890740022 | Predicción actual: [[0.79554725]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007786949863657355, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83008349]\n",
      " [0.83006084]\n",
      " [0.68539326]\n",
      " [0.82932687]\n",
      " [0.82274085]\n",
      " [0.8145355 ]\n",
      " [0.80547571]\n",
      " [0.79554725]] | y: 0.6772568771793879 | Predicción actual: [[0.7851975]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003019757801666856, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83006084]\n",
      " [0.68539326]\n",
      " [0.82932687]\n",
      " [0.82274085]\n",
      " [0.8145355 ]\n",
      " [0.80547571]\n",
      " [0.79554725]\n",
      " [0.7851975 ]] | y: 0.7621077101898488 | Predicción actual: [[0.7742892]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003182602231390774, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.82932687]\n",
      " [0.82274085]\n",
      " [0.8145355 ]\n",
      " [0.80547571]\n",
      " [0.79554725]\n",
      " [0.7851975 ]\n",
      " [0.77428919]] | y: 0.8070515304145678 | Predicción actual: [[0.7627432]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008367371745407581, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82932687]\n",
      " [0.82274085]\n",
      " [0.8145355 ]\n",
      " [0.80547571]\n",
      " [0.79554725]\n",
      " [0.7851975 ]\n",
      " [0.77428919]\n",
      " [0.76274318]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003152536926791072, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82274085]\n",
      " [0.8145355 ]\n",
      " [0.80547571]\n",
      " [0.79554725]\n",
      " [0.7851975 ]\n",
      " [0.77428919]\n",
      " [0.76274318]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7828598]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03563242405653, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8145355 ]\n",
      " [0.80547571]\n",
      " [0.79554725]\n",
      " [0.7851975 ]\n",
      " [0.77428919]\n",
      " [0.76274318]\n",
      " [0.81518791]\n",
      " [0.7828598 ]] | y: 0.9597055404881829 | Predicción actual: [[0.77436775]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06109240651130676, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80547571]\n",
      " [0.79554725]\n",
      " [0.7851975 ]\n",
      " [0.77428919]\n",
      " [0.76274318]\n",
      " [0.81518791]\n",
      " [0.7828598 ]\n",
      " [0.77436775]] | y: 0.9643549012010848 | Predicción actual: [[0.7671092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04975398629903793, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79554725]\n",
      " [0.7851975 ]\n",
      " [0.77428919]\n",
      " [0.76274318]\n",
      " [0.81518791]\n",
      " [0.7828598 ]\n",
      " [0.77436775]\n",
      " [0.76710922]] | y: 0.8880278961642774 | Predicción actual: [[0.7615177]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01563558168709278, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7851975 ]\n",
      " [0.77428919]\n",
      " [0.76274318]\n",
      " [0.81518791]\n",
      " [0.7828598 ]\n",
      " [0.77436775]\n",
      " [0.76710922]\n",
      " [0.7615177 ]] | y: 0.8926772568771792 | Predicción actual: [[0.75789016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002560829743742943, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77428919]\n",
      " [0.76274318]\n",
      " [0.81518791]\n",
      " [0.7828598 ]\n",
      " [0.77436775]\n",
      " [0.76710922]\n",
      " [0.7615177 ]\n",
      " [0.75789016]] | y: 0.8752421542037967 | Predicción actual: [[0.7562234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016552545130252838, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76274318]\n",
      " [0.81518791]\n",
      " [0.7828598 ]\n",
      " [0.77436775]\n",
      " [0.76710922]\n",
      " [0.7615177 ]\n",
      " [0.75789016]\n",
      " [0.75622338]] | y: 0.8508330104610615 | Predicción actual: [[0.7568487]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03156065568327904, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.7828598 ]\n",
      " [0.77436775]\n",
      " [0.76710922]\n",
      " [0.7615177 ]\n",
      " [0.75789016]\n",
      " [0.75622338]\n",
      " [0.75684869]] | y: 0.8488957768306855 | Predicción actual: [[0.76038736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026194723322987556, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7828598 ]\n",
      " [0.77436775]\n",
      " [0.76710922]\n",
      " [0.7615177 ]\n",
      " [0.75789016]\n",
      " [0.75622338]\n",
      " [0.75684869]\n",
      " [0.76038736]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05229564011096954, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77436775]\n",
      " [0.76710922]\n",
      " [0.7615177 ]\n",
      " [0.75789016]\n",
      " [0.75622338]\n",
      " [0.75684869]\n",
      " [0.76038736]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7452829]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004719012416899204, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76710922]\n",
      " [0.7615177 ]\n",
      " [0.75789016]\n",
      " [0.75622338]\n",
      " [0.75684869]\n",
      " [0.76038736]\n",
      " [0.96241767]\n",
      " [0.74528289]] | y: 0.9407206509104997 | Predicción actual: [[0.74528]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08218695223331451, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7615177 ]\n",
      " [0.75789016]\n",
      " [0.75622338]\n",
      " [0.75684869]\n",
      " [0.76038736]\n",
      " [0.96241767]\n",
      " [0.74528289]\n",
      " [0.74528003]] | y: 0.9724912824486633 | Predicción actual: [[0.74879414]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11033058166503906, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75789016]\n",
      " [0.75622338]\n",
      " [0.75684869]\n",
      " [0.76038736]\n",
      " [0.96241767]\n",
      " [0.74528289]\n",
      " [0.74528003]\n",
      " [0.74879414]] | y: 0.9969004261913985 | Predicción actual: [[0.75541097]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10325159877538681, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75622338]\n",
      " [0.75684869]\n",
      " [0.76038736]\n",
      " [0.96241767]\n",
      " [0.74528289]\n",
      " [0.74528003]\n",
      " [0.74879414]\n",
      " [0.75541097]] | y: 0.951181712514529 | Predicción actual: [[0.76433134]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05024399980902672, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75684869]\n",
      " [0.76038736]\n",
      " [0.96241767]\n",
      " [0.74528289]\n",
      " [0.74528003]\n",
      " [0.74879414]\n",
      " [0.75541097]\n",
      " [0.76433134]] | y: 0.8957768306857805 | Predicción actual: [[0.77447855]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.550421064981492e-06, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76038736]\n",
      " [0.96241767]\n",
      " [0.74528289]\n",
      " [0.74528003]\n",
      " [0.74879414]\n",
      " [0.75541097]\n",
      " [0.76433134]\n",
      " [0.77447855]] | y: 0.8814413018209997 | Predicción actual: [[0.7844186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011750725097954273, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.74528289]\n",
      " [0.74528003]\n",
      " [0.74879414]\n",
      " [0.75541097]\n",
      " [0.76433134]\n",
      " [0.77447855]\n",
      " [0.78441858]] | y: 0.9170864006199149 | Predicción actual: [[0.79265743]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029070589691400528, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74528289]\n",
      " [0.74528003]\n",
      " [0.74879414]\n",
      " [0.75541097]\n",
      " [0.76433134]\n",
      " [0.77447855]\n",
      " [0.78441858]\n",
      " [0.79265743]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02519283816218376, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74528003]\n",
      " [0.74879414]\n",
      " [0.75541097]\n",
      " [0.76433134]\n",
      " [0.77447855]\n",
      " [0.78441858]\n",
      " [0.79265743]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7483088]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031831455416977406, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74879414]\n",
      " [0.75541097]\n",
      " [0.76433134]\n",
      " [0.77447855]\n",
      " [0.78441858]\n",
      " [0.79265743]\n",
      " [0.91979853]\n",
      " [0.74830878]] | y: 0.9682293684618366 | Predicción actual: [[0.75756055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10152867436408997, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75541097]\n",
      " [0.76433134]\n",
      " [0.77447855]\n",
      " [0.78441858]\n",
      " [0.79265743]\n",
      " [0.91979853]\n",
      " [0.74830878]\n",
      " [0.75756055]] | y: 0.9577683068578069 | Predicción actual: [[0.7686888]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03913511335849762, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20245917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029722534120082855, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20245917]] | y: 0.10422316931421921 | Predicción actual: [[0.1870529]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003150693839415908, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20245917]\n",
      " [0.18705291]] | y: 0.15420379697791559 | Predicción actual: [[0.19126299]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.848788037430495e-05, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20245917]\n",
      " [0.18705291]\n",
      " [0.19126299]] | y: 0.1557535838822161 | Predicción actual: [[0.20280223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035440733190625906, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20245917]\n",
      " [0.18705291]\n",
      " [0.19126299]\n",
      " [0.20280223]] | y: 0.12553273924835334 | Predicción actual: [[0.2154499]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00791148655116558, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20245917]\n",
      " [0.18705291]\n",
      " [0.19126299]\n",
      " [0.20280223]\n",
      " [0.2154499 ]] | y: 0.1456799690042619 | Predicción actual: [[0.22539952]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012842421419918537, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20245917]\n",
      " [0.18705291]\n",
      " [0.19126299]\n",
      " [0.20280223]\n",
      " [0.2154499 ]\n",
      " [0.22539952]] | y: 0.1464548624564122 | Predicción actual: [[0.24677573]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006406448315829039, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20245917]\n",
      " [0.18705291]\n",
      " [0.19126299]\n",
      " [0.20280223]\n",
      " [0.2154499 ]\n",
      " [0.22539952]\n",
      " [0.24677573]] | y: 0.1960480433940332 | Predicción actual: [[0.27305526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012051863595843315, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20245917]\n",
      " [0.18705291]\n",
      " [0.19126299]\n",
      " [0.20280223]\n",
      " [0.2154499 ]\n",
      " [0.22539952]\n",
      " [0.24677573]\n",
      " [0.27305526]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004572119098156691, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18705291]\n",
      " [0.19126299]\n",
      " [0.20280223]\n",
      " [0.2154499 ]\n",
      " [0.22539952]\n",
      " [0.24677573]\n",
      " [0.27305526]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3068391]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008914635516703129, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19126299]\n",
      " [0.20280223]\n",
      " [0.2154499 ]\n",
      " [0.22539952]\n",
      " [0.24677573]\n",
      " [0.27305526]\n",
      " [0.2305308 ]\n",
      " [0.30683911]] | y: 0.211933359163115 | Predicción actual: [[0.3141347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008557284250855446, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20280223]\n",
      " [0.2154499 ]\n",
      " [0.22539952]\n",
      " [0.24677573]\n",
      " [0.27305526]\n",
      " [0.2305308 ]\n",
      " [0.30683911]\n",
      " [0.31413469]] | y: 0.2072839984502131 | Predicción actual: [[0.3232922]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026987986639142036, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2154499 ]\n",
      " [0.22539952]\n",
      " [0.24677573]\n",
      " [0.27305526]\n",
      " [0.2305308 ]\n",
      " [0.30683911]\n",
      " [0.31413469]\n",
      " [0.3232922 ]] | y: 0.19294846958543205 | Predicción actual: [[0.33303913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02174963802099228, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22539952]\n",
      " [0.24677573]\n",
      " [0.27305526]\n",
      " [0.2305308 ]\n",
      " [0.30683911]\n",
      " [0.31413469]\n",
      " [0.3232922 ]\n",
      " [0.33303913]] | y: 0.19682293684618352 | Predicción actual: [[0.34330562]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015413342975080013, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24677573]\n",
      " [0.27305526]\n",
      " [0.2305308 ]\n",
      " [0.30683911]\n",
      " [0.31413469]\n",
      " [0.3232922 ]\n",
      " [0.33303913]\n",
      " [0.34330562]] | y: 0.21425803951956607 | Predicción actual: [[0.35482827]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037914324551820755, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27305526]\n",
      " [0.2305308 ]\n",
      " [0.30683911]\n",
      " [0.31413469]\n",
      " [0.3232922 ]\n",
      " [0.33303913]\n",
      " [0.34330562]\n",
      " [0.35482827]] | y: 0.18132506780317698 | Predicción actual: [[0.3649634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036152321845293045, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.30683911]\n",
      " [0.31413469]\n",
      " [0.3232922 ]\n",
      " [0.33303913]\n",
      " [0.34330562]\n",
      " [0.35482827]\n",
      " [0.36496341]] | y: 0.17512592018597434 | Predicción actual: [[0.37222248]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04795391857624054, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30683911]\n",
      " [0.31413469]\n",
      " [0.3232922 ]\n",
      " [0.33303913]\n",
      " [0.34330562]\n",
      " [0.35482827]\n",
      " [0.36496341]\n",
      " [0.37222248]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04891962558031082, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31413469]\n",
      " [0.3232922 ]\n",
      " [0.33303913]\n",
      " [0.34330562]\n",
      " [0.35482827]\n",
      " [0.36496341]\n",
      " [0.37222248]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.39795795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04024263843894005, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3232922 ]\n",
      " [0.33303913]\n",
      " [0.34330562]\n",
      " [0.35482827]\n",
      " [0.36496341]\n",
      " [0.37222248]\n",
      " [0.14800465]\n",
      " [0.39795795]] | y: 0.19217357613328173 | Predicción actual: [[0.4019641]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03762345761060715, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33303913]\n",
      " [0.34330562]\n",
      " [0.35482827]\n",
      " [0.36496341]\n",
      " [0.37222248]\n",
      " [0.14800465]\n",
      " [0.39795795]\n",
      " [0.4019641 ]] | y: 0.1859744285160791 | Predicción actual: [[0.4042407]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.039829060435295105, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34330562]\n",
      " [0.35482827]\n",
      " [0.36496341]\n",
      " [0.37222248]\n",
      " [0.14800465]\n",
      " [0.39795795]\n",
      " [0.4019641 ]\n",
      " [0.4042407 ]] | y: 0.26695079426578844 | Predicción actual: [[0.40482572]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06505570560693741, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35482827]\n",
      " [0.36496341]\n",
      " [0.37222248]\n",
      " [0.14800465]\n",
      " [0.39795795]\n",
      " [0.4019641 ]\n",
      " [0.4042407 ]\n",
      " [0.40482572]] | y: 0.2925222781867493 | Predicción actual: [[0.4038326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02019403874874115, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36496341]\n",
      " [0.37222248]\n",
      " [0.14800465]\n",
      " [0.39795795]\n",
      " [0.4019641 ]\n",
      " [0.4042407 ]\n",
      " [0.40482572]\n",
      " [0.40383261]] | y: 0.3177063153816349 | Predicción actual: [[0.40137386]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007626381702721119, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37222248]\n",
      " [0.14800465]\n",
      " [0.39795795]\n",
      " [0.4019641 ]\n",
      " [0.4042407 ]\n",
      " [0.40482572]\n",
      " [0.40383261]\n",
      " [0.40137386]] | y: 0.31266950794265785 | Predicción actual: [[0.3980984]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018624749034643173, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.39795795]\n",
      " [0.4019641 ]\n",
      " [0.4042407 ]\n",
      " [0.40482572]\n",
      " [0.40383261]\n",
      " [0.40137386]\n",
      " [0.39809841]] | y: 0.2890352576520729 | Predicción actual: [[0.39482877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01766321063041687, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39795795]\n",
      " [0.4019641 ]\n",
      " [0.4042407 ]\n",
      " [0.40482572]\n",
      " [0.40383261]\n",
      " [0.40137386]\n",
      " [0.39809841]\n",
      " [0.39482877]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05096467584371567, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4019641 ]\n",
      " [0.4042407 ]\n",
      " [0.40482572]\n",
      " [0.40383261]\n",
      " [0.40137386]\n",
      " [0.39809841]\n",
      " [0.39482877]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.44800338]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014361739158630371, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4042407 ]\n",
      " [0.40482572]\n",
      " [0.40383261]\n",
      " [0.40137386]\n",
      " [0.39809841]\n",
      " [0.39482877]\n",
      " [0.28283611]\n",
      " [0.44800338]] | y: 0.2758620689655173 | Predicción actual: [[0.4459]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019633915275335312, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40482572]\n",
      " [0.40383261]\n",
      " [0.40137386]\n",
      " [0.39809841]\n",
      " [0.39482877]\n",
      " [0.28283611]\n",
      " [0.44800338]\n",
      " [0.44589999]] | y: 0.2746997287872917 | Predicción actual: [[0.4427564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03380707651376724, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40383261]\n",
      " [0.40137386]\n",
      " [0.39809841]\n",
      " [0.39482877]\n",
      " [0.28283611]\n",
      " [0.44800338]\n",
      " [0.44589999]\n",
      " [0.44275641]] | y: 0.275474622239442 | Predicción actual: [[0.43938386]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01248135045170784, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40137386]\n",
      " [0.39809841]\n",
      " [0.39482877]\n",
      " [0.28283611]\n",
      " [0.44800338]\n",
      " [0.44589999]\n",
      " [0.44275641]\n",
      " [0.43938386]] | y: 0.3347539713289423 | Predicción actual: [[0.43675274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008192218840122223, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39809841]\n",
      " [0.39482877]\n",
      " [0.28283611]\n",
      " [0.44800338]\n",
      " [0.44589999]\n",
      " [0.44275641]\n",
      " [0.43938386]\n",
      " [0.43675274]] | y: 0.35567609453700116 | Predicción actual: [[0.4357498]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019394082482904196, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39482877]\n",
      " [0.28283611]\n",
      " [0.44800338]\n",
      " [0.44589999]\n",
      " [0.44275641]\n",
      " [0.43938386]\n",
      " [0.43675274]\n",
      " [0.4357498 ]] | y: 0.3366912049593181 | Predicción actual: [[0.43705216]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021115312352776527, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.44800338]\n",
      " [0.44589999]\n",
      " [0.44275641]\n",
      " [0.43938386]\n",
      " [0.43675274]\n",
      " [0.4357498 ]\n",
      " [0.43705216]] | y: 0.3335916311507167 | Predicción actual: [[0.4409347]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004622815176844597, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44800338]\n",
      " [0.44589999]\n",
      " [0.44275641]\n",
      " [0.43938386]\n",
      " [0.43675274]\n",
      " [0.4357498 ]\n",
      " [0.43705216]\n",
      " [0.44093469]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004021544009447098, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44589999]\n",
      " [0.44275641]\n",
      " [0.43938386]\n",
      " [0.43675274]\n",
      " [0.4357498 ]\n",
      " [0.43705216]\n",
      " [0.44093469]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.47217923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007926489226520061, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44275641]\n",
      " [0.43938386]\n",
      " [0.43675274]\n",
      " [0.4357498 ]\n",
      " [0.43705216]\n",
      " [0.44093469]\n",
      " [0.3847346 ]\n",
      " [0.47217923]] | y: 0.5962805114296785 | Predicción actual: [[0.4695103]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021359959617257118, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43938386]\n",
      " [0.43675274]\n",
      " [0.4357498 ]\n",
      " [0.43705216]\n",
      " [0.44093469]\n",
      " [0.3847346 ]\n",
      " [0.47217923]\n",
      " [0.46951029]] | y: 0.574583494769469 | Predicción actual: [[0.46751288]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005903485231101513, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43675274]\n",
      " [0.4357498 ]\n",
      " [0.43705216]\n",
      " [0.44093469]\n",
      " [0.3847346 ]\n",
      " [0.47217923]\n",
      " [0.46951029]\n",
      " [0.46751288]] | y: 0.6063541263076326 | Predicción actual: [[0.46662253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025237852707505226, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4357498 ]\n",
      " [0.43705216]\n",
      " [0.44093469]\n",
      " [0.3847346 ]\n",
      " [0.47217923]\n",
      " [0.46951029]\n",
      " [0.46751288]\n",
      " [0.46662253]] | y: 0.5846571096474236 | Predicción actual: [[0.4671172]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03501423820853233, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.43705216]\n",
      " [0.44093469]\n",
      " [0.3847346 ]\n",
      " [0.47217923]\n",
      " [0.46951029]\n",
      " [0.46751288]\n",
      " [0.46662253]\n",
      " [0.46711719]] | y: 0.5687717938783416 | Predicción actual: [[0.46893877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008621249347925186, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44093469]\n",
      " [0.3847346 ]\n",
      " [0.47217923]\n",
      " [0.46951029]\n",
      " [0.46751288]\n",
      " [0.46662253]\n",
      " [0.46711719]\n",
      " [0.46893877]] | y: 0.6427741185586981 | Predicción actual: [[0.47170016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07065866887569427, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.47217923]\n",
      " [0.46951029]\n",
      " [0.46751288]\n",
      " [0.46662253]\n",
      " [0.46711719]\n",
      " [0.46893877]\n",
      " [0.47170016]] | y: 0.6617590081363811 | Predicción actual: [[0.47492808]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026850653812289238, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47217923]\n",
      " [0.46951029]\n",
      " [0.46751288]\n",
      " [0.46662253]\n",
      " [0.46711719]\n",
      " [0.46893877]\n",
      " [0.47170016]\n",
      " [0.47492808]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05088945850729942, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46951029]\n",
      " [0.46751288]\n",
      " [0.46662253]\n",
      " [0.46711719]\n",
      " [0.46893877]\n",
      " [0.47170016]\n",
      " [0.47492808]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.4946149]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07009103149175644, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46751288]\n",
      " [0.46662253]\n",
      " [0.46711719]\n",
      " [0.46893877]\n",
      " [0.47170016]\n",
      " [0.47492808]\n",
      " [0.67299496]\n",
      " [0.4946149 ]] | y: 0.703990701278574 | Predicción actual: [[0.49797094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022222120314836502, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46662253]\n",
      " [0.46711719]\n",
      " [0.46893877]\n",
      " [0.47170016]\n",
      " [0.47492808]\n",
      " [0.67299496]\n",
      " [0.4946149 ]\n",
      " [0.49797094]] | y: 0.7272375048430839 | Predicción actual: [[0.50412077]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06539245694875717, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46711719]\n",
      " [0.46893877]\n",
      " [0.47170016]\n",
      " [0.47492808]\n",
      " [0.67299496]\n",
      " [0.4946149 ]\n",
      " [0.49797094]\n",
      " [0.50412077]] | y: 0.722588144130182 | Predicción actual: [[0.51299584]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017833450809121132, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46893877]\n",
      " [0.47170016]\n",
      " [0.47492808]\n",
      " [0.67299496]\n",
      " [0.4946149 ]\n",
      " [0.49797094]\n",
      " [0.50412077]\n",
      " [0.51299584]] | y: 0.771793878341728 | Predicción actual: [[0.52413255]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.13911394774913788, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47170016]\n",
      " [0.47492808]\n",
      " [0.67299496]\n",
      " [0.4946149 ]\n",
      " [0.49797094]\n",
      " [0.50412077]\n",
      " [0.51299584]\n",
      " [0.52413255]] | y: 0.7245253777605578 | Predicción actual: [[0.5371204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02189234085381031, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47492808]\n",
      " [0.67299496]\n",
      " [0.4946149 ]\n",
      " [0.49797094]\n",
      " [0.50412077]\n",
      " [0.51299584]\n",
      " [0.52413255]\n",
      " [0.5371204 ]] | y: 0.6710577295621851 | Predicción actual: [[0.5513954]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01410055160522461, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.4946149 ]\n",
      " [0.49797094]\n",
      " [0.50412077]\n",
      " [0.51299584]\n",
      " [0.52413255]\n",
      " [0.5371204 ]\n",
      " [0.55139542]] | y: 0.6737698566447115 | Predicción actual: [[0.5666064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014890845865011215, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4946149 ]\n",
      " [0.49797094]\n",
      " [0.50412077]\n",
      " [0.51299584]\n",
      " [0.52413255]\n",
      " [0.5371204 ]\n",
      " [0.55139542]\n",
      " [0.5666064 ]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003159689251333475, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49797094]\n",
      " [0.50412077]\n",
      " [0.51299584]\n",
      " [0.52413255]\n",
      " [0.5371204 ]\n",
      " [0.55139542]\n",
      " [0.5666064 ]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.53864205]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06605508178472519, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50412077]\n",
      " [0.51299584]\n",
      " [0.52413255]\n",
      " [0.5371204 ]\n",
      " [0.55139542]\n",
      " [0.5666064 ]\n",
      " [0.71445176]\n",
      " [0.53864205]] | y: 0.722588144130182 | Predicción actual: [[0.549671]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015899091958999634, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51299584]\n",
      " [0.52413255]\n",
      " [0.5371204 ]\n",
      " [0.55139542]\n",
      " [0.5666064 ]\n",
      " [0.71445176]\n",
      " [0.53864205]\n",
      " [0.54967099]] | y: 0.6993413405656723 | Predicción actual: [[0.56271154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015807831659913063, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52413255]\n",
      " [0.5371204 ]\n",
      " [0.55139542]\n",
      " [0.5666064 ]\n",
      " [0.71445176]\n",
      " [0.53864205]\n",
      " [0.54967099]\n",
      " [0.56271154]] | y: 0.7373111197210385 | Predicción actual: [[0.5766986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01342055294662714, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5371204 ]\n",
      " [0.55139542]\n",
      " [0.5666064 ]\n",
      " [0.71445176]\n",
      " [0.53864205]\n",
      " [0.54967099]\n",
      " [0.56271154]\n",
      " [0.5766986 ]] | y: 0.7214258039519565 | Predicción actual: [[0.590461]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03376103192567825, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55139542]\n",
      " [0.5666064 ]\n",
      " [0.71445176]\n",
      " [0.53864205]\n",
      " [0.54967099]\n",
      " [0.56271154]\n",
      " [0.5766986 ]\n",
      " [0.59046102]] | y: 0.7187136768694304 | Predicción actual: [[0.6028853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022492125630378723, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5666064 ]\n",
      " [0.71445176]\n",
      " [0.53864205]\n",
      " [0.54967099]\n",
      " [0.56271154]\n",
      " [0.5766986 ]\n",
      " [0.59046102]\n",
      " [0.60288531]] | y: 0.6741573033707864 | Predicción actual: [[0.61295146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019052360206842422, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.53864205]\n",
      " [0.54967099]\n",
      " [0.56271154]\n",
      " [0.5766986 ]\n",
      " [0.59046102]\n",
      " [0.60288531]\n",
      " [0.61295146]] | y: 0.698566447113522 | Predicción actual: [[0.6198307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012791379354894161, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53864205]\n",
      " [0.54967099]\n",
      " [0.56271154]\n",
      " [0.5766986 ]\n",
      " [0.59046102]\n",
      " [0.60288531]\n",
      " [0.61295146]\n",
      " [0.61983073]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013563853688538074, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54967099]\n",
      " [0.56271154]\n",
      " [0.5766986 ]\n",
      " [0.59046102]\n",
      " [0.60288531]\n",
      " [0.61295146]\n",
      " [0.61983073]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.5986898]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006018328946083784, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56271154]\n",
      " [0.5766986 ]\n",
      " [0.59046102]\n",
      " [0.60288531]\n",
      " [0.61295146]\n",
      " [0.61983073]\n",
      " [0.72103836]\n",
      " [0.59868979]] | y: 0.7562960092987214 | Predicción actual: [[0.61198777]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024464845657348633, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5766986 ]\n",
      " [0.59046102]\n",
      " [0.60288531]\n",
      " [0.61295146]\n",
      " [0.61983073]\n",
      " [0.72103836]\n",
      " [0.59868979]\n",
      " [0.61198777]] | y: 0.8275862068965516 | Predicción actual: [[0.62528265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009736851789057255, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59046102]\n",
      " [0.60288531]\n",
      " [0.61295146]\n",
      " [0.61983073]\n",
      " [0.72103836]\n",
      " [0.59868979]\n",
      " [0.61198777]\n",
      " [0.62528265]] | y: 0.8388221619527314 | Predicción actual: [[0.6376765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05717618390917778, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60288531]\n",
      " [0.61295146]\n",
      " [0.61983073]\n",
      " [0.72103836]\n",
      " [0.59868979]\n",
      " [0.61198777]\n",
      " [0.62528265]\n",
      " [0.63767648]] | y: 0.7942657884540876 | Predicción actual: [[0.6486873]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022820595651865005, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61295146]\n",
      " [0.61983073]\n",
      " [0.72103836]\n",
      " [0.59868979]\n",
      " [0.61198777]\n",
      " [0.62528265]\n",
      " [0.63767648]\n",
      " [0.6486873 ]] | y: 0.7838047268500579 | Predicción actual: [[0.6579863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06165860965847969, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61983073]\n",
      " [0.72103836]\n",
      " [0.59868979]\n",
      " [0.61198777]\n",
      " [0.62528265]\n",
      " [0.63767648]\n",
      " [0.6486873 ]\n",
      " [0.65798628]] | y: 0.7679194110809764 | Predicción actual: [[0.66583467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0072455499321222305, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.59868979]\n",
      " [0.61198777]\n",
      " [0.62528265]\n",
      " [0.63767648]\n",
      " [0.6486873 ]\n",
      " [0.65798628]\n",
      " [0.66583467]] | y: 0.7845796203022084 | Predicción actual: [[0.6727424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002494686050340533, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59868979]\n",
      " [0.61198777]\n",
      " [0.62528265]\n",
      " [0.63767648]\n",
      " [0.6486873 ]\n",
      " [0.65798628]\n",
      " [0.66583467]\n",
      " [0.67274243]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09047972410917282, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61198777]\n",
      " [0.62528265]\n",
      " [0.63767648]\n",
      " [0.6486873 ]\n",
      " [0.65798628]\n",
      " [0.66583467]\n",
      " [0.67274243]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.66491914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.051742348819971085, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62528265]\n",
      " [0.63767648]\n",
      " [0.6486873 ]\n",
      " [0.65798628]\n",
      " [0.66583467]\n",
      " [0.67274243]\n",
      " [0.87872917]\n",
      " [0.66491914]] | y: 0.8488957768306855 | Predicción actual: [[0.6796964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04332467168569565, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63767648]\n",
      " [0.6486873 ]\n",
      " [0.65798628]\n",
      " [0.66583467]\n",
      " [0.67274243]\n",
      " [0.87872917]\n",
      " [0.66491914]\n",
      " [0.67969638]] | y: 0.8182874854707476 | Predicción actual: [[0.6952948]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005221967585384846, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6486873 ]\n",
      " [0.65798628]\n",
      " [0.66583467]\n",
      " [0.67274243]\n",
      " [0.87872917]\n",
      " [0.66491914]\n",
      " [0.67969638]\n",
      " [0.6952948 ]] | y: 0.8268113134444013 | Predicción actual: [[0.7112952]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02682999148964882, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65798628]\n",
      " [0.66583467]\n",
      " [0.67274243]\n",
      " [0.87872917]\n",
      " [0.66491914]\n",
      " [0.67969638]\n",
      " [0.6952948 ]\n",
      " [0.71129519]] | y: 0.7853545137543589 | Predicción actual: [[0.72758186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005264981184154749, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66583467]\n",
      " [0.67274243]\n",
      " [0.87872917]\n",
      " [0.66491914]\n",
      " [0.67969638]\n",
      " [0.6952948 ]\n",
      " [0.71129519]\n",
      " [0.72758186]] | y: 0.7892289810151103 | Predicción actual: [[0.7439498]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009569035028107464, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67274243]\n",
      " [0.87872917]\n",
      " [0.66491914]\n",
      " [0.67969638]\n",
      " [0.6952948 ]\n",
      " [0.71129519]\n",
      " [0.72758186]\n",
      " [0.74394977]] | y: 0.8341728012398295 | Predicción actual: [[0.76020324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.736892828484997e-05, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.66491914]\n",
      " [0.67969638]\n",
      " [0.6952948 ]\n",
      " [0.71129519]\n",
      " [0.72758186]\n",
      " [0.74394977]\n",
      " [0.76020324]] | y: 0.8124757845796202 | Predicción actual: [[0.77636075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027206309605389833, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66491914]\n",
      " [0.67969638]\n",
      " [0.6952948 ]\n",
      " [0.71129519]\n",
      " [0.72758186]\n",
      " [0.74394977]\n",
      " [0.76020324]\n",
      " [0.77636075]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004379199352115393, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67969638]\n",
      " [0.6952948 ]\n",
      " [0.71129519]\n",
      " [0.72758186]\n",
      " [0.74394977]\n",
      " [0.76020324]\n",
      " [0.77636075]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7472537]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003931570798158646, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6952948 ]\n",
      " [0.71129519]\n",
      " [0.72758186]\n",
      " [0.74394977]\n",
      " [0.76020324]\n",
      " [0.77636075]\n",
      " [0.80123983]\n",
      " [0.74725372]] | y: 0.793490895001937 | Predicción actual: [[0.76323664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01626492850482464, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71129519]\n",
      " [0.72758186]\n",
      " [0.74394977]\n",
      " [0.76020324]\n",
      " [0.77636075]\n",
      " [0.80123983]\n",
      " [0.74725372]\n",
      " [0.76323664]] | y: 0.760170476559473 | Predicción actual: [[0.77867335]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019755044486373663, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72758186]\n",
      " [0.74394977]\n",
      " [0.76020324]\n",
      " [0.77636075]\n",
      " [0.80123983]\n",
      " [0.74725372]\n",
      " [0.76323664]\n",
      " [0.77867335]] | y: 0.7353738860906625 | Predicción actual: [[0.7925343]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004360491875559092, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74394977]\n",
      " [0.76020324]\n",
      " [0.77636075]\n",
      " [0.80123983]\n",
      " [0.74725372]\n",
      " [0.76323664]\n",
      " [0.77867335]\n",
      " [0.79253429]] | y: 0.7101898488957767 | Predicción actual: [[0.8040522]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016050243750214577, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76020324]\n",
      " [0.77636075]\n",
      " [0.80123983]\n",
      " [0.74725372]\n",
      " [0.76323664]\n",
      " [0.77867335]\n",
      " [0.79253429]\n",
      " [0.80405217]] | y: 0.7121270825261525 | Predicción actual: [[0.8125134]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022138074040412903, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77636075]\n",
      " [0.80123983]\n",
      " [0.74725372]\n",
      " [0.76323664]\n",
      " [0.77867335]\n",
      " [0.79253429]\n",
      " [0.80405217]\n",
      " [0.81251341]] | y: 0.7396358000774894 | Predicción actual: [[0.8174599]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.7016925489297137e-06, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.74725372]\n",
      " [0.76323664]\n",
      " [0.77867335]\n",
      " [0.79253429]\n",
      " [0.80405217]\n",
      " [0.81251341]\n",
      " [0.81745988]] | y: 0.7361487795428128 | Predicción actual: [[0.8189099]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0963936448097229, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74725372]\n",
      " [0.76323664]\n",
      " [0.77867335]\n",
      " [0.79253429]\n",
      " [0.80405217]\n",
      " [0.81251341]\n",
      " [0.81745988]\n",
      " [0.81890988]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013016982935369015, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76323664]\n",
      " [0.77867335]\n",
      " [0.79253429]\n",
      " [0.80405217]\n",
      " [0.81251341]\n",
      " [0.81745988]\n",
      " [0.81890988]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.82431793]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012743144296109676, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77867335]\n",
      " [0.79253429]\n",
      " [0.80405217]\n",
      " [0.81251341]\n",
      " [0.81745988]\n",
      " [0.81890988]\n",
      " [0.66757071]\n",
      " [0.82431793]] | y: 0.696629213483146 | Predicción actual: [[0.83203584]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016102934256196022, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79253429]\n",
      " [0.80405217]\n",
      " [0.81251341]\n",
      " [0.81745988]\n",
      " [0.81890988]\n",
      " [0.66757071]\n",
      " [0.82431793]\n",
      " [0.83203584]] | y: 0.6559473072452537 | Predicción actual: [[0.8358096]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003992958925664425, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80405217]\n",
      " [0.81251341]\n",
      " [0.81745988]\n",
      " [0.81890988]\n",
      " [0.66757071]\n",
      " [0.82431793]\n",
      " [0.83203584]\n",
      " [0.83580959]] | y: 0.6788066640836885 | Predicción actual: [[0.835851]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01903362385928631, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81251341]\n",
      " [0.81745988]\n",
      " [0.81890988]\n",
      " [0.66757071]\n",
      " [0.82431793]\n",
      " [0.83203584]\n",
      " [0.83580959]\n",
      " [0.83585101]] | y: 0.6760945370011622 | Predicción actual: [[0.83262146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04330058395862579, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81745988]\n",
      " [0.81890988]\n",
      " [0.66757071]\n",
      " [0.82431793]\n",
      " [0.83203584]\n",
      " [0.83580959]\n",
      " [0.83585101]\n",
      " [0.83262146]] | y: 0.7295621851995349 | Predicción actual: [[0.8270528]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027176208794116974, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81890988]\n",
      " [0.66757071]\n",
      " [0.82431793]\n",
      " [0.83203584]\n",
      " [0.83580959]\n",
      " [0.83585101]\n",
      " [0.83262146]\n",
      " [0.82705277]] | y: 0.7012785741960481 | Predicción actual: [[0.8206282]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04467684403061867, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.82431793]\n",
      " [0.83203584]\n",
      " [0.83580959]\n",
      " [0.83585101]\n",
      " [0.83262146]\n",
      " [0.82705277]\n",
      " [0.82062823]] | y: 0.767531964354901 | Predicción actual: [[0.8146923]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014022581744939089, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82431793]\n",
      " [0.83203584]\n",
      " [0.83580959]\n",
      " [0.83585101]\n",
      " [0.83262146]\n",
      " [0.82705277]\n",
      " [0.82062823]\n",
      " [0.81469232]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013718944042921066, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83203584]\n",
      " [0.83580959]\n",
      " [0.83585101]\n",
      " [0.83262146]\n",
      " [0.82705277]\n",
      " [0.82062823]\n",
      " [0.81469232]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8566877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004315079655498266, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83580959]\n",
      " [0.83585101]\n",
      " [0.83262146]\n",
      " [0.82705277]\n",
      " [0.82062823]\n",
      " [0.81469232]\n",
      " [0.75513367]\n",
      " [0.85668772]] | y: 0.7520340953118947 | Predicción actual: [[0.8531496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.8952126993099228e-05, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83585101]\n",
      " [0.83262146]\n",
      " [0.82705277]\n",
      " [0.82062823]\n",
      " [0.81469232]\n",
      " [0.75513367]\n",
      " [0.85668772]\n",
      " [0.85314959]] | y: 0.7098024021697016 | Predicción actual: [[0.84787756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018287766724824905, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83262146]\n",
      " [0.82705277]\n",
      " [0.82062823]\n",
      " [0.81469232]\n",
      " [0.75513367]\n",
      " [0.85668772]\n",
      " [0.85314959]\n",
      " [0.84787756]] | y: 0.6904300658659435 | Predicción actual: [[0.8419753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06461872160434723, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82705277]\n",
      " [0.82062823]\n",
      " [0.81469232]\n",
      " [0.75513367]\n",
      " [0.85668772]\n",
      " [0.85314959]\n",
      " [0.84787756]\n",
      " [0.84197527]] | y: 0.7543587756683454 | Predicción actual: [[0.83661044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042016878724098206, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82062823]\n",
      " [0.81469232]\n",
      " [0.75513367]\n",
      " [0.85668772]\n",
      " [0.85314959]\n",
      " [0.84787756]\n",
      " [0.84197527]\n",
      " [0.83661044]] | y: 0.7222006974041069 | Predicción actual: [[0.8331436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009434607811272144, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81469232]\n",
      " [0.75513367]\n",
      " [0.85668772]\n",
      " [0.85314959]\n",
      " [0.84787756]\n",
      " [0.84197527]\n",
      " [0.83661044]\n",
      " [0.83314359]] | y: 0.8485083301046106 | Predicción actual: [[0.832547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021356074139475822, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.85668772]\n",
      " [0.85314959]\n",
      " [0.84787756]\n",
      " [0.84197527]\n",
      " [0.83661044]\n",
      " [0.83314359]\n",
      " [0.83254701]] | y: 0.9054629988376597 | Predicción actual: [[0.83483213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009678314090706408, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85668772]\n",
      " [0.85314959]\n",
      " [0.84787756]\n",
      " [0.84197527]\n",
      " [0.83661044]\n",
      " [0.83314359]\n",
      " [0.83254701]\n",
      " [0.83483213]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004710745066404343, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85314959]\n",
      " [0.84787756]\n",
      " [0.84197527]\n",
      " [0.83661044]\n",
      " [0.83314359]\n",
      " [0.83254701]\n",
      " [0.83483213]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.85111535]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010517645627260208, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84787756]\n",
      " [0.84197527]\n",
      " [0.83661044]\n",
      " [0.83314359]\n",
      " [0.83254701]\n",
      " [0.83483213]\n",
      " [0.8822162 ]\n",
      " [0.85111535]] | y: 0.889577683068578 | Predicción actual: [[0.8464795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010651794262230396, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84197527]\n",
      " [0.83661044]\n",
      " [0.83314359]\n",
      " [0.83254701]\n",
      " [0.83483213]\n",
      " [0.8822162 ]\n",
      " [0.85111535]\n",
      " [0.84647948]] | y: 0.8748547074777218 | Predicción actual: [[0.84368455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008583535440266132, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83661044]\n",
      " [0.83314359]\n",
      " [0.83254701]\n",
      " [0.83483213]\n",
      " [0.8822162 ]\n",
      " [0.85111535]\n",
      " [0.84647948]\n",
      " [0.84368455]] | y: 0.9132119333591631 | Predicción actual: [[0.843189]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00745593523606658, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83314359]\n",
      " [0.83254701]\n",
      " [0.83483213]\n",
      " [0.8822162 ]\n",
      " [0.85111535]\n",
      " [0.84647948]\n",
      " [0.84368455]\n",
      " [0.843189  ]] | y: 1.0 | Predicción actual: [[0.8450466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021876733750104904, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83254701]\n",
      " [0.83483213]\n",
      " [0.8822162 ]\n",
      " [0.85111535]\n",
      " [0.84647948]\n",
      " [0.84368455]\n",
      " [0.843189  ]\n",
      " [0.84504658]] | y: 0.9705540488182873 | Predicción actual: [[0.8489187]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0063217030838131905, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83483213]\n",
      " [0.8822162 ]\n",
      " [0.85111535]\n",
      " [0.84647948]\n",
      " [0.84368455]\n",
      " [0.843189  ]\n",
      " [0.84504658]\n",
      " [0.84891868]] | y: 0.8888027896164277 | Predicción actual: [[0.8537803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004679109901189804, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.85111535]\n",
      " [0.84647948]\n",
      " [0.84368455]\n",
      " [0.843189  ]\n",
      " [0.84504658]\n",
      " [0.84891868]\n",
      " [0.85378033]] | y: 0.877954281286323 | Predicción actual: [[0.85858244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027528724167495966, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85111535]\n",
      " [0.84647948]\n",
      " [0.84368455]\n",
      " [0.843189  ]\n",
      " [0.84504658]\n",
      " [0.84891868]\n",
      " [0.85378033]\n",
      " [0.85858244]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007284727762453258, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84647948]\n",
      " [0.84368455]\n",
      " [0.843189  ]\n",
      " [0.84504658]\n",
      " [0.84891868]\n",
      " [0.85378033]\n",
      " [0.85858244]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.84805363]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007174083730205894, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84368455]\n",
      " [0.843189  ]\n",
      " [0.84504658]\n",
      " [0.84891868]\n",
      " [0.85378033]\n",
      " [0.85858244]\n",
      " [0.84889578]\n",
      " [0.84805363]] | y: 0.8550949244478885 | Predicción actual: [[0.84838986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004084565211087465, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.843189  ]\n",
      " [0.84504658]\n",
      " [0.84891868]\n",
      " [0.85378033]\n",
      " [0.85858244]\n",
      " [0.84889578]\n",
      " [0.84805363]\n",
      " [0.84838986]] | y: 0.8752421542037967 | Predicción actual: [[0.849958]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016382650937885046, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84504658]\n",
      " [0.84891868]\n",
      " [0.85378033]\n",
      " [0.85858244]\n",
      " [0.84889578]\n",
      " [0.84805363]\n",
      " [0.84838986]\n",
      " [0.849958  ]] | y: 0.857032158078264 | Predicción actual: [[0.8520796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.449175008223392e-05, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84891868]\n",
      " [0.85378033]\n",
      " [0.85858244]\n",
      " [0.84889578]\n",
      " [0.84805363]\n",
      " [0.84838986]\n",
      " [0.849958  ]\n",
      " [0.85207957]] | y: 0.8500581170089112 | Predicción actual: [[0.85391504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012045880779623985, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85378033]\n",
      " [0.85858244]\n",
      " [0.84889578]\n",
      " [0.84805363]\n",
      " [0.84838986]\n",
      " [0.849958  ]\n",
      " [0.85207957]\n",
      " [0.85391504]] | y: 0.8426966292134832 | Predicción actual: [[0.85494554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015517856227234006, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85858244]\n",
      " [0.84889578]\n",
      " [0.84805363]\n",
      " [0.84838986]\n",
      " [0.849958  ]\n",
      " [0.85207957]\n",
      " [0.85391504]\n",
      " [0.85494554]] | y: 0.8229368461836497 | Predicción actual: [[0.85459316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004629675531759858, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.84805363]\n",
      " [0.84838986]\n",
      " [0.849958  ]\n",
      " [0.85207957]\n",
      " [0.85391504]\n",
      " [0.85494554]\n",
      " [0.85459316]] | y: 0.7745060054242543 | Predicción actual: [[0.85271585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011578110279515386, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84805363]\n",
      " [0.84838986]\n",
      " [0.849958  ]\n",
      " [0.85207957]\n",
      " [0.85391504]\n",
      " [0.85494554]\n",
      " [0.85459316]\n",
      " [0.85271585]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019859232008457184, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84838986]\n",
      " [0.849958  ]\n",
      " [0.85207957]\n",
      " [0.85391504]\n",
      " [0.85494554]\n",
      " [0.85459316]\n",
      " [0.85271585]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.85431]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017857305647339672, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.849958  ]\n",
      " [0.85207957]\n",
      " [0.85391504]\n",
      " [0.85494554]\n",
      " [0.85459316]\n",
      " [0.85271585]\n",
      " [0.78419217]\n",
      " [0.85430998]] | y: 0.854320030995738 | Predicción actual: [[0.8545027]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004878993146121502, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85207957]\n",
      " [0.85391504]\n",
      " [0.85494554]\n",
      " [0.85459316]\n",
      " [0.85271585]\n",
      " [0.78419217]\n",
      " [0.85430998]\n",
      " [0.85450268]] | y: 0.8368849283223556 | Predicción actual: [[0.85359114]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033829815220087767, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85391504]\n",
      " [0.85494554]\n",
      " [0.85459316]\n",
      " [0.85271585]\n",
      " [0.78419217]\n",
      " [0.85430998]\n",
      " [0.85450268]\n",
      " [0.85359114]] | y: 0.8299108872530028 | Predicción actual: [[0.85165006]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.135480361990631e-06, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85494554]\n",
      " [0.85459316]\n",
      " [0.85271585]\n",
      " [0.78419217]\n",
      " [0.85430998]\n",
      " [0.85450268]\n",
      " [0.85359114]\n",
      " [0.85165006]] | y: 0.887253002712127 | Predicción actual: [[0.8486874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00023219625290948898, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85459316]\n",
      " [0.85271585]\n",
      " [0.78419217]\n",
      " [0.85430998]\n",
      " [0.85450268]\n",
      " [0.85359114]\n",
      " [0.85165006]\n",
      " [0.84868741]] | y: 0.8597442851607902 | Predicción actual: [[0.84503037]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01485932432115078, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85271585]\n",
      " [0.78419217]\n",
      " [0.85430998]\n",
      " [0.85450268]\n",
      " [0.85359114]\n",
      " [0.85165006]\n",
      " [0.84868741]\n",
      " [0.84503037]] | y: 0.8395970554048819 | Predicción actual: [[0.8410182]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009838627884164453, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.85430998]\n",
      " [0.85450268]\n",
      " [0.85359114]\n",
      " [0.85165006]\n",
      " [0.84868741]\n",
      " [0.84503037]\n",
      " [0.8410182 ]] | y: 0.7838047268500579 | Predicción actual: [[0.8376461]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021495843306183815, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85430998]\n",
      " [0.85450268]\n",
      " [0.85359114]\n",
      " [0.85165006]\n",
      " [0.84868741]\n",
      " [0.84503037]\n",
      " [0.8410182 ]\n",
      " [0.83764613]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003988809417933226, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85450268]\n",
      " [0.85359114]\n",
      " [0.85165006]\n",
      " [0.84868741]\n",
      " [0.84503037]\n",
      " [0.8410182 ]\n",
      " [0.83764613]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8527264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001934730535140261, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85359114]\n",
      " [0.85165006]\n",
      " [0.84868741]\n",
      " [0.84503037]\n",
      " [0.8410182 ]\n",
      " [0.83764613]\n",
      " [0.81828749]\n",
      " [0.8527264 ]] | y: 0.7605579232855482 | Predicción actual: [[0.8498554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025109148118644953, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85165006]\n",
      " [0.84868741]\n",
      " [0.84503037]\n",
      " [0.8410182 ]\n",
      " [0.83764613]\n",
      " [0.81828749]\n",
      " [0.8527264 ]\n",
      " [0.84985542]] | y: 0.7915536613715615 | Predicción actual: [[0.8465191]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00018941554299090058, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84868741]\n",
      " [0.84503037]\n",
      " [0.8410182 ]\n",
      " [0.83764613]\n",
      " [0.81828749]\n",
      " [0.8527264 ]\n",
      " [0.84985542]\n",
      " [0.84651911]] | y: 0.7686943045331267 | Predicción actual: [[0.84324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06131943687796593, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84503037]\n",
      " [0.8410182 ]\n",
      " [0.83764613]\n",
      " [0.81828749]\n",
      " [0.8527264 ]\n",
      " [0.84985542]\n",
      " [0.84651911]\n",
      " [0.84324002]] | y: 0.7686943045331267 | Predicción actual: [[0.8399773]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009329106658697128, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8410182 ]\n",
      " [0.83764613]\n",
      " [0.81828749]\n",
      " [0.8527264 ]\n",
      " [0.84985542]\n",
      " [0.84651911]\n",
      " [0.84324002]\n",
      " [0.83997732]] | y: 0.7989151491669895 | Predicción actual: [[0.8379076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003250675508752465, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83764613]\n",
      " [0.81828749]\n",
      " [0.8527264 ]\n",
      " [0.84985542]\n",
      " [0.84651911]\n",
      " [0.84324002]\n",
      " [0.83997732]\n",
      " [0.83790761]] | y: 0.7900038744672608 | Predicción actual: [[0.83710116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010911468416452408, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.8527264 ]\n",
      " [0.84985542]\n",
      " [0.84651911]\n",
      " [0.84324002]\n",
      " [0.83997732]\n",
      " [0.83790761]\n",
      " [0.83710116]] | y: 0.760170476559473 | Predicción actual: [[0.8373053]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009498539380729198, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8527264 ]\n",
      " [0.84985542]\n",
      " [0.84651911]\n",
      " [0.84324002]\n",
      " [0.83997732]\n",
      " [0.83790761]\n",
      " [0.83710116]\n",
      " [0.83730531]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017791112884879112, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84985542]\n",
      " [0.84651911]\n",
      " [0.84324002]\n",
      " [0.83997732]\n",
      " [0.83790761]\n",
      " [0.83710116]\n",
      " [0.83730531]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.83860046]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.20142370462417603, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84651911]\n",
      " [0.84324002]\n",
      " [0.83997732]\n",
      " [0.83790761]\n",
      " [0.83710116]\n",
      " [0.83730531]\n",
      " [0.68539326]\n",
      " [0.83860046]] | y: 0.6648585819449826 | Predicción actual: [[0.8316757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.14084377884864807, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84324002]\n",
      " [0.83997732]\n",
      " [0.83790761]\n",
      " [0.83710116]\n",
      " [0.83730531]\n",
      " [0.68539326]\n",
      " [0.83860046]\n",
      " [0.83167571]] | y: 0.7078651685393258 | Predicción actual: [[0.8230511]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05305574834346771, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83997732]\n",
      " [0.83790761]\n",
      " [0.83710116]\n",
      " [0.83730531]\n",
      " [0.68539326]\n",
      " [0.83860046]\n",
      " [0.83167571]\n",
      " [0.8230511 ]] | y: 0.6648585819449826 | Predicción actual: [[0.81334066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019393064081668854, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83790761]\n",
      " [0.83710116]\n",
      " [0.83730531]\n",
      " [0.68539326]\n",
      " [0.83860046]\n",
      " [0.83167571]\n",
      " [0.8230511 ]\n",
      " [0.81334066]] | y: 0.7113521890740022 | Predicción actual: [[0.8030836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043895501643419266, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83710116]\n",
      " [0.83730531]\n",
      " [0.68539326]\n",
      " [0.83860046]\n",
      " [0.83167571]\n",
      " [0.8230511 ]\n",
      " [0.81334066]\n",
      " [0.8030836 ]] | y: 0.6772568771793879 | Predicción actual: [[0.79208016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026818744838237762, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83730531]\n",
      " [0.68539326]\n",
      " [0.83860046]\n",
      " [0.83167571]\n",
      " [0.8230511 ]\n",
      " [0.81334066]\n",
      " [0.8030836 ]\n",
      " [0.79208016]] | y: 0.7621077101898488 | Predicción actual: [[0.7803461]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0070854793302714825, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.83860046]\n",
      " [0.83167571]\n",
      " [0.8230511 ]\n",
      " [0.81334066]\n",
      " [0.8030836 ]\n",
      " [0.79208016]\n",
      " [0.7803461 ]] | y: 0.8070515304145678 | Predicción actual: [[0.76814044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01205059140920639, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83860046]\n",
      " [0.83167571]\n",
      " [0.8230511 ]\n",
      " [0.81334066]\n",
      " [0.8030836 ]\n",
      " [0.79208016]\n",
      " [0.7803461 ]\n",
      " [0.76814044]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02728353627026081, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83167571]\n",
      " [0.8230511 ]\n",
      " [0.81334066]\n",
      " [0.8030836 ]\n",
      " [0.79208016]\n",
      " [0.7803461 ]\n",
      " [0.76814044]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.78962654]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.366089458722854e-06, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8230511 ]\n",
      " [0.81334066]\n",
      " [0.8030836 ]\n",
      " [0.79208016]\n",
      " [0.7803461 ]\n",
      " [0.76814044]\n",
      " [0.81518791]\n",
      " [0.78962654]] | y: 0.9597055404881829 | Predicción actual: [[0.78025967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09350574016571045, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81334066]\n",
      " [0.8030836 ]\n",
      " [0.79208016]\n",
      " [0.7803461 ]\n",
      " [0.76814044]\n",
      " [0.81518791]\n",
      " [0.78962654]\n",
      " [0.78025967]] | y: 0.9643549012010848 | Predicción actual: [[0.77215064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02887794002890587, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8030836 ]\n",
      " [0.79208016]\n",
      " [0.7803461 ]\n",
      " [0.76814044]\n",
      " [0.81518791]\n",
      " [0.78962654]\n",
      " [0.78025967]\n",
      " [0.77215064]] | y: 0.8880278961642774 | Predicción actual: [[0.76570845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02419268898665905, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79208016]\n",
      " [0.7803461 ]\n",
      " [0.76814044]\n",
      " [0.81518791]\n",
      " [0.78962654]\n",
      " [0.78025967]\n",
      " [0.77215064]\n",
      " [0.76570845]] | y: 0.8926772568771792 | Predicción actual: [[0.761259]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02461552992463112, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7803461 ]\n",
      " [0.76814044]\n",
      " [0.81518791]\n",
      " [0.78962654]\n",
      " [0.78025967]\n",
      " [0.77215064]\n",
      " [0.76570845]\n",
      " [0.76125902]] | y: 0.8752421542037967 | Predicción actual: [[0.759192]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024575315415859222, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76814044]\n",
      " [0.81518791]\n",
      " [0.78962654]\n",
      " [0.78025967]\n",
      " [0.77215064]\n",
      " [0.76570845]\n",
      " [0.76125902]\n",
      " [0.75919199]] | y: 0.8508330104610615 | Predicción actual: [[0.7598403]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008846753626130521, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78962654]\n",
      " [0.78025967]\n",
      " [0.77215064]\n",
      " [0.76570845]\n",
      " [0.76125902]\n",
      " [0.75919199]\n",
      " [0.75984031]] | y: 0.8488957768306855 | Predicción actual: [[0.7631716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007446941453963518, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78962654]\n",
      " [0.78025967]\n",
      " [0.77215064]\n",
      " [0.76570845]\n",
      " [0.76125902]\n",
      " [0.75919199]\n",
      " [0.75984031]\n",
      " [0.76317161]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06720273941755295, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78025967]\n",
      " [0.77215064]\n",
      " [0.76570845]\n",
      " [0.76125902]\n",
      " [0.75919199]\n",
      " [0.75984031]\n",
      " [0.76317161]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7488383]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08232459425926208, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77215064]\n",
      " [0.76570845]\n",
      " [0.76125902]\n",
      " [0.75919199]\n",
      " [0.75984031]\n",
      " [0.76317161]\n",
      " [0.96241767]\n",
      " [0.74883831]] | y: 0.9407206509104997 | Predicción actual: [[0.748598]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09349910914897919, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76570845]\n",
      " [0.76125902]\n",
      " [0.75919199]\n",
      " [0.75984031]\n",
      " [0.76317161]\n",
      " [0.96241767]\n",
      " [0.74883831]\n",
      " [0.74859798]] | y: 0.9724912824486633 | Predicción actual: [[0.75194544]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03493037074804306, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76125902]\n",
      " [0.75919199]\n",
      " [0.75984031]\n",
      " [0.76317161]\n",
      " [0.96241767]\n",
      " [0.74883831]\n",
      " [0.74859798]\n",
      " [0.75194544]] | y: 0.9969004261913985 | Predicción actual: [[0.7583826]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06076645851135254, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75919199]\n",
      " [0.75984031]\n",
      " [0.76317161]\n",
      " [0.96241767]\n",
      " [0.74883831]\n",
      " [0.74859798]\n",
      " [0.75194544]\n",
      " [0.75838262]] | y: 0.951181712514529 | Predicción actual: [[0.76722646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03886896371841431, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75984031]\n",
      " [0.76317161]\n",
      " [0.96241767]\n",
      " [0.74883831]\n",
      " [0.74859798]\n",
      " [0.75194544]\n",
      " [0.75838262]\n",
      " [0.76722646]] | y: 0.8957768306857805 | Predicción actual: [[0.7773623]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01696055382490158, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76317161]\n",
      " [0.96241767]\n",
      " [0.74883831]\n",
      " [0.74859798]\n",
      " [0.75194544]\n",
      " [0.75838262]\n",
      " [0.76722646]\n",
      " [0.77736229]] | y: 0.8814413018209997 | Predicción actual: [[0.78748846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004629394970834255, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.74883831]\n",
      " [0.74859798]\n",
      " [0.75194544]\n",
      " [0.75838262]\n",
      " [0.76722646]\n",
      " [0.77736229]\n",
      " [0.78748846]] | y: 0.9170864006199149 | Predicción actual: [[0.79605496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010888717137277126, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74883831]\n",
      " [0.74859798]\n",
      " [0.75194544]\n",
      " [0.75838262]\n",
      " [0.76722646]\n",
      " [0.77736229]\n",
      " [0.78748846]\n",
      " [0.79605496]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025696931406855583, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74859798]\n",
      " [0.75194544]\n",
      " [0.75838262]\n",
      " [0.76722646]\n",
      " [0.77736229]\n",
      " [0.78748846]\n",
      " [0.79605496]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.75249434]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05633719637989998, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75194544]\n",
      " [0.75838262]\n",
      " [0.76722646]\n",
      " [0.77736229]\n",
      " [0.78748846]\n",
      " [0.79605496]\n",
      " [0.91979853]\n",
      " [0.75249434]] | y: 0.9682293684618366 | Predicción actual: [[0.76191145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.059847794473171234, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75838262]\n",
      " [0.76722646]\n",
      " [0.77736229]\n",
      " [0.78748846]\n",
      " [0.79605496]\n",
      " [0.91979853]\n",
      " [0.75249434]\n",
      " [0.76191145]] | y: 0.9577683068578069 | Predicción actual: [[0.77315736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0634147971868515, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20287555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020604996010661125, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287555]] | y: 0.10422316931421921 | Predicción actual: [[0.18745911]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003786018118262291, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287555]\n",
      " [0.18745911]] | y: 0.15420379697791559 | Predicción actual: [[0.19173895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007979240617714822, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287555]\n",
      " [0.18745911]\n",
      " [0.19173895]] | y: 0.1557535838822161 | Predicción actual: [[0.20338166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.80260855006054e-05, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287555]\n",
      " [0.18745911]\n",
      " [0.19173895]\n",
      " [0.20338166]] | y: 0.12553273924835334 | Predicción actual: [[0.21616234]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00962609052658081, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287555]\n",
      " [0.18745911]\n",
      " [0.19173895]\n",
      " [0.20338166]\n",
      " [0.21616234]] | y: 0.1456799690042619 | Predicción actual: [[0.22623993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006973715499043465, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287555]\n",
      " [0.18745911]\n",
      " [0.19173895]\n",
      " [0.20338166]\n",
      " [0.21616234]\n",
      " [0.22623993]] | y: 0.1464548624564122 | Predicción actual: [[0.24781126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010873512364923954, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20287555]\n",
      " [0.18745911]\n",
      " [0.19173895]\n",
      " [0.20338166]\n",
      " [0.21616234]\n",
      " [0.22623993]\n",
      " [0.24781126]] | y: 0.1960480433940332 | Predicción actual: [[0.27433446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011514914222061634, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20287555]\n",
      " [0.18745911]\n",
      " [0.19173895]\n",
      " [0.20338166]\n",
      " [0.21616234]\n",
      " [0.22623993]\n",
      " [0.24781126]\n",
      " [0.27433446]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005121024791151285, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18745911]\n",
      " [0.19173895]\n",
      " [0.20338166]\n",
      " [0.21616234]\n",
      " [0.22623993]\n",
      " [0.24781126]\n",
      " [0.27433446]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.30851308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009041414596140385, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19173895]\n",
      " [0.20338166]\n",
      " [0.21616234]\n",
      " [0.22623993]\n",
      " [0.24781126]\n",
      " [0.27433446]\n",
      " [0.2305308 ]\n",
      " [0.30851308]] | y: 0.211933359163115 | Predicción actual: [[0.3159361]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007694441359490156, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20338166]\n",
      " [0.21616234]\n",
      " [0.22623993]\n",
      " [0.24781126]\n",
      " [0.27433446]\n",
      " [0.2305308 ]\n",
      " [0.30851308]\n",
      " [0.31593609]] | y: 0.2072839984502131 | Predicción actual: [[0.325242]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012772510759532452, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21616234]\n",
      " [0.22623993]\n",
      " [0.24781126]\n",
      " [0.27433446]\n",
      " [0.2305308 ]\n",
      " [0.30851308]\n",
      " [0.31593609]\n",
      " [0.32524201]] | y: 0.19294846958543205 | Predicción actual: [[0.33517396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021281199529767036, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22623993]\n",
      " [0.24781126]\n",
      " [0.27433446]\n",
      " [0.2305308 ]\n",
      " [0.30851308]\n",
      " [0.31593609]\n",
      " [0.32524201]\n",
      " [0.33517396]] | y: 0.19682293684618352 | Predicción actual: [[0.3456312]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009452407248318195, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24781126]\n",
      " [0.27433446]\n",
      " [0.2305308 ]\n",
      " [0.30851308]\n",
      " [0.31593609]\n",
      " [0.32524201]\n",
      " [0.33517396]\n",
      " [0.34563121]] | y: 0.21425803951956607 | Predicción actual: [[0.35737306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021508002653717995, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27433446]\n",
      " [0.2305308 ]\n",
      " [0.30851308]\n",
      " [0.31593609]\n",
      " [0.32524201]\n",
      " [0.33517396]\n",
      " [0.34563121]\n",
      " [0.35737306]] | y: 0.18132506780317698 | Predicción actual: [[0.36774588]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05526973307132721, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.30851308]\n",
      " [0.31593609]\n",
      " [0.32524201]\n",
      " [0.33517396]\n",
      " [0.34563121]\n",
      " [0.35737306]\n",
      " [0.36774588]] | y: 0.17512592018597434 | Predicción actual: [[0.375178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026244957000017166, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30851308]\n",
      " [0.31593609]\n",
      " [0.32524201]\n",
      " [0.33517396]\n",
      " [0.34563121]\n",
      " [0.35737306]\n",
      " [0.36774588]\n",
      " [0.37517801]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06140671297907829, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31593609]\n",
      " [0.32524201]\n",
      " [0.33517396]\n",
      " [0.34563121]\n",
      " [0.35737306]\n",
      " [0.36774588]\n",
      " [0.37517801]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40178916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04258417710661888, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32524201]\n",
      " [0.33517396]\n",
      " [0.34563121]\n",
      " [0.35737306]\n",
      " [0.36774588]\n",
      " [0.37517801]\n",
      " [0.14800465]\n",
      " [0.40178916]] | y: 0.19217357613328173 | Predicción actual: [[0.4059819]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030430883169174194, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33517396]\n",
      " [0.34563121]\n",
      " [0.35737306]\n",
      " [0.36774588]\n",
      " [0.37517801]\n",
      " [0.14800465]\n",
      " [0.40178916]\n",
      " [0.4059819 ]] | y: 0.1859744285160791 | Predicción actual: [[0.4084341]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02956256829202175, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34563121]\n",
      " [0.35737306]\n",
      " [0.36774588]\n",
      " [0.37517801]\n",
      " [0.14800465]\n",
      " [0.40178916]\n",
      " [0.4059819 ]\n",
      " [0.40843409]] | y: 0.26695079426578844 | Predicción actual: [[0.4091823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010748636908829212, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35737306]\n",
      " [0.36774588]\n",
      " [0.37517801]\n",
      " [0.14800465]\n",
      " [0.40178916]\n",
      " [0.4059819 ]\n",
      " [0.40843409]\n",
      " [0.40918231]] | y: 0.2925222781867493 | Predicción actual: [[0.40844235]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018406124785542488, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36774588]\n",
      " [0.37517801]\n",
      " [0.14800465]\n",
      " [0.40178916]\n",
      " [0.4059819 ]\n",
      " [0.40843409]\n",
      " [0.40918231]\n",
      " [0.40844235]] | y: 0.3177063153816349 | Predicción actual: [[0.4062095]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01313857827335596, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37517801]\n",
      " [0.14800465]\n",
      " [0.40178916]\n",
      " [0.4059819 ]\n",
      " [0.40843409]\n",
      " [0.40918231]\n",
      " [0.40844235]\n",
      " [0.4062095 ]] | y: 0.31266950794265785 | Predicción actual: [[0.4030889]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010056547820568085, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40178916]\n",
      " [0.4059819 ]\n",
      " [0.40843409]\n",
      " [0.40918231]\n",
      " [0.40844235]\n",
      " [0.4062095 ]\n",
      " [0.4030889 ]] | y: 0.2890352576520729 | Predicción actual: [[0.40001062]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01615234650671482, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40178916]\n",
      " [0.4059819 ]\n",
      " [0.40843409]\n",
      " [0.40918231]\n",
      " [0.40844235]\n",
      " [0.4062095 ]\n",
      " [0.4030889 ]\n",
      " [0.40001062]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07639521360397339, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4059819 ]\n",
      " [0.40843409]\n",
      " [0.40918231]\n",
      " [0.40844235]\n",
      " [0.4062095 ]\n",
      " [0.4030889 ]\n",
      " [0.40001062]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.45494848]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02650025486946106, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40843409]\n",
      " [0.40918231]\n",
      " [0.40844235]\n",
      " [0.4062095 ]\n",
      " [0.4030889 ]\n",
      " [0.40001062]\n",
      " [0.28283611]\n",
      " [0.45494848]] | y: 0.2758620689655173 | Predicción actual: [[0.45293814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02302810736000538, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40918231]\n",
      " [0.40844235]\n",
      " [0.4062095 ]\n",
      " [0.4030889 ]\n",
      " [0.40001062]\n",
      " [0.28283611]\n",
      " [0.45494848]\n",
      " [0.45293814]] | y: 0.2746997287872917 | Predicción actual: [[0.44984433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05925537273287773, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40844235]\n",
      " [0.4062095 ]\n",
      " [0.4030889 ]\n",
      " [0.40001062]\n",
      " [0.28283611]\n",
      " [0.45494848]\n",
      " [0.45293814]\n",
      " [0.44984433]] | y: 0.275474622239442 | Predicción actual: [[0.446458]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02713189274072647, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4062095 ]\n",
      " [0.4030889 ]\n",
      " [0.40001062]\n",
      " [0.28283611]\n",
      " [0.45494848]\n",
      " [0.45293814]\n",
      " [0.44984433]\n",
      " [0.44645801]] | y: 0.3347539713289423 | Predicción actual: [[0.44377664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017421584576368332, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4030889 ]\n",
      " [0.40001062]\n",
      " [0.28283611]\n",
      " [0.45494848]\n",
      " [0.45293814]\n",
      " [0.44984433]\n",
      " [0.44645801]\n",
      " [0.44377664]] | y: 0.35567609453700116 | Predicción actual: [[0.4427309]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017478590831160545, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40001062]\n",
      " [0.28283611]\n",
      " [0.45494848]\n",
      " [0.45293814]\n",
      " [0.44984433]\n",
      " [0.44645801]\n",
      " [0.44377664]\n",
      " [0.4427309 ]] | y: 0.3366912049593181 | Predicción actual: [[0.44400603]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016824116930365562, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.45494848]\n",
      " [0.45293814]\n",
      " [0.44984433]\n",
      " [0.44645801]\n",
      " [0.44377664]\n",
      " [0.4427309 ]\n",
      " [0.44400603]] | y: 0.3335916311507167 | Predicción actual: [[0.4479547]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034350160509347916, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45494848]\n",
      " [0.45293814]\n",
      " [0.44984433]\n",
      " [0.44645801]\n",
      " [0.44377664]\n",
      " [0.4427309 ]\n",
      " [0.44400603]\n",
      " [0.44795471]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02265077829360962, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45293814]\n",
      " [0.44984433]\n",
      " [0.44645801]\n",
      " [0.44377664]\n",
      " [0.4427309 ]\n",
      " [0.44400603]\n",
      " [0.44795471]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.4806037]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.99339728069026e-06, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44984433]\n",
      " [0.44645801]\n",
      " [0.44377664]\n",
      " [0.4427309 ]\n",
      " [0.44400603]\n",
      " [0.44795471]\n",
      " [0.3847346 ]\n",
      " [0.48060369]] | y: 0.5962805114296785 | Predicción actual: [[0.47753936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009311090223491192, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44645801]\n",
      " [0.44377664]\n",
      " [0.4427309 ]\n",
      " [0.44400603]\n",
      " [0.44795471]\n",
      " [0.3847346 ]\n",
      " [0.48060369]\n",
      " [0.47753936]] | y: 0.574583494769469 | Predicción actual: [[0.47510266]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003143667709082365, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44377664]\n",
      " [0.4427309 ]\n",
      " [0.44400603]\n",
      " [0.44795471]\n",
      " [0.3847346 ]\n",
      " [0.48060369]\n",
      " [0.47753936]\n",
      " [0.47510266]] | y: 0.6063541263076326 | Predicción actual: [[0.47376966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014517340809106827, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4427309 ]\n",
      " [0.44400603]\n",
      " [0.44795471]\n",
      " [0.3847346 ]\n",
      " [0.48060369]\n",
      " [0.47753936]\n",
      " [0.47510266]\n",
      " [0.47376966]] | y: 0.5846571096474236 | Predicción actual: [[0.47383913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017820902867242694, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44400603]\n",
      " [0.44795471]\n",
      " [0.3847346 ]\n",
      " [0.48060369]\n",
      " [0.47753936]\n",
      " [0.47510266]\n",
      " [0.47376966]\n",
      " [0.47383913]] | y: 0.5687717938783416 | Predicción actual: [[0.47521132]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021560298278927803, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44795471]\n",
      " [0.3847346 ]\n",
      " [0.48060369]\n",
      " [0.47753936]\n",
      " [0.47510266]\n",
      " [0.47376966]\n",
      " [0.47383913]\n",
      " [0.47521132]] | y: 0.6427741185586981 | Predicción actual: [[0.47759563]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030587902292609215, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.48060369]\n",
      " [0.47753936]\n",
      " [0.47510266]\n",
      " [0.47376966]\n",
      " [0.47383913]\n",
      " [0.47521132]\n",
      " [0.47759563]] | y: 0.6617590081363811 | Predicción actual: [[0.48044038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00790321547538042, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48060369]\n",
      " [0.47753936]\n",
      " [0.47510266]\n",
      " [0.47376966]\n",
      " [0.47383913]\n",
      " [0.47521132]\n",
      " [0.47759563]\n",
      " [0.48044038]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04627004265785217, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47753936]\n",
      " [0.47510266]\n",
      " [0.47376966]\n",
      " [0.47383913]\n",
      " [0.47521132]\n",
      " [0.47759563]\n",
      " [0.48044038]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.501003]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012115586549043655, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47510266]\n",
      " [0.47376966]\n",
      " [0.47383913]\n",
      " [0.47521132]\n",
      " [0.47759563]\n",
      " [0.48044038]\n",
      " [0.67299496]\n",
      " [0.50100303]] | y: 0.703990701278574 | Predicción actual: [[0.5036747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03063741885125637, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47376966]\n",
      " [0.47383913]\n",
      " [0.47521132]\n",
      " [0.47759563]\n",
      " [0.48044038]\n",
      " [0.67299496]\n",
      " [0.50100303]\n",
      " [0.50367469]] | y: 0.7272375048430839 | Predicción actual: [[0.5091749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07003223150968552, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47383913]\n",
      " [0.47521132]\n",
      " [0.47759563]\n",
      " [0.48044038]\n",
      " [0.67299496]\n",
      " [0.50100303]\n",
      " [0.50367469]\n",
      " [0.50917488]] | y: 0.722588144130182 | Predicción actual: [[0.517429]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07238851487636566, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47521132]\n",
      " [0.47759563]\n",
      " [0.48044038]\n",
      " [0.67299496]\n",
      " [0.50100303]\n",
      " [0.50367469]\n",
      " [0.50917488]\n",
      " [0.51742899]] | y: 0.771793878341728 | Predicción actual: [[0.5280391]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03443527594208717, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47759563]\n",
      " [0.48044038]\n",
      " [0.67299496]\n",
      " [0.50100303]\n",
      " [0.50367469]\n",
      " [0.50917488]\n",
      " [0.51742899]\n",
      " [0.5280391 ]] | y: 0.7245253777605578 | Predicción actual: [[0.5404875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020337343215942383, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48044038]\n",
      " [0.67299496]\n",
      " [0.50100303]\n",
      " [0.50367469]\n",
      " [0.50917488]\n",
      " [0.51742899]\n",
      " [0.5280391 ]\n",
      " [0.54048753]] | y: 0.6710577295621851 | Predicción actual: [[0.55425715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0237127635627985, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.50100303]\n",
      " [0.50367469]\n",
      " [0.50917488]\n",
      " [0.51742899]\n",
      " [0.5280391 ]\n",
      " [0.54048753]\n",
      " [0.55425715]] | y: 0.6737698566447115 | Predicción actual: [[0.5690286]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007006044033914804, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50100303]\n",
      " [0.50367469]\n",
      " [0.50917488]\n",
      " [0.51742899]\n",
      " [0.5280391 ]\n",
      " [0.54048753]\n",
      " [0.55425715]\n",
      " [0.56902862]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07729672640562057, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50367469]\n",
      " [0.50917488]\n",
      " [0.51742899]\n",
      " [0.5280391 ]\n",
      " [0.54048753]\n",
      " [0.55425715]\n",
      " [0.56902862]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5413587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08346352726221085, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50917488]\n",
      " [0.51742899]\n",
      " [0.5280391 ]\n",
      " [0.54048753]\n",
      " [0.55425715]\n",
      " [0.56902862]\n",
      " [0.71445176]\n",
      " [0.54135871]] | y: 0.722588144130182 | Predicción actual: [[0.55184585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06375465542078018, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51742899]\n",
      " [0.5280391 ]\n",
      " [0.54048753]\n",
      " [0.55425715]\n",
      " [0.56902862]\n",
      " [0.71445176]\n",
      " [0.54135871]\n",
      " [0.55184585]] | y: 0.6993413405656723 | Predicción actual: [[0.5644353]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019841276109218597, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5280391 ]\n",
      " [0.54048753]\n",
      " [0.55425715]\n",
      " [0.56902862]\n",
      " [0.71445176]\n",
      " [0.54135871]\n",
      " [0.55184585]\n",
      " [0.5644353 ]] | y: 0.7373111197210385 | Predicción actual: [[0.5780154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06296093761920929, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54048753]\n",
      " [0.55425715]\n",
      " [0.56902862]\n",
      " [0.71445176]\n",
      " [0.54135871]\n",
      " [0.55184585]\n",
      " [0.5644353 ]\n",
      " [0.57801539]] | y: 0.7214258039519565 | Predicción actual: [[0.59147406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03751891106367111, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55425715]\n",
      " [0.56902862]\n",
      " [0.71445176]\n",
      " [0.54135871]\n",
      " [0.55184585]\n",
      " [0.5644353 ]\n",
      " [0.57801539]\n",
      " [0.59147406]] | y: 0.7187136768694304 | Predicción actual: [[0.6036447]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005543093429878354, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56902862]\n",
      " [0.71445176]\n",
      " [0.54135871]\n",
      " [0.55184585]\n",
      " [0.5644353 ]\n",
      " [0.57801539]\n",
      " [0.59147406]\n",
      " [0.60364473]] | y: 0.6741573033707864 | Predicción actual: [[0.61334217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004939422942698002, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.54135871]\n",
      " [0.55184585]\n",
      " [0.5644353 ]\n",
      " [0.57801539]\n",
      " [0.59147406]\n",
      " [0.60364473]\n",
      " [0.61334217]] | y: 0.698566447113522 | Predicción actual: [[0.6198622]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017319021746516228, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54135871]\n",
      " [0.55184585]\n",
      " [0.5644353 ]\n",
      " [0.57801539]\n",
      " [0.59147406]\n",
      " [0.60364473]\n",
      " [0.61334217]\n",
      " [0.6198622 ]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003219189355149865, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55184585]\n",
      " [0.5644353 ]\n",
      " [0.57801539]\n",
      " [0.59147406]\n",
      " [0.60364473]\n",
      " [0.61334217]\n",
      " [0.6198622 ]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.5985315]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013702441938221455, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5644353 ]\n",
      " [0.57801539]\n",
      " [0.59147406]\n",
      " [0.60364473]\n",
      " [0.61334217]\n",
      " [0.6198622 ]\n",
      " [0.72103836]\n",
      " [0.59853148]] | y: 0.7562960092987214 | Predicción actual: [[0.61132914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007967705838382244, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57801539]\n",
      " [0.59147406]\n",
      " [0.60364473]\n",
      " [0.61334217]\n",
      " [0.6198622 ]\n",
      " [0.72103836]\n",
      " [0.59853148]\n",
      " [0.61132914]] | y: 0.8275862068965516 | Predicción actual: [[0.6241077]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05529341101646423, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59147406]\n",
      " [0.60364473]\n",
      " [0.61334217]\n",
      " [0.6198622 ]\n",
      " [0.72103836]\n",
      " [0.59853148]\n",
      " [0.61132914]\n",
      " [0.62410772]] | y: 0.8388221619527314 | Predicción actual: [[0.6361359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05743609741330147, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60364473]\n",
      " [0.61334217]\n",
      " [0.6198622 ]\n",
      " [0.72103836]\n",
      " [0.59853148]\n",
      " [0.61132914]\n",
      " [0.62410772]\n",
      " [0.63613588]] | y: 0.7942657884540876 | Predicción actual: [[0.64678204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00936888437718153, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61334217]\n",
      " [0.6198622 ]\n",
      " [0.72103836]\n",
      " [0.59853148]\n",
      " [0.61132914]\n",
      " [0.62410772]\n",
      " [0.63613588]\n",
      " [0.64678204]] | y: 0.7838047268500579 | Predicción actual: [[0.6556554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.7929686590796337e-05, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6198622 ]\n",
      " [0.72103836]\n",
      " [0.59853148]\n",
      " [0.61132914]\n",
      " [0.62410772]\n",
      " [0.63613588]\n",
      " [0.64678204]\n",
      " [0.65565538]] | y: 0.7679194110809764 | Predicción actual: [[0.66288304]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011176034808158875, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.59853148]\n",
      " [0.61132914]\n",
      " [0.62410772]\n",
      " [0.63613588]\n",
      " [0.64678204]\n",
      " [0.65565538]\n",
      " [0.66288304]] | y: 0.7845796203022084 | Predicción actual: [[0.669223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02352466806769371, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59853148]\n",
      " [0.61132914]\n",
      " [0.62410772]\n",
      " [0.63613588]\n",
      " [0.64678204]\n",
      " [0.65565538]\n",
      " [0.66288304]\n",
      " [0.66922301]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04229799285531044, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61132914]\n",
      " [0.62410772]\n",
      " [0.63613588]\n",
      " [0.64678204]\n",
      " [0.65565538]\n",
      " [0.66288304]\n",
      " [0.66922301]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6604171]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004027336835861206, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62410772]\n",
      " [0.63613588]\n",
      " [0.64678204]\n",
      " [0.65565538]\n",
      " [0.66288304]\n",
      " [0.66922301]\n",
      " [0.87872917]\n",
      " [0.66041708]] | y: 0.8488957768306855 | Predicción actual: [[0.6744407]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006579721812158823, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63613588]\n",
      " [0.64678204]\n",
      " [0.65565538]\n",
      " [0.66288304]\n",
      " [0.66922301]\n",
      " [0.87872917]\n",
      " [0.66041708]\n",
      " [0.67444068]] | y: 0.8182874854707476 | Predicción actual: [[0.6892113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01822667196393013, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64678204]\n",
      " [0.65565538]\n",
      " [0.66288304]\n",
      " [0.66922301]\n",
      " [0.87872917]\n",
      " [0.66041708]\n",
      " [0.67444068]\n",
      " [0.68921131]] | y: 0.8268113134444013 | Predicción actual: [[0.704469]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.087213867227547e-05, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65565538]\n",
      " [0.66288304]\n",
      " [0.66922301]\n",
      " [0.87872917]\n",
      " [0.66041708]\n",
      " [0.67444068]\n",
      " [0.68921131]\n",
      " [0.70446903]] | y: 0.7853545137543589 | Predicción actual: [[0.7197996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025217323563992977, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66288304]\n",
      " [0.66922301]\n",
      " [0.87872917]\n",
      " [0.66041708]\n",
      " [0.67444068]\n",
      " [0.68921131]\n",
      " [0.70446903]\n",
      " [0.71979958]] | y: 0.7892289810151103 | Predicción actual: [[0.73501194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002931504510343075, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66922301]\n",
      " [0.87872917]\n",
      " [0.66041708]\n",
      " [0.67444068]\n",
      " [0.68921131]\n",
      " [0.70446903]\n",
      " [0.71979958]\n",
      " [0.73501194]] | y: 0.8341728012398295 | Predicción actual: [[0.75009316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005706333322450519, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.66041708]\n",
      " [0.67444068]\n",
      " [0.68921131]\n",
      " [0.70446903]\n",
      " [0.71979958]\n",
      " [0.73501194]\n",
      " [0.75009316]] | y: 0.8124757845796202 | Predicción actual: [[0.76511]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022354407235980034, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66041708]\n",
      " [0.67444068]\n",
      " [0.68921131]\n",
      " [0.70446903]\n",
      " [0.71979958]\n",
      " [0.73501194]\n",
      " [0.75009316]\n",
      " [0.76511002]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031232958659529686, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67444068]\n",
      " [0.68921131]\n",
      " [0.70446903]\n",
      " [0.71979958]\n",
      " [0.73501194]\n",
      " [0.75009316]\n",
      " [0.76511002]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.73365325]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008055685902945697, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68921131]\n",
      " [0.70446903]\n",
      " [0.71979958]\n",
      " [0.73501194]\n",
      " [0.75009316]\n",
      " [0.76511002]\n",
      " [0.80123983]\n",
      " [0.73365325]] | y: 0.793490895001937 | Predicción actual: [[0.74887943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001848952379077673, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70446903]\n",
      " [0.71979958]\n",
      " [0.73501194]\n",
      " [0.75009316]\n",
      " [0.76511002]\n",
      " [0.80123983]\n",
      " [0.73365325]\n",
      " [0.74887943]] | y: 0.760170476559473 | Predicción actual: [[0.7633686]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014634897001087666, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71979958]\n",
      " [0.73501194]\n",
      " [0.75009316]\n",
      " [0.76511002]\n",
      " [0.80123983]\n",
      " [0.73365325]\n",
      " [0.74887943]\n",
      " [0.76336861]] | y: 0.7353738860906625 | Predicción actual: [[0.7761792]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007942060939967632, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73501194]\n",
      " [0.75009316]\n",
      " [0.76511002]\n",
      " [0.80123983]\n",
      " [0.73365325]\n",
      " [0.74887943]\n",
      " [0.76336861]\n",
      " [0.77617919]] | y: 0.7101898488957767 | Predicción actual: [[0.7869711]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026130820624530315, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75009316]\n",
      " [0.76511002]\n",
      " [0.80123983]\n",
      " [0.73365325]\n",
      " [0.74887943]\n",
      " [0.76336861]\n",
      " [0.77617919]\n",
      " [0.78697109]] | y: 0.7121270825261525 | Predicción actual: [[0.79511917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023325588554143906, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76511002]\n",
      " [0.80123983]\n",
      " [0.73365325]\n",
      " [0.74887943]\n",
      " [0.76336861]\n",
      " [0.77617919]\n",
      " [0.78697109]\n",
      " [0.79511917]] | y: 0.7396358000774894 | Predicción actual: [[0.8001774]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014329265104606748, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.73365325]\n",
      " [0.74887943]\n",
      " [0.76336861]\n",
      " [0.77617919]\n",
      " [0.78697109]\n",
      " [0.79511917]\n",
      " [0.8001774 ]] | y: 0.7361487795428128 | Predicción actual: [[0.8016905]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014999140053987503, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73365325]\n",
      " [0.74887943]\n",
      " [0.76336861]\n",
      " [0.77617919]\n",
      " [0.78697109]\n",
      " [0.79511917]\n",
      " [0.8001774 ]\n",
      " [0.80169052]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035106258001178503, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74887943]\n",
      " [0.76336861]\n",
      " [0.77617919]\n",
      " [0.78697109]\n",
      " [0.79511917]\n",
      " [0.8001774 ]\n",
      " [0.80169052]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.804225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00019550127035472542, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76336861]\n",
      " [0.77617919]\n",
      " [0.78697109]\n",
      " [0.79511917]\n",
      " [0.8001774 ]\n",
      " [0.80169052]\n",
      " [0.66757071]\n",
      " [0.80422503]] | y: 0.696629213483146 | Predicción actual: [[0.81264204]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006186956539750099, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77617919]\n",
      " [0.78697109]\n",
      " [0.79511917]\n",
      " [0.8001774 ]\n",
      " [0.80169052]\n",
      " [0.66757071]\n",
      " [0.80422503]\n",
      " [0.81264204]] | y: 0.6559473072452537 | Predicción actual: [[0.8174525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015438891015946865, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78697109]\n",
      " [0.79511917]\n",
      " [0.8001774 ]\n",
      " [0.80169052]\n",
      " [0.66757071]\n",
      " [0.80422503]\n",
      " [0.81264204]\n",
      " [0.81745249]] | y: 0.6788066640836885 | Predicción actual: [[0.81870306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016518451273441315, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79511917]\n",
      " [0.8001774 ]\n",
      " [0.80169052]\n",
      " [0.66757071]\n",
      " [0.80422503]\n",
      " [0.81264204]\n",
      " [0.81745249]\n",
      " [0.81870306]] | y: 0.6760945370011622 | Predicción actual: [[0.81689394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023921426385641098, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8001774 ]\n",
      " [0.80169052]\n",
      " [0.66757071]\n",
      " [0.80422503]\n",
      " [0.81264204]\n",
      " [0.81745249]\n",
      " [0.81870306]\n",
      " [0.81689394]] | y: 0.7295621851995349 | Predicción actual: [[0.8129113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00044896252802573144, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80169052]\n",
      " [0.66757071]\n",
      " [0.80422503]\n",
      " [0.81264204]\n",
      " [0.81745249]\n",
      " [0.81870306]\n",
      " [0.81689394]\n",
      " [0.81291127]] | y: 0.7012785741960481 | Predicción actual: [[0.8082323]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014463715255260468, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.80422503]\n",
      " [0.81264204]\n",
      " [0.81745249]\n",
      " [0.81870306]\n",
      " [0.81689394]\n",
      " [0.81291127]\n",
      " [0.80823231]] | y: 0.767531964354901 | Predicción actual: [[0.8040886]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005034676752984524, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80422503]\n",
      " [0.81264204]\n",
      " [0.81745249]\n",
      " [0.81870306]\n",
      " [0.81689394]\n",
      " [0.81291127]\n",
      " [0.80823231]\n",
      " [0.80408859]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007228017784655094, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81264204]\n",
      " [0.81745249]\n",
      " [0.81870306]\n",
      " [0.81689394]\n",
      " [0.81291127]\n",
      " [0.80823231]\n",
      " [0.80408859]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8450585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00392899988219142, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81745249]\n",
      " [0.81870306]\n",
      " [0.81689394]\n",
      " [0.81291127]\n",
      " [0.80823231]\n",
      " [0.80408859]\n",
      " [0.75513367]\n",
      " [0.8450585 ]] | y: 0.7520340953118947 | Predicción actual: [[0.84416157]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03101062774658203, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81870306]\n",
      " [0.81689394]\n",
      " [0.81291127]\n",
      " [0.80823231]\n",
      " [0.80408859]\n",
      " [0.75513367]\n",
      " [0.8450585 ]\n",
      " [0.84416157]] | y: 0.7098024021697016 | Predicción actual: [[0.8411988]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.678430817264598e-05, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81689394]\n",
      " [0.81291127]\n",
      " [0.80823231]\n",
      " [0.80408859]\n",
      " [0.75513367]\n",
      " [0.8450585 ]\n",
      " [0.84416157]\n",
      " [0.8411988 ]] | y: 0.6904300658659435 | Predicción actual: [[0.8378809]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004560217261314392, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81291127]\n",
      " [0.80823231]\n",
      " [0.80408859]\n",
      " [0.75513367]\n",
      " [0.8450585 ]\n",
      " [0.84416157]\n",
      " [0.8411988 ]\n",
      " [0.83788091]] | y: 0.7543587756683454 | Predicción actual: [[0.8354476]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018101578578352928, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80823231]\n",
      " [0.80408859]\n",
      " [0.75513367]\n",
      " [0.8450585 ]\n",
      " [0.84416157]\n",
      " [0.8411988 ]\n",
      " [0.83788091]\n",
      " [0.83544761]] | y: 0.7222006974041069 | Predicción actual: [[0.8353616]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006146381492726505, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80408859]\n",
      " [0.75513367]\n",
      " [0.8450585 ]\n",
      " [0.84416157]\n",
      " [0.8411988 ]\n",
      " [0.83788091]\n",
      " [0.83544761]\n",
      " [0.8353616 ]] | y: 0.8485083301046106 | Predicción actual: [[0.8380387]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024129243567585945, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.8450585 ]\n",
      " [0.84416157]\n",
      " [0.8411988 ]\n",
      " [0.83788091]\n",
      " [0.83544761]\n",
      " [0.8353616 ]\n",
      " [0.83803868]] | y: 0.9054629988376597 | Predicción actual: [[0.8433571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020272742956876755, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8450585 ]\n",
      " [0.84416157]\n",
      " [0.8411988 ]\n",
      " [0.83788091]\n",
      " [0.83544761]\n",
      " [0.8353616 ]\n",
      " [0.83803868]\n",
      " [0.84335709]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.830253288266249e-05, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84416157]\n",
      " [0.8411988 ]\n",
      " [0.83788091]\n",
      " [0.83544761]\n",
      " [0.8353616 ]\n",
      " [0.83803868]\n",
      " [0.84335709]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8632044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02576887607574463, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8411988 ]\n",
      " [0.83788091]\n",
      " [0.83544761]\n",
      " [0.8353616 ]\n",
      " [0.83803868]\n",
      " [0.84335709]\n",
      " [0.8822162 ]\n",
      " [0.86320442]] | y: 0.889577683068578 | Predicción actual: [[0.8611516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003793359501287341, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83788091]\n",
      " [0.83544761]\n",
      " [0.8353616 ]\n",
      " [0.83803868]\n",
      " [0.84335709]\n",
      " [0.8822162 ]\n",
      " [0.86320442]\n",
      " [0.86115158]] | y: 0.8748547074777218 | Predicción actual: [[0.86065537]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.474730993322737e-06, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83544761]\n",
      " [0.8353616 ]\n",
      " [0.83803868]\n",
      " [0.84335709]\n",
      " [0.8822162 ]\n",
      " [0.86320442]\n",
      " [0.86115158]\n",
      " [0.86065537]] | y: 0.9132119333591631 | Predicción actual: [[0.8623052]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004302285611629486, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8353616 ]\n",
      " [0.83803868]\n",
      " [0.84335709]\n",
      " [0.8822162 ]\n",
      " [0.86320442]\n",
      " [0.86115158]\n",
      " [0.86065537]\n",
      " [0.86230522]] | y: 1.0 | Predicción actual: [[0.8659216]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012977393344044685, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83803868]\n",
      " [0.84335709]\n",
      " [0.8822162 ]\n",
      " [0.86320442]\n",
      " [0.86115158]\n",
      " [0.86065537]\n",
      " [0.86230522]\n",
      " [0.86592162]] | y: 0.9705540488182873 | Predicción actual: [[0.8712919]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006038098596036434, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84335709]\n",
      " [0.8822162 ]\n",
      " [0.86320442]\n",
      " [0.86115158]\n",
      " [0.86065537]\n",
      " [0.86230522]\n",
      " [0.86592162]\n",
      " [0.87129188]] | y: 0.8888027896164277 | Predicción actual: [[0.87743264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005342934746295214, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.86320442]\n",
      " [0.86115158]\n",
      " [0.86065537]\n",
      " [0.86230522]\n",
      " [0.86592162]\n",
      " [0.87129188]\n",
      " [0.87743264]] | y: 0.877954281286323 | Predicción actual: [[0.8833374]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005159726715646684, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86320442]\n",
      " [0.86115158]\n",
      " [0.86065537]\n",
      " [0.86230522]\n",
      " [0.86592162]\n",
      " [0.87129188]\n",
      " [0.87743264]\n",
      " [0.88333738]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013885434716939926, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86115158]\n",
      " [0.86065537]\n",
      " [0.86230522]\n",
      " [0.86592162]\n",
      " [0.87129188]\n",
      " [0.87743264]\n",
      " [0.88333738]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.87841624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00023740950564388186, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86065537]\n",
      " [0.86230522]\n",
      " [0.86592162]\n",
      " [0.87129188]\n",
      " [0.87743264]\n",
      " [0.88333738]\n",
      " [0.84889578]\n",
      " [0.87841624]] | y: 0.8550949244478885 | Predicción actual: [[0.87967557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004708833002950996, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86230522]\n",
      " [0.86592162]\n",
      " [0.87129188]\n",
      " [0.87743264]\n",
      " [0.88333738]\n",
      " [0.84889578]\n",
      " [0.87841624]\n",
      " [0.87967557]] | y: 0.8752421542037967 | Predicción actual: [[0.88164073]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003349575214087963, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86592162]\n",
      " [0.87129188]\n",
      " [0.87743264]\n",
      " [0.88333738]\n",
      " [0.84889578]\n",
      " [0.87841624]\n",
      " [0.87967557]\n",
      " [0.88164073]] | y: 0.857032158078264 | Predicción actual: [[0.88387084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028801029548048973, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87129188]\n",
      " [0.87743264]\n",
      " [0.88333738]\n",
      " [0.84889578]\n",
      " [0.87841624]\n",
      " [0.87967557]\n",
      " [0.88164073]\n",
      " [0.88387084]] | y: 0.8500581170089112 | Predicción actual: [[0.8855063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00392160564661026, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87743264]\n",
      " [0.88333738]\n",
      " [0.84889578]\n",
      " [0.87841624]\n",
      " [0.87967557]\n",
      " [0.88164073]\n",
      " [0.88387084]\n",
      " [0.88550627]] | y: 0.8426966292134832 | Predicción actual: [[0.8859302]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004664316074922681, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88333738]\n",
      " [0.84889578]\n",
      " [0.87841624]\n",
      " [0.87967557]\n",
      " [0.88164073]\n",
      " [0.88387084]\n",
      " [0.88550627]\n",
      " [0.88593018]] | y: 0.8229368461836497 | Predicción actual: [[0.8849208]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0456266812980175, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.87841624]\n",
      " [0.87967557]\n",
      " [0.88164073]\n",
      " [0.88387084]\n",
      " [0.88550627]\n",
      " [0.88593018]\n",
      " [0.88492078]] | y: 0.7745060054242543 | Predicción actual: [[0.88197935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032198935747146606, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87841624]\n",
      " [0.87967557]\n",
      " [0.88164073]\n",
      " [0.88387084]\n",
      " [0.88550627]\n",
      " [0.88593018]\n",
      " [0.88492078]\n",
      " [0.88197935]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0300848800688982, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87967557]\n",
      " [0.88164073]\n",
      " [0.88387084]\n",
      " [0.88550627]\n",
      " [0.88593018]\n",
      " [0.88492078]\n",
      " [0.88197935]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8887296]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023451615124940872, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88164073]\n",
      " [0.88387084]\n",
      " [0.88550627]\n",
      " [0.88593018]\n",
      " [0.88492078]\n",
      " [0.88197935]\n",
      " [0.78419217]\n",
      " [0.88872957]] | y: 0.854320030995738 | Predicción actual: [[0.8867967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026484886184334755, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88387084]\n",
      " [0.88550627]\n",
      " [0.88593018]\n",
      " [0.88492078]\n",
      " [0.88197935]\n",
      " [0.78419217]\n",
      " [0.88872957]\n",
      " [0.88679671]] | y: 0.8368849283223556 | Predicción actual: [[0.88321924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011545081622898579, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88550627]\n",
      " [0.88593018]\n",
      " [0.88492078]\n",
      " [0.88197935]\n",
      " [0.78419217]\n",
      " [0.88872957]\n",
      " [0.88679671]\n",
      " [0.88321924]] | y: 0.8299108872530028 | Predicción actual: [[0.8780953]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025477136950939894, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88593018]\n",
      " [0.88492078]\n",
      " [0.88197935]\n",
      " [0.78419217]\n",
      " [0.88872957]\n",
      " [0.88679671]\n",
      " [0.88321924]\n",
      " [0.87809533]] | y: 0.887253002712127 | Predicción actual: [[0.87203765]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011487427400425076, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88492078]\n",
      " [0.88197935]\n",
      " [0.78419217]\n",
      " [0.88872957]\n",
      " [0.88679671]\n",
      " [0.88321924]\n",
      " [0.87809533]\n",
      " [0.87203765]] | y: 0.8597442851607902 | Predicción actual: [[0.8655213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001065590069629252, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88197935]\n",
      " [0.78419217]\n",
      " [0.88872957]\n",
      " [0.88679671]\n",
      " [0.88321924]\n",
      " [0.87809533]\n",
      " [0.87203765]\n",
      " [0.86552131]] | y: 0.8395970554048819 | Predicción actual: [[0.85902256]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0199696384370327, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.88872957]\n",
      " [0.88679671]\n",
      " [0.88321924]\n",
      " [0.87809533]\n",
      " [0.87203765]\n",
      " [0.86552131]\n",
      " [0.85902256]] | y: 0.7838047268500579 | Predicción actual: [[0.85361546]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04281071946024895, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88872957]\n",
      " [0.88679671]\n",
      " [0.88321924]\n",
      " [0.87809533]\n",
      " [0.87203765]\n",
      " [0.86552131]\n",
      " [0.85902256]\n",
      " [0.85361546]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012078087776899338, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88679671]\n",
      " [0.88321924]\n",
      " [0.87809533]\n",
      " [0.87203765]\n",
      " [0.86552131]\n",
      " [0.85902256]\n",
      " [0.85361546]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8718019]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002434795256704092, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88321924]\n",
      " [0.87809533]\n",
      " [0.87203765]\n",
      " [0.86552131]\n",
      " [0.85902256]\n",
      " [0.85361546]\n",
      " [0.81828749]\n",
      " [0.87180191]] | y: 0.7605579232855482 | Predicción actual: [[0.86540794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001461924985051155, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87809533]\n",
      " [0.87203765]\n",
      " [0.86552131]\n",
      " [0.85902256]\n",
      " [0.85361546]\n",
      " [0.81828749]\n",
      " [0.87180191]\n",
      " [0.86540794]] | y: 0.7915536613715615 | Predicción actual: [[0.85862684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005432728212326765, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87203765]\n",
      " [0.86552131]\n",
      " [0.85902256]\n",
      " [0.85361546]\n",
      " [0.81828749]\n",
      " [0.87180191]\n",
      " [0.86540794]\n",
      " [0.85862684]] | y: 0.7686943045331267 | Predicción actual: [[0.8520739]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003737327177077532, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86552131]\n",
      " [0.85902256]\n",
      " [0.85361546]\n",
      " [0.81828749]\n",
      " [0.87180191]\n",
      " [0.86540794]\n",
      " [0.85862684]\n",
      " [0.85207391]] | y: 0.7686943045331267 | Predicción actual: [[0.8463644]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002845424460247159, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85902256]\n",
      " [0.85361546]\n",
      " [0.81828749]\n",
      " [0.87180191]\n",
      " [0.86540794]\n",
      " [0.85862684]\n",
      " [0.85207391]\n",
      " [0.84636438]] | y: 0.7989151491669895 | Predicción actual: [[0.84194845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036614721175283194, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85361546]\n",
      " [0.81828749]\n",
      " [0.87180191]\n",
      " [0.86540794]\n",
      " [0.85862684]\n",
      " [0.85207391]\n",
      " [0.84636438]\n",
      " [0.84194845]] | y: 0.7900038744672608 | Predicción actual: [[0.83925724]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019918945617973804, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.87180191]\n",
      " [0.86540794]\n",
      " [0.85862684]\n",
      " [0.85207391]\n",
      " [0.84636438]\n",
      " [0.84194845]\n",
      " [0.83925724]] | y: 0.760170476559473 | Predicción actual: [[0.83791566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.0513114122877596e-06, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87180191]\n",
      " [0.86540794]\n",
      " [0.85862684]\n",
      " [0.85207391]\n",
      " [0.84636438]\n",
      " [0.84194845]\n",
      " [0.83925724]\n",
      " [0.83791566]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014440985396504402, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86540794]\n",
      " [0.85862684]\n",
      " [0.85207391]\n",
      " [0.84636438]\n",
      " [0.84194845]\n",
      " [0.83925724]\n",
      " [0.83791566]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8394822]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05238978564739227, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85862684]\n",
      " [0.85207391]\n",
      " [0.84636438]\n",
      " [0.84194845]\n",
      " [0.83925724]\n",
      " [0.83791566]\n",
      " [0.68539326]\n",
      " [0.83948219]] | y: 0.6648585819449826 | Predicción actual: [[0.8308036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0654987320303917, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85207391]\n",
      " [0.84636438]\n",
      " [0.84194845]\n",
      " [0.83925724]\n",
      " [0.83791566]\n",
      " [0.68539326]\n",
      " [0.83948219]\n",
      " [0.83080357]] | y: 0.7078651685393258 | Predicción actual: [[0.8210503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01775255985558033, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84636438]\n",
      " [0.84194845]\n",
      " [0.83925724]\n",
      " [0.83791566]\n",
      " [0.68539326]\n",
      " [0.83948219]\n",
      " [0.83080357]\n",
      " [0.82105029]] | y: 0.6648585819449826 | Predicción actual: [[0.81078655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017522461712360382, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84194845]\n",
      " [0.83925724]\n",
      " [0.83791566]\n",
      " [0.68539326]\n",
      " [0.83948219]\n",
      " [0.83080357]\n",
      " [0.82105029]\n",
      " [0.81078655]] | y: 0.7113521890740022 | Predicción actual: [[0.8001818]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028364017605781555, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83925724]\n",
      " [0.83791566]\n",
      " [0.68539326]\n",
      " [0.83948219]\n",
      " [0.83080357]\n",
      " [0.82105029]\n",
      " [0.81078655]\n",
      " [0.80018181]] | y: 0.6772568771793879 | Predicción actual: [[0.78916687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031117203179746866, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83791566]\n",
      " [0.68539326]\n",
      " [0.83948219]\n",
      " [0.83080357]\n",
      " [0.82105029]\n",
      " [0.81078655]\n",
      " [0.80018181]\n",
      " [0.78916687]] | y: 0.7621077101898488 | Predicción actual: [[0.7778078]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0274199265986681, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.83948219]\n",
      " [0.83080357]\n",
      " [0.82105029]\n",
      " [0.81078655]\n",
      " [0.80018181]\n",
      " [0.78916687]\n",
      " [0.77780777]] | y: 0.8070515304145678 | Predicción actual: [[0.76567215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009022367186844349, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83948219]\n",
      " [0.83080357]\n",
      " [0.82105029]\n",
      " [0.81078655]\n",
      " [0.80018181]\n",
      " [0.78916687]\n",
      " [0.77780777]\n",
      " [0.76567215]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.4217048273130786e-06, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83080357]\n",
      " [0.82105029]\n",
      " [0.81078655]\n",
      " [0.80018181]\n",
      " [0.78916687]\n",
      " [0.77780777]\n",
      " [0.76567215]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7858889]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009582992643117905, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82105029]\n",
      " [0.81078655]\n",
      " [0.80018181]\n",
      " [0.78916687]\n",
      " [0.77780777]\n",
      " [0.76567215]\n",
      " [0.81518791]\n",
      " [0.78588891]] | y: 0.9597055404881829 | Predicción actual: [[0.7762068]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.8767390176653862e-05, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81078655]\n",
      " [0.80018181]\n",
      " [0.78916687]\n",
      " [0.77780777]\n",
      " [0.76567215]\n",
      " [0.81518791]\n",
      " [0.78588891]\n",
      " [0.77620679]] | y: 0.9643549012010848 | Predicción actual: [[0.76762307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0253136046230793, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80018181]\n",
      " [0.78916687]\n",
      " [0.77780777]\n",
      " [0.76567215]\n",
      " [0.81518791]\n",
      " [0.78588891]\n",
      " [0.77620679]\n",
      " [0.76762307]] | y: 0.8880278961642774 | Predicción actual: [[0.7608567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012586544267833233, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78916687]\n",
      " [0.77780777]\n",
      " [0.76567215]\n",
      " [0.81518791]\n",
      " [0.78588891]\n",
      " [0.77620679]\n",
      " [0.76762307]\n",
      " [0.76085669]] | y: 0.8926772568771792 | Predicción actual: [[0.7561232]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011119948700070381, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77780777]\n",
      " [0.76567215]\n",
      " [0.81518791]\n",
      " [0.78588891]\n",
      " [0.77620679]\n",
      " [0.76762307]\n",
      " [0.76085669]\n",
      " [0.75612319]] | y: 0.8752421542037967 | Predicción actual: [[0.7536834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005496812053024769, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76567215]\n",
      " [0.81518791]\n",
      " [0.78588891]\n",
      " [0.77620679]\n",
      " [0.76762307]\n",
      " [0.76085669]\n",
      " [0.75612319]\n",
      " [0.75368339]] | y: 0.8508330104610615 | Predicción actual: [[0.7534265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010578224435448647, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.78588891]\n",
      " [0.77620679]\n",
      " [0.76762307]\n",
      " [0.76085669]\n",
      " [0.75612319]\n",
      " [0.75368339]\n",
      " [0.75342649]] | y: 0.8488957768306855 | Predicción actual: [[0.75596863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042291149497032166, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78588891]\n",
      " [0.77620679]\n",
      " [0.76762307]\n",
      " [0.76085669]\n",
      " [0.75612319]\n",
      " [0.75368339]\n",
      " [0.75342649]\n",
      " [0.75596863]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04956606402993202, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77620679]\n",
      " [0.76762307]\n",
      " [0.76085669]\n",
      " [0.75612319]\n",
      " [0.75368339]\n",
      " [0.75342649]\n",
      " [0.75596863]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7397536]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08354506641626358, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76762307]\n",
      " [0.76085669]\n",
      " [0.75612319]\n",
      " [0.75368339]\n",
      " [0.75342649]\n",
      " [0.75596863]\n",
      " [0.96241767]\n",
      " [0.7397536 ]] | y: 0.9407206509104997 | Predicción actual: [[0.7390142]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.19565746188163757, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76085669]\n",
      " [0.75612319]\n",
      " [0.75368339]\n",
      " [0.75342649]\n",
      " [0.75596863]\n",
      " [0.96241767]\n",
      " [0.7397536 ]\n",
      " [0.73901421]] | y: 0.9724912824486633 | Predicción actual: [[0.74197423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0967610776424408, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75612319]\n",
      " [0.75368339]\n",
      " [0.75342649]\n",
      " [0.75596863]\n",
      " [0.96241767]\n",
      " [0.7397536 ]\n",
      " [0.73901421]\n",
      " [0.74197423]] | y: 0.9969004261913985 | Predicción actual: [[0.7481152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09494620561599731, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75368339]\n",
      " [0.75342649]\n",
      " [0.75596863]\n",
      " [0.96241767]\n",
      " [0.7397536 ]\n",
      " [0.73901421]\n",
      " [0.74197423]\n",
      " [0.74811518]] | y: 0.951181712514529 | Predicción actual: [[0.75663704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035356853157281876, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75342649]\n",
      " [0.75596863]\n",
      " [0.96241767]\n",
      " [0.7397536 ]\n",
      " [0.73901421]\n",
      " [0.74197423]\n",
      " [0.74811518]\n",
      " [0.75663704]] | y: 0.8957768306857805 | Predicción actual: [[0.7663597]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.056554511189460754, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75596863]\n",
      " [0.96241767]\n",
      " [0.7397536 ]\n",
      " [0.73901421]\n",
      " [0.74197423]\n",
      " [0.74811518]\n",
      " [0.75663704]\n",
      " [0.76635969]] | y: 0.8814413018209997 | Predicción actual: [[0.77624774]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014825311489403248, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.7397536 ]\n",
      " [0.73901421]\n",
      " [0.74197423]\n",
      " [0.74811518]\n",
      " [0.75663704]\n",
      " [0.76635969]\n",
      " [0.77624774]] | y: 0.9170864006199149 | Predicción actual: [[0.7849397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037021469324827194, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7397536 ]\n",
      " [0.73901421]\n",
      " [0.74197423]\n",
      " [0.74811518]\n",
      " [0.75663704]\n",
      " [0.76635969]\n",
      " [0.77624774]\n",
      " [0.78493971]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008051605895161629, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73901421]\n",
      " [0.74197423]\n",
      " [0.74811518]\n",
      " [0.75663704]\n",
      " [0.76635969]\n",
      " [0.77624774]\n",
      " [0.78493971]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.73997796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.045887548476457596, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74197423]\n",
      " [0.74811518]\n",
      " [0.75663704]\n",
      " [0.76635969]\n",
      " [0.77624774]\n",
      " [0.78493971]\n",
      " [0.91979853]\n",
      " [0.73997796]] | y: 0.9682293684618366 | Predicción actual: [[0.7496586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0943886935710907, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74811518]\n",
      " [0.75663704]\n",
      " [0.76635969]\n",
      " [0.77624774]\n",
      " [0.78493971]\n",
      " [0.91979853]\n",
      " [0.73997796]\n",
      " [0.74965858]] | y: 0.9577683068578069 | Predicción actual: [[0.7613098]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07225851714611053, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20175786]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017413510009646416, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20175786]] | y: 0.10422316931421921 | Predicción actual: [[0.18646191]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007288921624422073, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20175786]\n",
      " [0.18646191]] | y: 0.15420379697791559 | Predicción actual: [[0.1908195]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005402957322075963, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20175786]\n",
      " [0.18646191]\n",
      " [0.1908195 ]] | y: 0.1557535838822161 | Predicción actual: [[0.20252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003245052881538868, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20175786]\n",
      " [0.18646191]\n",
      " [0.1908195 ]\n",
      " [0.20252   ]] | y: 0.12553273924835334 | Predicción actual: [[0.21532045]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007020395249128342, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20175786]\n",
      " [0.18646191]\n",
      " [0.1908195 ]\n",
      " [0.20252   ]\n",
      " [0.21532045]] | y: 0.1456799690042619 | Predicción actual: [[0.22539116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011072855442762375, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20175786]\n",
      " [0.18646191]\n",
      " [0.1908195 ]\n",
      " [0.20252   ]\n",
      " [0.21532045]\n",
      " [0.22539116]] | y: 0.1464548624564122 | Predicción actual: [[0.2469241]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0100298086181283, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20175786]\n",
      " [0.18646191]\n",
      " [0.1908195 ]\n",
      " [0.20252   ]\n",
      " [0.21532045]\n",
      " [0.22539116]\n",
      " [0.2469241 ]] | y: 0.1960480433940332 | Predicción actual: [[0.2733836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004318982362747192, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20175786]\n",
      " [0.18646191]\n",
      " [0.1908195 ]\n",
      " [0.20252   ]\n",
      " [0.21532045]\n",
      " [0.22539116]\n",
      " [0.2469241 ]\n",
      " [0.27338359]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017252002726309001, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18646191]\n",
      " [0.1908195 ]\n",
      " [0.20252   ]\n",
      " [0.21532045]\n",
      " [0.22539116]\n",
      " [0.2469241 ]\n",
      " [0.27338359]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3076306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016632134094834328, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.1908195 ]\n",
      " [0.20252   ]\n",
      " [0.21532045]\n",
      " [0.22539116]\n",
      " [0.2469241 ]\n",
      " [0.27338359]\n",
      " [0.2305308 ]\n",
      " [0.3076306 ]] | y: 0.211933359163115 | Predicción actual: [[0.31516442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016994232311844826, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20252   ]\n",
      " [0.21532045]\n",
      " [0.22539116]\n",
      " [0.2469241 ]\n",
      " [0.27338359]\n",
      " [0.2305308 ]\n",
      " [0.3076306 ]\n",
      " [0.31516442]] | y: 0.2072839984502131 | Predicción actual: [[0.32455364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006433820817619562, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21532045]\n",
      " [0.22539116]\n",
      " [0.2469241 ]\n",
      " [0.27338359]\n",
      " [0.2305308 ]\n",
      " [0.3076306 ]\n",
      " [0.31516442]\n",
      " [0.32455364]] | y: 0.19294846958543205 | Predicción actual: [[0.33457854]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012970349751412868, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22539116]\n",
      " [0.2469241 ]\n",
      " [0.27338359]\n",
      " [0.2305308 ]\n",
      " [0.3076306 ]\n",
      " [0.31516442]\n",
      " [0.32455364]\n",
      " [0.33457854]] | y: 0.19682293684618352 | Predicción actual: [[0.3451467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029054006561636925, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2469241 ]\n",
      " [0.27338359]\n",
      " [0.2305308 ]\n",
      " [0.3076306 ]\n",
      " [0.31516442]\n",
      " [0.32455364]\n",
      " [0.33457854]\n",
      " [0.34514669]] | y: 0.21425803951956607 | Predicción actual: [[0.3569698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022699713706970215, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27338359]\n",
      " [0.2305308 ]\n",
      " [0.3076306 ]\n",
      " [0.31516442]\n",
      " [0.32455364]\n",
      " [0.33457854]\n",
      " [0.34514669]\n",
      " [0.3569698 ]] | y: 0.18132506780317698 | Predicción actual: [[0.36743796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02257237583398819, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.3076306 ]\n",
      " [0.31516442]\n",
      " [0.32455364]\n",
      " [0.33457854]\n",
      " [0.34514669]\n",
      " [0.3569698 ]\n",
      " [0.36743796]] | y: 0.17512592018597434 | Predicción actual: [[0.37504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.059378184378147125, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3076306 ]\n",
      " [0.31516442]\n",
      " [0.32455364]\n",
      " [0.33457854]\n",
      " [0.34514669]\n",
      " [0.3569698 ]\n",
      " [0.36743796]\n",
      " [0.37503999]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07259738445281982, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31516442]\n",
      " [0.32455364]\n",
      " [0.33457854]\n",
      " [0.34514669]\n",
      " [0.3569698 ]\n",
      " [0.36743796]\n",
      " [0.37503999]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.401662]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0653311014175415, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32455364]\n",
      " [0.33457854]\n",
      " [0.34514669]\n",
      " [0.3569698 ]\n",
      " [0.36743796]\n",
      " [0.37503999]\n",
      " [0.14800465]\n",
      " [0.40166199]] | y: 0.19217357613328173 | Predicción actual: [[0.4058927]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049279239028692245, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33457854]\n",
      " [0.34514669]\n",
      " [0.3569698 ]\n",
      " [0.36743796]\n",
      " [0.37503999]\n",
      " [0.14800465]\n",
      " [0.40166199]\n",
      " [0.4058927 ]] | y: 0.1859744285160791 | Predicción actual: [[0.40835255]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1063072681427002, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34514669]\n",
      " [0.3569698 ]\n",
      " [0.36743796]\n",
      " [0.37503999]\n",
      " [0.14800465]\n",
      " [0.40166199]\n",
      " [0.4058927 ]\n",
      " [0.40835255]] | y: 0.26695079426578844 | Predicción actual: [[0.40898812]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03261175751686096, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3569698 ]\n",
      " [0.36743796]\n",
      " [0.37503999]\n",
      " [0.14800465]\n",
      " [0.40166199]\n",
      " [0.4058927 ]\n",
      " [0.40835255]\n",
      " [0.40898812]] | y: 0.2925222781867493 | Predicción actual: [[0.40809]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004205016419291496, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36743796]\n",
      " [0.37503999]\n",
      " [0.14800465]\n",
      " [0.40166199]\n",
      " [0.4058927 ]\n",
      " [0.40835255]\n",
      " [0.40898812]\n",
      " [0.40809   ]] | y: 0.3177063153816349 | Predicción actual: [[0.40575173]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007893389090895653, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37503999]\n",
      " [0.14800465]\n",
      " [0.40166199]\n",
      " [0.4058927 ]\n",
      " [0.40835255]\n",
      " [0.40898812]\n",
      " [0.40809   ]\n",
      " [0.40575173]] | y: 0.31266950794265785 | Predicción actual: [[0.40253964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01033005677163601, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40166199]\n",
      " [0.4058927 ]\n",
      " [0.40835255]\n",
      " [0.40898812]\n",
      " [0.40809   ]\n",
      " [0.40575173]\n",
      " [0.40253964]] | y: 0.2890352576520729 | Predicción actual: [[0.39934048]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012056435458362103, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40166199]\n",
      " [0.4058927 ]\n",
      " [0.40835255]\n",
      " [0.40898812]\n",
      " [0.40809   ]\n",
      " [0.40575173]\n",
      " [0.40253964]\n",
      " [0.39934048]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036960478872060776, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4058927 ]\n",
      " [0.40835255]\n",
      " [0.40898812]\n",
      " [0.40809   ]\n",
      " [0.40575173]\n",
      " [0.40253964]\n",
      " [0.39934048]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.4541284]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029962783679366112, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40835255]\n",
      " [0.40898812]\n",
      " [0.40809   ]\n",
      " [0.40575173]\n",
      " [0.40253964]\n",
      " [0.39934048]\n",
      " [0.28283611]\n",
      " [0.45412841]] | y: 0.2758620689655173 | Predicción actual: [[0.45203748]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0513944998383522, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40898812]\n",
      " [0.40809   ]\n",
      " [0.40575173]\n",
      " [0.40253964]\n",
      " [0.39934048]\n",
      " [0.28283611]\n",
      " [0.45412841]\n",
      " [0.45203748]] | y: 0.2746997287872917 | Predicción actual: [[0.44878253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025265075266361237, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40809   ]\n",
      " [0.40575173]\n",
      " [0.40253964]\n",
      " [0.39934048]\n",
      " [0.28283611]\n",
      " [0.45412841]\n",
      " [0.45203748]\n",
      " [0.44878253]] | y: 0.275474622239442 | Predicción actual: [[0.4453238]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006902666762471199, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40575173]\n",
      " [0.40253964]\n",
      " [0.39934048]\n",
      " [0.28283611]\n",
      " [0.45412841]\n",
      " [0.45203748]\n",
      " [0.44878253]\n",
      " [0.4453238 ]] | y: 0.3347539713289423 | Predicción actual: [[0.4426428]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0159651767462492, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40253964]\n",
      " [0.39934048]\n",
      " [0.28283611]\n",
      " [0.45412841]\n",
      " [0.45203748]\n",
      " [0.44878253]\n",
      " [0.4453238 ]\n",
      " [0.44264281]] | y: 0.35567609453700116 | Predicción actual: [[0.4415991]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026386315003037453, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39934048]\n",
      " [0.28283611]\n",
      " [0.45412841]\n",
      " [0.45203748]\n",
      " [0.44878253]\n",
      " [0.4453238 ]\n",
      " [0.44264281]\n",
      " [0.4415991 ]] | y: 0.3366912049593181 | Predicción actual: [[0.44292834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0026528663001954556, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.45412841]\n",
      " [0.45203748]\n",
      " [0.44878253]\n",
      " [0.4453238 ]\n",
      " [0.44264281]\n",
      " [0.4415991 ]\n",
      " [0.44292834]] | y: 0.3335916311507167 | Predicción actual: [[0.44698194]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007078381720930338, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45412841]\n",
      " [0.45203748]\n",
      " [0.44878253]\n",
      " [0.4453238 ]\n",
      " [0.44264281]\n",
      " [0.4415991 ]\n",
      " [0.44292834]\n",
      " [0.44698194]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037265236023813486, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45203748]\n",
      " [0.44878253]\n",
      " [0.4453238 ]\n",
      " [0.44264281]\n",
      " [0.4415991 ]\n",
      " [0.44292834]\n",
      " [0.44698194]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.4798569]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027903233421966434, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44878253]\n",
      " [0.4453238 ]\n",
      " [0.44264281]\n",
      " [0.4415991 ]\n",
      " [0.44292834]\n",
      " [0.44698194]\n",
      " [0.3847346 ]\n",
      " [0.47985691]] | y: 0.5962805114296785 | Predicción actual: [[0.47700563]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020413098391145468, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4453238 ]\n",
      " [0.44264281]\n",
      " [0.4415991 ]\n",
      " [0.44292834]\n",
      " [0.44698194]\n",
      " [0.3847346 ]\n",
      " [0.47985691]\n",
      " [0.47700563]] | y: 0.574583494769469 | Predicción actual: [[0.47477585]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003618907881900668, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44264281]\n",
      " [0.4415991 ]\n",
      " [0.44292834]\n",
      " [0.44698194]\n",
      " [0.3847346 ]\n",
      " [0.47985691]\n",
      " [0.47700563]\n",
      " [0.47477585]] | y: 0.6063541263076326 | Predicción actual: [[0.47367448]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031619176268577576, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4415991 ]\n",
      " [0.44292834]\n",
      " [0.44698194]\n",
      " [0.3847346 ]\n",
      " [0.47985691]\n",
      " [0.47700563]\n",
      " [0.47477585]\n",
      " [0.47367448]] | y: 0.5846571096474236 | Predicción actual: [[0.47401127]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008146146312355995, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44292834]\n",
      " [0.44698194]\n",
      " [0.3847346 ]\n",
      " [0.47985691]\n",
      " [0.47700563]\n",
      " [0.47477585]\n",
      " [0.47367448]\n",
      " [0.47401127]] | y: 0.5687717938783416 | Predicción actual: [[0.4756993]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007492862641811371, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44698194]\n",
      " [0.3847346 ]\n",
      " [0.47985691]\n",
      " [0.47700563]\n",
      " [0.47477585]\n",
      " [0.47367448]\n",
      " [0.47401127]\n",
      " [0.47569931]] | y: 0.6427741185586981 | Predicción actual: [[0.4783821]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042614731937646866, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.47985691]\n",
      " [0.47700563]\n",
      " [0.47477585]\n",
      " [0.47367448]\n",
      " [0.47401127]\n",
      " [0.47569931]\n",
      " [0.47838211]] | y: 0.6617590081363811 | Predicción actual: [[0.48154345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016371404752135277, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47985691]\n",
      " [0.47700563]\n",
      " [0.47477585]\n",
      " [0.47367448]\n",
      " [0.47401127]\n",
      " [0.47569931]\n",
      " [0.47838211]\n",
      " [0.48154345]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04625837877392769, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47700563]\n",
      " [0.47477585]\n",
      " [0.47367448]\n",
      " [0.47401127]\n",
      " [0.47569931]\n",
      " [0.47838211]\n",
      " [0.48154345]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5026429]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10499683767557144, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47477585]\n",
      " [0.47367448]\n",
      " [0.47401127]\n",
      " [0.47569931]\n",
      " [0.47838211]\n",
      " [0.48154345]\n",
      " [0.67299496]\n",
      " [0.50264293]] | y: 0.703990701278574 | Predicción actual: [[0.5057241]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011355260387063026, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47367448]\n",
      " [0.47401127]\n",
      " [0.47569931]\n",
      " [0.47838211]\n",
      " [0.48154345]\n",
      " [0.67299496]\n",
      " [0.50264293]\n",
      " [0.50572407]] | y: 0.7272375048430839 | Predicción actual: [[0.51159614]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041845761239528656, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47401127]\n",
      " [0.47569931]\n",
      " [0.47838211]\n",
      " [0.48154345]\n",
      " [0.67299496]\n",
      " [0.50264293]\n",
      " [0.50572407]\n",
      " [0.51159614]] | y: 0.722588144130182 | Predicción actual: [[0.52021104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043275680392980576, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47569931]\n",
      " [0.47838211]\n",
      " [0.48154345]\n",
      " [0.67299496]\n",
      " [0.50264293]\n",
      " [0.50572407]\n",
      " [0.51159614]\n",
      " [0.52021104]] | y: 0.771793878341728 | Predicción actual: [[0.53117615]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07155458629131317, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47838211]\n",
      " [0.48154345]\n",
      " [0.67299496]\n",
      " [0.50264293]\n",
      " [0.50572407]\n",
      " [0.51159614]\n",
      " [0.52021104]\n",
      " [0.53117615]] | y: 0.7245253777605578 | Predicción actual: [[0.5440251]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04538845270872116, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48154345]\n",
      " [0.67299496]\n",
      " [0.50264293]\n",
      " [0.50572407]\n",
      " [0.51159614]\n",
      " [0.52021104]\n",
      " [0.53117615]\n",
      " [0.54402512]] | y: 0.6710577295621851 | Predicción actual: [[0.5582513]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03373017534613609, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.50264293]\n",
      " [0.50572407]\n",
      " [0.51159614]\n",
      " [0.52021104]\n",
      " [0.53117615]\n",
      " [0.54402512]\n",
      " [0.55825132]] | y: 0.6737698566447115 | Predicción actual: [[0.5735122]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011189043521881104, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50264293]\n",
      " [0.50572407]\n",
      " [0.51159614]\n",
      " [0.52021104]\n",
      " [0.53117615]\n",
      " [0.54402512]\n",
      " [0.55825132]\n",
      " [0.5735122 ]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008845143020153046, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50572407]\n",
      " [0.51159614]\n",
      " [0.52021104]\n",
      " [0.53117615]\n",
      " [0.54402512]\n",
      " [0.55825132]\n",
      " [0.5735122 ]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5468221]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016593916341662407, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51159614]\n",
      " [0.52021104]\n",
      " [0.53117615]\n",
      " [0.54402512]\n",
      " [0.55825132]\n",
      " [0.5735122 ]\n",
      " [0.71445176]\n",
      " [0.54682207]] | y: 0.722588144130182 | Predicción actual: [[0.55764604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013952197507023811, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52021104]\n",
      " [0.53117615]\n",
      " [0.54402512]\n",
      " [0.55825132]\n",
      " [0.5735122 ]\n",
      " [0.71445176]\n",
      " [0.54682207]\n",
      " [0.55764604]] | y: 0.6993413405656723 | Predicción actual: [[0.57049006]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0127114187926054, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53117615]\n",
      " [0.54402512]\n",
      " [0.55825132]\n",
      " [0.5735122 ]\n",
      " [0.71445176]\n",
      " [0.54682207]\n",
      " [0.55764604]\n",
      " [0.57049006]] | y: 0.7373111197210385 | Predicción actual: [[0.58429956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05964663624763489, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54402512]\n",
      " [0.55825132]\n",
      " [0.5735122 ]\n",
      " [0.71445176]\n",
      " [0.54682207]\n",
      " [0.55764604]\n",
      " [0.57049006]\n",
      " [0.58429956]] | y: 0.7214258039519565 | Predicción actual: [[0.5979832]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005797219346277416, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55825132]\n",
      " [0.5735122 ]\n",
      " [0.71445176]\n",
      " [0.54682207]\n",
      " [0.55764604]\n",
      " [0.57049006]\n",
      " [0.58429956]\n",
      " [0.59798318]] | y: 0.7187136768694304 | Predicción actual: [[0.6102239]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020120220258831978, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5735122 ]\n",
      " [0.71445176]\n",
      " [0.54682207]\n",
      " [0.55764604]\n",
      " [0.57049006]\n",
      " [0.58429956]\n",
      " [0.59798318]\n",
      " [0.61022389]] | y: 0.6741573033707864 | Predicción actual: [[0.6201303]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00019241329573560506, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.54682207]\n",
      " [0.55764604]\n",
      " [0.57049006]\n",
      " [0.58429956]\n",
      " [0.59798318]\n",
      " [0.61022389]\n",
      " [0.6201303 ]] | y: 0.698566447113522 | Predicción actual: [[0.62672216]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025087084621191025, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54682207]\n",
      " [0.55764604]\n",
      " [0.57049006]\n",
      " [0.58429956]\n",
      " [0.59798318]\n",
      " [0.61022389]\n",
      " [0.6201303 ]\n",
      " [0.62672216]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054934658110141754, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55764604]\n",
      " [0.57049006]\n",
      " [0.58429956]\n",
      " [0.59798318]\n",
      " [0.61022389]\n",
      " [0.6201303 ]\n",
      " [0.62672216]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6068337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00628096517175436, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57049006]\n",
      " [0.58429956]\n",
      " [0.59798318]\n",
      " [0.61022389]\n",
      " [0.6201303 ]\n",
      " [0.62672216]\n",
      " [0.72103836]\n",
      " [0.6068337 ]] | y: 0.7562960092987214 | Predicción actual: [[0.6199056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01788361556828022, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58429956]\n",
      " [0.59798318]\n",
      " [0.61022389]\n",
      " [0.6201303 ]\n",
      " [0.62672216]\n",
      " [0.72103836]\n",
      " [0.6068337 ]\n",
      " [0.61990559]] | y: 0.8275862068965516 | Predicción actual: [[0.63292766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06320139020681381, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59798318]\n",
      " [0.61022389]\n",
      " [0.6201303 ]\n",
      " [0.62672216]\n",
      " [0.72103836]\n",
      " [0.6068337 ]\n",
      " [0.61990559]\n",
      " [0.63292766]] | y: 0.8388221619527314 | Predicción actual: [[0.6451466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007869201712310314, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61022389]\n",
      " [0.6201303 ]\n",
      " [0.62672216]\n",
      " [0.72103836]\n",
      " [0.6068337 ]\n",
      " [0.61990559]\n",
      " [0.63292766]\n",
      " [0.64514661]] | y: 0.7942657884540876 | Predicción actual: [[0.65580815]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004994831397198141, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6201303 ]\n",
      " [0.62672216]\n",
      " [0.72103836]\n",
      " [0.6068337 ]\n",
      " [0.61990559]\n",
      " [0.63292766]\n",
      " [0.64514661]\n",
      " [0.65580815]] | y: 0.7838047268500579 | Predicción actual: [[0.664642]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046286776661872864, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62672216]\n",
      " [0.72103836]\n",
      " [0.6068337 ]\n",
      " [0.61990559]\n",
      " [0.63292766]\n",
      " [0.64514661]\n",
      " [0.65580815]\n",
      " [0.66464198]] | y: 0.7679194110809764 | Predicción actual: [[0.67206967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000767224351875484, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.6068337 ]\n",
      " [0.61990559]\n",
      " [0.63292766]\n",
      " [0.64514661]\n",
      " [0.65580815]\n",
      " [0.66464198]\n",
      " [0.67206967]] | y: 0.7845796203022084 | Predicción actual: [[0.6786007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005146529525518417, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6068337 ]\n",
      " [0.61990559]\n",
      " [0.63292766]\n",
      " [0.64514661]\n",
      " [0.65580815]\n",
      " [0.66464198]\n",
      " [0.67206967]\n",
      " [0.67860073]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.14951474964618683, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61990559]\n",
      " [0.63292766]\n",
      " [0.64514661]\n",
      " [0.65580815]\n",
      " [0.66464198]\n",
      " [0.67206967]\n",
      " [0.67860073]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6720418]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02290893904864788, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63292766]\n",
      " [0.64514661]\n",
      " [0.65580815]\n",
      " [0.66464198]\n",
      " [0.67206967]\n",
      " [0.67860073]\n",
      " [0.87872917]\n",
      " [0.67204177]] | y: 0.8488957768306855 | Predicción actual: [[0.68634933]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011218911036849022, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64514661]\n",
      " [0.65580815]\n",
      " [0.66464198]\n",
      " [0.67206967]\n",
      " [0.67860073]\n",
      " [0.87872917]\n",
      " [0.67204177]\n",
      " [0.68634933]] | y: 0.8182874854707476 | Predicción actual: [[0.7013369]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01817205734550953, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65580815]\n",
      " [0.66464198]\n",
      " [0.67206967]\n",
      " [0.67860073]\n",
      " [0.87872917]\n",
      " [0.67204177]\n",
      " [0.68634933]\n",
      " [0.70133692]] | y: 0.8268113134444013 | Predicción actual: [[0.71675277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011392040178179741, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66464198]\n",
      " [0.67206967]\n",
      " [0.67860073]\n",
      " [0.87872917]\n",
      " [0.67204177]\n",
      " [0.68634933]\n",
      " [0.70133692]\n",
      " [0.71675277]] | y: 0.7853545137543589 | Predicción actual: [[0.73241377]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015743088442832232, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67206967]\n",
      " [0.67860073]\n",
      " [0.87872917]\n",
      " [0.67204177]\n",
      " [0.68634933]\n",
      " [0.70133692]\n",
      " [0.71675277]\n",
      " [0.73241377]] | y: 0.7892289810151103 | Predicción actual: [[0.748188]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02796962484717369, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67860073]\n",
      " [0.87872917]\n",
      " [0.67204177]\n",
      " [0.68634933]\n",
      " [0.70133692]\n",
      " [0.71675277]\n",
      " [0.73241377]\n",
      " [0.74818802]] | y: 0.8341728012398295 | Predicción actual: [[0.7642056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04590128734707832, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.67204177]\n",
      " [0.68634933]\n",
      " [0.70133692]\n",
      " [0.71675277]\n",
      " [0.73241377]\n",
      " [0.74818802]\n",
      " [0.76420557]] | y: 0.8124757845796202 | Predicción actual: [[0.7804857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03194558992981911, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67204177]\n",
      " [0.68634933]\n",
      " [0.70133692]\n",
      " [0.71675277]\n",
      " [0.73241377]\n",
      " [0.74818802]\n",
      " [0.76420557]\n",
      " [0.78048569]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008439263328909874, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68634933]\n",
      " [0.70133692]\n",
      " [0.71675277]\n",
      " [0.73241377]\n",
      " [0.74818802]\n",
      " [0.76420557]\n",
      " [0.78048569]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.75338453]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020687755197286606, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70133692]\n",
      " [0.71675277]\n",
      " [0.73241377]\n",
      " [0.74818802]\n",
      " [0.76420557]\n",
      " [0.78048569]\n",
      " [0.80123983]\n",
      " [0.75338453]] | y: 0.793490895001937 | Predicción actual: [[0.7696342]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016888733953237534, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71675277]\n",
      " [0.73241377]\n",
      " [0.74818802]\n",
      " [0.76420557]\n",
      " [0.78048569]\n",
      " [0.80123983]\n",
      " [0.75338453]\n",
      " [0.76963419]] | y: 0.760170476559473 | Predicción actual: [[0.7853484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.4733467651240062e-05, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73241377]\n",
      " [0.74818802]\n",
      " [0.76420557]\n",
      " [0.78048569]\n",
      " [0.80123983]\n",
      " [0.75338453]\n",
      " [0.76963419]\n",
      " [0.78534842]] | y: 0.7353738860906625 | Predicción actual: [[0.7996307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0035672022495418787, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74818802]\n",
      " [0.76420557]\n",
      " [0.78048569]\n",
      " [0.80123983]\n",
      " [0.75338453]\n",
      " [0.76963419]\n",
      " [0.78534842]\n",
      " [0.7996307 ]] | y: 0.7101898488957767 | Predicción actual: [[0.8117136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.910404361955443e-07, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76420557]\n",
      " [0.78048569]\n",
      " [0.80123983]\n",
      " [0.75338453]\n",
      " [0.76963419]\n",
      " [0.78534842]\n",
      " [0.7996307 ]\n",
      " [0.81171358]] | y: 0.7121270825261525 | Predicción actual: [[0.8211594]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01276764739304781, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78048569]\n",
      " [0.80123983]\n",
      " [0.75338453]\n",
      " [0.76963419]\n",
      " [0.78534842]\n",
      " [0.7996307 ]\n",
      " [0.81171358]\n",
      " [0.82115942]] | y: 0.7396358000774894 | Predicción actual: [[0.82728624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009268822614103556, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.75338453]\n",
      " [0.76963419]\n",
      " [0.78534842]\n",
      " [0.7996307 ]\n",
      " [0.81171358]\n",
      " [0.82115942]\n",
      " [0.82728624]] | y: 0.7361487795428128 | Predicción actual: [[0.8299132]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007805258966982365, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75338453]\n",
      " [0.76963419]\n",
      " [0.78534842]\n",
      " [0.7996307 ]\n",
      " [0.81171358]\n",
      " [0.82115942]\n",
      " [0.82728624]\n",
      " [0.8299132 ]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04541913792490959, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76963419]\n",
      " [0.78534842]\n",
      " [0.7996307 ]\n",
      " [0.81171358]\n",
      " [0.82115942]\n",
      " [0.82728624]\n",
      " [0.8299132 ]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.83984756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025323089212179184, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78534842]\n",
      " [0.7996307 ]\n",
      " [0.81171358]\n",
      " [0.82115942]\n",
      " [0.82728624]\n",
      " [0.8299132 ]\n",
      " [0.66757071]\n",
      " [0.83984756]] | y: 0.696629213483146 | Predicción actual: [[0.8487951]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021837190724909306, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7996307 ]\n",
      " [0.81171358]\n",
      " [0.82115942]\n",
      " [0.82728624]\n",
      " [0.8299132 ]\n",
      " [0.66757071]\n",
      " [0.83984756]\n",
      " [0.84879512]] | y: 0.6559473072452537 | Predicción actual: [[0.8539219]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0001469234994146973, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81171358]\n",
      " [0.82115942]\n",
      " [0.82728624]\n",
      " [0.8299132 ]\n",
      " [0.66757071]\n",
      " [0.83984756]\n",
      " [0.84879512]\n",
      " [0.85392189]] | y: 0.6788066640836885 | Predicción actual: [[0.85541636]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02031380496919155, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82115942]\n",
      " [0.82728624]\n",
      " [0.8299132 ]\n",
      " [0.66757071]\n",
      " [0.83984756]\n",
      " [0.84879512]\n",
      " [0.85392189]\n",
      " [0.85541636]] | y: 0.6760945370011622 | Predicción actual: [[0.85362405]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00469348905608058, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82728624]\n",
      " [0.8299132 ]\n",
      " [0.66757071]\n",
      " [0.83984756]\n",
      " [0.84879512]\n",
      " [0.85392189]\n",
      " [0.85541636]\n",
      " [0.85362405]] | y: 0.7295621851995349 | Predicción actual: [[0.84975857]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.6649477048486006e-06, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8299132 ]\n",
      " [0.66757071]\n",
      " [0.83984756]\n",
      " [0.84879512]\n",
      " [0.85392189]\n",
      " [0.85541636]\n",
      " [0.85362405]\n",
      " [0.84975857]] | y: 0.7012785741960481 | Predicción actual: [[0.8453442]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03978986665606499, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.83984756]\n",
      " [0.84879512]\n",
      " [0.85392189]\n",
      " [0.85541636]\n",
      " [0.85362405]\n",
      " [0.84975857]\n",
      " [0.84534419]] | y: 0.767531964354901 | Predicción actual: [[0.84149164]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033865117002278566, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83984756]\n",
      " [0.84879512]\n",
      " [0.85392189]\n",
      " [0.85541636]\n",
      " [0.85362405]\n",
      " [0.84975857]\n",
      " [0.84534419]\n",
      " [0.84149164]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016728093847632408, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84879512]\n",
      " [0.85392189]\n",
      " [0.85541636]\n",
      " [0.85362405]\n",
      " [0.84975857]\n",
      " [0.84534419]\n",
      " [0.84149164]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.89306945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041454847902059555, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85392189]\n",
      " [0.85541636]\n",
      " [0.85362405]\n",
      " [0.84975857]\n",
      " [0.84534419]\n",
      " [0.84149164]\n",
      " [0.75513367]\n",
      " [0.89306945]] | y: 0.7520340953118947 | Predicción actual: [[0.89105004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002670682442840189, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85541636]\n",
      " [0.85362405]\n",
      " [0.84975857]\n",
      " [0.84534419]\n",
      " [0.84149164]\n",
      " [0.75513367]\n",
      " [0.89306945]\n",
      " [0.89105004]] | y: 0.7098024021697016 | Predicción actual: [[0.887056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09922345727682114, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85362405]\n",
      " [0.84975857]\n",
      " [0.84534419]\n",
      " [0.84149164]\n",
      " [0.75513367]\n",
      " [0.89306945]\n",
      " [0.89105004]\n",
      " [0.88705599]] | y: 0.6904300658659435 | Predicción actual: [[0.88181275]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05416567996144295, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84975857]\n",
      " [0.84534419]\n",
      " [0.84149164]\n",
      " [0.75513367]\n",
      " [0.89306945]\n",
      " [0.89105004]\n",
      " [0.88705599]\n",
      " [0.88181275]] | y: 0.7543587756683454 | Predicción actual: [[0.8772652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018184786662459373, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84534419]\n",
      " [0.84149164]\n",
      " [0.75513367]\n",
      " [0.89306945]\n",
      " [0.89105004]\n",
      " [0.88705599]\n",
      " [0.88181275]\n",
      " [0.87726521]] | y: 0.7222006974041069 | Predicción actual: [[0.8754424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05345514044165611, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84149164]\n",
      " [0.75513367]\n",
      " [0.89306945]\n",
      " [0.89105004]\n",
      " [0.88705599]\n",
      " [0.88181275]\n",
      " [0.87726521]\n",
      " [0.87544239]] | y: 0.8485083301046106 | Predicción actual: [[0.8763378]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.9829769371426664e-05, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.89306945]\n",
      " [0.89105004]\n",
      " [0.88705599]\n",
      " [0.88181275]\n",
      " [0.87726521]\n",
      " [0.87544239]\n",
      " [0.87633783]] | y: 0.9054629988376597 | Predicción actual: [[0.8807426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005281515419483185, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89306945]\n",
      " [0.89105004]\n",
      " [0.88705599]\n",
      " [0.88181275]\n",
      " [0.87726521]\n",
      " [0.87544239]\n",
      " [0.87633783]\n",
      " [0.88074261]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002177634509280324, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89105004]\n",
      " [0.88705599]\n",
      " [0.88181275]\n",
      " [0.87726521]\n",
      " [0.87544239]\n",
      " [0.87633783]\n",
      " [0.88074261]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.910675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0054323505610227585, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88705599]\n",
      " [0.88181275]\n",
      " [0.87726521]\n",
      " [0.87544239]\n",
      " [0.87633783]\n",
      " [0.88074261]\n",
      " [0.8822162 ]\n",
      " [0.91067499]] | y: 0.889577683068578 | Predicción actual: [[0.90642667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030368216335773468, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88181275]\n",
      " [0.87726521]\n",
      " [0.87544239]\n",
      " [0.87633783]\n",
      " [0.88074261]\n",
      " [0.8822162 ]\n",
      " [0.91067499]\n",
      " [0.90642667]] | y: 0.8748547074777218 | Predicción actual: [[0.9038558]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017450599698349833, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87726521]\n",
      " [0.87544239]\n",
      " [0.87633783]\n",
      " [0.88074261]\n",
      " [0.8822162 ]\n",
      " [0.91067499]\n",
      " [0.90642667]\n",
      " [0.9038558 ]] | y: 0.9132119333591631 | Predicción actual: [[0.9035906]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005394801497459412, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87544239]\n",
      " [0.87633783]\n",
      " [0.88074261]\n",
      " [0.8822162 ]\n",
      " [0.91067499]\n",
      " [0.90642667]\n",
      " [0.9038558 ]\n",
      " [0.90359062]] | y: 1.0 | Predicción actual: [[0.90594006]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016749885980971158, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87633783]\n",
      " [0.88074261]\n",
      " [0.8822162 ]\n",
      " [0.91067499]\n",
      " [0.90642667]\n",
      " [0.9038558 ]\n",
      " [0.90359062]\n",
      " [0.90594006]] | y: 0.9705540488182873 | Predicción actual: [[0.91026044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0017320024780929089, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88074261]\n",
      " [0.8822162 ]\n",
      " [0.91067499]\n",
      " [0.90642667]\n",
      " [0.9038558 ]\n",
      " [0.90359062]\n",
      " [0.90594006]\n",
      " [0.91026044]] | y: 0.8888027896164277 | Predicción actual: [[0.91592306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029298136942088604, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.91067499]\n",
      " [0.90642667]\n",
      " [0.9038558 ]\n",
      " [0.90359062]\n",
      " [0.90594006]\n",
      " [0.91026044]\n",
      " [0.91592306]] | y: 0.877954281286323 | Predicción actual: [[0.92159945]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012697678757831454, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91067499]\n",
      " [0.90642667]\n",
      " [0.9038558 ]\n",
      " [0.90359062]\n",
      " [0.90594006]\n",
      " [0.91026044]\n",
      " [0.91592306]\n",
      " [0.92159945]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011058775708079338, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90642667]\n",
      " [0.9038558 ]\n",
      " [0.90359062]\n",
      " [0.90594006]\n",
      " [0.91026044]\n",
      " [0.91592306]\n",
      " [0.92159945]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.9270037]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036387708969414234, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.9038558 ]\n",
      " [0.90359062]\n",
      " [0.90594006]\n",
      " [0.91026044]\n",
      " [0.91592306]\n",
      " [0.92159945]\n",
      " [0.84889578]\n",
      " [0.92700368]] | y: 0.8550949244478885 | Predicción actual: [[0.9266482]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036428552120923996, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90359062]\n",
      " [0.90594006]\n",
      " [0.91026044]\n",
      " [0.91592306]\n",
      " [0.92159945]\n",
      " [0.84889578]\n",
      " [0.92700368]\n",
      " [0.9266482 ]] | y: 0.8752421542037967 | Predicción actual: [[0.9266141]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014277283102273941, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90594006]\n",
      " [0.91026044]\n",
      " [0.91592306]\n",
      " [0.92159945]\n",
      " [0.84889578]\n",
      " [0.92700368]\n",
      " [0.9266482 ]\n",
      " [0.92661411]] | y: 0.857032158078264 | Predicción actual: [[0.9267004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004883665591478348, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91026044]\n",
      " [0.91592306]\n",
      " [0.92159945]\n",
      " [0.84889578]\n",
      " [0.92700368]\n",
      " [0.9266482 ]\n",
      " [0.92661411]\n",
      " [0.92670041]] | y: 0.8500581170089112 | Predicción actual: [[0.92675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.2502104002342094e-06, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91592306]\n",
      " [0.92159945]\n",
      " [0.84889578]\n",
      " [0.92700368]\n",
      " [0.9266482 ]\n",
      " [0.92661411]\n",
      " [0.92670041]\n",
      " [0.92675   ]] | y: 0.8426966292134832 | Predicción actual: [[0.92611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018493111710995436, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92159945]\n",
      " [0.84889578]\n",
      " [0.92700368]\n",
      " [0.9266482 ]\n",
      " [0.92661411]\n",
      " [0.92670041]\n",
      " [0.92675   ]\n",
      " [0.92611003]] | y: 0.8229368461836497 | Predicción actual: [[0.92433393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.053007129579782486, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.92700368]\n",
      " [0.9266482 ]\n",
      " [0.92661411]\n",
      " [0.92670041]\n",
      " [0.92675   ]\n",
      " [0.92611003]\n",
      " [0.92433393]] | y: 0.7745060054242543 | Predicción actual: [[0.92093426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03464488312602043, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92700368]\n",
      " [0.9266482 ]\n",
      " [0.92661411]\n",
      " [0.92670041]\n",
      " [0.92675   ]\n",
      " [0.92611003]\n",
      " [0.92433393]\n",
      " [0.92093426]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042661793529987335, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.9266482 ]\n",
      " [0.92661411]\n",
      " [0.92670041]\n",
      " [0.92675   ]\n",
      " [0.92611003]\n",
      " [0.92433393]\n",
      " [0.92093426]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.9376036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003641280811280012, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92661411]\n",
      " [0.92670041]\n",
      " [0.92675   ]\n",
      " [0.92611003]\n",
      " [0.92433393]\n",
      " [0.92093426]\n",
      " [0.78419217]\n",
      " [0.93760359]] | y: 0.854320030995738 | Predicción actual: [[0.9332518]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0569493497314397e-05, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92670041]\n",
      " [0.92675   ]\n",
      " [0.92611003]\n",
      " [0.92433393]\n",
      " [0.92093426]\n",
      " [0.78419217]\n",
      " [0.93760359]\n",
      " [0.9332518 ]] | y: 0.8368849283223556 | Predicción actual: [[0.92769384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.048940327018499374, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92675   ]\n",
      " [0.92611003]\n",
      " [0.92433393]\n",
      " [0.92093426]\n",
      " [0.78419217]\n",
      " [0.93760359]\n",
      " [0.9332518 ]\n",
      " [0.92769384]] | y: 0.8299108872530028 | Predicción actual: [[0.92044866]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011472621001303196, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92611003]\n",
      " [0.92433393]\n",
      " [0.92093426]\n",
      " [0.78419217]\n",
      " [0.93760359]\n",
      " [0.9332518 ]\n",
      " [0.92769384]\n",
      " [0.92044866]] | y: 0.887253002712127 | Predicción actual: [[0.91220385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01993936114013195, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92433393]\n",
      " [0.92093426]\n",
      " [0.78419217]\n",
      " [0.93760359]\n",
      " [0.9332518 ]\n",
      " [0.92769384]\n",
      " [0.92044866]\n",
      " [0.91220385]] | y: 0.8597442851607902 | Predicción actual: [[0.90343344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012188220862299204, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92093426]\n",
      " [0.78419217]\n",
      " [0.93760359]\n",
      " [0.9332518 ]\n",
      " [0.92769384]\n",
      " [0.92044866]\n",
      " [0.91220385]\n",
      " [0.90343344]] | y: 0.8395970554048819 | Predicción actual: [[0.89514214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.96666060219286e-05, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.93760359]\n",
      " [0.9332518 ]\n",
      " [0.92769384]\n",
      " [0.92044866]\n",
      " [0.91220385]\n",
      " [0.90343344]\n",
      " [0.89514214]] | y: 0.7838047268500579 | Predicción actual: [[0.8881946]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008761614444665611, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.93760359]\n",
      " [0.9332518 ]\n",
      " [0.92769384]\n",
      " [0.92044866]\n",
      " [0.91220385]\n",
      " [0.90343344]\n",
      " [0.89514214]\n",
      " [0.88819462]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005823138053528965, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.9332518 ]\n",
      " [0.92769384]\n",
      " [0.92044866]\n",
      " [0.91220385]\n",
      " [0.90343344]\n",
      " [0.89514214]\n",
      " [0.88819462]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.9156568]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03123871050775051, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92769384]\n",
      " [0.92044866]\n",
      " [0.91220385]\n",
      " [0.90343344]\n",
      " [0.89514214]\n",
      " [0.88819462]\n",
      " [0.81828749]\n",
      " [0.91565681]] | y: 0.7605579232855482 | Predicción actual: [[0.9063038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021816860884428024, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.92044866]\n",
      " [0.91220385]\n",
      " [0.90343344]\n",
      " [0.89514214]\n",
      " [0.88819462]\n",
      " [0.81828749]\n",
      " [0.91565681]\n",
      " [0.90630382]] | y: 0.7915536613715615 | Predicción actual: [[0.8962345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.041512612253427505, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91220385]\n",
      " [0.90343344]\n",
      " [0.89514214]\n",
      " [0.88819462]\n",
      " [0.81828749]\n",
      " [0.91565681]\n",
      " [0.90630382]\n",
      " [0.89623451]] | y: 0.7686943045331267 | Predicción actual: [[0.88620734]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04216655716300011, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90343344]\n",
      " [0.89514214]\n",
      " [0.88819462]\n",
      " [0.81828749]\n",
      " [0.91565681]\n",
      " [0.90630382]\n",
      " [0.89623451]\n",
      " [0.88620734]] | y: 0.7686943045331267 | Predicción actual: [[0.87704754]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0151955746114254, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89514214]\n",
      " [0.88819462]\n",
      " [0.81828749]\n",
      " [0.91565681]\n",
      " [0.90630382]\n",
      " [0.89623451]\n",
      " [0.88620734]\n",
      " [0.87704754]] | y: 0.7989151491669895 | Predicción actual: [[0.8696184]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018073967657983303, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88819462]\n",
      " [0.81828749]\n",
      " [0.91565681]\n",
      " [0.90630382]\n",
      " [0.89623451]\n",
      " [0.88620734]\n",
      " [0.87704754]\n",
      " [0.86961842]] | y: 0.7900038744672608 | Predicción actual: [[0.86445963]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00042098609264940023, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.91565681]\n",
      " [0.90630382]\n",
      " [0.89623451]\n",
      " [0.88620734]\n",
      " [0.87704754]\n",
      " [0.86961842]\n",
      " [0.86445963]] | y: 0.760170476559473 | Predicción actual: [[0.8613111]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019432028755545616, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.91565681]\n",
      " [0.90630382]\n",
      " [0.89623451]\n",
      " [0.88620734]\n",
      " [0.87704754]\n",
      " [0.86961842]\n",
      " [0.86445963]\n",
      " [0.86131108]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00030902191065251827, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.90630382]\n",
      " [0.89623451]\n",
      " [0.88620734]\n",
      " [0.87704754]\n",
      " [0.86961842]\n",
      " [0.86445963]\n",
      " [0.86131108]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.86727697]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10255394130945206, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89623451]\n",
      " [0.88620734]\n",
      " [0.87704754]\n",
      " [0.86961842]\n",
      " [0.86445963]\n",
      " [0.86131108]\n",
      " [0.68539326]\n",
      " [0.86727697]] | y: 0.6648585819449826 | Predicción actual: [[0.85445493]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020898966118693352, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88620734]\n",
      " [0.87704754]\n",
      " [0.86961842]\n",
      " [0.86445963]\n",
      " [0.86131108]\n",
      " [0.68539326]\n",
      " [0.86727697]\n",
      " [0.85445493]] | y: 0.7078651685393258 | Predicción actual: [[0.8410261]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013881810940802097, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87704754]\n",
      " [0.86961842]\n",
      " [0.86445963]\n",
      " [0.86131108]\n",
      " [0.68539326]\n",
      " [0.86727697]\n",
      " [0.85445493]\n",
      " [0.84102613]] | y: 0.6648585819449826 | Predicción actual: [[0.827446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.061236750334501266, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86961842]\n",
      " [0.86445963]\n",
      " [0.86131108]\n",
      " [0.68539326]\n",
      " [0.86727697]\n",
      " [0.85445493]\n",
      " [0.84102613]\n",
      " [0.82744598]] | y: 0.7113521890740022 | Predicción actual: [[0.8137111]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005181789863854647, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86445963]\n",
      " [0.86131108]\n",
      " [0.68539326]\n",
      " [0.86727697]\n",
      " [0.85445493]\n",
      " [0.84102613]\n",
      " [0.82744598]\n",
      " [0.81371111]] | y: 0.6772568771793879 | Predicción actual: [[0.80023956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04582605138421059, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86131108]\n",
      " [0.68539326]\n",
      " [0.86727697]\n",
      " [0.85445493]\n",
      " [0.84102613]\n",
      " [0.82744598]\n",
      " [0.81371111]\n",
      " [0.80023956]] | y: 0.7621077101898488 | Predicción actual: [[0.78649354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003429373318795115, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.86727697]\n",
      " [0.85445493]\n",
      " [0.84102613]\n",
      " [0.82744598]\n",
      " [0.81371111]\n",
      " [0.80023956]\n",
      " [0.78649354]] | y: 0.8070515304145678 | Predicción actual: [[0.7725845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01745971478521824, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86727697]\n",
      " [0.85445493]\n",
      " [0.84102613]\n",
      " [0.82744598]\n",
      " [0.81371111]\n",
      " [0.80023956]\n",
      " [0.78649354]\n",
      " [0.7725845 ]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006779728922992945, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85445493]\n",
      " [0.84102613]\n",
      " [0.82744598]\n",
      " [0.81371111]\n",
      " [0.80023956]\n",
      " [0.78649354]\n",
      " [0.7725845 ]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7937554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004892007913440466, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84102613]\n",
      " [0.82744598]\n",
      " [0.81371111]\n",
      " [0.80023956]\n",
      " [0.78649354]\n",
      " [0.7725845 ]\n",
      " [0.81518791]\n",
      " [0.79375541]] | y: 0.9597055404881829 | Predicción actual: [[0.7812122]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08288268744945526, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82744598]\n",
      " [0.81371111]\n",
      " [0.80023956]\n",
      " [0.78649354]\n",
      " [0.7725845 ]\n",
      " [0.81518791]\n",
      " [0.79375541]\n",
      " [0.78121221]] | y: 0.9643549012010848 | Predicción actual: [[0.7705277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011744949966669083, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81371111]\n",
      " [0.80023956]\n",
      " [0.78649354]\n",
      " [0.7725845 ]\n",
      " [0.81518791]\n",
      " [0.79375541]\n",
      " [0.78121221]\n",
      " [0.77052772]] | y: 0.8880278961642774 | Predicción actual: [[0.76186645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016620924696326256, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80023956]\n",
      " [0.78649354]\n",
      " [0.7725845 ]\n",
      " [0.81518791]\n",
      " [0.79375541]\n",
      " [0.78121221]\n",
      " [0.77052772]\n",
      " [0.76186645]] | y: 0.8926772568771792 | Predicción actual: [[0.7555886]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047105614095926285, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78649354]\n",
      " [0.7725845 ]\n",
      " [0.81518791]\n",
      " [0.79375541]\n",
      " [0.78121221]\n",
      " [0.77052772]\n",
      " [0.76186645]\n",
      " [0.75558859]] | y: 0.8752421542037967 | Predicción actual: [[0.7519557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012831629253923893, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7725845 ]\n",
      " [0.81518791]\n",
      " [0.79375541]\n",
      " [0.78121221]\n",
      " [0.77052772]\n",
      " [0.76186645]\n",
      " [0.75558859]\n",
      " [0.75195569]] | y: 0.8508330104610615 | Predicción actual: [[0.75106406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08332356065511703, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.79375541]\n",
      " [0.78121221]\n",
      " [0.77052772]\n",
      " [0.76186645]\n",
      " [0.75558859]\n",
      " [0.75195569]\n",
      " [0.75106406]] | y: 0.8488957768306855 | Predicción actual: [[0.7532248]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018038813723251224, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79375541]\n",
      " [0.78121221]\n",
      " [0.77052772]\n",
      " [0.76186645]\n",
      " [0.75558859]\n",
      " [0.75195569]\n",
      " [0.75106406]\n",
      " [0.75322479]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04332931339740753, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78121221]\n",
      " [0.77052772]\n",
      " [0.76186645]\n",
      " [0.75558859]\n",
      " [0.75195569]\n",
      " [0.75106406]\n",
      " [0.75322479]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.73677266]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10927174240350723, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77052772]\n",
      " [0.76186645]\n",
      " [0.75558859]\n",
      " [0.75195569]\n",
      " [0.75106406]\n",
      " [0.75322479]\n",
      " [0.96241767]\n",
      " [0.73677266]] | y: 0.9407206509104997 | Predicción actual: [[0.73505086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03217600658535957, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76186645]\n",
      " [0.75558859]\n",
      " [0.75195569]\n",
      " [0.75106406]\n",
      " [0.75322479]\n",
      " [0.96241767]\n",
      " [0.73677266]\n",
      " [0.73505086]] | y: 0.9724912824486633 | Predicción actual: [[0.7370881]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09512720257043839, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75558859]\n",
      " [0.75195569]\n",
      " [0.75106406]\n",
      " [0.75322479]\n",
      " [0.96241767]\n",
      " [0.73677266]\n",
      " [0.73505086]\n",
      " [0.73708808]] | y: 0.9969004261913985 | Predicción actual: [[0.74255466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10235361754894257, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75195569]\n",
      " [0.75106406]\n",
      " [0.75322479]\n",
      " [0.96241767]\n",
      " [0.73677266]\n",
      " [0.73505086]\n",
      " [0.73708808]\n",
      " [0.74255466]] | y: 0.951181712514529 | Predicción actual: [[0.7506079]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04315432533621788, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75106406]\n",
      " [0.75322479]\n",
      " [0.96241767]\n",
      " [0.73677266]\n",
      " [0.73505086]\n",
      " [0.73708808]\n",
      " [0.74255466]\n",
      " [0.75060791]] | y: 0.8957768306857805 | Predicción actual: [[0.7600464]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06321661174297333, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75322479]\n",
      " [0.96241767]\n",
      " [0.73677266]\n",
      " [0.73505086]\n",
      " [0.73708808]\n",
      " [0.74255466]\n",
      " [0.75060791]\n",
      " [0.76004642]] | y: 0.8814413018209997 | Predicción actual: [[0.76968455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004792028106749058, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.73677266]\n",
      " [0.73505086]\n",
      " [0.73708808]\n",
      " [0.74255466]\n",
      " [0.75060791]\n",
      " [0.76004642]\n",
      " [0.76968455]] | y: 0.9170864006199149 | Predicción actual: [[0.77801144]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007269781548529863, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73677266]\n",
      " [0.73505086]\n",
      " [0.73708808]\n",
      " [0.74255466]\n",
      " [0.75060791]\n",
      " [0.76004642]\n",
      " [0.76968455]\n",
      " [0.77801144]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05390151962637901, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73505086]\n",
      " [0.73708808]\n",
      " [0.74255466]\n",
      " [0.75060791]\n",
      " [0.76004642]\n",
      " [0.76968455]\n",
      " [0.77801144]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7315187]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055944159626960754, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73708808]\n",
      " [0.74255466]\n",
      " [0.75060791]\n",
      " [0.76004642]\n",
      " [0.76968455]\n",
      " [0.77801144]\n",
      " [0.91979853]\n",
      " [0.73151869]] | y: 0.9682293684618366 | Predicción actual: [[0.74072635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09349079430103302, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74255466]\n",
      " [0.75060791]\n",
      " [0.76004642]\n",
      " [0.76968455]\n",
      " [0.77801144]\n",
      " [0.91979853]\n",
      " [0.73151869]\n",
      " [0.74072635]] | y: 0.9577683068578069 | Predicción actual: [[0.7520503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06875934451818466, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20115837]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01647002063691616, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20115837]] | y: 0.10422316931421921 | Predicción actual: [[0.18592104]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01124564278870821, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20115837]\n",
      " [0.18592104]] | y: 0.15420379697791559 | Predicción actual: [[0.19025281]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020737817976623774, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20115837]\n",
      " [0.18592104]\n",
      " [0.19025281]] | y: 0.1557535838822161 | Predicción actual: [[0.20189413]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001549406792037189, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20115837]\n",
      " [0.18592104]\n",
      " [0.19025281]\n",
      " [0.20189413]] | y: 0.12553273924835334 | Predicción actual: [[0.21462214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003970300313085318, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20115837]\n",
      " [0.18592104]\n",
      " [0.19025281]\n",
      " [0.20189413]\n",
      " [0.21462214]] | y: 0.1456799690042619 | Predicción actual: [[0.22461851]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00659971684217453, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20115837]\n",
      " [0.18592104]\n",
      " [0.19025281]\n",
      " [0.20189413]\n",
      " [0.21462214]\n",
      " [0.22461851]] | y: 0.1464548624564122 | Predicción actual: [[0.24601561]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010515851899981499, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20115837]\n",
      " [0.18592104]\n",
      " [0.19025281]\n",
      " [0.20189413]\n",
      " [0.21462214]\n",
      " [0.22461851]\n",
      " [0.24601561]] | y: 0.1960480433940332 | Predicción actual: [[0.2722846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008756645955145359, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20115837]\n",
      " [0.18592104]\n",
      " [0.19025281]\n",
      " [0.20189413]\n",
      " [0.21462214]\n",
      " [0.22461851]\n",
      " [0.24601561]\n",
      " [0.2722846 ]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009722218848764896, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18592104]\n",
      " [0.19025281]\n",
      " [0.20189413]\n",
      " [0.21462214]\n",
      " [0.22461851]\n",
      " [0.24601561]\n",
      " [0.2722846 ]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3062118]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021330617368221283, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19025281]\n",
      " [0.20189413]\n",
      " [0.21462214]\n",
      " [0.22461851]\n",
      " [0.24601561]\n",
      " [0.2722846 ]\n",
      " [0.2305308 ]\n",
      " [0.3062118 ]] | y: 0.211933359163115 | Predicción actual: [[0.31364092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011299476958811283, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20189413]\n",
      " [0.21462214]\n",
      " [0.22461851]\n",
      " [0.24601561]\n",
      " [0.2722846 ]\n",
      " [0.2305308 ]\n",
      " [0.3062118 ]\n",
      " [0.31364092]] | y: 0.2072839984502131 | Predicción actual: [[0.32292062]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003483365522697568, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21462214]\n",
      " [0.22461851]\n",
      " [0.24601561]\n",
      " [0.2722846 ]\n",
      " [0.2305308 ]\n",
      " [0.3062118 ]\n",
      " [0.31364092]\n",
      " [0.32292062]] | y: 0.19294846958543205 | Predicción actual: [[0.33283663]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005203034728765488, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22461851]\n",
      " [0.24601561]\n",
      " [0.2722846 ]\n",
      " [0.2305308 ]\n",
      " [0.3062118 ]\n",
      " [0.31364092]\n",
      " [0.32292062]\n",
      " [0.33283663]] | y: 0.19682293684618352 | Predicción actual: [[0.34330252]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025267424061894417, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24601561]\n",
      " [0.2722846 ]\n",
      " [0.2305308 ]\n",
      " [0.3062118 ]\n",
      " [0.31364092]\n",
      " [0.32292062]\n",
      " [0.33283663]\n",
      " [0.34330252]] | y: 0.21425803951956607 | Predicción actual: [[0.3550118]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008875417523086071, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2722846 ]\n",
      " [0.2305308 ]\n",
      " [0.3062118 ]\n",
      " [0.31364092]\n",
      " [0.32292062]\n",
      " [0.33283663]\n",
      " [0.34330252]\n",
      " [0.35501179]] | y: 0.18132506780317698 | Predicción actual: [[0.36539894]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03273429721593857, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.3062118 ]\n",
      " [0.31364092]\n",
      " [0.32292062]\n",
      " [0.33283663]\n",
      " [0.34330252]\n",
      " [0.35501179]\n",
      " [0.36539894]] | y: 0.17512592018597434 | Predicción actual: [[0.37292418]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01799997314810753, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3062118 ]\n",
      " [0.31364092]\n",
      " [0.32292062]\n",
      " [0.33283663]\n",
      " [0.34330252]\n",
      " [0.35501179]\n",
      " [0.36539894]\n",
      " [0.37292418]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02401009202003479, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31364092]\n",
      " [0.32292062]\n",
      " [0.33283663]\n",
      " [0.34330252]\n",
      " [0.35501179]\n",
      " [0.36539894]\n",
      " [0.37292418]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.39922068]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04444022476673126, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32292062]\n",
      " [0.33283663]\n",
      " [0.34330252]\n",
      " [0.35501179]\n",
      " [0.36539894]\n",
      " [0.37292418]\n",
      " [0.14800465]\n",
      " [0.39922068]] | y: 0.19217357613328173 | Predicción actual: [[0.40355775]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08194185793399811, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33283663]\n",
      " [0.34330252]\n",
      " [0.35501179]\n",
      " [0.36539894]\n",
      " [0.37292418]\n",
      " [0.14800465]\n",
      " [0.39922068]\n",
      " [0.40355775]] | y: 0.1859744285160791 | Predicción actual: [[0.40608343]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054247841238975525, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34330252]\n",
      " [0.35501179]\n",
      " [0.36539894]\n",
      " [0.37292418]\n",
      " [0.14800465]\n",
      " [0.39922068]\n",
      " [0.40355775]\n",
      " [0.40608343]] | y: 0.26695079426578844 | Predicción actual: [[0.40688458]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.047851916402578354, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35501179]\n",
      " [0.36539894]\n",
      " [0.37292418]\n",
      " [0.14800465]\n",
      " [0.39922068]\n",
      " [0.40355775]\n",
      " [0.40608343]\n",
      " [0.40688458]] | y: 0.2925222781867493 | Predicción actual: [[0.40613225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030577270314097404, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36539894]\n",
      " [0.37292418]\n",
      " [0.14800465]\n",
      " [0.39922068]\n",
      " [0.40355775]\n",
      " [0.40608343]\n",
      " [0.40688458]\n",
      " [0.40613225]] | y: 0.3177063153816349 | Predicción actual: [[0.4038842]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004256801679730415, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37292418]\n",
      " [0.14800465]\n",
      " [0.39922068]\n",
      " [0.40355775]\n",
      " [0.40608343]\n",
      " [0.40688458]\n",
      " [0.40613225]\n",
      " [0.4038842 ]] | y: 0.31266950794265785 | Predicción actual: [[0.40078598]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002894669596571475, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.39922068]\n",
      " [0.40355775]\n",
      " [0.40608343]\n",
      " [0.40688458]\n",
      " [0.40613225]\n",
      " [0.4038842 ]\n",
      " [0.40078598]] | y: 0.2890352576520729 | Predicción actual: [[0.3977483]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012104448862373829, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39922068]\n",
      " [0.40355775]\n",
      " [0.40608343]\n",
      " [0.40688458]\n",
      " [0.40613225]\n",
      " [0.4038842 ]\n",
      " [0.40078598]\n",
      " [0.39774829]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015095322392880917, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40355775]\n",
      " [0.40608343]\n",
      " [0.40688458]\n",
      " [0.40613225]\n",
      " [0.4038842 ]\n",
      " [0.40078598]\n",
      " [0.39774829]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.45216897]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028794266283512115, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40608343]\n",
      " [0.40688458]\n",
      " [0.40613225]\n",
      " [0.4038842 ]\n",
      " [0.40078598]\n",
      " [0.39774829]\n",
      " [0.28283611]\n",
      " [0.45216897]] | y: 0.2758620689655173 | Predicción actual: [[0.4503238]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011225086636841297, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40688458]\n",
      " [0.40613225]\n",
      " [0.4038842 ]\n",
      " [0.40078598]\n",
      " [0.39774829]\n",
      " [0.28283611]\n",
      " [0.45216897]\n",
      " [0.45032379]] | y: 0.2746997287872917 | Predicción actual: [[0.44741797]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05399871990084648, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40613225]\n",
      " [0.4038842 ]\n",
      " [0.40078598]\n",
      " [0.39774829]\n",
      " [0.28283611]\n",
      " [0.45216897]\n",
      " [0.45032379]\n",
      " [0.44741797]] | y: 0.275474622239442 | Predicción actual: [[0.44421685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08174572885036469, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4038842 ]\n",
      " [0.40078598]\n",
      " [0.39774829]\n",
      " [0.28283611]\n",
      " [0.45216897]\n",
      " [0.45032379]\n",
      " [0.44741797]\n",
      " [0.44421685]] | y: 0.3347539713289423 | Predicción actual: [[0.44160947]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005240953527390957, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40078598]\n",
      " [0.39774829]\n",
      " [0.28283611]\n",
      " [0.45216897]\n",
      " [0.45032379]\n",
      " [0.44741797]\n",
      " [0.44421685]\n",
      " [0.44160947]] | y: 0.35567609453700116 | Predicción actual: [[0.44067615]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022947000339627266, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.39774829]\n",
      " [0.28283611]\n",
      " [0.45216897]\n",
      " [0.45032379]\n",
      " [0.44741797]\n",
      " [0.44421685]\n",
      " [0.44160947]\n",
      " [0.44067615]] | y: 0.3366912049593181 | Predicción actual: [[0.4420324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005868041887879372, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.45216897]\n",
      " [0.45032379]\n",
      " [0.44741797]\n",
      " [0.44421685]\n",
      " [0.44160947]\n",
      " [0.44067615]\n",
      " [0.4420324 ]] | y: 0.3335916311507167 | Predicción actual: [[0.4460753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01881573535501957, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45216897]\n",
      " [0.45032379]\n",
      " [0.44741797]\n",
      " [0.44421685]\n",
      " [0.44160947]\n",
      " [0.44067615]\n",
      " [0.4420324 ]\n",
      " [0.44607529]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034458679147064686, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45032379]\n",
      " [0.44741797]\n",
      " [0.44421685]\n",
      " [0.44160947]\n",
      " [0.44067615]\n",
      " [0.4420324 ]\n",
      " [0.44607529]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.47850555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027317162603139877, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44741797]\n",
      " [0.44421685]\n",
      " [0.44160947]\n",
      " [0.44067615]\n",
      " [0.4420324 ]\n",
      " [0.44607529]\n",
      " [0.3847346 ]\n",
      " [0.47850555]] | y: 0.5962805114296785 | Predicción actual: [[0.47575706]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020573070272803307, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44421685]\n",
      " [0.44160947]\n",
      " [0.44067615]\n",
      " [0.4420324 ]\n",
      " [0.44607529]\n",
      " [0.3847346 ]\n",
      " [0.47850555]\n",
      " [0.47575706]] | y: 0.574583494769469 | Predicción actual: [[0.47362888]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007015556562691927, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44160947]\n",
      " [0.44067615]\n",
      " [0.4420324 ]\n",
      " [0.44607529]\n",
      " [0.3847346 ]\n",
      " [0.47850555]\n",
      " [0.47575706]\n",
      " [0.47362888]] | y: 0.6063541263076326 | Predicción actual: [[0.4725871]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012131980620324612, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44067615]\n",
      " [0.4420324 ]\n",
      " [0.44607529]\n",
      " [0.3847346 ]\n",
      " [0.47850555]\n",
      " [0.47575706]\n",
      " [0.47362888]\n",
      " [0.47258711]] | y: 0.5846571096474236 | Predicción actual: [[0.47293276]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013348588719964027, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4420324 ]\n",
      " [0.44607529]\n",
      " [0.3847346 ]\n",
      " [0.47850555]\n",
      " [0.47575706]\n",
      " [0.47362888]\n",
      " [0.47258711]\n",
      " [0.47293276]] | y: 0.5687717938783416 | Predicción actual: [[0.47460586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02715393900871277, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44607529]\n",
      " [0.3847346 ]\n",
      " [0.47850555]\n",
      " [0.47575706]\n",
      " [0.47362888]\n",
      " [0.47258711]\n",
      " [0.47293276]\n",
      " [0.47460586]] | y: 0.6427741185586981 | Predicción actual: [[0.47728646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010656346566975117, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.47850555]\n",
      " [0.47575706]\n",
      " [0.47362888]\n",
      " [0.47258711]\n",
      " [0.47293276]\n",
      " [0.47460586]\n",
      " [0.47728646]] | y: 0.6617590081363811 | Predicción actual: [[0.48038557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05345618724822998, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47850555]\n",
      " [0.47575706]\n",
      " [0.47362888]\n",
      " [0.47258711]\n",
      " [0.47293276]\n",
      " [0.47460586]\n",
      " [0.47728646]\n",
      " [0.48038557]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02795923873782158, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47575706]\n",
      " [0.47362888]\n",
      " [0.47258711]\n",
      " [0.47293276]\n",
      " [0.47460586]\n",
      " [0.47728646]\n",
      " [0.48038557]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.50120044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05373603105545044, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47362888]\n",
      " [0.47258711]\n",
      " [0.47293276]\n",
      " [0.47460586]\n",
      " [0.47728646]\n",
      " [0.48038557]\n",
      " [0.67299496]\n",
      " [0.50120044]] | y: 0.703990701278574 | Predicción actual: [[0.5042792]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030482934787869453, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47258711]\n",
      " [0.47293276]\n",
      " [0.47460586]\n",
      " [0.47728646]\n",
      " [0.48038557]\n",
      " [0.67299496]\n",
      " [0.50120044]\n",
      " [0.5042792 ]] | y: 0.7272375048430839 | Predicción actual: [[0.5101604]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052290868014097214, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47293276]\n",
      " [0.47460586]\n",
      " [0.47728646]\n",
      " [0.48038557]\n",
      " [0.67299496]\n",
      " [0.50120044]\n",
      " [0.5042792 ]\n",
      " [0.51016039]] | y: 0.722588144130182 | Predicción actual: [[0.518769]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05922224000096321, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47460586]\n",
      " [0.47728646]\n",
      " [0.48038557]\n",
      " [0.67299496]\n",
      " [0.50120044]\n",
      " [0.5042792 ]\n",
      " [0.51016039]\n",
      " [0.51876903]] | y: 0.771793878341728 | Predicción actual: [[0.5297209]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05149247497320175, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47728646]\n",
      " [0.48038557]\n",
      " [0.67299496]\n",
      " [0.50120044]\n",
      " [0.5042792 ]\n",
      " [0.51016039]\n",
      " [0.51876903]\n",
      " [0.5297209 ]] | y: 0.7245253777605578 | Predicción actual: [[0.54252344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034110262989997864, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48038557]\n",
      " [0.67299496]\n",
      " [0.50120044]\n",
      " [0.5042792 ]\n",
      " [0.51016039]\n",
      " [0.51876903]\n",
      " [0.5297209 ]\n",
      " [0.54252344]] | y: 0.6710577295621851 | Predicción actual: [[0.5566697]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012106521055102348, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.50120044]\n",
      " [0.5042792 ]\n",
      " [0.51016039]\n",
      " [0.51876903]\n",
      " [0.5297209 ]\n",
      " [0.54252344]\n",
      " [0.55666971]] | y: 0.6737698566447115 | Predicción actual: [[0.5718038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012010985985398293, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.50120044]\n",
      " [0.5042792 ]\n",
      " [0.51016039]\n",
      " [0.51876903]\n",
      " [0.5297209 ]\n",
      " [0.54252344]\n",
      " [0.55666971]\n",
      " [0.57180381]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06813861429691315, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5042792 ]\n",
      " [0.51016039]\n",
      " [0.51876903]\n",
      " [0.5297209 ]\n",
      " [0.54252344]\n",
      " [0.55666971]\n",
      " [0.57180381]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5448983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05969278886914253, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51016039]\n",
      " [0.51876903]\n",
      " [0.5297209 ]\n",
      " [0.54252344]\n",
      " [0.55666971]\n",
      " [0.57180381]\n",
      " [0.71445176]\n",
      " [0.54489827]] | y: 0.722588144130182 | Predicción actual: [[0.5557787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.055612266063690186, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51876903]\n",
      " [0.5297209 ]\n",
      " [0.54252344]\n",
      " [0.55666971]\n",
      " [0.57180381]\n",
      " [0.71445176]\n",
      " [0.54489827]\n",
      " [0.55577868]] | y: 0.6993413405656723 | Predicción actual: [[0.5687259]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011650211177766323, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5297209 ]\n",
      " [0.54252344]\n",
      " [0.55666971]\n",
      " [0.57180381]\n",
      " [0.71445176]\n",
      " [0.54489827]\n",
      " [0.55577868]\n",
      " [0.56872588]] | y: 0.7373111197210385 | Predicción actual: [[0.5826202]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0057232254184782505, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54252344]\n",
      " [0.55666971]\n",
      " [0.57180381]\n",
      " [0.71445176]\n",
      " [0.54489827]\n",
      " [0.55577868]\n",
      " [0.56872588]\n",
      " [0.5826202 ]] | y: 0.7214258039519565 | Predicción actual: [[0.59627044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006528620142489672, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55666971]\n",
      " [0.57180381]\n",
      " [0.71445176]\n",
      " [0.54489827]\n",
      " [0.55577868]\n",
      " [0.56872588]\n",
      " [0.5826202 ]\n",
      " [0.59627044]] | y: 0.7187136768694304 | Predicción actual: [[0.6085462]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0236806683242321, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57180381]\n",
      " [0.71445176]\n",
      " [0.54489827]\n",
      " [0.55577868]\n",
      " [0.56872588]\n",
      " [0.5826202 ]\n",
      " [0.59627044]\n",
      " [0.6085462 ]] | y: 0.6741573033707864 | Predicción actual: [[0.61851686]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004142580553889275, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.54489827]\n",
      " [0.55577868]\n",
      " [0.56872588]\n",
      " [0.5826202 ]\n",
      " [0.59627044]\n",
      " [0.6085462 ]\n",
      " [0.61851686]] | y: 0.698566447113522 | Predicción actual: [[0.62529117]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005552127491682768, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54489827]\n",
      " [0.55577868]\n",
      " [0.56872588]\n",
      " [0.5826202 ]\n",
      " [0.59627044]\n",
      " [0.6085462 ]\n",
      " [0.61851686]\n",
      " [0.62529117]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03271762281656265, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55577868]\n",
      " [0.56872588]\n",
      " [0.5826202 ]\n",
      " [0.59627044]\n",
      " [0.6085462 ]\n",
      " [0.61851686]\n",
      " [0.62529117]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.60520804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.347521321004024e-06, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56872588]\n",
      " [0.5826202 ]\n",
      " [0.59627044]\n",
      " [0.6085462 ]\n",
      " [0.61851686]\n",
      " [0.62529117]\n",
      " [0.72103836]\n",
      " [0.60520804]] | y: 0.7562960092987214 | Predicción actual: [[0.6182508]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0057640704326331615, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5826202 ]\n",
      " [0.59627044]\n",
      " [0.6085462 ]\n",
      " [0.61851686]\n",
      " [0.62529117]\n",
      " [0.72103836]\n",
      " [0.60520804]\n",
      " [0.61825079]] | y: 0.8275862068965516 | Predicción actual: [[0.631189]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03335363045334816, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59627044]\n",
      " [0.6085462 ]\n",
      " [0.61851686]\n",
      " [0.62529117]\n",
      " [0.72103836]\n",
      " [0.60520804]\n",
      " [0.61825079]\n",
      " [0.63118899]] | y: 0.8388221619527314 | Predicción actual: [[0.6432852]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08353910595178604, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6085462 ]\n",
      " [0.61851686]\n",
      " [0.62529117]\n",
      " [0.72103836]\n",
      " [0.60520804]\n",
      " [0.61825079]\n",
      " [0.63118899]\n",
      " [0.64328521]] | y: 0.7942657884540876 | Predicción actual: [[0.6540129]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01841104030609131, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61851686]\n",
      " [0.62529117]\n",
      " [0.72103836]\n",
      " [0.60520804]\n",
      " [0.61825079]\n",
      " [0.63118899]\n",
      " [0.64328521]\n",
      " [0.65401292]] | y: 0.7838047268500579 | Predicción actual: [[0.6630398]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009163766168057919, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62529117]\n",
      " [0.72103836]\n",
      " [0.60520804]\n",
      " [0.61825079]\n",
      " [0.63118899]\n",
      " [0.64328521]\n",
      " [0.65401292]\n",
      " [0.6630398 ]] | y: 0.7679194110809764 | Predicción actual: [[0.6705303]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003115417202934623, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.60520804]\n",
      " [0.61825079]\n",
      " [0.63118899]\n",
      " [0.64328521]\n",
      " [0.65401292]\n",
      " [0.6630398 ]\n",
      " [0.67053032]] | y: 0.7845796203022084 | Predicción actual: [[0.6770515]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011718516470864415, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60520804]\n",
      " [0.61825079]\n",
      " [0.63118899]\n",
      " [0.64328521]\n",
      " [0.65401292]\n",
      " [0.6630398 ]\n",
      " [0.67053032]\n",
      " [0.67705148]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09767428040504456, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61825079]\n",
      " [0.63118899]\n",
      " [0.64328521]\n",
      " [0.65401292]\n",
      " [0.6630398 ]\n",
      " [0.67053032]\n",
      " [0.67705148]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6699706]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046142395585775375, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63118899]\n",
      " [0.64328521]\n",
      " [0.65401292]\n",
      " [0.6630398 ]\n",
      " [0.67053032]\n",
      " [0.67705148]\n",
      " [0.87872917]\n",
      " [0.66997057]] | y: 0.8488957768306855 | Predicción actual: [[0.6842164]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018694249913096428, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64328521]\n",
      " [0.65401292]\n",
      " [0.6630398 ]\n",
      " [0.67053032]\n",
      " [0.67705148]\n",
      " [0.87872917]\n",
      " [0.66997057]\n",
      " [0.68421638]] | y: 0.8182874854707476 | Predicción actual: [[0.69920176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011826429516077042, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65401292]\n",
      " [0.6630398 ]\n",
      " [0.67053032]\n",
      " [0.67705148]\n",
      " [0.87872917]\n",
      " [0.66997057]\n",
      " [0.68421638]\n",
      " [0.69920176]] | y: 0.8268113134444013 | Predicción actual: [[0.7146253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013578064972534776, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6630398 ]\n",
      " [0.67053032]\n",
      " [0.67705148]\n",
      " [0.87872917]\n",
      " [0.66997057]\n",
      " [0.68421638]\n",
      " [0.69920176]\n",
      " [0.7146253 ]] | y: 0.7853545137543589 | Predicción actual: [[0.7301823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013585882261395454, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67053032]\n",
      " [0.67705148]\n",
      " [0.87872917]\n",
      " [0.66997057]\n",
      " [0.68421638]\n",
      " [0.69920176]\n",
      " [0.7146253 ]\n",
      " [0.73018229]] | y: 0.7892289810151103 | Predicción actual: [[0.74588645]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.877229341422208e-06, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67705148]\n",
      " [0.87872917]\n",
      " [0.66997057]\n",
      " [0.68421638]\n",
      " [0.69920176]\n",
      " [0.7146253 ]\n",
      " [0.73018229]\n",
      " [0.74588645]] | y: 0.8341728012398295 | Predicción actual: [[0.76157105]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008466930128633976, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.66997057]\n",
      " [0.68421638]\n",
      " [0.69920176]\n",
      " [0.7146253 ]\n",
      " [0.73018229]\n",
      " [0.74588645]\n",
      " [0.76157105]] | y: 0.8124757845796202 | Predicción actual: [[0.7770519]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017715031281113625, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66997057]\n",
      " [0.68421638]\n",
      " [0.69920176]\n",
      " [0.7146253 ]\n",
      " [0.73018229]\n",
      " [0.74588645]\n",
      " [0.76157105]\n",
      " [0.77705193]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013293824158608913, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68421638]\n",
      " [0.69920176]\n",
      " [0.7146253 ]\n",
      " [0.73018229]\n",
      " [0.74588645]\n",
      " [0.76157105]\n",
      " [0.77705193]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7482352]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0220296923071146, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69920176]\n",
      " [0.7146253 ]\n",
      " [0.73018229]\n",
      " [0.74588645]\n",
      " [0.76157105]\n",
      " [0.77705193]\n",
      " [0.80123983]\n",
      " [0.74823523]] | y: 0.793490895001937 | Predicción actual: [[0.7637012]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005629335064440966, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7146253 ]\n",
      " [0.73018229]\n",
      " [0.74588645]\n",
      " [0.76157105]\n",
      " [0.77705193]\n",
      " [0.80123983]\n",
      " [0.74823523]\n",
      " [0.7637012 ]] | y: 0.760170476559473 | Predicción actual: [[0.77831197]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0052033681422472, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73018229]\n",
      " [0.74588645]\n",
      " [0.76157105]\n",
      " [0.77705193]\n",
      " [0.80123983]\n",
      " [0.74823523]\n",
      " [0.7637012 ]\n",
      " [0.77831197]] | y: 0.7353738860906625 | Predicción actual: [[0.79133356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0321081317961216, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74588645]\n",
      " [0.76157105]\n",
      " [0.77705193]\n",
      " [0.80123983]\n",
      " [0.74823523]\n",
      " [0.7637012 ]\n",
      " [0.77831197]\n",
      " [0.79133356]] | y: 0.7101898488957767 | Predicción actual: [[0.801877]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003437126288190484, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76157105]\n",
      " [0.77705193]\n",
      " [0.80123983]\n",
      " [0.74823523]\n",
      " [0.7637012 ]\n",
      " [0.77831197]\n",
      " [0.79133356]\n",
      " [0.80187702]] | y: 0.7121270825261525 | Predicción actual: [[0.80974084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005556969903409481, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77705193]\n",
      " [0.80123983]\n",
      " [0.74823523]\n",
      " [0.7637012 ]\n",
      " [0.77831197]\n",
      " [0.79133356]\n",
      " [0.80187702]\n",
      " [0.80974084]] | y: 0.7396358000774894 | Predicción actual: [[0.81432164]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038766826037317514, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.74823523]\n",
      " [0.7637012 ]\n",
      " [0.77831197]\n",
      " [0.79133356]\n",
      " [0.80187702]\n",
      " [0.80974084]\n",
      " [0.81432164]] | y: 0.7361487795428128 | Predicción actual: [[0.8153921]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005305801052600145, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74823523]\n",
      " [0.7637012 ]\n",
      " [0.77831197]\n",
      " [0.79133356]\n",
      " [0.80187702]\n",
      " [0.80974084]\n",
      " [0.81432164]\n",
      " [0.81539208]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05215934291481972, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7637012 ]\n",
      " [0.77831197]\n",
      " [0.79133356]\n",
      " [0.80187702]\n",
      " [0.80974084]\n",
      " [0.81432164]\n",
      " [0.81539208]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8206151]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008877983200363815, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77831197]\n",
      " [0.79133356]\n",
      " [0.80187702]\n",
      " [0.80974084]\n",
      " [0.81432164]\n",
      " [0.81539208]\n",
      " [0.66757071]\n",
      " [0.82061511]] | y: 0.696629213483146 | Predicción actual: [[0.82797843]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038324058055877686, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79133356]\n",
      " [0.80187702]\n",
      " [0.80974084]\n",
      " [0.81432164]\n",
      " [0.81539208]\n",
      " [0.66757071]\n",
      " [0.82061511]\n",
      " [0.82797843]] | y: 0.6559473072452537 | Predicción actual: [[0.8313526]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040132857859134674, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80187702]\n",
      " [0.80974084]\n",
      " [0.81432164]\n",
      " [0.81539208]\n",
      " [0.66757071]\n",
      " [0.82061511]\n",
      " [0.82797843]\n",
      " [0.83135259]] | y: 0.6788066640836885 | Predicción actual: [[0.8308691]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009558233432471752, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80974084]\n",
      " [0.81432164]\n",
      " [0.81539208]\n",
      " [0.66757071]\n",
      " [0.82061511]\n",
      " [0.82797843]\n",
      " [0.83135259]\n",
      " [0.83086908]] | y: 0.6760945370011622 | Predicción actual: [[0.8275528]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023851819336414337, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81432164]\n",
      " [0.81539208]\n",
      " [0.66757071]\n",
      " [0.82061511]\n",
      " [0.82797843]\n",
      " [0.83135259]\n",
      " [0.83086908]\n",
      " [0.8275528 ]] | y: 0.7295621851995349 | Predicción actual: [[0.82212716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00360633316449821, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81539208]\n",
      " [0.66757071]\n",
      " [0.82061511]\n",
      " [0.82797843]\n",
      " [0.83135259]\n",
      " [0.83086908]\n",
      " [0.8275528 ]\n",
      " [0.82212716]] | y: 0.7012785741960481 | Predicción actual: [[0.81607026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044306136667728424, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.82061511]\n",
      " [0.82797843]\n",
      " [0.83135259]\n",
      " [0.83086908]\n",
      " [0.8275528 ]\n",
      " [0.82212716]\n",
      " [0.81607026]] | y: 0.767531964354901 | Predicción actual: [[0.8104774]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.303504389710724e-05, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82061511]\n",
      " [0.82797843]\n",
      " [0.83135259]\n",
      " [0.83086908]\n",
      " [0.8275528 ]\n",
      " [0.82212716]\n",
      " [0.81607026]\n",
      " [0.81047738]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025383392348885536, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82797843]\n",
      " [0.83135259]\n",
      " [0.83086908]\n",
      " [0.8275528 ]\n",
      " [0.82212716]\n",
      " [0.81607026]\n",
      " [0.81047738]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8513218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006908030714839697, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83135259]\n",
      " [0.83086908]\n",
      " [0.8275528 ]\n",
      " [0.82212716]\n",
      " [0.81607026]\n",
      " [0.81047738]\n",
      " [0.75513367]\n",
      " [0.85132182]] | y: 0.7520340953118947 | Predicción actual: [[0.84782976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013675985857844353, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83086908]\n",
      " [0.8275528 ]\n",
      " [0.82212716]\n",
      " [0.81607026]\n",
      " [0.81047738]\n",
      " [0.75513367]\n",
      " [0.85132182]\n",
      " [0.84782976]] | y: 0.7098024021697016 | Predicción actual: [[0.84251916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032508496195077896, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8275528 ]\n",
      " [0.82212716]\n",
      " [0.81607026]\n",
      " [0.81047738]\n",
      " [0.75513367]\n",
      " [0.85132182]\n",
      " [0.84782976]\n",
      " [0.84251916]] | y: 0.6904300658659435 | Predicción actual: [[0.8366791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007505355752073228, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82212716]\n",
      " [0.81607026]\n",
      " [0.81047738]\n",
      " [0.75513367]\n",
      " [0.85132182]\n",
      " [0.84782976]\n",
      " [0.84251916]\n",
      " [0.8366791 ]] | y: 0.7543587756683454 | Predicción actual: [[0.8319383]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020189998031128198, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81607026]\n",
      " [0.81047738]\n",
      " [0.75513367]\n",
      " [0.85132182]\n",
      " [0.84782976]\n",
      " [0.84251916]\n",
      " [0.8366791 ]\n",
      " [0.83193833]] | y: 0.7222006974041069 | Predicción actual: [[0.8294629]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005943974247202277, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81047738]\n",
      " [0.75513367]\n",
      " [0.85132182]\n",
      " [0.84782976]\n",
      " [0.84251916]\n",
      " [0.8366791 ]\n",
      " [0.83193833]\n",
      " [0.82946289]] | y: 0.8485083301046106 | Predicción actual: [[0.82978785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012851094652432948, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.85132182]\n",
      " [0.84782976]\n",
      " [0.84251916]\n",
      " [0.8366791 ]\n",
      " [0.83193833]\n",
      " [0.82946289]\n",
      " [0.82978785]] | y: 0.9054629988376597 | Predicción actual: [[0.83312905]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015313715673983097, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85132182]\n",
      " [0.84782976]\n",
      " [0.84251916]\n",
      " [0.8366791 ]\n",
      " [0.83193833]\n",
      " [0.82946289]\n",
      " [0.82978785]\n",
      " [0.83312905]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002538942266255617, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84782976]\n",
      " [0.84251916]\n",
      " [0.8366791 ]\n",
      " [0.83193833]\n",
      " [0.82946289]\n",
      " [0.82978785]\n",
      " [0.83312905]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8505566]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026556406170129776, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84251916]\n",
      " [0.8366791 ]\n",
      " [0.83193833]\n",
      " [0.82946289]\n",
      " [0.82978785]\n",
      " [0.83312905]\n",
      " [0.8822162 ]\n",
      " [0.85055661]] | y: 0.889577683068578 | Predicción actual: [[0.84655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06259912997484207, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8366791 ]\n",
      " [0.83193833]\n",
      " [0.82946289]\n",
      " [0.82978785]\n",
      " [0.83312905]\n",
      " [0.8822162 ]\n",
      " [0.85055661]\n",
      " [0.84654999]] | y: 0.8748547074777218 | Predicción actual: [[0.8437519]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008048675023019314, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83193833]\n",
      " [0.82946289]\n",
      " [0.82978785]\n",
      " [0.83312905]\n",
      " [0.8822162 ]\n",
      " [0.85055661]\n",
      " [0.84654999]\n",
      " [0.84375191]] | y: 0.9132119333591631 | Predicción actual: [[0.8435136]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005469773896038532, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82946289]\n",
      " [0.82978785]\n",
      " [0.83312905]\n",
      " [0.8822162 ]\n",
      " [0.85055661]\n",
      " [0.84654999]\n",
      " [0.84375191]\n",
      " [0.84351361]] | y: 1.0 | Predicción actual: [[0.8457036]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025597089901566505, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82978785]\n",
      " [0.83312905]\n",
      " [0.8822162 ]\n",
      " [0.85055661]\n",
      " [0.84654999]\n",
      " [0.84375191]\n",
      " [0.84351361]\n",
      " [0.8457036 ]] | y: 0.9705540488182873 | Predicción actual: [[0.84988904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013575421646237373, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83312905]\n",
      " [0.8822162 ]\n",
      " [0.85055661]\n",
      " [0.84654999]\n",
      " [0.84375191]\n",
      " [0.84351361]\n",
      " [0.8457036 ]\n",
      " [0.84988904]] | y: 0.8888027896164277 | Predicción actual: [[0.8550646]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001843804377131164, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.85055661]\n",
      " [0.84654999]\n",
      " [0.84375191]\n",
      " [0.84351361]\n",
      " [0.8457036 ]\n",
      " [0.84988904]\n",
      " [0.85506457]] | y: 0.877954281286323 | Predicción actual: [[0.8598197]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004107973072677851, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85055661]\n",
      " [0.84654999]\n",
      " [0.84375191]\n",
      " [0.84351361]\n",
      " [0.8457036 ]\n",
      " [0.84988904]\n",
      " [0.85506457]\n",
      " [0.85981971]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024275530129671097, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84654999]\n",
      " [0.84375191]\n",
      " [0.84351361]\n",
      " [0.8457036 ]\n",
      " [0.84988904]\n",
      " [0.85506457]\n",
      " [0.85981971]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8487922]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023411333560943604, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84375191]\n",
      " [0.84351361]\n",
      " [0.8457036 ]\n",
      " [0.84988904]\n",
      " [0.85506457]\n",
      " [0.85981971]\n",
      " [0.84889578]\n",
      " [0.8487922 ]] | y: 0.8550949244478885 | Predicción actual: [[0.8490043]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004310171934776008, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84351361]\n",
      " [0.8457036 ]\n",
      " [0.84988904]\n",
      " [0.85506457]\n",
      " [0.85981971]\n",
      " [0.84889578]\n",
      " [0.8487922 ]\n",
      " [0.84900433]] | y: 0.8752421542037967 | Predicción actual: [[0.8503455]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007809919770807028, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8457036 ]\n",
      " [0.84988904]\n",
      " [0.85506457]\n",
      " [0.85981971]\n",
      " [0.84889578]\n",
      " [0.8487922 ]\n",
      " [0.84900433]\n",
      " [0.85034549]] | y: 0.857032158078264 | Predicción actual: [[0.8520895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.189591658767313e-05, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84988904]\n",
      " [0.85506457]\n",
      " [0.85981971]\n",
      " [0.84889578]\n",
      " [0.8487922 ]\n",
      " [0.84900433]\n",
      " [0.85034549]\n",
      " [0.85208952]] | y: 0.8500581170089112 | Predicción actual: [[0.85352427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.053526025265455246, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85506457]\n",
      " [0.85981971]\n",
      " [0.84889578]\n",
      " [0.8487922 ]\n",
      " [0.84900433]\n",
      " [0.85034549]\n",
      " [0.85208952]\n",
      " [0.85352427]] | y: 0.8426966292134832 | Predicción actual: [[0.8533393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026670873165130615, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85981971]\n",
      " [0.84889578]\n",
      " [0.8487922 ]\n",
      " [0.84900433]\n",
      " [0.85034549]\n",
      " [0.85208952]\n",
      " [0.85352427]\n",
      " [0.85333931]] | y: 0.8229368461836497 | Predicción actual: [[0.8519322]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005521463230252266, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.8487922 ]\n",
      " [0.84900433]\n",
      " [0.85034549]\n",
      " [0.85208952]\n",
      " [0.85352427]\n",
      " [0.85333931]\n",
      " [0.85193223]] | y: 0.7745060054242543 | Predicción actual: [[0.848833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026665715500712395, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8487922 ]\n",
      " [0.84900433]\n",
      " [0.85034549]\n",
      " [0.85208952]\n",
      " [0.85352427]\n",
      " [0.85333931]\n",
      " [0.85193223]\n",
      " [0.84883302]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.4792553884035442e-05, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84900433]\n",
      " [0.85034549]\n",
      " [0.85208952]\n",
      " [0.85352427]\n",
      " [0.85333931]\n",
      " [0.85193223]\n",
      " [0.84883302]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.847951]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.843705028179102e-06, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85034549]\n",
      " [0.85208952]\n",
      " [0.85352427]\n",
      " [0.85333931]\n",
      " [0.85193223]\n",
      " [0.84883302]\n",
      " [0.78419217]\n",
      " [0.84795099]] | y: 0.854320030995738 | Predicción actual: [[0.84690183]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010038486681878567, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85208952]\n",
      " [0.85352427]\n",
      " [0.85333931]\n",
      " [0.85193223]\n",
      " [0.84883302]\n",
      " [0.78419217]\n",
      " [0.84795099]\n",
      " [0.84690183]] | y: 0.8368849283223556 | Predicción actual: [[0.8450351]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034557138569653034, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85352427]\n",
      " [0.85333931]\n",
      " [0.85193223]\n",
      " [0.84883302]\n",
      " [0.78419217]\n",
      " [0.84795099]\n",
      " [0.84690183]\n",
      " [0.84503508]] | y: 0.8299108872530028 | Predicción actual: [[0.8418433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006314113270491362, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85333931]\n",
      " [0.85193223]\n",
      " [0.84883302]\n",
      " [0.78419217]\n",
      " [0.84795099]\n",
      " [0.84690183]\n",
      " [0.84503508]\n",
      " [0.84184331]] | y: 0.887253002712127 | Predicción actual: [[0.83767533]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00047186939627863467, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85193223]\n",
      " [0.84883302]\n",
      " [0.78419217]\n",
      " [0.84795099]\n",
      " [0.84690183]\n",
      " [0.84503508]\n",
      " [0.84184331]\n",
      " [0.83767533]] | y: 0.8597442851607902 | Predicción actual: [[0.8329678]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022860122844576836, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84883302]\n",
      " [0.78419217]\n",
      " [0.84795099]\n",
      " [0.84690183]\n",
      " [0.84503508]\n",
      " [0.84184331]\n",
      " [0.83767533]\n",
      " [0.83296782]] | y: 0.8395970554048819 | Predicción actual: [[0.8278404]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02196591906249523, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.84795099]\n",
      " [0.84690183]\n",
      " [0.84503508]\n",
      " [0.84184331]\n",
      " [0.83767533]\n",
      " [0.83296782]\n",
      " [0.82784039]] | y: 0.7838047268500579 | Predicción actual: [[0.8235326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005910221370868385, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84795099]\n",
      " [0.84690183]\n",
      " [0.84503508]\n",
      " [0.84184331]\n",
      " [0.83767533]\n",
      " [0.83296782]\n",
      " [0.82784039]\n",
      " [0.82353258]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005010936292819679, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84690183]\n",
      " [0.84503508]\n",
      " [0.84184331]\n",
      " [0.83767533]\n",
      " [0.83296782]\n",
      " [0.82784039]\n",
      " [0.82353258]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.83556175]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00043939542956650257, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84503508]\n",
      " [0.84184331]\n",
      " [0.83767533]\n",
      " [0.83296782]\n",
      " [0.82784039]\n",
      " [0.82353258]\n",
      " [0.81828749]\n",
      " [0.83556175]] | y: 0.7605579232855482 | Predicción actual: [[0.83224875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013237274251878262, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84184331]\n",
      " [0.83767533]\n",
      " [0.83296782]\n",
      " [0.82784039]\n",
      " [0.82353258]\n",
      " [0.81828749]\n",
      " [0.83556175]\n",
      " [0.83224875]] | y: 0.7915536613715615 | Predicción actual: [[0.828806]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.339800893329084e-05, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83767533]\n",
      " [0.83296782]\n",
      " [0.82784039]\n",
      " [0.82353258]\n",
      " [0.81828749]\n",
      " [0.83556175]\n",
      " [0.83224875]\n",
      " [0.82880598]] | y: 0.7686943045331267 | Predicción actual: [[0.82558167]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030550053343176842, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83296782]\n",
      " [0.82784039]\n",
      " [0.82353258]\n",
      " [0.81828749]\n",
      " [0.83556175]\n",
      " [0.83224875]\n",
      " [0.82880598]\n",
      " [0.82558167]] | y: 0.7686943045331267 | Predicción actual: [[0.82267076]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025904731824994087, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82784039]\n",
      " [0.82353258]\n",
      " [0.81828749]\n",
      " [0.83556175]\n",
      " [0.83224875]\n",
      " [0.82880598]\n",
      " [0.82558167]\n",
      " [0.82267076]] | y: 0.7989151491669895 | Predicción actual: [[0.82048213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.031248360872268677, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82353258]\n",
      " [0.81828749]\n",
      " [0.83556175]\n",
      " [0.83224875]\n",
      " [0.82880598]\n",
      " [0.82558167]\n",
      " [0.82267076]\n",
      " [0.82048213]] | y: 0.7900038744672608 | Predicción actual: [[0.81928396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016465557739138603, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.83556175]\n",
      " [0.83224875]\n",
      " [0.82880598]\n",
      " [0.82558167]\n",
      " [0.82267076]\n",
      " [0.82048213]\n",
      " [0.81928396]] | y: 0.760170476559473 | Predicción actual: [[0.8191002]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03412585332989693, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83556175]\n",
      " [0.83224875]\n",
      " [0.82880598]\n",
      " [0.82558167]\n",
      " [0.82267076]\n",
      " [0.82048213]\n",
      " [0.81928396]\n",
      " [0.8191002 ]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03393473103642464, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83224875]\n",
      " [0.82880598]\n",
      " [0.82558167]\n",
      " [0.82267076]\n",
      " [0.82048213]\n",
      " [0.81928396]\n",
      " [0.8191002 ]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8149445]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05732598900794983, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82880598]\n",
      " [0.82558167]\n",
      " [0.82267076]\n",
      " [0.82048213]\n",
      " [0.81928396]\n",
      " [0.8191002 ]\n",
      " [0.68539326]\n",
      " [0.81494451]] | y: 0.6648585819449826 | Predicción actual: [[0.80854326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06669192016124725, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82558167]\n",
      " [0.82267076]\n",
      " [0.82048213]\n",
      " [0.81928396]\n",
      " [0.8191002 ]\n",
      " [0.68539326]\n",
      " [0.81494451]\n",
      " [0.80854326]] | y: 0.7078651685393258 | Predicción actual: [[0.8008809]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03199644759297371, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82267076]\n",
      " [0.82048213]\n",
      " [0.81928396]\n",
      " [0.8191002 ]\n",
      " [0.68539326]\n",
      " [0.81494451]\n",
      " [0.80854326]\n",
      " [0.80088091]] | y: 0.6648585819449826 | Predicción actual: [[0.7922203]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002792394661810249, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82048213]\n",
      " [0.81928396]\n",
      " [0.8191002 ]\n",
      " [0.68539326]\n",
      " [0.81494451]\n",
      " [0.80854326]\n",
      " [0.80088091]\n",
      " [0.79222029]] | y: 0.7113521890740022 | Predicción actual: [[0.78305364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003472601994872093, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81928396]\n",
      " [0.8191002 ]\n",
      " [0.68539326]\n",
      " [0.81494451]\n",
      " [0.80854326]\n",
      " [0.80088091]\n",
      " [0.79222029]\n",
      " [0.78305364]] | y: 0.6772568771793879 | Predicción actual: [[0.7734397]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011474689468741417, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8191002 ]\n",
      " [0.68539326]\n",
      " [0.81494451]\n",
      " [0.80854326]\n",
      " [0.80088091]\n",
      " [0.79222029]\n",
      " [0.78305364]\n",
      " [0.77343971]] | y: 0.7621077101898488 | Predicción actual: [[0.7630178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010787248611450195, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.81494451]\n",
      " [0.80854326]\n",
      " [0.80088091]\n",
      " [0.79222029]\n",
      " [0.78305364]\n",
      " [0.77343971]\n",
      " [0.76301777]] | y: 0.8070515304145678 | Predicción actual: [[0.75184995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038187983445823193, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81494451]\n",
      " [0.80854326]\n",
      " [0.80088091]\n",
      " [0.79222029]\n",
      " [0.78305364]\n",
      " [0.77343971]\n",
      " [0.76301777]\n",
      " [0.75184995]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003095157677307725, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80854326]\n",
      " [0.80088091]\n",
      " [0.79222029]\n",
      " [0.78305364]\n",
      " [0.77343971]\n",
      " [0.76301777]\n",
      " [0.75184995]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7701184]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.062074851244688034, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80088091]\n",
      " [0.79222029]\n",
      " [0.78305364]\n",
      " [0.77343971]\n",
      " [0.76301777]\n",
      " [0.75184995]\n",
      " [0.81518791]\n",
      " [0.77011842]] | y: 0.9597055404881829 | Predicción actual: [[0.7628807]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.075833760201931, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79222029]\n",
      " [0.78305364]\n",
      " [0.77343971]\n",
      " [0.76301777]\n",
      " [0.75184995]\n",
      " [0.81518791]\n",
      " [0.77011842]\n",
      " [0.76288068]] | y: 0.9643549012010848 | Predicción actual: [[0.75687313]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016239291056990623, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78305364]\n",
      " [0.77343971]\n",
      " [0.76301777]\n",
      " [0.75184995]\n",
      " [0.81518791]\n",
      " [0.77011842]\n",
      " [0.76288068]\n",
      " [0.75687313]] | y: 0.8880278961642774 | Predicción actual: [[0.75241315]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013382771285250783, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77343971]\n",
      " [0.76301777]\n",
      " [0.75184995]\n",
      " [0.81518791]\n",
      " [0.77011842]\n",
      " [0.76288068]\n",
      " [0.75687313]\n",
      " [0.75241315]] | y: 0.8926772568771792 | Predicción actual: [[0.74968135]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040913622826337814, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76301777]\n",
      " [0.75184995]\n",
      " [0.81518791]\n",
      " [0.77011842]\n",
      " [0.76288068]\n",
      " [0.75687313]\n",
      " [0.75241315]\n",
      " [0.74968135]] | y: 0.8752421542037967 | Predicción actual: [[0.7491713]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08073756843805313, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75184995]\n",
      " [0.81518791]\n",
      " [0.77011842]\n",
      " [0.76288068]\n",
      " [0.75687313]\n",
      " [0.75241315]\n",
      " [0.74968135]\n",
      " [0.74917132]] | y: 0.8508330104610615 | Predicción actual: [[0.7512606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009292646427638829, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.77011842]\n",
      " [0.76288068]\n",
      " [0.75687313]\n",
      " [0.75241315]\n",
      " [0.74968135]\n",
      " [0.74917132]\n",
      " [0.75126058]] | y: 0.8488957768306855 | Predicción actual: [[0.75597006]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020329304039478302, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77011842]\n",
      " [0.76288068]\n",
      " [0.75687313]\n",
      " [0.75241315]\n",
      " [0.74968135]\n",
      " [0.74917132]\n",
      " [0.75126058]\n",
      " [0.75597006]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01581081561744213, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76288068]\n",
      " [0.75687313]\n",
      " [0.75241315]\n",
      " [0.74968135]\n",
      " [0.74917132]\n",
      " [0.75126058]\n",
      " [0.75597006]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.74060744]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.17043200135231018, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75687313]\n",
      " [0.75241315]\n",
      " [0.74968135]\n",
      " [0.74917132]\n",
      " [0.75126058]\n",
      " [0.75597006]\n",
      " [0.96241767]\n",
      " [0.74060744]] | y: 0.9407206509104997 | Predicción actual: [[0.7423767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0761483758687973, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75241315]\n",
      " [0.74968135]\n",
      " [0.74917132]\n",
      " [0.75126058]\n",
      " [0.75597006]\n",
      " [0.96241767]\n",
      " [0.74060744]\n",
      " [0.74237669]] | y: 0.9724912824486633 | Predicción actual: [[0.74756145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017441021278500557, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74968135]\n",
      " [0.74917132]\n",
      " [0.75126058]\n",
      " [0.75597006]\n",
      " [0.96241767]\n",
      " [0.74060744]\n",
      " [0.74237669]\n",
      " [0.74756145]] | y: 0.9969004261913985 | Predicción actual: [[0.75559247]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03931894525885582, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74917132]\n",
      " [0.75126058]\n",
      " [0.75597006]\n",
      " [0.96241767]\n",
      " [0.74060744]\n",
      " [0.74237669]\n",
      " [0.74756145]\n",
      " [0.75559247]] | y: 0.951181712514529 | Predicción actual: [[0.7658332]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02278193086385727, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75126058]\n",
      " [0.75597006]\n",
      " [0.96241767]\n",
      " [0.74060744]\n",
      " [0.74237669]\n",
      " [0.74756145]\n",
      " [0.75559247]\n",
      " [0.7658332 ]] | y: 0.8957768306857805 | Predicción actual: [[0.7771854]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022464048117399216, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75597006]\n",
      " [0.96241767]\n",
      " [0.74060744]\n",
      " [0.74237669]\n",
      " [0.74756145]\n",
      " [0.75559247]\n",
      " [0.7658332 ]\n",
      " [0.77718538]] | y: 0.8814413018209997 | Predicción actual: [[0.78843683]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01092137023806572, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.74060744]\n",
      " [0.74237669]\n",
      " [0.74756145]\n",
      " [0.75559247]\n",
      " [0.7658332 ]\n",
      " [0.77718538]\n",
      " [0.78843683]] | y: 0.9170864006199149 | Predicción actual: [[0.7983125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009358064271509647, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74060744]\n",
      " [0.74237669]\n",
      " [0.74756145]\n",
      " [0.75559247]\n",
      " [0.7658332 ]\n",
      " [0.77718538]\n",
      " [0.78843683]\n",
      " [0.79831249]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009971236810088158, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74237669]\n",
      " [0.74756145]\n",
      " [0.75559247]\n",
      " [0.7658332 ]\n",
      " [0.77718538]\n",
      " [0.78843683]\n",
      " [0.79831249]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7556853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060761258006095886, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74756145]\n",
      " [0.75559247]\n",
      " [0.7658332 ]\n",
      " [0.77718538]\n",
      " [0.78843683]\n",
      " [0.79831249]\n",
      " [0.91979853]\n",
      " [0.75568533]] | y: 0.9682293684618366 | Predicción actual: [[0.76678264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10794959217309952, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75559247]\n",
      " [0.7658332 ]\n",
      " [0.77718538]\n",
      " [0.78843683]\n",
      " [0.79831249]\n",
      " [0.91979853]\n",
      " [0.75568533]\n",
      " [0.76678264]] | y: 0.9577683068578069 | Predicción actual: [[0.7795863]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02204183116555214, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20440635]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022141825407743454, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20440635]] | y: 0.10422316931421921 | Predicción actual: [[0.18881899]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00502445874735713, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20440635]\n",
      " [0.18881899]] | y: 0.15420379697791559 | Predicción actual: [[0.19320375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014341439818963408, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20440635]\n",
      " [0.18881899]\n",
      " [0.19320375]] | y: 0.1557535838822161 | Predicción actual: [[0.20507467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034206523559987545, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20440635]\n",
      " [0.18881899]\n",
      " [0.19320375]\n",
      " [0.20507467]] | y: 0.12553273924835334 | Predicción actual: [[0.21811956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007279430516064167, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20440635]\n",
      " [0.18881899]\n",
      " [0.19320375]\n",
      " [0.20507467]\n",
      " [0.21811956]] | y: 0.1456799690042619 | Predicción actual: [[0.22847062]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0046873739920556545, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20440635]\n",
      " [0.18881899]\n",
      " [0.19320375]\n",
      " [0.20507467]\n",
      " [0.21811956]\n",
      " [0.22847062]] | y: 0.1464548624564122 | Predicción actual: [[0.25055116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017079772427678108, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20440635]\n",
      " [0.18881899]\n",
      " [0.19320375]\n",
      " [0.20507467]\n",
      " [0.21811956]\n",
      " [0.22847062]\n",
      " [0.25055116]] | y: 0.1960480433940332 | Predicción actual: [[0.27772787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011293535120785236, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20440635]\n",
      " [0.18881899]\n",
      " [0.19320375]\n",
      " [0.20507467]\n",
      " [0.21811956]\n",
      " [0.22847062]\n",
      " [0.25055116]\n",
      " [0.27772787]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005776109639555216, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18881899]\n",
      " [0.19320375]\n",
      " [0.20507467]\n",
      " [0.21811956]\n",
      " [0.22847062]\n",
      " [0.25055116]\n",
      " [0.27772787]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.31285277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003661910304799676, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19320375]\n",
      " [0.20507467]\n",
      " [0.21811956]\n",
      " [0.22847062]\n",
      " [0.25055116]\n",
      " [0.27772787]\n",
      " [0.2305308 ]\n",
      " [0.31285277]] | y: 0.211933359163115 | Predicción actual: [[0.3205473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007855811156332493, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20507467]\n",
      " [0.21811956]\n",
      " [0.22847062]\n",
      " [0.25055116]\n",
      " [0.27772787]\n",
      " [0.2305308 ]\n",
      " [0.31285277]\n",
      " [0.32054731]] | y: 0.2072839984502131 | Predicción actual: [[0.3301797]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01892424002289772, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21811956]\n",
      " [0.22847062]\n",
      " [0.25055116]\n",
      " [0.27772787]\n",
      " [0.2305308 ]\n",
      " [0.31285277]\n",
      " [0.32054731]\n",
      " [0.33017969]] | y: 0.19294846958543205 | Predicción actual: [[0.34044895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04375988245010376, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22847062]\n",
      " [0.25055116]\n",
      " [0.27772787]\n",
      " [0.2305308 ]\n",
      " [0.31285277]\n",
      " [0.32054731]\n",
      " [0.33017969]\n",
      " [0.34044895]] | y: 0.19682293684618352 | Predicción actual: [[0.35123286]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02917373925447464, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.25055116]\n",
      " [0.27772787]\n",
      " [0.2305308 ]\n",
      " [0.31285277]\n",
      " [0.32054731]\n",
      " [0.33017969]\n",
      " [0.34044895]\n",
      " [0.35123286]] | y: 0.21425803951956607 | Predicción actual: [[0.36331517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020795512944459915, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27772787]\n",
      " [0.2305308 ]\n",
      " [0.31285277]\n",
      " [0.32054731]\n",
      " [0.33017969]\n",
      " [0.34044895]\n",
      " [0.35123286]\n",
      " [0.36331517]] | y: 0.18132506780317698 | Predicción actual: [[0.37399662]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029468318447470665, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31285277]\n",
      " [0.32054731]\n",
      " [0.33017969]\n",
      " [0.34044895]\n",
      " [0.35123286]\n",
      " [0.36331517]\n",
      " [0.37399662]] | y: 0.17512592018597434 | Predicción actual: [[0.38168436]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019968004897236824, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31285277]\n",
      " [0.32054731]\n",
      " [0.33017969]\n",
      " [0.34044895]\n",
      " [0.35123286]\n",
      " [0.36331517]\n",
      " [0.37399662]\n",
      " [0.38168436]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08033900707960129, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32054731]\n",
      " [0.33017969]\n",
      " [0.34044895]\n",
      " [0.35123286]\n",
      " [0.36331517]\n",
      " [0.37399662]\n",
      " [0.38168436]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40999788]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07186448574066162, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33017969]\n",
      " [0.34044895]\n",
      " [0.35123286]\n",
      " [0.36331517]\n",
      " [0.37399662]\n",
      " [0.38168436]\n",
      " [0.14800465]\n",
      " [0.40999788]] | y: 0.19217357613328173 | Predicción actual: [[0.4143567]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05427760258316994, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34044895]\n",
      " [0.35123286]\n",
      " [0.36331517]\n",
      " [0.37399662]\n",
      " [0.38168436]\n",
      " [0.14800465]\n",
      " [0.40999788]\n",
      " [0.41435671]] | y: 0.1859744285160791 | Predicción actual: [[0.4168692]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06123486906290054, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35123286]\n",
      " [0.36331517]\n",
      " [0.37399662]\n",
      " [0.38168436]\n",
      " [0.14800465]\n",
      " [0.40999788]\n",
      " [0.41435671]\n",
      " [0.41686919]] | y: 0.26695079426578844 | Predicción actual: [[0.41756818]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013265399262309074, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36331517]\n",
      " [0.37399662]\n",
      " [0.38168436]\n",
      " [0.14800465]\n",
      " [0.40999788]\n",
      " [0.41435671]\n",
      " [0.41686919]\n",
      " [0.41756818]] | y: 0.2925222781867493 | Predicción actual: [[0.4167387]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01773833855986595, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37399662]\n",
      " [0.38168436]\n",
      " [0.14800465]\n",
      " [0.40999788]\n",
      " [0.41435671]\n",
      " [0.41686919]\n",
      " [0.41756818]\n",
      " [0.41673869]] | y: 0.3177063153816349 | Predicción actual: [[0.41439262]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021439891308546066, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38168436]\n",
      " [0.14800465]\n",
      " [0.40999788]\n",
      " [0.41435671]\n",
      " [0.41686919]\n",
      " [0.41756818]\n",
      " [0.41673869]\n",
      " [0.41439262]] | y: 0.31266950794265785 | Predicción actual: [[0.41113782]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006712287664413452, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40999788]\n",
      " [0.41435671]\n",
      " [0.41686919]\n",
      " [0.41756818]\n",
      " [0.41673869]\n",
      " [0.41439262]\n",
      " [0.41113782]] | y: 0.2890352576520729 | Predicción actual: [[0.40797353]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017904769629240036, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40999788]\n",
      " [0.41435671]\n",
      " [0.41686919]\n",
      " [0.41756818]\n",
      " [0.41673869]\n",
      " [0.41439262]\n",
      " [0.41113782]\n",
      " [0.40797353]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02720952033996582, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41435671]\n",
      " [0.41686919]\n",
      " [0.41756818]\n",
      " [0.41673869]\n",
      " [0.41439262]\n",
      " [0.41113782]\n",
      " [0.40797353]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.46545264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023768022656440735, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41686919]\n",
      " [0.41756818]\n",
      " [0.41673869]\n",
      " [0.41439262]\n",
      " [0.41113782]\n",
      " [0.40797353]\n",
      " [0.28283611]\n",
      " [0.46545264]] | y: 0.2758620689655173 | Predicción actual: [[0.46328846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025414587929844856, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41756818]\n",
      " [0.41673869]\n",
      " [0.41439262]\n",
      " [0.41113782]\n",
      " [0.40797353]\n",
      " [0.28283611]\n",
      " [0.46545264]\n",
      " [0.46328846]] | y: 0.2746997287872917 | Predicción actual: [[0.45995384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05586668848991394, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41673869]\n",
      " [0.41439262]\n",
      " [0.41113782]\n",
      " [0.40797353]\n",
      " [0.28283611]\n",
      " [0.46545264]\n",
      " [0.46328846]\n",
      " [0.45995384]] | y: 0.275474622239442 | Predicción actual: [[0.45631754]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021893169730901718, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41439262]\n",
      " [0.41113782]\n",
      " [0.40797353]\n",
      " [0.28283611]\n",
      " [0.46545264]\n",
      " [0.46328846]\n",
      " [0.45995384]\n",
      " [0.45631754]] | y: 0.3347539713289423 | Predicción actual: [[0.45343578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010181686840951443, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41113782]\n",
      " [0.40797353]\n",
      " [0.28283611]\n",
      " [0.46545264]\n",
      " [0.46328846]\n",
      " [0.45995384]\n",
      " [0.45631754]\n",
      " [0.45343578]] | y: 0.35567609453700116 | Predicción actual: [[0.45229894]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008316036313772202, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40797353]\n",
      " [0.28283611]\n",
      " [0.46545264]\n",
      " [0.46328846]\n",
      " [0.45995384]\n",
      " [0.45631754]\n",
      " [0.45343578]\n",
      " [0.45229894]] | y: 0.3366912049593181 | Predicción actual: [[0.45364246]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011796735227108002, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.46545264]\n",
      " [0.46328846]\n",
      " [0.45995384]\n",
      " [0.45631754]\n",
      " [0.45343578]\n",
      " [0.45229894]\n",
      " [0.45364246]] | y: 0.3335916311507167 | Predicción actual: [[0.45781833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007265035528689623, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46545264]\n",
      " [0.46328846]\n",
      " [0.45995384]\n",
      " [0.45631754]\n",
      " [0.45343578]\n",
      " [0.45229894]\n",
      " [0.45364246]\n",
      " [0.45781833]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011979611590504646, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46328846]\n",
      " [0.45995384]\n",
      " [0.45631754]\n",
      " [0.45343578]\n",
      " [0.45229894]\n",
      " [0.45364246]\n",
      " [0.45781833]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.4933826]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007125025149434805, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45995384]\n",
      " [0.45631754]\n",
      " [0.45343578]\n",
      " [0.45229894]\n",
      " [0.45364246]\n",
      " [0.45781833]\n",
      " [0.3847346 ]\n",
      " [0.4933826 ]] | y: 0.5962805114296785 | Predicción actual: [[0.49022496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013390995562076569, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45631754]\n",
      " [0.45343578]\n",
      " [0.45229894]\n",
      " [0.45364246]\n",
      " [0.45781833]\n",
      " [0.3847346 ]\n",
      " [0.4933826 ]\n",
      " [0.49022496]] | y: 0.574583494769469 | Predicción actual: [[0.48768967]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038636673707515, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45343578]\n",
      " [0.45229894]\n",
      " [0.45364246]\n",
      " [0.45781833]\n",
      " [0.3847346 ]\n",
      " [0.4933826 ]\n",
      " [0.49022496]\n",
      " [0.48768967]] | y: 0.6063541263076326 | Predicción actual: [[0.48630446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00495206518098712, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45229894]\n",
      " [0.45364246]\n",
      " [0.45781833]\n",
      " [0.3847346 ]\n",
      " [0.4933826 ]\n",
      " [0.49022496]\n",
      " [0.48768967]\n",
      " [0.48630446]] | y: 0.5846571096474236 | Predicción actual: [[0.48638064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017183592543005943, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45364246]\n",
      " [0.45781833]\n",
      " [0.3847346 ]\n",
      " [0.4933826 ]\n",
      " [0.49022496]\n",
      " [0.48768967]\n",
      " [0.48630446]\n",
      " [0.48638064]] | y: 0.5687717938783416 | Predicción actual: [[0.48791757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008530323393642902, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45781833]\n",
      " [0.3847346 ]\n",
      " [0.4933826 ]\n",
      " [0.49022496]\n",
      " [0.48768967]\n",
      " [0.48630446]\n",
      " [0.48638064]\n",
      " [0.48791757]] | y: 0.6427741185586981 | Predicción actual: [[0.49054077]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021696386858820915, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.4933826 ]\n",
      " [0.49022496]\n",
      " [0.48768967]\n",
      " [0.48630446]\n",
      " [0.48638064]\n",
      " [0.48791757]\n",
      " [0.49054077]] | y: 0.6617590081363811 | Predicción actual: [[0.4936902]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05830872803926468, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4933826 ]\n",
      " [0.49022496]\n",
      " [0.48768967]\n",
      " [0.48630446]\n",
      " [0.48638064]\n",
      " [0.48791757]\n",
      " [0.49054077]\n",
      " [0.49369019]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10566199570894241, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49022496]\n",
      " [0.48768967]\n",
      " [0.48630446]\n",
      " [0.48638064]\n",
      " [0.48791757]\n",
      " [0.49054077]\n",
      " [0.49369019]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5177869]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0788361132144928, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48768967]\n",
      " [0.48630446]\n",
      " [0.48638064]\n",
      " [0.48791757]\n",
      " [0.49054077]\n",
      " [0.49369019]\n",
      " [0.67299496]\n",
      " [0.51778692]] | y: 0.703990701278574 | Predicción actual: [[0.5205852]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07271792739629745, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48630446]\n",
      " [0.48638064]\n",
      " [0.48791757]\n",
      " [0.49054077]\n",
      " [0.49369019]\n",
      " [0.67299496]\n",
      " [0.51778692]\n",
      " [0.52058518]] | y: 0.7272375048430839 | Predicción actual: [[0.52625865]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04922410473227501, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48638064]\n",
      " [0.48791757]\n",
      " [0.49054077]\n",
      " [0.49369019]\n",
      " [0.67299496]\n",
      " [0.51778692]\n",
      " [0.52058518]\n",
      " [0.52625865]] | y: 0.722588144130182 | Predicción actual: [[0.5347337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07381732761859894, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48791757]\n",
      " [0.49054077]\n",
      " [0.49369019]\n",
      " [0.67299496]\n",
      " [0.51778692]\n",
      " [0.52058518]\n",
      " [0.52625865]\n",
      " [0.53473371]] | y: 0.771793878341728 | Predicción actual: [[0.5456699]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044536229223012924, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49054077]\n",
      " [0.49369019]\n",
      " [0.67299496]\n",
      " [0.51778692]\n",
      " [0.52058518]\n",
      " [0.52625865]\n",
      " [0.53473371]\n",
      " [0.54566991]] | y: 0.7245253777605578 | Predicción actual: [[0.5585781]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010704110376536846, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49369019]\n",
      " [0.67299496]\n",
      " [0.51778692]\n",
      " [0.52058518]\n",
      " [0.52625865]\n",
      " [0.53473371]\n",
      " [0.54566991]\n",
      " [0.55857807]] | y: 0.6710577295621851 | Predicción actual: [[0.572927]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003010489046573639, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.51778692]\n",
      " [0.52058518]\n",
      " [0.52625865]\n",
      " [0.53473371]\n",
      " [0.54566991]\n",
      " [0.55857807]\n",
      " [0.572927  ]] | y: 0.6737698566447115 | Predicción actual: [[0.58837265]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014204091392457485, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51778692]\n",
      " [0.52058518]\n",
      " [0.52625865]\n",
      " [0.53473371]\n",
      " [0.54566991]\n",
      " [0.55857807]\n",
      " [0.572927  ]\n",
      " [0.58837265]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003567102598026395, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52058518]\n",
      " [0.52625865]\n",
      " [0.53473371]\n",
      " [0.54566991]\n",
      " [0.55857807]\n",
      " [0.572927  ]\n",
      " [0.58837265]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.56439406]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03749596327543259, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52625865]\n",
      " [0.53473371]\n",
      " [0.54566991]\n",
      " [0.55857807]\n",
      " [0.572927  ]\n",
      " [0.58837265]\n",
      " [0.71445176]\n",
      " [0.56439406]] | y: 0.722588144130182 | Predicción actual: [[0.5750859]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030280896462500095, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53473371]\n",
      " [0.54566991]\n",
      " [0.55857807]\n",
      " [0.572927  ]\n",
      " [0.58837265]\n",
      " [0.71445176]\n",
      " [0.56439406]\n",
      " [0.57508588]] | y: 0.6993413405656723 | Predicción actual: [[0.58773166]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014713772572577, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54566991]\n",
      " [0.55857807]\n",
      " [0.572927  ]\n",
      " [0.58837265]\n",
      " [0.71445176]\n",
      " [0.56439406]\n",
      " [0.57508588]\n",
      " [0.58773166]] | y: 0.7373111197210385 | Predicción actual: [[0.6013535]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002965650288388133, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55857807]\n",
      " [0.572927  ]\n",
      " [0.58837265]\n",
      " [0.71445176]\n",
      " [0.56439406]\n",
      " [0.57508588]\n",
      " [0.58773166]\n",
      " [0.60135353]] | y: 0.7214258039519565 | Predicción actual: [[0.61473083]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022330209612846375, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.572927  ]\n",
      " [0.58837265]\n",
      " [0.71445176]\n",
      " [0.56439406]\n",
      " [0.57508588]\n",
      " [0.58773166]\n",
      " [0.60135353]\n",
      " [0.61473083]] | y: 0.7187136768694304 | Predicción actual: [[0.6268073]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04428761824965477, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58837265]\n",
      " [0.71445176]\n",
      " [0.56439406]\n",
      " [0.57508588]\n",
      " [0.58773166]\n",
      " [0.60135353]\n",
      " [0.61473083]\n",
      " [0.62680727]] | y: 0.6741573033707864 | Predicción actual: [[0.6366273]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012445346219465137, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.56439406]\n",
      " [0.57508588]\n",
      " [0.58773166]\n",
      " [0.60135353]\n",
      " [0.61473083]\n",
      " [0.62680727]\n",
      " [0.63662732]] | y: 0.698566447113522 | Predicción actual: [[0.6432178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03221316263079643, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56439406]\n",
      " [0.57508588]\n",
      " [0.58773166]\n",
      " [0.60135353]\n",
      " [0.61473083]\n",
      " [0.62680727]\n",
      " [0.63662732]\n",
      " [0.6432178 ]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004624148365110159, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57508588]\n",
      " [0.58773166]\n",
      " [0.60135353]\n",
      " [0.61473083]\n",
      " [0.62680727]\n",
      " [0.63662732]\n",
      " [0.6432178 ]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6268226]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017215946689248085, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58773166]\n",
      " [0.60135353]\n",
      " [0.61473083]\n",
      " [0.62680727]\n",
      " [0.63662732]\n",
      " [0.6432178 ]\n",
      " [0.72103836]\n",
      " [0.62682259]] | y: 0.7562960092987214 | Predicción actual: [[0.6395237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024671465158462524, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60135353]\n",
      " [0.61473083]\n",
      " [0.62680727]\n",
      " [0.63662732]\n",
      " [0.6432178 ]\n",
      " [0.72103836]\n",
      " [0.62682259]\n",
      " [0.63952368]] | y: 0.8275862068965516 | Predicción actual: [[0.6521039]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018209872767329216, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61473083]\n",
      " [0.62680727]\n",
      " [0.63662732]\n",
      " [0.6432178 ]\n",
      " [0.72103836]\n",
      " [0.62682259]\n",
      " [0.63952368]\n",
      " [0.6521039 ]] | y: 0.8388221619527314 | Predicción actual: [[0.6637457]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0913114845752716, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62680727]\n",
      " [0.63662732]\n",
      " [0.6432178 ]\n",
      " [0.72103836]\n",
      " [0.62682259]\n",
      " [0.63952368]\n",
      " [0.6521039 ]\n",
      " [0.6637457 ]] | y: 0.7942657884540876 | Predicción actual: [[0.674048]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027850469574332237, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63662732]\n",
      " [0.6432178 ]\n",
      " [0.72103836]\n",
      " [0.62682259]\n",
      " [0.63952368]\n",
      " [0.6521039 ]\n",
      " [0.6637457 ]\n",
      " [0.67404801]] | y: 0.7838047268500579 | Predicción actual: [[0.6827355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009628090774640441, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6432178 ]\n",
      " [0.72103836]\n",
      " [0.62682259]\n",
      " [0.63952368]\n",
      " [0.6521039 ]\n",
      " [0.6637457 ]\n",
      " [0.67404801]\n",
      " [0.6827355 ]] | y: 0.7679194110809764 | Predicción actual: [[0.6899187]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018230469897389412, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62682259]\n",
      " [0.63952368]\n",
      " [0.6521039 ]\n",
      " [0.6637457 ]\n",
      " [0.67404801]\n",
      " [0.6827355 ]\n",
      " [0.6899187 ]] | y: 0.7845796203022084 | Predicción actual: [[0.6964503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014557281974703074, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62682259]\n",
      " [0.63952368]\n",
      " [0.6521039 ]\n",
      " [0.6637457 ]\n",
      " [0.67404801]\n",
      " [0.6827355 ]\n",
      " [0.6899187 ]\n",
      " [0.69645029]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03523562103509903, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63952368]\n",
      " [0.6521039 ]\n",
      " [0.6637457 ]\n",
      " [0.67404801]\n",
      " [0.6827355 ]\n",
      " [0.6899187 ]\n",
      " [0.69645029]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.69411606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10399659723043442, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6521039 ]\n",
      " [0.6637457 ]\n",
      " [0.67404801]\n",
      " [0.6827355 ]\n",
      " [0.6899187 ]\n",
      " [0.69645029]\n",
      " [0.87872917]\n",
      " [0.69411606]] | y: 0.8488957768306855 | Predicción actual: [[0.70803696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013247727416455746, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6637457 ]\n",
      " [0.67404801]\n",
      " [0.6827355 ]\n",
      " [0.6899187 ]\n",
      " [0.69645029]\n",
      " [0.87872917]\n",
      " [0.69411606]\n",
      " [0.70803696]] | y: 0.8182874854707476 | Predicción actual: [[0.72258675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014604325406253338, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67404801]\n",
      " [0.6827355 ]\n",
      " [0.6899187 ]\n",
      " [0.69645029]\n",
      " [0.87872917]\n",
      " [0.69411606]\n",
      " [0.70803696]\n",
      " [0.72258675]] | y: 0.8268113134444013 | Predicción actual: [[0.7375986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00013375542766880244, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6827355 ]\n",
      " [0.6899187 ]\n",
      " [0.69645029]\n",
      " [0.87872917]\n",
      " [0.69411606]\n",
      " [0.70803696]\n",
      " [0.72258675]\n",
      " [0.7375986 ]] | y: 0.7853545137543589 | Predicción actual: [[0.7527628]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024971766397356987, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6899187 ]\n",
      " [0.69645029]\n",
      " [0.87872917]\n",
      " [0.69411606]\n",
      " [0.70803696]\n",
      " [0.72258675]\n",
      " [0.7375986 ]\n",
      " [0.75276279]] | y: 0.7892289810151103 | Predicción actual: [[0.76816505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00036636716686189175, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69645029]\n",
      " [0.87872917]\n",
      " [0.69411606]\n",
      " [0.70803696]\n",
      " [0.72258675]\n",
      " [0.7375986 ]\n",
      " [0.75276279]\n",
      " [0.76816505]] | y: 0.8341728012398295 | Predicción actual: [[0.78382844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00431186193600297, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.69411606]\n",
      " [0.70803696]\n",
      " [0.72258675]\n",
      " [0.7375986 ]\n",
      " [0.75276279]\n",
      " [0.76816505]\n",
      " [0.78382844]] | y: 0.8124757845796202 | Predicción actual: [[0.7995501]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009260948863811791, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69411606]\n",
      " [0.70803696]\n",
      " [0.72258675]\n",
      " [0.7375986 ]\n",
      " [0.75276279]\n",
      " [0.76816505]\n",
      " [0.78382844]\n",
      " [0.79955012]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024062201380729675, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70803696]\n",
      " [0.72258675]\n",
      " [0.7375986 ]\n",
      " [0.75276279]\n",
      " [0.76816505]\n",
      " [0.78382844]\n",
      " [0.79955012]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.77599293]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010941836051642895, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72258675]\n",
      " [0.7375986 ]\n",
      " [0.75276279]\n",
      " [0.76816505]\n",
      " [0.78382844]\n",
      " [0.79955012]\n",
      " [0.80123983]\n",
      " [0.77599293]] | y: 0.793490895001937 | Predicción actual: [[0.7911595]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008460158132947981, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7375986 ]\n",
      " [0.75276279]\n",
      " [0.76816505]\n",
      " [0.78382844]\n",
      " [0.79955012]\n",
      " [0.80123983]\n",
      " [0.77599293]\n",
      " [0.79115951]] | y: 0.760170476559473 | Predicción actual: [[0.8054541]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018444699235260487, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75276279]\n",
      " [0.76816505]\n",
      " [0.78382844]\n",
      " [0.79955012]\n",
      " [0.80123983]\n",
      " [0.77599293]\n",
      " [0.79115951]\n",
      " [0.80545408]] | y: 0.7353738860906625 | Predicción actual: [[0.8183163]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00034111409331671894, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76816505]\n",
      " [0.78382844]\n",
      " [0.79955012]\n",
      " [0.80123983]\n",
      " [0.77599293]\n",
      " [0.79115951]\n",
      " [0.80545408]\n",
      " [0.81831628]] | y: 0.7101898488957767 | Predicción actual: [[0.8290689]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036710113286972046, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78382844]\n",
      " [0.79955012]\n",
      " [0.80123983]\n",
      " [0.77599293]\n",
      " [0.79115951]\n",
      " [0.80545408]\n",
      " [0.81831628]\n",
      " [0.8290689 ]] | y: 0.7121270825261525 | Predicción actual: [[0.8368382]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012203870341181755, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79955012]\n",
      " [0.80123983]\n",
      " [0.77599293]\n",
      " [0.79115951]\n",
      " [0.80545408]\n",
      " [0.81831628]\n",
      " [0.8290689 ]\n",
      " [0.83683819]] | y: 0.7396358000774894 | Predicción actual: [[0.84139943]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02733650989830494, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.77599293]\n",
      " [0.79115951]\n",
      " [0.80545408]\n",
      " [0.81831628]\n",
      " [0.8290689 ]\n",
      " [0.83683819]\n",
      " [0.84139943]] | y: 0.7361487795428128 | Predicción actual: [[0.8423799]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015322037041187286, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77599293]\n",
      " [0.79115951]\n",
      " [0.80545408]\n",
      " [0.81831628]\n",
      " [0.8290689 ]\n",
      " [0.83683819]\n",
      " [0.84139943]\n",
      " [0.84237993]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036820517852902412, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79115951]\n",
      " [0.80545408]\n",
      " [0.81831628]\n",
      " [0.8290689 ]\n",
      " [0.83683819]\n",
      " [0.84139943]\n",
      " [0.84237993]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8547353]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0488012321293354, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80545408]\n",
      " [0.81831628]\n",
      " [0.8290689 ]\n",
      " [0.83683819]\n",
      " [0.84139943]\n",
      " [0.84237993]\n",
      " [0.66757071]\n",
      " [0.85473531]] | y: 0.696629213483146 | Predicción actual: [[0.8614409]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003127800300717354, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81831628]\n",
      " [0.8290689 ]\n",
      " [0.83683819]\n",
      " [0.84139943]\n",
      " [0.84237993]\n",
      " [0.66757071]\n",
      " [0.85473531]\n",
      " [0.8614409 ]] | y: 0.6559473072452537 | Predicción actual: [[0.8644903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011821646243333817, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8290689 ]\n",
      " [0.83683819]\n",
      " [0.84139943]\n",
      " [0.84237993]\n",
      " [0.66757071]\n",
      " [0.85473531]\n",
      " [0.8614409 ]\n",
      " [0.86449027]] | y: 0.6788066640836885 | Predicción actual: [[0.8637373]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07221987098455429, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83683819]\n",
      " [0.84139943]\n",
      " [0.84237993]\n",
      " [0.66757071]\n",
      " [0.85473531]\n",
      " [0.8614409 ]\n",
      " [0.86449027]\n",
      " [0.86373729]] | y: 0.6760945370011622 | Predicción actual: [[0.8594777]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009581475518643856, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84139943]\n",
      " [0.84237993]\n",
      " [0.66757071]\n",
      " [0.85473531]\n",
      " [0.8614409 ]\n",
      " [0.86449027]\n",
      " [0.86373729]\n",
      " [0.8594777 ]] | y: 0.7295621851995349 | Predicción actual: [[0.85336727]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00457288883626461, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84237993]\n",
      " [0.66757071]\n",
      " [0.85473531]\n",
      " [0.8614409 ]\n",
      " [0.86449027]\n",
      " [0.86373729]\n",
      " [0.8594777 ]\n",
      " [0.85336727]] | y: 0.7012785741960481 | Predicción actual: [[0.846867]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01036448311060667, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.85473531]\n",
      " [0.8614409 ]\n",
      " [0.86449027]\n",
      " [0.86373729]\n",
      " [0.8594777 ]\n",
      " [0.85336727]\n",
      " [0.84686702]] | y: 0.767531964354901 | Predicción actual: [[0.8414666]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0025734954979270697, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85473531]\n",
      " [0.8614409 ]\n",
      " [0.86449027]\n",
      " [0.86373729]\n",
      " [0.8594777 ]\n",
      " [0.85336727]\n",
      " [0.84686702]\n",
      " [0.84146661]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.10216102749109268, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8614409 ]\n",
      " [0.86449027]\n",
      " [0.86373729]\n",
      " [0.8594777 ]\n",
      " [0.85336727]\n",
      " [0.84686702]\n",
      " [0.84146661]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8910716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013406208716332912, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86449027]\n",
      " [0.86373729]\n",
      " [0.8594777 ]\n",
      " [0.85336727]\n",
      " [0.84686702]\n",
      " [0.84146661]\n",
      " [0.75513367]\n",
      " [0.89107162]] | y: 0.7520340953118947 | Predicción actual: [[0.8861701]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05399457737803459, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86373729]\n",
      " [0.8594777 ]\n",
      " [0.85336727]\n",
      " [0.84686702]\n",
      " [0.84146661]\n",
      " [0.75513367]\n",
      " [0.89107162]\n",
      " [0.88617009]] | y: 0.7098024021697016 | Predicción actual: [[0.87895787]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025439471006393433, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8594777 ]\n",
      " [0.85336727]\n",
      " [0.84686702]\n",
      " [0.84146661]\n",
      " [0.75513367]\n",
      " [0.89107162]\n",
      " [0.88617009]\n",
      " [0.87895787]] | y: 0.6904300658659435 | Predicción actual: [[0.87121063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005162131506949663, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85336727]\n",
      " [0.84686702]\n",
      " [0.84146661]\n",
      " [0.75513367]\n",
      " [0.89107162]\n",
      " [0.88617009]\n",
      " [0.87895787]\n",
      " [0.87121063]] | y: 0.7543587756683454 | Predicción actual: [[0.86477965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03815412148833275, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84686702]\n",
      " [0.84146661]\n",
      " [0.75513367]\n",
      " [0.89107162]\n",
      " [0.88617009]\n",
      " [0.87895787]\n",
      " [0.87121063]\n",
      " [0.86477965]] | y: 0.7222006974041069 | Predicción actual: [[0.8605625]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008654055185616016, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84146661]\n",
      " [0.75513367]\n",
      " [0.89107162]\n",
      " [0.88617009]\n",
      " [0.87895787]\n",
      " [0.87121063]\n",
      " [0.86477965]\n",
      " [0.8605625 ]] | y: 0.8485083301046106 | Predicción actual: [[0.8594808]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006585599039681256, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.89107162]\n",
      " [0.88617009]\n",
      " [0.87895787]\n",
      " [0.87121063]\n",
      " [0.86477965]\n",
      " [0.8605625 ]\n",
      " [0.8594808 ]] | y: 0.9054629988376597 | Predicción actual: [[0.8617676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008419040590524673, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89107162]\n",
      " [0.88617009]\n",
      " [0.87895787]\n",
      " [0.87121063]\n",
      " [0.86477965]\n",
      " [0.8605625 ]\n",
      " [0.8594808 ]\n",
      " [0.86176759]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01694599539041519, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88617009]\n",
      " [0.87895787]\n",
      " [0.87121063]\n",
      " [0.86477965]\n",
      " [0.8605625 ]\n",
      " [0.8594808 ]\n",
      " [0.86176759]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8853684]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00026456298655830324, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87895787]\n",
      " [0.87121063]\n",
      " [0.86477965]\n",
      " [0.8605625 ]\n",
      " [0.8594808 ]\n",
      " [0.86176759]\n",
      " [0.8822162 ]\n",
      " [0.88536841]] | y: 0.889577683068578 | Predicción actual: [[0.87880313]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003890813095495105, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87121063]\n",
      " [0.86477965]\n",
      " [0.8605625 ]\n",
      " [0.8594808 ]\n",
      " [0.86176759]\n",
      " [0.8822162 ]\n",
      " [0.88536841]\n",
      " [0.87880313]] | y: 0.8748547074777218 | Predicción actual: [[0.8741355]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0074673243798315525, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86477965]\n",
      " [0.8605625 ]\n",
      " [0.8594808 ]\n",
      " [0.86176759]\n",
      " [0.8822162 ]\n",
      " [0.88536841]\n",
      " [0.87880313]\n",
      " [0.87413549]] | y: 0.9132119333591631 | Predicción actual: [[0.8721084]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018753212643787265, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8605625 ]\n",
      " [0.8594808 ]\n",
      " [0.86176759]\n",
      " [0.8822162 ]\n",
      " [0.88536841]\n",
      " [0.87880313]\n",
      " [0.87413549]\n",
      " [0.8721084 ]] | y: 1.0 | Predicción actual: [[0.87262034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08133842796087265, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8594808 ]\n",
      " [0.86176759]\n",
      " [0.8822162 ]\n",
      " [0.88536841]\n",
      " [0.87880313]\n",
      " [0.87413549]\n",
      " [0.8721084 ]\n",
      " [0.87262034]] | y: 0.9705540488182873 | Predicción actual: [[0.8756262]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002565659233368933, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86176759]\n",
      " [0.8822162 ]\n",
      " [0.88536841]\n",
      " [0.87880313]\n",
      " [0.87413549]\n",
      " [0.8721084 ]\n",
      " [0.87262034]\n",
      " [0.87562621]] | y: 0.8888027896164277 | Predicción actual: [[0.8796874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00923781655728817, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.88536841]\n",
      " [0.87880313]\n",
      " [0.87413549]\n",
      " [0.8721084 ]\n",
      " [0.87262034]\n",
      " [0.87562621]\n",
      " [0.87968743]] | y: 0.877954281286323 | Predicción actual: [[0.8839279]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01730073243379593, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88536841]\n",
      " [0.87880313]\n",
      " [0.87413549]\n",
      " [0.8721084 ]\n",
      " [0.87262034]\n",
      " [0.87562621]\n",
      " [0.87968743]\n",
      " [0.88392788]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024078531190752983, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87880313]\n",
      " [0.87413549]\n",
      " [0.8721084 ]\n",
      " [0.87262034]\n",
      " [0.87562621]\n",
      " [0.87968743]\n",
      " [0.88392788]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.87851185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007588767330162227, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87413549]\n",
      " [0.8721084 ]\n",
      " [0.87262034]\n",
      " [0.87562621]\n",
      " [0.87968743]\n",
      " [0.88392788]\n",
      " [0.84889578]\n",
      " [0.87851185]] | y: 0.8550949244478885 | Predicción actual: [[0.8765911]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00029595254454761744, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8721084 ]\n",
      " [0.87262034]\n",
      " [0.87562621]\n",
      " [0.87968743]\n",
      " [0.88392788]\n",
      " [0.84889578]\n",
      " [0.87851185]\n",
      " [0.87659109]] | y: 0.8752421542037967 | Predicción actual: [[0.8759671]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024421359412372112, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87262034]\n",
      " [0.87562621]\n",
      " [0.87968743]\n",
      " [0.88392788]\n",
      " [0.84889578]\n",
      " [0.87851185]\n",
      " [0.87659109]\n",
      " [0.87596709]] | y: 0.857032158078264 | Predicción actual: [[0.8758677]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007968909107148647, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87562621]\n",
      " [0.87968743]\n",
      " [0.88392788]\n",
      " [0.84889578]\n",
      " [0.87851185]\n",
      " [0.87659109]\n",
      " [0.87596709]\n",
      " [0.87586772]] | y: 0.8500581170089112 | Predicción actual: [[0.8755125]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04620269313454628, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87968743]\n",
      " [0.88392788]\n",
      " [0.84889578]\n",
      " [0.87851185]\n",
      " [0.87659109]\n",
      " [0.87596709]\n",
      " [0.87586772]\n",
      " [0.87551248]] | y: 0.8426966292134832 | Predicción actual: [[0.87380207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002648946538101882, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88392788]\n",
      " [0.84889578]\n",
      " [0.87851185]\n",
      " [0.87659109]\n",
      " [0.87596709]\n",
      " [0.87586772]\n",
      " [0.87551248]\n",
      " [0.87380207]] | y: 0.8229368461836497 | Predicción actual: [[0.8709495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010983261745423079, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.87851185]\n",
      " [0.87659109]\n",
      " [0.87596709]\n",
      " [0.87586772]\n",
      " [0.87551248]\n",
      " [0.87380207]\n",
      " [0.87094951]] | y: 0.7745060054242543 | Predicción actual: [[0.86674047]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011507799848914146, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87851185]\n",
      " [0.87659109]\n",
      " [0.87596709]\n",
      " [0.87586772]\n",
      " [0.87551248]\n",
      " [0.87380207]\n",
      " [0.87094951]\n",
      " [0.86674047]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012456998229026794, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87659109]\n",
      " [0.87596709]\n",
      " [0.87586772]\n",
      " [0.87551248]\n",
      " [0.87380207]\n",
      " [0.87094951]\n",
      " [0.86674047]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.87010664]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00017563815345056355, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87596709]\n",
      " [0.87586772]\n",
      " [0.87551248]\n",
      " [0.87380207]\n",
      " [0.87094951]\n",
      " [0.86674047]\n",
      " [0.78419217]\n",
      " [0.87010664]] | y: 0.854320030995738 | Predicción actual: [[0.86700326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021745648700743914, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87586772]\n",
      " [0.87551248]\n",
      " [0.87380207]\n",
      " [0.87094951]\n",
      " [0.86674047]\n",
      " [0.78419217]\n",
      " [0.87010664]\n",
      " [0.86700326]] | y: 0.8368849283223556 | Predicción actual: [[0.86306745]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029382213950157166, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87551248]\n",
      " [0.87380207]\n",
      " [0.87094951]\n",
      " [0.86674047]\n",
      " [0.78419217]\n",
      " [0.87010664]\n",
      " [0.86700326]\n",
      " [0.86306745]] | y: 0.8299108872530028 | Predicción actual: [[0.85833055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015853773802518845, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87380207]\n",
      " [0.87094951]\n",
      " [0.86674047]\n",
      " [0.78419217]\n",
      " [0.87010664]\n",
      " [0.86700326]\n",
      " [0.86306745]\n",
      " [0.85833055]] | y: 0.887253002712127 | Predicción actual: [[0.85240716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023518686648458242, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87094951]\n",
      " [0.86674047]\n",
      " [0.78419217]\n",
      " [0.87010664]\n",
      " [0.86700326]\n",
      " [0.86306745]\n",
      " [0.85833055]\n",
      " [0.85240716]] | y: 0.8597442851607902 | Predicción actual: [[0.8462533]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003149686148390174, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86674047]\n",
      " [0.78419217]\n",
      " [0.87010664]\n",
      " [0.86700326]\n",
      " [0.86306745]\n",
      " [0.85833055]\n",
      " [0.85240716]\n",
      " [0.84625328]] | y: 0.8395970554048819 | Predicción actual: [[0.84041846]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02685432694852352, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.87010664]\n",
      " [0.86700326]\n",
      " [0.86306745]\n",
      " [0.85833055]\n",
      " [0.85240716]\n",
      " [0.84625328]\n",
      " [0.84041846]] | y: 0.7838047268500579 | Predicción actual: [[0.8350329]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04825255274772644, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87010664]\n",
      " [0.86700326]\n",
      " [0.86306745]\n",
      " [0.85833055]\n",
      " [0.85240716]\n",
      " [0.84625328]\n",
      " [0.84041846]\n",
      " [0.83503288]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030212386045604944, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86700326]\n",
      " [0.86306745]\n",
      " [0.85833055]\n",
      " [0.85240716]\n",
      " [0.84625328]\n",
      " [0.84041846]\n",
      " [0.83503288]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8482503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003916904330253601, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86306745]\n",
      " [0.85833055]\n",
      " [0.85240716]\n",
      " [0.84625328]\n",
      " [0.84041846]\n",
      " [0.83503288]\n",
      " [0.81828749]\n",
      " [0.84825033]] | y: 0.7605579232855482 | Predicción actual: [[0.8423834]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002206930803367868, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85833055]\n",
      " [0.85240716]\n",
      " [0.84625328]\n",
      " [0.84041846]\n",
      " [0.83503288]\n",
      " [0.81828749]\n",
      " [0.84825033]\n",
      " [0.84238338]] | y: 0.7915536613715615 | Predicción actual: [[0.8364467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00028139702044427395, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85240716]\n",
      " [0.84625328]\n",
      " [0.84041846]\n",
      " [0.83503288]\n",
      " [0.81828749]\n",
      " [0.84825033]\n",
      " [0.84238338]\n",
      " [0.8364467 ]] | y: 0.7686943045331267 | Predicción actual: [[0.8309075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04122328385710716, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84625328]\n",
      " [0.84041846]\n",
      " [0.83503288]\n",
      " [0.81828749]\n",
      " [0.84825033]\n",
      " [0.84238338]\n",
      " [0.8364467 ]\n",
      " [0.83090752]] | y: 0.7686943045331267 | Predicción actual: [[0.82586324]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003841373836621642, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84041846]\n",
      " [0.83503288]\n",
      " [0.81828749]\n",
      " [0.84825033]\n",
      " [0.84238338]\n",
      " [0.8364467 ]\n",
      " [0.83090752]\n",
      " [0.82586324]] | y: 0.7989151491669895 | Predicción actual: [[0.82195044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020435485988855362, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83503288]\n",
      " [0.81828749]\n",
      " [0.84825033]\n",
      " [0.84238338]\n",
      " [0.8364467 ]\n",
      " [0.83090752]\n",
      " [0.82586324]\n",
      " [0.82195044]] | y: 0.7900038744672608 | Predicción actual: [[0.8190534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02488747239112854, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.84825033]\n",
      " [0.84238338]\n",
      " [0.8364467 ]\n",
      " [0.83090752]\n",
      " [0.82586324]\n",
      " [0.82195044]\n",
      " [0.81905341]] | y: 0.760170476559473 | Predicción actual: [[0.8171134]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019472964107990265, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84825033]\n",
      " [0.84238338]\n",
      " [0.8364467 ]\n",
      " [0.83090752]\n",
      " [0.82586324]\n",
      " [0.82195044]\n",
      " [0.81905341]\n",
      " [0.8171134 ]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009667191188782454, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84238338]\n",
      " [0.8364467 ]\n",
      " [0.83090752]\n",
      " [0.82586324]\n",
      " [0.82195044]\n",
      " [0.81905341]\n",
      " [0.8171134 ]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.81240964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05200283229351044, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8364467 ]\n",
      " [0.83090752]\n",
      " [0.82586324]\n",
      " [0.82195044]\n",
      " [0.81905341]\n",
      " [0.8171134 ]\n",
      " [0.68539326]\n",
      " [0.81240964]] | y: 0.6648585819449826 | Predicción actual: [[0.8042941]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035514697432518005, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83090752]\n",
      " [0.82586324]\n",
      " [0.82195044]\n",
      " [0.81905341]\n",
      " [0.8171134 ]\n",
      " [0.68539326]\n",
      " [0.81240964]\n",
      " [0.80429411]] | y: 0.7078651685393258 | Predicción actual: [[0.7953129]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00399252213537693, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82586324]\n",
      " [0.82195044]\n",
      " [0.81905341]\n",
      " [0.8171134 ]\n",
      " [0.68539326]\n",
      " [0.81240964]\n",
      " [0.80429411]\n",
      " [0.79531288]] | y: 0.6648585819449826 | Predicción actual: [[0.78579396]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.400813046842813e-05, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82195044]\n",
      " [0.81905341]\n",
      " [0.8171134 ]\n",
      " [0.68539326]\n",
      " [0.81240964]\n",
      " [0.80429411]\n",
      " [0.79531288]\n",
      " [0.78579396]] | y: 0.7113521890740022 | Predicción actual: [[0.7759339]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005815573967993259, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81905341]\n",
      " [0.8171134 ]\n",
      " [0.68539326]\n",
      " [0.81240964]\n",
      " [0.80429411]\n",
      " [0.79531288]\n",
      " [0.78579396]\n",
      " [0.77593392]] | y: 0.6772568771793879 | Predicción actual: [[0.76555294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038448176346719265, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8171134 ]\n",
      " [0.68539326]\n",
      " [0.81240964]\n",
      " [0.80429411]\n",
      " [0.79531288]\n",
      " [0.78579396]\n",
      " [0.77593392]\n",
      " [0.76555294]] | y: 0.7621077101898488 | Predicción actual: [[0.7546153]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010685901157557964, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.81240964]\n",
      " [0.80429411]\n",
      " [0.79531288]\n",
      " [0.78579396]\n",
      " [0.77593392]\n",
      " [0.76555294]\n",
      " [0.75461531]] | y: 0.8070515304145678 | Predicción actual: [[0.74291]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009602400241419673, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81240964]\n",
      " [0.80429411]\n",
      " [0.79531288]\n",
      " [0.78579396]\n",
      " [0.77593392]\n",
      " [0.76555294]\n",
      " [0.75461531]\n",
      " [0.74291003]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038691451773047447, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80429411]\n",
      " [0.79531288]\n",
      " [0.78579396]\n",
      " [0.77593392]\n",
      " [0.76555294]\n",
      " [0.75461531]\n",
      " [0.74291003]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7584835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0269605852663517, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79531288]\n",
      " [0.78579396]\n",
      " [0.77593392]\n",
      " [0.76555294]\n",
      " [0.75461531]\n",
      " [0.74291003]\n",
      " [0.81518791]\n",
      " [0.75848353]] | y: 0.9597055404881829 | Predicción actual: [[0.75051385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038023509085178375, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78579396]\n",
      " [0.77593392]\n",
      " [0.76555294]\n",
      " [0.75461531]\n",
      " [0.74291003]\n",
      " [0.81518791]\n",
      " [0.75848353]\n",
      " [0.75051385]] | y: 0.9643549012010848 | Predicción actual: [[0.7439343]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.054142460227012634, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77593392]\n",
      " [0.76555294]\n",
      " [0.75461531]\n",
      " [0.74291003]\n",
      " [0.81518791]\n",
      " [0.75848353]\n",
      " [0.75051385]\n",
      " [0.74393427]] | y: 0.8880278961642774 | Predicción actual: [[0.73913676]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024138703010976315, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76555294]\n",
      " [0.75461531]\n",
      " [0.74291003]\n",
      " [0.81518791]\n",
      " [0.75848353]\n",
      " [0.75051385]\n",
      " [0.74393427]\n",
      " [0.73913676]] | y: 0.8926772568771792 | Predicción actual: [[0.7361089]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028695423156023026, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75461531]\n",
      " [0.74291003]\n",
      " [0.81518791]\n",
      " [0.75848353]\n",
      " [0.75051385]\n",
      " [0.74393427]\n",
      " [0.73913676]\n",
      " [0.7361089 ]] | y: 0.8752421542037967 | Predicción actual: [[0.7352726]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08354809880256653, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74291003]\n",
      " [0.81518791]\n",
      " [0.75848353]\n",
      " [0.75051385]\n",
      " [0.74393427]\n",
      " [0.73913676]\n",
      " [0.7361089 ]\n",
      " [0.73527259]] | y: 0.8508330104610615 | Predicción actual: [[0.73694634]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06803625822067261, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.75848353]\n",
      " [0.75051385]\n",
      " [0.74393427]\n",
      " [0.73913676]\n",
      " [0.7361089 ]\n",
      " [0.73527259]\n",
      " [0.73694634]] | y: 0.8488957768306855 | Predicción actual: [[0.74137264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006665742490440607, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75848353]\n",
      " [0.75051385]\n",
      " [0.74393427]\n",
      " [0.73913676]\n",
      " [0.7361089 ]\n",
      " [0.73527259]\n",
      " [0.73694634]\n",
      " [0.74137264]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008355174213647842, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75051385]\n",
      " [0.74393427]\n",
      " [0.73913676]\n",
      " [0.7361089 ]\n",
      " [0.73527259]\n",
      " [0.73694634]\n",
      " [0.74137264]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7228005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08756960928440094, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74393427]\n",
      " [0.73913676]\n",
      " [0.7361089 ]\n",
      " [0.73527259]\n",
      " [0.73694634]\n",
      " [0.74137264]\n",
      " [0.96241767]\n",
      " [0.72280049]] | y: 0.9407206509104997 | Predicción actual: [[0.72437555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020305395126342773, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73913676]\n",
      " [0.7361089 ]\n",
      " [0.73527259]\n",
      " [0.73694634]\n",
      " [0.74137264]\n",
      " [0.96241767]\n",
      " [0.72280049]\n",
      " [0.72437555]] | y: 0.9724912824486633 | Predicción actual: [[0.7293533]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.12158864736557007, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7361089 ]\n",
      " [0.73527259]\n",
      " [0.73694634]\n",
      " [0.74137264]\n",
      " [0.96241767]\n",
      " [0.72280049]\n",
      " [0.72437555]\n",
      " [0.72935331]] | y: 0.9969004261913985 | Predicción actual: [[0.73742247]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026067670434713364, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73527259]\n",
      " [0.73694634]\n",
      " [0.74137264]\n",
      " [0.96241767]\n",
      " [0.72280049]\n",
      " [0.72437555]\n",
      " [0.72935331]\n",
      " [0.73742247]] | y: 0.951181712514529 | Predicción actual: [[0.74763256]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.18356111645698547, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73694634]\n",
      " [0.74137264]\n",
      " [0.96241767]\n",
      " [0.72280049]\n",
      " [0.72437555]\n",
      " [0.72935331]\n",
      " [0.73742247]\n",
      " [0.74763256]] | y: 0.8957768306857805 | Predicción actual: [[0.75911087]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 4.964421691511234e-07, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74137264]\n",
      " [0.96241767]\n",
      " [0.72280049]\n",
      " [0.72437555]\n",
      " [0.72935331]\n",
      " [0.73742247]\n",
      " [0.74763256]\n",
      " [0.75911087]] | y: 0.8814413018209997 | Predicción actual: [[0.77018946]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029530363157391548, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.72280049]\n",
      " [0.72437555]\n",
      " [0.72935331]\n",
      " [0.73742247]\n",
      " [0.74763256]\n",
      " [0.75911087]\n",
      " [0.77018946]] | y: 0.9170864006199149 | Predicción actual: [[0.7798663]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034151256550103426, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72280049]\n",
      " [0.72437555]\n",
      " [0.72935331]\n",
      " [0.73742247]\n",
      " [0.74763256]\n",
      " [0.75911087]\n",
      " [0.77018946]\n",
      " [0.77986628]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07733049988746643, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72437555]\n",
      " [0.72935331]\n",
      " [0.73742247]\n",
      " [0.74763256]\n",
      " [0.75911087]\n",
      " [0.77018946]\n",
      " [0.77986628]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7329934]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05914238467812538, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72935331]\n",
      " [0.73742247]\n",
      " [0.74763256]\n",
      " [0.75911087]\n",
      " [0.77018946]\n",
      " [0.77986628]\n",
      " [0.91979853]\n",
      " [0.73299342]] | y: 0.9682293684618366 | Predicción actual: [[0.7441012]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0400647297501564, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73742247]\n",
      " [0.74763256]\n",
      " [0.75911087]\n",
      " [0.77018946]\n",
      " [0.77986628]\n",
      " [0.91979853]\n",
      " [0.73299342]\n",
      " [0.74410123]] | y: 0.9577683068578069 | Predicción actual: [[0.7569371]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035995885729789734, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20197426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027311300858855247, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20197426]] | y: 0.10422316931421921 | Predicción actual: [[0.18647403]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003918811678886414, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20197426]\n",
      " [0.18647403]] | y: 0.15420379697791559 | Predicción actual: [[0.19079891]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031501175835728645, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20197426]\n",
      " [0.18647403]\n",
      " [0.19079891]] | y: 0.1557535838822161 | Predicción actual: [[0.20251359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004018140956759453, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20197426]\n",
      " [0.18647403]\n",
      " [0.19079891]\n",
      " [0.20251359]] | y: 0.12553273924835334 | Predicción actual: [[0.21533214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008334118872880936, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20197426]\n",
      " [0.18647403]\n",
      " [0.19079891]\n",
      " [0.20251359]\n",
      " [0.21533214]] | y: 0.1456799690042619 | Predicción actual: [[0.225398]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0043629794381558895, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20197426]\n",
      " [0.18647403]\n",
      " [0.19079891]\n",
      " [0.20251359]\n",
      " [0.21533214]\n",
      " [0.225398  ]] | y: 0.1464548624564122 | Predicción actual: [[0.24701154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011157085187733173, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20197426]\n",
      " [0.18647403]\n",
      " [0.19079891]\n",
      " [0.20251359]\n",
      " [0.21533214]\n",
      " [0.225398  ]\n",
      " [0.24701154]] | y: 0.1960480433940332 | Predicción actual: [[0.2735723]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003059208858758211, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20197426]\n",
      " [0.18647403]\n",
      " [0.19079891]\n",
      " [0.20251359]\n",
      " [0.21533214]\n",
      " [0.225398  ]\n",
      " [0.24701154]\n",
      " [0.2735723 ]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0021256294567137957, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18647403]\n",
      " [0.19079891]\n",
      " [0.20251359]\n",
      " [0.21533214]\n",
      " [0.225398  ]\n",
      " [0.24701154]\n",
      " [0.2735723 ]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.30786258]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009524078108370304, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19079891]\n",
      " [0.20251359]\n",
      " [0.21533214]\n",
      " [0.225398  ]\n",
      " [0.24701154]\n",
      " [0.2735723 ]\n",
      " [0.2305308 ]\n",
      " [0.30786258]] | y: 0.211933359163115 | Predicción actual: [[0.31539842]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010665329173207283, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20251359]\n",
      " [0.21533214]\n",
      " [0.225398  ]\n",
      " [0.24701154]\n",
      " [0.2735723 ]\n",
      " [0.2305308 ]\n",
      " [0.30786258]\n",
      " [0.31539842]] | y: 0.2072839984502131 | Predicción actual: [[0.32482186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00992012768983841, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21533214]\n",
      " [0.225398  ]\n",
      " [0.24701154]\n",
      " [0.2735723 ]\n",
      " [0.2305308 ]\n",
      " [0.30786258]\n",
      " [0.31539842]\n",
      " [0.32482186]] | y: 0.19294846958543205 | Predicción actual: [[0.33487833]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013561129570007324, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.225398  ]\n",
      " [0.24701154]\n",
      " [0.2735723 ]\n",
      " [0.2305308 ]\n",
      " [0.30786258]\n",
      " [0.31539842]\n",
      " [0.32482186]\n",
      " [0.33487833]] | y: 0.19682293684618352 | Predicción actual: [[0.3454814]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03525136411190033, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24701154]\n",
      " [0.2735723 ]\n",
      " [0.2305308 ]\n",
      " [0.30786258]\n",
      " [0.31539842]\n",
      " [0.32482186]\n",
      " [0.33487833]\n",
      " [0.3454814 ]] | y: 0.21425803951956607 | Predicción actual: [[0.3573448]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0073466976173222065, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2735723 ]\n",
      " [0.2305308 ]\n",
      " [0.30786258]\n",
      " [0.31539842]\n",
      " [0.32482186]\n",
      " [0.33487833]\n",
      " [0.3454814 ]\n",
      " [0.35734481]] | y: 0.18132506780317698 | Predicción actual: [[0.36787164]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022257128730416298, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.30786258]\n",
      " [0.31539842]\n",
      " [0.32482186]\n",
      " [0.33487833]\n",
      " [0.3454814 ]\n",
      " [0.35734481]\n",
      " [0.36787164]] | y: 0.17512592018597434 | Predicción actual: [[0.3755044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0371362641453743, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.30786258]\n",
      " [0.31539842]\n",
      " [0.32482186]\n",
      " [0.33487833]\n",
      " [0.3454814 ]\n",
      " [0.35734481]\n",
      " [0.36787164]\n",
      " [0.3755044 ]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08305732905864716, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31539842]\n",
      " [0.32482186]\n",
      " [0.33487833]\n",
      " [0.3454814 ]\n",
      " [0.35734481]\n",
      " [0.36787164]\n",
      " [0.3755044 ]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.402351]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03442080318927765, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32482186]\n",
      " [0.33487833]\n",
      " [0.3454814 ]\n",
      " [0.35734481]\n",
      " [0.36787164]\n",
      " [0.3755044 ]\n",
      " [0.14800465]\n",
      " [0.40235099]] | y: 0.19217357613328173 | Predicción actual: [[0.4066904]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.032446347177028656, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33487833]\n",
      " [0.3454814 ]\n",
      " [0.35734481]\n",
      " [0.36787164]\n",
      " [0.3755044 ]\n",
      " [0.14800465]\n",
      " [0.40235099]\n",
      " [0.40669039]] | y: 0.1859744285160791 | Predicción actual: [[0.40927717]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04812828078866005, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3454814 ]\n",
      " [0.35734481]\n",
      " [0.36787164]\n",
      " [0.3755044 ]\n",
      " [0.14800465]\n",
      " [0.40235099]\n",
      " [0.40669039]\n",
      " [0.40927717]] | y: 0.26695079426578844 | Predicción actual: [[0.41012087]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02868739701807499, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.35734481]\n",
      " [0.36787164]\n",
      " [0.3755044 ]\n",
      " [0.14800465]\n",
      " [0.40235099]\n",
      " [0.40669039]\n",
      " [0.40927717]\n",
      " [0.41012087]] | y: 0.2925222781867493 | Predicción actual: [[0.40941983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014186551561579108, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36787164]\n",
      " [0.3755044 ]\n",
      " [0.14800465]\n",
      " [0.40235099]\n",
      " [0.40669039]\n",
      " [0.40927717]\n",
      " [0.41012087]\n",
      " [0.40941983]] | y: 0.3177063153816349 | Predicción actual: [[0.40727353]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013985003344714642, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3755044 ]\n",
      " [0.14800465]\n",
      " [0.40235099]\n",
      " [0.40669039]\n",
      " [0.40927717]\n",
      " [0.41012087]\n",
      " [0.40941983]\n",
      " [0.40727353]] | y: 0.31266950794265785 | Predicción actual: [[0.40421835]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006900700740516186, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40235099]\n",
      " [0.40669039]\n",
      " [0.40927717]\n",
      " [0.41012087]\n",
      " [0.40941983]\n",
      " [0.40727353]\n",
      " [0.40421835]] | y: 0.2890352576520729 | Predicción actual: [[0.4011895]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015456381253898144, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40235099]\n",
      " [0.40669039]\n",
      " [0.40927717]\n",
      " [0.41012087]\n",
      " [0.40941983]\n",
      " [0.40727353]\n",
      " [0.40421835]\n",
      " [0.40118951]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018808206543326378, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40669039]\n",
      " [0.40927717]\n",
      " [0.41012087]\n",
      " [0.40941983]\n",
      " [0.40727353]\n",
      " [0.40421835]\n",
      " [0.40118951]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.45686108]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005962632596492767, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40927717]\n",
      " [0.41012087]\n",
      " [0.40941983]\n",
      " [0.40727353]\n",
      " [0.40421835]\n",
      " [0.40118951]\n",
      " [0.28283611]\n",
      " [0.45686108]] | y: 0.2758620689655173 | Predicción actual: [[0.45507592]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052086468786001205, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41012087]\n",
      " [0.40941983]\n",
      " [0.40727353]\n",
      " [0.40421835]\n",
      " [0.40118951]\n",
      " [0.28283611]\n",
      " [0.45686108]\n",
      " [0.45507592]] | y: 0.2746997287872917 | Predicción actual: [[0.45209968]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014807731844484806, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40941983]\n",
      " [0.40727353]\n",
      " [0.40421835]\n",
      " [0.40118951]\n",
      " [0.28283611]\n",
      " [0.45686108]\n",
      " [0.45507592]\n",
      " [0.45209968]] | y: 0.275474622239442 | Predicción actual: [[0.44891387]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03204195573925972, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40727353]\n",
      " [0.40421835]\n",
      " [0.40118951]\n",
      " [0.28283611]\n",
      " [0.45686108]\n",
      " [0.45507592]\n",
      " [0.45209968]\n",
      " [0.44891387]] | y: 0.3347539713289423 | Predicción actual: [[0.44642517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017518818378448486, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40421835]\n",
      " [0.40118951]\n",
      " [0.28283611]\n",
      " [0.45686108]\n",
      " [0.45507592]\n",
      " [0.45209968]\n",
      " [0.44891387]\n",
      " [0.44642517]] | y: 0.35567609453700116 | Predicción actual: [[0.4455824]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005185171030461788, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40118951]\n",
      " [0.28283611]\n",
      " [0.45686108]\n",
      " [0.45507592]\n",
      " [0.45209968]\n",
      " [0.44891387]\n",
      " [0.44642517]\n",
      " [0.44558239]] | y: 0.3366912049593181 | Predicción actual: [[0.44713715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003629593877121806, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.45686108]\n",
      " [0.45507592]\n",
      " [0.45209968]\n",
      " [0.44891387]\n",
      " [0.44642517]\n",
      " [0.44558239]\n",
      " [0.44713715]] | y: 0.3335916311507167 | Predicción actual: [[0.45146263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02365034632384777, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45686108]\n",
      " [0.45507592]\n",
      " [0.45209968]\n",
      " [0.44891387]\n",
      " [0.44642517]\n",
      " [0.44558239]\n",
      " [0.44713715]\n",
      " [0.45146263]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0023039348889142275, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45507592]\n",
      " [0.45209968]\n",
      " [0.44891387]\n",
      " [0.44642517]\n",
      " [0.44558239]\n",
      " [0.44713715]\n",
      " [0.45146263]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.48555005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005665137432515621, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45209968]\n",
      " [0.44891387]\n",
      " [0.44642517]\n",
      " [0.44558239]\n",
      " [0.44713715]\n",
      " [0.45146263]\n",
      " [0.3847346 ]\n",
      " [0.48555005]] | y: 0.5962805114296785 | Predicción actual: [[0.4828606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020522523671388626, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44891387]\n",
      " [0.44642517]\n",
      " [0.44558239]\n",
      " [0.44713715]\n",
      " [0.45146263]\n",
      " [0.3847346 ]\n",
      " [0.48555005]\n",
      " [0.48286059]] | y: 0.574583494769469 | Predicción actual: [[0.48080358]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07640481740236282, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44642517]\n",
      " [0.44558239]\n",
      " [0.44713715]\n",
      " [0.45146263]\n",
      " [0.3847346 ]\n",
      " [0.48555005]\n",
      " [0.48286059]\n",
      " [0.48080358]] | y: 0.6063541263076326 | Predicción actual: [[0.4799063]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001531817251816392, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44558239]\n",
      " [0.44713715]\n",
      " [0.45146263]\n",
      " [0.3847346 ]\n",
      " [0.48555005]\n",
      " [0.48286059]\n",
      " [0.48080358]\n",
      " [0.47990629]] | y: 0.5846571096474236 | Predicción actual: [[0.4803725]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03186260908842087, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44713715]\n",
      " [0.45146263]\n",
      " [0.3847346 ]\n",
      " [0.48555005]\n",
      " [0.48286059]\n",
      " [0.48080358]\n",
      " [0.47990629]\n",
      " [0.48037249]] | y: 0.5687717938783416 | Predicción actual: [[0.4822443]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00442353542894125, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45146263]\n",
      " [0.3847346 ]\n",
      " [0.48555005]\n",
      " [0.48286059]\n",
      " [0.48080358]\n",
      " [0.47990629]\n",
      " [0.48037249]\n",
      " [0.48224431]] | y: 0.6427741185586981 | Predicción actual: [[0.485122]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02317352592945099, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.48555005]\n",
      " [0.48286059]\n",
      " [0.48080358]\n",
      " [0.47990629]\n",
      " [0.48037249]\n",
      " [0.48224431]\n",
      " [0.485122  ]] | y: 0.6617590081363811 | Predicción actual: [[0.48847517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.049433160573244095, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48555005]\n",
      " [0.48286059]\n",
      " [0.48080358]\n",
      " [0.47990629]\n",
      " [0.48037249]\n",
      " [0.48224431]\n",
      " [0.485122  ]\n",
      " [0.48847517]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002460674848407507, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48286059]\n",
      " [0.48080358]\n",
      " [0.47990629]\n",
      " [0.48037249]\n",
      " [0.48224431]\n",
      " [0.485122  ]\n",
      " [0.48847517]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5113201]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07916776090860367, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48080358]\n",
      " [0.47990629]\n",
      " [0.48037249]\n",
      " [0.48224431]\n",
      " [0.485122  ]\n",
      " [0.48847517]\n",
      " [0.67299496]\n",
      " [0.51132011]] | y: 0.703990701278574 | Predicción actual: [[0.5144468]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.027804991230368614, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.47990629]\n",
      " [0.48037249]\n",
      " [0.48224431]\n",
      " [0.485122  ]\n",
      " [0.48847517]\n",
      " [0.67299496]\n",
      " [0.51132011]\n",
      " [0.51444679]] | y: 0.7272375048430839 | Predicción actual: [[0.52038306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025700204074382782, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48037249]\n",
      " [0.48224431]\n",
      " [0.485122  ]\n",
      " [0.48847517]\n",
      " [0.67299496]\n",
      " [0.51132011]\n",
      " [0.51444679]\n",
      " [0.52038306]] | y: 0.722588144130182 | Predicción actual: [[0.52903384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07294346392154694, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48224431]\n",
      " [0.485122  ]\n",
      " [0.48847517]\n",
      " [0.67299496]\n",
      " [0.51132011]\n",
      " [0.51444679]\n",
      " [0.52038306]\n",
      " [0.52903384]] | y: 0.771793878341728 | Predicción actual: [[0.5400918]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06726554781198502, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.485122  ]\n",
      " [0.48847517]\n",
      " [0.67299496]\n",
      " [0.51132011]\n",
      " [0.51444679]\n",
      " [0.52038306]\n",
      " [0.52903384]\n",
      " [0.54009181]] | y: 0.7245253777605578 | Predicción actual: [[0.55306864]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03359227627515793, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48847517]\n",
      " [0.67299496]\n",
      " [0.51132011]\n",
      " [0.51444679]\n",
      " [0.52038306]\n",
      " [0.52903384]\n",
      " [0.54009181]\n",
      " [0.55306864]] | y: 0.6710577295621851 | Predicción actual: [[0.56745994]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0032138482201844454, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.51132011]\n",
      " [0.51444679]\n",
      " [0.52038306]\n",
      " [0.52903384]\n",
      " [0.54009181]\n",
      " [0.55306864]\n",
      " [0.56745994]] | y: 0.6737698566447115 | Predicción actual: [[0.58286935]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012952079065144062, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51132011]\n",
      " [0.51444679]\n",
      " [0.52038306]\n",
      " [0.52903384]\n",
      " [0.54009181]\n",
      " [0.55306864]\n",
      " [0.56745994]\n",
      " [0.58286935]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04349398612976074, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51444679]\n",
      " [0.52038306]\n",
      " [0.52903384]\n",
      " [0.54009181]\n",
      " [0.55306864]\n",
      " [0.56745994]\n",
      " [0.58286935]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.55793756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06020265072584152, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52038306]\n",
      " [0.52903384]\n",
      " [0.54009181]\n",
      " [0.55306864]\n",
      " [0.56745994]\n",
      " [0.58286935]\n",
      " [0.71445176]\n",
      " [0.55793756]] | y: 0.722588144130182 | Predicción actual: [[0.5688578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011194542050361633, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52903384]\n",
      " [0.54009181]\n",
      " [0.55306864]\n",
      " [0.56745994]\n",
      " [0.58286935]\n",
      " [0.71445176]\n",
      " [0.55793756]\n",
      " [0.56885779]] | y: 0.6993413405656723 | Predicción actual: [[0.5817482]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006642248947173357, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54009181]\n",
      " [0.55306864]\n",
      " [0.56745994]\n",
      " [0.58286935]\n",
      " [0.71445176]\n",
      " [0.55793756]\n",
      " [0.56885779]\n",
      " [0.58174819]] | y: 0.7373111197210385 | Predicción actual: [[0.5955649]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011168159544467926, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55306864]\n",
      " [0.56745994]\n",
      " [0.58286935]\n",
      " [0.71445176]\n",
      " [0.55793756]\n",
      " [0.56885779]\n",
      " [0.58174819]\n",
      " [0.5955649 ]] | y: 0.7214258039519565 | Predicción actual: [[0.6091708]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01963835023343563, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56745994]\n",
      " [0.58286935]\n",
      " [0.71445176]\n",
      " [0.55793756]\n",
      " [0.56885779]\n",
      " [0.58174819]\n",
      " [0.5955649 ]\n",
      " [0.60917079]] | y: 0.7187136768694304 | Predicción actual: [[0.6214538]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01069334615021944, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58286935]\n",
      " [0.71445176]\n",
      " [0.55793756]\n",
      " [0.56885779]\n",
      " [0.58174819]\n",
      " [0.5955649 ]\n",
      " [0.60917079]\n",
      " [0.62145382]] | y: 0.6741573033707864 | Predicción actual: [[0.6313915]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0019120487850159407, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55793756]\n",
      " [0.56885779]\n",
      " [0.58174819]\n",
      " [0.5955649 ]\n",
      " [0.60917079]\n",
      " [0.62145382]\n",
      " [0.63139153]] | y: 0.698566447113522 | Predicción actual: [[0.6381164]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002683048078324646, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55793756]\n",
      " [0.56885779]\n",
      " [0.58174819]\n",
      " [0.5955649 ]\n",
      " [0.60917079]\n",
      " [0.62145382]\n",
      " [0.63139153]\n",
      " [0.63811642]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018553859554231167, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56885779]\n",
      " [0.58174819]\n",
      " [0.5955649 ]\n",
      " [0.60917079]\n",
      " [0.62145382]\n",
      " [0.63139153]\n",
      " [0.63811642]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6205044]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00943303294479847, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58174819]\n",
      " [0.5955649 ]\n",
      " [0.60917079]\n",
      " [0.62145382]\n",
      " [0.63139153]\n",
      " [0.63811642]\n",
      " [0.72103836]\n",
      " [0.62050438]] | y: 0.7562960092987214 | Predicción actual: [[0.633387]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025406721979379654, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5955649 ]\n",
      " [0.60917079]\n",
      " [0.62145382]\n",
      " [0.63139153]\n",
      " [0.63811642]\n",
      " [0.72103836]\n",
      " [0.62050438]\n",
      " [0.63338703]] | y: 0.8275862068965516 | Predicción actual: [[0.6461615]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028592225164175034, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60917079]\n",
      " [0.62145382]\n",
      " [0.63139153]\n",
      " [0.63811642]\n",
      " [0.72103836]\n",
      " [0.62050438]\n",
      " [0.63338703]\n",
      " [0.6461615 ]] | y: 0.8388221619527314 | Predicción actual: [[0.65803516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05091400071978569, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62145382]\n",
      " [0.63139153]\n",
      " [0.63811642]\n",
      " [0.72103836]\n",
      " [0.62050438]\n",
      " [0.63338703]\n",
      " [0.6461615 ]\n",
      " [0.65803516]] | y: 0.7942657884540876 | Predicción actual: [[0.6684938]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007298666052520275, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63139153]\n",
      " [0.63811642]\n",
      " [0.72103836]\n",
      " [0.62050438]\n",
      " [0.63338703]\n",
      " [0.6461615 ]\n",
      " [0.65803516]\n",
      " [0.66849381]] | y: 0.7838047268500579 | Predicción actual: [[0.67721736]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019216865301132202, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63811642]\n",
      " [0.72103836]\n",
      " [0.62050438]\n",
      " [0.63338703]\n",
      " [0.6461615 ]\n",
      " [0.65803516]\n",
      " [0.66849381]\n",
      " [0.67721736]] | y: 0.7679194110809764 | Predicción actual: [[0.6845178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021547801792621613, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.62050438]\n",
      " [0.63338703]\n",
      " [0.6461615 ]\n",
      " [0.65803516]\n",
      " [0.66849381]\n",
      " [0.67721736]\n",
      " [0.6845178 ]] | y: 0.7845796203022084 | Predicción actual: [[0.6911003]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.547613000089768e-06, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62050438]\n",
      " [0.63338703]\n",
      " [0.6461615 ]\n",
      " [0.65803516]\n",
      " [0.66849381]\n",
      " [0.67721736]\n",
      " [0.6845178 ]\n",
      " [0.6911003 ]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07970546931028366, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63338703]\n",
      " [0.6461615 ]\n",
      " [0.65803516]\n",
      " [0.66849381]\n",
      " [0.67721736]\n",
      " [0.6845178 ]\n",
      " [0.6911003 ]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6875056]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0034718504175543785, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6461615 ]\n",
      " [0.65803516]\n",
      " [0.66849381]\n",
      " [0.67721736]\n",
      " [0.6845178 ]\n",
      " [0.6911003 ]\n",
      " [0.87872917]\n",
      " [0.6875056 ]] | y: 0.8488957768306855 | Predicción actual: [[0.701384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026699772104620934, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65803516]\n",
      " [0.66849381]\n",
      " [0.67721736]\n",
      " [0.6845178 ]\n",
      " [0.6911003 ]\n",
      " [0.87872917]\n",
      " [0.6875056 ]\n",
      " [0.70138401]] | y: 0.8182874854707476 | Predicción actual: [[0.71595913]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014122586697340012, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66849381]\n",
      " [0.67721736]\n",
      " [0.6845178 ]\n",
      " [0.6911003 ]\n",
      " [0.87872917]\n",
      " [0.6875056 ]\n",
      " [0.70138401]\n",
      " [0.71595913]] | y: 0.8268113134444013 | Predicción actual: [[0.73097086]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011803417466580868, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67721736]\n",
      " [0.6845178 ]\n",
      " [0.6911003 ]\n",
      " [0.87872917]\n",
      " [0.6875056 ]\n",
      " [0.70138401]\n",
      " [0.71595913]\n",
      " [0.73097086]] | y: 0.7853545137543589 | Predicción actual: [[0.74627286]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015019961865618825, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6845178 ]\n",
      " [0.6911003 ]\n",
      " [0.87872917]\n",
      " [0.6875056 ]\n",
      " [0.70138401]\n",
      " [0.71595913]\n",
      " [0.73097086]\n",
      " [0.74627286]] | y: 0.7892289810151103 | Predicción actual: [[0.76176137]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.2315904314164072e-05, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6911003 ]\n",
      " [0.87872917]\n",
      " [0.6875056 ]\n",
      " [0.70138401]\n",
      " [0.71595913]\n",
      " [0.73097086]\n",
      " [0.74627286]\n",
      " [0.76176137]] | y: 0.8341728012398295 | Predicción actual: [[0.7774038]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005200342857278883, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.6875056 ]\n",
      " [0.70138401]\n",
      " [0.71595913]\n",
      " [0.73097086]\n",
      " [0.74627286]\n",
      " [0.76176137]\n",
      " [0.77740377]] | y: 0.8124757845796202 | Predicción actual: [[0.79318523]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022403091192245483, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6875056 ]\n",
      " [0.70138401]\n",
      " [0.71595913]\n",
      " [0.73097086]\n",
      " [0.74627286]\n",
      " [0.76176137]\n",
      " [0.77740377]\n",
      " [0.79318523]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003253912553191185, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70138401]\n",
      " [0.71595913]\n",
      " [0.73097086]\n",
      " [0.74627286]\n",
      " [0.76176137]\n",
      " [0.77740377]\n",
      " [0.79318523]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7685298]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018541092053055763, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71595913]\n",
      " [0.73097086]\n",
      " [0.74627286]\n",
      " [0.76176137]\n",
      " [0.77740377]\n",
      " [0.79318523]\n",
      " [0.80123983]\n",
      " [0.76852977]] | y: 0.793490895001937 | Predicción actual: [[0.7839309]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002029069699347019, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73097086]\n",
      " [0.74627286]\n",
      " [0.76176137]\n",
      " [0.77740377]\n",
      " [0.79318523]\n",
      " [0.80123983]\n",
      " [0.76852977]\n",
      " [0.7839309 ]] | y: 0.760170476559473 | Predicción actual: [[0.79848075]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008041500113904476, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74627286]\n",
      " [0.76176137]\n",
      " [0.77740377]\n",
      " [0.79318523]\n",
      " [0.80123983]\n",
      " [0.76852977]\n",
      " [0.7839309 ]\n",
      " [0.79848075]] | y: 0.7353738860906625 | Predicción actual: [[0.81171024]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004106208216398954, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76176137]\n",
      " [0.77740377]\n",
      " [0.79318523]\n",
      " [0.80123983]\n",
      " [0.76852977]\n",
      " [0.7839309 ]\n",
      " [0.79848075]\n",
      " [0.81171024]] | y: 0.7101898488957767 | Predicción actual: [[0.822739]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043299540877342224, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77740377]\n",
      " [0.79318523]\n",
      " [0.80123983]\n",
      " [0.76852977]\n",
      " [0.7839309 ]\n",
      " [0.79848075]\n",
      " [0.81171024]\n",
      " [0.82273901]] | y: 0.7121270825261525 | Predicción actual: [[0.8307266]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016515026800334454, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79318523]\n",
      " [0.80123983]\n",
      " [0.76852977]\n",
      " [0.7839309 ]\n",
      " [0.79848075]\n",
      " [0.81171024]\n",
      " [0.82273901]\n",
      " [0.83072662]] | y: 0.7396358000774894 | Predicción actual: [[0.8357808]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003708458272740245, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.76852977]\n",
      " [0.7839309 ]\n",
      " [0.79848075]\n",
      " [0.81171024]\n",
      " [0.82273901]\n",
      " [0.83072662]\n",
      " [0.8357808 ]] | y: 0.7361487795428128 | Predicción actual: [[0.8376273]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001988055184483528, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76852977]\n",
      " [0.7839309 ]\n",
      " [0.79848075]\n",
      " [0.81171024]\n",
      " [0.82273901]\n",
      " [0.83072662]\n",
      " [0.8357808 ]\n",
      " [0.83762729]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02611430734395981, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7839309 ]\n",
      " [0.79848075]\n",
      " [0.81171024]\n",
      " [0.82273901]\n",
      " [0.83072662]\n",
      " [0.8357808 ]\n",
      " [0.83762729]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8497336]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1424035280942917, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79848075]\n",
      " [0.81171024]\n",
      " [0.82273901]\n",
      " [0.83072662]\n",
      " [0.8357808 ]\n",
      " [0.83762729]\n",
      " [0.66757071]\n",
      " [0.84973359]] | y: 0.696629213483146 | Predicción actual: [[0.85687]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013078722171485424, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81171024]\n",
      " [0.82273901]\n",
      " [0.83072662]\n",
      " [0.8357808 ]\n",
      " [0.83762729]\n",
      " [0.66757071]\n",
      " [0.84973359]\n",
      " [0.85687   ]] | y: 0.6559473072452537 | Predicción actual: [[0.8601392]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0036491043865680695, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82273901]\n",
      " [0.83072662]\n",
      " [0.8357808 ]\n",
      " [0.83762729]\n",
      " [0.66757071]\n",
      " [0.84973359]\n",
      " [0.85687   ]\n",
      " [0.86013919]] | y: 0.6788066640836885 | Predicción actual: [[0.85976213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03812262415885925, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83072662]\n",
      " [0.8357808 ]\n",
      " [0.83762729]\n",
      " [0.66757071]\n",
      " [0.84973359]\n",
      " [0.85687   ]\n",
      " [0.86013919]\n",
      " [0.85976213]] | y: 0.6760945370011622 | Predicción actual: [[0.85613346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02431233786046505, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8357808 ]\n",
      " [0.83762729]\n",
      " [0.66757071]\n",
      " [0.84973359]\n",
      " [0.85687   ]\n",
      " [0.86013919]\n",
      " [0.85976213]\n",
      " [0.85613346]] | y: 0.7295621851995349 | Predicción actual: [[0.8505675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009985764510929585, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83762729]\n",
      " [0.66757071]\n",
      " [0.84973359]\n",
      " [0.85687   ]\n",
      " [0.86013919]\n",
      " [0.85976213]\n",
      " [0.85613346]\n",
      " [0.85056752]] | y: 0.7012785741960481 | Predicción actual: [[0.8444883]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0048459419049322605, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.84973359]\n",
      " [0.85687   ]\n",
      " [0.86013919]\n",
      " [0.85976213]\n",
      " [0.85613346]\n",
      " [0.85056752]\n",
      " [0.84448832]] | y: 0.767531964354901 | Predicción actual: [[0.8393749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004265591036528349, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84973359]\n",
      " [0.85687   ]\n",
      " [0.86013919]\n",
      " [0.85976213]\n",
      " [0.85613346]\n",
      " [0.85056752]\n",
      " [0.84448832]\n",
      " [0.8393749 ]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015372456051409245, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85687   ]\n",
      " [0.86013919]\n",
      " [0.85976213]\n",
      " [0.85613346]\n",
      " [0.85056752]\n",
      " [0.84448832]\n",
      " [0.8393749 ]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8886102]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11640690267086029, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86013919]\n",
      " [0.85976213]\n",
      " [0.85613346]\n",
      " [0.85056752]\n",
      " [0.84448832]\n",
      " [0.8393749 ]\n",
      " [0.75513367]\n",
      " [0.88861018]] | y: 0.7520340953118947 | Predicción actual: [[0.88393354]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013673992827534676, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85976213]\n",
      " [0.85613346]\n",
      " [0.85056752]\n",
      " [0.84448832]\n",
      " [0.8393749 ]\n",
      " [0.75513367]\n",
      " [0.88861018]\n",
      " [0.88393354]] | y: 0.7098024021697016 | Predicción actual: [[0.8773193]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.042701371014118195, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85613346]\n",
      " [0.85056752]\n",
      " [0.84448832]\n",
      " [0.8393749 ]\n",
      " [0.75513367]\n",
      " [0.88861018]\n",
      " [0.88393354]\n",
      " [0.87731928]] | y: 0.6904300658659435 | Predicción actual: [[0.87004805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004451178014278412, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85056752]\n",
      " [0.84448832]\n",
      " [0.8393749 ]\n",
      " [0.75513367]\n",
      " [0.88861018]\n",
      " [0.88393354]\n",
      " [0.87731928]\n",
      " [0.87004805]] | y: 0.7543587756683454 | Predicción actual: [[0.86400926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.734234385570744e-06, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84448832]\n",
      " [0.8393749 ]\n",
      " [0.75513367]\n",
      " [0.88861018]\n",
      " [0.88393354]\n",
      " [0.87731928]\n",
      " [0.87004805]\n",
      " [0.86400926]] | y: 0.7222006974041069 | Predicción actual: [[0.8605071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003122343623545021, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8393749 ]\n",
      " [0.75513367]\n",
      " [0.88861018]\n",
      " [0.88393354]\n",
      " [0.87731928]\n",
      " [0.87004805]\n",
      " [0.86400926]\n",
      " [0.86050707]] | y: 0.8485083301046106 | Predicción actual: [[0.860226]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006995337083935738, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.88861018]\n",
      " [0.88393354]\n",
      " [0.87731928]\n",
      " [0.87004805]\n",
      " [0.86400926]\n",
      " [0.86050707]\n",
      " [0.86022598]] | y: 0.9054629988376597 | Predicción actual: [[0.86301017]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06224999949336052, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88861018]\n",
      " [0.88393354]\n",
      " [0.87731928]\n",
      " [0.87004805]\n",
      " [0.86400926]\n",
      " [0.86050707]\n",
      " [0.86022598]\n",
      " [0.86301017]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01397604588419199, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88393354]\n",
      " [0.87731928]\n",
      " [0.87004805]\n",
      " [0.86400926]\n",
      " [0.86050707]\n",
      " [0.86022598]\n",
      " [0.86301017]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8881484]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01119833905249834, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87731928]\n",
      " [0.87004805]\n",
      " [0.86400926]\n",
      " [0.86050707]\n",
      " [0.86022598]\n",
      " [0.86301017]\n",
      " [0.8822162 ]\n",
      " [0.88814843]] | y: 0.889577683068578 | Predicción actual: [[0.88264996]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011571713723242283, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87004805]\n",
      " [0.86400926]\n",
      " [0.86050707]\n",
      " [0.86022598]\n",
      " [0.86301017]\n",
      " [0.8822162 ]\n",
      " [0.88814843]\n",
      " [0.88264996]] | y: 0.8748547074777218 | Predicción actual: [[0.8791267]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00011576625547604635, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86400926]\n",
      " [0.86050707]\n",
      " [0.86022598]\n",
      " [0.86301017]\n",
      " [0.8822162 ]\n",
      " [0.88814843]\n",
      " [0.88264996]\n",
      " [0.87912673]] | y: 0.9132119333591631 | Predicción actual: [[0.87803656]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010253358632326126, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86050707]\n",
      " [0.86022598]\n",
      " [0.86301017]\n",
      " [0.8822162 ]\n",
      " [0.88814843]\n",
      " [0.88264996]\n",
      " [0.87912673]\n",
      " [0.87803656]] | y: 1.0 | Predicción actual: [[0.87952167]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008760273340158165, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86022598]\n",
      " [0.86301017]\n",
      " [0.8822162 ]\n",
      " [0.88814843]\n",
      " [0.88264996]\n",
      " [0.87912673]\n",
      " [0.87803656]\n",
      " [0.87952167]] | y: 0.9705540488182873 | Predicción actual: [[0.88308334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01904856041073799, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86301017]\n",
      " [0.8822162 ]\n",
      " [0.88814843]\n",
      " [0.88264996]\n",
      " [0.87912673]\n",
      " [0.87803656]\n",
      " [0.87952167]\n",
      " [0.88308334]] | y: 0.8888027896164277 | Predicción actual: [[0.88804334]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0061757564544677734, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.88814843]\n",
      " [0.88264996]\n",
      " [0.87912673]\n",
      " [0.87803656]\n",
      " [0.87952167]\n",
      " [0.88308334]\n",
      " [0.88804334]] | y: 0.877954281286323 | Predicción actual: [[0.89325964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018733703764155507, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88814843]\n",
      " [0.88264996]\n",
      " [0.87912673]\n",
      " [0.87803656]\n",
      " [0.87952167]\n",
      " [0.88308334]\n",
      " [0.88804334]\n",
      " [0.89325964]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 7.701692084083334e-08, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88264996]\n",
      " [0.87912673]\n",
      " [0.87803656]\n",
      " [0.87952167]\n",
      " [0.88308334]\n",
      " [0.88804334]\n",
      " [0.89325964]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.89122796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08692923933267593, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87912673]\n",
      " [0.87803656]\n",
      " [0.87952167]\n",
      " [0.88308334]\n",
      " [0.88804334]\n",
      " [0.89325964]\n",
      " [0.84889578]\n",
      " [0.89122796]] | y: 0.8550949244478885 | Predicción actual: [[0.8898375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009637696668505669, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87803656]\n",
      " [0.87952167]\n",
      " [0.88308334]\n",
      " [0.88804334]\n",
      " [0.89325964]\n",
      " [0.84889578]\n",
      " [0.89122796]\n",
      " [0.8898375 ]] | y: 0.8752421542037967 | Predicción actual: [[0.8893667]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003830639470834285, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87952167]\n",
      " [0.88308334]\n",
      " [0.88804334]\n",
      " [0.89325964]\n",
      " [0.84889578]\n",
      " [0.89122796]\n",
      " [0.8898375 ]\n",
      " [0.88936669]] | y: 0.857032158078264 | Predicción actual: [[0.8894463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003548558335751295, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88308334]\n",
      " [0.88804334]\n",
      " [0.89325964]\n",
      " [0.84889578]\n",
      " [0.89122796]\n",
      " [0.8898375 ]\n",
      " [0.88936669]\n",
      " [0.88944632]] | y: 0.8500581170089112 | Predicción actual: [[0.88928896]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003037050599232316, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88804334]\n",
      " [0.89325964]\n",
      " [0.84889578]\n",
      " [0.89122796]\n",
      " [0.8898375 ]\n",
      " [0.88936669]\n",
      " [0.88944632]\n",
      " [0.88928896]] | y: 0.8426966292134832 | Predicción actual: [[0.8882845]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005324112251400948, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89325964]\n",
      " [0.84889578]\n",
      " [0.89122796]\n",
      " [0.8898375 ]\n",
      " [0.88936669]\n",
      " [0.88944632]\n",
      " [0.88928896]\n",
      " [0.8882845 ]] | y: 0.8229368461836497 | Predicción actual: [[0.88620263]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030638419091701508, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.89122796]\n",
      " [0.8898375 ]\n",
      " [0.88936669]\n",
      " [0.88944632]\n",
      " [0.88928896]\n",
      " [0.8882845 ]\n",
      " [0.88620263]] | y: 0.7745060054242543 | Predicción actual: [[0.88232726]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0029185970779508352, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89122796]\n",
      " [0.8898375 ]\n",
      " [0.88936669]\n",
      " [0.88944632]\n",
      " [0.88928896]\n",
      " [0.8882845 ]\n",
      " [0.88620263]\n",
      " [0.88232726]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015677794814109802, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8898375 ]\n",
      " [0.88936669]\n",
      " [0.88944632]\n",
      " [0.88928896]\n",
      " [0.8882845 ]\n",
      " [0.88620263]\n",
      " [0.88232726]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.8894215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019931534305214882, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88936669]\n",
      " [0.88944632]\n",
      " [0.88928896]\n",
      " [0.8882845 ]\n",
      " [0.88620263]\n",
      " [0.88232726]\n",
      " [0.78419217]\n",
      " [0.88942152]] | y: 0.854320030995738 | Predicción actual: [[0.88582426]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002118254778906703, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88944632]\n",
      " [0.88928896]\n",
      " [0.8882845 ]\n",
      " [0.88620263]\n",
      " [0.88232726]\n",
      " [0.78419217]\n",
      " [0.88942152]\n",
      " [0.88582426]] | y: 0.8368849283223556 | Predicción actual: [[0.8814002]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005062238313257694, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88928896]\n",
      " [0.8882845 ]\n",
      " [0.88620263]\n",
      " [0.88232726]\n",
      " [0.78419217]\n",
      " [0.88942152]\n",
      " [0.88582426]\n",
      " [0.88140023]] | y: 0.8299108872530028 | Predicción actual: [[0.87578225]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00039847244624979794, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8882845 ]\n",
      " [0.88620263]\n",
      " [0.88232726]\n",
      " [0.78419217]\n",
      " [0.88942152]\n",
      " [0.88582426]\n",
      " [0.88140023]\n",
      " [0.87578225]] | y: 0.887253002712127 | Predicción actual: [[0.86931014]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 9.454914106754586e-06, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88620263]\n",
      " [0.88232726]\n",
      " [0.78419217]\n",
      " [0.88942152]\n",
      " [0.88582426]\n",
      " [0.88140023]\n",
      " [0.87578225]\n",
      " [0.86931014]] | y: 0.8597442851607902 | Predicción actual: [[0.8624853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.8531529349274933e-05, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88232726]\n",
      " [0.78419217]\n",
      " [0.88942152]\n",
      " [0.88582426]\n",
      " [0.88140023]\n",
      " [0.87578225]\n",
      " [0.86931014]\n",
      " [0.86248529]] | y: 0.8395970554048819 | Predicción actual: [[0.85583675]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026652207598090172, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.88942152]\n",
      " [0.88582426]\n",
      " [0.88140023]\n",
      " [0.87578225]\n",
      " [0.86931014]\n",
      " [0.86248529]\n",
      " [0.85583675]] | y: 0.7838047268500579 | Predicción actual: [[0.8497467]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00501683633774519, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88942152]\n",
      " [0.88582426]\n",
      " [0.88140023]\n",
      " [0.87578225]\n",
      " [0.86931014]\n",
      " [0.86248529]\n",
      " [0.85583675]\n",
      " [0.8497467 ]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030216051265597343, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88582426]\n",
      " [0.88140023]\n",
      " [0.87578225]\n",
      " [0.86931014]\n",
      " [0.86248529]\n",
      " [0.85583675]\n",
      " [0.8497467 ]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.86650306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037343106232583523, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88140023]\n",
      " [0.87578225]\n",
      " [0.86931014]\n",
      " [0.86248529]\n",
      " [0.85583675]\n",
      " [0.8497467 ]\n",
      " [0.81828749]\n",
      " [0.86650306]] | y: 0.7605579232855482 | Predicción actual: [[0.8594411]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005025503225624561, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87578225]\n",
      " [0.86931014]\n",
      " [0.86248529]\n",
      " [0.85583675]\n",
      " [0.8497467 ]\n",
      " [0.81828749]\n",
      " [0.86650306]\n",
      " [0.8594411 ]] | y: 0.7915536613715615 | Predicción actual: [[0.85212004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01298186182975769, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86931014]\n",
      " [0.86248529]\n",
      " [0.85583675]\n",
      " [0.8497467 ]\n",
      " [0.81828749]\n",
      " [0.86650306]\n",
      " [0.8594411 ]\n",
      " [0.85212004]] | y: 0.7686943045331267 | Predicción actual: [[0.8450253]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008428531000390649, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86248529]\n",
      " [0.85583675]\n",
      " [0.8497467 ]\n",
      " [0.81828749]\n",
      " [0.86650306]\n",
      " [0.8594411 ]\n",
      " [0.85212004]\n",
      " [0.8450253 ]] | y: 0.7686943045331267 | Predicción actual: [[0.8388766]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023085379973053932, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85583675]\n",
      " [0.8497467 ]\n",
      " [0.81828749]\n",
      " [0.86650306]\n",
      " [0.8594411 ]\n",
      " [0.85212004]\n",
      " [0.8450253 ]\n",
      " [0.83887661]] | y: 0.7989151491669895 | Predicción actual: [[0.8337771]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00027302539092488587, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8497467 ]\n",
      " [0.81828749]\n",
      " [0.86650306]\n",
      " [0.8594411 ]\n",
      " [0.85212004]\n",
      " [0.8450253 ]\n",
      " [0.83887661]\n",
      " [0.83377713]] | y: 0.7900038744672608 | Predicción actual: [[0.8302341]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011897292919456959, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.86650306]\n",
      " [0.8594411 ]\n",
      " [0.85212004]\n",
      " [0.8450253 ]\n",
      " [0.83887661]\n",
      " [0.83377713]\n",
      " [0.83023411]] | y: 0.760170476559473 | Predicción actual: [[0.82794535]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004429308755788952, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86650306]\n",
      " [0.8594411 ]\n",
      " [0.85212004]\n",
      " [0.8450253 ]\n",
      " [0.83887661]\n",
      " [0.83377713]\n",
      " [0.83023411]\n",
      " [0.82794535]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023510975763201714, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8594411 ]\n",
      " [0.85212004]\n",
      " [0.8450253 ]\n",
      " [0.83887661]\n",
      " [0.83377713]\n",
      " [0.83023411]\n",
      " [0.82794535]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.8261917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04956619814038277, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85212004]\n",
      " [0.8450253 ]\n",
      " [0.83887661]\n",
      " [0.83377713]\n",
      " [0.83023411]\n",
      " [0.82794535]\n",
      " [0.68539326]\n",
      " [0.82619172]] | y: 0.6648585819449826 | Predicción actual: [[0.81680804]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007046618964523077, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8450253 ]\n",
      " [0.83887661]\n",
      " [0.83377713]\n",
      " [0.83023411]\n",
      " [0.82794535]\n",
      " [0.68539326]\n",
      " [0.82619172]\n",
      " [0.81680804]] | y: 0.7078651685393258 | Predicción actual: [[0.80685836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04164538159966469, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83887661]\n",
      " [0.83377713]\n",
      " [0.83023411]\n",
      " [0.82794535]\n",
      " [0.68539326]\n",
      " [0.82619172]\n",
      " [0.81680804]\n",
      " [0.80685836]] | y: 0.6648585819449826 | Predicción actual: [[0.79626185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021769925951957703, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83377713]\n",
      " [0.83023411]\n",
      " [0.82794535]\n",
      " [0.68539326]\n",
      " [0.82619172]\n",
      " [0.81680804]\n",
      " [0.80685836]\n",
      " [0.79626185]] | y: 0.7113521890740022 | Predicción actual: [[0.7852618]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0076530021615326405, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83023411]\n",
      " [0.82794535]\n",
      " [0.68539326]\n",
      " [0.82619172]\n",
      " [0.81680804]\n",
      " [0.80685836]\n",
      " [0.79626185]\n",
      " [0.78526181]] | y: 0.6772568771793879 | Predicción actual: [[0.7742651]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014323805226013064, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82794535]\n",
      " [0.68539326]\n",
      " [0.82619172]\n",
      " [0.81680804]\n",
      " [0.80685836]\n",
      " [0.79626185]\n",
      " [0.78526181]\n",
      " [0.77426511]] | y: 0.7621077101898488 | Predicción actual: [[0.7629005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02166859060525894, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.82619172]\n",
      " [0.81680804]\n",
      " [0.80685836]\n",
      " [0.79626185]\n",
      " [0.78526181]\n",
      " [0.77426511]\n",
      " [0.76290047]] | y: 0.8070515304145678 | Predicción actual: [[0.75121313]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0004252552171237767, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82619172]\n",
      " [0.81680804]\n",
      " [0.80685836]\n",
      " [0.79626185]\n",
      " [0.78526181]\n",
      " [0.77426511]\n",
      " [0.76290047]\n",
      " [0.75121313]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02948557771742344, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81680804]\n",
      " [0.80685836]\n",
      " [0.79626185]\n",
      " [0.78526181]\n",
      " [0.77426511]\n",
      " [0.76290047]\n",
      " [0.75121313]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.7693126]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015239839442074299, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80685836]\n",
      " [0.79626185]\n",
      " [0.78526181]\n",
      " [0.77426511]\n",
      " [0.76290047]\n",
      " [0.75121313]\n",
      " [0.81518791]\n",
      " [0.76931262]] | y: 0.9597055404881829 | Predicción actual: [[0.76075965]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037820059806108475, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79626185]\n",
      " [0.78526181]\n",
      " [0.77426511]\n",
      " [0.76290047]\n",
      " [0.75121313]\n",
      " [0.81518791]\n",
      " [0.76931262]\n",
      " [0.76075965]] | y: 0.9643549012010848 | Predicción actual: [[0.75362456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06542175263166428, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78526181]\n",
      " [0.77426511]\n",
      " [0.76290047]\n",
      " [0.75121313]\n",
      " [0.81518791]\n",
      " [0.76931262]\n",
      " [0.76075965]\n",
      " [0.75362456]] | y: 0.8880278961642774 | Predicción actual: [[0.7484245]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005449699703603983, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77426511]\n",
      " [0.76290047]\n",
      " [0.75121313]\n",
      " [0.81518791]\n",
      " [0.76931262]\n",
      " [0.76075965]\n",
      " [0.75362456]\n",
      " [0.74842447]] | y: 0.8926772568771792 | Predicción actual: [[0.7452534]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06553669273853302, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76290047]\n",
      " [0.75121313]\n",
      " [0.81518791]\n",
      " [0.76931262]\n",
      " [0.76075965]\n",
      " [0.75362456]\n",
      " [0.74842447]\n",
      " [0.74525338]] | y: 0.8752421542037967 | Predicción actual: [[0.7444875]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044727958738803864, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75121313]\n",
      " [0.81518791]\n",
      " [0.76931262]\n",
      " [0.76075965]\n",
      " [0.75362456]\n",
      " [0.74842447]\n",
      " [0.74525338]\n",
      " [0.74448752]] | y: 0.8508330104610615 | Predicción actual: [[0.7463113]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11043629050254822, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.76931262]\n",
      " [0.76075965]\n",
      " [0.75362456]\n",
      " [0.74842447]\n",
      " [0.74525338]\n",
      " [0.74448752]\n",
      " [0.74631131]] | y: 0.8488957768306855 | Predicción actual: [[0.7509964]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004379964899271727, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76931262]\n",
      " [0.76075965]\n",
      " [0.75362456]\n",
      " [0.74842447]\n",
      " [0.74525338]\n",
      " [0.74448752]\n",
      " [0.74631131]\n",
      " [0.75099641]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017578953877091408, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76075965]\n",
      " [0.75362456]\n",
      " [0.74842447]\n",
      " [0.74525338]\n",
      " [0.74448752]\n",
      " [0.74631131]\n",
      " [0.75099641]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.7347916]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.059186723083257675, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75362456]\n",
      " [0.74842447]\n",
      " [0.74525338]\n",
      " [0.74448752]\n",
      " [0.74631131]\n",
      " [0.75099641]\n",
      " [0.96241767]\n",
      " [0.73479158]] | y: 0.9407206509104997 | Predicción actual: [[0.7362045]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002060707425698638, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74842447]\n",
      " [0.74525338]\n",
      " [0.74448752]\n",
      " [0.74631131]\n",
      " [0.75099641]\n",
      " [0.96241767]\n",
      " [0.73479158]\n",
      " [0.7362045 ]] | y: 0.9724912824486633 | Predicción actual: [[0.7409587]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04578520357608795, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74525338]\n",
      " [0.74448752]\n",
      " [0.74631131]\n",
      " [0.75099641]\n",
      " [0.96241767]\n",
      " [0.73479158]\n",
      " [0.7362045 ]\n",
      " [0.74095869]] | y: 0.9969004261913985 | Predicción actual: [[0.7488066]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.062178876250982285, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74448752]\n",
      " [0.74631131]\n",
      " [0.75099641]\n",
      " [0.96241767]\n",
      " [0.73479158]\n",
      " [0.7362045 ]\n",
      " [0.74095869]\n",
      " [0.7488066 ]] | y: 0.951181712514529 | Predicción actual: [[0.75898224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035077035427093506, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74631131]\n",
      " [0.75099641]\n",
      " [0.96241767]\n",
      " [0.73479158]\n",
      " [0.7362045 ]\n",
      " [0.74095869]\n",
      " [0.7488066 ]\n",
      " [0.75898224]] | y: 0.8957768306857805 | Predicción actual: [[0.77031344]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.046868011355400085, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75099641]\n",
      " [0.96241767]\n",
      " [0.73479158]\n",
      " [0.7362045 ]\n",
      " [0.74095869]\n",
      " [0.7488066 ]\n",
      " [0.75898224]\n",
      " [0.77031344]] | y: 0.8814413018209997 | Predicción actual: [[0.7816152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03352997079491615, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.73479158]\n",
      " [0.7362045 ]\n",
      " [0.74095869]\n",
      " [0.7488066 ]\n",
      " [0.75898224]\n",
      " [0.77031344]\n",
      " [0.7816152 ]] | y: 0.9170864006199149 | Predicción actual: [[0.7915606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03902807459235191, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73479158]\n",
      " [0.7362045 ]\n",
      " [0.74095869]\n",
      " [0.7488066 ]\n",
      " [0.75898224]\n",
      " [0.77031344]\n",
      " [0.7816152 ]\n",
      " [0.79156059]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03148014843463898, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7362045 ]\n",
      " [0.74095869]\n",
      " [0.7488066 ]\n",
      " [0.75898224]\n",
      " [0.77031344]\n",
      " [0.7816152 ]\n",
      " [0.79156059]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7480244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022237708792090416, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74095869]\n",
      " [0.7488066 ]\n",
      " [0.75898224]\n",
      " [0.77031344]\n",
      " [0.7816152 ]\n",
      " [0.79156059]\n",
      " [0.91979853]\n",
      " [0.7480244 ]] | y: 0.9682293684618366 | Predicción actual: [[0.7592189]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07441380620002747, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7488066 ]\n",
      " [0.75898224]\n",
      " [0.77031344]\n",
      " [0.7816152 ]\n",
      " [0.79156059]\n",
      " [0.91979853]\n",
      " [0.7480244 ]\n",
      " [0.75921887]] | y: 0.9577683068578069 | Predicción actual: [[0.77220714]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00763664860278368, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.2036899]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023967320099473, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2036899 ]] | y: 0.10422316931421921 | Predicción actual: [[0.18808359]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008799192495644093, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2036899 ]\n",
      " [0.18808359]] | y: 0.15420379697791559 | Predicción actual: [[0.19247216]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018539561424404383, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2036899 ]\n",
      " [0.18808359]\n",
      " [0.19247216]] | y: 0.1557535838822161 | Predicción actual: [[0.20434701]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005441582296043634, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2036899 ]\n",
      " [0.18808359]\n",
      " [0.19247216]\n",
      " [0.20434701]] | y: 0.12553273924835334 | Predicción actual: [[0.21737264]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010734203271567822, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2036899 ]\n",
      " [0.18808359]\n",
      " [0.19247216]\n",
      " [0.20434701]\n",
      " [0.21737264]] | y: 0.1456799690042619 | Predicción actual: [[0.22766769]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005351285915821791, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.2036899 ]\n",
      " [0.18808359]\n",
      " [0.19247216]\n",
      " [0.20434701]\n",
      " [0.21737264]\n",
      " [0.22766769]] | y: 0.1464548624564122 | Predicción actual: [[0.2496844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019768305122852325, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.2036899 ]\n",
      " [0.18808359]\n",
      " [0.19247216]\n",
      " [0.20434701]\n",
      " [0.21737264]\n",
      " [0.22766769]\n",
      " [0.24968439]] | y: 0.1960480433940332 | Predicción actual: [[0.2767663]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006049732211977243, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2036899 ]\n",
      " [0.18808359]\n",
      " [0.19247216]\n",
      " [0.20434701]\n",
      " [0.21737264]\n",
      " [0.22766769]\n",
      " [0.24968439]\n",
      " [0.2767663 ]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016010049730539322, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18808359]\n",
      " [0.19247216]\n",
      " [0.20434701]\n",
      " [0.21737264]\n",
      " [0.22766769]\n",
      " [0.24968439]\n",
      " [0.2767663 ]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3117463]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022640720009803772, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19247216]\n",
      " [0.20434701]\n",
      " [0.21737264]\n",
      " [0.22766769]\n",
      " [0.24968439]\n",
      " [0.2767663 ]\n",
      " [0.2305308 ]\n",
      " [0.3117463 ]] | y: 0.211933359163115 | Predicción actual: [[0.3193772]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005213281139731407, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20434701]\n",
      " [0.21737264]\n",
      " [0.22766769]\n",
      " [0.24968439]\n",
      " [0.2767663 ]\n",
      " [0.2305308 ]\n",
      " [0.3117463 ]\n",
      " [0.31937721]] | y: 0.2072839984502131 | Predicción actual: [[0.32895577]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015210317447781563, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21737264]\n",
      " [0.22766769]\n",
      " [0.24968439]\n",
      " [0.2767663 ]\n",
      " [0.2305308 ]\n",
      " [0.3117463 ]\n",
      " [0.31937721]\n",
      " [0.32895577]] | y: 0.19294846958543205 | Predicción actual: [[0.33917516]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022259734570980072, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22766769]\n",
      " [0.24968439]\n",
      " [0.2767663 ]\n",
      " [0.2305308 ]\n",
      " [0.3117463 ]\n",
      " [0.31937721]\n",
      " [0.32895577]\n",
      " [0.33917516]] | y: 0.19682293684618352 | Predicción actual: [[0.34994182]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030023150146007538, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.24968439]\n",
      " [0.2767663 ]\n",
      " [0.2305308 ]\n",
      " [0.3117463 ]\n",
      " [0.31937721]\n",
      " [0.32895577]\n",
      " [0.33917516]\n",
      " [0.34994182]] | y: 0.21425803951956607 | Predicción actual: [[0.36200497]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026868032291531563, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2767663 ]\n",
      " [0.2305308 ]\n",
      " [0.3117463 ]\n",
      " [0.31937721]\n",
      " [0.32895577]\n",
      " [0.33917516]\n",
      " [0.34994182]\n",
      " [0.36200497]] | y: 0.18132506780317698 | Predicción actual: [[0.37265345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04268665984272957, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.3117463 ]\n",
      " [0.31937721]\n",
      " [0.32895577]\n",
      " [0.33917516]\n",
      " [0.34994182]\n",
      " [0.36200497]\n",
      " [0.37265345]] | y: 0.17512592018597434 | Predicción actual: [[0.38029024]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.037806279957294464, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3117463 ]\n",
      " [0.31937721]\n",
      " [0.32895577]\n",
      " [0.33917516]\n",
      " [0.34994182]\n",
      " [0.36200497]\n",
      " [0.37265345]\n",
      " [0.38029024]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07529395073652267, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31937721]\n",
      " [0.32895577]\n",
      " [0.33917516]\n",
      " [0.34994182]\n",
      " [0.36200497]\n",
      " [0.37265345]\n",
      " [0.38029024]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40818402]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06229245662689209, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32895577]\n",
      " [0.33917516]\n",
      " [0.34994182]\n",
      " [0.36200497]\n",
      " [0.37265345]\n",
      " [0.38029024]\n",
      " [0.14800465]\n",
      " [0.40818402]] | y: 0.19217357613328173 | Predicción actual: [[0.4124976]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007815467193722725, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.33917516]\n",
      " [0.34994182]\n",
      " [0.36200497]\n",
      " [0.37265345]\n",
      " [0.38029024]\n",
      " [0.14800465]\n",
      " [0.40818402]\n",
      " [0.41249761]] | y: 0.1859744285160791 | Predicción actual: [[0.4150688]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0384092703461647, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34994182]\n",
      " [0.36200497]\n",
      " [0.37265345]\n",
      " [0.38029024]\n",
      " [0.14800465]\n",
      " [0.40818402]\n",
      " [0.41249761]\n",
      " [0.41506881]] | y: 0.26695079426578844 | Predicción actual: [[0.41587016]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023035787045955658, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36200497]\n",
      " [0.37265345]\n",
      " [0.38029024]\n",
      " [0.14800465]\n",
      " [0.40818402]\n",
      " [0.41249761]\n",
      " [0.41506881]\n",
      " [0.41587016]] | y: 0.2925222781867493 | Predicción actual: [[0.41510606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029024042189121246, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37265345]\n",
      " [0.38029024]\n",
      " [0.14800465]\n",
      " [0.40818402]\n",
      " [0.41249761]\n",
      " [0.41506881]\n",
      " [0.41587016]\n",
      " [0.41510606]] | y: 0.3177063153816349 | Predicción actual: [[0.4127794]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01555420272052288, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.38029024]\n",
      " [0.14800465]\n",
      " [0.40818402]\n",
      " [0.41249761]\n",
      " [0.41506881]\n",
      " [0.41587016]\n",
      " [0.41510606]\n",
      " [0.41277939]] | y: 0.31266950794265785 | Predicción actual: [[0.40954578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009099170565605164, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40818402]\n",
      " [0.41249761]\n",
      " [0.41506881]\n",
      " [0.41587016]\n",
      " [0.41510606]\n",
      " [0.41277939]\n",
      " [0.40954578]] | y: 0.2890352576520729 | Predicción actual: [[0.40638167]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020990688353776932, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40818402]\n",
      " [0.41249761]\n",
      " [0.41506881]\n",
      " [0.41587016]\n",
      " [0.41510606]\n",
      " [0.41277939]\n",
      " [0.40954578]\n",
      " [0.40638167]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015620976686477661, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41249761]\n",
      " [0.41506881]\n",
      " [0.41587016]\n",
      " [0.41510606]\n",
      " [0.41277939]\n",
      " [0.40954578]\n",
      " [0.40638167]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.46356383]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02078770101070404, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41506881]\n",
      " [0.41587016]\n",
      " [0.41510606]\n",
      " [0.41277939]\n",
      " [0.40954578]\n",
      " [0.40638167]\n",
      " [0.28283611]\n",
      " [0.46356383]] | y: 0.2758620689655173 | Predicción actual: [[0.4615207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0481337271630764, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41587016]\n",
      " [0.41510606]\n",
      " [0.41277939]\n",
      " [0.40954578]\n",
      " [0.40638167]\n",
      " [0.28283611]\n",
      " [0.46356383]\n",
      " [0.4615207 ]] | y: 0.2746997287872917 | Predicción actual: [[0.45825356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.052698470652103424, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41510606]\n",
      " [0.41277939]\n",
      " [0.40954578]\n",
      " [0.40638167]\n",
      " [0.28283611]\n",
      " [0.46356383]\n",
      " [0.4615207 ]\n",
      " [0.45825356]] | y: 0.275474622239442 | Predicción actual: [[0.45467874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060048896819353104, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41277939]\n",
      " [0.40954578]\n",
      " [0.40638167]\n",
      " [0.28283611]\n",
      " [0.46356383]\n",
      " [0.4615207 ]\n",
      " [0.45825356]\n",
      " [0.45467874]] | y: 0.3347539713289423 | Predicción actual: [[0.45176685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014502557925879955, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40954578]\n",
      " [0.40638167]\n",
      " [0.28283611]\n",
      " [0.46356383]\n",
      " [0.4615207 ]\n",
      " [0.45825356]\n",
      " [0.45467874]\n",
      " [0.45176685]] | y: 0.35567609453700116 | Predicción actual: [[0.45058832]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001454995945096016, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40638167]\n",
      " [0.28283611]\n",
      " [0.46356383]\n",
      " [0.4615207 ]\n",
      " [0.45825356]\n",
      " [0.45467874]\n",
      " [0.45176685]\n",
      " [0.45058832]] | y: 0.3366912049593181 | Predicción actual: [[0.45191985]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007553489413112402, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.46356383]\n",
      " [0.4615207 ]\n",
      " [0.45825356]\n",
      " [0.45467874]\n",
      " [0.45176685]\n",
      " [0.45058832]\n",
      " [0.45191985]] | y: 0.3335916311507167 | Predicción actual: [[0.45609227]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044170115143060684, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46356383]\n",
      " [0.4615207 ]\n",
      " [0.45825356]\n",
      " [0.45467874]\n",
      " [0.45176685]\n",
      " [0.45058832]\n",
      " [0.45191985]\n",
      " [0.45609227]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015884416177868843, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4615207 ]\n",
      " [0.45825356]\n",
      " [0.45467874]\n",
      " [0.45176685]\n",
      " [0.45058832]\n",
      " [0.45191985]\n",
      " [0.45609227]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.49103966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00075953034684062, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45825356]\n",
      " [0.45467874]\n",
      " [0.45176685]\n",
      " [0.45058832]\n",
      " [0.45191985]\n",
      " [0.45609227]\n",
      " [0.3847346 ]\n",
      " [0.49103966]] | y: 0.5962805114296785 | Predicción actual: [[0.48777768]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007196439895778894, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45467874]\n",
      " [0.45176685]\n",
      " [0.45058832]\n",
      " [0.45191985]\n",
      " [0.45609227]\n",
      " [0.3847346 ]\n",
      " [0.49103966]\n",
      " [0.48777768]] | y: 0.574583494769469 | Predicción actual: [[0.48512557]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005018643569201231, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45176685]\n",
      " [0.45058832]\n",
      " [0.45191985]\n",
      " [0.45609227]\n",
      " [0.3847346 ]\n",
      " [0.49103966]\n",
      " [0.48777768]\n",
      " [0.48512557]] | y: 0.6063541263076326 | Predicción actual: [[0.4836213]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03191893920302391, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45058832]\n",
      " [0.45191985]\n",
      " [0.45609227]\n",
      " [0.3847346 ]\n",
      " [0.49103966]\n",
      " [0.48777768]\n",
      " [0.48512557]\n",
      " [0.4836213 ]] | y: 0.5846571096474236 | Predicción actual: [[0.48363152]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013369263149797916, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45191985]\n",
      " [0.45609227]\n",
      " [0.3847346 ]\n",
      " [0.49103966]\n",
      " [0.48777768]\n",
      " [0.48512557]\n",
      " [0.4836213 ]\n",
      " [0.48363152]] | y: 0.5687717938783416 | Predicción actual: [[0.48508033]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015984877943992615, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45609227]\n",
      " [0.3847346 ]\n",
      " [0.49103966]\n",
      " [0.48777768]\n",
      " [0.48512557]\n",
      " [0.4836213 ]\n",
      " [0.48363152]\n",
      " [0.48508033]] | y: 0.6427741185586981 | Predicción actual: [[0.4876005]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008289909455925226, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.49103966]\n",
      " [0.48777768]\n",
      " [0.48512557]\n",
      " [0.4836213 ]\n",
      " [0.48363152]\n",
      " [0.48508033]\n",
      " [0.48760051]] | y: 0.6617590081363811 | Predicción actual: [[0.49053088]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004894059617072344, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49103966]\n",
      " [0.48777768]\n",
      " [0.48512557]\n",
      " [0.4836213 ]\n",
      " [0.48363152]\n",
      " [0.48508033]\n",
      " [0.48760051]\n",
      " [0.49053088]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0520724318921566, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48777768]\n",
      " [0.48512557]\n",
      " [0.4836213 ]\n",
      " [0.48363152]\n",
      " [0.48508033]\n",
      " [0.48760051]\n",
      " [0.49053088]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.51350504]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030544573441147804, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48512557]\n",
      " [0.4836213 ]\n",
      " [0.48363152]\n",
      " [0.48508033]\n",
      " [0.48760051]\n",
      " [0.49053088]\n",
      " [0.67299496]\n",
      " [0.51350504]] | y: 0.703990701278574 | Predicción actual: [[0.51603186]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04592769965529442, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.4836213 ]\n",
      " [0.48363152]\n",
      " [0.48508033]\n",
      " [0.48760051]\n",
      " [0.49053088]\n",
      " [0.67299496]\n",
      " [0.51350504]\n",
      " [0.51603186]] | y: 0.7272375048430839 | Predicción actual: [[0.52143914]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.040596723556518555, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48363152]\n",
      " [0.48508033]\n",
      " [0.48760051]\n",
      " [0.49053088]\n",
      " [0.67299496]\n",
      " [0.51350504]\n",
      " [0.51603186]\n",
      " [0.52143914]] | y: 0.722588144130182 | Predicción actual: [[0.5296424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03648734837770462, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48508033]\n",
      " [0.48760051]\n",
      " [0.49053088]\n",
      " [0.67299496]\n",
      " [0.51350504]\n",
      " [0.51603186]\n",
      " [0.52143914]\n",
      " [0.5296424 ]] | y: 0.771793878341728 | Predicción actual: [[0.5402496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08267300575971603, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48760051]\n",
      " [0.49053088]\n",
      " [0.67299496]\n",
      " [0.51350504]\n",
      " [0.51603186]\n",
      " [0.52143914]\n",
      " [0.5296424 ]\n",
      " [0.54024959]] | y: 0.7245253777605578 | Predicción actual: [[0.55281776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005540825892239809, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.49053088]\n",
      " [0.67299496]\n",
      " [0.51350504]\n",
      " [0.51603186]\n",
      " [0.52143914]\n",
      " [0.5296424 ]\n",
      " [0.54024959]\n",
      " [0.55281776]] | y: 0.6710577295621851 | Predicción actual: [[0.5667382]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02041192539036274, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.51350504]\n",
      " [0.51603186]\n",
      " [0.52143914]\n",
      " [0.5296424 ]\n",
      " [0.54024959]\n",
      " [0.55281776]\n",
      " [0.56673819]] | y: 0.6737698566447115 | Predicción actual: [[0.58177423]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023137064650654793, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51350504]\n",
      " [0.51603186]\n",
      " [0.52143914]\n",
      " [0.5296424 ]\n",
      " [0.54024959]\n",
      " [0.55281776]\n",
      " [0.56673819]\n",
      " [0.58177423]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04579535499215126, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51603186]\n",
      " [0.52143914]\n",
      " [0.5296424 ]\n",
      " [0.54024959]\n",
      " [0.55281776]\n",
      " [0.56673819]\n",
      " [0.58177423]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.5565468]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02091694436967373, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52143914]\n",
      " [0.5296424 ]\n",
      " [0.54024959]\n",
      " [0.55281776]\n",
      " [0.56673819]\n",
      " [0.58177423]\n",
      " [0.71445176]\n",
      " [0.55654681]] | y: 0.722588144130182 | Predicción actual: [[0.56699026]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019312135875225067, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5296424 ]\n",
      " [0.54024959]\n",
      " [0.55281776]\n",
      " [0.56673819]\n",
      " [0.58177423]\n",
      " [0.71445176]\n",
      " [0.55654681]\n",
      " [0.56699026]] | y: 0.6993413405656723 | Predicción actual: [[0.5794698]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005928012076765299, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.54024959]\n",
      " [0.55281776]\n",
      " [0.56673819]\n",
      " [0.58177423]\n",
      " [0.71445176]\n",
      " [0.55654681]\n",
      " [0.56699026]\n",
      " [0.5794698 ]] | y: 0.7373111197210385 | Predicción actual: [[0.59289926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05498127266764641, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55281776]\n",
      " [0.56673819]\n",
      " [0.58177423]\n",
      " [0.71445176]\n",
      " [0.55654681]\n",
      " [0.56699026]\n",
      " [0.5794698 ]\n",
      " [0.59289926]] | y: 0.7214258039519565 | Predicción actual: [[0.60623246]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01848691515624523, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56673819]\n",
      " [0.58177423]\n",
      " [0.71445176]\n",
      " [0.55654681]\n",
      " [0.56699026]\n",
      " [0.5794698 ]\n",
      " [0.59289926]\n",
      " [0.60623246]] | y: 0.7187136768694304 | Predicción actual: [[0.61826277]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006526992656290531, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58177423]\n",
      " [0.71445176]\n",
      " [0.55654681]\n",
      " [0.56699026]\n",
      " [0.5794698 ]\n",
      " [0.59289926]\n",
      " [0.60623246]\n",
      " [0.61826277]] | y: 0.6741573033707864 | Predicción actual: [[0.62797177]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006541467737406492, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55654681]\n",
      " [0.56699026]\n",
      " [0.5794698 ]\n",
      " [0.59289926]\n",
      " [0.60623246]\n",
      " [0.61826277]\n",
      " [0.62797177]] | y: 0.698566447113522 | Predicción actual: [[0.6344145]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007664613425731659, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55654681]\n",
      " [0.56699026]\n",
      " [0.5794698 ]\n",
      " [0.59289926]\n",
      " [0.60623246]\n",
      " [0.61826277]\n",
      " [0.62797177]\n",
      " [0.63441449]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006978347897529602, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56699026]\n",
      " [0.5794698 ]\n",
      " [0.59289926]\n",
      " [0.60623246]\n",
      " [0.61826277]\n",
      " [0.62797177]\n",
      " [0.63441449]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.6159852]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006783478893339634, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.5794698 ]\n",
      " [0.59289926]\n",
      " [0.60623246]\n",
      " [0.61826277]\n",
      " [0.62797177]\n",
      " [0.63441449]\n",
      " [0.72103836]\n",
      " [0.61598521]] | y: 0.7562960092987214 | Predicción actual: [[0.62861156]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00111616519279778, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59289926]\n",
      " [0.60623246]\n",
      " [0.61826277]\n",
      " [0.62797177]\n",
      " [0.63441449]\n",
      " [0.72103836]\n",
      " [0.61598521]\n",
      " [0.62861156]] | y: 0.8275862068965516 | Predicción actual: [[0.6410711]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008206680067814887, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60623246]\n",
      " [0.61826277]\n",
      " [0.62797177]\n",
      " [0.63441449]\n",
      " [0.72103836]\n",
      " [0.61598521]\n",
      " [0.62861156]\n",
      " [0.64107108]] | y: 0.8388221619527314 | Predicción actual: [[0.65254503]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01572982594370842, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61826277]\n",
      " [0.62797177]\n",
      " [0.63441449]\n",
      " [0.72103836]\n",
      " [0.61598521]\n",
      " [0.62861156]\n",
      " [0.64107108]\n",
      " [0.65254503]] | y: 0.7942657884540876 | Predicción actual: [[0.66255903]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00020648389181587845, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62797177]\n",
      " [0.63441449]\n",
      " [0.72103836]\n",
      " [0.61598521]\n",
      " [0.62861156]\n",
      " [0.64107108]\n",
      " [0.65254503]\n",
      " [0.66255903]] | y: 0.7838047268500579 | Predicción actual: [[0.6707759]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05646275356411934, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63441449]\n",
      " [0.72103836]\n",
      " [0.61598521]\n",
      " [0.62861156]\n",
      " [0.64107108]\n",
      " [0.65254503]\n",
      " [0.66255903]\n",
      " [0.67077589]] | y: 0.7679194110809764 | Predicción actual: [[0.6776479]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006626159884035587, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.61598521]\n",
      " [0.62861156]\n",
      " [0.64107108]\n",
      " [0.65254503]\n",
      " [0.66255903]\n",
      " [0.67077589]\n",
      " [0.67764789]] | y: 0.7845796203022084 | Predicción actual: [[0.68373346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008147701621055603, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61598521]\n",
      " [0.62861156]\n",
      " [0.64107108]\n",
      " [0.65254503]\n",
      " [0.66255903]\n",
      " [0.67077589]\n",
      " [0.67764789]\n",
      " [0.68373346]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08087460696697235, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62861156]\n",
      " [0.64107108]\n",
      " [0.65254503]\n",
      " [0.66255903]\n",
      " [0.67077589]\n",
      " [0.67764789]\n",
      " [0.68373346]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.6782004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029391102492809296, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64107108]\n",
      " [0.65254503]\n",
      " [0.66255903]\n",
      " [0.67077589]\n",
      " [0.67764789]\n",
      " [0.68373346]\n",
      " [0.87872917]\n",
      " [0.67820042]] | y: 0.8488957768306855 | Predicción actual: [[0.6917307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04483666270971298, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.65254503]\n",
      " [0.66255903]\n",
      " [0.67077589]\n",
      " [0.67764789]\n",
      " [0.68373346]\n",
      " [0.87872917]\n",
      " [0.67820042]\n",
      " [0.69173068]] | y: 0.8182874854707476 | Predicción actual: [[0.7060179]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022827457636594772, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66255903]\n",
      " [0.67077589]\n",
      " [0.67764789]\n",
      " [0.68373346]\n",
      " [0.87872917]\n",
      " [0.67820042]\n",
      " [0.69173068]\n",
      " [0.70601791]] | y: 0.8268113134444013 | Predicción actual: [[0.72079307]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0838443860411644, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67077589]\n",
      " [0.67764789]\n",
      " [0.68373346]\n",
      " [0.87872917]\n",
      " [0.67820042]\n",
      " [0.69173068]\n",
      " [0.70601791]\n",
      " [0.72079307]] | y: 0.7853545137543589 | Predicción actual: [[0.73601586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002272986574098468, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67764789]\n",
      " [0.68373346]\n",
      " [0.87872917]\n",
      " [0.67820042]\n",
      " [0.69173068]\n",
      " [0.70601791]\n",
      " [0.72079307]\n",
      " [0.73601586]] | y: 0.7892289810151103 | Predicción actual: [[0.75143445]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003331083105877042, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68373346]\n",
      " [0.87872917]\n",
      " [0.67820042]\n",
      " [0.69173068]\n",
      " [0.70601791]\n",
      " [0.72079307]\n",
      " [0.73601586]\n",
      " [0.75143445]] | y: 0.8341728012398295 | Predicción actual: [[0.7670458]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0039789751172065735, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.67820042]\n",
      " [0.69173068]\n",
      " [0.70601791]\n",
      " [0.72079307]\n",
      " [0.73601586]\n",
      " [0.75143445]\n",
      " [0.7670458 ]] | y: 0.8124757845796202 | Predicción actual: [[0.7828247]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007482083048671484, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67820042]\n",
      " [0.69173068]\n",
      " [0.70601791]\n",
      " [0.72079307]\n",
      " [0.73601586]\n",
      " [0.75143445]\n",
      " [0.7670458 ]\n",
      " [0.7828247 ]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023932287469506264, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69173068]\n",
      " [0.70601791]\n",
      " [0.72079307]\n",
      " [0.73601586]\n",
      " [0.75143445]\n",
      " [0.7670458 ]\n",
      " [0.7828247 ]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.7560018]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005456187296658754, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.70601791]\n",
      " [0.72079307]\n",
      " [0.73601586]\n",
      " [0.75143445]\n",
      " [0.7670458 ]\n",
      " [0.7828247 ]\n",
      " [0.80123983]\n",
      " [0.75600177]] | y: 0.793490895001937 | Predicción actual: [[0.77150023]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00031596541521139443, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72079307]\n",
      " [0.73601586]\n",
      " [0.75143445]\n",
      " [0.7670458 ]\n",
      " [0.7828247 ]\n",
      " [0.80123983]\n",
      " [0.75600177]\n",
      " [0.77150023]] | y: 0.760170476559473 | Predicción actual: [[0.7863783]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017247604206204414, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.73601586]\n",
      " [0.75143445]\n",
      " [0.7670458 ]\n",
      " [0.7828247 ]\n",
      " [0.80123983]\n",
      " [0.75600177]\n",
      " [0.77150023]\n",
      " [0.78637832]] | y: 0.7353738860906625 | Predicción actual: [[0.79964805]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012501789256930351, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75143445]\n",
      " [0.7670458 ]\n",
      " [0.7828247 ]\n",
      " [0.80123983]\n",
      " [0.75600177]\n",
      " [0.77150023]\n",
      " [0.78637832]\n",
      " [0.79964805]] | y: 0.7101898488957767 | Predicción actual: [[0.81067294]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005406393320299685, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7670458 ]\n",
      " [0.7828247 ]\n",
      " [0.80123983]\n",
      " [0.75600177]\n",
      " [0.77150023]\n",
      " [0.78637832]\n",
      " [0.79964805]\n",
      " [0.81067294]] | y: 0.7121270825261525 | Predicción actual: [[0.8190603]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0690757335396484e-05, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7828247 ]\n",
      " [0.80123983]\n",
      " [0.75600177]\n",
      " [0.77150023]\n",
      " [0.78637832]\n",
      " [0.79964805]\n",
      " [0.81067294]\n",
      " [0.81906033]] | y: 0.7396358000774894 | Predicción actual: [[0.82437927]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023174144327640533, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.75600177]\n",
      " [0.77150023]\n",
      " [0.78637832]\n",
      " [0.79964805]\n",
      " [0.81067294]\n",
      " [0.81906033]\n",
      " [0.82437927]] | y: 0.7361487795428128 | Predicción actual: [[0.82599556]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026468632742762566, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75600177]\n",
      " [0.77150023]\n",
      " [0.78637832]\n",
      " [0.79964805]\n",
      " [0.81067294]\n",
      " [0.81906033]\n",
      " [0.82437927]\n",
      " [0.82599556]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017962805926799774, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77150023]\n",
      " [0.78637832]\n",
      " [0.79964805]\n",
      " [0.81067294]\n",
      " [0.81906033]\n",
      " [0.82437927]\n",
      " [0.82599556]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.8340367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009625646285712719, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78637832]\n",
      " [0.79964805]\n",
      " [0.81067294]\n",
      " [0.81906033]\n",
      " [0.82437927]\n",
      " [0.82599556]\n",
      " [0.66757071]\n",
      " [0.83403671]] | y: 0.696629213483146 | Predicción actual: [[0.84180224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01406116969883442, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79964805]\n",
      " [0.81067294]\n",
      " [0.81906033]\n",
      " [0.82437927]\n",
      " [0.82599556]\n",
      " [0.66757071]\n",
      " [0.83403671]\n",
      " [0.84180224]] | y: 0.6559473072452537 | Predicción actual: [[0.8456823]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08115983009338379, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81067294]\n",
      " [0.81906033]\n",
      " [0.82437927]\n",
      " [0.82599556]\n",
      " [0.66757071]\n",
      " [0.83403671]\n",
      " [0.84180224]\n",
      " [0.84568232]] | y: 0.6788066640836885 | Predicción actual: [[0.84543705]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006789478939026594, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81906033]\n",
      " [0.82437927]\n",
      " [0.82599556]\n",
      " [0.66757071]\n",
      " [0.83403671]\n",
      " [0.84180224]\n",
      " [0.84568232]\n",
      " [0.84543705]] | y: 0.6760945370011622 | Predicción actual: [[0.842221]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06584491580724716, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82437927]\n",
      " [0.82599556]\n",
      " [0.66757071]\n",
      " [0.83403671]\n",
      " [0.84180224]\n",
      " [0.84568232]\n",
      " [0.84543705]\n",
      " [0.84222102]] | y: 0.7295621851995349 | Predicción actual: [[0.8366446]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04933016747236252, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82599556]\n",
      " [0.66757071]\n",
      " [0.83403671]\n",
      " [0.84180224]\n",
      " [0.84568232]\n",
      " [0.84543705]\n",
      " [0.84222102]\n",
      " [0.83664459]] | y: 0.7012785741960481 | Predicción actual: [[0.8300926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017287438735365868, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.83403671]\n",
      " [0.84180224]\n",
      " [0.84568232]\n",
      " [0.84543705]\n",
      " [0.84222102]\n",
      " [0.83664459]\n",
      " [0.83009261]] | y: 0.767531964354901 | Predicción actual: [[0.8243214]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008121907711029053, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83403671]\n",
      " [0.84180224]\n",
      " [0.84568232]\n",
      " [0.84543705]\n",
      " [0.84222102]\n",
      " [0.83664459]\n",
      " [0.83009261]\n",
      " [0.82432139]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011847051791846752, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84180224]\n",
      " [0.84568232]\n",
      " [0.84543705]\n",
      " [0.84222102]\n",
      " [0.83664459]\n",
      " [0.83009261]\n",
      " [0.82432139]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8686219]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01799052208662033, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84568232]\n",
      " [0.84543705]\n",
      " [0.84222102]\n",
      " [0.83664459]\n",
      " [0.83009261]\n",
      " [0.82432139]\n",
      " [0.75513367]\n",
      " [0.86862189]] | y: 0.7520340953118947 | Predicción actual: [[0.86456454]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022810116410255432, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84543705]\n",
      " [0.84222102]\n",
      " [0.83664459]\n",
      " [0.83009261]\n",
      " [0.82432139]\n",
      " [0.75513367]\n",
      " [0.86862189]\n",
      " [0.86456454]] | y: 0.7098024021697016 | Predicción actual: [[0.85838884]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014499320648610592, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84222102]\n",
      " [0.83664459]\n",
      " [0.83009261]\n",
      " [0.82432139]\n",
      " [0.75513367]\n",
      " [0.86862189]\n",
      " [0.86456454]\n",
      " [0.85838884]] | y: 0.6904300658659435 | Predicción actual: [[0.851711]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0790739357471466, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83664459]\n",
      " [0.83009261]\n",
      " [0.82432139]\n",
      " [0.75513367]\n",
      " [0.86862189]\n",
      " [0.86456454]\n",
      " [0.85838884]\n",
      " [0.85171098]] | y: 0.7543587756683454 | Predicción actual: [[0.84552795]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031851569656282663, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83009261]\n",
      " [0.82432139]\n",
      " [0.75513367]\n",
      " [0.86862189]\n",
      " [0.86456454]\n",
      " [0.85838884]\n",
      " [0.85171098]\n",
      " [0.84552795]] | y: 0.7222006974041069 | Predicción actual: [[0.84162956]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.11985158175230026, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82432139]\n",
      " [0.75513367]\n",
      " [0.86862189]\n",
      " [0.86456454]\n",
      " [0.85838884]\n",
      " [0.85171098]\n",
      " [0.84552795]\n",
      " [0.84162956]] | y: 0.8485083301046106 | Predicción actual: [[0.8400586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027704949025064707, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.86862189]\n",
      " [0.86456454]\n",
      " [0.85838884]\n",
      " [0.85171098]\n",
      " [0.84552795]\n",
      " [0.84162956]\n",
      " [0.84005862]] | y: 0.9054629988376597 | Predicción actual: [[0.8418309]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018633389845490456, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86862189]\n",
      " [0.86456454]\n",
      " [0.85838884]\n",
      " [0.85171098]\n",
      " [0.84552795]\n",
      " [0.84162956]\n",
      " [0.84005862]\n",
      " [0.84183091]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0024101058952510357, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86456454]\n",
      " [0.85838884]\n",
      " [0.85171098]\n",
      " [0.84552795]\n",
      " [0.84162956]\n",
      " [0.84005862]\n",
      " [0.84183091]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8602083]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005432825069874525, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85838884]\n",
      " [0.85171098]\n",
      " [0.84552795]\n",
      " [0.84162956]\n",
      " [0.84005862]\n",
      " [0.84183091]\n",
      " [0.8822162 ]\n",
      " [0.86020827]] | y: 0.889577683068578 | Predicción actual: [[0.8547223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 2.3320866660014872e-07, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85171098]\n",
      " [0.84552795]\n",
      " [0.84162956]\n",
      " [0.84005862]\n",
      " [0.84183091]\n",
      " [0.8822162 ]\n",
      " [0.86020827]\n",
      " [0.85472232]] | y: 0.8748547074777218 | Predicción actual: [[0.8509373]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.017155826091766357, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84552795]\n",
      " [0.84162956]\n",
      " [0.84005862]\n",
      " [0.84183091]\n",
      " [0.8822162 ]\n",
      " [0.86020827]\n",
      " [0.85472232]\n",
      " [0.85093731]] | y: 0.9132119333591631 | Predicción actual: [[0.8495844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009511474519968033, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84162956]\n",
      " [0.84005862]\n",
      " [0.84183091]\n",
      " [0.8822162 ]\n",
      " [0.86020827]\n",
      " [0.85472232]\n",
      " [0.85093731]\n",
      " [0.8495844 ]] | y: 1.0 | Predicción actual: [[0.8503227]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008269606158137321, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84005862]\n",
      " [0.84183091]\n",
      " [0.8822162 ]\n",
      " [0.86020827]\n",
      " [0.85472232]\n",
      " [0.85093731]\n",
      " [0.8495844 ]\n",
      " [0.85032272]] | y: 0.9705540488182873 | Predicción actual: [[0.85305053]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.034628577530384064, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84183091]\n",
      " [0.8822162 ]\n",
      " [0.86020827]\n",
      " [0.85472232]\n",
      " [0.85093731]\n",
      " [0.8495844 ]\n",
      " [0.85032272]\n",
      " [0.85305053]] | y: 0.8888027896164277 | Predicción actual: [[0.85720724]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006844745017588139, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.86020827]\n",
      " [0.85472232]\n",
      " [0.85093731]\n",
      " [0.8495844 ]\n",
      " [0.85032272]\n",
      " [0.85305053]\n",
      " [0.85720724]] | y: 0.877954281286323 | Predicción actual: [[0.86145407]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003261662321165204, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86020827]\n",
      " [0.85472232]\n",
      " [0.85093731]\n",
      " [0.8495844 ]\n",
      " [0.85032272]\n",
      " [0.85305053]\n",
      " [0.85720724]\n",
      " [0.86145407]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002080370904877782, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85472232]\n",
      " [0.85093731]\n",
      " [0.8495844 ]\n",
      " [0.85032272]\n",
      " [0.85305053]\n",
      " [0.85720724]\n",
      " [0.86145407]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.85165393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003097061300650239, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85093731]\n",
      " [0.8495844 ]\n",
      " [0.85032272]\n",
      " [0.85305053]\n",
      " [0.85720724]\n",
      " [0.86145407]\n",
      " [0.84889578]\n",
      " [0.85165393]] | y: 0.8550949244478885 | Predicción actual: [[0.85107046]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.035539258271455765, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8495844 ]\n",
      " [0.85032272]\n",
      " [0.85305053]\n",
      " [0.85720724]\n",
      " [0.86145407]\n",
      " [0.84889578]\n",
      " [0.85165393]\n",
      " [0.85107046]] | y: 0.8752421542037967 | Predicción actual: [[0.85192424]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0027248545084148645, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85032272]\n",
      " [0.85305053]\n",
      " [0.85720724]\n",
      " [0.86145407]\n",
      " [0.84889578]\n",
      " [0.85165393]\n",
      " [0.85107046]\n",
      " [0.85192424]] | y: 0.857032158078264 | Predicción actual: [[0.8533728]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004627862013876438, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85305053]\n",
      " [0.85720724]\n",
      " [0.86145407]\n",
      " [0.84889578]\n",
      " [0.85165393]\n",
      " [0.85107046]\n",
      " [0.85192424]\n",
      " [0.85337281]] | y: 0.8500581170089112 | Predicción actual: [[0.8545427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.6020351621555164e-05, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85720724]\n",
      " [0.86145407]\n",
      " [0.84889578]\n",
      " [0.85165393]\n",
      " [0.85107046]\n",
      " [0.85192424]\n",
      " [0.85337281]\n",
      " [0.85454267]] | y: 0.8426966292134832 | Predicción actual: [[0.854906]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0018686522962525487, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86145407]\n",
      " [0.84889578]\n",
      " [0.85165393]\n",
      " [0.85107046]\n",
      " [0.85192424]\n",
      " [0.85337281]\n",
      " [0.85454267]\n",
      " [0.85490602]] | y: 0.8229368461836497 | Predicción actual: [[0.8538514]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006774339126423001, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.85165393]\n",
      " [0.85107046]\n",
      " [0.85192424]\n",
      " [0.85337281]\n",
      " [0.85454267]\n",
      " [0.85490602]\n",
      " [0.85385138]] | y: 0.7745060054242543 | Predicción actual: [[0.8513785]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007015162147581577, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85165393]\n",
      " [0.85107046]\n",
      " [0.85192424]\n",
      " [0.85337281]\n",
      " [0.85454267]\n",
      " [0.85490602]\n",
      " [0.85385138]\n",
      " [0.8513785 ]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012433771044015884, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85107046]\n",
      " [0.85192424]\n",
      " [0.85337281]\n",
      " [0.85454267]\n",
      " [0.85490602]\n",
      " [0.85385138]\n",
      " [0.8513785 ]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.85243154]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012625609524548054, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85192424]\n",
      " [0.85337281]\n",
      " [0.85454267]\n",
      " [0.85490602]\n",
      " [0.85385138]\n",
      " [0.8513785 ]\n",
      " [0.78419217]\n",
      " [0.85243154]] | y: 0.854320030995738 | Predicción actual: [[0.85183936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002995092188939452, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85337281]\n",
      " [0.85454267]\n",
      " [0.85490602]\n",
      " [0.85385138]\n",
      " [0.8513785 ]\n",
      " [0.78419217]\n",
      " [0.85243154]\n",
      " [0.85183936]] | y: 0.8368849283223556 | Predicción actual: [[0.8502551]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03192991018295288, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85454267]\n",
      " [0.85490602]\n",
      " [0.85385138]\n",
      " [0.8513785 ]\n",
      " [0.78419217]\n",
      " [0.85243154]\n",
      " [0.85183936]\n",
      " [0.85025507]] | y: 0.8299108872530028 | Predicción actual: [[0.847862]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02150600031018257, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85490602]\n",
      " [0.85385138]\n",
      " [0.8513785 ]\n",
      " [0.78419217]\n",
      " [0.85243154]\n",
      " [0.85183936]\n",
      " [0.85025507]\n",
      " [0.84786201]] | y: 0.887253002712127 | Predicción actual: [[0.8447207]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03713904321193695, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85385138]\n",
      " [0.8513785 ]\n",
      " [0.78419217]\n",
      " [0.85243154]\n",
      " [0.85183936]\n",
      " [0.85025507]\n",
      " [0.84786201]\n",
      " [0.84472072]] | y: 0.8597442851607902 | Predicción actual: [[0.8412274]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0014385456452146173, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8513785 ]\n",
      " [0.78419217]\n",
      " [0.85243154]\n",
      " [0.85183936]\n",
      " [0.85025507]\n",
      " [0.84786201]\n",
      " [0.84472072]\n",
      " [0.84122741]] | y: 0.8395970554048819 | Predicción actual: [[0.83771306]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.717234954412561e-05, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.85243154]\n",
      " [0.85183936]\n",
      " [0.85025507]\n",
      " [0.84786201]\n",
      " [0.84472072]\n",
      " [0.84122741]\n",
      " [0.83771306]] | y: 0.7838047268500579 | Predicción actual: [[0.83473456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010005045915022492, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85243154]\n",
      " [0.85183936]\n",
      " [0.85025507]\n",
      " [0.84786201]\n",
      " [0.84472072]\n",
      " [0.84122741]\n",
      " [0.83771306]\n",
      " [0.83473456]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03692331537604332, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85183936]\n",
      " [0.85025507]\n",
      " [0.84786201]\n",
      " [0.84472072]\n",
      " [0.84122741]\n",
      " [0.83771306]\n",
      " [0.83473456]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.8499668]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031312613282352686, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85025507]\n",
      " [0.84786201]\n",
      " [0.84472072]\n",
      " [0.84122741]\n",
      " [0.83771306]\n",
      " [0.83473456]\n",
      " [0.81828749]\n",
      " [0.84996682]] | y: 0.7605579232855482 | Predicción actual: [[0.84725356]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00012880031135864556, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84786201]\n",
      " [0.84472072]\n",
      " [0.84122741]\n",
      " [0.83771306]\n",
      " [0.83473456]\n",
      " [0.81828749]\n",
      " [0.84996682]\n",
      " [0.84725356]] | y: 0.7915536613715615 | Predicción actual: [[0.84434116]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006139013450592756, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84472072]\n",
      " [0.84122741]\n",
      " [0.83771306]\n",
      " [0.83473456]\n",
      " [0.81828749]\n",
      " [0.84996682]\n",
      " [0.84725356]\n",
      " [0.84434116]] | y: 0.7686943045331267 | Predicción actual: [[0.8415117]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002805018099024892, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84122741]\n",
      " [0.83771306]\n",
      " [0.83473456]\n",
      " [0.81828749]\n",
      " [0.84996682]\n",
      " [0.84725356]\n",
      " [0.84434116]\n",
      " [0.84151173]] | y: 0.7686943045331267 | Predicción actual: [[0.8392753]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02593054436147213, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83771306]\n",
      " [0.83473456]\n",
      " [0.81828749]\n",
      " [0.84996682]\n",
      " [0.84725356]\n",
      " [0.84434116]\n",
      " [0.84151173]\n",
      " [0.8392753 ]] | y: 0.7989151491669895 | Predicción actual: [[0.8377218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.353571370709687e-05, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83473456]\n",
      " [0.81828749]\n",
      " [0.84996682]\n",
      " [0.84725356]\n",
      " [0.84434116]\n",
      " [0.84151173]\n",
      " [0.8392753 ]\n",
      " [0.83772182]] | y: 0.7900038744672608 | Predicción actual: [[0.83738685]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002201022347435355, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.84996682]\n",
      " [0.84725356]\n",
      " [0.84434116]\n",
      " [0.84151173]\n",
      " [0.8392753 ]\n",
      " [0.83772182]\n",
      " [0.83738685]] | y: 0.760170476559473 | Predicción actual: [[0.83815473]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00016938484623096883, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84996682]\n",
      " [0.84725356]\n",
      " [0.84434116]\n",
      " [0.84151173]\n",
      " [0.8392753 ]\n",
      " [0.83772182]\n",
      " [0.83738685]\n",
      " [0.83815473]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006882175337523222, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84725356]\n",
      " [0.84434116]\n",
      " [0.84151173]\n",
      " [0.8392753 ]\n",
      " [0.83772182]\n",
      " [0.83738685]\n",
      " [0.83815473]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.84050345]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.038677141070365906, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84434116]\n",
      " [0.84151173]\n",
      " [0.8392753 ]\n",
      " [0.83772182]\n",
      " [0.83738685]\n",
      " [0.83815473]\n",
      " [0.68539326]\n",
      " [0.84050345]] | y: 0.6648585819449826 | Predicción actual: [[0.8354094]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03070063330233097, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84151173]\n",
      " [0.8392753 ]\n",
      " [0.83772182]\n",
      " [0.83738685]\n",
      " [0.83815473]\n",
      " [0.68539326]\n",
      " [0.84050345]\n",
      " [0.8354094 ]] | y: 0.7078651685393258 | Predicción actual: [[0.82901704]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01930338889360428, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8392753 ]\n",
      " [0.83772182]\n",
      " [0.83738685]\n",
      " [0.83815473]\n",
      " [0.68539326]\n",
      " [0.84050345]\n",
      " [0.8354094 ]\n",
      " [0.82901704]] | y: 0.6648585819449826 | Predicción actual: [[0.8215932]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0571095310151577, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83772182]\n",
      " [0.83738685]\n",
      " [0.83815473]\n",
      " [0.68539326]\n",
      " [0.84050345]\n",
      " [0.8354094 ]\n",
      " [0.82901704]\n",
      " [0.82159323]] | y: 0.7113521890740022 | Predicción actual: [[0.8130986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000828609976451844, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83738685]\n",
      " [0.83815473]\n",
      " [0.68539326]\n",
      " [0.84050345]\n",
      " [0.8354094 ]\n",
      " [0.82901704]\n",
      " [0.82159323]\n",
      " [0.81309861]] | y: 0.6772568771793879 | Predicción actual: [[0.8041456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004139128606766462, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83815473]\n",
      " [0.68539326]\n",
      " [0.84050345]\n",
      " [0.8354094 ]\n",
      " [0.82901704]\n",
      " [0.82159323]\n",
      " [0.81309861]\n",
      " [0.80414557]] | y: 0.7621077101898488 | Predicción actual: [[0.7946224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0447764907439705e-05, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84050345]\n",
      " [0.8354094 ]\n",
      " [0.82901704]\n",
      " [0.82159323]\n",
      " [0.81309861]\n",
      " [0.80414557]\n",
      " [0.79462242]] | y: 0.8070515304145678 | Predicción actual: [[0.7845278]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0028528247494250536, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84050345]\n",
      " [0.8354094 ]\n",
      " [0.82901704]\n",
      " [0.82159323]\n",
      " [0.81309861]\n",
      " [0.80414557]\n",
      " [0.79462242]\n",
      " [0.78452778]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020289355888962746, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8354094 ]\n",
      " [0.82901704]\n",
      " [0.82159323]\n",
      " [0.81309861]\n",
      " [0.80414557]\n",
      " [0.79462242]\n",
      " [0.78452778]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.81206]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012732932344079018, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82901704]\n",
      " [0.82159323]\n",
      " [0.81309861]\n",
      " [0.80414557]\n",
      " [0.79462242]\n",
      " [0.78452778]\n",
      " [0.81518791]\n",
      " [0.81206   ]] | y: 0.9597055404881829 | Predicción actual: [[0.8051022]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0525827631354332, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.82159323]\n",
      " [0.81309861]\n",
      " [0.80414557]\n",
      " [0.79462242]\n",
      " [0.78452778]\n",
      " [0.81518791]\n",
      " [0.81206   ]\n",
      " [0.80510223]] | y: 0.9643549012010848 | Predicción actual: [[0.7990539]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011087012477219105, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81309861]\n",
      " [0.80414557]\n",
      " [0.79462242]\n",
      " [0.78452778]\n",
      " [0.81518791]\n",
      " [0.81206   ]\n",
      " [0.80510223]\n",
      " [0.79905391]] | y: 0.8880278961642774 | Predicción actual: [[0.7943418]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04975225776433945, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80414557]\n",
      " [0.79462242]\n",
      " [0.78452778]\n",
      " [0.81518791]\n",
      " [0.81206   ]\n",
      " [0.80510223]\n",
      " [0.79905391]\n",
      " [0.7943418 ]] | y: 0.8926772568771792 | Predicción actual: [[0.79170936]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04663814231753349, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79462242]\n",
      " [0.78452778]\n",
      " [0.81518791]\n",
      " [0.81206   ]\n",
      " [0.80510223]\n",
      " [0.79905391]\n",
      " [0.7943418 ]\n",
      " [0.79170936]] | y: 0.8752421542037967 | Predicción actual: [[0.79155517]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010265217162668705, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78452778]\n",
      " [0.81518791]\n",
      " [0.81206   ]\n",
      " [0.80510223]\n",
      " [0.79905391]\n",
      " [0.7943418 ]\n",
      " [0.79170936]\n",
      " [0.79155517]] | y: 0.8508330104610615 | Predicción actual: [[0.79412633]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0010913099395111203, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.81206   ]\n",
      " [0.80510223]\n",
      " [0.79905391]\n",
      " [0.7943418 ]\n",
      " [0.79170936]\n",
      " [0.79155517]\n",
      " [0.79412633]] | y: 0.8488957768306855 | Predicción actual: [[0.79956454]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009495054371654987, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81206   ]\n",
      " [0.80510223]\n",
      " [0.79905391]\n",
      " [0.7943418 ]\n",
      " [0.79170936]\n",
      " [0.79155517]\n",
      " [0.79412633]\n",
      " [0.79956454]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03883242607116699, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80510223]\n",
      " [0.79905391]\n",
      " [0.7943418 ]\n",
      " [0.79170936]\n",
      " [0.79155517]\n",
      " [0.79412633]\n",
      " [0.79956454]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.79424393]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04481155052781105, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79905391]\n",
      " [0.7943418 ]\n",
      " [0.79170936]\n",
      " [0.79155517]\n",
      " [0.79412633]\n",
      " [0.79956454]\n",
      " [0.96241767]\n",
      " [0.79424393]] | y: 0.9407206509104997 | Predicción actual: [[0.795362]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014949381351470947, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7943418 ]\n",
      " [0.79170936]\n",
      " [0.79155517]\n",
      " [0.79412633]\n",
      " [0.79956454]\n",
      " [0.96241767]\n",
      " [0.79424393]\n",
      " [0.795362  ]] | y: 0.9724912824486633 | Predicción actual: [[0.7996499]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00580391613766551, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79170936]\n",
      " [0.79155517]\n",
      " [0.79412633]\n",
      " [0.79956454]\n",
      " [0.96241767]\n",
      " [0.79424393]\n",
      " [0.795362  ]\n",
      " [0.79964989]] | y: 0.9969004261913985 | Predicción actual: [[0.8068203]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01558498665690422, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79155517]\n",
      " [0.79412633]\n",
      " [0.79956454]\n",
      " [0.96241767]\n",
      " [0.79424393]\n",
      " [0.795362  ]\n",
      " [0.79964989]\n",
      " [0.80682027]] | y: 0.951181712514529 | Predicción actual: [[0.81628966]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04934293031692505, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79412633]\n",
      " [0.79956454]\n",
      " [0.96241767]\n",
      " [0.79424393]\n",
      " [0.795362  ]\n",
      " [0.79964989]\n",
      " [0.80682027]\n",
      " [0.81628966]] | y: 0.8957768306857805 | Predicción actual: [[0.8272051]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004220266826450825, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79956454]\n",
      " [0.96241767]\n",
      " [0.79424393]\n",
      " [0.795362  ]\n",
      " [0.79964989]\n",
      " [0.80682027]\n",
      " [0.81628966]\n",
      " [0.82720512]] | y: 0.8814413018209997 | Predicción actual: [[0.83791536]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0217113234102726, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.79424393]\n",
      " [0.795362  ]\n",
      " [0.79964989]\n",
      " [0.80682027]\n",
      " [0.81628966]\n",
      " [0.82720512]\n",
      " [0.83791536]] | y: 0.9170864006199149 | Predicción actual: [[0.847007]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014753028750419617, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79424393]\n",
      " [0.795362  ]\n",
      " [0.79964989]\n",
      " [0.80682027]\n",
      " [0.81628966]\n",
      " [0.82720512]\n",
      " [0.83791536]\n",
      " [0.84700698]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005945684388279915, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.795362  ]\n",
      " [0.79964989]\n",
      " [0.80682027]\n",
      " [0.81628966]\n",
      " [0.82720512]\n",
      " [0.83791536]\n",
      " [0.84700698]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.8138747]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012741193175315857, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79964989]\n",
      " [0.80682027]\n",
      " [0.81628966]\n",
      " [0.82720512]\n",
      " [0.83791536]\n",
      " [0.84700698]\n",
      " [0.91979853]\n",
      " [0.81387472]] | y: 0.9682293684618366 | Predicción actual: [[0.8229969]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022136230021715164, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80682027]\n",
      " [0.81628966]\n",
      " [0.82720512]\n",
      " [0.83791536]\n",
      " [0.84700698]\n",
      " [0.91979853]\n",
      " [0.81387472]\n",
      " [0.82299691]] | y: 0.9577683068578069 | Predicción actual: [[0.833505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012266411446034908, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n",
      "Ejemplar x: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]] | y: 0.04610616040294452 | Predicción actual: [[0.20404215]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03392485901713371, batch 1, lote_designado 1\n",
      "lr: 1e-05, batch: 1\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20404215]] | y: 0.10422316931421921 | Predicción actual: [[0.18794844]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009130111895501614, batch 2, lote_designado 1\n",
      "lr: 1e-05, batch: 2\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20404215]\n",
      " [0.18794844]] | y: 0.15420379697791559 | Predicción actual: [[0.19214869]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00040668476140126586, batch 3, lote_designado 1\n",
      "lr: 1e-05, batch: 3\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20404215]\n",
      " [0.18794844]\n",
      " [0.19214869]] | y: 0.1557535838822161 | Predicción actual: [[0.2039394]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0038073186296969652, batch 4, lote_designado 1\n",
      "lr: 1e-05, batch: 4\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20404215]\n",
      " [0.18794844]\n",
      " [0.19214869]\n",
      " [0.20393939]] | y: 0.12553273924835334 | Predicción actual: [[0.21689571]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.005261376965790987, batch 5, lote_designado 1\n",
      "lr: 1e-05, batch: 5\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20404215]\n",
      " [0.18794844]\n",
      " [0.19214869]\n",
      " [0.20393939]\n",
      " [0.21689571]] | y: 0.1456799690042619 | Predicción actual: [[0.22709836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0072499848902225494, batch 6, lote_designado 1\n",
      "lr: 1e-05, batch: 6\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20404215]\n",
      " [0.18794844]\n",
      " [0.19214869]\n",
      " [0.20393939]\n",
      " [0.21689571]\n",
      " [0.22709836]] | y: 0.1464548624564122 | Predicción actual: [[0.2491226]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014300691895186901, batch 7, lote_designado 1\n",
      "lr: 1e-05, batch: 7\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.04223169]\n",
      " [0.20404215]\n",
      " [0.18794844]\n",
      " [0.19214869]\n",
      " [0.20393939]\n",
      " [0.21689571]\n",
      " [0.22709836]\n",
      " [0.2491226 ]] | y: 0.1960480433940332 | Predicción actual: [[0.2762493]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008406146429479122, batch 8, lote_designado 1\n",
      "lr: 1e-05, batch: 8\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20404215]\n",
      " [0.18794844]\n",
      " [0.19214869]\n",
      " [0.20393939]\n",
      " [0.21689571]\n",
      " [0.22709836]\n",
      " [0.2491226 ]\n",
      " [0.27624929]] | y: 0.23053080201472292 | Predicción actual: [[0.2305308]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00896939542144537, batch 9, lote_designado 1\n",
      "lr: 1e-05, batch: 9\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.18794844]\n",
      " [0.19214869]\n",
      " [0.20393939]\n",
      " [0.21689571]\n",
      " [0.22709836]\n",
      " [0.2491226 ]\n",
      " [0.27624929]\n",
      " [0.2305308 ]] | y: 0.20844633862843848 | Predicción actual: [[0.3110178]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004463360644876957, batch 10, lote_designado 1\n",
      "lr: 1e-05, batch: 10\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.19214869]\n",
      " [0.20393939]\n",
      " [0.21689571]\n",
      " [0.22709836]\n",
      " [0.2491226 ]\n",
      " [0.27624929]\n",
      " [0.2305308 ]\n",
      " [0.31101781]] | y: 0.211933359163115 | Predicción actual: [[0.3185505]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028771528974175453, batch 11, lote_designado 1\n",
      "lr: 1e-05, batch: 11\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.20393939]\n",
      " [0.21689571]\n",
      " [0.22709836]\n",
      " [0.2491226 ]\n",
      " [0.27624929]\n",
      " [0.2305308 ]\n",
      " [0.31101781]\n",
      " [0.3185505 ]] | y: 0.2072839984502131 | Predicción actual: [[0.32803]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021232817322015762, batch 12, lote_designado 1\n",
      "lr: 1e-05, batch: 12\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.21689571]\n",
      " [0.22709836]\n",
      " [0.2491226 ]\n",
      " [0.27624929]\n",
      " [0.2305308 ]\n",
      " [0.31101781]\n",
      " [0.3185505 ]\n",
      " [0.32802999]] | y: 0.19294846958543205 | Predicción actual: [[0.3381598]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03225386515259743, batch 13, lote_designado 1\n",
      "lr: 1e-05, batch: 13\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.22709836]\n",
      " [0.2491226 ]\n",
      " [0.27624929]\n",
      " [0.2305308 ]\n",
      " [0.31101781]\n",
      " [0.3185505 ]\n",
      " [0.32802999]\n",
      " [0.3381598 ]] | y: 0.19682293684618352 | Predicción actual: [[0.3488337]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012715619057416916, batch 14, lote_designado 1\n",
      "lr: 1e-05, batch: 14\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2491226 ]\n",
      " [0.27624929]\n",
      " [0.2305308 ]\n",
      " [0.31101781]\n",
      " [0.3185505 ]\n",
      " [0.32802999]\n",
      " [0.3381598 ]\n",
      " [0.34883371]] | y: 0.21425803951956607 | Predicción actual: [[0.36086237]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0109159080311656, batch 15, lote_designado 1\n",
      "lr: 1e-05, batch: 15\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.27624929]\n",
      " [0.2305308 ]\n",
      " [0.31101781]\n",
      " [0.3185505 ]\n",
      " [0.32802999]\n",
      " [0.3381598 ]\n",
      " [0.34883371]\n",
      " [0.36086237]] | y: 0.18132506780317698 | Predicción actual: [[0.37148818]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03397683426737785, batch 16, lote_designado 1\n",
      "lr: 1e-05, batch: 16\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.2305308 ]\n",
      " [0.31101781]\n",
      " [0.3185505 ]\n",
      " [0.32802999]\n",
      " [0.3381598 ]\n",
      " [0.34883371]\n",
      " [0.36086237]\n",
      " [0.37148818]] | y: 0.17512592018597434 | Predicción actual: [[0.37907422]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06948176771402359, batch 17, lote_designado 1\n",
      "lr: 1e-05, batch: 17\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.31101781]\n",
      " [0.3185505 ]\n",
      " [0.32802999]\n",
      " [0.3381598 ]\n",
      " [0.34883371]\n",
      " [0.36086237]\n",
      " [0.37148818]\n",
      " [0.37907422]] | y: 0.14800464936071295 | Predicción actual: [[0.14800465]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06656856089830399, batch 18, lote_designado 1\n",
      "lr: 1e-05, batch: 18\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3185505 ]\n",
      " [0.32802999]\n",
      " [0.3381598 ]\n",
      " [0.34883371]\n",
      " [0.36086237]\n",
      " [0.37148818]\n",
      " [0.37907422]\n",
      " [0.14800465]] | y: 0.1588531576908176 | Predicción actual: [[0.40670037]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06197059154510498, batch 19, lote_designado 1\n",
      "lr: 1e-05, batch: 19\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.32802999]\n",
      " [0.3381598 ]\n",
      " [0.34883371]\n",
      " [0.36086237]\n",
      " [0.37148818]\n",
      " [0.37907422]\n",
      " [0.14800465]\n",
      " [0.40670037]] | y: 0.19217357613328173 | Predicción actual: [[0.410932]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04453563690185547, batch 20, lote_designado 1\n",
      "lr: 1e-05, batch: 20\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3381598 ]\n",
      " [0.34883371]\n",
      " [0.36086237]\n",
      " [0.37148818]\n",
      " [0.37907422]\n",
      " [0.14800465]\n",
      " [0.40670037]\n",
      " [0.410932  ]] | y: 0.1859744285160791 | Predicción actual: [[0.41336218]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03450504317879677, batch 21, lote_designado 1\n",
      "lr: 1e-05, batch: 21\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.34883371]\n",
      " [0.36086237]\n",
      " [0.37148818]\n",
      " [0.37907422]\n",
      " [0.14800465]\n",
      " [0.40670037]\n",
      " [0.410932  ]\n",
      " [0.41336218]] | y: 0.26695079426578844 | Predicción actual: [[0.41404325]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044987887144088745, batch 22, lote_designado 1\n",
      "lr: 1e-05, batch: 22\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.36086237]\n",
      " [0.37148818]\n",
      " [0.37907422]\n",
      " [0.14800465]\n",
      " [0.40670037]\n",
      " [0.410932  ]\n",
      " [0.41336218]\n",
      " [0.41404325]] | y: 0.2925222781867493 | Predicción actual: [[0.41312715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0201986376196146, batch 23, lote_designado 1\n",
      "lr: 1e-05, batch: 23\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37148818]\n",
      " [0.37907422]\n",
      " [0.14800465]\n",
      " [0.40670037]\n",
      " [0.410932  ]\n",
      " [0.41336218]\n",
      " [0.41404325]\n",
      " [0.41312715]] | y: 0.3177063153816349 | Predicción actual: [[0.4106702]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015587189234793186, batch 24, lote_designado 1\n",
      "lr: 1e-05, batch: 24\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.37907422]\n",
      " [0.14800465]\n",
      " [0.40670037]\n",
      " [0.410932  ]\n",
      " [0.41336218]\n",
      " [0.41404325]\n",
      " [0.41312715]\n",
      " [0.41067019]] | y: 0.31266950794265785 | Predicción actual: [[0.40729278]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0054416898638010025, batch 25, lote_designado 1\n",
      "lr: 1e-05, batch: 25\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.14800465]\n",
      " [0.40670037]\n",
      " [0.410932  ]\n",
      " [0.41336218]\n",
      " [0.41404325]\n",
      " [0.41312715]\n",
      " [0.41067019]\n",
      " [0.40729278]] | y: 0.2890352576520729 | Predicción actual: [[0.40398777]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0174600537866354, batch 26, lote_designado 1\n",
      "lr: 1e-05, batch: 26\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40670037]\n",
      " [0.410932  ]\n",
      " [0.41336218]\n",
      " [0.41404325]\n",
      " [0.41312715]\n",
      " [0.41067019]\n",
      " [0.40729278]\n",
      " [0.40398777]] | y: 0.28283611003487025 | Predicción actual: [[0.28283611]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009972432628273964, batch 27, lote_designado 1\n",
      "lr: 1e-05, batch: 27\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.410932  ]\n",
      " [0.41336218]\n",
      " [0.41404325]\n",
      " [0.41312715]\n",
      " [0.41067019]\n",
      " [0.40729278]\n",
      " [0.40398777]\n",
      " [0.28283611]] | y: 0.29949631925610226 | Predicción actual: [[0.46076244]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003768814029172063, batch 28, lote_designado 1\n",
      "lr: 1e-05, batch: 28\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41336218]\n",
      " [0.41404325]\n",
      " [0.41312715]\n",
      " [0.41067019]\n",
      " [0.40729278]\n",
      " [0.40398777]\n",
      " [0.28283611]\n",
      " [0.46076244]] | y: 0.2758620689655173 | Predicción actual: [[0.45865312]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01745568960905075, batch 29, lote_designado 1\n",
      "lr: 1e-05, batch: 29\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41404325]\n",
      " [0.41312715]\n",
      " [0.41067019]\n",
      " [0.40729278]\n",
      " [0.40398777]\n",
      " [0.28283611]\n",
      " [0.46076244]\n",
      " [0.45865312]] | y: 0.2746997287872917 | Predicción actual: [[0.45540696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.07153387367725372, batch 30, lote_designado 1\n",
      "lr: 1e-05, batch: 30\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41312715]\n",
      " [0.41067019]\n",
      " [0.40729278]\n",
      " [0.40398777]\n",
      " [0.28283611]\n",
      " [0.46076244]\n",
      " [0.45865312]\n",
      " [0.45540696]] | y: 0.275474622239442 | Predicción actual: [[0.45181847]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04091930389404297, batch 31, lote_designado 1\n",
      "lr: 1e-05, batch: 31\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.41067019]\n",
      " [0.40729278]\n",
      " [0.40398777]\n",
      " [0.28283611]\n",
      " [0.46076244]\n",
      " [0.45865312]\n",
      " [0.45540696]\n",
      " [0.45181847]] | y: 0.3347539713289423 | Predicción actual: [[0.44894466]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004941752180457115, batch 32, lote_designado 1\n",
      "lr: 1e-05, batch: 32\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40729278]\n",
      " [0.40398777]\n",
      " [0.28283611]\n",
      " [0.46076244]\n",
      " [0.45865312]\n",
      " [0.45540696]\n",
      " [0.45181847]\n",
      " [0.44894466]] | y: 0.35567609453700116 | Predicción actual: [[0.4478427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.1236190857744077e-06, batch 33, lote_designado 1\n",
      "lr: 1e-05, batch: 33\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.40398777]\n",
      " [0.28283611]\n",
      " [0.46076244]\n",
      " [0.45865312]\n",
      " [0.45540696]\n",
      " [0.45181847]\n",
      " [0.44894466]\n",
      " [0.44784269]] | y: 0.3366912049593181 | Predicción actual: [[0.44927716]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0114952577278018, batch 34, lote_designado 1\n",
      "lr: 1e-05, batch: 34\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.28283611]\n",
      " [0.46076244]\n",
      " [0.45865312]\n",
      " [0.45540696]\n",
      " [0.45181847]\n",
      " [0.44894466]\n",
      " [0.44784269]\n",
      " [0.44927716]] | y: 0.3335916311507167 | Predicción actual: [[0.45354596]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02545013837516308, batch 35, lote_designado 1\n",
      "lr: 1e-05, batch: 35\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.46076244]\n",
      " [0.45865312]\n",
      " [0.45540696]\n",
      " [0.45181847]\n",
      " [0.44894466]\n",
      " [0.44784269]\n",
      " [0.44927716]\n",
      " [0.45354596]] | y: 0.38473459899263845 | Predicción actual: [[0.3847346]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.019266828894615173, batch 36, lote_designado 1\n",
      "lr: 1e-05, batch: 36\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45865312]\n",
      " [0.45540696]\n",
      " [0.45181847]\n",
      " [0.44894466]\n",
      " [0.44784269]\n",
      " [0.44927716]\n",
      " [0.45354596]\n",
      " [0.3847346 ]] | y: 0.5710964742347926 | Predicción actual: [[0.48821554]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015150296967476606, batch 37, lote_designado 1\n",
      "lr: 1e-05, batch: 37\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45540696]\n",
      " [0.45181847]\n",
      " [0.44894466]\n",
      " [0.44784269]\n",
      " [0.44927716]\n",
      " [0.45354596]\n",
      " [0.3847346 ]\n",
      " [0.48821554]] | y: 0.5962805114296785 | Predicción actual: [[0.48510072]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01373236533254385, batch 38, lote_designado 1\n",
      "lr: 1e-05, batch: 38\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45181847]\n",
      " [0.44894466]\n",
      " [0.44784269]\n",
      " [0.44927716]\n",
      " [0.45354596]\n",
      " [0.3847346 ]\n",
      " [0.48821554]\n",
      " [0.48510072]] | y: 0.574583494769469 | Predicción actual: [[0.48263004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01702706515789032, batch 39, lote_designado 1\n",
      "lr: 1e-05, batch: 39\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44894466]\n",
      " [0.44784269]\n",
      " [0.44927716]\n",
      " [0.45354596]\n",
      " [0.3847346 ]\n",
      " [0.48821554]\n",
      " [0.48510072]\n",
      " [0.48263004]] | y: 0.6063541263076326 | Predicción actual: [[0.48136064]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010138945654034615, batch 40, lote_designado 1\n",
      "lr: 1e-05, batch: 40\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44784269]\n",
      " [0.44927716]\n",
      " [0.45354596]\n",
      " [0.3847346 ]\n",
      " [0.48821554]\n",
      " [0.48510072]\n",
      " [0.48263004]\n",
      " [0.48136064]] | y: 0.5846571096474236 | Predicción actual: [[0.48157728]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009815594181418419, batch 41, lote_designado 1\n",
      "lr: 1e-05, batch: 41\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.44927716]\n",
      " [0.45354596]\n",
      " [0.3847346 ]\n",
      " [0.48821554]\n",
      " [0.48510072]\n",
      " [0.48263004]\n",
      " [0.48136064]\n",
      " [0.48157728]] | y: 0.5687717938783416 | Predicción actual: [[0.48322594]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01873277686536312, batch 42, lote_designado 1\n",
      "lr: 1e-05, batch: 42\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.45354596]\n",
      " [0.3847346 ]\n",
      " [0.48821554]\n",
      " [0.48510072]\n",
      " [0.48263004]\n",
      " [0.48136064]\n",
      " [0.48157728]\n",
      " [0.48322594]] | y: 0.6427741185586981 | Predicción actual: [[0.48594034]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.021246828138828278, batch 43, lote_designado 1\n",
      "lr: 1e-05, batch: 43\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.3847346 ]\n",
      " [0.48821554]\n",
      " [0.48510072]\n",
      " [0.48263004]\n",
      " [0.48136064]\n",
      " [0.48157728]\n",
      " [0.48322594]\n",
      " [0.48594034]] | y: 0.6617590081363811 | Predicción actual: [[0.4891249]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.020532088354229927, batch 44, lote_designado 1\n",
      "lr: 1e-05, batch: 44\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48821554]\n",
      " [0.48510072]\n",
      " [0.48263004]\n",
      " [0.48136064]\n",
      " [0.48157728]\n",
      " [0.48322594]\n",
      " [0.48594034]\n",
      " [0.48912489]] | y: 0.6729949631925611 | Predicción actual: [[0.67299496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0031946906819939613, batch 45, lote_designado 1\n",
      "lr: 1e-05, batch: 45\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48510072]\n",
      " [0.48263004]\n",
      " [0.48136064]\n",
      " [0.48157728]\n",
      " [0.48322594]\n",
      " [0.48594034]\n",
      " [0.48912489]\n",
      " [0.67299496]] | y: 0.7105772956218519 | Predicción actual: [[0.5120656]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03364923968911171, batch 46, lote_designado 1\n",
      "lr: 1e-05, batch: 46\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48263004]\n",
      " [0.48136064]\n",
      " [0.48157728]\n",
      " [0.48322594]\n",
      " [0.48594034]\n",
      " [0.48912489]\n",
      " [0.67299496]\n",
      " [0.51206559]] | y: 0.703990701278574 | Predicción actual: [[0.5148427]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.013590468093752861, batch 47, lote_designado 1\n",
      "lr: 1e-05, batch: 47\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48136064]\n",
      " [0.48157728]\n",
      " [0.48322594]\n",
      " [0.48594034]\n",
      " [0.48912489]\n",
      " [0.67299496]\n",
      " [0.51206559]\n",
      " [0.51484269]] | y: 0.7272375048430839 | Predicción actual: [[0.52047205]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030524304136633873, batch 48, lote_designado 1\n",
      "lr: 1e-05, batch: 48\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48157728]\n",
      " [0.48322594]\n",
      " [0.48594034]\n",
      " [0.48912489]\n",
      " [0.67299496]\n",
      " [0.51206559]\n",
      " [0.51484269]\n",
      " [0.52047205]] | y: 0.722588144130182 | Predicción actual: [[0.52889365]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024822071194648743, batch 49, lote_designado 1\n",
      "lr: 1e-05, batch: 49\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48322594]\n",
      " [0.48594034]\n",
      " [0.48912489]\n",
      " [0.67299496]\n",
      " [0.51206559]\n",
      " [0.51484269]\n",
      " [0.52047205]\n",
      " [0.52889365]] | y: 0.771793878341728 | Predicción actual: [[0.53971624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08489305526018143, batch 50, lote_designado 1\n",
      "lr: 1e-05, batch: 50\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48594034]\n",
      " [0.48912489]\n",
      " [0.67299496]\n",
      " [0.51206559]\n",
      " [0.51484269]\n",
      " [0.52047205]\n",
      " [0.52889365]\n",
      " [0.53971624]] | y: 0.7245253777605578 | Predicción actual: [[0.5525112]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009964690543711185, batch 51, lote_designado 1\n",
      "lr: 1e-05, batch: 51\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.48912489]\n",
      " [0.67299496]\n",
      " [0.51206559]\n",
      " [0.51484269]\n",
      " [0.52047205]\n",
      " [0.52889365]\n",
      " [0.53971624]\n",
      " [0.55251122]] | y: 0.6710577295621851 | Predicción actual: [[0.5666874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004312910605221987, batch 52, lote_designado 1\n",
      "lr: 1e-05, batch: 52\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67299496]\n",
      " [0.51206559]\n",
      " [0.51484269]\n",
      " [0.52047205]\n",
      " [0.52889365]\n",
      " [0.53971624]\n",
      " [0.55251122]\n",
      " [0.56668741]] | y: 0.6737698566447115 | Predicción actual: [[0.5819078]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015690678730607033, batch 53, lote_designado 1\n",
      "lr: 1e-05, batch: 53\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51206559]\n",
      " [0.51484269]\n",
      " [0.52047205]\n",
      " [0.52889365]\n",
      " [0.53971624]\n",
      " [0.55251122]\n",
      " [0.56668741]\n",
      " [0.58190781]] | y: 0.7144517628826037 | Predicción actual: [[0.71445176]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04380640760064125, batch 54, lote_designado 1\n",
      "lr: 1e-05, batch: 54\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.51484269]\n",
      " [0.52047205]\n",
      " [0.52889365]\n",
      " [0.53971624]\n",
      " [0.55251122]\n",
      " [0.56668741]\n",
      " [0.58190781]\n",
      " [0.71445176]] | y: 0.7438977140643162 | Predicción actual: [[0.55638146]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012309490703046322, batch 55, lote_designado 1\n",
      "lr: 1e-05, batch: 55\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52047205]\n",
      " [0.52889365]\n",
      " [0.53971624]\n",
      " [0.55251122]\n",
      " [0.56668741]\n",
      " [0.58190781]\n",
      " [0.71445176]\n",
      " [0.55638146]] | y: 0.722588144130182 | Predicción actual: [[0.5669756]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03156832233071327, batch 56, lote_designado 1\n",
      "lr: 1e-05, batch: 56\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.52889365]\n",
      " [0.53971624]\n",
      " [0.55251122]\n",
      " [0.56668741]\n",
      " [0.58190781]\n",
      " [0.71445176]\n",
      " [0.55638146]\n",
      " [0.56697559]] | y: 0.6993413405656723 | Predicción actual: [[0.57963663]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007058131508529186, batch 57, lote_designado 1\n",
      "lr: 1e-05, batch: 57\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.53971624]\n",
      " [0.55251122]\n",
      " [0.56668741]\n",
      " [0.58190781]\n",
      " [0.71445176]\n",
      " [0.55638146]\n",
      " [0.56697559]\n",
      " [0.57963663]] | y: 0.7373111197210385 | Predicción actual: [[0.59324497]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.025143951177597046, batch 58, lote_designado 1\n",
      "lr: 1e-05, batch: 58\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55251122]\n",
      " [0.56668741]\n",
      " [0.58190781]\n",
      " [0.71445176]\n",
      " [0.55638146]\n",
      " [0.56697559]\n",
      " [0.57963663]\n",
      " [0.59324497]] | y: 0.7214258039519565 | Predicción actual: [[0.60669696]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.036248303949832916, batch 59, lote_designado 1\n",
      "lr: 1e-05, batch: 59\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56668741]\n",
      " [0.58190781]\n",
      " [0.71445176]\n",
      " [0.55638146]\n",
      " [0.56697559]\n",
      " [0.57963663]\n",
      " [0.59324497]\n",
      " [0.60669696]] | y: 0.7187136768694304 | Predicción actual: [[0.6188451]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03424094617366791, batch 60, lote_designado 1\n",
      "lr: 1e-05, batch: 60\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.58190781]\n",
      " [0.71445176]\n",
      " [0.55638146]\n",
      " [0.56697559]\n",
      " [0.57963663]\n",
      " [0.59324497]\n",
      " [0.60669696]\n",
      " [0.61884511]] | y: 0.6741573033707864 | Predicción actual: [[0.62869364]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0030529433861374855, batch 61, lote_designado 1\n",
      "lr: 1e-05, batch: 61\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71445176]\n",
      " [0.55638146]\n",
      " [0.56697559]\n",
      " [0.57963663]\n",
      " [0.59324497]\n",
      " [0.60669696]\n",
      " [0.61884511]\n",
      " [0.62869364]] | y: 0.698566447113522 | Predicción actual: [[0.63530874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008453212678432465, batch 62, lote_designado 1\n",
      "lr: 1e-05, batch: 62\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.55638146]\n",
      " [0.56697559]\n",
      " [0.57963663]\n",
      " [0.59324497]\n",
      " [0.60669696]\n",
      " [0.61884511]\n",
      " [0.62869364]\n",
      " [0.63530874]] | y: 0.7210383572258814 | Predicción actual: [[0.72103836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.007529073860496283, batch 63, lote_designado 1\n",
      "lr: 1e-05, batch: 63\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.56697559]\n",
      " [0.57963663]\n",
      " [0.59324497]\n",
      " [0.60669696]\n",
      " [0.61884511]\n",
      " [0.62869364]\n",
      " [0.63530874]\n",
      " [0.72103836]] | y: 0.722588144130182 | Predicción actual: [[0.61717653]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01365077868103981, batch 64, lote_designado 1\n",
      "lr: 1e-05, batch: 64\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.57963663]\n",
      " [0.59324497]\n",
      " [0.60669696]\n",
      " [0.61884511]\n",
      " [0.62869364]\n",
      " [0.63530874]\n",
      " [0.72103836]\n",
      " [0.61717653]] | y: 0.7562960092987214 | Predicción actual: [[0.6301379]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005873299669474363, batch 65, lote_designado 1\n",
      "lr: 1e-05, batch: 65\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.59324497]\n",
      " [0.60669696]\n",
      " [0.61884511]\n",
      " [0.62869364]\n",
      " [0.63530874]\n",
      " [0.72103836]\n",
      " [0.61717653]\n",
      " [0.63013792]] | y: 0.8275862068965516 | Predicción actual: [[0.6428351]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.030465392395853996, batch 66, lote_designado 1\n",
      "lr: 1e-05, batch: 66\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.60669696]\n",
      " [0.61884511]\n",
      " [0.62869364]\n",
      " [0.63530874]\n",
      " [0.72103836]\n",
      " [0.61717653]\n",
      " [0.63013792]\n",
      " [0.64283508]] | y: 0.8388221619527314 | Predicción actual: [[0.6546815]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.010099360719323158, batch 67, lote_designado 1\n",
      "lr: 1e-05, batch: 67\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61884511]\n",
      " [0.62869364]\n",
      " [0.63530874]\n",
      " [0.72103836]\n",
      " [0.61717653]\n",
      " [0.63013792]\n",
      " [0.64283508]\n",
      " [0.6546815 ]] | y: 0.7942657884540876 | Predicción actual: [[0.66502655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02291707880795002, batch 68, lote_designado 1\n",
      "lr: 1e-05, batch: 68\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.62869364]\n",
      " [0.63530874]\n",
      " [0.72103836]\n",
      " [0.61717653]\n",
      " [0.63013792]\n",
      " [0.64283508]\n",
      " [0.6546815 ]\n",
      " [0.66502655]] | y: 0.7838047268500579 | Predicción actual: [[0.6737223]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.022406142204999924, batch 69, lote_designado 1\n",
      "lr: 1e-05, batch: 69\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63530874]\n",
      " [0.72103836]\n",
      " [0.61717653]\n",
      " [0.63013792]\n",
      " [0.64283508]\n",
      " [0.6546815 ]\n",
      " [0.66502655]\n",
      " [0.67372233]] | y: 0.7679194110809764 | Predicción actual: [[0.6810032]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0033687411341816187, batch 70, lote_designado 1\n",
      "lr: 1e-05, batch: 70\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72103836]\n",
      " [0.61717653]\n",
      " [0.63013792]\n",
      " [0.64283508]\n",
      " [0.6546815 ]\n",
      " [0.66502655]\n",
      " [0.67372233]\n",
      " [0.68100321]] | y: 0.7845796203022084 | Predicción actual: [[0.6874757]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008715908043086529, batch 71, lote_designado 1\n",
      "lr: 1e-05, batch: 71\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.61717653]\n",
      " [0.63013792]\n",
      " [0.64283508]\n",
      " [0.6546815 ]\n",
      " [0.66502655]\n",
      " [0.67372233]\n",
      " [0.68100321]\n",
      " [0.68747568]] | y: 0.8787291747384733 | Predicción actual: [[0.87872917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.060427434742450714, batch 72, lote_designado 1\n",
      "lr: 1e-05, batch: 72\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.63013792]\n",
      " [0.64283508]\n",
      " [0.6546815 ]\n",
      " [0.66502655]\n",
      " [0.67372233]\n",
      " [0.68100321]\n",
      " [0.68747568]\n",
      " [0.87872917]] | y: 0.8756296009298721 | Predicción actual: [[0.68265474]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.050678104162216187, batch 73, lote_designado 1\n",
      "lr: 1e-05, batch: 73\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.64283508]\n",
      " [0.6546815 ]\n",
      " [0.66502655]\n",
      " [0.67372233]\n",
      " [0.68100321]\n",
      " [0.68747568]\n",
      " [0.87872917]\n",
      " [0.68265474]] | y: 0.8488957768306855 | Predicción actual: [[0.696579]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015874870121479034, batch 74, lote_designado 1\n",
      "lr: 1e-05, batch: 74\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.6546815 ]\n",
      " [0.66502655]\n",
      " [0.67372233]\n",
      " [0.68100321]\n",
      " [0.68747568]\n",
      " [0.87872917]\n",
      " [0.68265474]\n",
      " [0.69657898]] | y: 0.8182874854707476 | Predicción actual: [[0.711185]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001335269771516323, batch 75, lote_designado 1\n",
      "lr: 1e-05, batch: 75\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66502655]\n",
      " [0.67372233]\n",
      " [0.68100321]\n",
      " [0.68747568]\n",
      " [0.87872917]\n",
      " [0.68265474]\n",
      " [0.69657898]\n",
      " [0.71118498]] | y: 0.8268113134444013 | Predicción actual: [[0.7261243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.028024835512042046, batch 76, lote_designado 1\n",
      "lr: 1e-05, batch: 76\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.67372233]\n",
      " [0.68100321]\n",
      " [0.68747568]\n",
      " [0.87872917]\n",
      " [0.68265474]\n",
      " [0.69657898]\n",
      " [0.71118498]\n",
      " [0.72612429]] | y: 0.7853545137543589 | Predicción actual: [[0.74143636]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00195549544878304, batch 77, lote_designado 1\n",
      "lr: 1e-05, batch: 77\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68100321]\n",
      " [0.68747568]\n",
      " [0.87872917]\n",
      " [0.68265474]\n",
      " [0.69657898]\n",
      " [0.71118498]\n",
      " [0.72612429]\n",
      " [0.74143636]] | y: 0.7892289810151103 | Predicción actual: [[0.7567746]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003698613727465272, batch 78, lote_designado 1\n",
      "lr: 1e-05, batch: 78\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68747568]\n",
      " [0.87872917]\n",
      " [0.68265474]\n",
      " [0.69657898]\n",
      " [0.71118498]\n",
      " [0.72612429]\n",
      " [0.74143636]\n",
      " [0.7567746 ]] | y: 0.8341728012398295 | Predicción actual: [[0.77231055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04266726225614548, batch 79, lote_designado 1\n",
      "lr: 1e-05, batch: 79\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87872917]\n",
      " [0.68265474]\n",
      " [0.69657898]\n",
      " [0.71118498]\n",
      " [0.72612429]\n",
      " [0.74143636]\n",
      " [0.7567746 ]\n",
      " [0.77231055]] | y: 0.8124757845796202 | Predicción actual: [[0.78818613]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005275506409816444, batch 80, lote_designado 1\n",
      "lr: 1e-05, batch: 80\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68265474]\n",
      " [0.69657898]\n",
      " [0.71118498]\n",
      " [0.72612429]\n",
      " [0.74143636]\n",
      " [0.7567746 ]\n",
      " [0.77231055]\n",
      " [0.78818613]] | y: 0.8012398295234404 | Predicción actual: [[0.80123983]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018120205029845238, batch 81, lote_designado 1\n",
      "lr: 1e-05, batch: 81\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.69657898]\n",
      " [0.71118498]\n",
      " [0.72612429]\n",
      " [0.74143636]\n",
      " [0.7567746 ]\n",
      " [0.77231055]\n",
      " [0.78818613]\n",
      " [0.80123983]] | y: 0.8031770631538162 | Predicción actual: [[0.76225376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0071897064335644245, batch 82, lote_designado 1\n",
      "lr: 1e-05, batch: 82\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.71118498]\n",
      " [0.72612429]\n",
      " [0.74143636]\n",
      " [0.7567746 ]\n",
      " [0.77231055]\n",
      " [0.78818613]\n",
      " [0.80123983]\n",
      " [0.76225376]] | y: 0.793490895001937 | Predicción actual: [[0.77773327]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0013130123261362314, batch 83, lote_designado 1\n",
      "lr: 1e-05, batch: 83\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.72612429]\n",
      " [0.74143636]\n",
      " [0.7567746 ]\n",
      " [0.77231055]\n",
      " [0.78818613]\n",
      " [0.80123983]\n",
      " [0.76225376]\n",
      " [0.77773327]] | y: 0.760170476559473 | Predicción actual: [[0.79250854]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00034624559339135885, batch 84, lote_designado 1\n",
      "lr: 1e-05, batch: 84\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.74143636]\n",
      " [0.7567746 ]\n",
      " [0.77231055]\n",
      " [0.78818613]\n",
      " [0.80123983]\n",
      " [0.76225376]\n",
      " [0.77773327]\n",
      " [0.79250854]] | y: 0.7353738860906625 | Predicción actual: [[0.8058821]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.012900047935545444, batch 85, lote_designado 1\n",
      "lr: 1e-05, batch: 85\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.7567746 ]\n",
      " [0.77231055]\n",
      " [0.78818613]\n",
      " [0.80123983]\n",
      " [0.76225376]\n",
      " [0.77773327]\n",
      " [0.79250854]\n",
      " [0.8058821 ]] | y: 0.7101898488957767 | Predicción actual: [[0.8169425]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00010420591570436954, batch 86, lote_designado 1\n",
      "lr: 1e-05, batch: 86\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77231055]\n",
      " [0.78818613]\n",
      " [0.80123983]\n",
      " [0.76225376]\n",
      " [0.77773327]\n",
      " [0.79250854]\n",
      " [0.8058821 ]\n",
      " [0.81694251]] | y: 0.7121270825261525 | Predicción actual: [[0.8253926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.000495057029183954, batch 87, lote_designado 1\n",
      "lr: 1e-05, batch: 87\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78818613]\n",
      " [0.80123983]\n",
      " [0.76225376]\n",
      " [0.77773327]\n",
      " [0.79250854]\n",
      " [0.8058821 ]\n",
      " [0.81694251]\n",
      " [0.8253926 ]] | y: 0.7396358000774894 | Predicción actual: [[0.8307692]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011468203738331795, batch 88, lote_designado 1\n",
      "lr: 1e-05, batch: 88\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80123983]\n",
      " [0.76225376]\n",
      " [0.77773327]\n",
      " [0.79250854]\n",
      " [0.8058821 ]\n",
      " [0.81694251]\n",
      " [0.8253926 ]\n",
      " [0.83076918]] | y: 0.7361487795428128 | Predicción actual: [[0.8326802]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0003164572117384523, batch 89, lote_designado 1\n",
      "lr: 1e-05, batch: 89\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.76225376]\n",
      " [0.77773327]\n",
      " [0.79250854]\n",
      " [0.8058821 ]\n",
      " [0.81694251]\n",
      " [0.8253926 ]\n",
      " [0.83076918]\n",
      " [0.83268023]] | y: 0.6675707090275087 | Predicción actual: [[0.66757071]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0022048046812415123, batch 90, lote_designado 1\n",
      "lr: 1e-05, batch: 90\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77773327]\n",
      " [0.79250854]\n",
      " [0.8058821 ]\n",
      " [0.81694251]\n",
      " [0.8253926 ]\n",
      " [0.83076918]\n",
      " [0.83268023]\n",
      " [0.66757071]] | y: 0.6698953893839596 | Predicción actual: [[0.84377825]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.014781871810555458, batch 91, lote_designado 1\n",
      "lr: 1e-05, batch: 91\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79250854]\n",
      " [0.8058821 ]\n",
      " [0.81694251]\n",
      " [0.8253926 ]\n",
      " [0.83076918]\n",
      " [0.83268023]\n",
      " [0.66757071]\n",
      " [0.84377825]] | y: 0.696629213483146 | Predicción actual: [[0.85215384]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011317462660372257, batch 92, lote_designado 1\n",
      "lr: 1e-05, batch: 92\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8058821 ]\n",
      " [0.81694251]\n",
      " [0.8253926 ]\n",
      " [0.83076918]\n",
      " [0.83268023]\n",
      " [0.66757071]\n",
      " [0.84377825]\n",
      " [0.85215384]] | y: 0.6559473072452537 | Predicción actual: [[0.85661626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016063883900642395, batch 93, lote_designado 1\n",
      "lr: 1e-05, batch: 93\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81694251]\n",
      " [0.8253926 ]\n",
      " [0.83076918]\n",
      " [0.83268023]\n",
      " [0.66757071]\n",
      " [0.84377825]\n",
      " [0.85215384]\n",
      " [0.85661626]] | y: 0.6788066640836885 | Predicción actual: [[0.8572568]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08421845734119415, batch 94, lote_designado 1\n",
      "lr: 1e-05, batch: 94\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8253926 ]\n",
      " [0.83076918]\n",
      " [0.83268023]\n",
      " [0.66757071]\n",
      " [0.84377825]\n",
      " [0.85215384]\n",
      " [0.85661626]\n",
      " [0.85725683]] | y: 0.6760945370011622 | Predicción actual: [[0.8543796]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.011903041042387486, batch 95, lote_designado 1\n",
      "lr: 1e-05, batch: 95\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83076918]\n",
      " [0.83268023]\n",
      " [0.66757071]\n",
      " [0.84377825]\n",
      " [0.85215384]\n",
      " [0.85661626]\n",
      " [0.85725683]\n",
      " [0.85437959]] | y: 0.7295621851995349 | Predicción actual: [[0.84957564]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05990362539887428, batch 96, lote_designado 1\n",
      "lr: 1e-05, batch: 96\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83268023]\n",
      " [0.66757071]\n",
      " [0.84377825]\n",
      " [0.85215384]\n",
      " [0.85661626]\n",
      " [0.85725683]\n",
      " [0.85437959]\n",
      " [0.84957564]] | y: 0.7012785741960481 | Predicción actual: [[0.843872]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02423919551074505, batch 97, lote_designado 1\n",
      "lr: 1e-05, batch: 97\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.66757071]\n",
      " [0.84377825]\n",
      " [0.85215384]\n",
      " [0.85661626]\n",
      " [0.85725683]\n",
      " [0.85437959]\n",
      " [0.84957564]\n",
      " [0.84387201]] | y: 0.767531964354901 | Predicción actual: [[0.8390595]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.01234032679349184, batch 98, lote_designado 1\n",
      "lr: 1e-05, batch: 98\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84377825]\n",
      " [0.85215384]\n",
      " [0.85661626]\n",
      " [0.85725683]\n",
      " [0.85437959]\n",
      " [0.84957564]\n",
      " [0.84387201]\n",
      " [0.83905947]] | y: 0.7551336691204957 | Predicción actual: [[0.75513367]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0012013473315164447, batch 99, lote_designado 1\n",
      "lr: 1e-05, batch: 99\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85215384]\n",
      " [0.85661626]\n",
      " [0.85725683]\n",
      " [0.85437959]\n",
      " [0.84957564]\n",
      " [0.84387201]\n",
      " [0.83905947]\n",
      " [0.75513367]] | y: 0.7450600542425416 | Predicción actual: [[0.8884735]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.009334691800177097, batch 100, lote_designado 1\n",
      "lr: 1e-05, batch: 100\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85661626]\n",
      " [0.85725683]\n",
      " [0.85437959]\n",
      " [0.84957564]\n",
      " [0.84387201]\n",
      " [0.83905947]\n",
      " [0.75513367]\n",
      " [0.88847351]] | y: 0.7520340953118947 | Predicción actual: [[0.88525283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.043385136872529984, batch 101, lote_designado 1\n",
      "lr: 1e-05, batch: 101\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85725683]\n",
      " [0.85437959]\n",
      " [0.84957564]\n",
      " [0.84387201]\n",
      " [0.83905947]\n",
      " [0.75513367]\n",
      " [0.88847351]\n",
      " [0.88525283]] | y: 0.7098024021697016 | Predicción actual: [[0.87960035]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001085021998733282, batch 102, lote_designado 1\n",
      "lr: 1e-05, batch: 102\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85437959]\n",
      " [0.84957564]\n",
      " [0.84387201]\n",
      " [0.83905947]\n",
      " [0.75513367]\n",
      " [0.88847351]\n",
      " [0.88525283]\n",
      " [0.87960035]] | y: 0.6904300658659435 | Predicción actual: [[0.8735867]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.08621767163276672, batch 103, lote_designado 1\n",
      "lr: 1e-05, batch: 103\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84957564]\n",
      " [0.84387201]\n",
      " [0.83905947]\n",
      " [0.75513367]\n",
      " [0.88847351]\n",
      " [0.88525283]\n",
      " [0.87960035]\n",
      " [0.87358671]] | y: 0.7543587756683454 | Predicción actual: [[0.8680973]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023394610732793808, batch 104, lote_designado 1\n",
      "lr: 1e-05, batch: 104\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84387201]\n",
      " [0.83905947]\n",
      " [0.75513367]\n",
      " [0.88847351]\n",
      " [0.88525283]\n",
      " [0.87960035]\n",
      " [0.87358671]\n",
      " [0.86809731]] | y: 0.7222006974041069 | Predicción actual: [[0.86476624]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002497963432688266, batch 105, lote_designado 1\n",
      "lr: 1e-05, batch: 105\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83905947]\n",
      " [0.75513367]\n",
      " [0.88847351]\n",
      " [0.88525283]\n",
      " [0.87960035]\n",
      " [0.87358671]\n",
      " [0.86809731]\n",
      " [0.86476624]] | y: 0.8485083301046106 | Predicción actual: [[0.86471283]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006630139425396919, batch 106, lote_designado 1\n",
      "lr: 1e-05, batch: 106\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.75513367]\n",
      " [0.88847351]\n",
      " [0.88525283]\n",
      " [0.87960035]\n",
      " [0.87358671]\n",
      " [0.86809731]\n",
      " [0.86476624]\n",
      " [0.86471283]] | y: 0.9054629988376597 | Predicción actual: [[0.868202]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002729386556893587, batch 107, lote_designado 1\n",
      "lr: 1e-05, batch: 107\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88847351]\n",
      " [0.88525283]\n",
      " [0.87960035]\n",
      " [0.87358671]\n",
      " [0.86809731]\n",
      " [0.86476624]\n",
      " [0.86471283]\n",
      " [0.86820197]] | y: 0.88221619527315 | Predicción actual: [[0.8822162]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006018439773470163, batch 108, lote_designado 1\n",
      "lr: 1e-05, batch: 108\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88525283]\n",
      " [0.87960035]\n",
      " [0.87358671]\n",
      " [0.86809731]\n",
      " [0.86476624]\n",
      " [0.86471283]\n",
      " [0.86820197]\n",
      " [0.8822162 ]] | y: 0.9077876791941106 | Predicción actual: [[0.8940655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004878068808466196, batch 109, lote_designado 1\n",
      "lr: 1e-05, batch: 109\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87960035]\n",
      " [0.87358671]\n",
      " [0.86809731]\n",
      " [0.86476624]\n",
      " [0.86471283]\n",
      " [0.86820197]\n",
      " [0.8822162 ]\n",
      " [0.8940655 ]] | y: 0.889577683068578 | Predicción actual: [[0.8885655]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0006636633188463748, batch 110, lote_designado 1\n",
      "lr: 1e-05, batch: 110\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87358671]\n",
      " [0.86809731]\n",
      " [0.86476624]\n",
      " [0.86471283]\n",
      " [0.86820197]\n",
      " [0.8822162 ]\n",
      " [0.8940655 ]\n",
      " [0.88856548]] | y: 0.8748547074777218 | Predicción actual: [[0.8847986]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00023915765632409602, batch 111, lote_designado 1\n",
      "lr: 1e-05, batch: 111\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86809731]\n",
      " [0.86476624]\n",
      " [0.86471283]\n",
      " [0.86820197]\n",
      " [0.8822162 ]\n",
      " [0.8940655 ]\n",
      " [0.88856548]\n",
      " [0.88479859]] | y: 0.9132119333591631 | Predicción actual: [[0.8832412]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 5.810766015201807e-05, batch 112, lote_designado 1\n",
      "lr: 1e-05, batch: 112\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86476624]\n",
      " [0.86471283]\n",
      " [0.86820197]\n",
      " [0.8822162 ]\n",
      " [0.8940655 ]\n",
      " [0.88856548]\n",
      " [0.88479859]\n",
      " [0.88324118]] | y: 1.0 | Predicción actual: [[0.88413924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008611921221017838, batch 113, lote_designado 1\n",
      "lr: 1e-05, batch: 113\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86471283]\n",
      " [0.86820197]\n",
      " [0.8822162 ]\n",
      " [0.8940655 ]\n",
      " [0.88856548]\n",
      " [0.88479859]\n",
      " [0.88324118]\n",
      " [0.88413924]] | y: 0.9705540488182873 | Predicción actual: [[0.88730776]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.144584979963838e-06, batch 114, lote_designado 1\n",
      "lr: 1e-05, batch: 114\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86820197]\n",
      " [0.8822162 ]\n",
      " [0.8940655 ]\n",
      " [0.88856548]\n",
      " [0.88479859]\n",
      " [0.88324118]\n",
      " [0.88413924]\n",
      " [0.88730776]] | y: 0.8888027896164277 | Predicción actual: [[0.89161855]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0073221903294324875, batch 115, lote_designado 1\n",
      "lr: 1e-05, batch: 115\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8822162 ]\n",
      " [0.8940655 ]\n",
      " [0.88856548]\n",
      " [0.88479859]\n",
      " [0.88324118]\n",
      " [0.88413924]\n",
      " [0.88730776]\n",
      " [0.89161855]] | y: 0.877954281286323 | Predicción actual: [[0.89570385]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008003597031347454, batch 116, lote_designado 1\n",
      "lr: 1e-05, batch: 116\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8940655 ]\n",
      " [0.88856548]\n",
      " [0.88479859]\n",
      " [0.88324118]\n",
      " [0.88413924]\n",
      " [0.88730776]\n",
      " [0.89161855]\n",
      " [0.89570385]] | y: 0.8488957768306855 | Predicción actual: [[0.84889578]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004489044193178415, batch 117, lote_designado 1\n",
      "lr: 1e-05, batch: 117\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88856548]\n",
      " [0.88479859]\n",
      " [0.88324118]\n",
      " [0.88413924]\n",
      " [0.88730776]\n",
      " [0.89161855]\n",
      " [0.89570385]\n",
      " [0.84889578]] | y: 0.8341728012398295 | Predicción actual: [[0.8932448]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02325735054910183, batch 118, lote_designado 1\n",
      "lr: 1e-05, batch: 118\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88479859]\n",
      " [0.88324118]\n",
      " [0.88413924]\n",
      " [0.88730776]\n",
      " [0.89161855]\n",
      " [0.89570385]\n",
      " [0.84889578]\n",
      " [0.8932448 ]] | y: 0.8550949244478885 | Predicción actual: [[0.89170957]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002814630279317498, batch 119, lote_designado 1\n",
      "lr: 1e-05, batch: 119\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88324118]\n",
      " [0.88413924]\n",
      " [0.88730776]\n",
      " [0.89161855]\n",
      " [0.89570385]\n",
      " [0.84889578]\n",
      " [0.8932448 ]\n",
      " [0.89170957]] | y: 0.8752421542037967 | Predicción actual: [[0.89120924]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.936088902875781e-05, batch 120, lote_designado 1\n",
      "lr: 1e-05, batch: 120\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88413924]\n",
      " [0.88730776]\n",
      " [0.89161855]\n",
      " [0.89570385]\n",
      " [0.84889578]\n",
      " [0.8932448 ]\n",
      " [0.89170957]\n",
      " [0.89120924]] | y: 0.857032158078264 | Predicción actual: [[0.89119285]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04244222491979599, batch 121, lote_designado 1\n",
      "lr: 1e-05, batch: 121\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88730776]\n",
      " [0.89161855]\n",
      " [0.89570385]\n",
      " [0.84889578]\n",
      " [0.8932448 ]\n",
      " [0.89170957]\n",
      " [0.89120924]\n",
      " [0.89119285]] | y: 0.8500581170089112 | Predicción actual: [[0.8905043]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02311527542769909, batch 122, lote_designado 1\n",
      "lr: 1e-05, batch: 122\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89161855]\n",
      " [0.89570385]\n",
      " [0.84889578]\n",
      " [0.8932448 ]\n",
      " [0.89170957]\n",
      " [0.89120924]\n",
      " [0.89119285]\n",
      " [0.8905043 ]] | y: 0.8426966292134832 | Predicción actual: [[0.88869256]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.585602250197553e-07, batch 123, lote_designado 1\n",
      "lr: 1e-05, batch: 123\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89570385]\n",
      " [0.84889578]\n",
      " [0.8932448 ]\n",
      " [0.89170957]\n",
      " [0.89120924]\n",
      " [0.89119285]\n",
      " [0.8905043 ]\n",
      " [0.88869256]] | y: 0.8229368461836497 | Predicción actual: [[0.88576376]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.044982049614191055, batch 124, lote_designado 1\n",
      "lr: 1e-05, batch: 124\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84889578]\n",
      " [0.8932448 ]\n",
      " [0.89170957]\n",
      " [0.89120924]\n",
      " [0.89119285]\n",
      " [0.8905043 ]\n",
      " [0.88869256]\n",
      " [0.88576376]] | y: 0.7745060054242543 | Predicción actual: [[0.88119525]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001582203432917595, batch 125, lote_designado 1\n",
      "lr: 1e-05, batch: 125\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8932448 ]\n",
      " [0.89170957]\n",
      " [0.89120924]\n",
      " [0.89119285]\n",
      " [0.8905043 ]\n",
      " [0.88869256]\n",
      " [0.88576376]\n",
      " [0.88119525]] | y: 0.7841921735761332 | Predicción actual: [[0.78419217]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008343092049472034, batch 126, lote_designado 1\n",
      "lr: 1e-05, batch: 126\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89170957]\n",
      " [0.89120924]\n",
      " [0.89119285]\n",
      " [0.8905043 ]\n",
      " [0.88869256]\n",
      " [0.88576376]\n",
      " [0.88119525]\n",
      " [0.78419217]] | y: 0.8597442851607902 | Predicción actual: [[0.888042]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0011016045464202762, batch 127, lote_designado 1\n",
      "lr: 1e-05, batch: 127\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89120924]\n",
      " [0.89119285]\n",
      " [0.8905043 ]\n",
      " [0.88869256]\n",
      " [0.88576376]\n",
      " [0.88119525]\n",
      " [0.78419217]\n",
      " [0.88804197]] | y: 0.854320030995738 | Predicción actual: [[0.88445926]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0007227408932521939, batch 128, lote_designado 1\n",
      "lr: 1e-05, batch: 128\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.89119285]\n",
      " [0.8905043 ]\n",
      " [0.88869256]\n",
      " [0.88576376]\n",
      " [0.88119525]\n",
      " [0.78419217]\n",
      " [0.88804197]\n",
      " [0.88445926]] | y: 0.8368849283223556 | Predicción actual: [[0.87986636]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006905355956405401, batch 129, lote_designado 1\n",
      "lr: 1e-05, batch: 129\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8905043 ]\n",
      " [0.88869256]\n",
      " [0.88576376]\n",
      " [0.88119525]\n",
      " [0.78419217]\n",
      " [0.88804197]\n",
      " [0.88445926]\n",
      " [0.87986636]] | y: 0.8299108872530028 | Predicción actual: [[0.8742489]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002588157309219241, batch 130, lote_designado 1\n",
      "lr: 1e-05, batch: 130\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88869256]\n",
      " [0.88576376]\n",
      " [0.88119525]\n",
      " [0.78419217]\n",
      " [0.88804197]\n",
      " [0.88445926]\n",
      " [0.87986636]\n",
      " [0.87424892]] | y: 0.887253002712127 | Predicción actual: [[0.86767715]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020137839019298553, batch 131, lote_designado 1\n",
      "lr: 1e-05, batch: 131\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88576376]\n",
      " [0.88119525]\n",
      " [0.78419217]\n",
      " [0.88804197]\n",
      " [0.88445926]\n",
      " [0.87986636]\n",
      " [0.87424892]\n",
      " [0.86767715]] | y: 0.8597442851607902 | Predicción actual: [[0.8609198]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09150589257478714, batch 132, lote_designado 1\n",
      "lr: 1e-05, batch: 132\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88119525]\n",
      " [0.78419217]\n",
      " [0.88804197]\n",
      " [0.88445926]\n",
      " [0.87986636]\n",
      " [0.87424892]\n",
      " [0.86767715]\n",
      " [0.86091977]] | y: 0.8395970554048819 | Predicción actual: [[0.8548678]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.008686123415827751, batch 133, lote_designado 1\n",
      "lr: 1e-05, batch: 133\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78419217]\n",
      " [0.88804197]\n",
      " [0.88445926]\n",
      " [0.87986636]\n",
      " [0.87424892]\n",
      " [0.86767715]\n",
      " [0.86091977]\n",
      " [0.85486782]] | y: 0.7838047268500579 | Predicción actual: [[0.84961873]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 6.376206147251651e-05, batch 134, lote_designado 1\n",
      "lr: 1e-05, batch: 134\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88804197]\n",
      " [0.88445926]\n",
      " [0.87986636]\n",
      " [0.87424892]\n",
      " [0.86767715]\n",
      " [0.86091977]\n",
      " [0.85486782]\n",
      " [0.84961873]] | y: 0.8182874854707476 | Predicción actual: [[0.81828749]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.026447845622897148, batch 135, lote_designado 1\n",
      "lr: 1e-05, batch: 135\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.88445926]\n",
      " [0.87986636]\n",
      " [0.87424892]\n",
      " [0.86767715]\n",
      " [0.86091977]\n",
      " [0.85486782]\n",
      " [0.84961873]\n",
      " [0.81828749]] | y: 0.7911662146454863 | Predicción actual: [[0.86799586]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.018343200907111168, batch 136, lote_designado 1\n",
      "lr: 1e-05, batch: 136\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87986636]\n",
      " [0.87424892]\n",
      " [0.86767715]\n",
      " [0.86091977]\n",
      " [0.85486782]\n",
      " [0.84961873]\n",
      " [0.81828749]\n",
      " [0.86799586]] | y: 0.7605579232855482 | Predicción actual: [[0.8620708]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0020772619172930717, batch 137, lote_designado 1\n",
      "lr: 1e-05, batch: 137\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.87424892]\n",
      " [0.86767715]\n",
      " [0.86091977]\n",
      " [0.85486782]\n",
      " [0.84961873]\n",
      " [0.81828749]\n",
      " [0.86799586]\n",
      " [0.8620708 ]] | y: 0.7915536613715615 | Predicción actual: [[0.8560941]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05585816502571106, batch 138, lote_designado 1\n",
      "lr: 1e-05, batch: 138\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86767715]\n",
      " [0.86091977]\n",
      " [0.85486782]\n",
      " [0.84961873]\n",
      " [0.81828749]\n",
      " [0.86799586]\n",
      " [0.8620708 ]\n",
      " [0.85609412]] | y: 0.7686943045331267 | Predicción actual: [[0.85001004]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.016518542543053627, batch 139, lote_designado 1\n",
      "lr: 1e-05, batch: 139\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86091977]\n",
      " [0.85486782]\n",
      " [0.84961873]\n",
      " [0.81828749]\n",
      " [0.86799586]\n",
      " [0.8620708 ]\n",
      " [0.85609412]\n",
      " [0.85001004]] | y: 0.7686943045331267 | Predicción actual: [[0.8447917]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.015609849244356155, batch 140, lote_designado 1\n",
      "lr: 1e-05, batch: 140\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85486782]\n",
      " [0.84961873]\n",
      " [0.81828749]\n",
      " [0.86799586]\n",
      " [0.8620708 ]\n",
      " [0.85609412]\n",
      " [0.85001004]\n",
      " [0.84479171]] | y: 0.7989151491669895 | Predicción actual: [[0.8412792]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00754527049139142, batch 141, lote_designado 1\n",
      "lr: 1e-05, batch: 141\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84961873]\n",
      " [0.81828749]\n",
      " [0.86799586]\n",
      " [0.8620708 ]\n",
      " [0.85609412]\n",
      " [0.85001004]\n",
      " [0.84479171]\n",
      " [0.84127921]] | y: 0.7900038744672608 | Predicción actual: [[0.8394555]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.003332197666168213, batch 142, lote_designado 1\n",
      "lr: 1e-05, batch: 142\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81828749]\n",
      " [0.86799586]\n",
      " [0.8620708 ]\n",
      " [0.85609412]\n",
      " [0.85001004]\n",
      " [0.84479171]\n",
      " [0.84127921]\n",
      " [0.83945549]] | y: 0.760170476559473 | Predicción actual: [[0.8389706]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002181190764531493, batch 143, lote_designado 1\n",
      "lr: 1e-05, batch: 143\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.86799586]\n",
      " [0.8620708 ]\n",
      " [0.85609412]\n",
      " [0.85001004]\n",
      " [0.84479171]\n",
      " [0.84127921]\n",
      " [0.83945549]\n",
      " [0.8389706 ]] | y: 0.6853932584269664 | Predicción actual: [[0.68539326]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.004171164706349373, batch 144, lote_designado 1\n",
      "lr: 1e-05, batch: 144\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8620708 ]\n",
      " [0.85609412]\n",
      " [0.85001004]\n",
      " [0.84479171]\n",
      " [0.84127921]\n",
      " [0.83945549]\n",
      " [0.8389706 ]\n",
      " [0.68539326]] | y: 0.6051917861294072 | Predicción actual: [[0.84116495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006717025302350521, batch 145, lote_designado 1\n",
      "lr: 1e-05, batch: 145\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85609412]\n",
      " [0.85001004]\n",
      " [0.84479171]\n",
      " [0.84127921]\n",
      " [0.83945549]\n",
      " [0.8389706 ]\n",
      " [0.68539326]\n",
      " [0.84116495]] | y: 0.6648585819449826 | Predicción actual: [[0.83369243]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.05835770443081856, batch 146, lote_designado 1\n",
      "lr: 1e-05, batch: 146\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.85001004]\n",
      " [0.84479171]\n",
      " [0.84127921]\n",
      " [0.83945549]\n",
      " [0.8389706 ]\n",
      " [0.68539326]\n",
      " [0.84116495]\n",
      " [0.83369243]] | y: 0.7078651685393258 | Predicción actual: [[0.8250652]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.00022182794054970145, batch 147, lote_designado 1\n",
      "lr: 1e-05, batch: 147\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84479171]\n",
      " [0.84127921]\n",
      " [0.83945549]\n",
      " [0.8389706 ]\n",
      " [0.68539326]\n",
      " [0.84116495]\n",
      " [0.83369243]\n",
      " [0.8250652 ]] | y: 0.6648585819449826 | Predicción actual: [[0.81611496]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.001098623382858932, batch 148, lote_designado 1\n",
      "lr: 1e-05, batch: 148\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84127921]\n",
      " [0.83945549]\n",
      " [0.8389706 ]\n",
      " [0.68539326]\n",
      " [0.84116495]\n",
      " [0.83369243]\n",
      " [0.8250652 ]\n",
      " [0.81611496]] | y: 0.7113521890740022 | Predicción actual: [[0.80695456]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0037567303515970707, batch 149, lote_designado 1\n",
      "lr: 1e-05, batch: 149\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83945549]\n",
      " [0.8389706 ]\n",
      " [0.68539326]\n",
      " [0.84116495]\n",
      " [0.83369243]\n",
      " [0.8250652 ]\n",
      " [0.81611496]\n",
      " [0.80695456]] | y: 0.6772568771793879 | Predicción actual: [[0.79743606]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03323449566960335, batch 150, lote_designado 1\n",
      "lr: 1e-05, batch: 150\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8389706 ]\n",
      " [0.68539326]\n",
      " [0.84116495]\n",
      " [0.83369243]\n",
      " [0.8250652 ]\n",
      " [0.81611496]\n",
      " [0.80695456]\n",
      " [0.79743606]] | y: 0.7621077101898488 | Predicción actual: [[0.78717375]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0016906920354813337, batch 151, lote_designado 1\n",
      "lr: 1e-05, batch: 151\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.68539326]\n",
      " [0.84116495]\n",
      " [0.83369243]\n",
      " [0.8250652 ]\n",
      " [0.81611496]\n",
      " [0.80695456]\n",
      " [0.79743606]\n",
      " [0.78717375]] | y: 0.8070515304145678 | Predicción actual: [[0.77629495]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 3.8917645724723116e-05, batch 152, lote_designado 1\n",
      "lr: 1e-05, batch: 152\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.84116495]\n",
      " [0.83369243]\n",
      " [0.8250652 ]\n",
      " [0.81611496]\n",
      " [0.80695456]\n",
      " [0.79743606]\n",
      " [0.78717375]\n",
      " [0.77629495]] | y: 0.8151879116621463 | Predicción actual: [[0.81518791]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.0668594541130005e-06, batch 153, lote_designado 1\n",
      "lr: 1e-05, batch: 153\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.83369243]\n",
      " [0.8250652 ]\n",
      " [0.81611496]\n",
      " [0.80695456]\n",
      " [0.79743606]\n",
      " [0.78717375]\n",
      " [0.77629495]\n",
      " [0.81518791]] | y: 0.9062378922898102 | Predicción actual: [[0.8009995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.02896714396774769, batch 154, lote_designado 1\n",
      "lr: 1e-05, batch: 154\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.8250652 ]\n",
      " [0.81611496]\n",
      " [0.80695456]\n",
      " [0.79743606]\n",
      " [0.78717375]\n",
      " [0.77629495]\n",
      " [0.81518791]\n",
      " [0.80099952]] | y: 0.9597055404881829 | Predicción actual: [[0.7930241]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.023692980408668518, batch 155, lote_designado 1\n",
      "lr: 1e-05, batch: 155\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81611496]\n",
      " [0.80695456]\n",
      " [0.79743606]\n",
      " [0.78717375]\n",
      " [0.77629495]\n",
      " [0.81518791]\n",
      " [0.80099952]\n",
      " [0.79302412]] | y: 0.9643549012010848 | Predicción actual: [[0.7862836]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.06263561546802521, batch 156, lote_designado 1\n",
      "lr: 1e-05, batch: 156\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80695456]\n",
      " [0.79743606]\n",
      " [0.78717375]\n",
      " [0.77629495]\n",
      " [0.81518791]\n",
      " [0.80099952]\n",
      " [0.79302412]\n",
      " [0.78628361]] | y: 0.8880278961642774 | Predicción actual: [[0.7813092]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015505977207794785, batch 157, lote_designado 1\n",
      "lr: 1e-05, batch: 157\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79743606]\n",
      " [0.78717375]\n",
      " [0.77629495]\n",
      " [0.81518791]\n",
      " [0.80099952]\n",
      " [0.79302412]\n",
      " [0.78628361]\n",
      " [0.78130919]] | y: 0.8926772568771792 | Predicción actual: [[0.7781454]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.024030406028032303, batch 158, lote_designado 1\n",
      "lr: 1e-05, batch: 158\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78717375]\n",
      " [0.77629495]\n",
      " [0.81518791]\n",
      " [0.80099952]\n",
      " [0.79302412]\n",
      " [0.78628361]\n",
      " [0.78130919]\n",
      " [0.77814537]] | y: 0.8752421542037967 | Predicción actual: [[0.7773255]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0008002922404557467, batch 159, lote_designado 1\n",
      "lr: 1e-05, batch: 159\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77629495]\n",
      " [0.81518791]\n",
      " [0.80099952]\n",
      " [0.79302412]\n",
      " [0.78628361]\n",
      " [0.78130919]\n",
      " [0.77814537]\n",
      " [0.77732551]] | y: 0.8508330104610615 | Predicción actual: [[0.77905995]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.002342235529795289, batch 160, lote_designado 1\n",
      "lr: 1e-05, batch: 160\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.81518791]\n",
      " [0.80099952]\n",
      " [0.79302412]\n",
      " [0.78628361]\n",
      " [0.78130919]\n",
      " [0.77814537]\n",
      " [0.77732551]\n",
      " [0.77905995]] | y: 0.8488957768306855 | Predicción actual: [[0.7837316]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0009243181557394564, batch 161, lote_designado 1\n",
      "lr: 1e-05, batch: 161\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.80099952]\n",
      " [0.79302412]\n",
      " [0.78628361]\n",
      " [0.78130919]\n",
      " [0.77814537]\n",
      " [0.77732551]\n",
      " [0.77905995]\n",
      " [0.78373158]] | y: 0.9624176675707088 | Predicción actual: [[0.96241767]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.1382920742034912, batch 162, lote_designado 1\n",
      "lr: 1e-05, batch: 162\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.79302412]\n",
      " [0.78628361]\n",
      " [0.78130919]\n",
      " [0.77814537]\n",
      " [0.77732551]\n",
      " [0.77905995]\n",
      " [0.78373158]\n",
      " [0.96241767]] | y: 0.9678419217357612 | Predicción actual: [[0.77437764]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.029239371418952942, batch 163, lote_designado 1\n",
      "lr: 1e-05, batch: 163\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78628361]\n",
      " [0.78130919]\n",
      " [0.77814537]\n",
      " [0.77732551]\n",
      " [0.77905995]\n",
      " [0.78373158]\n",
      " [0.96241767]\n",
      " [0.77437764]] | y: 0.9407206509104997 | Predicción actual: [[0.7750941]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.006770848296582699, batch 164, lote_designado 1\n",
      "lr: 1e-05, batch: 164\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78130919]\n",
      " [0.77814537]\n",
      " [0.77732551]\n",
      " [0.77905995]\n",
      " [0.78373158]\n",
      " [0.96241767]\n",
      " [0.77437764]\n",
      " [0.77509409]] | y: 0.9724912824486633 | Predicción actual: [[0.7790323]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0927945226430893, batch 165, lote_designado 1\n",
      "lr: 1e-05, batch: 165\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77814537]\n",
      " [0.77732551]\n",
      " [0.77905995]\n",
      " [0.78373158]\n",
      " [0.96241767]\n",
      " [0.77437764]\n",
      " [0.77509409]\n",
      " [0.77903229]] | y: 0.9969004261913985 | Predicción actual: [[0.78609055]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.09615939855575562, batch 166, lote_designado 1\n",
      "lr: 1e-05, batch: 166\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77732551]\n",
      " [0.77905995]\n",
      " [0.78373158]\n",
      " [0.96241767]\n",
      " [0.77437764]\n",
      " [0.77509409]\n",
      " [0.77903229]\n",
      " [0.78609055]] | y: 0.951181712514529 | Predicción actual: [[0.7956165]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0694359764456749, batch 167, lote_designado 1\n",
      "lr: 1e-05, batch: 167\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77905995]\n",
      " [0.78373158]\n",
      " [0.96241767]\n",
      " [0.77437764]\n",
      " [0.77509409]\n",
      " [0.77903229]\n",
      " [0.78609055]\n",
      " [0.79561651]] | y: 0.8957768306857805 | Predicción actual: [[0.806545]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 1.5055048606882337e-05, batch 168, lote_designado 1\n",
      "lr: 1e-05, batch: 168\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78373158]\n",
      " [0.96241767]\n",
      " [0.77437764]\n",
      " [0.77509409]\n",
      " [0.77903229]\n",
      " [0.78609055]\n",
      " [0.79561651]\n",
      " [0.80654502]] | y: 0.8814413018209997 | Predicción actual: [[0.8173626]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0015938897849991918, batch 169, lote_designado 1\n",
      "lr: 1e-05, batch: 169\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.96241767]\n",
      " [0.77437764]\n",
      " [0.77509409]\n",
      " [0.77903229]\n",
      " [0.78609055]\n",
      " [0.79561651]\n",
      " [0.80654502]\n",
      " [0.81736261]] | y: 0.9170864006199149 | Predicción actual: [[0.82688874]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0002962602593470365, batch 170, lote_designado 1\n",
      "lr: 1e-05, batch: 170\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77437764]\n",
      " [0.77509409]\n",
      " [0.77903229]\n",
      " [0.78609055]\n",
      " [0.79561651]\n",
      " [0.80654502]\n",
      " [0.81736261]\n",
      " [0.82688874]] | y: 0.919798527702441 | Predicción actual: [[0.91979853]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.04118267819285393, batch 171, lote_designado 1\n",
      "lr: 1e-05, batch: 171\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77509409]\n",
      " [0.77903229]\n",
      " [0.78609055]\n",
      " [0.79561651]\n",
      " [0.80654502]\n",
      " [0.81736261]\n",
      " [0.82688874]\n",
      " [0.91979853]] | y: 0.9616427741185587 | Predicción actual: [[0.7899541]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0596243217587471, batch 172, lote_designado 1\n",
      "lr: 1e-05, batch: 172\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.77903229]\n",
      " [0.78609055]\n",
      " [0.79561651]\n",
      " [0.80654502]\n",
      " [0.81736261]\n",
      " [0.82688874]\n",
      " [0.91979853]\n",
      " [0.78995413]] | y: 0.9682293684618366 | Predicción actual: [[0.79997224]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.03630545362830162, batch 173, lote_designado 1\n",
      "lr: 1e-05, batch: 173\n",
      ">Fin lote<\n",
      "Ejemplar x: [[0.78609055]\n",
      " [0.79561651]\n",
      " [0.80654502]\n",
      " [0.81736261]\n",
      " [0.82688874]\n",
      " [0.91979853]\n",
      " [0.78995413]\n",
      " [0.79997224]] | y: 0.9577683068578069 | Predicción actual: [[0.81161433]]\n",
      "Lr que voy a aplicar en el lote es 9.999999747378752e-06\n",
      "loss en el callback: 0.0005926345475018024, batch 174, lote_designado 1\n",
      "lr: 1e-05, batch: 174\n",
      ">Fin lote<\n",
      "Se resetea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12389325726463696,\n",
       " 0.12413302685184611,\n",
       " 0.12323438427770847,\n",
       " 0.12623179922523325,\n",
       " 0.12604638479775437,\n",
       " 0.12475872666667186,\n",
       " 0.12484375408626758,\n",
       " 0.125682004703958,\n",
       " 0.1263528139438373,\n",
       " 0.12674657241689505,\n",
       " 0.12589410494411785,\n",
       " 0.12449866194134936,\n",
       " 0.12634070525681043,\n",
       " 0.1279924332076849,\n",
       " 0.12829748170562602,\n",
       " 0.12755625731091752,\n",
       " 0.1315207039619848,\n",
       " 0.13312295156628293,\n",
       " 0.12882559586411227,\n",
       " 0.12777923010741646,\n",
       " 0.1315239279458558,\n",
       " 0.12938529643134744,\n",
       " 0.13048129882696166,\n",
       " 0.13084827611584668,\n",
       " 0.1362778290391154,\n",
       " 0.12916345450028976,\n",
       " 0.1306183549338757,\n",
       " 0.13243951262175052,\n",
       " 0.13117282358844592,\n",
       " 0.13346561270078733]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f'redes/NARNN/auto_predictiva/red_NARNN.pth'\n",
    "red.load_state_dict(torch.load(model_path))\n",
    "red.eval()\n",
    "\n",
    "entr = entr(red,0, logs_dir_auto_pred)\n",
    "entr_red.entrena_lm(entrenamiento_8_1[0],EPOCAS,lr=0.5,λ=0.1,batch_size=8,decay_factor=5,e_predictivo=True)\n",
    "# torch.save(networks[0].state_dict(), 'redes/DWT_NARNN/red_A5_pred') #Salvamos el estado actual del modelo\n",
    "\n",
    "# red.save_weights(f'redes/LSTM/auto_predictiva/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdida: 32.46885432713034\n"
     ]
    }
   ],
   "source": [
    "# Predice el conjunto de entrenamiento usando la prediccion predictiva a partir de los primeros (usando los datos que predice)\n",
    "prediccion_ap = utls.genera_prediccion_predictiva(prueba_8_1[0][0][:8],8,len(prueba_8_1[0]),red)\n",
    "red_ap_precios_predichos = utls.desnormalizar(prediccion_ap,np.max(c_prueba),np.min(c_prueba)).detach().numpy()\n",
    "\n",
    "plt.plot(c_prueba, color = '#451952', label = 'Precios originales')\n",
    "plt.plot(red_ap_precios_predichos, label = 'Precios predichos')#label=f\"Datos de Analisis: {DATOS}\",\n",
    "plt.title('Conjunto de Prueba')\n",
    "plt.xlabel('Semanas')\n",
    "plt.ylabel('Precio')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Perdida: {float(criterion(torch.tensor(red_ap_precios_predichos), torch.tensor(c_prueba)))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          RMSE     MAPE       DS\n",
      "Precicción de c_prueba  5.6981  13.8056  83.7209\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "r_c_prueba_txt = 'Precicción de c_prueba'\n",
    "# Supongamos que tenemos una lista de errores de predicción para cada red neuronal\n",
    "rmse = {\n",
    "    r_c_prueba_txt: utls.rmse(c_prueba,red_ap_precios_predichos)\n",
    "}\n",
    "mape = {\n",
    "    r_c_prueba_txt: utls.mape(c_prueba,red_ap_precios_predichos)\n",
    "}\n",
    "ds = {\n",
    "    r_c_prueba_txt: utls.directional_symmetry(c_prueba,red_ap_precios_predichos)\n",
    "}\n",
    "\n",
    "# Creamos un DataFrame de Pandas a partir del diccionario de errores\n",
    "df_errores = pd.DataFrame({\n",
    "    'RMSE': pd.Series(rmse),\n",
    "    'MAPE': pd.Series(mape),\n",
    "    'DS': pd.Series(ds)\n",
    "})\n",
    "\n",
    "# Mostramos el DataFrame con los errores\n",
    "print(df_errores) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
